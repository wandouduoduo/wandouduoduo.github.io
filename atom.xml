<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>豌豆多多</title>
  
  <subtitle>Senior O &amp; M Architect</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://wandouduoduo.netlify.com/"/>
  <updated>2019-12-23T07:18:08.726Z</updated>
  <id>https://wandouduoduo.netlify.com/</id>
  
  <author>
    <name>WanDouDuoDuo</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Elasticsearch分片副本机制</title>
    <link href="https://wandouduoduo.netlify.com/articles/688d9226.html"/>
    <id>https://wandouduoduo.netlify.com/articles/688d9226.html</id>
    <published>2019-12-23T06:46:15.000Z</published>
    <updated>2019-12-23T07:18:08.726Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>日常运维工作中，保证系统服务的稳定是第一优先级的。做好高可用方案是关键。在用Elasticsearch作为存储的服务中，保证Elasticsearch数据的高可用，数据的安全性和一致性至关重要。本文就针对这一问题详细介绍了Elasticsearch的分片和副本机制。</p><a id="more"></a><h2 id="分片和副本机制"><a href="#分片和副本机制" class="headerlink" title="分片和副本机制"></a>分片和副本机制</h2><ol><li><p>index(索引) 包含多个 shard(分片)，创建 index 时可以在settings中设置分片数，不设置时默认是5个。</p></li><li><p>每个 shard 都是一个最小工作单元，承载部分数据；每个 shard 都是一个 lucene 实例，并且具有完整的建立索引和处理能力。</p></li><li><p>增减节点时，shard 会自动在 nodes 中负载均衡。</p></li><li><p>primary shard（主分片） 和 replica shard（副本分片），每个 document 肯定只存在于某一个 primary shard 以及对应的 replica shard 中，不可能存在于多个 primary shard 。</p><p><img src="/articles/688d9226/1.png" alt></p></li><li><p>replica shard 是 primary shard 的副本，负责容错，以及承担读请求负载。</p></li><li><p>primary shard 的数量在创建索引的时候就固定了，不可更改；replica shard 的数量可以随时修改。</p></li><li><p>primary shard 的默认数量是5，replica 默认是1，默认有10个 shard，5个 primary shard ，5个 replica shard 。</p></li><li><p>primary shard 不能和自己的 replica shard 放在同一个节点上，否则节点宕机，primary shard 和副本都丢失，容错机制将失效；但是可以和其他 primary shard 的 replica shard 放在同一个节点上。</p><p><img src="/articles/688d9226/2.png" alt></p></li></ol><h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><p>Shards分片个数:  3</p><p>Replica副本个数：3</p><h4 id="单节点环境下"><a href="#单节点环境下" class="headerlink" title="单节点环境下"></a>单节点环境下</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">PUT /myindex</span><br><span class="line">&#123;</span><br><span class="line">    &quot;settings&quot;: &#123;</span><br><span class="line">        &quot;number_of_shards&quot;: 3,</span><br><span class="line">        &quot;number_of_replica&quot;: 1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"># 查看集群健康状态 --- 将返回yellow，说明集群状态不健康</span><br><span class="line">GET _cat/health</span><br></pre></td></tr></table></figure><p>此时，因为是单节点环境，3个 primary shard 只能分配到这个仅有的 node 上，另外3个 replica shard 是无法分配的（一个 shard 的副本 replica，两个是不能在同一个节点），集群可以正常工作；但出现宕机，数据全部丢失，而且集群不可用，无法接受任何请求。</p><h4 id="两个节点环境下"><a href="#两个节点环境下" class="headerlink" title="两个节点环境下"></a>两个节点环境下</h4><p>将3个 primary shard 分配到一个 node 上，另外3个 replica shard 分配到另一个节点上；<br>primary shard 和 replica shard 保持同步；<br>primary shard 和 replica shard 都可以处理客户端的读请求。</p><p><img src="/articles/688d9226/3.png" alt></p><h4 id="三个节点环境下"><a href="#三个节点环境下" class="headerlink" title="三个节点环境下"></a>三个节点环境下</h4><p>将3个 primary shard 分别分配到一个 node 上，另外3个 replica shard 也交叉分配到另一个节点上；</p><p><img src="/articles/688d9226/1.png" alt></p><p>这样3个节点都可以负载均衡增大访问量，同时如果一台服务器宕机后，数据也不会丢失，还可以对外正常提供服务。保证了服务的高可用和数据的安全。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>建议:  primary shard的个数和集群节点数一致，replica shard 数可以根据业务需求量决定，需求量大可以设定多个replica shard，来增加读取操作。但是至少每个primary shard设置1个replica shard，来保证高可用和数据的安全性。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;日常运维工作中，保证系统服务的稳定是第一优先级的。做好高可用方案是关键。在用Elasticsearch作为存储的服务中，保证Elasticsearch数据的高可用，数据的安全性和一致性至关重要。本文就针对这一问题详细介绍了Elasticsearch的分片和副本机制。&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.netlify.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://wandouduoduo.netlify.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="https://wandouduoduo.netlify.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Nginx之正反代理详解</title>
    <link href="https://wandouduoduo.netlify.com/articles/c5ecc6c0.html"/>
    <id>https://wandouduoduo.netlify.com/articles/c5ecc6c0.html</id>
    <published>2019-12-19T11:14:45.000Z</published>
    <updated>2019-12-24T04:16:05.986Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在日常运维工作中，常常会用到反向代理，为了更安全同时为了负载均衡，分担压力。</p><p>那么，有小伙伴就会有疑问：</p><ul><li>什么是反向代理？</li><li>负载均衡又是怎么实现的？</li><li>有反向代理那有正向代理吗？</li><li>正向代理的应用场景是怎样的？</li><li>反向代理和正向代理怎么配置实现呢？</li></ul><p>带着这些疑问，就给大家详细解释下nginx的正反向代理。</p><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>Nginx（Nginx是一款自由的、开源的、高性能的HTTP服务器。功能优势等等这里就不再赘述了。度娘那里有很多信息。）</p><h2 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h2><p>说到代理，首先我们要明确一个概念，所谓代理就是一个代表、一个渠道；</p><p>此时就设计到两个角色，一个是被代理角色，一个是目标角色，被代理角色通过这个代理访问目标角色完成一些任务的过程称为代理操作过程；如同生活中的专卖店~客人到adidas专卖店买了一双鞋，这个专卖店就是代理，被代理角色就是adidas厂家，目标角色就是用户。</p><h2 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h2><p>我们在运维的日常工作中经常用到负载均衡，所以接触反向代理比较多，那么反向代理是怎样的呢？。例如人气比较高的网站，如淘宝，京东等等。每天访问人数的人很多，数以万计，此时单台服务器远远不能承载所有人的访问请求，这时作为资深运维人员就需要对web服务进行分布式部署；何为分布式部署呢？就是通过部署多台服务器组成web集群共同来处理访问请求，解决单台服务器不能承载的问题；分布式部署的web服务可以横行扩展。而实现web分布式部署通常要用到反向代理。apache或nginx都可以。本文以nginx为例，用nginx的反向代理实现的。国内公司通过把nginx和其他的组件进行封装，根据场景或侧重点不同，便于构建安装，就有了：Tengine或OpenResty等。有兴趣的朋友可以度娘搜索学习。那么反向代理具体是通过什么样的方式实现的分布式的集群操作呢，我们先看一个示意图：</p><p><img src="/articles/c5ecc6c0/2.png" alt></p><p>通过上述的图解大家就可以看清楚了，多个客户端给服务器发送的请求，nginx服务器接收到之后，按照一定的规则分发给了后端的web服务器进行处理了。此时请求的来源也就是客户端是明确的，但是请求后具体由哪台服务器进行处理响应并不明确了，web服务（nginx）扮演的就是一个反向代理角色。</p><p>反向代理，主要用于服务器集群分布式部署负载均衡共同承载请求压力或安全需求等的情况下使用，反向代理可以隐藏了响应服务器的信息，能够过滤网络攻击，保证安全。</p><h2 id="正向代理"><a href="#正向代理" class="headerlink" title="正向代理"></a>正向代理</h2><p>阴阳两仪生万物，有阴就有阳，有反就有正。说完反向代理了，我们再来看看正向代理。正向代理可能在日常工作中用的不是很多，但是，相信大家经常听到：翻墙这个词，何为翻墙呢？翻墙是因为大陆对网络中攻击等等进行了屏蔽和过滤，相当于防火墙的墙一样，允许的我们才可以访问，屏蔽的我们就不能访问。这是我们做技术的如果需要在国外查询技术文档等就需要翻墙，通常我们需要购买vpn来实现，vpn的功能就是用的正向代理。那么vpn是怎么实现的呢？我们如果需要访问国外的某些网站，此时你会发现位于国外的某网站我们通过浏览器是没有办法访问的，被屏蔽过滤掉了。vpn的方式就是找一个可以正常访问国外网站的代理服务器，我们将请求发送给代理服务器，然后代理服务器去访问国外的网站，然后将访问到的数据传递给我们！</p><p>上述描述的代理模式称为正向代理，正向代理的特点是：客户端非常明确要访问的服务器地址；服务器只清楚请求来自哪个代理服务器，但是不清楚来自哪个具体的客户端；正向代理模式屏蔽或者隐藏了真实客户端信息。如下图</p><p><img src="/articles/c5ecc6c0/1.png" alt></p><h2 id="正反向代理共同使用"><a href="#正反向代理共同使用" class="headerlink" title="正反向代理共同使用"></a>正反向代理共同使用</h2><p>日常在实际项目操作中，正向代理和反向代理会搭配使用。正向代理代理客户端的请求去访问目标服务器，而目标服务器是又使用反向代理服务器，反向代理多台真实的业务处理服务器，进行负载均衡。具体的拓扑图如下：</p><p><img src="/articles/c5ecc6c0/2.jpg" alt></p><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p>我们知道了代理服务器，也一直说负载均衡，何为负载均衡呢？简单的说：web服务（nginx）作为反向代理服务器，依据一定的规则对请求进行分发，把请求平均让后端业务服务器进行响应，已达到分担压力的作用。负载就是客户端对业务发送的请求，分发到不同的服务器处理的规则，就是一种均衡规则。将服务器接收到的请求按照规则分发的过程，就是负载均衡。</p><p>负载均衡，有硬件负载均衡和软件负载均衡两种，硬件负载均衡也称为硬负载，如F5负载均衡，但是相对造价昂贵成本较高，但是数据的稳定性安全性等等有非常好的保障，如国有企业三大运营商这样的公司才会选择硬负载进行操作；通常公司都会考虑到成本问题，会选择使用软件负载均衡，软件负载均衡是利用现有的技术结合主机硬件实现的一种消息队列分发机制。软件负载均衡肯定和硬负载没发比较的，但是成本较低，稳定性和安全性在架构优化后在可接受范围，广为使用。</p><p>nginx的负载均衡规则如下：</p><ul><li><strong>weight轮询（默认</strong>）：接收到的请求按照顺序逐一分配到不同的后端服务器，即使在使用过程中，某一台后端服务器宕机，nginx会自动将该服务器剔除出队列，请求受理情况不会受到任何影响。 这种方式下，可以给不同的后端服务器设置一个权重值（weight），用于调整不同的服务器上请求的分配率；权重数据越大，被分配到请求的几率越大；该权重值，主要是针对实际工作环境中不同的后端服务器硬件配置进行调整的。</li><li><strong>ip_hash</strong>：每个请求按照发起客户端的ip的hash结果进行匹配，这样的算法下一个固定ip地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题。</li><li><strong>fair</strong>：智能调整调度算法，动态的根据后端服务器的请求处理到响应的时间进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高，响应时间长处理效率低的服务器分配到的请求少；结合了前两者的优点的一种调度算法。但是需要注意的是nginx默认不支持fair算法，如果要使用这种调度算法，请安装upstream_fair模块</li><li><strong>url_hash</strong>：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在nginx作为静态服务器的情况下提高缓存效率。同样要注意nginx默认不支持这种调度算法，要使用的话需要安装nginx的hash软件包</li></ul><h2 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h2><p>了解了正反向代理和负载均衡，那么要怎么实现呢？如何去配置。</p><h4 id="正向代理配置"><a href="#正向代理配置" class="headerlink" title="正向代理配置"></a><strong>正向代理配置</strong></h4><p>现在我登录上代理服务器上, 打开/etc/nginx/conf.d/default.conf<br>添加<code>resolver</code>和<code>proxy_pass</code>,设置如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  localhost nginx.tangll.cn;</span><br><span class="line"></span><br><span class="line">    resolver 8.8.8.8;</span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://$http_host$request_uri;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    error_page   500 502 503 504  /50x.html;</span><br><span class="line">    location = /50x.html &#123;</span><br><span class="line">        root   /usr/share/nginx/html;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>resolver</code>为DNS解析,这里填写的IP为Google提供的免费DNS服务器的IP地址。<br><code>proxy_pass</code>配置代理转发。<br>至此便是配置了代理服务器，所有访问请求全部都通过代理服务器转发,<code>$http_host</code>就是我们要访问的主机名,<code>$request_uri</code>就是我们后面所加的参数。<br>简单的说至此就是相当于配置好了我们请求了代理服务器,代理服务器再去请求我们所请求的地址。</p><p>然后，只需要在本机系统或浏览器配置代理即可访问。</p><h6 id="windows配置"><a href="#windows配置" class="headerlink" title="windows配置"></a><strong>windows配置</strong></h6><p><img src="/articles/c5ecc6c0/3.png" alt></p><h6 id="Linux系统"><a href="#Linux系统" class="headerlink" title="Linux系统"></a><strong>Linux系统</strong></h6><p><strong>使用yum 的设置代理的方法</strong></p><p>如果只需要使用yum来更新包的，只需进行yum配置即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vim /etc/yum.conf </span></span><br><span class="line">proxy=http://192.168.99.99:80</span><br><span class="line"><span class="comment">#proxy=ftp://192.168.99.99:80</span></span><br><span class="line"><span class="comment">#proxy_username=username                 #####代理的用户名</span></span><br><span class="line"><span class="comment">#proxy_password=password                  #####代理的密码</span></span><br><span class="line"><span class="comment">#然后直接用yum安装即可</span></span><br></pre></td></tr></table></figure><p><strong>wget设置代理的方法</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vim /etc/wgetrc</span></span><br><span class="line">http_proxy=192.168.99.99:80</span><br><span class="line">http_proxy=192.168.99.99:443</span><br></pre></td></tr></table></figure><p><strong>curl访问代理设置的方法</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#如果访问HTTP网站，可以直接这样的方式: curl --proxy proxy_server:80 http://www.taobao.com/</span></span><br><span class="line"><span class="comment">#如果访问HTTPS网站，例如https://www.alipay.com，那么可以使用nginx的HTTPS转发的server：</span></span><br><span class="line">curl --proxy proxy_server:443 http://www.alipay.com</span><br><span class="line"></span><br><span class="line">[root@localhost ~]<span class="comment"># curl -I --proxy 192.168.99.99:80 www.baidu.com    ###显示http访问的状态码</span></span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">备注：上边有介绍，详见上边内容。</span><br></pre></td></tr></table></figure><p><strong>使用设置全局代理的方法</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vim /etc/profile</span></span><br><span class="line">http_proxy = http://192.168.99.99:80</span><br><span class="line">http_proxy = http://192.168.99.99:443</span><br><span class="line">ftp_proxy = http://192.168.99.99:80/</span><br><span class="line"><span class="built_in">export</span> http_proxy</span><br><span class="line"><span class="built_in">export</span> ftp_proxy</span><br></pre></td></tr></table></figure><h4 id="反向代理配置"><a href="#反向代理配置" class="headerlink" title="反向代理配置"></a>反向代理配置</h4><p>反向代理的演示更为简单一些。<br>首先在/etc/nginx/conf.d/下新建一个default.conf:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  localhost nginx.tangll.cn;</span><br><span class="line">    location / &#123;</span><br><span class="line">        root   /usr/share/nginx/html;</span><br><span class="line">        index  index.html index.htm;</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">    #设置代理</span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://127.0.0.1:8080;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    error_page   500 502 503 504 404  /50x.html;</span><br><span class="line">    location = /50x.html &#123;</span><br><span class="line">        root   /usr/share/nginx/html;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>代理服务器站在客户端那边就是正向代理，代理服务器站在原始服务器那边就是反向代理, Nginx通过<code>proxy_pass</code>可以设置代理服务。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;在日常运维工作中，常常会用到反向代理，为了更安全同时为了负载均衡，分担压力。&lt;/p&gt;
&lt;p&gt;那么，有小伙伴就会有疑问：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;什么是反向代理？&lt;/li&gt;
&lt;li&gt;负载均衡又是怎么实现的？&lt;/li&gt;
&lt;li&gt;有反向代理那有正向代理吗？&lt;/li&gt;
&lt;li&gt;正向代理的应用场景是怎样的？&lt;/li&gt;
&lt;li&gt;反向代理和正向代理怎么配置实现呢？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;带着这些疑问，就给大家详细解释下nginx的正反向代理。&lt;/p&gt;
    
    </summary>
    
      <category term="Web服务" scheme="https://wandouduoduo.netlify.com/categories/Web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Nginx" scheme="https://wandouduoduo.netlify.com/categories/Web%E6%9C%8D%E5%8A%A1/Nginx/"/>
    
    
      <category term="Nginx" scheme="https://wandouduoduo.netlify.com/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>zookeeper集群脑裂探讨</title>
    <link href="https://wandouduoduo.netlify.com/articles/f714eb8e.html"/>
    <id>https://wandouduoduo.netlify.com/articles/f714eb8e.html</id>
    <published>2019-12-19T08:57:10.000Z</published>
    <updated>2019-12-19T10:28:23.763Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是脑裂"><a href="#什么是脑裂" class="headerlink" title="什么是脑裂"></a>什么是脑裂</h2><p>脑裂(split-brain)就是“大脑分裂”，也就是本来一个“大脑”被拆分了两个或多个“大脑”，我们都知道，如果一个人有多个大脑，并且相互独立的话，那么会导致人体“手舞足蹈”，“不听使唤”。</p><p>脑裂通常会出现在集群环境中，比如ElasticSearch、Zookeeper集群，而这些集群环境有一个统一的特点，就是它们有一个大脑，比如ElasticSearch集群中有Master节点，Zookeeper集群中有Leader节点。</p><p>本篇文章着重来给大家讲一下Zookeeper中的脑裂问题，以及是如果解决脑裂问题的。</p><a id="more"></a><h2 id="集群脑裂场景"><a href="#集群脑裂场景" class="headerlink" title="集群脑裂场景"></a>集群脑裂场景</h2><hr><p>对于一个集群，想要提高这个集群的可用性，通常会采用多机房部署，比如现在有一个由6台zkServer所组成的一个集群，部署在了两个机房：</p><p><img src="/articles/f714eb8e/2.png" alt="img"></p><p>正常情况下，此集群只会有一个Leader，那么如果机房之间的网络断了之后，两个机房内的zkServer还是可以相互通信的，如果<strong>不考虑过半机制</strong>，那么就会出现每个机房内部都将选出一个Leader。<img src="/articles/f714eb8e/1.png" alt="img"></p><p>这就相当于原本一个集群，被分成了两个集群，出现了两个“大脑”，这就是脑裂。</p><p>对于这种情况，我们也可以看出来，原本应该是统一的一个集群对外提供服务的，现在变成了两个集群同时对外提供服务，如果过了一会，断了的网络突然联通了，那么此时就会出现问题了，两个集群刚刚都对外提供服务了，数据该怎么合并，数据冲突怎么解决等等问题。</p><p>刚刚在说明脑裂场景时，有一个前提条件就是没有考虑过半机制，所以实际上Zookeeper集群中是不会出现脑裂问题的，而不会出现的原因就跟过半机制有关。</p><h2 id="过半机制"><a href="#过半机制" class="headerlink" title="过半机制"></a>过半机制</h2><p>在领导者选举的过程中，如果某台zkServer获得了超过半数的选票，则此zkServer就可以成为Leader了。</p><p>过半机制的源码实现其实非常简单：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">QuorumMaj</span> <span class="keyword">implements</span> <span class="title">QuorumVerifier</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(QuorumMaj.class);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span> half;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// n表示集群中zkServer的个数（准确的说是参与者的个数，参与者不包括观察者节点）</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">QuorumMaj</span><span class="params">(<span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.half = n/<span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 验证是否符合过半机制</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">containsQuorum</span><span class="params">(Set&lt;Long&gt; set)</span></span>&#123;</span><br><span class="line">        <span class="comment">// half是在构造方法里赋值的</span></span><br><span class="line">        <span class="comment">// set.size()表示某台zkServer获得的票数</span></span><br><span class="line">        <span class="keyword">return</span> (set.size() &gt; half);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>大家仔细看一下上面方法中的注释，核心代码就是下面两行：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">this.half = n/2;return (set.size() &gt; half);</span><br></pre></td></tr></table></figure><p>举个简单的例子：如果现在集群中有5台zkServer，那么half=5/2=2，那么也就是说，领导者选举的过程中至少要有三台zkServer投了同一个zkServer，才会符合过半机制，才能选出来一个Leader。</p><p>那么有一个问题我们想一下，<strong>选举的过程中为什么一定要有一个过半机制验证？</strong>因为这样不需要等待所有zkServer都投了同一个zkServer就可以选举出来一个Leader了，这样比较快，所以叫快速领导者选举算法呗。</p><p>那么再来想一个问题，<strong>过半机制中为什么是大于，而不是大于等于呢？</strong></p><p>这就是更脑裂问题有关系了，比如回到上文出现脑裂问题的场景：<img src="/articles/f714eb8e/3.png" alt="img"></p><p>当机房中间的网络断掉之后，机房1内的三台服务器会进行领导者选举，但是此时过半机制的条件是set.size() &gt; 3，也就是说至少要4台zkServer才能选出来一个Leader，所以对于机房1来说它不能选出一个Leader，同样机房2也不能选出一个Leader，这种情况下整个集群当机房间的网络断掉后，整个集群将没有Leader。没有Leader对外就不能提供服务。</p><p>而如果过半机制的条件是set.size() &gt;= 3，那么机房1和机房2都会选出一个Leader，这样就出现了脑裂。所以我们就知道了，为什么过半机制中是<strong>大于</strong>，而不是<strong>大于等于</strong>。就是为了防止脑裂。</p><p>如果假设我们现在只有5台机器，也部署在两个机房：<img src="/articles/f714eb8e/4.png" alt="img"></p><p>此时过半机制的条件是set.size() &gt; 2，也就是至少要3台服务器才能选出一个Leader，此时机房件的网络断开了，对于机房1来说是没有影响的，Leader依然还是Leader，对于机房2来说是选不出来Leader的，此时整个集群中只有一个Leader。</p><p>所以，我们可以总结得出，有了过半机制，对于一个Zookeeper集群，要么没有Leader，要没只有1个Leader，这样就避免了脑裂问题。</p><h2 id="奇偶节点数探讨"><a href="#奇偶节点数探讨" class="headerlink" title="奇偶节点数探讨"></a>奇偶节点数探讨</h2><p>命题：A,B两个机房5个节点和6个节点zookeeper节点比较。</p><p>5个节点：A机房3个，B机房2个。如果网络出现中断，根据过半机制原则, 大于2个节点就可以选举出来leader。那么结果就是A机房3个节点大于2，就可以正常选举出来Leader。B节点不大于2，不能选举出Leader。这时集群还是可以正常对外提供服务，只是节点少两个而已。当网络恢复后，B机房节点再加入到集群，集群恢复。</p><p>6个节点：A机房3个，B机房3个。如果网络出现中断，根据过半机制原则, 大于3个节点才可以选举出来leader。那么结果就是A机房3个节点不大于3，B节点也不大于3，两个机房都不能选举出Leader。而没有Leader集群就不能对外提供服务，造成整个集群不可用。违背了高可用的初衷。并且还多用一台服务器，还有搭建和维护成本。而且和5个节点冗余是一样的。</p><p>可能有同学会说那A机房4个，B节点2个不就可以了。是的，这样是可以，但是偶数是存在3，3分布的这种情况。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>综上所述，为了保证zookeeper集群高可用，防止脑裂。建议用奇数个zk节点，当然是大于2的奇数。奇数个zk节点有两个好处：1，奇数个节点可用节省一个节点的资源（服务器和部署及维护成本）。2，如为偶数个节点，因为过半机制的设定，有可能出现没有leader，造成整个集群不可以。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是脑裂&quot;&gt;&lt;a href=&quot;#什么是脑裂&quot; class=&quot;headerlink&quot; title=&quot;什么是脑裂&quot;&gt;&lt;/a&gt;什么是脑裂&lt;/h2&gt;&lt;p&gt;脑裂(split-brain)就是“大脑分裂”，也就是本来一个“大脑”被拆分了两个或多个“大脑”，我们都知道，如果一个人有多个大脑，并且相互独立的话，那么会导致人体“手舞足蹈”，“不听使唤”。&lt;/p&gt;
&lt;p&gt;脑裂通常会出现在集群环境中，比如ElasticSearch、Zookeeper集群，而这些集群环境有一个统一的特点，就是它们有一个大脑，比如ElasticSearch集群中有Master节点，Zookeeper集群中有Leader节点。&lt;/p&gt;
&lt;p&gt;本篇文章着重来给大家讲一下Zookeeper中的脑裂问题，以及是如果解决脑裂问题的。&lt;/p&gt;
    
    </summary>
    
      <category term="自动化" scheme="https://wandouduoduo.netlify.com/categories/%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
      <category term="Zookeeper" scheme="https://wandouduoduo.netlify.com/categories/%E8%87%AA%E5%8A%A8%E5%8C%96/Zookeeper/"/>
    
    
      <category term="Zookeeper" scheme="https://wandouduoduo.netlify.com/tags/Zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>Tomcat最强优化</title>
    <link href="https://wandouduoduo.netlify.com/articles/a315956e.html"/>
    <id>https://wandouduoduo.netlify.com/articles/a315956e.html</id>
    <published>2019-12-19T06:54:38.000Z</published>
    <updated>2019-12-19T08:44:05.768Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文不在于给出最佳配置，而是带领开发者，能够从实际情况出发，通过不断的调节tomcat和jvm参数，去发现吞吐量，平均响应时间和错误率等信息的变化，同时根据服务器的cpu和内存等信息，结合接口的业务逻辑，最好是测试使用率最高，并发最大，或者是最重要的接口(比如下单支付接口)，设置最优的tomcat和jvm配置参数。通过Tomcat性能优化可以提高网站的并发能力。Tomcat服务器在JavaEE项目中使用率非常高，所以在生产环境对Tomcat的优化也变得非常重要了。</p><a id="more"></a><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>对于Tomcat的优化，主要是从2个方面入手：</p><p>一是<strong>Tomcat自身的配置</strong>，另一个是<strong>Tomcat所运行的jvm虚拟机的调优</strong>。</p><h2 id="硬件资源"><a href="#硬件资源" class="headerlink" title="硬件资源"></a>硬件资源</h2><p>服务器所能提供CPU、内存、硬盘的性能对处理能力有决定性影响。硬件我们不说了，这个方面是钱越多越好是吧。</p><h2 id="Tomcat配置优化"><a href="#Tomcat配置优化" class="headerlink" title="Tomcat配置优化"></a>Tomcat配置优化</h2><h4 id="管理界面"><a href="#管理界面" class="headerlink" title="管理界面"></a>管理界面</h4><p>Linux环境安装运行Tomcat8，具体的安装步骤省略 (官网下载，解压即可)。</p><p><a href="https://tomcat.apache.org/download-80.cgi" target="_blank" rel="noopener">Tomcat官网</a></p><p>如果需要登录系统，必须配置tomcat用户，在安装完Tomcat后，进行如下操作</p><p>在 <strong>/conf/tomcat-users.xml</strong>  文件中的 <tomcat-users> 标签里面添加如下内容</tomcat-users></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 修改配置文件，配置tomcat的管理用户 --&gt;</span><br><span class="line">&lt;role rolename=&quot;manager&quot;/&gt;</span><br><span class="line">&lt;role rolename=&quot;manager-gui&quot;/&gt;</span><br><span class="line">&lt;role rolename=&quot;admin&quot;/&gt;</span><br><span class="line">&lt;role rolename=&quot;admin-gui&quot;/&gt;</span><br><span class="line">&lt;user username=&quot;tomcat&quot; password=&quot;tomcat&quot; roles=&quot;admin-gui,admin,manager-gui,manager&quot;/&gt;</span><br></pre></td></tr></table></figure><p>如果是tomcat7，配置了tomcat用户就可以登录系统了，但是tomcat8中不行，还需要修改另一个配置文件，否则访问不了，提示403，打开 <code>webapps/manager/META-INF/context.xml</code>文件</p><p>启动Tomcat。(下图为默认配置启动)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/startup.sh</span><br></pre></td></tr></table></figure><p><img src="/articles/a315956e/1.png" alt></p><p>打开浏览器进行访问<a href="http://10.93.165.61:8080/" target="_blank" rel="noopener">http://10.93.165.61:8080/</a>,  点击“Server Status”，输入用户名/密码进行登陆tomcat/tomcat</p><p><img src="/articles/a315956e/2.png" alt></p><p>登录之后可以看到服务器状态等信息，主要包括服务器信息，JVM，ajp和http信息</p><p><img src="/articles/a315956e/3.png" alt></p><h4 id="AJP连接"><a href="#AJP连接" class="headerlink" title="AJP连接"></a>AJP连接</h4><p>在服务状态页面中可以看到，默认状态下会启用AJP服务，并且占用8009端口。</p><p><img src="/articles/a315956e/4.png" alt></p><p><strong>什么是AJP</strong></p><p>AJP（Apache JServer Protocol）<br>AJPv13协议是面向包的。WEB服务器和Servlet容器通过TCP连接来交互；为了节省SOCKET创建的昂贵代价，WEB服务器会尝试维护一个永久TCP连接到servlet容器，并且在多个请求和响应周期过程会重用连接。</p><p><img src="/articles/a315956e/5.png" alt></p><p>我们一般是使用Nginx+Tomcat的架构，所以用不着AJP协议，把AJP连接器禁用。</p><p>修改conf下的server.xml文件，将AJP服务禁用掉即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 禁用AJP连接 --&gt;</span><br><span class="line">&lt;!-- &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; --&gt;</span><br></pre></td></tr></table></figure><p>重启tomcat，查看效果。可以看到AJP服务已经不存在了。</p><p><img src="/articles/a315956e/6.png" alt></p><h4 id="执行器（线程池）"><a href="#执行器（线程池）" class="headerlink" title="执行器（线程池）"></a>执行器（线程池）</h4><p>在tomcat中每一个用户请求都是一个线程，所以可以使用线程池提高性能。</p><p>修改server.xml文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--将注释打开--&gt;</span><br><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;500&quot; minSpareThreads=&quot;50&quot; prestartminSpareThreads=&quot;true&quot; maxQueueSize=&quot;100&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--</span><br><span class="line">参数说明：</span><br><span class="line">maxThreads：最大并发数，默认设置 200，一般建议在 500 ~ 1000，根据硬件设施和业务来判断</span><br><span class="line">minSpareThreads：Tomcat 初始化时创建的线程数，默认设置 25</span><br><span class="line">prestartminSpareThreads： 在 Tomcat 初始化的时候就初始化 minSpareThreads 的参数值，如果不等于 true，minSpareThreads 的值就没啥效果了</span><br><span class="line">maxQueueSize，最大的等待队列数，超过则拒绝请求</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--在Connector中设置executor属性指向上面的执行器--&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure><p>保存退出，重启tomcat，查看效果。</p><p><img src="/articles/a315956e/7.png" alt></p><p>在页面中显示最大线程数为-1，这个是正常的，仅仅是显示的问题，实际使用的是指定的值。如果配置了一个Executor，则该属性的任何值将被正确记录，但是它将被显示为-1</p><h4 id="运行模式"><a href="#运行模式" class="headerlink" title="运行模式"></a>运行模式</h4><p>tomcat的运行模式有3种：</p><p><strong>bio</strong><br>性能非常低下，没有经过任何优化处理和支持。</p><p><strong>nio</strong><br>nio(new I/O)，是Java SE 1.4及后续版本提供的一种新的I/O操作方式(即java.nio包及其子包)。Java nio是一个基于缓冲区、并能提供非阻塞I/O操作的Java API，因此nio也被看成是non-blocking I/O的缩写。它拥有比传统I/O操作(bio)更好的并发运行性能。Tomcat8默认使用nio运行模式。</p><p><strong>apr</strong><br>安装起来最困难，但是从操作系统级别来解决异步的IO问题，大幅度的提高性能。</p><p>对于每种协议，Tomcat都提供了对应的I/O方式的实现，而且Tomcat官方还提供了在每种协议下每种I/O实现方案的差异， HTTP协议下的处理方式如下表，详情可查看<a href="https://tomcat.apache.org/tomcat-8.5-doc/config/http.html" target="_blank" rel="noopener">Tomcat官网说明</a></p><p><img src="/articles/a315956e/8.png" alt><br>推荐使用nio，在tomcat8中有最新的nio2，速度更快，建议使用nio2</p><p>设置nio2：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot;  port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11Nio2Protocol&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure><p>可以看到已经设置为nio2了。</p><p>部署测试用的web项目<br>为了方便测试性能，我们将部署一个java web项目，这个项目本身和本博客没有什么关系，仅仅用于测试。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：这里在测试时，我们使用一个新的tomcat，进行测试，后面再对其进行优化调整，再测试。</span><br></pre></td></tr></table></figure><h2 id="查看服务器信息"><a href="#查看服务器信息" class="headerlink" title="查看服务器信息"></a>查看服务器信息</h2><p>说明一下我的测试服务器配置，不同的服务器配置对Tomcat的性能会有所影响。</p><p><img src="/articles/a315956e/9.png" alt></p><p>CentOS7服务器环境信息查看命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">查看Linux版本：cat /etc/centos-release</span><br><span class="line"></span><br><span class="line">查看CPU个数</span><br><span class="line">查看逻辑cpu个数：cat /proc/cpuinfo | grep “processor” | wc -l</span><br><span class="line">查看物理cpu个数：cat /proc/cpuinfo | grep “physical id” | sort | uniq | wc -l</span><br><span class="line">查看每个物理cpu的核数cores：cat /proc/cpuinfo | grep “cpu cores”</span><br><span class="line">如果所有物理cpu的cores个数加起来小于逻辑cpu的个数，则该cpu使用了超线程技术。查看每个物理cpu中逻辑cpu的个数：cat /proc/cpuinfo | grep “siblings”</span><br><span class="line"></span><br><span class="line">查看内存使用情况</span><br><span class="line">查看内存占用情况：free -m</span><br><span class="line"></span><br><span class="line">参数说明</span><br><span class="line">Mem：内存的使用情况总览表。</span><br><span class="line">total：机器总的物理内存 单位为：M</span><br><span class="line">used：用掉的内存。</span><br><span class="line">free：空闲的物理内存。</span><br></pre></td></tr></table></figure><h2 id="部署web应用"><a href="#部署web应用" class="headerlink" title="部署web应用"></a>部署web应用</h2><p>上传war包到linux服务器，然后进行部署</p><p>我的web应用的名字叫tomcat-optimization，主要是提供了一个查询用户列表的接口，该接口会去阿里云数据库查询用户列表，没有任务业务逻辑的处理。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除tomcat的/webapps/ROOT目录的所有文件</span></span><br><span class="line"><span class="built_in">cd</span> /webapps/ROOT</span><br><span class="line">rm -rf *</span><br><span class="line"></span><br><span class="line"><span class="comment"># 上传war包到tomcat的/webapps/ROOT，然后解压</span></span><br><span class="line">jar -xvf tomcat-optimization.war</span><br><span class="line">rm -rf tomcat-optimization.war</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入tomcat的/bin目录重启tomcat</span></span><br><span class="line"><span class="built_in">cd</span> /bin</span><br><span class="line">./shutdown.sh</span><br><span class="line">./startup.sh</span><br></pre></td></tr></table></figure><p>访问接口地址： <a href="http://10.93.165.61:8080/user/listUser" target="_blank" rel="noopener">http://10.93.165.61:8080/user/listUser</a></p><h2 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h2><p>Apache JMeter是Apache组织开发的基于Java的压力测试工具。 我们借助于此工具进行测试，将测试出tomcat的吞吐量等信息。</p><p><a href="http://jmeter.apache.org/download_jmeter.cgi" target="_blank" rel="noopener">官网下载地址</a></p><p><img src="/articles/a315956e/10.png" alt></p><p>注意：这里需要先安装好jdk8及其以上版本的环境。</p><p>直接将下载好的zip压缩包进行解压, 进入bin目录，找到jmeter.bat文件，双机打开即可启动。</p><p><img src="/articles/a315956e/11.png" alt></p><p>启动后，JMeter主页面如下</p><p><img src="/articles/a315956e/12.png" alt></p><p>修改语言<br>默认的主题是黑色风格的主题并且语言是英语，这样不太方便使用，所以需要修改下语言。</p><p>设置语言为简体中文。</p><p><img src="/articles/a315956e/13.png" alt></p><p>创建接口的测试用例<br>测试接口之前需要调整Windows环境配置，不然会报如下错误</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JMeter java.net.BindException: Address already in use: connect</span><br></pre></td></tr></table></figure><p>出现原因：<br>TCP/IP连接数不够或TIME_WAIT中存在很多链接，导致吞吐量低。</p><p>解决方案：<br>从问题的原因分析，有两种解决方案，一是增加预留给TCP/IP服务的临时端口的数量，二是加快被占用端口的释放速度。</p><p>解决办法：<br>1、打开注册表：regedit<br>2、HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\ Services\TCPIP\Parameters<br>3、新建 DWORD值，name：TCPTimedWaitDelay，value：30（十进制） –&gt; 设置为30秒，默认是240秒<br>4、新建 DWORD值，name：MaxUserPort，value：65534（十进制） –&gt; 设置最大连接数65534<br>5、重启系统</p><p>第一步：设置测试计划的名称</p><p>第二步：添加线程组，使用线程模拟用户的并发</p><p><img src="/articles/a315956e/14.png" alt></p><p><img src="/articles/a315956e/15.png" alt></p><p>1000个线程，每个线程循环10次，也就是tomcat会接收到10000个请求。</p><p>第三步：添加http请求</p><p><img src="/articles/a315956e/16.png" alt></p><p>设置http请求</p><p><img src="/articles/a315956e/17.png" alt></p><p>第四步：添加请求监控</p><p><img src="/articles/a315956e/18.png" alt></p><p>启动与进行接口测试</p><p>查看测试报告<br>在聚合报告中，重点看吞吐量。</p><p><img src="/articles/a315956e/19.png" alt></p><p>调整Tomcat参数进行优化<br>通过上面测试可以看出，tomcat在不做任何调整时，吞吐量为697次/秒。这个吞吐量跟接口的业务逻辑关系很大，如果业务逻辑复杂，需要比较长时间计算的，可能吞吐量只有几十次/秒，我这里测试的时候没有添加任务业务逻辑，才会出现吞吐量为697次/秒的情况。这里的吞吐量最好是经过多次测试取平均值，因为单次测试具有一定的随机性</p><p>禁用AJP连接<br>修改conf下的server.xml文件，将AJP服务禁用掉即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; --&gt;</span><br></pre></td></tr></table></figure><p><img src="/articles/a315956e/20.png" alt></p><p>这里经过9次测试，测试结果如下704 730 736 728 730 727 714 708 735 平均是723</p><p>可以看到，禁用AJP服务后，吞吐量会有所提升。</p><p>当然了，测试不一定准确，需要多测试几次才能看出是否有提升。</p><p>设置线程池<br>通过设置线程池，调整线程池相关的参数进行测试tomcat的性能。有关线程池更多更详细的配置参考Tomcat官网提供的配置详解</p><p>最大线程数为150，初始为4</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;150&quot; minSpareThreads=&quot;4&quot; prestartminSpareThreads=&quot;true&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--在Connector中设置executor属性指向上面的执行器--&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure><p><img src="/articles/a315956e/21.png" alt></p><p>经过9次测试，测试结果如下705 725 702 729 733 738 735 728 平均是724</p><p><strong>最大线程数为500，初始为50</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;500&quot; minSpareThreads=&quot;50&quot; prestartminSpareThreads=&quot;true&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--在Connector中设置executor属性指向上面的执行器--&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure><p>测试结果：733 724 718 728 734 721 720 723 平均725。吞吐量为725次/秒，性能有所提升。</p><p><strong>最大线程数为1000，初始为200</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;1000&quot; minSpareThreads=&quot;200&quot; prestartminSpareThreads=&quot;true&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--在Connector中设置executor属性指向上面的执行器--&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure><p>吞吐量为732，性能有所提升。测试结果 737 729 730 738 735 726 725 740 平均732</p><p><strong>最大线程数为5000，初始为1000</strong><br>是否是线程数最多，速度越快呢？ 我们来测试下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;5000&quot; minSpareThreads=&quot;1000&quot; prestartminSpareThreads=&quot;true&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--在Connector中设置executor属性指向上面的执行器--&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure><p>测试结果 727 733 728 725 738 729 737 735 739 平均732</p><p>可以看到，虽然最大线程已经设置到5000，但是实际测试效果并不理想，并且平均的响应时间也边长了，所以单纯靠提升线程数量是不能一直得到性能提升的。</p><p><strong>设置最大等待队列数</strong><br>默认情况下，请求发送到tomcat，如果tomcat正忙，那么该请求会一直等待。这样虽然可以保证每个请求都能请求到，但是请求时间就会边长。</p><p>有些时候，我们也不一定要求请求一定等待，可以设置最大等待队列大小，如果超过就不等待了。这样虽然有些请求是失败的，但是请求时间会虽短。典型的应用：12306。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--最大等待数为100--&gt;</span><br><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;500&quot; minSpareThreads=&quot;100&quot; prestartminSpareThreads=&quot;true&quot; maxQueueSize=&quot;100&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--在Connector中设置executor属性指向上面的执行器--&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure><p><img src="/articles/a315956e/22.png" alt></p><p>测试结果：</p><ul><li><p>平均响应时间：0.438秒，响应时间明显缩短</p></li><li><p>错误率：43.07%，错误率超过40%，也可以理解，最大线程为500，测试的并发为1000</p></li><li><p>吞吐量：1359次/秒，吞吐量明显提升</p><p>结论：响应时间、吞吐量这2个指标需要找到平衡才能达到更好的性能。</p></li></ul><p><strong>设置nio2的运行模式</strong><br>将最大线程设置为500进行测试：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;500&quot; minSpareThreads=&quot;100&quot; prestartminSpareThreads=&quot;true&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 设置nio2 --&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11Nio2Protocol&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure><p>从测试结果可以看到，平均响应时间有缩短，吞吐量有提升，可以得出结论：nio2的性能要高于nio。</p><p>参数说明与最佳实践<br>具体参数参考官网说明</p><p>执行器参数说明(加粗是重点)<br><img src="/articles/a315956e/23.png" alt><br>执行器最佳实践<br>此最佳配置仅供参考</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;800&quot; minSpareThreads=&quot;100&quot; maxQueueSize=&quot;100&quot;                                 prestartminSpareThreads=&quot;true&quot;/&gt;</span><br></pre></td></tr></table></figure><p>连接器参数说明<br>可以看到除了这几个基本配置外并无特殊功能，所以我们需要对 Connector 进行扩展。</p><p>其中Connector 支持参数属性可以参考Tomcat官方网站，本文就只介绍些常用的。</p><p>通用属性(加粗是重点)<br><img src="/articles/a315956e/24.png" alt></p><p><img src="/articles/a315956e/25.png" alt></p><p><img src="/articles/a315956e/26.png" alt></p><p><strong>标准实现(加粗是重点)</strong><br>除了上面列出的常见的连接器属性，标准的HTTP连接器（BIO，NIO和APR/native）都支持以下属性。</p><p><img src="/articles/a315956e/27.png" alt></p><p><img src="/articles/a315956e/28.png" alt></p><p><img src="/articles/a315956e/29.png" alt></p><p><img src="/articles/a315956e/30.png" alt></p><p><strong>连接器最佳实践</strong><br>此最佳配置仅供参考</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot;                             protocol=&quot;org.apache.coyote.http11.Http11Nio2Protocol&quot; </span><br><span class="line">           connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; </span><br><span class="line">           enableLookups=&quot;false&quot; maxPostSize=&quot;10485760&quot; URIEncoding=&quot;UTF-8&quot;                     acceptCount=&quot;100&quot; acceptorThreadCount=&quot;2&quot; disableUploadTimeout=&quot;true&quot;                    maxConnections=&quot;10000&quot; SSLEnabled=&quot;false&quot;/&gt;</span><br></pre></td></tr></table></figure><p><strong>调整JVM参数进行优化</strong><br>接下来，通过设置jvm参数进行优化，为了测试一致性，依然将最大线程数设置为500，启用nio2运行模式</p><p><strong>设置并行垃圾回收器</strong><br>在/bin/catalina.sh文件第一行添加如下参数，gc日志输出到/logs/gc.log</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#年轻代、老年代均使用并行收集器，初始堆内存64M，最大堆内存512M</span><br><span class="line">JAVA_OPTS=&quot;-XX:+UseParallelGC -XX:+UseParallelOldGC -Xms64m -Xmx512m -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -Xloggc:../logs/gc.log&quot;</span><br></pre></td></tr></table></figure><p>测试结果与默认的JVM参数结果接近。</p><p>查看gc日志文件<br>将gc.log文件上传到gceasy.io查看gc中是否存在问题。上传文件后需要等待一段时间，需要耐心等待。</p><p>问题一：<strong>系统所消耗的时间大于用户时间</strong></p><p>如果在报告中显示System Time greater than User Time，系统所消耗的时间大于用户时间，这反应出的服务器的性能存在瓶颈，调度CPU等资源所消耗的时间要长一些。</p><p>问题二：<strong>线程暂停时间有点长</strong></p><p>可以关键指标中可以看出，吞吐量表现不错，但是gc时，线程的暂停时间稍有点长。</p><p>问题三：<strong>GC总次数过多</strong></p><p><img src="/articles/a315956e/31.png" alt></p><p>通过GC的统计可以看出：</p><p>年轻代的gc有100次，次数有点多，说明年轻代设置的大小不合适，需要调整<br>FullGC有7次，说明堆内存的大小不合适，需要调整</p><p>问题四：<strong>年轻代内存不足导致GC</strong></p><p><img src="/articles/a315956e/32.png" alt></p><p>从GC原因的可以看出，年轻代大小设置不合理，导致了多次GC。</p><p>调整年轻代大小<br>调整jvm配置参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-XX:+UseParallelGC -XX:+UseParallelOldGC -Xms128m -Xmx1024m -XX:NewSize=64m -XX:MaxNewSize=256m -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -Xloggc:../logs/gc.log&quot;</span><br></pre></td></tr></table></figure><p>将初始堆大小设置为128m，最大为1024m，初始年轻代大小64m，年轻代最大256m</p><p>从测试结果来看，吞吐量以及响应时间均有提升。</p><p>查看gc日志</p><p><img src="/articles/a315956e/33.png" alt></p><p>可以看到GC次数要明显减少，说明调整是有效的。</p><p><img src="/articles/a315956e/34.png" alt></p><p>GC次数有所减少</p><p><img src="/articles/a315956e/35.png" alt></p><p>设置G1垃圾回收器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#设置了最大停顿时间100毫秒，初始堆内存128m，最大堆内存1024m</span><br><span class="line">JAVA_OPTS=&quot;-XX:+UseG1GC -XX:MaxGCPauseMillis=100 -Xms128m -Xmx1024m -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -Xloggc:../logs/gc.log&quot;</span><br></pre></td></tr></table></figure><p>测试结果: 可以看到，吞吐量有所提升，评价响应时间也有所缩短。</p><p>JVM配置最佳实践<br>此最佳配置仅供参考</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-Dfile.encoding=UTF-8-server -Xms1024m -Xmx2048m -XX:NewSize=512m -XX:MaxNewSize=1024m -XX:PermSize=256m -XX:MaxPermSize=256m -XX:MaxTenuringThreshold=10-XX:NewRatio=2 -XX:+DisableExplicitGC&quot;</span><br></pre></td></tr></table></figure><p>参数说明：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">file.encoding 默认文件编码</span><br><span class="line">-Xmx1024m 设置JVM最大可用内存为1024MB</span><br><span class="line">-Xms1024m 设置JVM最小内存为1024m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。</span><br><span class="line">-XX:NewSize 设置年轻代大小</span><br><span class="line">-XX:MaxNewSize 设置最大的年轻代大小</span><br><span class="line">-XX:PermSize 设置永久代大小</span><br><span class="line">-XX:MaxPermSize 设置最大永久代大小</span><br><span class="line">-XX:NewRatio=4 设置年轻代（包括Eden和两个Survivor区）与终身代的比值（除去永久代）。设置为4，则年轻代与终身代所占比值为1：4，年轻代占整个堆栈的1/5</span><br><span class="line">-XX:MaxTenuringThreshold=0 设置垃圾最大年龄，默认为：15。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。</span><br><span class="line">-XX:+DisableExplicitGC 这个将会忽略手动调用GC的代码使得System.gc()的调用就会变成一个空调用，完全不会触发任何GC。</span><br></pre></td></tr></table></figure><p>总结<br>通过上述的测试，可以总结出，对tomcat性能优化就是需要不断的进行调整参数，然后测试结果，可能会调优也可能会调差，这时就需要借助于gc的可视化工具来看gc的情况。再帮我我们做出决策应该调整哪些参数。</p><p>再次重申本博客的目的不在于给出最佳配置，而是带领开发者，能够从实际情况出发，通过不断的调节tomcat和jvm参数，去发现吞吐量，平均响应时间和错误率等信息的变化，同时根据服务器的cpu和内存等信息，结合接口的业务逻辑，最好是测试使用率最高，并发最大，或者是最重要的接口(比如下单支付接口)，设置最优的tomcat和jvm配置参数。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;本文不在于给出最佳配置，而是带领开发者，能够从实际情况出发，通过不断的调节tomcat和jvm参数，去发现吞吐量，平均响应时间和错误率等信息的变化，同时根据服务器的cpu和内存等信息，结合接口的业务逻辑，最好是测试使用率最高，并发最大，或者是最重要的接口(比如下单支付接口)，设置最优的tomcat和jvm配置参数。通过Tomcat性能优化可以提高网站的并发能力。Tomcat服务器在JavaEE项目中使用率非常高，所以在生产环境对Tomcat的优化也变得非常重要了。&lt;/p&gt;
    
    </summary>
    
      <category term="容器化" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Tomcat" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/Tomcat/"/>
    
    
      <category term="Tomcat" scheme="https://wandouduoduo.netlify.com/tags/Tomcat/"/>
    
  </entry>
  
  <entry>
    <title>Tomcat高并发和安全配置</title>
    <link href="https://wandouduoduo.netlify.com/articles/d5611253.html"/>
    <id>https://wandouduoduo.netlify.com/articles/d5611253.html</id>
    <published>2019-12-19T03:43:17.000Z</published>
    <updated>2019-12-19T04:30:04.086Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>现在Tomcat容器在企业中的应用还占据很高比例，如何对Tomcat优化配置，让其实现高并发的同时，安全也能兼顾呢。本篇就详细介绍Tomcat高并发和安全配置。</p><a id="more"></a><h2 id="变量配置"><a href="#变量配置" class="headerlink" title="变量配置"></a>变量配置</h2><p>设置 Tomcat 相关变量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim bin/catalina.sh</span><br></pre></td></tr></table></figure><p>在配置文件的可编辑内容最上面（98 行开始），加上如下内容（具体参数根据你服务器情况自行修改）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">JAVA_HOME=/usr/program/jdk1.8.0_72</span><br><span class="line">CATALINA_HOME=/usr/program/tomcat8</span><br><span class="line">CATALINA_OPTS=&quot;-server -Xms528m -Xmx528m -XX:PermSize=256m -XX:MaxPermSize=358m&quot;</span><br><span class="line">CATALINA_PID=$CATALINA_HOME/catalina.pid</span><br></pre></td></tr></table></figure><p>如果使用 shutdown.sh 还无法停止 tomcat，可以修改其配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim bin/shutdown.sh</span><br><span class="line">把最尾巴这一行：exec &quot;$PRGDIR&quot;/&quot;$EXECUTABLE&quot; stop &quot;$@&quot;</span><br><span class="line">改为：exec &quot;$PRGDIR&quot;/&quot;$EXECUTABLE&quot; stop 10 -force</span><br></pre></td></tr></table></figure><h2 id="JVM-优化"><a href="#JVM-优化" class="headerlink" title="JVM 优化"></a>JVM 优化</h2><p>Java 的内存模型分为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Young，年轻代（易被 GC）。Young 区被划分为三部分，Eden 区和两个大小严格相同的 Survivor 区，其中 Survivor 区间中，某一时刻只有其中一个是被使用的，另外一个留做垃圾收集时复制对象用，在 Young 区间变满的时候，minor GC 就会将存活的对象移到空闲的Survivor 区间中，根据 JVM 的策略，在经过几次垃圾收集后，任然存活于 Survivor 的对象将被移动到 Tenured 区间。</span><br><span class="line"></span><br><span class="line">Tenured，终身代。Tenured 区主要保存生命周期长的对象，一般是一些老的对象，当一些对象在 Young 复制转移一定的次数以后，对象就会被转移到 Tenured 区，一般如果系统中用了 application 级别的缓存，缓存中的对象往往会被转移到这一区间。</span><br><span class="line"></span><br><span class="line">Perm，永久代。主要保存 class,method,filed 对象，这部门的空间一般不会溢出，除非一次性加载了很多的类，不过在涉及到热部署的应用服务器的时候，有时候会遇到 java.lang.OutOfMemoryError : PermGen space 的错误，造成这个错误的很大原因就有可能是每次都重新部署，但是重新部署后，类的 class 没有被卸载掉，这样就造成了大量的 class 对象保存在了 perm 中，这种情况下，一般重新启动应用服务器可以解决问题。</span><br></pre></td></tr></table></figure><p>Linux 修改 bin/catalina.sh 文件，把下面信息添加到文件第一行。Windows 和 Linux 有点不一样的地方在于，在 Linux 下，下面的的参数值是被引号包围的，而 Windows 不需要引号包围。</p><p>如果服务器只运行一个 Tomcat<br>机子内存如果是 8G，一般 PermSize 配置是主要保证系统能稳定起来就行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-Dfile.encoding=UTF-8 -server -Xms6144m -Xmx6144m -XX:NewSize=1024m -XX:MaxNewSize=2048m -XX:PermSize=512m -XX:MaxPermSize=512m -XX:MaxTenuringThreshold=10 -XX:NewRatio=2 -XX:+DisableExplicitGC&quot;</span><br></pre></td></tr></table></figure><p>机子内存如果是 16G，一般 PermSize 配置是主要保证系统能稳定起来就行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-Dfile.encoding=UTF-8 -server -Xms13312m -Xmx13312m -XX:NewSize=3072m -XX:MaxNewSize=4096m -XX:PermSize=512m -XX:MaxPermSize=512m -XX:MaxTenuringThreshold=10 -XX:NewRatio=2 -XX:+DisableExplicitGC&quot;</span><br></pre></td></tr></table></figure><p>机子内存如果是 32G，一般 PermSize 配置是主要保证系统能稳定起来就行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-Dfile.encoding=UTF-8 -server -Xms29696m -Xmx29696m -XX:NewSize=6144m -XX:MaxNewSize=9216m -XX:PermSize=1024m -XX:MaxPermSize=1024m -XX:MaxTenuringThreshold=10 -XX:NewRatio=2 -XX:+DisableExplicitGC&quot;</span><br></pre></td></tr></table></figure><p>如果是开发机</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-Xms550m -Xmx1250m -XX:PermSize=550m -XX:MaxPermSize=1250m</span><br></pre></td></tr></table></figure><p>参数说明：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">-Dfile.encoding：默认文件编码</span><br><span class="line">-server：表示这是应用于服务器的配置，JVM 内部会有特殊处理的</span><br><span class="line">-Xmx1024m：设置JVM最大可用内存为1024MB</span><br><span class="line">-Xms1024m：设置JVM最小内存为1024m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。</span><br><span class="line">-XX:NewSize：设置年轻代大小</span><br><span class="line">-XX:MaxNewSize：设置最大的年轻代大小</span><br><span class="line">-XX:PermSize：设置永久代大小</span><br><span class="line">-XX:MaxPermSize：设置最大永久代大小</span><br><span class="line">-XX:NewRatio=4：设置年轻代（包括 Eden 和两个 Survivor 区）与终身代的比值（除去永久代）。设置为 4，则年轻代与终身代所占比值为 1：4，年轻代占整个堆栈的 1/5</span><br><span class="line">-XX:MaxTenuringThreshold=10：设置垃圾最大年龄，默认为：15。如果设置为 0 的话，则年轻代对象不经过 Survivor 区，直接进入年老代。对于年老代比较多的应用，可以提高效率。                             如果将此值设置为一个较大值，则年轻代对象会在 Survivor 区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。</span><br><span class="line">-XX:+DisableExplicitGC：这个将会忽略手动调用 GC 的代码使得 System.gc() 的调用就会变成一个空调用，完全不会触发任何 GC</span><br></pre></td></tr></table></figure><h2 id="禁用8005端口"><a href="#禁用8005端口" class="headerlink" title="禁用8005端口"></a>禁用8005端口</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim conf/server.xml</span><br><span class="line"></span><br><span class="line"><span class="comment"># telnet localhost 8005 然后输入 SHUTDOWN 就可以关闭 Tomcat，为了安全我们要禁用该功能。</span></span><br><span class="line"><span class="comment"># 禁用该端口，要说明的是： shutdown端口是Tomcat中shutdown.sh脚本执行时给操作系统发送停止信号的端口，禁用后，执行shutdown.sh并不能停掉tomcat。那有同学就问，那我要怎么停，并且问什么要禁掉呢？停可以直接停止进程。禁掉是为了安全，同时在日常自动化运维中，为了自动批量控制业务状态，都会直接控制业务进程，所以就可以禁掉。</span></span><br><span class="line"></span><br><span class="line">默认值:</span><br><span class="line">&lt;Server port=<span class="string">"8005"</span> shutdown=<span class="string">"SHUTDOWN"</span>&gt;</span><br><span class="line">修改为:</span><br><span class="line">&lt;Server port=<span class="string">"-1"</span> shutdown=<span class="string">"SHUTDOWN"</span>&gt;</span><br></pre></td></tr></table></figure><h2 id="关闭自动部署"><a href="#关闭自动部署" class="headerlink" title="关闭自动部署"></a>关闭自动部署</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">默认值:</span><br><span class="line">&lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot;</span><br><span class="line">     unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;</span><br><span class="line">修改为:</span><br><span class="line">&lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot;</span><br><span class="line">     unpackWARs=&quot;false&quot; autoDeploy=&quot;false&quot; reloadable=&quot;false&quot;&gt;</span><br><span class="line">     </span><br><span class="line"># 在tomcat8版本中配置 reloadable=&quot;false&quot; 选项启动时会包如下警告可忽略：</span><br><span class="line">警告 [main] org.apache.tomcat.util.digester.SetPropertiesRule.begin [SetPropertiesRule]Server/Service/Engine/Host&#125; Setting property &apos;reloadable&apos; to &apos;false&apos; did not find a matching property.</span><br></pre></td></tr></table></figure><h2 id="线程池限制"><a href="#线程池限制" class="headerlink" title="线程池限制"></a>线程池限制</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">默认为注释:</span><br><span class="line">&lt;!--</span><br><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">maxThreads=&quot;150&quot; minSpareThreads=&quot;4&quot;/&gt;</span><br><span class="line">--&gt;</span><br><span class="line">修改为:</span><br><span class="line">&lt;Executor</span><br><span class="line">   name=&quot;tomcatThreadPool&quot;</span><br><span class="line">   namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">   maxThreads=&quot;500&quot;</span><br><span class="line">   minSpareThreads=&quot;100&quot; </span><br><span class="line">   maxIdleTime=&quot;60000&quot;</span><br><span class="line">  prestartminSpareThreads = &quot;true&quot;</span><br><span class="line">  maxQueueSize = &quot;100&quot;</span><br><span class="line">/&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">参数解释：</span><br><span class="line"></span><br><span class="line">maxThreads：最大并发数，默认设置 200，一般建议在 500 ~ 800，根据硬件设施和业务来判断</span><br><span class="line">minSpareThreads：Tomcat 初始化时创建的线程数，默认设置 25</span><br><span class="line">maxIdleTime：如果当前线程大于初始化线程，那空闲线程存活的时间，单位毫秒，默认60000=60秒=1分钟。</span><br><span class="line">prestartminSpareThreads：在 Tomcat 初始化的时候就初始化 minSpareThreads 的参数值，如果不等于 true，minSpareThreads 的值就没啥效果了</span><br><span class="line">maxQueueSize：最大的等待队列数，超过则拒绝请求</span><br></pre></td></tr></table></figure><h2 id="连接器配置"><a href="#连接器配置" class="headerlink" title="连接器配置"></a>连接器配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">默认值：</span><br><span class="line">&lt;Connector </span><br><span class="line">   port=&quot;8080&quot; </span><br><span class="line">   protocol=&quot;HTTP/1.1&quot; </span><br><span class="line">   connectionTimeout=&quot;20000&quot; </span><br><span class="line">   redirectPort=&quot;8443&quot; </span><br><span class="line">/&gt;</span><br><span class="line">修改为：</span><br><span class="line">&lt;Connector </span><br><span class="line">  executor=&quot;tomcatThreadPool&quot;</span><br><span class="line">  port=&quot;8080&quot; </span><br><span class="line">  protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot; </span><br><span class="line">  connectionTimeout=&quot;40000&quot; </span><br><span class="line">  maxConnections=&quot;10000&quot; </span><br><span class="line">  redirectPort=&quot;8443&quot; </span><br><span class="line">  enableLookups=&quot;false&quot; </span><br><span class="line">  acceptCount=&quot;100&quot; </span><br><span class="line">  maxPostSize=&quot;10485760&quot; </span><br><span class="line">  compression=&quot;on&quot; </span><br><span class="line">  disableUploadTimeout=&quot;true&quot; </span><br><span class="line">  compressionMinSize=&quot;2048&quot; </span><br><span class="line">  acceptorThreadCount=&quot;2&quot; </span><br><span class="line">compressableMimeType=&quot;text/html,text/xml,text/plain,text/css,text/javascript,application/javascript&quot; </span><br><span class="line">  maxHttpHeaderSize=&quot;8192&quot;</span><br><span class="line">  processorCache=&quot;20000&quot;</span><br><span class="line">  tcpNoDelay=&quot;true&quot;</span><br><span class="line">  connectionLinger=&quot;5&quot;</span><br><span class="line">  server=&quot;Server Version 11.0&quot;</span><br><span class="line">  URIEncoding=&quot;utf-8&quot;</span><br><span class="line">/&gt;</span><br><span class="line"></span><br><span class="line">用此项配置 protocol=&quot;org.apache.coyote.http11.Http11Nio2Protocol&quot;启动时会有警告可忽略</span><br><span class="line">警告 [main] org.apache.tomcat.util.net.Nio2Endpoint.bind The NIO2 connector requires an exclusive executor to operate properly on shutdown</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">参数解释：</span><br><span class="line"></span><br><span class="line">protocol：Tomcat 8 设置 nio2 更好：org.apache.coyote.http11.Http11Nio2Protocol（如果这个用不了，就用下面那个），Tomcat 6、7 设置 nio 更好：org.apache.coyote.http11.Http11NioProtocol</span><br><span class="line">enableLookups：禁用DNS查询</span><br><span class="line">acceptCount：指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理，默认设置 100</span><br><span class="line">maxPostSize：以 FORM URL 参数方式的 POST 提交方式，限制提交最大的大小，默认是 2097152(2兆)，它使用的单位是字节。10485760 为 10M。如果要禁用限制，则可以设置为 -1。</span><br><span class="line">maxPostSize：设置由容器解析的URL参数的最大长度，-1(小于0)为禁用这个属性，默认为2097152(2M) 请注意， FailedRequestFilter 过滤器可以用来拒绝达到了极限值的请求。</span><br><span class="line">acceptorThreadCount，用于接收连接的线程的数量，默认值是1。一般这个指需要改动的时候是因为该服务器是一个多核CPU，如果是多核 CPU 一般配置为 2.</span><br><span class="line">acceptorThreadCount：用于接受连接的线程数量。增加这个值在多CPU的机器上,尽管你永远不会真正需要超过2。 也有很多非维持连接,您可能希望增加这个值。默认值是1。</span><br><span class="line">connectionTimeout：Connector接受一个连接后等待的时间(milliseconds)，默认值是60000。</span><br><span class="line">maxConnections：这个值表示最多可以有多少个socket连接到tomcat上</span><br><span class="line">maxHttpHeaderSize：http请求头信息的最大程度，超过此长度的部分不予处理。一般8K。</span><br><span class="line">compression：是否启用GZIP压缩 on为启用（文本数据压缩） off为不启用， force 压缩所有数据</span><br><span class="line">disableUploadTimeout：这个标志允许servlet容器使用一个不同的,通常长在数据上传连接超时。 如果不指定,这个属性被设置为true,表示禁用该时间超时。</span><br><span class="line">compressionMinSize：当超过最小数据大小才进行压缩</span><br><span class="line">compressableMimeType：配置想压缩的数据类型</span><br><span class="line">URIEncoding：网站一般采用UTF-8作为默认编码。</span><br><span class="line">processorCache：协议处理器缓存的处理器对象来提高性能。 该设置决定多少这些对象的缓存。-1意味着无限的,默认是200。 如果不使用Servlet 3.0异步处理,默认是使用一样的maxThreads设置。                 如果使用Servlet 3.0异步处理,默认是使用大maxThreads和预期的并发请求的最大数量(同步和异步)。</span><br><span class="line">tcpNoDelay：如果设置为true,TCP_NO_DELAY选项将被设置在服务器套接字,而在大多数情况下提高性能。这是默认设置为true。</span><br><span class="line">connectionLinger：秒数在这个连接器将持续使用的套接字时关闭。默认值是 -1,禁用socket 延迟时间。</span><br><span class="line">server：隐藏Tomcat版本信息，首先隐藏HTTP头中的版本信息</span><br></pre></td></tr></table></figure><p><strong>建议：压缩会增加Tomcat负担，最好采用Nginx + Tomcat 或者 Apache + Tomcat 方式，压缩交由Nginx/Apache 去做。</strong><br><strong>Tomcat 的压缩是在客户端请求服务器对应资源后，从服务器端将资源文件压缩，再输出到客户端，由客户端的浏览器负责解压缩并浏览。相对于普通的 浏览过程 HTML、CSS、Javascript和Text，它可以节省40% 左右的流量。更为重要的是，它可以对动态生成的，包括CGI、PHP、JSP、ASP、Servlet,SHTML等输出的网页也能进行压缩，压缩效率也很高。</strong></p><h2 id="禁用-AJP"><a href="#禁用-AJP" class="headerlink" title="禁用 AJP"></a>禁用 AJP</h2><p><strong>前提：如果你服务器没有使用 Apache或不用ajp</strong></p><p>AJP是为 Tomcat 与 HTTP 服务器之间通信而定制的协议，能提供较高的通信速度和效率。如果tomcat前端放的是apache的时候，会使用到AJP这个连接器。 默认是开启的。如果不使用apache，注释该连接器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">把下面这一行注释掉，默认 Tomcat 是开启的。</span><br><span class="line">&lt;!-- &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; --&gt;</span><br></pre></td></tr></table></figure><h2 id="隐藏或修改版本号"><a href="#隐藏或修改版本号" class="headerlink" title="隐藏或修改版本号"></a>隐藏或修改版本号</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/tomcat/lib/</span><br><span class="line">unzip catalina.jar</span><br><span class="line"><span class="built_in">cd</span> org/apache/catalina/util</span><br><span class="line">vim ServerInfo.properties</span><br><span class="line"></span><br><span class="line">server.info=Apache Tomcat/8.5.16</span><br><span class="line">server.number=8.5.16.0</span><br><span class="line">server.built=Jun 21 2017 17:01:09 UTC</span><br><span class="line"><span class="comment"># 将以上去掉或修改版本号即可。</span></span><br></pre></td></tr></table></figure><h2 id="管理页面安全"><a href="#管理页面安全" class="headerlink" title="管理页面安全"></a>管理页面安全</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rm -rf /usr/<span class="built_in">local</span>/apache-tomcat-8.5.16/webapps/*</span><br><span class="line">rm -rf /usr/<span class="built_in">local</span>/apache-tomcat-8.5.16/conf/tomcat-users.xml</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;现在Tomcat容器在企业中的应用还占据很高比例，如何对Tomcat优化配置，让其实现高并发的同时，安全也能兼顾呢。本篇就详细介绍Tomcat高并发和安全配置。&lt;/p&gt;
    
    </summary>
    
      <category term="容器化" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Tomcat" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/Tomcat/"/>
    
    
      <category term="Tomcat" scheme="https://wandouduoduo.netlify.com/tags/Tomcat/"/>
    
  </entry>
  
  <entry>
    <title>Tomcat优化之APR模式</title>
    <link href="https://wandouduoduo.netlify.com/articles/98d7cf0b.html"/>
    <id>https://wandouduoduo.netlify.com/articles/98d7cf0b.html</id>
    <published>2019-12-18T09:22:37.000Z</published>
    <updated>2019-12-18T13:57:15.961Z</updated>
    
    <content type="html"><![CDATA[<h2 id="APR模式介绍"><a href="#APR模式介绍" class="headerlink" title="APR模式介绍"></a>APR模式介绍</h2><p>Tomcat可以使用APR来提供超强的可伸缩性和性能，更好地集成本地服务器技术。APR(Apache Portable Runtime)是一个高可移植库，它是Apache HTTP Server2.x的核心。</p><p>APR有很多用途，包括访问高级IO功能(例如sendfile,epoll和OpenSSL)，OS级别功能(随机数生成，系统状态等等)，本地进程管理(共享内存，NT管道和UNIXsockets)。这些功能可以使Tomcat作为一个通常的前台WEB服务器，能更好地和其它本地web技术集成，总体上让Java更有效率作为一个高性能web服务器平台而不是简单作为后台容器。</p><p>在产品环境中，特别是直接使用Tomcat做WEB服务器的时候，应该使用Tomcat Native来提高其性能。就是如何  在Tomcat中使用JNI的方式来读取文件以及进行网络传输。这个东西可以大大提升Tomcat对静态文件的处理性能，同时如果你使用了HTTPS方式  传输的话，也可以提升SSL的处理性能。</p><a id="more"></a><h2 id="APR模式配置"><a href="#APR模式配置" class="headerlink" title="APR模式配置"></a>APR模式配置</h2><h4 id="获取APR组件依赖包"><a href="#获取APR组件依赖包" class="headerlink" title="获取APR组件依赖包"></a>获取APR组件依赖包</h4><p>首先需要下载APR的三个依赖包 <a href="http://apr.apache.org/download.cgi" target="_blank" rel="noopener">官方下载地址</a> </p><p><img src="/articles/98d7cf0b/1.png" alt></p><p>然后把包上传到服务器。</p><h4 id="编译安装各个组件"><a href="#编译安装各个组件" class="headerlink" title="编译安装各个组件"></a>编译安装各个组件</h4><h6 id="安装相关环境包"><a href="#安装相关环境包" class="headerlink" title="安装相关环境包"></a>安装相关环境包</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install cmake gcc expat-devel</span><br></pre></td></tr></table></figure><h6 id="安装apr"><a href="#安装apr" class="headerlink" title="安装apr"></a>安装apr</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf apr-1.7.0.tar.gz</span><br><span class="line">cd apr-1.7.0</span><br><span class="line">./configure --prefix=/usr/local/apr</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h6 id="安装apr-iconv"><a href="#安装apr-iconv" class="headerlink" title="安装apr-iconv"></a>安装apr-iconv</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf apr-iconv-1.2.2.tar.gz</span><br><span class="line"><span class="built_in">cd</span> apr-iconv-1.2.2</span><br><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/apr-iconv --with-apr=/usr/<span class="built_in">local</span>/apr</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h6 id="安装apr-util"><a href="#安装apr-util" class="headerlink" title="安装apr-util"></a>安装apr-util</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf apr-util-1.6.1.tar.gz</span><br><span class="line"><span class="built_in">cd</span> apr-util-1.6.1</span><br><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/apr-util --with-apr=/usr/<span class="built_in">local</span>/apr --with-apr-iconv=/usr/<span class="built_in">local</span>/apr-iconv/bin/apriconv</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h6 id="安装Tomcat-native"><a href="#安装Tomcat-native" class="headerlink" title="安装Tomcat-native"></a>安装Tomcat-native</h6><p>两种方式获取安装包：1，<a href="http://tomcat.apache.org/download-native.cgi" target="_blank" rel="noopener">从官方网站下载</a>；2，Tomcat中就包含该安装包，目录在: tomcat_home/bin/下。本教程采用第二种。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd tomcat_home/bin</span><br><span class="line">tar -zxvf tomcat-native.tar.gz</span><br><span class="line">cd tomcat-native-1.2.23-src/native/</span><br><span class="line">./configure  --with-apr=/usr/local/apr </span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>如有报错，openssl版本过低，需要大于1.0.2版本的，如下图</p><p><img src="/articles/98d7cf0b/2.png" alt></p><p>在<a href="https://www.openssl.org/source/" target="_blank" rel="noopener">openssl官方网站</a>下载。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget https://www.openssl.org/<span class="built_in">source</span>/openssl-1.0.2t.tar.gz</span><br><span class="line">tar xzvf openssl-1.0.2t.tar.gz</span><br><span class="line"><span class="built_in">cd</span> openssl-1.0.2t</span><br><span class="line">./config --prefix=/usr/<span class="built_in">local</span>/openssl  –fPIC <span class="comment">#加上-fPIC参数,否则编译native的时候会报错</span></span><br><span class="line">./config -t</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>安装成功openssl后再次编译还是报错，说明没找到，可以添加绝对路径编译</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./configure  --with-apr=/usr/<span class="built_in">local</span>/apr --with-ssl=/usr/<span class="built_in">local</span>/openssl</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h6 id="设置环境变量"><a href="#设置环境变量" class="headerlink" title="设置环境变量"></a>设置环境变量</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/<span class="built_in">local</span>/apr/lib <span class="comment">##添加apr path</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><h4 id="修改tomcat配置文件"><a href="#修改tomcat配置文件" class="headerlink" title="修改tomcat配置文件"></a>修改tomcat配置文件</h4><h6 id="修改protocol值"><a href="#修改protocol值" class="headerlink" title="修改protocol值"></a>修改protocol值</h6><p>Tomcat默认是HTTP/1.1，如果运行apr模式需要把protocol值修改成apr模式：<strong>org.apache.coyote.http11.Http11AprProtocol</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim server.xml</span></span><br><span class="line"></span><br><span class="line">&lt;Connector port=<span class="string">"8080"</span> protocol=<span class="string">"org.apache.coyote.http11.Http11AprProtocol"</span></span><br></pre></td></tr></table></figure><h6 id="修改SSLEngine"><a href="#修改SSLEngine" class="headerlink" title="修改SSLEngine"></a>修改SSLEngine</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim server.xml</span></span><br><span class="line"></span><br><span class="line">&lt;Listener className=<span class="string">"org.apache.catalina.core.AprLifecycleListener"</span> SSLEngine=<span class="string">"off"</span> /&gt;</span><br></pre></td></tr></table></figure><h2 id="启动tomcat验证"><a href="#启动tomcat验证" class="headerlink" title="启动tomcat验证"></a>启动tomcat验证</h2><p><img src="/articles/98d7cf0b/3.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;APR模式介绍&quot;&gt;&lt;a href=&quot;#APR模式介绍&quot; class=&quot;headerlink&quot; title=&quot;APR模式介绍&quot;&gt;&lt;/a&gt;APR模式介绍&lt;/h2&gt;&lt;p&gt;Tomcat可以使用APR来提供超强的可伸缩性和性能，更好地集成本地服务器技术。APR(Apache Portable Runtime)是一个高可移植库，它是Apache HTTP Server2.x的核心。&lt;/p&gt;
&lt;p&gt;APR有很多用途，包括访问高级IO功能(例如sendfile,epoll和OpenSSL)，OS级别功能(随机数生成，系统状态等等)，本地进程管理(共享内存，NT管道和UNIXsockets)。这些功能可以使Tomcat作为一个通常的前台WEB服务器，能更好地和其它本地web技术集成，总体上让Java更有效率作为一个高性能web服务器平台而不是简单作为后台容器。&lt;/p&gt;
&lt;p&gt;在产品环境中，特别是直接使用Tomcat做WEB服务器的时候，应该使用Tomcat Native来提高其性能。就是如何  在Tomcat中使用JNI的方式来读取文件以及进行网络传输。这个东西可以大大提升Tomcat对静态文件的处理性能，同时如果你使用了HTTPS方式  传输的话，也可以提升SSL的处理性能。&lt;/p&gt;
    
    </summary>
    
      <category term="容器化" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Tomcat" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/Tomcat/"/>
    
    
      <category term="Tomcat" scheme="https://wandouduoduo.netlify.com/tags/Tomcat/"/>
    
  </entry>
  
  <entry>
    <title>shell中的多进程并发</title>
    <link href="https://wandouduoduo.netlify.com/articles/d7c52fa4.html"/>
    <id>https://wandouduoduo.netlify.com/articles/d7c52fa4.html</id>
    <published>2019-12-10T08:23:40.000Z</published>
    <updated>2019-12-10T09:18:52.522Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>日常工作中编写shell脚本处理事务，很多时候需要一次性处理很多，需要用到循环，但是循环体内还是线性的，还是要一个个处理，这样并不会节省很多时间，只是节省了人工一次次输入的繁琐。但是对于提高处理能力，没有实质性的提高。这就需要考虑并发。但Shell中并没有真正意义的多线程，要实现多线程可以启动多个后端进程，最大程度利用cpu性能。即：多进程并发，本篇教程由浅入深详细介绍了shell中的多进程并发。</p><a id="more"></a><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>所谓的多进程只不过是将多个任务放到后台执行而已，很多人都用到过，所以现在讲的主要是控制，而不是实现。</p><h4 id="实验一"><a href="#实验一" class="headerlink" title="实验一"></a>实验一</h4><p>先看一个小shell：</p><p><img src="/articles/d7c52fa4/1.jpg" alt></p><p>看执行结果：</p><p><img src="/articles/d7c52fa4/2.jpg" alt></p><p>很明显是8s，这种不占处理器却有很耗时的进程，我们可以通过一种后台运行的方式<br>来达到节约时间的目的。</p><h4 id="实验二"><a href="#实验二" class="headerlink" title="实验二"></a>实验二</h4><p>如下为改进：</p><p><img src="/articles/d7c52fa4/3.jpg" alt="img"></p><p>用“{}”将主执行程序变为一个块，用&amp;放入后台，四次执行全部放入后台后，我们需要用一个wait指令，等待所有后台进程执行结束，不然 系统是不会等待的，直接继续执行后续指令，知道整个程序结束。<br>看结果：</p><p><img src="/articles/d7c52fa4/4.jpg" alt="img"> </p><p>可以看到，时间已经大大缩短了！</p><h4 id="实验三"><a href="#实验三" class="headerlink" title="实验三"></a>实验三</h4><p>以上实验虽然达到了多线程并发的目的，但有一个缺陷，不能控制运行在后台的进程数。为了控制进程，我们引入了管道 和文件操作符。</p><p>无名管道： 就是我们经常使用的 例如： cat text | grep “abc”   那个“|”就是管道，只不过是无名的，可以直接作为两个进程的数据通道<br>有名管道： mkfilo  可以创建一个管道文件 ，例如： mkfifo　fifo_file</p><p>管道有一个特点，如果管道中没有数据，那么取管道数据的操作就会停滞，直到管道内进入数据，然后读出后才会终止这一操作，同理，写入管道的操作，如果没有读取操作，这一个动作也会停滞。</p><p><img src="/articles/d7c52fa4/5.jpg" alt="img"> </p><p>当我们试图用echo想管道文件中写入数据时，由于没有任何进程在对它做读取操作，所以它会一直停留在那里等待读取操作，此时我们在另一终端上用cat指令做读取操作</p><p><img src="/articles/d7c52fa4/6.jpg" alt="img"> </p><p>你会发现读取操作一旦执行，写入操作就可以顺利完成了，同理，先做读取操作也是一样的：<br><img src="/articles/d7c52fa4/7.jpg" alt="img"> </p><p>由于没有管道内没有数据，所以读取操作一直滞留在那里等待写入的数据<br><img src="/articles/d7c52fa4/8.jpg" alt></p><p>一旦有了写入的数据，读取操作立刻顺利完成</p><p>以上实验，看以看到，仅仅一个管道文件似乎很难实现 我们的目的（控制后台线程数),  所以 接下来介绍 文件操作符，这里只做简单的介绍，如果不熟悉的可以自行查阅资料。<br>系统运行起始，就相应设备自动绑定到了 三个文件操作符   分别为 0  1  2 对应 stdin ，stdout， stderr 。<br>在 /proc/self/fd 中 可以看到 这三个三个对应文件</p><p><img src="/articles/d7c52fa4/9.jpg" alt="img"> </p><p>输出到这三个文件的内容都会显示出来。只是因为显示器作为最常用的输出设备而被绑定。</p><p>我们可以exec 指令自行定义、绑定文件操作符，文件操作符一般从3–（n-1）都可以随便使用<br>此处的n 为 ulimit -n 的定义值得<br><img src="/articles/d7c52fa4/10.jpg" alt="img"> </p><p>可以看到 我的 n值为1024 ，所以文件操作符只能使用 0-1023，可自行定义的 就只能是 3-1023 了。</p><p>直接上代码，然后根据代码分析每行代码的含义：<br><img src="/articles/d7c52fa4/11.jpg" alt="img"> </p><p><strong>代码解释</strong></p><p>第3行：  接受信号 2 （ctrl +C）做的操作。exec 1000&gt;&amp;-和exec 1000&lt;&amp;- 是关闭fd1000的意思，我们生成做绑                定时 可以用 exec 1000&lt;&gt;testfifo 来实现，但关闭时必须分开来写，&gt; 读的绑定，&lt; 标识写的绑定  &lt;&gt; 则                标识 对文件描述符 1000的所有操作等同于对管道文件testfifo的操作。</p><p>第5-7行：分别为 创建管道文件，文件操作符绑定，删除管道文件<br>　　　　  可能会有疑问，为什么不能直接使用管道文件呢？　<br>　　　　  事实上，这并非多此一举，刚才已经说明了管道文件的一个重要特性了，那就是读写必须同时存在<br>　　　　  缺少某一种操作，另一种操作就是滞留，而绑定文件操作符　正好解决了这个问题。</p><p>第9-12 行： 对文件操作符进行写入操作。通过一个for循环写入10个空行，这个10就是我们要定义的后台线程数                     量。<br>                     为什么写入空行而不是10个字符呢 ？<br>                     这是因为，管道文件的读取 是以行为单位的。<br><img src="/articles/d7c52fa4/12.jpg" alt="img"><br>                      当我们试图用 read 读取管道中的一个字符时，结果是不成功的，而刚才我们已经证实使用cat是可以                      读取的。</p><p>第17-24行：这里假定我们有100个任务，我们要实现的时 ，保证后台只有10个进程在同步运行 。read -u1000 的                     作用是：读取一次管道中的一行，在这儿就是读取一个空行。减少操作附中的一个空行之后，执行一                     次任务（当然是放到后台执行），需要注意的是，这个任务在后台执行结束以后会向文件操作符中写                    入一个空行，这就是重点所在，如果我们不在某种情况某种时刻向操作符中写入空行，那么结果就                    是：在后台放入10个任务之后，由于操作符中没有可读取的空行，导致  read -u1000 这儿 始终停顿。</p><p>后边的 就不用解释了。</p><p>贴下执行结果：<br><img src="/articles/d7c52fa4/13.jpg" alt="img"> </p><p>每次的停顿中都能看到  只有10个进程在运行<br>一共耗时50s  一共100个任务，每次10个 ，每个5s 正好50s。上边的结果图之所以这么有规律，这是因为我们所执行的100个任务耗时都是相同的。</p><p>比如，系统将第一批10个任务放入后台的过程所消耗的时间 几乎可以忽略不计，也就是说这10个任务几乎可以任务是同时运行，当然也就可以认为是同时结束了，而按照刚才的分析，一个任务结束时就会向文件描述符写入空行，既然是同时结束的，那么肯定是同时写入的空行，所以下一批任务又几乎同时运行，如此循环下去的。实际应用时，肯定不是这个样子的，比如，第一个放到后台执行的任务，是最耗时间的，那他肯定就会是最后一个执行完毕。所以，实际上来说，只要有一个任务完成，那么下一个任务就可以被放到后台并发执行了。  </p><h2 id="范例"><a href="#范例" class="headerlink" title="范例"></a>范例</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">trap</span> <span class="string">"exec 1000&gt;&amp;-;exec 1000&lt;&amp;-;exit 0"</span> 2</span><br><span class="line"></span><br><span class="line">mkfifo testfifo</span><br><span class="line"><span class="built_in">exec</span> 1000&lt;&gt;testfifo</span><br><span class="line">rm -fr testfifo</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>((n=1;n&lt;=10;n++))</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> &gt;&amp;1000</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">start=`date <span class="string">"+%s"</span>`</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>((i=1;i&lt;=100;i++))</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">read</span> -u1000</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"success <span class="variable">$i</span>"</span>;</span><br><span class="line">        sleep 5</span><br><span class="line"></span><br><span class="line">        <span class="built_in">echo</span> &gt;&amp;1000</span><br><span class="line">    &#125;&amp;</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">wait</span></span><br><span class="line"></span><br><span class="line">end=`date <span class="string">"+%s"</span>`</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Time: `expr <span class="variable">$end</span> - <span class="variable">$start</span>`"</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">exec</span> 1000&gt;&amp;-</span><br><span class="line"><span class="built_in">exec</span> 1000&lt;&amp;-</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;日常工作中编写shell脚本处理事务，很多时候需要一次性处理很多，需要用到循环，但是循环体内还是线性的，还是要一个个处理，这样并不会节省很多时间，只是节省了人工一次次输入的繁琐。但是对于提高处理能力，没有实质性的提高。这就需要考虑并发。但Shell中并没有真正意义的多线程，要实现多线程可以启动多个后端进程，最大程度利用cpu性能。即：多进程并发，本篇教程由浅入深详细介绍了shell中的多进程并发。&lt;/p&gt;
    
    </summary>
    
      <category term="编程积累" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/"/>
    
      <category term="Shell" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/Shell/"/>
    
    
      <category term="Shell" scheme="https://wandouduoduo.netlify.com/tags/Shell/"/>
    
  </entry>
  
  <entry>
    <title>Python多进程和多线程效率最优选</title>
    <link href="https://wandouduoduo.netlify.com/articles/4efb4de8.html"/>
    <id>https://wandouduoduo.netlify.com/articles/4efb4de8.html</id>
    <published>2019-11-29T08:51:15.000Z</published>
    <updated>2019-11-29T10:50:01.362Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>通过实例实验，比较用多线程和多进程耗时情况，并进行总结归纳，选择效率最高的方法。</p><a id="more"></a><h2 id="多线程和多进程测试"><a href="#多线程和多进程测试" class="headerlink" title="多线程和多进程测试"></a>多线程和多进程测试</h2><h4 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h4><ul><li>python3.6</li><li>threading和multiprocessing</li><li>四核+三星250G-850-SSD</li></ul><p>自从用多进程和多线程进行编程,一致没搞懂到底谁更快。网上很多都说python多进程更快，因为GIL(全局解释器锁)。但是我在写代码的时候，测试时间却是多线程更快，所以这到底是怎么回事？最近再做分词工作，原来的代码速度太慢，想提速，所以来探求一下有效方法(文末有代码和效果图)</p><p>这里先来一张程序的结果图，说明线程和进程谁更快</p><p><img src="/articles/4efb4de8/1.png" alt></p><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">并行是指两个或者多个事件在同一时刻发生。并发是指两个或多个事件在同一时间间隔内发生</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">线程是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一个程序的执行实例就是一个进程。</span><br></pre></td></tr></table></figure><h4 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h4><p>而python里面的多线程显然得拿到GIL,执行code，最后释放GIL。所以由于GIL，多线程的时候拿不到，实际上，它是并发实现，即多个事件，在同一时间间隔内发生。</p><p>但进程有独立GIL，所以可以并行实现。因此，针对多核CPU，理论上采用多进程更能有效利用资源。</p><h4 id="现实问题"><a href="#现实问题" class="headerlink" title="现实问题"></a>现实问题</h4><p>在网上的教程里面，经常能见到python多线程的身影。比如网络爬虫的教程、端口扫描的教程。</p><p>这里拿端口扫描来说，大家可以用多进程实现下面的脚本，会发现python多进程更快。那么不就是和我们分析相悖了吗？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys,threading</span><br><span class="line"><span class="keyword">from</span> socket <span class="keyword">import</span> *</span><br><span class="line"> </span><br><span class="line">host = <span class="string">"127.0.0.1"</span> <span class="keyword">if</span> len(sys.argv)==<span class="number">1</span> <span class="keyword">else</span> sys.argv[<span class="number">1</span>]</span><br><span class="line">portList = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">1000</span>)]</span><br><span class="line">scanList = []</span><br><span class="line">lock = threading.Lock()</span><br><span class="line">print(<span class="string">'Please waiting... From '</span>,host)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scanPort</span><span class="params">(port)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        tcp = socket(AF_INET,SOCK_STREAM)</span><br><span class="line">        tcp.connect((host,port))</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> lock.acquire():</span><br><span class="line">            print(<span class="string">'[+]port'</span>,port,<span class="string">'open'</span>)</span><br><span class="line">            lock.release()</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        tcp.close()</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> portList:</span><br><span class="line">    t = threading.Thread(target=scanPort,args=(p,))</span><br><span class="line">    scanList.append(t)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(portList)):</span><br><span class="line">    scanList[i].start()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(portList)):</span><br><span class="line">    scanList[i].join()</span><br></pre></td></tr></table></figure><h4 id="谁更快"><a href="#谁更快" class="headerlink" title="谁更快"></a>谁更快</h4><p>因为python锁的问题，线程进行锁竞争、切换线程，会消耗资源。所以，大胆猜测一下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在CPU密集型任务下，多进程更快，或者说效果更好；而IO密集型，多线程能有效提高效率。</span><br></pre></td></tr></table></figure><p>大家看一下下面的代码:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"> </span><br><span class="line">max_process = <span class="number">4</span></span><br><span class="line">max_thread = max_process</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(n,n2)</span>:</span></span><br><span class="line">    <span class="comment">#cpu密集型</span></span><br><span class="line">    <span class="keyword">for</span>  i <span class="keyword">in</span> range(<span class="number">0</span>,n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,(int)(n*n*n*n2)):</span><br><span class="line">            t = i*j</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">thread_main</span><span class="params">(n2)</span>:</span></span><br><span class="line">    thread_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,max_thread):</span><br><span class="line">        t = threading.Thread(target=fun,args=(<span class="number">50</span>,n2))</span><br><span class="line">        thread_list.append(t)</span><br><span class="line"> </span><br><span class="line">    start = time.time()</span><br><span class="line">    print(<span class="string">' [+] much thread start'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> thread_list:</span><br><span class="line">        i.start()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> thread_list:</span><br><span class="line">        i.join()</span><br><span class="line">    print(<span class="string">' [-] much thread use '</span>,time.time()-start,<span class="string">'s'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_main</span><span class="params">(n2)</span>:</span></span><br><span class="line">    p = multiprocessing.Pool(max_process)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,max_process):</span><br><span class="line">        p.apply_async(func = fun,args=(<span class="number">50</span>,n2))</span><br><span class="line">    start = time.time()</span><br><span class="line">    print(<span class="string">' [+] much process start'</span>)</span><br><span class="line">    p.close()<span class="comment">#关闭进程池</span></span><br><span class="line">    p.join()<span class="comment">#等待所有子进程完毕</span></span><br><span class="line">    print(<span class="string">' [-] much process use '</span>,time.time()-start,<span class="string">'s'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">"[++]When n=50,n2=0.1:"</span>)</span><br><span class="line">    thread_main(<span class="number">0.1</span>)</span><br><span class="line">    process_main(<span class="number">0.1</span>)</span><br><span class="line">    print(<span class="string">"[++]When n=50,n2=1:"</span>)</span><br><span class="line">    thread_main(<span class="number">1</span>)</span><br><span class="line">    process_main(<span class="number">1</span>)</span><br><span class="line">    print(<span class="string">"[++]When n=50,n2=10:"</span>)</span><br><span class="line">    thread_main(<span class="number">10</span>)</span><br><span class="line">    process_main(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>结果如下：</p><p><img src="/articles/4efb4de8/2.png" alt></p><p>可以看出来，当对cpu使用率越来越高的时候（代码循环越多的时候），差距越来越大。</p><p><strong>验证我们猜想(在CPU密集型任务下，多进程更快，或者说效果更好；而IO密集型，多线程能有效提高效率。</strong></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>CPU密集型代码(如：各种循环处理、计数等等)，适合用多进程<br>IO密集型代码(如：文件处理、网络爬虫等)，适合用多线程</p><h2 id="判断方法"><a href="#判断方法" class="headerlink" title="判断方法"></a>判断方法</h2><p>1，直接看CPU占用率或硬盘IO读写速度<br>2，大致上归纳：计算较多为CPU密集型；时间等待较多(如网络爬虫)为IO密集型。</p><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>对于IO密集型任务：</p><p>单进程单线程直接执行用时：10.0333秒<br>多线程执行用时：4.0156秒<br>多进程执行用时：5.0182秒<br>说明多线程适合IO密集型任务。</p><p>对于计算密集型任务</p><p>单进程单线程直接执行用时：10.0273秒<br>多线程执行用时：13.247秒<br>多进程执行用时：6.8377秒</p><p><strong>说明多进程适合计算密集型任务</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义全局变量Queue</span></span><br><span class="line">g_queue = multiprocessing.Queue()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_queue</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"init g_queue start"</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> g_queue.empty():</span><br><span class="line">        g_queue.get()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">for</span> _index <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        g_queue.put(_index)</span><br><span class="line">    print(<span class="string">"init g_queue end"</span>)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个IO密集型任务：利用time.sleep()</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">task_io</span><span class="params">(task_id)</span>:</span></span><br><span class="line">    print(<span class="string">"IOTask[%s] start"</span> % task_id)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> g_queue.empty():</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data = g_queue.get(block=<span class="literal">True</span>, timeout=<span class="number">1</span>)</span><br><span class="line">            print(<span class="string">"IOTask[%s] get data: %s"</span> % (task_id, data))</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> excep:</span><br><span class="line">            print(<span class="string">"IOTask[%s] error: %s"</span> % (task_id, str(excep)))</span><br><span class="line">    print(<span class="string">"IOTask[%s] end"</span> % task_id)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">g_search_list = list(range(<span class="number">10000</span>))</span><br><span class="line"><span class="comment"># 定义一个计算密集型任务：利用一些复杂加减乘除、列表查找等</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">task_cpu</span><span class="params">(task_id)</span>:</span></span><br><span class="line">    print(<span class="string">"CPUTask[%s] start"</span> % task_id)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> g_queue.empty():</span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">            count += pow(<span class="number">3</span>*<span class="number">2</span>, <span class="number">3</span>*<span class="number">2</span>) <span class="keyword">if</span> i <span class="keyword">in</span> g_search_list <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data = g_queue.get(block=<span class="literal">True</span>, timeout=<span class="number">1</span>)</span><br><span class="line">            print(<span class="string">"CPUTask[%s] get data: %s"</span> % (task_id, data))</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> excep:</span><br><span class="line">            print(<span class="string">"CPUTask[%s] error: %s"</span> % (task_id, str(excep)))</span><br><span class="line">    print(<span class="string">"CPUTask[%s] end"</span> % task_id)</span><br><span class="line">    <span class="keyword">return</span> task_id</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">"cpu count:"</span>, multiprocessing.cpu_count(), <span class="string">"\n"</span>)</span><br><span class="line">    print(<span class="string">u"========== 直接执行IO密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    task_io(<span class="number">0</span>)</span><br><span class="line">    print(<span class="string">u"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 多线程执行IO密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    thread_list = [threading.Thread(target=task_io, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        <span class="keyword">if</span> t.is_alive():</span><br><span class="line">            t.join()</span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 多进程执行IO密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    process_list = [multiprocessing.Process(target=task_io, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(multiprocessing.cpu_count())]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        p.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        <span class="keyword">if</span> p.is_alive():</span><br><span class="line">            p.join()</span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 直接执行CPU密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    task_cpu(<span class="number">0</span>)</span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 多线程执行CPU密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    thread_list = [threading.Thread(target=task_cpu, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        <span class="keyword">if</span> t.is_alive():</span><br><span class="line">            t.join()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 多进程执行cpu密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    process_list = [multiprocessing.Process(target=task_cpu, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(multiprocessing.cpu_count())]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        p.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        <span class="keyword">if</span> p.is_alive():</span><br><span class="line">            p.join()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;通过实例实验，比较用多线程和多进程耗时情况，并进行总结归纳，选择效率最高的方法。&lt;/p&gt;
    
    </summary>
    
      <category term="编程积累" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/"/>
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/Python/"/>
    
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Multiprocessing基础</title>
    <link href="https://wandouduoduo.netlify.com/articles/9a80786c.html"/>
    <id>https://wandouduoduo.netlify.com/articles/9a80786c.html</id>
    <published>2019-11-29T07:40:05.000Z</published>
    <updated>2019-11-29T10:50:01.360Z</updated>
    
    <content type="html"><![CDATA[<p>multiprocessing是Python的标准模块，它既可以用来编写多进程，也可以用来编写多线程。如果是多线程的话，用multiprocessing.dummy即可，用法与multiprocessing基本相同，这里主要介绍多进程的用法，欢迎纠错。</p><h2 id="Multiprocessing介绍"><a href="#Multiprocessing介绍" class="headerlink" title="Multiprocessing介绍"></a>Multiprocessing介绍</h2><h5 id="为什么要使用python多进程？"><a href="#为什么要使用python多进程？" class="headerlink" title="为什么要使用python多进程？"></a>为什么要使用python<strong>多进程</strong>？</h5><p>因为python使用全局解释器锁(GIL)，他会将进程中的线程序列化，也就是多核cpu实际上并不能达到并行提高速度的目的，而使用多进程则是不受限的，所以实际应用中都是推荐多进程的。<br>如果每个子进程执行需要消耗的时间非常短（执行+1操作等），这不必使用多进程，因为进程的启动关闭也会耗费资源。<br>当然使用多进程往往是用来处理CPU密集型（科学计算）的需求，如果是IO密集型（文件读取，爬虫等）则可以使用多线程去处理。</p><a id="more"></a><h2 id="multiprocessing常用组件及功能"><a href="#multiprocessing常用组件及功能" class="headerlink" title="multiprocessing常用组件及功能"></a>multiprocessing常用组件及功能</h2><p>创建管理进程模块：</p><ul><li>Process (用于创建进程模块）</li><li>Pool（用于创建管理进程池）</li><li>Queue（用于进程通信，资源共享）</li><li>Value，Array（用于进程通信，资源共享）</li><li>Pipe（用于管道通信）</li><li>Manager（用于资源共享）</li></ul><p>同步子进程模块：</p><ul><li>Condition</li><li>Event</li><li>Lock</li><li>RLock</li><li>Semaphore</li></ul><h2 id="Multiprocessing进程管理模块"><a href="#Multiprocessing进程管理模块" class="headerlink" title="Multiprocessing进程管理模块"></a>Multiprocessing进程管理模块</h2><p>说明：由于篇幅有限，模块具体用法结束请参考每个模块的具体链接。</p><h5 id="Process模块"><a href="#Process模块" class="headerlink" title="Process模块"></a>Process模块</h5><p>Process模块用来创建子进程，是Multiprocessing核心模块，使用方式与Threading类似，可以实现多进程的创建，启动，关闭等操作。</p><h5 id="Pool模块"><a href="#Pool模块" class="headerlink" title="Pool模块"></a>Pool模块</h5><p>Pool模块是用来创建管理进程池的，当子进程非常多且需要控制子进程数量时可以使用此模块。</p><h5 id="Queue模块"><a href="#Queue模块" class="headerlink" title="Queue模块"></a>Queue模块</h5><p>Queue模块用来控制进程安全，与线程中的Queue用法一样。</p><h5 id="Pipe模块"><a href="#Pipe模块" class="headerlink" title="Pipe模块"></a>Pipe模块</h5><p>Pipe模块用来管道操作。</p><h5 id="Manager模块"><a href="#Manager模块" class="headerlink" title="Manager模块"></a>Manager模块</h5><p>Manager模块常与Pool模块一起使用，作用是共享资源。</p><h4 id="Multiprocessing同步进程模块"><a href="#Multiprocessing同步进程模块" class="headerlink" title="Multiprocessing同步进程模块"></a>Multiprocessing同步进程模块</h4><h5 id="Lock模块"><a href="#Lock模块" class="headerlink" title="Lock模块"></a>Lock模块</h5><p>作用：当多个进程需要访问共享资源的时候，Lock可以用来避免访问的冲突。</p><p>具体场景：所有的任务在打印的时候都会向同一个标准输出(stdout)输出。这样输出的字符会混合在一起，无法阅读。使用Lock同步，在一个任务输出完成之后，再允许另一个任务输出，可以避免多个任务同时向终端输出。</p><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process, Lock  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">l</span><span class="params">(lock, num)</span>:</span>      </span><br><span class="line">lock.acquire()      </span><br><span class="line"><span class="keyword">print</span> <span class="string">"Hello Num: %s"</span> % (num)      </span><br><span class="line">lock.release()  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:      </span><br><span class="line">lock = Lock()  <span class="comment">#这个一定要定义为全局    </span></span><br><span class="line"><span class="keyword">for</span> num <span class="keyword">in</span> range(<span class="number">20</span>):          </span><br><span class="line">Process(target=l, args=(lock, num)).start()  <span class="comment">#这个类似多线程中的threading，但是进程太多了，控制不了。</span></span><br></pre></td></tr></table></figure><h5 id="Semaphore模块"><a href="#Semaphore模块" class="headerlink" title="Semaphore模块"></a>Semaphore模块</h5><p>作用：用来控制对共享资源的访问数量，例如池的最大连接数。</p><h5 id="Event模块"><a href="#Event模块" class="headerlink" title="Event模块"></a>Event模块</h5><p>作用：用来实现进程间同步通信。</p><h2 id="Multiprocessing-dummy多线程"><a href="#Multiprocessing-dummy多线程" class="headerlink" title="Multiprocessing.dummy多线程"></a>Multiprocessing.dummy多线程</h2><p>Multiprocessing.dummy用法与Multiprocessing用法基本相同，只不过是用来创建多线程。</p><h2 id="使用Multiprocessing疑问"><a href="#使用Multiprocessing疑问" class="headerlink" title="使用Multiprocessing疑问"></a>使用Multiprocessing疑问</h2><ul><li><em>启动多进程的代码一定要放在</em> if <strong>name</strong>==”<strong>main</strong>“: <em>后面吗？</em></li></ul><p>　　解答：windows系统下，想要启动一个子进程，必须加上<em>if *</em>name<strong>==”</strong>main*<em>“:</em>，linux则不需要。</p><ul><li><em>父进程中的全局变量能被子进程共享吗？</em></li></ul><p>　　解答：不行，因为每个进程享有独立的内存数据，如果想要共享资源，可以使用Manage类，或者Queue等模块。</p><ul><li><em>子进程能结束其他子进程或父进程吗？如果能，怎么通过子进程去结束所有进程?</em></li></ul><p>　　解答：此需求可以稍作修改：所有的子进程都是为了完成一件事情，而当某个子进程完成该事情后，父进程就该结束所有子进程，请问该怎么做？此时结束所有子进程的操作可以交给父进程去做，因为子进程想要结束另外的子进程比较难实现。<br>　　那么问题就又变成了父进程什么时候该结束所有进程？<br>　　其中一个思路是<em>获取每个子进程的返回值</em>，一旦有返回True（结束的标记），则立马结束所有进程；<br>　　另外一种思路是<em>使用共享资源</em>，父进程可以一直去判断这个公共资源，一旦子进程将它改变，则结束所有子进程。（推荐使用前者，因为多进程中不推荐使用资源共享）</p><ul><li><em>子进程中还能再创建子进程吗？</em></li></ul><p>解答：可以，子进程可以再创建进程，线程中也可以创建进程。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;multiprocessing是Python的标准模块，它既可以用来编写多进程，也可以用来编写多线程。如果是多线程的话，用multiprocessing.dummy即可，用法与multiprocessing基本相同，这里主要介绍多进程的用法，欢迎纠错。&lt;/p&gt;
&lt;h2 id=&quot;Multiprocessing介绍&quot;&gt;&lt;a href=&quot;#Multiprocessing介绍&quot; class=&quot;headerlink&quot; title=&quot;Multiprocessing介绍&quot;&gt;&lt;/a&gt;Multiprocessing介绍&lt;/h2&gt;&lt;h5 id=&quot;为什么要使用python多进程？&quot;&gt;&lt;a href=&quot;#为什么要使用python多进程？&quot; class=&quot;headerlink&quot; title=&quot;为什么要使用python多进程？&quot;&gt;&lt;/a&gt;为什么要使用python&lt;strong&gt;多进程&lt;/strong&gt;？&lt;/h5&gt;&lt;p&gt;因为python使用全局解释器锁(GIL)，他会将进程中的线程序列化，也就是多核cpu实际上并不能达到并行提高速度的目的，而使用多进程则是不受限的，所以实际应用中都是推荐多进程的。&lt;br&gt;如果每个子进程执行需要消耗的时间非常短（执行+1操作等），这不必使用多进程，因为进程的启动关闭也会耗费资源。&lt;br&gt;当然使用多进程往往是用来处理CPU密集型（科学计算）的需求，如果是IO密集型（文件读取，爬虫等）则可以使用多线程去处理。&lt;/p&gt;
    
    </summary>
    
      <category term="编程积累" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/"/>
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/Python/"/>
    
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python之多进程详解</title>
    <link href="https://wandouduoduo.netlify.com/articles/a5c1f14c.html"/>
    <id>https://wandouduoduo.netlify.com/articles/a5c1f14c.html</id>
    <published>2019-11-29T07:34:06.000Z</published>
    <updated>2019-11-29T10:50:01.364Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>Python中的multiprocess提供了Process类，实现进程相关的功能。但是它基于fork机制，因此不被windows平台支持。想要在windows中运行，必须使用 if <strong>name</strong> == ‘<strong>main</strong>: 的方式)。并且多进程就是开启多个进程，每个进程之间是不会互相通信互相干扰的，适用于密集计算。</p><a id="more"></a><h2 id="案例一-基础用法"><a href="#案例一-基础用法" class="headerlink" title="案例一 基础用法"></a>案例一 基础用法</h2><p>多进程的使用方法和多线程使用方法基本一样，所以如果你会多线程用法多进程也就懂了，有一点要注意，定义多进程，然后传递参数的时候，如果是有一个参数就是用args=（i，）一定要加上逗号，如果有两个或者以上的参数就不用这样。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">import multiprocessing</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line">def fun(i):</span><br><span class="line">    print sys.path</span><br><span class="line">    print sys.version_info</span><br><span class="line">    print sys.platform</span><br><span class="line">    print sys.long_info</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    m = multiprocessing.Process(target=fun,args=(1,))</span><br><span class="line">    m.start()</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[&apos;E:\\python27\\python study&apos;, &apos;E:\\python27&apos;, &apos;C:\\windows\\SYSTEM32\\python27.zip&apos;, &apos;F:\\Python27\\DLLs&apos;, &apos;F:\\Python27\\lib&apos;, &apos;F:\\Python27\\lib\\plat-win&apos;, &apos;F:\\Python27\\lib\\lib-tk&apos;, &apos;F:\\Python27&apos;, &apos;F:\\Python27\\lib\\site-packages&apos;, &apos;F:\\Python27\\lib\\site-packages\\certifi-2017.7.27.1-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\idna-2.6-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\pypiwin32-219-py2.7-win-amd64.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\future-0.16.0-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\dis3-0.1.1-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\macholib-1.8-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\pefile-2017.9.3-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\altgraph-0.14-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\beautifulsoup4-4.6.0-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\chardet-3.0.4-py2.7.egg&apos;]</span><br><span class="line">sys.version_info(major=2, minor=7, micro=14, releaselevel=&apos;final&apos;, serial=0)</span><br><span class="line">win32</span><br><span class="line">sys.long_info(bits_per_digit=30, sizeof_digit=4)</span><br></pre></td></tr></table></figure><h2 id="案例二-数据通信"><a href="#案例二-数据通信" class="headerlink" title="案例二 数据通信"></a>案例二 数据通信</h2><p>ipc：就是进程间的通信模式，常用的一半是socke，rpc，pipe和消息队列等。</p><p>multiprocessing提供了threading包中没有的IPC(比如Pipe和Queue)，效率上更高。应优先考虑Pipe和Queue，避免使用Lock/Event/Semaphore/Condition等同步方式 (因为它们占据的不是用户进程的资源)。</p><h4 id="使用Array共享数据"><a href="#使用Array共享数据" class="headerlink" title="使用Array共享数据"></a>使用Array共享数据</h4><p>对于Array数组类，括号内的“i”表示它内部的元素全部是int类型，而不是指字符“i”，数组内的元素可以预先指定，也可以只指定数组的长度。Array类在实例化的时候必须指定数组的数据类型和数组的大小，类似temp = Array(‘i’, 5)。对于数据类型有下面的对应关系：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&apos;c&apos;: ctypes.c_char, &apos;u&apos;: ctypes.c_wchar,</span><br><span class="line">&apos;b&apos;: ctypes.c_byte, &apos;B&apos;: ctypes.c_ubyte,</span><br><span class="line">&apos;h&apos;: ctypes.c_short, &apos;H&apos;: ctypes.c_ushort,</span><br><span class="line">&apos;i&apos;: ctypes.c_int, &apos;I&apos;: ctypes.c_uint,</span><br><span class="line">&apos;l&apos;: ctypes.c_long, &apos;L&apos;: ctypes.c_ulong,</span><br><span class="line">&apos;f&apos;: ctypes.c_float, &apos;d&apos;: ctypes.c_double</span><br></pre></td></tr></table></figure><p>代码实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Process</span><br><span class="line">from multiprocessing import Array</span><br><span class="line"></span><br><span class="line">def func(i,temp):</span><br><span class="line">    temp[0] += 100</span><br><span class="line">    print(&quot;进程%s &quot; % i, &apos; 修改数组第一个元素后-----&gt;&apos;, temp[0])</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    temp = Array(&apos;i&apos;, [1, 2, 3, 4])</span><br><span class="line">    for i in range(10):</span><br><span class="line">        p = Process(target=func, args=(i, temp))</span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">进程2   修改数组第一个元素后-----&gt; 101</span><br><span class="line">进程4   修改数组第一个元素后-----&gt; 201</span><br><span class="line">进程5   修改数组第一个元素后-----&gt; 301</span><br><span class="line">进程3   修改数组第一个元素后-----&gt; 401</span><br><span class="line">进程1   修改数组第一个元素后-----&gt; 501</span><br><span class="line">进程6   修改数组第一个元素后-----&gt; 601</span><br><span class="line">进程9   修改数组第一个元素后-----&gt; 701</span><br><span class="line">进程8   修改数组第一个元素后-----&gt; 801</span><br><span class="line">进程0   修改数组第一个元素后-----&gt; 901</span><br><span class="line">进程7   修改数组第一个元素后-----&gt; 1001</span><br></pre></td></tr></table></figure><h4 id="使用Manager共享数据"><a href="#使用Manager共享数据" class="headerlink" title="使用Manager共享数据"></a>使用Manager共享数据</h4><p>通过Manager类也可以实现进程间数据的共享，主要用于线程池之间通信，Manager()返回的manager对象提供一个服务进程，使得其他进程可以通过代理的方式操作Python对象。manager对象支持 list, dict, Namespace, Lock, RLock, Semaphore, BoundedSemaphore, Condition, Event, Barrier, Queue, Value ,Array等多种格式。</p><p>代码实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Process</span><br><span class="line">from multiprocessing import Manager</span><br><span class="line"></span><br><span class="line">def func(i, dic):</span><br><span class="line">    dic[&quot;num&quot;] = 100+i</span><br><span class="line">    print(dic.items())</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    dic = Manager().dict()</span><br><span class="line">    for i in range(10):</span><br><span class="line">        p = Process(target=func, args=(i, dic))</span><br><span class="line">        p.start()</span><br><span class="line">        p.join()</span><br></pre></td></tr></table></figure><h4 id="使用queues的Queue类共享数据"><a href="#使用queues的Queue类共享数据" class="headerlink" title="使用queues的Queue类共享数据"></a>使用queues的Queue类共享数据</h4><p>multiprocessing是一个包，它内部有一个queues模块，提供了一个Queue队列类，可以实现进程间的数据共享，如下例所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import multiprocessing</span><br><span class="line">from multiprocessing import Process</span><br><span class="line">from multiprocessing import queues</span><br><span class="line"></span><br><span class="line">def func(i, q):</span><br><span class="line">    ret = q.get()</span><br><span class="line">    print(&quot;进程%s从队列里获取了一个%s，然后又向队列里放入了一个%s&quot; % (i, ret, i))</span><br><span class="line">    q.put(i)</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    lis = queues.Queue(20, ctx=multiprocessing)</span><br><span class="line">    lis.put(0)</span><br><span class="line">    for i in range(10):</span><br><span class="line">        p = Process(target=func, args=(i, lis,))</span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">进程1从队列里获取了一个0，然后又向队列里放入了一个1</span><br><span class="line">进程4从队列里获取了一个1，然后又向队列里放入了一个4</span><br><span class="line">进程2从队列里获取了一个4，然后又向队列里放入了一个2</span><br><span class="line">进程6从队列里获取了一个2，然后又向队列里放入了一个6</span><br><span class="line">进程0从队列里获取了一个6，然后又向队列里放入了一个0</span><br><span class="line">进程5从队列里获取了一个0，然后又向队列里放入了一个5</span><br><span class="line">进程9从队列里获取了一个5，然后又向队列里放入了一个9</span><br><span class="line">进程7从队列里获取了一个9，然后又向队列里放入了一个7</span><br><span class="line">进程3从队列里获取了一个7，然后又向队列里放入了一个3</span><br><span class="line">进程8从队列里获取了一个3，然后又向队列里放入了一个8</span><br></pre></td></tr></table></figure><p>例如来跑多进程对一批IP列表进行运算，运算后的结果都存到Queue队列里面，这个就必须使用multiprocessing提供的Queue来实现</p><p>关于queue和Queue，在Python库中非常频繁的出现，很容易就搞混淆了。甚至是multiprocessing自己还有一个Queue类(大写的Q)和的Manager类中提供的Queue方法，一样能实现消息队列queues.Queue的功能，导入方式是from multiprocessing import Queue，前者Queue用于多个进程间通信，和queues.Queue()差不多，后者Manager().queue用于进程池之间通信。</p><h4 id="使用pipe实现进程间通信"><a href="#使用pipe实现进程间通信" class="headerlink" title="使用pipe实现进程间通信"></a>使用pipe实现进程间通信</h4><p>pipe只能适用于两个进程间通信，queue则没这个限制，他有两个方法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">receive_pi = Pipe()</span><br><span class="line"># 定义变量，用来获取数据</span><br><span class="line">send_pi = Pipe()</span><br><span class="line"># 用来发送数据</span><br></pre></td></tr></table></figure><p>具体例子如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pipe,Process</span><br><span class="line">import time</span><br><span class="line">def produce(pipe):</span><br><span class="line">    pipe.send(&apos;666&apos;)</span><br><span class="line">    time.sleep(1)</span><br><span class="line">def consumer(pipe):</span><br><span class="line">    print(pipe.recv())</span><br><span class="line">    # 有些类似socket的recv方法</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    send_pi,recv_pi = Pipe()</span><br><span class="line">    my_pro = Process(target=produce,args=(send_pi,))</span><br><span class="line">    my_con = Process(target=consumer,args=(recv_pi,))</span><br><span class="line">    my_pro.start()</span><br><span class="line">    my_con.start()</span><br><span class="line">    my_pro.join()</span><br><span class="line">    my_con.join()</span><br></pre></td></tr></table></figure><p>pipe相当于queue的一个子集，只能服务两个进程，pipe的性能高于queue。</p><h2 id="案例三-进程锁"><a href="#案例三-进程锁" class="headerlink" title="案例三 进程锁"></a>案例三 进程锁</h2><p>一般来说每个进程使用单独的空间，不必加进程锁的，但是如果你需要先实现进程数据共享，<strong>使用案例二中的代码</strong>，又害怕造成数据抢夺和脏数据的问题。就可以设置进程锁，与threading类似，在multiprocessing里也有同名的锁类RLock，Lock，Event，Condition和 Semaphore，连用法都是一样样的。</p><p><strong>如果有多个进程要上锁，使用multiprocessing.Manager().BoundedSemaphore(1)</strong></p><p>代码实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Process</span><br><span class="line">from multiprocessing import Array</span><br><span class="line">from multiprocessing import RLock, Lock, Event, Condition, Semaphore</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">def func(i,lis,lc):</span><br><span class="line">    lc.acquire()</span><br><span class="line">    lis[0] = lis[0] - 1</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    print(&apos;say hi&apos;, lis[0])</span><br><span class="line">    lc.release()</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    array = Array(&apos;i&apos;, 1)</span><br><span class="line">    array[0] = 10</span><br><span class="line">    lock = RLock()</span><br><span class="line">    for i in range(10):</span><br><span class="line">        p = Process(target=func, args=(i, array, lock))</span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">say hi 9</span><br><span class="line">say hi 8</span><br><span class="line">say hi 7</span><br><span class="line">say hi 6</span><br><span class="line">say hi 5</span><br><span class="line">say hi 4</span><br><span class="line">say hi 3</span><br><span class="line">say hi 2</span><br><span class="line">say hi 1</span><br><span class="line">say hi 0</span><br></pre></td></tr></table></figure><h2 id="案例四-进程池"><a href="#案例四-进程池" class="headerlink" title="案例四 进程池"></a>案例四 进程池</h2><p>from multiprocessing import Pool导入就行，非常容易使用的。进程池内部维护了一个进程序列，需要时就去进程池中拿取一个进程，如果进程池序列中没有可供使用的进程，那么程序就会等待，直到进程池中有可用进程为止。</p><ol><li>apply() 同步执行（串行）</li><li>apply_async() 异步执行（并行）</li><li>terminate() 立刻关闭进程池</li><li>join() 主进程等待所有子进程执行完毕。必须在close或terminate()之后。</li><li>close() 等待所有进程结束后，才关闭进程池。</li></ol><p>代码实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">import time</span><br><span class="line">def func(args):</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    print(&quot;正在执行进程 &quot;, args)</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    p = Pool(5)     # 创建一个包含5个进程的进程池</span><br><span class="line">    for i in range(30):</span><br><span class="line">        # 有30个任务</span><br><span class="line">        p.apply_async(func=func, args=(i,))</span><br><span class="line">        # 异步执行，并发。这里不用target，要用func</span><br><span class="line">    p.close()           # 等子进程执行完毕后关闭进程池</span><br><span class="line">    # time.sleep(2)</span><br><span class="line">    # p.terminate()     # 立刻关闭进程池</span><br><span class="line">    p.join()</span><br></pre></td></tr></table></figure><p>from multiprocessing.dummy import Pool as ThreadPool 是多线程进程池，绑定一个cpu核心。from multiprocessing import Pool多进程，运行于多个cpu核心。multiprocessing 是多进程模块， 而multiprocessing.dummy是以相同API实现的多线程模块。<br>没有绕过GIL情况下，多线程一定受GIL限制。</p><p>代码实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing.dummy import Pool as tp</span><br><span class="line">def fun(i):</span><br><span class="line">    print i+i+i+i</span><br><span class="line"></span><br><span class="line">list_i=[range(100)]</span><br><span class="line"></span><br><span class="line">px = tp(processes=8)</span><br><span class="line"># 开启8个线程池</span><br><span class="line">px.map(fun,list_i)</span><br><span class="line">px.close()</span><br><span class="line">px.join()</span><br></pre></td></tr></table></figure><p>使用dummy方法可以不用<strong>name</strong>=’<strong>main</strong>‘，并且用法很简单，开启线程池用法一样，需要注意的是导入的参数，要在一个列表中导入。比如你有一批数据要放进这个线程池，就直接把这批数据放在一个列表中。</p><h2 id="案例五-爬虫进程池"><a href="#案例五-爬虫进程池" class="headerlink" title="案例五 爬虫进程池"></a>案例五 爬虫进程池</h2><p>案例来自<a href="https://morvanzhou.github.io/tutorials/data-manipulation/scraping/4-01-distributed-scraping/" target="_blank" rel="noopener">莫凡</a></p><h4 id="什么是分布式爬虫"><a href="#什么是分布式爬虫" class="headerlink" title="什么是分布式爬虫"></a>什么是分布式爬虫</h4><p>分布式爬虫主要是为了非常有效率的抓取网页, 我们的程序一般是单线程跑的, 指令也是一条条处理的, 每执行完一条指令才能跳到下一条. 那么在爬虫的世界里, 这里存在着一个问题.</p><p>如果你已经顺利地执行过了前几节的爬虫代码, 你会发现, 有时候代码运行的时间大部分都花在了下载网页上. 有时候不到一秒能下载好一张网页的 HTML, 有时候却要几十秒. 而且非要等到 HTML 下载好了以后, 才能执行网页分析等步骤. 这非常浪费时间.</p><p>如果我们能合理利用计算资源, 在下载一部分网页的时候就已经开始分析另一部分网页了. 这将会大大节省整个程序的运行时间. 又或者, 我们能同时下载多个网页, 同时分析多个网页, 这样就有种事倍功半的效用. 分布式爬虫的体系有很多种, 处理优化的问题也是多样的. 这里有一篇博客可以当做扩展阅读, 来了解当今比较流行的分布式爬虫框架.</p><h4 id="我们的分布式爬虫"><a href="#我们的分布式爬虫" class="headerlink" title="我们的分布式爬虫"></a>我们的分布式爬虫</h4><p>而今天我们想搭建的这一个爬虫, 就是同时下载, 同时分析的这一种类型的分布式爬虫. 虽然算不上特别优化的框架, 但是概念理解起来比较容易. 我有尝试过徒手写高级一点的分布式爬虫, 但是写起来非常麻烦. 我琢磨了一下, 打算给大家介绍的这种分布式爬虫代码也较好写, 而且效率比普通爬虫快了3.5倍. 我也特地画了张图给大家解释一下要搭建的分布式爬虫.</p><p><img src="/articles/a5c1f14c/1.png" alt="img"></p><p>主要来说, 我们最开始有一个网页, 比如说是莫烦Python的首页, 然后首页中有很多 url, 我们使用多进程 (Python多进程教程) 同时开始下载这些 url, 得到这些 url 的 HTML 以后, 同时开始解析 (比如 BeautifulSoup) 网页内容. 在网页中寻找这个网站还没有爬过的链接. 最终爬完整个 莫烦 Python 网站所有页面.</p><p>有了这种思路, 我们就可以开始写代码了. 你可以在我的 Github 一次性观看全部代码.</p><p>首先 import 全部要用的模块, 并规定一个主页. 注意, 我用这份代码测试我内网的网站(速度不受外网影响) 所以使用的 base_url 是 “<a href="http://127.0.0.1:4000/”" target="_blank" rel="noopener">http://127.0.0.1:4000/”</a>, 如果你要爬 莫烦Python, 你的 base_url 要是 “<a href="https://morvanzhou.github.io/”" target="_blank" rel="noopener">https://morvanzhou.github.io/”</a> (下载速度会受外网影响).</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import multiprocessing as mp</span><br><span class="line">import time</span><br><span class="line">from urllib.request import urlopen, urljoin</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line"># base_url = &quot;http://127.0.0.1:4000/&quot;</span><br><span class="line">base_url = &apos;https://morvanzhou.github.io/&apos;</span><br></pre></td></tr></table></figure><p>我们定义两个功能, 一个是用来爬取网页的(crawl), 一个是解析网页的(parse). 有了前几节内容的铺垫, 你应该能一言看懂下面的代码. crawl() 用 urlopen 来打开网页, 我用的内网测试, 所以为了体现下载网页的延迟, 添加了一个 time.sleep(0.1) 的下载延迟. 返回原始的 HTML 页面, parse() 就是在这个 HTML 页面中找到需要的信息, 我们用 BeautifulSoup 找 (BeautifulSoup 教程). 返回找到的信息.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def crawl(url):</span><br><span class="line">    response = urlopen(url)</span><br><span class="line">    # time.sleep(0.1)             # slightly delay for downloading</span><br><span class="line">    return response.read().decode()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def parse(html):</span><br><span class="line">    soup = BeautifulSoup(html, &apos;lxml&apos;)</span><br><span class="line">    urls = soup.find_all(&apos;a&apos;, &#123;&quot;href&quot;: re.compile(&apos;^/.+?/$&apos;)&#125;)</span><br><span class="line">    title = soup.find(&apos;h1&apos;).get_text().strip()</span><br><span class="line">    page_urls = set([urljoin(base_url, url[&apos;href&apos;]) for url in urls])   # 去重</span><br><span class="line">    url = soup.find(&apos;meta&apos;, &#123;&apos;property&apos;: &quot;og:url&quot;&#125;)[&apos;content&apos;]</span><br><span class="line">    return title, page_urls, url</span><br></pre></td></tr></table></figure><p>网页中爬取中, 肯定会爬到重复的网址, 为了去除掉这些重复, 我们使用 python 的 set 功能. 定义两个 set, 用来搜集爬过的网页和没爬过的.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">unseen = set([base_url,])</span><br><span class="line">seen = set()</span><br></pre></td></tr></table></figure><h4 id="测试普通爬法"><a href="#测试普通爬法" class="headerlink" title="测试普通爬法"></a>测试普通爬法</h4><p>为了对比效果, 我们将在下面对比普通的爬虫和这种分布式的效果. 如果是普通爬虫, 我简化了一下接下来的代码, 将一些不影响的代码去除掉了, 如果你想看全部的代码, 请来到我的 Github. 我们用循环一个个 crawl unseen 里面的 url, 爬出来的 HTML 放到 parse 里面去分析得到结果. 接着就是更新 seen 和 unseen 这两个集合了.</p><p>特别注意: 任何网站都是有一个服务器压力的, 如果你爬的过于频繁, 特别是使用多进程爬取或异步爬取, 一次性提交请求给服务器太多次, 这将可能会使得服务器瘫痪, 你可能再也看不到莫烦 Python 了. 所以为了安全起见, 我限制了爬取数量(restricted_crawl=True). 因为我测试使用的是内网 “<a href="http://127.0.0.1:4000/”" target="_blank" rel="noopener">http://127.0.0.1:4000/”</a> 所以不会有这种压力. 你在以后的爬网页中, 会经常遇到这样的爬取次数的限制 (甚至被封号). 我以前爬 github 时就被限制成一小时只能爬60页.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># DON&apos;T OVER CRAWL THE WEBSITE OR YOU MAY NEVER VISIT AGAIN</span><br><span class="line">if base_url != &quot;http://127.0.0.1:4000/&quot;:</span><br><span class="line">    restricted_crawl = True</span><br><span class="line">else:</span><br><span class="line">    restricted_crawl = False</span><br><span class="line"></span><br><span class="line">while len(unseen) != 0:                 # still get some url to visit</span><br><span class="line">    if restricted_crawl and len(seen) &gt;= 20:</span><br><span class="line">        break</span><br><span class="line">    htmls = [crawl(url) for url in unseen]</span><br><span class="line">    results = [parse(html) for html in htmls]</span><br><span class="line"></span><br><span class="line">    seen.update(unseen)         # seen the crawled</span><br><span class="line">    unseen.clear()              # nothing unseen</span><br><span class="line"></span><br><span class="line">    for title, page_urls, url in results:</span><br><span class="line">        unseen.update(page_urls - seen)     # get new url to crawl</span><br></pre></td></tr></table></figure><p>使用这种单线程的方法, 在我的内网上面爬, 爬完整个 莫烦Python, 一共消耗 52.3秒. 接着我们把它改成多进程分布式.</p><h4 id="测试分布式爬法"><a href="#测试分布式爬法" class="headerlink" title="测试分布式爬法"></a>测试分布式爬法</h4><p>还是上一个 while 循环, 首先我们创建一个进程池(Pool). 不太懂进程池的朋友看过来. 然后我们修改得到 htmls 和 results 的两句代码. 其他都不变, 只将这两个功能给并行了. 我在这里写的都是简化代码, 你可以在这里 看到完整代码.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">pool = mp.Pool(4)</span><br><span class="line">while len(unseen) != 0:</span><br><span class="line">    # htmls = [crawl(url) for url in unseen]</span><br><span class="line">    # ---&gt;</span><br><span class="line">    crawl_jobs = [pool.apply_async(crawl, args=(url,)) for url in unseen]</span><br><span class="line">    htmls = [j.get() for j in crawl_jobs]</span><br><span class="line"></span><br><span class="line">    # results = [parse(html) for html in htmls]</span><br><span class="line">    # ---&gt;</span><br><span class="line">    parse_jobs = [pool.apply_async(parse, args=(html,)) for html in htmls]</span><br><span class="line">    results = [j.get() for j in parse_jobs]</span><br></pre></td></tr></table></figure><p>还是在内网测试, 只用了 16.3秒!! 这可比上面的单线程爬虫快了3.5倍. 而且我还不是在外网测试的. 如果在外网, 爬取一张网页的时间更长, 使用多进程会更加有效率, 节省的时间更多.</p><h2 id="各模块作用"><a href="#各模块作用" class="headerlink" title="各模块作用"></a>各模块作用</h2><h4 id="Process介绍"><a href="#Process介绍" class="headerlink" title="Process介绍"></a>Process介绍</h4><p>构造方法:</p><ol><li>Process([group [, target [, name [, args [, kwargs]]]]])</li><li>group: 线程组，目前还没有实现，库引用中提示必须是None；</li><li>target: 要执行的方法；</li><li>name: 进程名；</li><li>args/kwargs: 要传入方法的参数。</li></ol><p>实例方法:</p><ol><li>is_alive()：返回进程是否在运行。</li><li>join([timeout])：阻塞当前上下文环境的进程程，直到调用此方法的进程终止或到达指定的3. timeout（可选参数）。</li><li>start()：进程准备就绪，等待CPU调度。</li><li>run()：strat()调用run方法，如果实例进程时未制定传入target，这star执行t默认run()方法。</li><li>terminate()：不管任务是否完成，立即停止工作进程。</li></ol><p>属性：</p><ol><li>authkey</li><li>daemon：和线程的setDeamon功能一样（将父进程设置为守护进程，当父进程结束时，子进程也结束）。</li><li>exitcode(进程在运行时为None、如果为–N，表示被信号N结束）。</li><li>name：进程名字。</li><li>pid：进程号。</li></ol><h4 id="Pool介绍"><a href="#Pool介绍" class="headerlink" title="Pool介绍"></a>Pool介绍</h4><p>Multiprocessing.Pool可以提供指定数量的进程供用户调用，当有新的请求提交到pool中时，如果池还没有满，那么就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到规定最大值，那么该请求就会等待，直到池中有进程结束，才会创建新的进程来执行它。在共享资源时，只能使用Multiprocessing.Manager类，而不能使用Queue或者Array。Pool类用于需要执行的目标很多，而手动限制进程数量又太繁琐时，如果目标少且不用控制进程数量则可以用Process类。</p><p>构造方法：</p><ol><li>Pool([processes[, initializer[, initargs[, maxtasksperchild[, context]]]]])</li><li>processes ：使用的工作进程的数量，如果processes是None那么使用 os.cpu_count()返回的数量。</li><li>initializer： 如果initializer是None，那么每一个工作进程在开始的时候会调用initializer(*initargs)。</li><li>maxtasksperchild：工作进程退出之前可以完成的任务数，完成后用一个新的工作进程来替代原进程，来让闲置的资源被释放。maxtasksperchild默认是None，意味着只要Pool存在工作进程就会一直存活。</li><li>context: 用在制定工作进程启动时的上下文，一般使用 multiprocessing.Pool() 或者一个context对象的Pool()方法来创建一个池，两种方法都适当的设置了context。</li></ol><p>实例方法：</p><ol><li>apply_async(func[, args[, kwds[, callback]]]) 它是非阻塞。</li><li>apply(func[, args[, kwds]])是阻塞的</li><li>close() 关闭pool，使其不在接受新的任务。</li><li>terminate() 关闭pool，结束工作进程，不在处理未完成的任务。</li><li>join() 主进程阻塞，等待子进程的退出， join方法要在close或terminate之后使用。</li></ol><p>Pool使用方法</p><p>Pool+map函数</p><p>说明：此写法缺点在于只能通过map向函数传递一个参数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">def test(i):</span><br><span class="line">    print i</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    lists=[1,2,3]</span><br><span class="line">    pool=Pool(processes=2) #定义最大的进程数</span><br><span class="line">    pool.map(test,lists)        #p必须是一个可迭代变量。</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure><p>异步进程池（非阻塞）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">def test(i):</span><br><span class="line">    print i</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    pool = Pool(processes=10)</span><br><span class="line">    for i  in xrange(500):</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        For循环中执行步骤：</span><br><span class="line">        （1）循环遍历，将500个子进程添加到进程池（相对父进程会阻塞）</span><br><span class="line">        （2）每次执行10个子进程，等一个子进程执行完后，立马启动新的子进程。（相对父进程不阻塞）</span><br><span class="line"></span><br><span class="line">        apply_async为异步进程池写法。</span><br><span class="line">        异步指的是启动子进程的过程，与父进程本身的执行（print）是异步的，而For循环中往进程池添加子进程的过程，与父进程本身的执行却是同步的。</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        pool.apply_async(test, args=(i,)) #维持执行的进程总数为10，当一个进程执行完后启动一个新进程.       </span><br><span class="line">    print “test”</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure><p>执行顺序：For循环内执行了2个步骤，第一步：将500个对象放入进程池（阻塞）。第二步：同时执行10个子进程（非阻塞），有结束的就立即添加，维持10个子进程运行。（apply_async方法的会在执行完for循环的添加步骤后，直接执行后面的print语句，而apply方法会等所有进程池中的子进程运行完以后再执行后面的print语句）</p><p>注意：调用join之前，先调用close或者terminate方法，否则会出错。执行完close后不会有新的进程加入到pool,join函数等待所有子进程结束。</p><p>同步进程池（阻塞）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">def test(p):</span><br><span class="line">       print p</span><br><span class="line">       time.sleep(3)</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    pool = Pool(processes=10)</span><br><span class="line">    for i  in xrange(500):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    实际测试发现，for循环内部执行步骤：</span><br><span class="line">    （1）遍历500个可迭代对象，往进程池放一个子进程</span><br><span class="line">    （2）执行这个子进程，等子进程执行完毕，再往进程池放一个子进程，再执行。（同时只执行一个子进程）</span><br><span class="line">    for循环执行完毕，再执行print函数。</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">        pool.apply(test, args=(i,))   #维持执行的进程总数为10，当一个进程执行完后启动一个新进程.</span><br><span class="line">    print “test”</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure><p>说明：for循环内执行的步骤顺序，往进程池中添加一个子进程，执行子进程，等待执行完毕再添加一个子进程…..等500个子进程都执行完了，再执行print “test”。（从结果来看，并没有多进程并发）</p><h4 id="子进程返回值"><a href="#子进程返回值" class="headerlink" title="子进程返回值"></a>子进程返回值</h4><p>在实际使用多进程的时候，可能需要获取到子进程运行的返回值。如果只是用来存储，则可以将返回值保存到一个数据结构中；如果需要判断此返回值，从而决定是否继续执行所有子进程，则会相对比较复杂。另外在Multiprocessing中，可以利用Process与Pool创建子进程，这两种用法在获取子进程返回值上的写法上也不相同。这篇中，我们直接上代码，分析多进程中获取子进程返回值的不同用法，以及优缺点。</p><p>初级用法（Pool）</p><p>目的：存储子进程返回值</p><p>说明：如果只是单纯的存储子进程返回值，则可以使用Pool的apply_async异步进程池；当然也可以使用Process，用法与threading中的相同，这里只介绍前者。</p><p>实例：当进程池中所有子进程执行完毕后，输出每个子进程的返回值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">def test(p):     </span><br><span class="line">    return p</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    pool = Pool(processes=10)</span><br><span class="line">    result=[]</span><br><span class="line">    for i  in xrange(50000):</span><br><span class="line">       &apos;&apos;&apos;</span><br><span class="line">       for循环执行流程：</span><br><span class="line">       （1）添加子进程到pool，并将这个对象（子进程）添加到result这个列表中。（此时子进程并没有运行）</span><br><span class="line">       （2）执行子进程（同时执行10个）</span><br><span class="line">       &apos;&apos;&apos;</span><br><span class="line">       result.append(pool.apply_async(test, args=(i,)))#维持执行的进程总数为10，当一个进程执行完后添加新进程.       </span><br><span class="line">    pool.join()</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    遍历result列表，取出子进程对象，访问get()方法，获取返回值。（此时所有子进程已执行完毕）</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    for i in result:</span><br><span class="line">        print i.get()</span><br></pre></td></tr></table></figure><p>错误写法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for i  in xrange(50000):</span><br><span class="line">   t=pool.apply_async(test, args=(i,)))</span><br><span class="line">   print t.get()</span><br></pre></td></tr></table></figure><p>说明：这样会造成阻塞，因为get()方法只能等子进程运行完毕后才能调用成功，否则会一直阻塞等待。如果写在for循环内容，相当于变成了同步，执行效率将会非常低。</p><p>高级用法（Pool）<br>目的：父进程实时获取子进程返回值，以此为标记结束所有进程。</p><p>实例（一）<br>执行子进程的过程中，不断获取返回值并校验，如果返回值为True则结果所有进程。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">import Queue</span><br><span class="line">import time</span><br><span class="line">def test(p):</span><br><span class="line">    time.sleep(0.001)</span><br><span class="line">    if p==10000:</span><br><span class="line">        return True</span><br><span class="line">    else:</span><br><span class="line">        return False</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    pool = Pool(processes=10)</span><br><span class="line">    q=Queue.Queue()</span><br><span class="line">    for i  in xrange(50000):</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        将子进程对象存入队列中。</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        q.put(pool.apply_async(test, args=(i,)))#维持执行的进程总数为10，当一个进程执行完后添加新进程.       </span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    因为这里使用的为pool.apply_async异步方法，因此子进程执行的过程中，父进程会执行while，获取返回值并校验。</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    while 1:</span><br><span class="line">        if q.get().get():</span><br><span class="line">            pool.terminate() #结束进程池中的所有子进程。</span><br><span class="line">            break</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure><p>说明：总共要执行50000个子进程（并发数量为10），当其中一个子进程返回True时，结束进程池。因为使用了apply_async为异步进程，因此在执行完for循环的添加子进程操作后（只是添加并没有执行完所有的子进程），可以直接执行while代码，实时判断子进程返回值是否有True，有的话结束所有进程。</p><p>优点：不必等到所有子进程结束再结束程序，只要得到想要的结果就可以提前结束，节省资源。</p><p>不足：当需要执行的子进程非常大时，不适用，因为for循环在添加子进程时，要花费很长的时间，虽然是异步，但是也需要等待for循环添加子进程操作结束才能执行while代码，因此会比较慢。</p><p>实例（二）</p><p>多线程+多进程，添加执行子进程的过程中，不断获取返回值并校验，如果返回值为True则结果所有进程。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">import Queue</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">def test(p):</span><br><span class="line">    time.sleep(0.001)</span><br><span class="line">    if p==10000:</span><br><span class="line">        return True</span><br><span class="line">    else:</span><br><span class="line">        return False</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    result=Queue.Queue() #队列</span><br><span class="line">    pool = Pool()</span><br><span class="line">    def pool_th():</span><br><span class="line">        for i  in xrange(50000000): ##这里需要创建执行的子进程非常多</span><br><span class="line">            try:</span><br><span class="line">                result.put(pool.apply_async(test, args=(i,)))</span><br><span class="line">            except:</span><br><span class="line">                break</span><br><span class="line">    def result_th():</span><br><span class="line">        while 1:</span><br><span class="line">            a=result.get().get() #获取子进程返回值</span><br><span class="line">            if a:</span><br><span class="line">                pool.terminate() #结束所有子进程</span><br><span class="line">                break</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    利用多线程，同时运行Pool函数创建执行子进程，以及运行获取子进程返回值函数。</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    t1=threading.Thread(target=pool_th)</span><br><span class="line">    t2=threading.Thread(target=result_th)</span><br><span class="line">    t1.start()</span><br><span class="line">    t2.start()</span><br><span class="line">    t1.join()</span><br><span class="line">    t2.join()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure><p>执行流程：利用多线程，创建一个执行pool_th函数线程，一个执行result_th函数线程，pool_th函数用来添加进程池，开启进程执行功能函数并将子进程对象存入队列，而result_th()函数用来不停地从队列中取子进程对象，调用get（）方法获取返回值。等发现其中存在子进程的返回值为True时，结束所有进程，最后结束线程。</p><p>优点：弥补了实例（一）的不足，即使for循环的子进程数量很多，也能提高性能，因为for循环与判断子进程返回值同时进行。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;Python中的multiprocess提供了Process类，实现进程相关的功能。但是它基于fork机制，因此不被windows平台支持。想要在windows中运行，必须使用 if &lt;strong&gt;name&lt;/strong&gt; == ‘&lt;strong&gt;main&lt;/strong&gt;: 的方式)。并且多进程就是开启多个进程，每个进程之间是不会互相通信互相干扰的，适用于密集计算。&lt;/p&gt;
    
    </summary>
    
      <category term="编程积累" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/"/>
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/Python/"/>
    
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python之多线程详解</title>
    <link href="https://wandouduoduo.netlify.com/articles/e0b461d5.html"/>
    <id>https://wandouduoduo.netlify.com/articles/e0b461d5.html</id>
    <published>2019-11-29T07:28:51.000Z</published>
    <updated>2019-11-29T10:50:01.363Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>线程是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务，多线程就是在一个进程中的多个线程，如果使用多线程默认开启一个主线程，按照程序需求自动开启多个线程(也可以自己定义线程数)。</p><a id="more"></a><h2 id="多线程知识点"><a href="#多线程知识点" class="headerlink" title="多线程知识点"></a>多线程知识点</h2><ol><li>Python 在设计之初就考虑到要在解释器的主循环中，同时只有一个线程在执行，即在任意时刻，只有一个线程在解释器中运行。对Python 虚拟机的访问由全局解释器锁（GIL）来控制，正是这个锁能保证同一时刻只有一个线程在运行。</li><li>多线程共享主进程的资源，所以可能还会改变其中的变量，这个时候就要加上线程锁，每次执行完一个线程在执行下一个线程。</li><li>因为每次只能有一个线程运行，多线程怎么实现的呢？Python解释器中一个线程做完了任务然后做IO(文件读写)操作的时候，这个线程就退出，然后下一个线程开始运行，循环之。</li><li>当你读完上面三点你就知道多线程如何运行起来，并且知道多线程常用在那些需要等待然后执行的应用程序上(比如爬虫读取到数据，然后保存的时候下一个线程开始启动)也就是说多线程适用于IO密集型的任务量（文件存储，网络通信）。</li><li>注意一点，定义多线程，然后传递参数的时候，如果是有一个参数就是用args=（i，）一定要加上逗号，如果有两个或者以上的参数就不用这样。</li></ol><h2 id="代码实例"><a href="#代码实例" class="headerlink" title="代码实例"></a>代码实例</h2><h4 id="案例一-多线程核心用法"><a href="#案例一-多线程核心用法" class="headerlink" title="案例一 多线程核心用法"></a>案例一 多线程核心用法</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line"></span><br><span class="line">def loop():</span><br><span class="line">    #定义一个要循环的函数，当然后面肯定会定义好几个函数</span><br><span class="line">    print &apos;thread %s is running...&apos; % threading.current_thread().name</span><br><span class="line">    #threading.current_thread().name就是当前线程的名字  在声明线程的时候可以自定义子线程的名字</span><br><span class="line">    n = 0</span><br><span class="line">    while n &lt; 10:</span><br><span class="line">        n = n + 1</span><br><span class="line">        print &apos;%s &gt;&gt;&gt; %s&apos; % (threading.current_thread().name, n)</span><br><span class="line">        #输出当前线程名字  和循环的参数n</span><br><span class="line">    print &apos;thread %s ended.&apos; % threading.current_thread().name</span><br><span class="line">print &apos;thread %s is running...&apos; % threading.current_thread().name</span><br><span class="line"></span><br><span class="line">#下面的一部分就是threading的核心用法</span><br><span class="line">#包括target name args 之类的 一般我只用targer=你定义的函数名</span><br><span class="line">t = threading.Thread(target=loop, name=&apos;线程名:&apos;)</span><br><span class="line"># 在这里就申明了这个线程的名字</span><br><span class="line">t.start()</span><br><span class="line">#开始</span><br><span class="line">t.join()</span><br><span class="line">#关于join的相关信息我会在后面的代码详说</span><br><span class="line">print &apos;thread %s ended.&apos; % threading.current_thread().name</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">thread MainThread is running...</span><br><span class="line">thread 线程名: is running...</span><br><span class="line">线程名: &gt;&gt;&gt; 1</span><br><span class="line">线程名: &gt;&gt;&gt; 2</span><br><span class="line">线程名: &gt;&gt;&gt; 3</span><br><span class="line">线程名: &gt;&gt;&gt; 4</span><br><span class="line">线程名: &gt;&gt;&gt; 5</span><br><span class="line">线程名: &gt;&gt;&gt; 6</span><br><span class="line">线程名: &gt;&gt;&gt; 7</span><br><span class="line">线程名: &gt;&gt;&gt; 8</span><br><span class="line">线程名: &gt;&gt;&gt; 9</span><br><span class="line">线程名: &gt;&gt;&gt; 10</span><br><span class="line">thread 线程名: ended.</span><br><span class="line">thread MainThread ended.</span><br></pre></td></tr></table></figure><h4 id="案例二-线程锁"><a href="#案例二-线程锁" class="headerlink" title="案例二 线程锁"></a>案例二 线程锁</h4><p>前面有说到过，多线程是共享内存的，所以其中的变量如果发生了改变的话就会改变后边的变量，导致异常，这个时候可以加上线程锁。线程锁的概念就是主要这个线程运行完后再运行下一个线程。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line"></span><br><span class="line">def loop():</span><br><span class="line">    l.acquire()</span><br><span class="line">    # 这里相当于把线程加了锁，目前只允许这一个线程运行</span><br><span class="line">    print &apos;thread %s is running...&apos; % threading.current_thread().name</span><br><span class="line">    #threading.current_thread().name就是当前线程的名字  在声明线程的时候可以自定义子线程的名字</span><br><span class="line">    n = 0</span><br><span class="line">    while n &lt; 10:</span><br><span class="line">        n = n + 1</span><br><span class="line">        print &apos;%s &gt;&gt;&gt; %s&apos; % (threading.current_thread().name, n)</span><br><span class="line">        #输出当前线程名字  和循环的参数n</span><br><span class="line">    print &apos;thread %s ended.&apos; % threading.current_thread().name</span><br><span class="line">    l.release()</span><br><span class="line">    # 这里是把线程锁解开，可以再运行写一个线程</span><br><span class="line">print &apos;thread %s is running...&apos; % threading.current_thread().name</span><br><span class="line"></span><br><span class="line">#下面的一部分就是threading的核心用法</span><br><span class="line">#包括target name args 之类的 一般我只用targer=你定义的函数名</span><br><span class="line">t = threading.Thread(target=loop, name=&apos;线程名:&apos;)</span><br><span class="line">l = threading.Lock()</span><br><span class="line"># 这里申明一个线程锁</span><br><span class="line">t.start()</span><br><span class="line">#开始</span><br><span class="line">t.join()</span><br><span class="line">#关于join的相关信息我会在后面的代码详说</span><br><span class="line">print &apos;thread %s ended.&apos; % threading.current_thread().name</span><br></pre></td></tr></table></figure><p>使用线程锁后，程序按照一个一个有序执行。其中lock还有Rlock的方法，RLock允许在同一线程中被多次acquire。而Lock却不允许这种情况。否则会出现死循环，程序不知道解哪一把锁。注意：如果使用RLock，那么acquire和release必须成对出现，即调用了n次acquire，必须调用n次的release才能真正释放所占用的锁</p><h4 id="案例三-join-方法的使用"><a href="#案例三-join-方法的使用" class="headerlink" title="案例三 join()方法的使用"></a>案例三 join()方法的使用</h4><p>在多线程中，每个线程自顾执行自己的任务，当最后一个线程运行完毕后再退出，所以这个时候如果你要打印信息的话，会看到打印出来的信息错乱无章，有的时候希望主线程能够等子线程执行完毕后在继续执行，就是用join()方法。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line">t00 = time.time()</span><br><span class="line"># 获取当前时间戳</span><br><span class="line">def cs1():</span><br><span class="line">    time0 = time.time()</span><br><span class="line">    for x in range(9):</span><br><span class="line">        print x + time.time()-time0</span><br><span class="line">        # 计算用了多少时间</span><br><span class="line">        print threading.current_thread().name</span><br><span class="line">        # 打印这个线程名字</span><br><span class="line"></span><br><span class="line">def cs2():</span><br><span class="line">    for x1 in range(6,9):</span><br><span class="line">        print x1</span><br><span class="line">        print threading.current_thread().name</span><br><span class="line"></span><br><span class="line">threads=[]</span><br><span class="line"># 定义一个空的列表</span><br><span class="line">t1 = threading.Thread(target=cs1)</span><br><span class="line">t2 = threading.Thread(target=cs2)</span><br><span class="line">threads.append(t1)</span><br><span class="line">threads.append(t2)</span><br><span class="line"># 把这两个线程的任务加载到这个列表中</span><br><span class="line">for x in threads:</span><br><span class="line">    x.start()</span><br><span class="line">    # 然后执行，这个案例很常用，就是有多个函数要多线程执行的时候用到</span><br><span class="line">    # 如果一个程序有多个函数，但是你只想其中的某一个或者某两个函数多线程，用法一样加入空的列表即可</span><br><span class="line">    x.join()</span><br><span class="line">    #线程堵塞 先运行第一个在运行第二个</span><br><span class="line">#x.join()</span><br><span class="line">#注意你的join放在这里是没有意义的，和不加join一样。线程不堵塞  但是会出现不匀称的表现  并且会修改不同线程中的变量</span><br><span class="line">print &apos;use time.&#123;&#125;&apos;.format(time.time()-t00)</span><br></pre></td></tr></table></figure><p>关于setDaemon()的概念就是：主线程A中，创建了子线程B，并且在主线程A中调用了B.setDaemon(),这个的意思是，把主线程A设置为守护线程，这时候，要是主线程A执行结束了，就不管子线程B是否完成,一并和主线程A退出.这就是setDaemon方法的含义，这基本和join是相反的。此外，还有个要特别注意的：必须在start() 方法调用之前设置，如果不设置为守护线程，程序会被无限挂起。</p><h4 id="案例四-线程锁之信号Semaphore"><a href="#案例四-线程锁之信号Semaphore" class="headerlink" title="案例四 线程锁之信号Semaphore"></a>案例四 线程锁之信号Semaphore</h4><p>类名：BoundedSemaphore。这种锁允许一定数量的线程同时更改数据，它不是互斥锁。比如地铁安检，排队人很多，工作人员只允许一定数量的人进入安检区，其它的人继续排队。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">import threading</span><br><span class="line"></span><br><span class="line">def run(n, se):</span><br><span class="line">    se.acquire()</span><br><span class="line">    print(&quot;run the thread: %s&quot; % n)</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    se.release()</span><br><span class="line"></span><br><span class="line"># 设置允许5个线程同时运行</span><br><span class="line">semaphore = threading.BoundedSemaphore(5)</span><br><span class="line">for i in range(20):</span><br><span class="line">    t = threading.Thread(target=run, args=(i,semaphore))</span><br><span class="line">    t.start()</span><br></pre></td></tr></table></figure><p>运行后，可以看到5个一批的线程被放行。</p><h4 id="案例五-线程锁之事件Event"><a href="#案例五-线程锁之事件Event" class="headerlink" title="案例五 线程锁之事件Event"></a>案例五 线程锁之事件Event</h4><p>事件线程锁的运行机制：<br>全局定义了一个Flag，如果Flag的值为False，那么当程序执行wait()方法时就会阻塞，如果Flag值为True，线程不再阻塞。这种锁，类似交通红绿灯（默认是红灯），它属于在红灯的时候一次性阻挡所有线程，在绿灯的时候，一次性放行所有排队中的线程。<br>事件主要提供了四个方法set()、wait()、clear()和is_set()。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">调用clear()方法会将事件的Flag设置为False。</span><br><span class="line">调用set()方法会将Flag设置为True。</span><br><span class="line">调用wait()方法将等待“红绿灯”信号。</span><br><span class="line">is_set():判断当前是否&quot;绿灯放行&quot;状态</span><br></pre></td></tr></table></figure><p>下面是一个模拟红绿灯，然后汽车通行的例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">#利用Event类模拟红绿灯</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">event = threading.Event()</span><br><span class="line"># 定义一个事件的对象</span><br><span class="line">def lighter():</span><br><span class="line">    green_time = 5       </span><br><span class="line">    # 绿灯时间</span><br><span class="line">    red_time = 5         </span><br><span class="line">    # 红灯时间</span><br><span class="line">    event.set()          </span><br><span class="line">    # 初始设为绿灯</span><br><span class="line">    while True:</span><br><span class="line">        print(&quot;\33[32;0m 绿灯亮...\033[0m&quot;)</span><br><span class="line">        time.sleep(green_time)</span><br><span class="line">        event.clear()</span><br><span class="line">        print(&quot;\33[31;0m 红灯亮...\033[0m&quot;)</span><br><span class="line">        time.sleep(red_time)</span><br><span class="line">        event.set()</span><br><span class="line"></span><br><span class="line">def run(name):</span><br><span class="line">    while True:</span><br><span class="line">        if event.is_set():      </span><br><span class="line">        # 判断当前是否&quot;放行&quot;状态</span><br><span class="line">            print(&quot;一辆[%s] 呼啸开过...&quot; % name)</span><br><span class="line">            time.sleep(1)</span><br><span class="line">        else:</span><br><span class="line">            print(&quot;一辆[%s]开来，看到红灯，无奈的停下了...&quot; % name)</span><br><span class="line">            event.wait()</span><br><span class="line">            print(&quot;[%s] 看到绿灯亮了，瞬间飞起.....&quot; % name)</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    light = threading.Thread(target=lighter,)</span><br><span class="line">    light.start()</span><br><span class="line">        for name in [&apos;奔驰&apos;, &apos;宝马&apos;, &apos;奥迪&apos;]:</span><br><span class="line">        car = threading.Thread(target=run, args=(name,))</span><br><span class="line">        car.start()</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">绿灯亮...</span><br><span class="line">一辆[奔驰] 呼啸开过...</span><br><span class="line">一辆[宝马] 呼啸开过...</span><br><span class="line">一辆[奥迪] 呼啸开过...</span><br><span class="line">一辆[奥迪] 呼啸开过...</span><br><span class="line">......</span><br><span class="line"> 红灯亮...</span><br><span class="line">一辆[宝马]开来，看到红灯，无奈的停下了...</span><br><span class="line">一辆[奥迪]开来，看到红灯，无奈的停下了...</span><br><span class="line">一辆[奔驰]开来，看到红灯，无奈的停下了...</span><br><span class="line">绿灯亮...</span><br><span class="line">[奥迪] 看到绿灯亮了，瞬间飞起.....</span><br><span class="line">一辆[奥迪] 呼啸开过...</span><br><span class="line">[奔驰] 看到绿灯亮了，瞬间飞起.....</span><br><span class="line">一辆[奔驰] 呼啸开过...</span><br><span class="line">[宝马] 看到绿灯亮了，瞬间飞起.....</span><br><span class="line">一辆[宝马] 呼啸开过...</span><br><span class="line">一辆[奥迪] 呼啸开过...</span><br><span class="line">......</span><br></pre></td></tr></table></figure><h4 id="案例六-线程锁之条件Condition"><a href="#案例六-线程锁之条件Condition" class="headerlink" title="案例六 线程锁之条件Condition"></a>案例六 线程锁之条件Condition</h4><p>Condition称作条件锁，依然是通过acquire()/release()加锁解锁。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wait([timeout])方法将使线程进入Condition的等待池等待通知，并释放锁。使用前线程必须已获得锁定，否则将抛出异常。</span><br><span class="line">notify()方法将从等待池挑选一个线程并通知，收到通知的线程将自动调用acquire()尝试获得锁定（进入锁定池），其他线程仍然在等待池中。调用这个方法不会释放锁定。使用前线程必须已获得锁定，否则将抛出异常。</span><br><span class="line">notifyAll()方法将通知等待池中所有的线程，这些线程都将进入锁定池尝试获得锁定。调用这个方法不会释放锁定。使用前线程必须已获得锁定，否则将抛出异常。</span><br></pre></td></tr></table></figure><p>实际案例</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">num = 0</span><br><span class="line">con = threading.Condition()</span><br><span class="line">class Foo(threading.Thread):</span><br><span class="line"></span><br><span class="line">    def __init__(self, name, action):</span><br><span class="line">        super(Foo, self).__init__()</span><br><span class="line">        self.name = name</span><br><span class="line">        self.action = action</span><br><span class="line"></span><br><span class="line">    def run(self):</span><br><span class="line">        global num</span><br><span class="line">        con.acquire()</span><br><span class="line">        print(&quot;%s开始执行...&quot; % self.name)</span><br><span class="line">        while True:</span><br><span class="line">            if self.action == &quot;add&quot;:</span><br><span class="line">                num += 1</span><br><span class="line">            elif self.action == &apos;reduce&apos;:</span><br><span class="line">                num -= 1</span><br><span class="line">            else:</span><br><span class="line">                exit(1)</span><br><span class="line">            print(&quot;num当前为：&quot;, num)</span><br><span class="line">            time.sleep(1)</span><br><span class="line">            if num == 5 or num == 0:</span><br><span class="line">                print(&quot;暂停执行%s！&quot; % self.name)</span><br><span class="line">                con.notify()</span><br><span class="line">                con.wait()</span><br><span class="line">                print(&quot;%s开始执行...&quot; % self.name)</span><br><span class="line">        con.release()</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    a = Foo(&quot;线程A&quot;, &apos;add&apos;)</span><br><span class="line">    b = Foo(&quot;线程B&quot;, &apos;reduce&apos;)</span><br><span class="line">    a.start()</span><br><span class="line">    b.start()</span><br></pre></td></tr></table></figure><p>如果不强制停止，程序会一直执行下去，并循环下面的结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">线程A开始执行...</span><br><span class="line">num当前为： 1</span><br><span class="line">num当前为： 2</span><br><span class="line">num当前为： 3</span><br><span class="line">num当前为： 4</span><br><span class="line">num当前为： 5</span><br><span class="line">暂停执行线程A！</span><br><span class="line">线程B开始执行...</span><br><span class="line">num当前为： 4</span><br><span class="line">num当前为： 3</span><br><span class="line">num当前为： 2</span><br><span class="line">num当前为： 1</span><br><span class="line">num当前为： 0</span><br><span class="line">暂停执行线程B！</span><br><span class="line">线程A开始执行...</span><br><span class="line">num当前为： 1</span><br><span class="line">num当前为： 2</span><br><span class="line">num当前为： 3</span><br><span class="line">num当前为： 4</span><br><span class="line">num当前为： 5</span><br><span class="line">暂停执行线程A！</span><br><span class="line">线程B开始执行...</span><br></pre></td></tr></table></figure><h4 id="案例-七定时器"><a href="#案例-七定时器" class="headerlink" title="案例 七定时器"></a>案例 七定时器</h4><p>定时器Timer类是threading模块中的一个小工具，用于指定n秒后执行某操作。一个简单但很实用的东西。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from threading import Timer</span><br><span class="line">def hello():</span><br><span class="line">    print(&quot;hello, world&quot;)</span><br><span class="line">t = Timer(1, hello)</span><br><span class="line"># 表示1秒后执行hello函数</span><br><span class="line">t.start()</span><br></pre></td></tr></table></figure><h4 id="案例八-通过with语句使用线程锁"><a href="#案例八-通过with语句使用线程锁" class="headerlink" title="案例八 通过with语句使用线程锁"></a>案例八 通过with语句使用线程锁</h4><p>类似于上下文管理器，所有的线程锁都有一个加锁和释放锁的动作，非常类似文件的打开和关闭。在加锁后，如果线程执行过程中出现异常或者错误，没有正常的释放锁，那么其他的线程会造到致命性的影响。通过with上下文管理器，可以确保锁被正常释放。其格式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">with some_lock:</span><br><span class="line">    # 执行任务...</span><br></pre></td></tr></table></figure><p>这相当于：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">some_lock.acquire()</span><br><span class="line">try:</span><br><span class="line">    # 执行任务..</span><br><span class="line">finally:</span><br><span class="line">    some_lock.release()</span><br></pre></td></tr></table></figure><h2 id="threading-的常用属性"><a href="#threading-的常用属性" class="headerlink" title="threading 的常用属性"></a>threading 的常用属性</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">current_thread()    返回当前线程</span><br><span class="line">active_count()    返回当前活跃的线程数，1个主线程+n个子线程</span><br><span class="line">get_ident()    返回当前线程</span><br><span class="line">enumerater()    返回当前活动 Thread 对象列表</span><br><span class="line">main_thread()    返回主 Thread 对象</span><br><span class="line">settrace(func)    为所有线程设置一个 trace 函数</span><br><span class="line">setprofile(func)    为所有线程设置一个 profile 函数</span><br><span class="line">stack_size([size])    返回新创建线程栈大小；或为后续创建的线程设定栈大小为 size</span><br><span class="line">TIMEOUT_MAX    Lock.acquire(), RLock.acquire(), Condition.wait() 允许的最大超时时间</span><br></pre></td></tr></table></figure><h2 id="线程池-threadingpool"><a href="#线程池-threadingpool" class="headerlink" title="线程池 threadingpool"></a>线程池 threadingpool</h2><p>在使用多线程处理任务时也不是线程越多越好。因为在切换线程的时候，需要切换上下文环境，线程很多的时候，依然会造成CPU的大量开销。为解决这个问题，线程池的概念被提出来了。</p><p>预先创建好一个数量较为优化的线程组，在需要的时候立刻能够使用，就形成了线程池。在Python中，没有内置的较好的线程池模块，需要自己实现或使用第三方模块。<br>需要注意的是，线程池的整体构造需要自己精心设计，比如某个函数定义存在多少个线程，某个函数定义什么时候运行这个线程，某个函数定义去获取线程获取任务，某个线程设置线程守护(线程锁之类的)，等等…<br>在网上找了几个案例，供大家学习参考。</p><p>下面是一个简单的线程池：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import queue</span><br><span class="line">import time</span><br><span class="line">import threading</span><br><span class="line">class MyThreadPool:</span><br><span class="line">    def __init__(self, maxsize=5):</span><br><span class="line">        self.maxsize = maxsize</span><br><span class="line">        self._pool = queue.Queue(maxsize)   # 使用queue队列，创建一个线程池</span><br><span class="line">        for _ in range(maxsize):</span><br><span class="line">            self._pool.put(threading.Thread)</span><br><span class="line">    def get_thread(self):</span><br><span class="line">        return self._pool.get()</span><br><span class="line"></span><br><span class="line">    def add_thread(self):</span><br><span class="line">        self._pool.put(threading.Thread)</span><br><span class="line"></span><br><span class="line">def run(i, pool):</span><br><span class="line">    print(&apos;执行任务&apos;, i)</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    pool.add_thread()   # 执行完毕后，再向线程池中添加一个线程类</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    pool = MyThreadPool(5)  # 设定线程池中最多只能有5个线程类</span><br><span class="line">    for i in range(20):</span><br><span class="line">        t = pool.get_thread()   # 每个t都是一个线程类</span><br><span class="line">        obj = t(target=run, args=(i, pool)) # 这里的obj才是正真的线程对象</span><br><span class="line">        obj.start()</span><br><span class="line">    print(&quot;活动的子线程数： &quot;, threading.active_count()-1)</span><br></pre></td></tr></table></figure><p>分析一下上面的代码：</p><ol><li>实例化一个MyThreadPool的对象，在其内部建立了一个最多包含5个元素的阻塞队列，并一次性将5个Thread类型添加进去。</li><li>循环100次，每次从pool中获取一个thread类，利用该类，传递参数，实例化线程对象。</li><li>在run()方法中，每当任务完成后，又为pool添加一个thread类，保持队列中始终有5个thread类。</li><li>一定要分清楚，代码里各个变量表示的内容。t表示的是一个线程类，也就是threading.Thread，而obj才是正真的线程对象。</li></ol><p>上面的例子是把线程类当做元素添加到队列内，从而实现的线程池。这种方法比较糙，每个线程使用后就被抛弃，并且一开始就将线程开到满，因此性能较差。下面是一个相对好一点的例子，在这个例子中，队列里存放的不再是线程类，而是任务，线程池也不是一开始就直接开辟所有线程，而是根据需要，逐步建立，直至池满。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">一个基于thread和queue的线程池，以任务为队列元素，动态创建线程，重复利用线程，</span><br><span class="line">通过close和terminate方法关闭线程池。</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">import queue</span><br><span class="line">import threading</span><br><span class="line">import contextlib</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"># 创建空对象,用于停止线程</span><br><span class="line">StopEvent = object()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def callback(status, result):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    根据需要进行的回调函数，默认不执行。</span><br><span class="line">    :param status: action函数的执行状态</span><br><span class="line">    :param result: action函数的返回值</span><br><span class="line">    :return:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def action(thread_name, arg):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    真实的任务定义在这个函数里</span><br><span class="line">    :param thread_name: 执行该方法的线程名</span><br><span class="line">    :param arg: 该函数需要的参数</span><br><span class="line">    :return:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 模拟该函数执行了0.1秒</span><br><span class="line">    time.sleep(0.1)</span><br><span class="line">    print(&quot;第%s个任务调用了线程 %s，并打印了这条信息！&quot; % (arg+1, thread_name))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class ThreadPool:</span><br><span class="line"></span><br><span class="line">    def __init__(self, max_num, max_task_num=None):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        初始化线程池</span><br><span class="line">        :param max_num: 线程池最大线程数量</span><br><span class="line">        :param max_task_num: 任务队列长度</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 如果提供了最大任务数的参数，则将队列的最大元素个数设置为这个值。</span><br><span class="line">        if max_task_num:</span><br><span class="line">            self.q = queue.Queue(max_task_num)</span><br><span class="line">        # 默认队列可接受无限多个的任务</span><br><span class="line">        else:</span><br><span class="line">            self.q = queue.Queue()</span><br><span class="line">        # 设置线程池最多可实例化的线程数</span><br><span class="line">        self.max_num = max_num</span><br><span class="line">        # 任务取消标识</span><br><span class="line">        self.cancel = False</span><br><span class="line">        # 任务中断标识</span><br><span class="line">        self.terminal = False</span><br><span class="line">        # 已实例化的线程列表</span><br><span class="line">        self.generate_list = []</span><br><span class="line">        # 处于空闲状态的线程列表</span><br><span class="line">        self.free_list = []</span><br><span class="line"></span><br><span class="line">    def put(self, func, args, callback=None):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        往任务队列里放入一个任务</span><br><span class="line">        :param func: 任务函数</span><br><span class="line">        :param args: 任务函数所需参数</span><br><span class="line">        :param callback: 任务执行失败或成功后执行的回调函数，回调函数有两个参数</span><br><span class="line">        1、任务函数执行状态；2、任务函数返回值（默认为None，即：不执行回调函数）</span><br><span class="line">        :return: 如果线程池已经终止，则返回True否则None</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 先判断标识，看看任务是否取消了</span><br><span class="line">        if self.cancel:</span><br><span class="line">            return</span><br><span class="line">        # 如果没有空闲的线程，并且已创建的线程的数量小于预定义的最大线程数，则创建新线程。</span><br><span class="line">        if len(self.free_list) == 0 and len(self.generate_list) &lt; self.max_num:</span><br><span class="line">            self.generate_thread()</span><br><span class="line">        # 构造任务参数元组，分别是调用的函数，该函数的参数，回调函数。</span><br><span class="line">        w = (func, args, callback,)</span><br><span class="line">        # 将任务放入队列</span><br><span class="line">        self.q.put(w)</span><br><span class="line"></span><br><span class="line">    def generate_thread(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        创建一个线程</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 每个线程都执行call方法</span><br><span class="line">        t = threading.Thread(target=self.call)</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line">    def call(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        循环去获取任务函数并执行任务函数。在正常情况下，每个线程都保存生存状态，  直到获取线程终止的flag。</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 获取当前线程的名字</span><br><span class="line">        current_thread = threading.currentThread().getName()</span><br><span class="line">        # 将当前线程的名字加入已实例化的线程列表中</span><br><span class="line">        self.generate_list.append(current_thread)</span><br><span class="line">        # 从任务队列中获取一个任务</span><br><span class="line">        event = self.q.get()</span><br><span class="line">        # 让获取的任务不是终止线程的标识对象时</span><br><span class="line">        while event != StopEvent:</span><br><span class="line">            # 解析任务中封装的三个参数</span><br><span class="line">            func, arguments, callback = event</span><br><span class="line">            # 抓取异常，防止线程因为异常退出</span><br><span class="line">            try:</span><br><span class="line">                # 正常执行任务函数</span><br><span class="line">                result = func(current_thread, *arguments)</span><br><span class="line">                success = True</span><br><span class="line">            except Exception as e:</span><br><span class="line">                # 当任务执行过程中弹出异常</span><br><span class="line">                result = None</span><br><span class="line">                success = False</span><br><span class="line">            # 如果有指定的回调函数</span><br><span class="line">            if callback is not None:</span><br><span class="line">                # 执行回调函数，并抓取异常</span><br><span class="line">                try:</span><br><span class="line">                    callback(success, result)</span><br><span class="line">                except Exception as e:</span><br><span class="line">                    pass</span><br><span class="line">            # 当某个线程正常执行完一个任务时，先执行worker_state方法</span><br><span class="line">            with self.worker_state(self.free_list, current_thread):</span><br><span class="line">                # 如果强制关闭线程的flag开启，则传入一个StopEvent元素</span><br><span class="line">                if self.terminal:</span><br><span class="line">                    event = StopEvent</span><br><span class="line">                # 否则获取一个正常的任务，并回调worker_state方法的yield语句</span><br><span class="line">                else:</span><br><span class="line">                    # 从这里开始又是一个正常的任务循环</span><br><span class="line">                    event = self.q.get()</span><br><span class="line">        else:</span><br><span class="line">            # 一旦发现任务是个终止线程的标识元素，将线程从已创建线程列表中删除</span><br><span class="line">            self.generate_list.remove(current_thread)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def close(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        执行完所有的任务后，让所有线程都停止的方法</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 设置flag</span><br><span class="line">        self.cancel = True</span><br><span class="line">        # 计算已创建线程列表中线程的个数，</span><br><span class="line">        # 然后往任务队列里推送相同数量的终止线程的标识元素</span><br><span class="line">        full_size = len(self.generate_list)</span><br><span class="line">        while full_size:</span><br><span class="line">            self.q.put(StopEvent)</span><br><span class="line">            full_size -= 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def terminate(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        在任务执行过程中，终止线程，提前退出。</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.terminal = True</span><br><span class="line">        # 强制性的停止线程</span><br><span class="line">        while self.generate_list:</span><br><span class="line">            self.q.put(StopEvent)</span><br><span class="line"></span><br><span class="line"># 该装饰器用于上下文管理</span><br><span class="line">    @contextlib.contextmanager</span><br><span class="line">    def worker_state(self, state_list, worker_thread):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        用于记录空闲的线程，或从空闲列表中取出线程处理任务</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 将当前线程，添加到空闲线程列表中</span><br><span class="line">        state_list.append(worker_thread)</span><br><span class="line">        # 捕获异常</span><br><span class="line">        try:</span><br><span class="line">            # 在此等待</span><br><span class="line">            yield</span><br><span class="line">        finally:</span><br><span class="line">            # 将线程从空闲列表中移除</span><br><span class="line">            state_list.remove(worker_thread)</span><br><span class="line"></span><br><span class="line"># 调用方式</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    # 创建一个最多包含5个线程的线程池</span><br><span class="line">    pool = ThreadPool(5)</span><br><span class="line">    # 创建100个任务，让线程池进行处理</span><br><span class="line">    for i in range(100):</span><br><span class="line">        pool.put(action, (i,), callback)</span><br><span class="line">    # 等待一定时间，让线程执行任务</span><br><span class="line">    time.sleep(3)</span><br><span class="line">    print(&quot;-&quot; * 50)</span><br><span class="line">    print(&quot;\033[32;0m任务停止之前线程池中有%s个线程，空闲的线程有%s个！\033[0m&quot;</span><br><span class="line">          % (len(pool.generate_list), len(pool.free_list)))</span><br><span class="line">    # 正常关闭线程池</span><br><span class="line">    pool.close()</span><br><span class="line">    print(&quot;任务执行完毕，正常退出！&quot;)</span><br><span class="line">    # 强制关闭线程池</span><br><span class="line">    # pool.terminate()</span><br><span class="line">    # print(&quot;强制停止任务！&quot;)</span><br></pre></td></tr></table></figure><p>关于线程池其实涉及到工程设计，需要自己很熟练的运行面向对象程序设计。</p><h2 id="生产者和消费者模式"><a href="#生产者和消费者模式" class="headerlink" title="生产者和消费者模式"></a>生产者和消费者模式</h2><p>生产者就是生成任务，消费者就是解决处理任务。比如在一个程序中，代码是按照重上往下执行，有的时候做等待的时间完全可以用来做任务处理或者做别的事情，为了节省时间，可以借助多线程的功能（自顾自完成自己线程任务）加上Queue队列特性（管道模式。里面存储数据，然后提供给线程处理）完成生产者和消费者模式。关于Queue的用法参考我之前的文章。</p><h4 id="案例一"><a href="#案例一" class="headerlink" title="案例一"></a>案例一</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">import Queue</span><br><span class="line">import time</span><br><span class="line">import threading</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line">q = Queue.Queue(10)</span><br><span class="line">def get(i):</span><br><span class="line">    # 这个函数用来生产任务，接受参数i，也可以不传入参数</span><br><span class="line">    while 1:</span><br><span class="line">        time.sleep(2)</span><br><span class="line">        # 这里可以做一些动作，比如过去网站的网址之类的</span><br><span class="line">        q.put(i)</span><br><span class="line">        # 然后把得到的数据放在消息队列中</span><br><span class="line">def fun(o):</span><br><span class="line">    # 这个函数用来处理任务，必须要接受参数</span><br><span class="line">    q.get(o)</span><br><span class="line">    # 得到获取接受来的参数</span><br><span class="line">    print o*10</span><br><span class="line">    # 然后对获取的参数作处理，我这里仅仅打印数据乘以10</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for i in range(100):</span><br><span class="line">    # 生产任务启动，有100个任务量要产生</span><br><span class="line">    t1 = threading.Thread(target=get, args=(i,))</span><br><span class="line">    t1.start()</span><br><span class="line">for o in range(100):</span><br><span class="line">    # 处理任务启动</span><br><span class="line">    t = threading.Thread(target=fun, args=(o,))</span><br><span class="line">    t.start()</span><br></pre></td></tr></table></figure><p>上面这个代码主要是针对骨架进行拆分解说，一般的生产者消费者模式都是这种构架，下面用一个更加清晰的案例来帮助理解。</p><h4 id="案例二"><a href="#案例二" class="headerlink" title="案例二"></a>案例二</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line">import time</span><br><span class="line">import queue</span><br><span class="line">import threading</span><br><span class="line"></span><br><span class="line">q = queue.Queue(10)     # 生成一个队列，用来保存“包子”，最大数量为10</span><br><span class="line"></span><br><span class="line">def productor(i):</span><br><span class="line">    # 厨师不停地每2秒做一个包子</span><br><span class="line">    while True:</span><br><span class="line">        q.put(&quot;厨师 %s 做的包子！&quot; % i)</span><br><span class="line">        time.sleep(2)</span><br><span class="line"></span><br><span class="line">def consumer(j):</span><br><span class="line">    # 顾客不停地每秒吃一个包子</span><br><span class="line">    while True:</span><br><span class="line">        print(&quot;顾客 %s 吃了一个 %s&quot;%(j,q.get()))</span><br><span class="line">        time.sleep(1)</span><br><span class="line"></span><br><span class="line"># 实例化了3个生产者（厨师）</span><br><span class="line">for i in range(3):</span><br><span class="line">    t = threading.Thread(target=productor, args=(i,))</span><br><span class="line">    t.start()</span><br><span class="line"># 实例化了10个消费者（顾客）</span><br><span class="line">for j in range(10):</span><br><span class="line">    v = threading.Thread(target=consumer, args=(j,))</span><br><span class="line">    v.start()</span><br></pre></td></tr></table></figure><h4 id="案例三"><a href="#案例三" class="headerlink" title="案例三"></a>案例三</h4><p>使用生产者消费者模式实现代理IP扫描并且同步扫描代理IP是否可用，如果不适用生产者消费者模式的话，首先要获取代理IP，然后把获取到的IP放在一个列表，然后在扫描列表的IP，扫描过程为—-&gt;获取IP—-&gt;IP保存—-&gt;IP存活扫描。过程是单向的，也就是说没办法同步一边获取IP然后马上验证。</p><p>下面的代码是用生产者消费者模式实现代理IP的获取与存活扫描。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"># @Time    : 2018/5/3 0003 10:52</span><br><span class="line"># @Author  : Sun</span><br><span class="line"># @Blog    : wandouduoduo</span><br><span class="line"># @File    : 生产者消费者.py</span><br><span class="line"># @Software: PyCharm</span><br><span class="line">import sys</span><br><span class="line">import Queue</span><br><span class="line">import time</span><br><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import threading</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line">q = Queue.Queue(10)</span><br><span class="line">headers=&#123;&apos;User-Agent&apos;:&apos;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36&apos;&#125;</span><br><span class="line">def get_ip(page):</span><br><span class="line">    url1=&apos;http://www.66ip.cn/mo.php?sxb=&amp;tqsl=30&amp;port=&amp;export=&amp;ktip=&amp;sxa=&amp;submit=%CC%E1++%C8%A1&amp;textarea=&apos;</span><br><span class="line">    url2=&apos;http://www.xicidaili.com/nn/%s&apos;</span><br><span class="line">    for i in range(1,page):</span><br><span class="line">        url1_1=url1+str(i)</span><br><span class="line">        url2_2=url2+str(i)</span><br><span class="line">        try:</span><br><span class="line">            r = requests.get(url=url1_1,headers=headers,timeout=5)</span><br><span class="line">            #time.sleep(20)</span><br><span class="line">            rr = re.findall(&apos;        (.*?)&lt;br /&gt;&apos;,r.content)</span><br><span class="line">            for x in rr:</span><br><span class="line">                q.put(x)</span><br><span class="line">            time.sleep(20)</span><br><span class="line">        except Exception,e:</span><br><span class="line">            print e</span><br><span class="line">        try:</span><br><span class="line">            time.sleep(30)</span><br><span class="line">            r = requests.get(url=url2_2,headers=headers,timeout=5)</span><br><span class="line">            rr = re.findall(&apos;/&gt;&lt;/td&gt;(.*?)&lt;a href&apos;,r.content,re.S)</span><br><span class="line">            for x in rr:</span><br><span class="line">                x1 = x.replace(&apos;\n&apos;,&apos;&apos;).replace(&apos;&lt;td&gt;&apos;,&apos;&apos;).replace(&quot;&lt;/td&gt;&quot;,&apos;:&apos;).replace(&apos;      &apos;,&apos;&apos;).replace(&apos;:  &apos;,&apos;&apos;)</span><br><span class="line">                print x1</span><br><span class="line">                q.put(x1)</span><br><span class="line">            time.sleep(20)</span><br><span class="line">        except Exception,e:</span><br><span class="line">            print e</span><br><span class="line">def scan_ip():</span><br><span class="line">    while 1:</span><br><span class="line">        proxies=&#123;&#125;</span><br><span class="line">        ip = q.get()</span><br><span class="line">        proxies[&apos;http&apos;] = str(ip)</span><br><span class="line">        try:</span><br><span class="line">            req2 = requests.get(url=&apos;http://blog.csdn.net/lzy98&apos;, proxies=proxies, headers=headers, timeout=5)</span><br><span class="line">            if &apos;One puls&apos; in req2.content:</span><br><span class="line">                print str(proxies[&apos;http&apos;]) + unicode(&apos;该代理可正常访问网页...&apos;,&apos;utf-8&apos;)</span><br><span class="line">            else:</span><br><span class="line">                print unicode(&apos;  该代理无法访问网页,继续验证下一代理...&apos;, &apos;utf-8&apos;)</span><br><span class="line">        except :</span><br><span class="line">            print str(proxies[&apos;http&apos;])+unicode(&apos;  无法连接到代理服务器&apos;,&apos;utf-8&apos;)</span><br><span class="line"></span><br><span class="line">for i in range(2):</span><br><span class="line">    # 这里是要开2个任务量，就是2个线程</span><br><span class="line">    t = threading.Thread(target=get_ip,args=(10,))</span><br><span class="line">    # 传入的参数是10，回归到get_ip函数，发现传入的参数就是要扫描提供代理网站的页数</span><br><span class="line">    t.start()</span><br><span class="line"></span><br><span class="line">t1 = threading.Thread(target=scan_ip)</span><br><span class="line">t1.start()</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">177.132.249.127:20183无法连接到代理服务器</span><br><span class="line">39.104.82.143:8080无法连接到代理服务器</span><br><span class="line">123.231.203.139:8080无法连接到代理服务器</span><br><span class="line">180.250.43.66:8080该代理可正常访问网页...</span><br><span class="line">189.127.238.65:8080无法连接到代理服务器</span><br><span class="line">107.178.3.105:8181该代理可正常访问网页...</span><br><span class="line">95.31.80.67:53281该代理可正常访问网页...</span><br><span class="line">79.174.160.167:8080无法连接到代理服务器</span><br><span class="line">223.242.94.36:31588无法连接到代理服务器</span><br><span class="line">该代理无法访问网页,继续验证下一代理...</span><br><span class="line">5.188.155.243:8080无法连接到代理服务器</span><br><span class="line">180.183.17.151:8080该代理可正常访问网页...</span><br><span class="line">113.90.247.99:8118该代理可正常访问网页...</span><br><span class="line">180.119.65.184:3128无法连接到代理服务器</span><br></pre></td></tr></table></figure><h2 id="Python3中的线程池方法"><a href="#Python3中的线程池方法" class="headerlink" title="Python3中的线程池方法"></a>Python3中的线程池方法</h2><p>虽然在2版本中并没有线程池，但是在3版本中有相关线程池的使用方法。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from concurrent.futures import ThreadPoolExecutor</span><br><span class="line">executor = ThreadPoolExecutor(3)</span><br><span class="line"># 实例化线程池对象，开启3个线程</span><br><span class="line">def fun(a,b):</span><br><span class="line">    print (a,b)</span><br><span class="line">    returl a**b</span><br><span class="line"># 定义一个函数</span><br><span class="line">executor.submit(fun,2,5) # y运行结果：2,5</span><br><span class="line"># 这是调用与开启线程</span><br><span class="line">result=executor.submit(fun,5,2)</span><br><span class="line">print result # 运行结果: 25</span><br><span class="line"># 如果要有很多参数传入进行运算</span><br><span class="line">executor.map(fun,[1,2,3,4],[2,3,5,6])</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;线程是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务，多线程就是在一个进程中的多个线程，如果使用多线程默认开启一个主线程，按照程序需求自动开启多个线程(也可以自己定义线程数)。&lt;/p&gt;
    
    </summary>
    
      <category term="编程积累" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/"/>
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/Python/"/>
    
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>glusterfs常用命令</title>
    <link href="https://wandouduoduo.netlify.com/articles/4f1d1494.html"/>
    <id>https://wandouduoduo.netlify.com/articles/4f1d1494.html</id>
    <published>2019-11-26T08:03:27.000Z</published>
    <updated>2019-11-26T09:20:44.545Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>glusterfs作为分布式存储，优点和安装这里就不再赘述了，看博客中教程。本文主要是介绍glusterfs常用命令和案例。</p><a id="more"></a><h2 id="命令详解"><a href="#命令详解" class="headerlink" title="命令详解"></a>命令详解</h2><h4 id="服务器节点"><a href="#服务器节点" class="headerlink" title="服务器节点"></a>服务器节点</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看所有节点信息，显示时不包括本节点</span></span><br><span class="line">gluster peer status </span><br><span class="line"><span class="comment">#添加节点</span></span><br><span class="line">gluster peer probe NODE-NAME </span><br><span class="line"><span class="comment">#移除节点，需要提前将该节点上的brick移除</span></span><br><span class="line">gluster peer detach NODE-NAME</span><br></pre></td></tr></table></figure><h4 id="glusterd服务"><a href="#glusterd服务" class="headerlink" title="glusterd服务"></a>glusterd服务</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#启动glusterd服务</span></span><br><span class="line">/etc/init.d/glusterd start </span><br><span class="line"><span class="comment">#关闭glusterd服务</span></span><br><span class="line">/etc/init.d/glusterd stop </span><br><span class="line"><span class="comment">#查看glusterd服务</span></span><br><span class="line">/etc/init.d/glusterd status</span><br></pre></td></tr></table></figure><h4 id="卷管理"><a href="#卷管理" class="headerlink" title="卷管理"></a>卷管理</h4><h5 id="创建卷"><a href="#创建卷" class="headerlink" title="创建卷"></a>创建卷</h5><p><strong>复制卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法： gluster volume create NEW-VOLNAME [replica COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK</span><br><span class="line"></span><br><span class="line">示例1：gluster volume create <span class="built_in">test</span>-volume replica 2 transport tcp server1:/exp1/brick server2:/exp2/brick</span><br></pre></td></tr></table></figure><p><strong>条带卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法：gluster volume create NEW-VOLNAME [stripe COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK...</span><br><span class="line"></span><br><span class="line">示例：gluster volume create <span class="built_in">test</span>-volume stripe 2 transport tcp server1:/exp1/brick server2:/exp2/brick</span><br></pre></td></tr></table></figure><p><strong>分布式卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">语法： gluster volume create NEW-VOLNAME [transport tcp | rdma | tcp, rdma] NEW-BRICK</span><br><span class="line"></span><br><span class="line">示例1：gluster volume create <span class="built_in">test</span>-volume server1:/exp1/brick server2:/exp2/brick</span><br><span class="line">示例2：gluster volume create <span class="built_in">test</span>-volume transport rdma server1:/exp1/brick server2:/exp2/brick server3:/exp3/brick server4:/exp4/brick</span><br></pre></td></tr></table></figure><p><strong>分布式复制卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">语法： gluster volume create NEW-VOLNAME [replica COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK...</span><br><span class="line">示例： gluster volume create <span class="built_in">test</span>-volume replica 2 transport tcp server1:/exp1/brick server2:/exp2/brick server3:/exp3/brick server4:/exp4/brick</span><br></pre></td></tr></table></figure><p> <strong>分布式条带卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法：gluster volume create NEW-VOLNAME [stripe COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK...</span><br><span class="line"></span><br><span class="line">示例：gluster volume create <span class="built_in">test</span>-volume stripe 2 transport tcp server1:/exp1/brick server2:/exp2/brick server3:/exp3/brick server4:/exp4/brick</span><br></pre></td></tr></table></figure><p><strong>条带复制卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法：gluster volume create NEW-VOLNAME [stripe COUNT] [replica COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK...</span><br><span class="line"></span><br><span class="line">示例：gluster volume create <span class="built_in">test</span>-volume stripe 2 replica 2 transport tcp server1:/exp1/brick server2:/exp2/brick server3:/exp3/brick server4:/exp4/brick</span><br></pre></td></tr></table></figure><h5 id="启动卷"><a href="#启动卷" class="headerlink" title="启动卷"></a>启动卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume start <span class="built_in">test</span>-volume</span><br></pre></td></tr></table></figure><h5 id="停止卷"><a href="#停止卷" class="headerlink" title="停止卷"></a>停止卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume stop <span class="built_in">test</span>-volume</span><br></pre></td></tr></table></figure><p> <strong>删除卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先停止卷后才能删除</span></span><br><span class="line">gluster volume delete <span class="built_in">test</span>-volume</span><br></pre></td></tr></table></figure><h5 id="查看卷"><a href="#查看卷" class="headerlink" title="查看卷"></a>查看卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#列出集群中的所有卷</span></span><br><span class="line">gluster volume list </span><br><span class="line"><span class="comment">#查看集群中的卷信息</span></span><br><span class="line">gluster volume info [all] </span><br><span class="line"><span class="comment">#查看集群中的卷状态</span></span><br><span class="line">gluster volume status [all] </span><br><span class="line"></span><br><span class="line">gluster volume status [detail| clients | mem | inode | fd]</span><br></pre></td></tr></table></figure><h5 id="配置卷"><a href="#配置卷" class="headerlink" title="配置卷"></a>配置卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume <span class="built_in">set</span> &lt;VOLNAME&gt; &lt;OPTION&gt; &lt;PARAMETER&gt;</span><br></pre></td></tr></table></figure><h5 id="扩展卷"><a href="#扩展卷" class="headerlink" title="扩展卷"></a>扩展卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gluster volume add-brick &lt;VOLNAME&gt; &lt;NEW-BRICK&gt;</span><br><span class="line"><span class="comment">#注意，如果是复制卷或者条带卷，则每次添加的Brick数必须是replica或者stripe的整数倍。</span></span><br></pre></td></tr></table></figure><h5 id="收缩卷"><a href="#收缩卷" class="headerlink" title="收缩卷"></a>收缩卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先将数据迁移到其它可用的Brick，迁移结束后才将该Brick移除：</span></span><br><span class="line">gluster volume remove-brick start</span><br><span class="line"><span class="comment">#在执行了start之后，可以使用status命令查看移除进度：</span></span><br><span class="line">gluster volume remove-brick status</span><br><span class="line"><span class="comment">#不进行数据迁移，直接删除该Brick：</span></span><br><span class="line">gluster volume remove-brick commit</span><br><span class="line"><span class="comment">#注意，如果是复制卷或者条带卷，则每次移除的Brick数必须是replica或者stripe的整数倍。</span></span><br></pre></td></tr></table></figure><h5 id="迁移卷"><a href="#迁移卷" class="headerlink" title="迁移卷"></a>迁移卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用start命令开始进行迁移：</span></span><br><span class="line">gluster volume replace-brick start</span><br><span class="line"><span class="comment">#在数据迁移过程中，可以使用pause命令暂停迁移：</span></span><br><span class="line">gluster volume replace-brick pause</span><br><span class="line"><span class="comment">#在数据迁移过程中，可以使用abort命令终止迁移：</span></span><br><span class="line">gluster volume replace-brick abort</span><br><span class="line"><span class="comment">#在数据迁移过程中，可以使用status命令查看迁移进度：</span></span><br><span class="line">gluster volume replace-brick status</span><br><span class="line"><span class="comment">#在数据迁移结束后，执行commit命令来进行Brick替换：</span></span><br><span class="line">gluster volume replace-brick commit</span><br></pre></td></tr></table></figure><h5 id="重新均衡卷"><a href="#重新均衡卷" class="headerlink" title="重新均衡卷"></a>重新均衡卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#不迁移数据：</span></span><br><span class="line">gluster volume rebalance lay-outstart</span><br><span class="line">gluster volume rebalance start</span><br><span class="line">gluster volume rebalance startforce</span><br><span class="line">gluster volume rebalance status</span><br><span class="line">gluster volume rebalance stop</span><br></pre></td></tr></table></figure><h4 id="Brick管理"><a href="#Brick管理" class="headerlink" title="Brick管理"></a>Brick管理</h4><h5 id="添加Brick"><a href="#添加Brick" class="headerlink" title="添加Brick"></a>添加Brick</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume add-brick <span class="built_in">test</span>-volume 192.168.1.&#123;151,152&#125;:/mnt/brick2</span><br></pre></td></tr></table></figure><h5 id="删除Brick"><a href="#删除Brick" class="headerlink" title="删除Brick"></a>删除Brick</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#若是副本卷，则移除的Bricks数是replica的整数倍</span></span><br><span class="line">gluster volume remove-brick <span class="built_in">test</span>-volume 192.168.1.&#123;151,152&#125;:/mnt/brick2 start</span><br><span class="line"><span class="comment">#在执行开始移除之后，可以使用status命令进行移除状态查看。</span></span><br><span class="line">gluster volume remove-brick <span class="built_in">test</span>-volume 192.168.1.&#123;151,152&#125;:/mnt/brick2 status</span><br><span class="line"><span class="comment">#使用commit命令执行Brick移除，则不会进行数据迁移而直接删除Brick，符合不需要数据迁移的用户需求。</span></span><br><span class="line">gluster volume remove-brick <span class="built_in">test</span>-volume 192.168.1.&#123;151,152&#125;:/mnt/brick2 commit</span><br></pre></td></tr></table></figure><h5 id="替换Brick"><a href="#替换Brick" class="headerlink" title="替换Brick"></a>替换Brick</h5><p>任务：把192.168.1.151:/mnt/brick0 替换为192.168.1.151:/mnt/brick2</p><p><strong>开始替换</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">gluster volume replace-brick <span class="built_in">test</span>-volume 192.168.1.:/mnt/brick0 ..152:/mnt/brick2 start</span><br><span class="line">异常信息：volume replace-brick: failed: /data/share2 or a prefix of it is already part of a volume</span><br><span class="line"></span><br><span class="line"><span class="comment">#说明 /mnt/brick2 曾经是一个Brick。具体解决方法</span></span><br><span class="line">rm -rf /mnt/brick2/.glusterfs</span><br><span class="line"></span><br><span class="line">setfattr -x trusted.glusterfs.volume-id /mnt/brick2</span><br><span class="line">setfattr -x trusted.gfid /mnt/brick2</span><br><span class="line"></span><br><span class="line"><span class="comment">#如上，执行replcace-brick卷替换启动命令，使用start启动命令后，开始将原始Brick的数据迁移到即将需要替换的Brick上。</span></span><br></pre></td></tr></table></figure><p><strong>查看是否替换完</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume replace-brick <span class="built_in">test</span>-volume 192.168.1.151:/mnt/brick0 ..152:/mnt/brick2 status</span><br></pre></td></tr></table></figure><p><strong>在数据迁移的过程中，可以执行abort命令终止Brick替换。</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume replace-brick <span class="built_in">test</span>-volume 192.168.1.151:/mnt/brick0 ..152:/mnt/brick2 abort</span><br></pre></td></tr></table></figure><p><strong>在数据迁移结束之后，执行commit命令结束任务，则进行Brick替换。使用volume info命令可以查看到Brick已经被替换</strong>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gluster volume replace-brick <span class="built_in">test</span>-volume 192.168.1.151:/mnt/brick0 .152:/mnt/brick2 commit</span><br><span class="line"><span class="comment">#此时我们再往 /sf/data/vs/gfs/rep2上添加数据的话，数据会同步到 192.168.1.152:/mnt/brick0和192.168.1.152:/mnt/brick2上。而不会同步到192.168.1.151:/mnt/brick0 上。</span></span><br></pre></td></tr></table></figure><h4 id="文件系统扩展属性"><a href="#文件系统扩展属性" class="headerlink" title="文件系统扩展属性"></a>文件系统扩展属性</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获取文件扩展属性</span></span><br><span class="line">getfattr -d -m . -e hex filename</span><br><span class="line">getfattr -d -m <span class="string">"trusted.afr.*"</span> -e hex filename</span><br></pre></td></tr></table></figure><h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><h4 id="增加节点"><a href="#增加节点" class="headerlink" title="增加节点"></a>增加节点</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#hosts文件中添加对应服务器解析</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"ip   gs3"</span> &gt;&gt;/etc/hosts</span><br><span class="line"><span class="comment">#查看节点信息</span></span><br><span class="line">gluster peer status</span><br><span class="line"><span class="comment">#添加节点</span></span><br><span class="line">gluster peer probe gs3</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据卷添加新的brick</span></span><br><span class="line">gluster volume add-brick 卷名 replica 添加后的副本个数 brick所在的IP:brick所在的地址 force</span><br><span class="line">最后的force是因为，gluster集群推荐不要和系统公用磁盘，如果公用就需添加。</span><br><span class="line"></span><br><span class="line">例如：</span><br><span class="line">mkdir -p /brick/gv0</span><br><span class="line">gluster volume add-brick gv0 replica 2 gs2:/brick/gv0  force</span><br></pre></td></tr></table></figure><h4 id="删除节点"><a href="#删除节点" class="headerlink" title="删除节点"></a>删除节点</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看节点信息</span></span><br><span class="line">gluster peer status</span><br><span class="line"><span class="comment"># 删除操作,注意删除节点必须先删除brick</span></span><br><span class="line">gluster peer detach gs3</span><br></pre></td></tr></table></figure><p><img src="/articles/4f1d1494/1.png" alt></p><p>上面报错，是因为没有删除brick导致。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#数据卷移除旧的brick</span></span><br><span class="line">gluster volume remove-brick 卷名 replica 移除后的副本个数 brick所在的IP:brick所在的地址</span><br><span class="line"></span><br><span class="line">例如：移除gs3上的static卷</span><br><span class="line">gluster volume remove-brick static gs3:/data/volume/brick/static</span><br></pre></td></tr></table></figure><p><img src="/articles/4f1d1494/2.png" alt></p><p>执行移除报错，是因为先删除副本。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gluster volume remove-brick gv0 replica 2  gs3:/brick/gv0 force</span><br><span class="line"><span class="comment">#注意副本数为删除后还剩的个数</span></span><br><span class="line"><span class="comment">#然后再移除节点</span></span><br><span class="line">gluster peer detach gs3</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;glusterfs作为分布式存储，优点和安装这里就不再赘述了，看博客中教程。本文主要是介绍glusterfs常用命令和案例。&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.netlify.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="GlusterFS" scheme="https://wandouduoduo.netlify.com/tags/GlusterFS/"/>
    
  </entry>
  
  <entry>
    <title>GlusterFS分布式存储集群之使用</title>
    <link href="https://wandouduoduo.netlify.com/articles/35de9bb2.html"/>
    <id>https://wandouduoduo.netlify.com/articles/35de9bb2.html</id>
    <published>2019-11-05T03:56:15.000Z</published>
    <updated>2019-11-05T06:32:39.546Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Glusterfs逻辑卷创建与使用"><a href="#Glusterfs逻辑卷创建与使用" class="headerlink" title="Glusterfs逻辑卷创建与使用"></a>Glusterfs逻辑卷创建与使用</h1><p>volume是brick的组合，并且大部分glusterfs文件系统的操作都在volume上。</p><p>glusterfs支持4种基本卷，并可以根据需求对4种基本卷进行组合形成多种扩展卷（得益于glusterfs的模块化堆栈架构设计）。</p><p>以下主要展示各类型逻辑卷的功能性，未对性能做测试验证。</p><a id="more"></a><h2 id="分布式卷"><a href="#分布式卷" class="headerlink" title="分布式卷"></a>分布式卷</h2><p>分布式卷（Distributed Glusterfs Volume，又称DHT），glusterfs创建volume不指定卷类型时，默认即分布式卷，特点如下：</p><ol><li>根据hash算法，将多个文件分布到卷中的多个brick server上，类似（不是）raid0，但文件无分片；</li><li>方便扩展空间，但无冗余保护；</li><li>由于使用本地文件系统进行存储（brick server 的本地文件系统），存取效率不高；</li><li>受限于本地文件系统对单文件容量的限制，支持超大型文件系统有问题。</li></ol><p><img src="/articles/35de9bb2/1.png" alt="img"></p><h4 id="创建存储目录（optional）"><a href="#创建存储目录（optional）" class="headerlink" title="创建存储目录（optional）"></a>创建存储目录（optional）</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在brick server节点创建存储目录，即brick所在；</span></span><br><span class="line"><span class="comment"># 以glusterfs01节点为例，注意各brick server挂载磁盘的目录名的不同</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># mkdir -p /brick1/dis_volume</span></span><br></pre></td></tr></table></figure><h4 id="创建分布式卷"><a href="#创建分布式卷" class="headerlink" title="创建分布式卷"></a>创建分布式卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [transport [tcp | rdma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 演示分布式卷的创建，两个server节点即可，创建名为”distributed-volume”的逻辑卷</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create distributed-volume glusterfs01:/brick1/dis_volume glusterfs02:/brick2/dis_volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/2.png" alt="img"></p><h4 id="卷信息-状态"><a href="#卷信息-状态" class="headerlink" title="卷信息/状态"></a>卷信息/状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令”gluster volume list”可列出已创建的卷；</span></span><br><span class="line"><span class="comment"># 命令”gluster volume info”可不指定具体的卷，即列出所有卷信息；</span></span><br><span class="line"><span class="comment"># info中给出除卷名外，还有卷类型，状态，brick组成等信息；</span></span><br><span class="line"><span class="comment"># 其中状态为“Created”，需要通过命令启动后才可被挂载使用，在创建成功后的提示信息中有提到”please start the volume to access data”</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info distributed-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/3.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看卷状态；</span></span><br><span class="line"><span class="comment"># 展示卷中每个brick的状态，以及每个brick服务的监听端口</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume status distributed-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/4.png" alt="img"></p><h4 id="启动卷"><a href="#启动卷" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start distributed-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/5.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 再次查看卷信息，状态变为"Started"</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info distributed-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/6.png" alt="img"></p><h4 id="client挂载"><a href="#client挂载" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在客户端创建挂载目录</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/distributed</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 挂载时，可使用任意1台已加入可信存储池并已创建对应卷类型的server节点；</span></span><br><span class="line"><span class="comment"># brick以”SERVER:EXPORT”的形式标识</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:distributed-volume /mnt/distributed/</span></span><br></pre></td></tr></table></figure><h4 id="查看挂载情况"><a href="#查看挂载情况" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过“df -Th”命令可查看被挂载的volume，被挂载的文件系统，已经挂载卷的容量是2个brick容量之和</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/7.png" alt="img"></p><h4 id="查看brick的监听端口"><a href="#查看brick的监听端口" class="headerlink" title="查看brick的监听端口"></a>查看brick的监听端口</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># server节点上每启动1个brick，即启动1个brick服务，具备相应的服务监听端口，起始端口号是tcp49152</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># netstat -tunlp | grep gluster</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/8.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 另外，client连接的即brick服务的监听端口</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># netstat -nt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/9.png" alt="img"></p><h4 id="存储测试"><a href="#存储测试" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/distributed/</span></span><br><span class="line">[root@glusterfs-client distributed]<span class="comment"># touch distributed&#123;1..4&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/dis_volume/</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/10.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/dis_volume/</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/11.png" alt="img"></p><p><strong>结论：分布式卷将多个文件分布存储在多个brick server，但并无副本。</strong> </p><h2 id="条带卷（Deprecated）"><a href="#条带卷（Deprecated）" class="headerlink" title="条带卷（Deprecated）"></a>条带卷（Deprecated）</h2><p>条带卷（Striped Glusterfs Volume），特点如下：</p><ol><li>每个文件被分片成等同于brick数量的chunks，然后以round robin的方式将每个chunk存储到1个brick，相当于raid0；</li><li>单一超大容量文件可被分片，不受brick server本地文件系统的限制；</li><li>文件分片后，并发粒度是chunks，分布式读写性能较高，但分片随机读写可能会导致硬盘iops较高；</li><li>无冗余，1个server节点故障会导致所有数据丢失。</li></ol><p><img src="/articles/35de9bb2/12.png" alt="img"></p><h4 id="创建条带卷"><a href="#创建条带卷" class="headerlink" title="创建条带卷"></a>创建条带卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [stripe COUNT] [transport [tcp | dma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”strsipe-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的条带数量，数量需要与后续使用brick server数量对等；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create stripe-volume stripe 3 transport tcp glusterfs01:/brick1/str_volume glusterfs02:/brick2/str_volume glusterfs03:/brick3/str_volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/13.png" alt="img"></p><h4 id="启动卷-1"><a href="#启动卷-1" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start stripe-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/14.png" alt="img"></p><h4 id="client挂载-1"><a href="#client挂载-1" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/stripe</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:stripe-volume /mnt/stripe/</span></span><br></pre></td></tr></table></figure><h4 id="查看挂载情况-1"><a href="#查看挂载情况-1" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是3个brick容量之和</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/15.png" alt="img"></p><h4 id="存储测试-1"><a href="#存储测试-1" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/stripe/</span></span><br><span class="line">[root@glusterfs-client stripe]<span class="comment"># touch stripe&#123;1..6&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向strip1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client stripe]<span class="comment"># echo "this is stripe1.txt" &gt;&gt; strip1.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/str_volume/</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># cat /brick1/str_volume/strip1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/16.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/str_volume/</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># cat /brick2/str_volume/strip1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/17.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs03节点</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># tree /brick3/str_volume/</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># cat /brick3/str_volume/strip1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/18.png" alt="img"></p><p><strong>结论：条带卷将1个文件分片存储在多个brick server，但并无副本。</strong></p><h2 id="复制卷"><a href="#复制卷" class="headerlink" title="复制卷"></a>复制卷</h2><p>复制卷（Replicated Glusterfs Volume，又称AFR（Auto File Replication）），特点如下：</p><ol><li>每个文件同步复制镜像到多个brick，相当于文件级raid1；</li><li>副本数量通常设置为2或3，设置的副本数量需要是brick数量（至少为2）的倍数（如2台brick server，可设置副本数为2/4/6/…；如3台brick server，可设置副本数为3/6/9/…；依次类推），且每个brick的容量相等；</li><li>读性能提升，写性能下降，因为<strong>glusterfs的复制是同步事务操作，即写文件时，先把这个文件锁住，然后同时写两个或多个副本，写完后解锁，操作结束</strong>（ceph采用异步写副本，即写到一个主OSD便返回，这个OSD再通过内部网络异步写到其余OSD）；</li><li>通常与分布式卷或条带卷组合使用，解决前两者的冗余问题；</li><li>提升数据可靠性，但磁盘利用率低；</li><li>副本数设置为2时，可能会有脑裂（Split-brain）的风险（风险提示，但可配置），主要因在两个副本不一致时，无法仲裁以哪个副本为准，解决方案是加入仲裁或者设置3副本。</li></ol><p><img src="/articles/35de9bb2/19.png" alt="img"></p><h4 id="创建复制卷"><a href="#创建复制卷" class="headerlink" title="创建复制卷"></a>创建复制卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [replica COUNT] [transport [tcp | rdma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”replica-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的副本数量，数量需要与后续使用brick server数量对等；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式；</span></span><br><span class="line"><span class="comment"># 副本数为2时，有脑裂风险提示，提示采用3副本或仲裁机制，验证环境略过即可</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create replica-volume replica 2 transport tcp glusterfs01:/brick1/repl_volume glusterfs02:/brick2/repl_volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/20.png" alt="img"></p><h4 id="启动卷-2"><a href="#启动卷-2" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start replica-volume</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info replica-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/21.png" alt="img"></p><h4 id="client挂载-2"><a href="#client挂载-2" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/replica</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:replica-volume /mnt/replica/</span></span><br></pre></td></tr></table></figure><h4 id="查看挂载情况-2"><a href="#查看挂载情况-2" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是1个brick的容量</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/22.png" alt="img"></p><h4 id="存储测试-2"><a href="#存储测试-2" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/replica/</span></span><br><span class="line">[root@glusterfs-client replica]<span class="comment"># touch replica&#123;1..4&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向replica1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client replica]<span class="comment"># echo "this is replica1.txt" &gt;&gt; replica1.txt</span></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/repl_volume/</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># cat /brick1/repl_volume/replica1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/23.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/repl_volume/</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># cat /brick2/repl_volume/replica1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/24.png" alt="img"></p><p><strong>结论：复制卷将1个文件同步镜像到多个brick server，数据有冗余备份。</strong></p><h4 id="AFR恢复原理"><a href="#AFR恢复原理" class="headerlink" title="AFR恢复原理"></a>AFR恢复原理</h4><p>数据恢复只针对复制卷，AFR数据修复主要涉及三个方面：ENTRY，META，DATA。</p><p>记录描述副本状态的称之为<strong>ChangeLog</strong>，记录在每个副本文件扩展属性里，读入内存后以矩阵形式判断是否需要修复以及要以哪个副本为Source进行修复；初始值以及正常值为0（注：ENTRY和META,DATA分布对应着一个数值）。</p><p>以冗余度为2，即含有2个副本A和B的DATA修复为例，write的步骤分解为：</p><ol><li>下发Write操作；</li><li>加锁Lock；</li><li>向A，B副本的ChangeLog分别加1，记录到各副本的扩展属性中；</li><li>对A，B副本进行写操作；</li><li>若副本写成功则ChangeLog减1，若该副本写失败则ChangLog值不变，记录到各个副本的扩展属性中；</li><li>解锁UnLock；</li><li>向上层返回，只要有一个副本写成功就返回成功。 </li></ol><p>上述操作在AFR中是完整的一个transaction动作，根据两个副本记录的ChangeLog的数值确定了副本的几种状态：</p><ol><li>WISE：智慧的，即该副本的ChangeLog中对应的值是0，而另一副本对应的数值大于0；</li><li>INNOCENT：无辜的，即两副本的ChangeLog对应的值都是0；</li><li>FOOL：愚蠢的，即该副本的ChangeLog对应的值大于是0，而另一副本对应的数值是0；</li><li>IGNORANT，忽略的，即该副本的ChangeLog丢失。</li></ol><p>恢复分以下场景：</p><ol><li><p>1个节点changelog状态为WISE，其余节点为FOOL或其他非WISE状态，以WISE节点去恢复其他节点；</p></li><li><p>所有节点是IGNORANT状态，手动触发heal，通过命令以UID最小的文件作为source，去恢复大小为0的其他文件；</p></li><li><p>多个状态是WISE时，即出现脑裂状态，脑裂的文件通常读不出来，报”Input/Output error”，可查看日志/var/log/glusterfs/glustershd.log。</p><p>脑裂原理及解决方案：[<a href="https://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/]" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/]</a>(<a href="https://docs.gluster.org/en/latest/Administrator" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator</a> Guide/Split brain and ways to deal with it/)</p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过命令查看副本文件的扩展属性：getfattr -m . -d -e hex [filename]</span></span><br><span class="line"><span class="comment"># “trusted.afr.xxx”部分即扩展属性，值是24bit，分3部分，依次标识DATA ，META， ENTRY 3者的changelog</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># getfattr -m . -d -e hex /brick1/repl_volume/replica1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/25.png" alt="img"></p><h2 id="分布式复制卷"><a href="#分布式复制卷" class="headerlink" title="分布式复制卷"></a>分布式复制卷</h2><p>分布式复制卷（Distributed Replicated Glusterfs Volume），是分布式卷与复制卷的组合，兼具两者的功能，特点如下：</p><ol><li>若干brick组成1个复制卷，另外若干brick组成其他复制卷；单个文件在复制卷内数据保持副本，不同文件在不同复制卷之间进行哈希分布；即分布式卷跨复制卷集（replicated sets ）；</li><li>brick server数量是副本数量的倍数，且&gt;=2倍，即最少需要4台brick server，同时组建复制卷集的brick容量相等。</li></ol><p><img src="/articles/35de9bb2/26.png" alt="img"></p><h4 id="创建分布式复制卷"><a href="#创建分布式复制卷" class="headerlink" title="创建分布式复制卷"></a>创建分布式复制卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [replica COUNT] [transport [tcp | rdma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”distributed-replica-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的副本数量，brick server数量是副本数量的倍数，且&gt;=2倍；</span></span><br><span class="line"><span class="comment"># 不需要指出分布式卷类型，只要副本数量与brick server数量不等且符合倍数关系，即是分布式复制卷；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式；</span></span><br><span class="line"><span class="comment"># 副本数为2时，有脑裂风险提示，提示采用3副本或仲裁机制，验证环境略过即可</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create distributed-replica-volume replica 2 transport tcp \</span></span><br><span class="line"> glusterfs01:/brick1/dis_repl_volume \</span><br><span class="line"> glusterfs02:/brick2/dis_repl_volume \</span><br><span class="line"> glusterfs03:/brick3/dis_repl_volume \</span><br><span class="line"> glusterfs04:/brick4/dis_repl_volume</span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/27.png" alt="img"></p><h4 id="启动卷-3"><a href="#启动卷-3" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 卷类型：分布式复制卷</span></span><br><span class="line"><span class="comment"># “Number of Bricks”：2副本，2个副本集（replicated sets ），4个brick server</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start distributed-replica-volume</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info distributed-replica-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/28.png" alt="img"></p><h4 id="client挂载-3"><a href="#client挂载-3" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/distributed-replica</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:distributed-replica-volume /mnt/distributed-replica/</span></span><br></pre></td></tr></table></figure><h4 id="查看挂载情况-3"><a href="#查看挂载情况-3" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是2个副本集（replicated sets ）容量之和</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/29.png" alt="img"></p><h4 id="存储测试-3"><a href="#存储测试-3" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/distributed-replica/</span></span><br><span class="line">[root@glusterfs-client distributed-replica]<span class="comment"># touch distributed-replica&#123;1..6&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向distributed-replica1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client distributed-replica]<span class="comment"># echo "this is distributed-replica1.txt" &gt;&gt; distributed-replica1.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/dis_repl_volume/</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/30.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/dis_repl_volume/</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/31.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs03节点</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># tree /brick3/dis_repl_volume/</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># cat /brick3/dis_repl_volume/distributed-replica1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/32.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs04节点</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># tree /brick4/dis_repl_volume/</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># cat /brick4/dis_repl_volume/distributed-replica1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/33.png" alt="img"></p><p><strong>结论：分布式复制卷将数据文件分布在多个复制集（replicated sets ）中，每个复制集中数据有镜像冗余。</strong></p><h2 id="分布式条带卷（Deprecated）"><a href="#分布式条带卷（Deprecated）" class="headerlink" title="分布式条带卷（Deprecated）"></a>分布式条带卷（Deprecated）</h2><p>分布式条带卷（Distributed Striped Glusterfs Volume），是分布式卷与条带卷的组合，兼具两者的功能，特点如下：</p><ol><li>若干brick组成1个条带卷，另外若干brick组成其他条带卷；单个文件在条带卷内数据以条带的形式存储，不同文件在不同条带卷之间进行哈希分布；即分布式卷跨条带卷；</li><li>brick server数量是条带数的倍数，且&gt;=2倍，即最少需要4台brick server。</li></ol><p><img src="/articles/35de9bb2/34.png" alt="img"></p><h4 id="创建分布式条带卷"><a href="#创建分布式条带卷" class="headerlink" title="创建分布式条带卷"></a>创建分布式条带卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [stripe COUNT] [transport [tcp | rdma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”distributed-stripe-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的条带数，brick server数量是条带数量的倍数，且&gt;=2倍；</span></span><br><span class="line"><span class="comment"># 不需要指出分布式卷类型，只要条带数量与brick server数量不等且符合倍数关系，即是分布式复制卷；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式；</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create distributed-stripe-volume stripe 2 transport tcp \</span></span><br><span class="line"> glusterfs01:/brick1/dis_str_volume \</span><br><span class="line"> glusterfs02:/brick2/dis_str_volume \</span><br><span class="line"> glusterfs03:/brick3/dis_str_volume \</span><br><span class="line"> glusterfs04:/brick4/dis_str_volume</span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/35.png" alt="img"></p><h4 id="启动卷-4"><a href="#启动卷-4" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 卷类型：分布式条带卷</span></span><br><span class="line"><span class="comment"># “Number of Bricks”：2分布集，2条带集（replicated sets ），4个brick server</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start distributed-stripe-volume</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info distributed-stripe-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/36.png" alt="img"></p><h4 id="client挂载-4"><a href="#client挂载-4" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/distributed-stripe</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:distributed-stripe-volume /mnt/distributed-stripe/</span></span><br></pre></td></tr></table></figure><h4 id="查看挂载情况-4"><a href="#查看挂载情况-4" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是4个brick容量之和</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/37.png" alt="img"></p><h4 id="存储测试-4"><a href="#存储测试-4" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/distributed-stripe/</span></span><br><span class="line">[root@glusterfs-client distributed-stripe]<span class="comment"># touch distributed-stripe&#123;1..6&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向distributed-stripe1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client distributed-stripe]<span class="comment"># echo "this is distributed-stripe1.txt" &gt;&gt; distributed-stripe1.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/dis_str_volume/</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/38.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/dis_str_volume/</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/39.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs03节点</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># tree /brick3/dis_str_volume/</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># cat /brick3/dis_str_volume/distributed-stripe1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/40.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs04节点</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># tree /brick4/dis_str_volume/</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># cat /brick4/dis_str_volume/distributed-stripe1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/41.png" alt="img"></p><p><strong>结论：分布式条带卷将数据文件分布在多个条带集中，每个条带集中数据再以条带的形式存储在对应条带集中的全部brick上，数据无冗余备份。</strong></p><h2 id="条带镜像卷（Deprecated）"><a href="#条带镜像卷（Deprecated）" class="headerlink" title="条带镜像卷（Deprecated）"></a>条带镜像卷（Deprecated）</h2><p>条带复制卷（STRIPE REPLICA Volume），是条带与复制卷的组合，兼具两者的功能，特点如下：</p><ol><li>若干brick组成1个复制卷，另外若干brick组成其他复制卷；单个文件以条带的形式存储在2个或多个复制集（replicated sets ），复制集内文件分片以副本的形式保存；相当于文件级raid01；</li><li>brick server数量是副本数的倍数，且&gt;=2倍，即最少需要4台brick server。</li></ol><p><img src="/articles/35de9bb2/42.png" alt="img"></p><h2 id="分布式条带镜像卷（Deprecated）"><a href="#分布式条带镜像卷（Deprecated）" class="headerlink" title="分布式条带镜像卷（Deprecated）"></a>分布式条带镜像卷（Deprecated）</h2><p>分布式条带复制卷（DISTRIBUTE STRIPE REPLICA VOLUME），是分布式卷，条带与复制卷的组合，兼具三者的功能，特点如下：</p><ol><li>多个文件哈希分布到到多个条带集中，单个文件在条带集中以条带的形式存储在2个或多个复制集（replicated sets ），复制集内文件分片以副本的形式保存；</li><li>brick server数量是副本数的倍数，且&gt;=2倍，即最少需要4台brick server。</li></ol><p><img src="/articles/35de9bb2/43.png" alt="img"></p><h2 id="纠删卷"><a href="#纠删卷" class="headerlink" title="纠删卷"></a>纠删卷</h2><p>纠删卷（Dispersed Volumes）是v3.6版本后发布的一种volume特点如下：</p><ol><li>基于纠删码（erasure codes， EC）实现，类似于raid5/6（取决于redundancy等级）；</li><li>通过配置redundancy（冗余）级别提高可靠性，在保证较高的可靠性同时，可以提升物理存储空间的利用率；</li><li>文件被分割成大小相同的chunk(块)，每个chunk又被分割成fragment，冗余信息的fragment随之生成，且同一个fragment只会保存一个brick上；</li><li>redundancy均匀分布存储在所有的brick，逻辑卷的有效空间是<usable size> = <brick size> * (#bricks - redundancy)；</brick></usable></li><li>在数据恢复时，只要(#bricks - redundancy)个fragment（数据或冗余信息）可用，就能正常恢复数据；</li><li>卷中所有brick容量需要相同，否则最小的brick满容量时，数据无法写入；</li><li>实际部署时，redundancy &lt; #bricks / 2 (or equivalently, redundancy * 2 &lt; #bricks)，即brick至少是3个；redundancy设置为0时，DispersedVolume等同于分布式卷；若redundancy设置为brick/2时，DispersedVolume等同于复制卷。</li></ol><h4 id="创建纠删卷"><a href="#创建纠删卷" class="headerlink" title="创建纠删卷"></a>创建纠删卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create [disperse [&lt;count&gt;]] [redundancy &lt;count&gt;] [transport tcp | rdma | tcp,rdma]</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”disperse-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的brick server数量；</span></span><br><span class="line"><span class="comment"># 冗余等级”redundancy”需要根据使用brick server数量(“disperse conunt”)，并结合期望的冗余度数综合考量；</span></span><br><span class="line"><span class="comment"># 也可不设置冗余等级”redundancy”，系统会根据brick server数量(“disperse conunt”)自动计算最优值，确认即可；如disperse conunt=3，则redundancy=1（无“warning message”）；disperse conunt=6，则redundancy=2（有“warning message”）；但disperse conunt=4，则无最优值，此时使用默认redundancy=1（有“warning message”）；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式，默认即tcp；</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create disperse-volume disperse 3 transport tcp \</span></span><br><span class="line"> glusterfs01:/brick1/disperse_volume \</span><br><span class="line"> glusterfs02:/brick2/disperse_volume \</span><br><span class="line"> glusterfs03:/brick3/disperse_volume</span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/44.png" alt="img"></p><h4 id="启动卷-5"><a href="#启动卷-5" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 卷类型：disperse卷</span></span><br><span class="line"><span class="comment"># “Number of Bricks”：rudundancy=1，3个brick server</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start disperse-volume</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info disperse-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/45.png" alt="img"></p><h4 id="client挂载-5"><a href="#client挂载-5" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/disperse</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:disperse-volume /mnt/disperse/</span></span><br></pre></td></tr></table></figure><h4 id="查看挂载情况-5"><a href="#查看挂载情况-5" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是2个brick容量之和，&lt;usable size&gt; = &lt;brick size&gt; * (#bricks - redundancy)</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/46.png" alt="img"></p><h4 id="存储测试-5"><a href="#存储测试-5" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/disperse/</span></span><br><span class="line">[root@glusterfs-client disperse]<span class="comment"># touch disperse&#123;1..4&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向distributed-replica1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client disperse]<span class="comment"># echo "this is disperse1.txt" &gt;&gt; disperse1.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/disperse_volume/</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># cat /brick1/disperse_volume/disperse1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/47.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/disperse_volume/</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># cat /brick2/disperse_volume/disperse1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/48.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs03节点</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># tree /brick3/disperse_volume/</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># cat /brick3/disperse_volume/disperse1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/49.png" alt="img"></p><p><strong>结论：纠删卷将数据文件（含冗余信息）分布在多个brick中，数据有冗余。</strong></p><h2 id="分布式纠删卷"><a href="#分布式纠删卷" class="headerlink" title="分布式纠删卷"></a>分布式纠删卷</h2><p>分布式纠删卷（Distributed Dispersed Volumes）等效于分布式复制卷，但使用的是纠删子卷，而非复制子卷。</p><h1 id="Glusterfs管理"><a href="#Glusterfs管理" class="headerlink" title="Glusterfs管理"></a>Glusterfs管理</h1><h2 id="均衡卷"><a href="#均衡卷" class="headerlink" title="均衡卷"></a>均衡卷</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不迁移数据</span></span><br><span class="line">gluster volume VOLNAME rebalance [fix-layout start | start | startforce | status | stop]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修复卷（只针对复制卷）</span></span><br><span class="line">gluster volume heal REPLICATE-VOLNAME/DISPERSE-VOLNAME       <span class="comment">#只修复有问题的文件  </span></span><br><span class="line">gluster volume heal REPLICATE-VOLNAME/DISPERSE-VOLNAME full    <span class="comment">#修复所有文件  </span></span><br><span class="line">gluster volume heal REPLICATE-VOLNAME/DISPERSE-VOLNAME info    <span class="comment">#查看自愈详情  </span></span><br><span class="line">gluster volume heal REPLICATE-VOLNAME/DISPERSE-VOLNAME info healed|heal-failed|split-brain</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置卷</span></span><br><span class="line">gluster volume <span class="built_in">set</span> options</span><br></pre></td></tr></table></figure><h2 id="删除卷"><a href="#删除卷" class="headerlink" title="删除卷"></a>删除卷</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除卷操作，必须先停用卷；</span></span><br><span class="line"><span class="comment"># 最后可清空brick server节点对应目录下的内容</span></span><br><span class="line">gluster volume stop distributed-volume</span><br><span class="line">gluster volume delete distributed-volume</span><br><span class="line">rm -f /brick1/dis_volume</span><br></pre></td></tr></table></figure><h2 id="brick管理"><a href="#brick管理" class="headerlink" title="brick管理"></a>brick管理</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加brick</span></span><br><span class="line">gluster volume add-brick VOLNAME NEW-BRICK</span><br><span class="line"></span><br><span class="line"><span class="comment"># 移除brick</span></span><br><span class="line">gluster volume remove-brick VOLNAME BRICK [start | status | commit]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换brick</span></span><br><span class="line">gluster volume replace-brick VOLNAME BRICKNEW-BRICK [start | pause | sbortstatus | commit]</span><br></pre></td></tr></table></figure><h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p>相关日志，在/var/log/glusterfs/目录下，可根据需要查看；</p><p>如/var/log/glusterfs/brick/下是各brick创建的日志；</p><p>如/var/log/glusterfs/cmd_history.log是命令执行记录日志；</p><p>如/var/log/glusterfs/glusterd.log是glusterd守护进程日志。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Glusterfs逻辑卷创建与使用&quot;&gt;&lt;a href=&quot;#Glusterfs逻辑卷创建与使用&quot; class=&quot;headerlink&quot; title=&quot;Glusterfs逻辑卷创建与使用&quot;&gt;&lt;/a&gt;Glusterfs逻辑卷创建与使用&lt;/h1&gt;&lt;p&gt;volume是brick的组合，并且大部分glusterfs文件系统的操作都在volume上。&lt;/p&gt;
&lt;p&gt;glusterfs支持4种基本卷，并可以根据需求对4种基本卷进行组合形成多种扩展卷（得益于glusterfs的模块化堆栈架构设计）。&lt;/p&gt;
&lt;p&gt;以下主要展示各类型逻辑卷的功能性，未对性能做测试验证。&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.netlify.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="GlusterFS" scheme="https://wandouduoduo.netlify.com/tags/GlusterFS/"/>
    
  </entry>
  
  <entry>
    <title>GlusterFS分布式存储集群之部署</title>
    <link href="https://wandouduoduo.netlify.com/articles/e3bb873c.html"/>
    <id>https://wandouduoduo.netlify.com/articles/e3bb873c.html</id>
    <published>2019-11-05T03:37:42.000Z</published>
    <updated>2019-11-05T04:36:27.123Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Glusterfs框架"><a href="#Glusterfs框架" class="headerlink" title="Glusterfs框架"></a>Glusterfs框架</h1><p>Glusterfs（Gluster file system）是开源的，具有强大横向扩展能力的（scale-out）,分布式的，可将来自多个服务器的存储资源通过tcp/ip或infiniBand RDMA 网络整合到一个统一的全局命名空间中的文件系统。</p><h2 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h2><p><img src="/articles/e3bb873c/1.png" alt="img"></p><ol><li>GlusterFS主要由存储服务器（Brick Server）、客户端以及 NFS/Samba 存储网关组成；</li><li>架构中无元数据服务器组件，无对于提升整个系统的性单点故障和性能瓶颈问题，可提高系统扩展性、性能、可靠性和稳定性；</li><li>GlusterFS支持 TCP/IP 和 InfiniBand RDMA 高速网络互联；</li><li>客户端可通过原生 GlusterFS 协议访问数据，其他没有运行 GlusterFS 客户端的终端可通过 NFS/CIFS 标准协议通过存储网关访问数据（存储网关提供弹性卷管理和访问代理功能）；</li><li>存储服务器主要提供基本的数据存储功能，客户端弥补了没有元数据服务器的问题，承担了更多的功能，包括数据卷管理、I/O 调度、文件定位、数据缓存等功能，利用 FUSE（File system in User Space）模块将 GlusterFS 挂载到本地文件系统之上，实现 POSIX 兼容的方式来访问系统数据。</li></ol><h2 id="常见术语"><a href="#常见术语" class="headerlink" title="常见术语"></a>常见术语</h2><ol><li>Brick：GlusterFS中最基本的存储单元，表示为受信存储池（trusted storage pool）中输出的目录，供客户端挂载用，可以通过主机名与目录名来标识，如’SERVER:EXPORT’；</li><li>Volume：卷，逻辑上由N个brick组成；</li><li>FUSE：Unix-like OS上的可动态加载的模块，允许用户不用修改内核即可创建自己的文件系统；</li><li>Glusterd：Gluster management daemon，在trusted storage pool中所有的服务器上运行；</li><li>Volfile：Glusterfs进程的配置文件，通常是位于/var/lib/glusterd/vols/目录下的{volname}文件；</li><li>Self-heal：用于后台运行检测复本卷中文件与目录的不一致性并解决这些不一致；</li><li>Split-brain：脑裂；</li><li>GFID：GlusterFS卷中的每个文件或目录都有一个唯一的128位的数据相关联，用于模拟inode；</li><li>Namespace：每个Gluster卷都导出单个ns作为POSIX的挂载点。</li></ol><h2 id="数据访问流程"><a href="#数据访问流程" class="headerlink" title="数据访问流程"></a>数据访问流程</h2><p><img src="/articles/e3bb873c/2.png" alt="img"></p><ol><li>在客户端,用户通过 glusterfs的mount point读写数据；</li><li>用户的这个操作被递交给本地 Linux 系统的VFS 来处理；</li><li>VFS 将数据递交给 FUSE 内核文件系统（在启动 glusterfs 客户端以前,需要向系统注册一个实际的文件系统 FUSE），该文件系统与 ext3 在同一个层次， ext3 是对实际的磁盘进行处理，而 fuse 文件系统则是将数据通过 /dev/fuse 这个设备文件递交给了glusterfs client 端，可以将 fuse 文件系统理解为一个代理；</li><li>数据被 fuse 递交给 Glusterfs client 后， client 对数据进行一些指定的处理（即按 client 配置文件来进行的一系列处理）；</li><li>在 glusterfs client 的处理末端,通过网络将数据递交给 Glusterfs Server, 并且将数据写入到服务器所控制的存储设备上。</li></ol><a id="more"></a><h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><ol><li><p>Quick Start Guide：<a href="http://gluster.readthedocs.io/en/latest/Quick-Start-Guide/Quickstart/" target="_blank" rel="noopener">http://gluster.readthedocs.io/en/latest/Quick-Start-Guide/Quickstart/</a></p></li><li><p>Install-Guide：<a href="https://docs.gluster.org/en/latest/Install-Guide/Install/" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Install-Guide/Install/</a></p></li><li><p>CentOS gluster-Quickstart：<a href="https://wiki.centos.org/SpecialInterestGroup/Storage/gluster-Quickstart" target="_blank" rel="noopener">https://wiki.centos.org/SpecialInterestGroup/Storage/gluster-Quickstart</a></p></li><li><p>Type of Volumes：<a href="https://docs.gluster.org/en/latest/Quick-Start-Guide/Architecture/#types-of-volumes" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Quick-Start-Guide/Architecture/#types-of-volumes</a></p></li><li><p>Setting up GlusterFS Volumes：[<a href="https://docs.gluster.org/en/latest/Administrator%20Guide/Setting%20Up%20Volumes/]" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator%20Guide/Setting%20Up%20Volumes/]</a>(<a href="https://docs.gluster.org/en/latest/Administrator" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator</a> Guide/Setting Up Volumes/)</p></li><li><p>脑裂：[<a href="https://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/]" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/]</a>(<a href="https://docs.gluster.org/en/latest/Administrator" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator</a> Guide/Split brain and ways to deal with it/)</p></li><li><p>Glusterfs技术详解（推荐）：<a href="https://czero000.github.io/2016/04/05/glusterfs-technical-explanation.html" target="_blank" rel="noopener">https://czero000.github.io/2016/04/05/glusterfs-technical-explanation.html</a></p></li></ol><h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><h2 id="环境规划"><a href="#环境规划" class="headerlink" title="环境规划"></a>环境规划</h2><table><thead><tr><th><strong>Hostname</strong></th><th><strong>IP</strong></th><th><strong>Service</strong></th><th><strong>Remark</strong></th></tr></thead><tbody><tr><td>glusterfs-client</td><td>172.30.200.50</td><td>glusterfs(3.12.9)glusterfs-fuse</td><td>客户端</td></tr><tr><td>glusterfs01</td><td>172.30.200.51</td><td>glusterfs(3.12.9)glusterfs-server(3.12.9)glusterfs-fuse</td><td>服务器端</td></tr><tr><td>glusterfs02</td><td>172.30.200.52</td><td>glusterfs(3.12.9)glusterfs-server(3.12.9)glusterfs-fuse</td><td>服务器端</td></tr><tr><td>glusterfs03</td><td>172.30.200.53</td><td>glusterfs(3.12.9)glusterfs-server(3.12.9)glusterfs-fuse</td><td>服务器端</td></tr><tr><td>glusterfs04</td><td>172.30.200.54</td><td>glusterfs(3.12.9)glusterfs-server(3.12.9)glusterfs-fuse</td><td>服务器端</td></tr></tbody></table><h2 id="设置hosts"><a href="#设置hosts" class="headerlink" title="设置hosts"></a>设置hosts</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 所有节点保持一致的hosts即可，以gluster01节点为例；</span></span><br><span class="line"><span class="comment"># 绑定hosts不是必须的，后续组建受信存储池也可使用ip的形式</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># vim /etc/hosts </span></span><br><span class="line"><span class="comment"># glusterfs</span></span><br><span class="line">172.30.200.50   glusterfs-client</span><br><span class="line">172.30.200.51   glusterfs01</span><br><span class="line">172.30.200.52   glusterfs02</span><br><span class="line">172.30.200.53   glusterfs03</span><br><span class="line">172.30.200.54   glusterfs04</span><br><span class="line"></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># cat /etc/hosts</span></span><br></pre></td></tr></table></figure><p><img src="/articles/e3bb873c/3.png" alt="img"></p><h2 id="设置ntp"><a href="#设置ntp" class="headerlink" title="设置ntp"></a>设置ntp</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 至少4个Brick Server节点需要保持时钟同步（重要），以glusterfs01节点为例</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># yum install chrony -y </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑/etc/chrony.conf文件，设置”172.20.0.252”为时钟源；</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># egrep -v "^$|^#" /etc/chrony.conf </span></span><br><span class="line">server 172.20.0.252 iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">logdir /var/<span class="built_in">log</span>/chrony</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置开机启动，并重启</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># systemctl enable chronyd.service</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># systemctl restart chronyd.service</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看状态</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># systemctl status chronyd.service</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># chronyc sources -v</span></span><br></pre></td></tr></table></figure><h2 id="设置glusterfs-packages"><a href="#设置glusterfs-packages" class="headerlink" title="设置glusterfs packages"></a>设置glusterfs packages</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 全部节点安装glusterfs yum源</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># yum install -y centos-release-gluster </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># yum repolist</span></span><br></pre></td></tr></table></figure><h2 id="设置iptables"><a href="#设置iptables" class="headerlink" title="设置iptables"></a>设置iptables</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 提前统一设置iptables（至少4个Brick Server节点），以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 初始环境已使用iptables替代centos7.x自带的firewalld，同时关闭selinux；</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># vim /etc/sysconfig/iptables</span></span><br><span class="line"><span class="comment"># tcp24007:24008：glusterfsd daemon management服务监听端口；</span></span><br><span class="line"><span class="comment"># tcp49152:49160：3.4版本之后（之前的版本的起始端口是24009），启动1个brick，即启动1个监听端口，起始端口为49152，依次类推，如这里设置49152:49160，可开启9个brick；</span></span><br><span class="line"><span class="comment"># 另如果启动nfs server，需要开启38465:38467，111等端口</span></span><br><span class="line">-A INPUT -p tcp -m state --state NEW -m tcp --dport 24007:24008 -j ACCEPT</span><br><span class="line">-A INPUT -p tcp -m state --state NEW -m tcp --dport 49152:49160 -j ACCEPT</span><br><span class="line"></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># service iptables restart</span></span><br></pre></td></tr></table></figure><h1 id="设置glusterfs"><a href="#设置glusterfs" class="headerlink" title="设置glusterfs"></a>设置glusterfs</h1><h2 id="mount-brick"><a href="#mount-brick" class="headerlink" title="mount brick"></a>mount brick</h2><h4 id="创建分区"><a href="#创建分区" class="headerlink" title="创建分区"></a>创建分区</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 各brick server的磁盘挂载前需要创建分区并格式化，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 将整个/dev/sdb磁盘设置为1个分区，分区设置默认即可</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># fdisk /dev/sdb</span></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): n</span><br><span class="line">Select (default p): </span><br><span class="line">Partition number (1-4, default 1): </span><br><span class="line">First sector (2048-209715199, default 2048): </span><br><span class="line">Last sector, +sectors or +size&#123;K,M,G&#125; (2048-209715199, default 209715199): </span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): w</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># fdisk -l /dev/sdb</span></span><br></pre></td></tr></table></figure><p><img src="/articles/e3bb873c/4.png" alt="img"></p><h4 id="格式化分区"><a href="#格式化分区" class="headerlink" title="格式化分区"></a>格式化分区</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs01 ~]<span class="comment"># mkfs.xfs -i size=512 /dev/sdb1</span></span><br></pre></td></tr></table></figure><p><img src="/articles/e3bb873c/5.png" alt="img"></p><h4 id="挂载分区"><a href="#挂载分区" class="headerlink" title="挂载分区"></a>挂载分区</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建挂载目录，目录名自定义；</span></span><br><span class="line"><span class="comment"># 这里为区分，可以将4个server节点的目录名按顺序命名（非必须）</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># mkdir -p /brick1</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># mkdir -p /brick2</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># mkdir -p /brick3</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># mkdir -p /brick4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改/etc/fstab文件，以glusterfs01节点为例，注意其余3各节点挂载点目录名不同；</span></span><br><span class="line"><span class="comment"># 第一栏：设备装置名；</span></span><br><span class="line"><span class="comment"># 第二栏：挂载点；</span></span><br><span class="line"><span class="comment"># 第三栏：文件系统；</span></span><br><span class="line"><span class="comment"># 第四栏：文件系统参数，默认情况使用 defaults 即可，同时具有 rw, suid, dev, exec, auto, nouser, async 等参数；</span></span><br><span class="line"><span class="comment"># 第五栏：是否被 dump 备份命令作用，"0"代表不做 dump 备份； "1"代表要每天进行 dump； "2"代表其他不定日期的 dump； 通常设置"0" 或者"1"；</span></span><br><span class="line"><span class="comment"># 第六栏：是否以 fsck 检验扇区，启动过程中，系统默认会以 fsck 检验 filesystem 是否完整 (clean)， 但某些 filesystem 是不需要检验的，如swap；"0"是不要检验，"1"表示最早检验(一般只有根目录会配置为 "1")，"2"是检验，但晚于"1"；通常根目录配置为"1" ，其余需要要检验的 filesystem 都配置为"2"；</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># echo "/dev/sdb1 /brick1                               xfs     defaults        1 2" &gt;&gt; /etc/fstab</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 挂载并展示</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># mount -a &amp;&amp; mount</span></span><br></pre></td></tr></table></figure><p><img src="/articles/e3bb873c/6.png" alt="img"></p><h2 id="启动glusterfs-server"><a href="#启动glusterfs-server" class="headerlink" title="启动glusterfs-server"></a>启动glusterfs-server</h2><h4 id="安装glusterfs-server"><a href="#安装glusterfs-server" class="headerlink" title="安装glusterfs-server"></a>安装glusterfs-server</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在4个brick server节点安装glusterfs-server，以glusterfs01节点为例</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># yum install -y glusterfs-server</span></span><br></pre></td></tr></table></figure><h4 id="启动glusterfs-server-1"><a href="#启动glusterfs-server-1" class="headerlink" title="启动glusterfs-server"></a>启动glusterfs-server</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs01 ~]<span class="comment"># systemctl enable glusterd</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># systemctl restart glusterd</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看状态</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># systemctl status glusterd</span></span><br></pre></td></tr></table></figure><p><img src="/articles/e3bb873c/7.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看服务监听端口</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># netstat -tunlp</span></span><br></pre></td></tr></table></figure><p><img src="/articles/e3bb873c/8.png" alt="img"></p><h2 id="组建受信存储池"><a href="#组建受信存储池" class="headerlink" title="组建受信存储池"></a>组建受信存储池</h2><p>受信存储池（trusted storage pools），是1个可信的网络存储服务器，为卷提供brick，可以理解为集群。 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在任意一个server节点组建受信存储池均可，即由任意节点邀请其他节点组建存储池；</span></span><br><span class="line"><span class="comment"># 组建时，做为”邀请者”，不需要再加入本节点；</span></span><br><span class="line"><span class="comment"># 使用ip或dns主机名解析都可以，这里已在hosts文件绑定主机，采用主机名；</span></span><br><span class="line"><span class="comment"># 从集群移除节点：gluster peer detach &lt;ip or hostname&gt;</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster peer probe glusterfs02</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster peer probe glusterfs03</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster peer probe glusterfs04</span></span><br></pre></td></tr></table></figure><p><img src="/articles/e3bb873c/9.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看受信存储池状态；</span></span><br><span class="line"><span class="comment"># 在glusterfs01节点查看集群状态，不会list出本节点，只展示peers</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster peer status</span></span><br></pre></td></tr></table></figure><p><img src="/articles/e3bb873c/10.png" alt="img"></p><h2 id="设置glusterfs-client"><a href="#设置glusterfs-client" class="headerlink" title="设置glusterfs-client"></a>设置glusterfs-client</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 客户端主要安装两个组件，glusterfs与glusterfs-fuse；</span></span><br><span class="line"><span class="comment"># glusterfs-client具备如数据卷管理、I/O 调度、文件定位、数据缓存等功能；</span></span><br><span class="line"><span class="comment"># glusterfs-fuse将远端glusterfs挂载到本地文件系统，可通过”modinfo fuse”，“ll /dev/fuse”等命令查看</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># yum install -y glusterfs glusterfs-fuse</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Glusterfs框架&quot;&gt;&lt;a href=&quot;#Glusterfs框架&quot; class=&quot;headerlink&quot; title=&quot;Glusterfs框架&quot;&gt;&lt;/a&gt;Glusterfs框架&lt;/h1&gt;&lt;p&gt;Glusterfs（Gluster file system）是开源的，具有强大横向扩展能力的（scale-out）,分布式的，可将来自多个服务器的存储资源通过tcp/ip或infiniBand RDMA 网络整合到一个统一的全局命名空间中的文件系统。&lt;/p&gt;
&lt;h2 id=&quot;框架&quot;&gt;&lt;a href=&quot;#框架&quot; class=&quot;headerlink&quot; title=&quot;框架&quot;&gt;&lt;/a&gt;框架&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/articles/e3bb873c/1.png&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;GlusterFS主要由存储服务器（Brick Server）、客户端以及 NFS/Samba 存储网关组成；&lt;/li&gt;
&lt;li&gt;架构中无元数据服务器组件，无对于提升整个系统的性单点故障和性能瓶颈问题，可提高系统扩展性、性能、可靠性和稳定性；&lt;/li&gt;
&lt;li&gt;GlusterFS支持 TCP/IP 和 InfiniBand RDMA 高速网络互联；&lt;/li&gt;
&lt;li&gt;客户端可通过原生 GlusterFS 协议访问数据，其他没有运行 GlusterFS 客户端的终端可通过 NFS/CIFS 标准协议通过存储网关访问数据（存储网关提供弹性卷管理和访问代理功能）；&lt;/li&gt;
&lt;li&gt;存储服务器主要提供基本的数据存储功能，客户端弥补了没有元数据服务器的问题，承担了更多的功能，包括数据卷管理、I/O 调度、文件定位、数据缓存等功能，利用 FUSE（File system in User Space）模块将 GlusterFS 挂载到本地文件系统之上，实现 POSIX 兼容的方式来访问系统数据。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;常见术语&quot;&gt;&lt;a href=&quot;#常见术语&quot; class=&quot;headerlink&quot; title=&quot;常见术语&quot;&gt;&lt;/a&gt;常见术语&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Brick：GlusterFS中最基本的存储单元，表示为受信存储池（trusted storage pool）中输出的目录，供客户端挂载用，可以通过主机名与目录名来标识，如’SERVER:EXPORT’；&lt;/li&gt;
&lt;li&gt;Volume：卷，逻辑上由N个brick组成；&lt;/li&gt;
&lt;li&gt;FUSE：Unix-like OS上的可动态加载的模块，允许用户不用修改内核即可创建自己的文件系统；&lt;/li&gt;
&lt;li&gt;Glusterd：Gluster management daemon，在trusted storage pool中所有的服务器上运行；&lt;/li&gt;
&lt;li&gt;Volfile：Glusterfs进程的配置文件，通常是位于/var/lib/glusterd/vols/目录下的{volname}文件；&lt;/li&gt;
&lt;li&gt;Self-heal：用于后台运行检测复本卷中文件与目录的不一致性并解决这些不一致；&lt;/li&gt;
&lt;li&gt;Split-brain：脑裂；&lt;/li&gt;
&lt;li&gt;GFID：GlusterFS卷中的每个文件或目录都有一个唯一的128位的数据相关联，用于模拟inode；&lt;/li&gt;
&lt;li&gt;Namespace：每个Gluster卷都导出单个ns作为POSIX的挂载点。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;数据访问流程&quot;&gt;&lt;a href=&quot;#数据访问流程&quot; class=&quot;headerlink&quot; title=&quot;数据访问流程&quot;&gt;&lt;/a&gt;数据访问流程&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/articles/e3bb873c/2.png&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在客户端,用户通过 glusterfs的mount point读写数据；&lt;/li&gt;
&lt;li&gt;用户的这个操作被递交给本地 Linux 系统的VFS 来处理；&lt;/li&gt;
&lt;li&gt;VFS 将数据递交给 FUSE 内核文件系统（在启动 glusterfs 客户端以前,需要向系统注册一个实际的文件系统 FUSE），该文件系统与 ext3 在同一个层次， ext3 是对实际的磁盘进行处理，而 fuse 文件系统则是将数据通过 /dev/fuse 这个设备文件递交给了glusterfs client 端，可以将 fuse 文件系统理解为一个代理；&lt;/li&gt;
&lt;li&gt;数据被 fuse 递交给 Glusterfs client 后， client 对数据进行一些指定的处理（即按 client 配置文件来进行的一系列处理）；&lt;/li&gt;
&lt;li&gt;在 glusterfs client 的处理末端,通过网络将数据递交给 Glusterfs Server, 并且将数据写入到服务器所控制的存储设备上。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.netlify.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="GlusterFS" scheme="https://wandouduoduo.netlify.com/tags/GlusterFS/"/>
    
  </entry>
  
  <entry>
    <title>分布式存储的优劣对比</title>
    <link href="https://wandouduoduo.netlify.com/articles/455d7de6.html"/>
    <id>https://wandouduoduo.netlify.com/articles/455d7de6.html</id>
    <published>2019-11-04T04:20:43.000Z</published>
    <updated>2019-11-04T04:31:50.576Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文通过对比当前主流的几种分布式存储方案（Ceph,TFS,FastDFS,MogileFS,MooseFS,GlusterFS等），让你知道他们的优缺点，便于你根据使用场景选择合适的方案。</p><h2 id="系统整体对比"><a href="#系统整体对比" class="headerlink" title="系统整体对比"></a>系统整体对比</h2><table><thead><tr><th>对比说明/文件系统</th><th>TFS</th><th>FastDFS</th><th>MogileFS</th><th>MooseFS</th><th>GlusterFS</th><th>Ceph</th></tr></thead><tbody><tr><td>开发语言</td><td>C++</td><td>C</td><td>Perl</td><td>C</td><td>C</td><td>C++</td></tr><tr><td>开源协议</td><td>GPL V2</td><td>GPL V3</td><td>GPL</td><td>GPL V3</td><td>GPL V3</td><td>LGPL</td></tr><tr><td>数据存储方式</td><td>块</td><td>文件/Trunk</td><td>文件</td><td>块</td><td>文件/块</td><td>对象/文件/块</td></tr><tr><td>集群节点通信协议</td><td>私有协议（TCP）</td><td>私有协议（TCP）</td><td>HTTP</td><td>私有协议（TCP）</td><td>私有协议（TCP）/ RDAM(远程直接访问内存)</td><td>私有协议（TCP）</td></tr><tr><td>专用元数据存储点</td><td>占用NS</td><td>无</td><td>占用DB</td><td>占用MFS</td><td>无</td><td>占用MDS</td></tr><tr><td>在线扩容</td><td>支持</td><td>支持</td><td>支持</td><td>支持</td><td>支持</td><td>支持</td></tr><tr><td>冗余备份</td><td>支持</td><td>支持</td><td>-</td><td>支持</td><td>支持</td><td>支持</td></tr><tr><td>单点故障</td><td>存在</td><td>不存在</td><td>存在</td><td>存在</td><td>不存在</td><td>存在</td></tr><tr><td>跨集群同步</td><td>支持</td><td>部分支持</td><td>-</td><td>-</td><td>支持</td><td>不适用</td></tr><tr><td>易用性</td><td>安装复杂，官方文档少</td><td>安装简单，社区相对活跃</td><td>-</td><td>安装简单，官方文档多</td><td>安装简单，官方文档专业化</td><td>安装简单，官方文档专业化</td></tr><tr><td>适用场景</td><td>跨集群的小文件</td><td>单集群的中小文件</td><td>-</td><td>单集群的大中文件</td><td>跨集群云存储</td><td>单集群的大中小文件</td></tr></tbody></table><p>开源协议说明</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">GPL:不允许修改后和衍生的代码做为闭源的商业软件发布和销售，修改后该软件产品必须也采用GPL协议；</span><br><span class="line">GPL V2：修改文本的整体就必须按照GPL流通，不仅该修改文本的源码必须向社 会公开，而且对于这种修改文本的流通不准许附加修改者自己作出的限制;</span><br><span class="line">GPL V3：要求用户公布修改的源代码，还要求公布相关硬件;LGPL：更宽松的GPL</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="TFS"><a href="#TFS" class="headerlink" title="TFS"></a>TFS</h2><p>TFS（Taobao File System）是由淘宝开发的一个分布式文件系统，其内部经过特殊的优化处理，适用于海量的小文件存储，目前已经对外开源；</p><p>TFS采用自有的文件系统格式存储，因此需要专用的API接口去访问，目前官方提供的客户端版本有：C++/JAVA/PHP。</p><p><img src="/articles/455d7de6/1.png" alt="img"></p><ul><li>特性</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1）在TFS文件系统中，NameServer负责管理文件元数据，通过HA机制实现主备热切换，由于所有元数据都是在内存中，其处理效率非常高效，系统架构也非常简单，管理也很方便；</span><br><span class="line">2）TFS的DataServer作为分部署数据存储节点，同时也具备负载均衡和冗余备份的功能，由于采用自有的文件系统，对小文件会采取合并策略，减少数据碎片，从而提升IO性能；</span><br><span class="line">3）TFS将元数据信息（BlockID、FileID）直接映射至文件名中，这一设计大大降低了存储元数据的内存空间；</span><br></pre></td></tr></table></figure><ul><li>优点</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1）针对小文件量身定做，随机IO性能比较高；</span><br><span class="line">2）支持在线扩容机制，增强系统的可扩展性；</span><br><span class="line">3）实现了软RAID，增强系统的并发处理能力及数据容错恢复能力；</span><br><span class="line">4）支持主备热倒换，提升系统的可用性；</span><br><span class="line">5）支持主从集群部署，其中从集群主要提供读/备功能；</span><br></pre></td></tr></table></figure><ul><li>缺点</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1）TFS只对小文件做优化，不适合大文件的存储；</span><br><span class="line">2）不支持POSIX通用接口访问，通用性较低；</span><br><span class="line">3）不支持自定义目录结构，及文件权限控制；</span><br><span class="line">4）通过API下载，存在单点的性能瓶颈；</span><br><span class="line">5）官方文档非常少，学习成本高；</span><br></pre></td></tr></table></figure><ul><li>应用场景</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1）多集群部署的应用</span><br><span class="line">2）存储后基本不做改动</span><br><span class="line">3）海量小型文件</span><br><span class="line">根据目前官方提供的材料，对单个集群节点，存储节点在1000台以内可以良好工作，如存储节点扩大可能会出现NameServer的性能瓶颈，目前淘宝线上部署容量已达到1800TB规模（2009年数据）</span><br></pre></td></tr></table></figure><ul><li><p>安装及使用</p></li><li><p><a href="http://blog.csdn.net/junefsh/article/details/43987811" target="_blank" rel="noopener">安装指导</a></p></li><li><p><a href="http://blog.csdn.net/junefsh/article/details/43987829" target="_blank" rel="noopener">TFS_配置使用</a></p></li></ul><p> <strong>源代码路径</strong>：<a href="http://code.taobao.org/p/tfs/src/" target="_blank" rel="noopener">http://code.taobao.org/p/tfs/src/</a></p><p> <strong>参考</strong></p><p> <strong><a href="http://rdc.taobao.com/blog/cs/?p=128" target="_blank" rel="noopener">http://rdc.taobao.com/blog/cs/?p=128</a></strong></p><p> <strong><a href="http://elf8848.iteye.com/blog/1724423" target="_blank" rel="noopener">http://elf8848.iteye.com/blog/1724423</a></strong></p><p> <strong><a href="http://baike.baidu.com/view/1030880.htm" target="_blank" rel="noopener">http://baike.baidu.com/view/1030880.htm</a></strong></p><p> <strong><a href="http://blog.yunnotes.net/index.php/install_document_for_tfs/" target="_blank" rel="noopener">http://blog.yunnotes.net/index.php/install_document_for_tfs/</a></strong></p><h2 id="FastDFS"><a href="#FastDFS" class="headerlink" title="FastDFS"></a><strong>FastDFS</strong></h2><p><img src="/articles/455d7de6/2.png" alt="img"></p><p>FastDFS是国人开发的一款分布式文件系统，目前社区比较活跃。如上图所示系统中存在三种节点：Client、Tracker、Storage，在底层存储上通过逻辑的分组概念，使得通过在同组内配置多个Storage，从而实现软RAID10,提升并发IO的性能、简单负载均衡及数据的冗余备份；同时通过线性的添加新的逻辑存储组，从容实现存储容量的线性扩容。</p><p>文件下载上，除了支持通过API方式，目前还提供了apache和nginx的插件支持，同时也可以不使用对应的插件，直接以Web静态资源方式对外提供下载。</p><p>目前FastDFS(V4.x)代码量大概6w多行，内部的网络模型使用比较成熟的libevent三方库，具备高并发的处理能力。</p><ul><li><strong>特性</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1）在上述介绍中Tracker服务器是整个系统的核心枢纽，其完成了访问调度（负载均衡），监控管理Storage服务器，由此可见Tracker的作用至关重要，也就增加了系统的单点故障，为此FastDFS支持多个备用的Tracker，虽然实际测试发现备用Tracker运行不是非常完美，但还是能保证系统可用。</span><br><span class="line">2）在文件同步上，只有同组的Storage才做同步，由文件所在的源Storage服务器push至其它Storage服务器，目前同步是采用Binlog方式实现，由于目前底层对同步后的文件不做正确性校验，因此这种同步方式仅适用单个集群点的局部内部网络，如果在公网上使用，肯定会出现损坏文件的情况，需要自行添加文件校验机制。</span><br><span class="line">3）支持主从文件，非常适合存在关联关系的图片，在存储方式上，FastDFS在主从文件ID上做取巧，完成了关联关系的存储。</span><br></pre></td></tr></table></figure><ul><li><strong>优点</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1）系统无需支持POSIX(可移植操作系统)，降低了系统的复杂度，处理效率更高</span><br><span class="line">2）支持在线扩容机制，增强系统的可扩展性</span><br><span class="line">3）实现了软RAID，增强系统的并发处理能力及数据容错恢复能力</span><br><span class="line">4）支持主从文件，支持自定义扩展名</span><br><span class="line">5）主备Tracker服务，增强系统的可用性</span><br></pre></td></tr></table></figure><ul><li><strong>缺点</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1）不支持断点续传，对大文件将是噩梦（FastDFS不适合大文件存储）</span><br><span class="line">2）不支持POSIX通用接口访问，通用性较低</span><br><span class="line">3）对跨公网的文件同步，存在较大延迟，需要应用做相应的容错策略</span><br><span class="line">4）同步机制不支持文件正确性校验，降低了系统的可用性</span><br><span class="line">5）通过API下载，存在单点的性能瓶颈</span><br></pre></td></tr></table></figure><ul><li><strong>应用场景</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1）单集群部署的应用</span><br><span class="line">2）存储后基本不做改动</span><br><span class="line">3）小中型文件根据</span><br><span class="line">目前官方提供的材料，现有的使用FastDFS系统存储容量已经达到900T，物理机器已经达到100台（50个组）</span><br></pre></td></tr></table></figure><p> <a href="http://blog.csdn.net/junefsh/article/details/43987863" target="_blank" rel="noopener">安装指导_FastDFS</a></p><p> <strong>源码路径：</strong><a href="https://github.com/happyfish100/fastdfs" target="_blank" rel="noopener">https://github.com/happyfish100/fastdfs</a></p><ul><li><p><strong>参考</strong></p><p><a href="https://code.google.com/p/fastdfs/" target="_blank" rel="noopener">https://code.google.com/p/fastdfs/</a> </p><p><a href="http://bbs.chinaunix.net/forum-240-1.html" target="_blank" rel="noopener">http://bbs.chinaunix.net/forum-240-1.html</a></p><p><a href="http://portal.ucweb.local/docz/spec/platform/datastore/fastdfs" target="_blank" rel="noopener">http://portal.ucweb.local/docz/spec/platform/datastore/fastdfs</a></p></li></ul><h2 id="MooseFS"><a href="#MooseFS" class="headerlink" title="MooseFS"></a><strong>MooseFS</strong></h2><p>MooseFS是一个高可用的故障容错分布式文件系统，它支持通过FUSE方式将文件挂载操作，同时其提供的web管理界面非常方便查看当前的文件存储状态。</p><ul><li><strong>特性</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1）从下图中我们可以看到MooseFS文件系统由四部分组成：Managing Server 、Data Server 、Metadata Backup Server 及Client</span><br><span class="line">2）其中所有的元数据都是由Managing Server管理，为了提高整个系统的可用性，Metadata Backup Server记录文件元数据操作日志，用于数据的及时恢复</span><br><span class="line">3）Data Server可以分布式部署，存储的数据是以块的方式分布至各存储节点的，因此提升了系统的整体性能，同时Data Server提供了冗余备份的能力，提升系统的可靠性</span><br><span class="line">4）Client通过FUSE方式挂载，提供了类似POSIX的访问方式，从而降低了Client端的开发难度，增强系统的通用性</span><br></pre></td></tr></table></figure><p><img src="/articles/455d7de6/3.png" alt="img"></p><ul><li>元数据服务器（master）:负责各个数据存储服务器的管理，文件读写调度，文件空间回收以及恢复</li><li>元数据日志服务器（metalogger）:负责备份master服务器的变化日志文件，以便于在master server出问题的时候接替其进行工作</li><li>数据存储服务器（chunkserver）:数据实际存储的地方，由多个物理服务器组成，负责连接管理服务器，听从管理服务器调度，提供存储空间，并为客户提供数据传输；多节点拷贝;在数据存储目录，看不见实际的数据</li></ul><p><img src="/articles/455d7de6/4.png" alt="img"></p><ul><li><strong>优点</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1）部署安装非常简单，管理方便</span><br><span class="line">2）支持在线扩容机制，增强系统的可扩展性</span><br><span class="line">3）实现了软RAID，增强系统的 并发处理能力及数据容错恢复能力</span><br><span class="line">4）数据恢复比较容易，增强系统的可用性5）有回收站功能，方便业务定制</span><br></pre></td></tr></table></figure><ul><li><strong>缺点</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1）存在单点性能瓶颈及单点故障</span><br><span class="line">2）MFS Master节点很消耗内存</span><br><span class="line">3）对于小于64KB的文件，存储利用率较低</span><br></pre></td></tr></table></figure><ul><li><strong>应用场景</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1）单集群部署的应用</span><br><span class="line">2）中、大型文件</span><br></pre></td></tr></table></figure><ul><li><p>参考</p><p><a href="http://portal.ucweb.local/docz/spec/platform/datastore/moosefsh" target="_blank" rel="noopener">http://portal.ucweb.local/docz/spec/platform/datastore/moosefsh</a> </p><p><a href="http://www.moosefs.org/" target="_blank" rel="noopener">http://www.moosefs.org/</a> </p><p><a href="http://sourceforge.net/projects/moosefs/?source=directory" target="_blank" rel="noopener">http://sourceforge.net/projects/moosefs/?source=directory</a></p></li></ul><h2 id="GlusterFS"><a href="#GlusterFS" class="headerlink" title="GlusterFS"></a><strong>GlusterFS</strong></h2><p>GlusterFS是Red Hat旗下的一款开源分布式文件系统，它具备高扩展、高可用及高性能等特性，由于其无元数据服务器的设计，使其真正实现了线性的扩展能力，使存储总容量可 轻松达到PB级别，支持数千客户端并发访问；对跨集群，其强大的Geo-Replication可以实现集群间数据镜像，而且是支持链式复制，这非常适用 于垮集群的应用场景</p><ul><li><strong>特性</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1）目前GlusterFS支持FUSE方式挂载，可以通过标准的NFS/SMB/CIFS协议像访问本体文件一样访问文件系统，同时其也支持HTTP/FTP/GlusterFS访问，同时最新版本支持接入Amazon的AWS系统</span><br><span class="line">2）GlusterFS系统通过基于SSH的命令行管理界面，可以远程添加、删除存储节点，也可以监控当前存储节点的使用状态</span><br><span class="line">3）GlusterFS支持集群节点中存储虚拟卷的扩容动态扩容；同时在分布式冗余模式下，具备自愈管理功能，在Geo冗余模式下，文件支持断点续传、异步传输及增量传送等特点</span><br></pre></td></tr></table></figure><p><img src="/articles/455d7de6/5.jpg" alt></p><ul><li><strong>优点</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1）系统支持POSIX(可移植操作系统)，支持FUSE挂载通过多种协议访问，通用性比较高</span><br><span class="line">2）支持在线扩容机制，增强系统的可扩展性</span><br><span class="line">3）实现了软RAID，增强系统的 并发处理能力及数据容错恢复能力</span><br><span class="line">4）强大的命令行管理，降低学习、部署成本</span><br><span class="line">5）支持整个集群镜像拷贝，方便根据业务压力，增加集群节点</span><br><span class="line">6）官方资料文档专业化，该文件系统由Red Hat企业级做维护，版本质量有保障</span><br></pre></td></tr></table></figure><ul><li><strong>缺点</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1）通用性越强，其跨越的层次就越多，影响其IO处理效率</span><br><span class="line">2）频繁读写下，会产生垃圾文件，占用磁盘空间</span><br></pre></td></tr></table></figure><ul><li><strong>应用场景</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1）多集群部署的应用</span><br><span class="line">2）中大型文件根据目前官方提供的材料，现有的使用GlusterFS系统存储容量可轻松达到PB</span><br></pre></td></tr></table></figure><ul><li><strong>术语：</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">brick：分配到卷上的文件系统块；</span><br><span class="line">client：挂载卷，并对外提供服务；</span><br><span class="line">server：实际文件存储的地方；</span><br><span class="line">subvolume：被转换过的文件系统块；</span><br><span class="line">volume：最终转换后的文件系统卷。</span><br></pre></td></tr></table></figure><ul><li><p><strong>参考</strong></p><p><a href="http://www.gluster.org/" target="_blank" rel="noopener">http://www.gluster.org/</a></p><p><a href="http://www.gluster.org/wp-content/uploads/2012/05/Gluster_File_System-3.3.0-Administration_Guide-en-US.pdf" target="_blank" rel="noopener">http://www.gluster.org/wp-content/uploads/2012/05/Gluster_File_System-3.3.0-Administration_Guide-en-US.pdf</a></p><p><a href="http://blog.csdn.net/liuben/article/details/6284551" target="_blank" rel="noopener">http://blog.csdn.net/liuben/article/details/6284551</a></p></li></ul><h2 id="Ceph"><a href="#Ceph" class="headerlink" title="Ceph"></a><strong>Ceph</strong></h2><p>Ceph是一个可以按对象/块/文件方式存储的开源分布式文件系统，其设计之初，就将单点故障作为首先要解决的问题，因此该系统具备高可用性、高性能及可 扩展等特点。该文件系统支持目前还处于试验阶段的高性能文件系统BTRFS(B-Tree文件系统)，同时支持按OSD方式存储，因此其性能是很卓越的， 因为该系统处于试商用阶段，需谨慎引入到生产环境</p><ul><li><strong>特性</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1）Ceph底层存储是基于RADOS（可靠的、自动的分布式对象存储），它提供了LIBRADOS/RADOSGW/RBD/CEPH FS方式访问底层的存储系统，如下图所示</span><br><span class="line">2）通过FUSE，Ceph支持类似的POSIX访问方式；Ceph分布式系统中最关键的MDS节点是可以部署多台，无单点故障的问题，且处理性能大大提升</span><br><span class="line">3）Ceph通过使用CRUSH算法动态完成文件inode number到object number的转换，从而避免再存储文件metadata信息，增强系统的灵活性</span><br></pre></td></tr></table></figure><ul><li><strong>优点</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1）支持对象存储（OSD）集群，通过CRUSH算法，完成文件动态定位， 处理效率更高</span><br><span class="line">2）支持通过FUSE方式挂载，降低客户端的开发成本，通用性高</span><br><span class="line">3）支持分布式的MDS/MON，无单点故障</span><br><span class="line">4）强大的容错处理和自愈能力5）支持在线扩容和冗余备份，增强系统的可靠性</span><br></pre></td></tr></table></figure><ul><li><strong>缺点</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1）目前处于试验阶段，系统稳定性有待考究</span><br></pre></td></tr></table></figure><ul><li><strong>应用场景</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1）全网分布式部署的应用</span><br><span class="line">2）对实时性、可靠性要求比较高官方宣传，存储容量可轻松达到PB级别</span><br></pre></td></tr></table></figure><p> <strong>源码路径：</strong><a href="https://github.com/ceph/ceph" target="_blank" rel="noopener">https://github.com/ceph/ceph</a></p><ul><li><p><strong>参考</strong></p><p><a href="http://ceph.com/" target="_blank" rel="noopener">http://ceph.com/</a></p></li></ul><h2 id="MogileFS"><a href="#MogileFS" class="headerlink" title="MogileFS"></a><strong>MogileFS</strong></h2><ul><li><p>开发语言：perl</p></li><li><p>开源协议：GPL</p></li><li><p>依赖数据库</p></li><li><p>Trackers(控制中心):负责读写数据库，作为代理复制storage间同步的数据</p></li><li><p>Database:存储源数据（默认mysql）</p></li><li><p>Storage:文件存储</p></li><li><p>除了API，可以通过与nginx集成，对外提供下载服务</p></li></ul><p> <strong>源码路径：</strong><a href="https://github.com/mogilefs" target="_blank" rel="noopener">https://github.com/mogilefs</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;本文通过对比当前主流的几种分布式存储方案（Ceph,TFS,FastDFS,MogileFS,MooseFS,GlusterFS等），让你知道他们的优缺点，便于你根据使用场景选择合适的方案。&lt;/p&gt;
&lt;h2 id=&quot;系统整体对比&quot;&gt;&lt;a href=&quot;#系统整体对比&quot; class=&quot;headerlink&quot; title=&quot;系统整体对比&quot;&gt;&lt;/a&gt;系统整体对比&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;对比说明/文件系统&lt;/th&gt;
&lt;th&gt;TFS&lt;/th&gt;
&lt;th&gt;FastDFS&lt;/th&gt;
&lt;th&gt;MogileFS&lt;/th&gt;
&lt;th&gt;MooseFS&lt;/th&gt;
&lt;th&gt;GlusterFS&lt;/th&gt;
&lt;th&gt;Ceph&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;开发语言&lt;/td&gt;
&lt;td&gt;C++&lt;/td&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;Perl&lt;/td&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;C++&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;开源协议&lt;/td&gt;
&lt;td&gt;GPL V2&lt;/td&gt;
&lt;td&gt;GPL V3&lt;/td&gt;
&lt;td&gt;GPL&lt;/td&gt;
&lt;td&gt;GPL V3&lt;/td&gt;
&lt;td&gt;GPL V3&lt;/td&gt;
&lt;td&gt;LGPL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;数据存储方式&lt;/td&gt;
&lt;td&gt;块&lt;/td&gt;
&lt;td&gt;文件/Trunk&lt;/td&gt;
&lt;td&gt;文件&lt;/td&gt;
&lt;td&gt;块&lt;/td&gt;
&lt;td&gt;文件/块&lt;/td&gt;
&lt;td&gt;对象/文件/块&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;集群节点通信协议&lt;/td&gt;
&lt;td&gt;私有协议（TCP）&lt;/td&gt;
&lt;td&gt;私有协议（TCP）&lt;/td&gt;
&lt;td&gt;HTTP&lt;/td&gt;
&lt;td&gt;私有协议（TCP）&lt;/td&gt;
&lt;td&gt;私有协议（TCP）/ RDAM(远程直接访问内存)&lt;/td&gt;
&lt;td&gt;私有协议（TCP）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;专用元数据存储点&lt;/td&gt;
&lt;td&gt;占用NS&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;占用DB&lt;/td&gt;
&lt;td&gt;占用MFS&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;占用MDS&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;在线扩容&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;冗余备份&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;单点故障&lt;/td&gt;
&lt;td&gt;存在&lt;/td&gt;
&lt;td&gt;不存在&lt;/td&gt;
&lt;td&gt;存在&lt;/td&gt;
&lt;td&gt;存在&lt;/td&gt;
&lt;td&gt;不存在&lt;/td&gt;
&lt;td&gt;存在&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;跨集群同步&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;部分支持&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;不适用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;易用性&lt;/td&gt;
&lt;td&gt;安装复杂，官方文档少&lt;/td&gt;
&lt;td&gt;安装简单，社区相对活跃&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;安装简单，官方文档多&lt;/td&gt;
&lt;td&gt;安装简单，官方文档专业化&lt;/td&gt;
&lt;td&gt;安装简单，官方文档专业化&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;适用场景&lt;/td&gt;
&lt;td&gt;跨集群的小文件&lt;/td&gt;
&lt;td&gt;单集群的中小文件&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;单集群的大中文件&lt;/td&gt;
&lt;td&gt;跨集群云存储&lt;/td&gt;
&lt;td&gt;单集群的大中小文件&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;开源协议说明&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;GPL:不允许修改后和衍生的代码做为闭源的商业软件发布和销售，修改后该软件产品必须也采用GPL协议；&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;GPL V2：修改文本的整体就必须按照GPL流通，不仅该修改文本的源码必须向社 会公开，而且对于这种修改文本的流通不准许附加修改者自己作出的限制;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;GPL V3：要求用户公布修改的源代码，还要求公布相关硬件;LGPL：更宽松的GPL&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.netlify.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="Linux" scheme="https://wandouduoduo.netlify.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>基于Keepalived+Haproxy搭建四层负载均衡器</title>
    <link href="https://wandouduoduo.netlify.com/articles/95471f15.html"/>
    <id>https://wandouduoduo.netlify.com/articles/95471f15.html</id>
    <published>2019-11-02T13:42:25.000Z</published>
    <updated>2019-11-04T01:49:45.715Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​        Haproxy是稳定、高性能、高可用性的负载均衡解决方案，支持HTTP及TCP代理后端服务器池，因支持强大灵活的7层acl规则，广泛作为HTTP反向代理。本文则详细介绍如何利用它的四层交换与Keepalived实现一个负载均衡器，适用于Socket、ICE、Mail、Mysql、私有通讯等任意TCP服务。系统架构图如下：</p><p><img src="/articles/95471f15/0.027865917857136546.png" alt="点击在新窗口中浏览此图片"></p><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>OS:    Centos6.x(64X)<br>MASTER:   192.168.0.20<br>BACKUP:   192.168.0.21<br>VIP:  192.168.0.100<br>Serivce Port: 11231</p><h2 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h2><h4 id="添加非本机IP邦定支持"><a href="#添加非本机IP邦定支持" class="headerlink" title="添加非本机IP邦定支持"></a><strong>添加非本机IP邦定支持</strong></h4><p>#vim  /etc/sysctl.conf</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.ip_nonlocal_bind=1</span><br><span class="line"></span><br><span class="line"><span class="comment">#sysctl –p</span></span><br></pre></td></tr></table></figure><h4 id="配置平台日志支持"><a href="#配置平台日志支持" class="headerlink" title="配置平台日志支持"></a>配置平台日志支持</h4><p>#vim  /etc/syslog.conf  添加</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">local3.*        /var/log/haproxy.log</span><br><span class="line">local0.*        /var/log/haproxy.log</span><br></pre></td></tr></table></figure><p>#vim /etc/sysconfig/syslog</p><p>修改：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SYSLOGD_OPTIONS=&quot;-r -m 0&quot;</span><br></pre></td></tr></table></figure><p>#/etc/init.d/syslog restart</p><h4 id="关闭SELINUX"><a href="#关闭SELINUX" class="headerlink" title="关闭SELINUX"></a>关闭SELINUX</h4><p>vim /etc/sysconfig/selinux<br>修改</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELINUX=disabled</span><br></pre></td></tr></table></figure><p>#setenforce 0</p><h4 id="配置iptables"><a href="#配置iptables" class="headerlink" title="配置iptables"></a>配置iptables</h4><p>添加VRRP通讯支持</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -A INPUT -d 224.0.0.18 -j ACCEPT</span><br></pre></td></tr></table></figure><h4 id="Keepalived的安装、配置"><a href="#Keepalived的安装、配置" class="headerlink" title="Keepalived的安装、配置"></a>Keepalived的安装、配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#mkdir -p /home/install/keepalivedha</span></span><br><span class="line"><span class="comment">#cd /home/install/keepalivedha</span></span><br><span class="line"><span class="comment">#wget http://www.keepalived.org/software/keepalived-1.2.2.tar.gz</span></span><br><span class="line"><span class="comment">#tar zxvf keepalived-1.2.2.tar.gz</span></span><br><span class="line"><span class="comment">#cd keepalived-1.2.2</span></span><br><span class="line"><span class="comment">#./configure</span></span><br><span class="line"><span class="comment">#make &amp;&amp; make install</span></span><br><span class="line"><span class="comment">#cp /usr/local/etc/rc.d/init.d/keepalived /etc/rc.d/init.d/</span></span><br><span class="line"><span class="comment">#cp /usr/local/etc/sysconfig/keepalived /etc/sysconfig/</span></span><br><span class="line"><span class="comment">#mkdir /etc/keepalived</span></span><br><span class="line"><span class="comment">#cp /usr/local/etc/keepalived/keepalived.conf /etc/keepalived/</span></span><br><span class="line"><span class="comment">#cp /usr/local/sbin/keepalived /usr/sbin/</span></span><br></pre></td></tr></table></figure><p>#vim  /etc/keepalived/keepalived.conf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">! Configuration File for keepalived </span><br><span class="line"></span><br><span class="line">global_defs &#123;  </span><br><span class="line">   notification_email &#123;  </span><br><span class="line">         liutiansi@gmail.com  </span><br><span class="line">   &#125;  </span><br><span class="line">   notification_email_from liutiansi@gmail.com  </span><br><span class="line">   smtp_connect_timeout 3  </span><br><span class="line">   smtp_server 127.0.0.1  </span><br><span class="line">   router_id LVS_DEVEL  </span><br><span class="line">&#125;  </span><br><span class="line">vrrp_script chk_haproxy &#123;  </span><br><span class="line">    script &quot;killall -0 haproxy&quot;  </span><br><span class="line">    interval 2  </span><br><span class="line">    weight 2  </span><br><span class="line">&#125;  </span><br><span class="line">vrrp_instance VI_1 &#123;  </span><br><span class="line">    interface eth1  </span><br><span class="line">    state MASTER # 从为BACKUP  </span><br><span class="line">    priority 101 # 从为100  </span><br><span class="line">    virtual_router_id 50 #路由ID，可通过#tcpdump vrrp查看。  </span><br><span class="line">    garp_master_delay 1 #主从切换时间，单位为秒。  </span><br><span class="line">  </span><br><span class="line">    authentication &#123;  </span><br><span class="line">        auth_type PASS  </span><br><span class="line">        auth_pass KJj23576hYgu23IP  </span><br><span class="line">    &#125;  </span><br><span class="line">    track_interface &#123;  </span><br><span class="line">       eth0  </span><br><span class="line">       eth1  </span><br><span class="line">    &#125;  </span><br><span class="line">    virtual_ipaddress &#123;  </span><br><span class="line">        192.168.0.100  </span><br><span class="line">    &#125;  </span><br><span class="line">    track_script &#123;  </span><br><span class="line">        chk_haproxy  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    #状态通知  </span><br><span class="line">    notify_master &quot;/etc/keepalived/Mailnotify.py master&quot;  </span><br><span class="line">    notify_backup &quot;/etc/keepalived/Mailnotify.py backup&quot;  </span><br><span class="line">    notify_fault &quot;/etc/keepalived/Mailnotify.py fault&quot;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Haproxy的安装与配置"><a href="#Haproxy的安装与配置" class="headerlink" title="Haproxy的安装与配置"></a>Haproxy的安装与配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#cd /home/install/keepalivedha</span><br><span class="line">#wget http://haproxy.1wt.eu/download/1.4/src/haproxy-1.4.11.tar.gz</span><br><span class="line">#tar -zxvf haproxy-1.4.11.tar.gz</span><br><span class="line">#cd haproxy-1.4.11</span><br><span class="line">#make install</span><br><span class="line">#mkdir -p /usr/local/haproxy/etc</span><br><span class="line">#mkdir -p /usr/local/haproxy/sbin</span><br><span class="line">#cp examples/haproxy.cfg /usr/local/haproxy/etc</span><br><span class="line">#ln -s /usr/local/sbin/haproxy /usr/local/haproxy/sbin/haproxy</span><br></pre></td></tr></table></figure><p>#vim  /usr/local/haproxy/etc/haproxy.cfg</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"># this config needs haproxy-1.1.28 or haproxy-1.2.1</span><br><span class="line">global  </span><br><span class="line">#        log 127.0.0.1   local0  </span><br><span class="line">        log 127.0.0.1   local1 notice  </span><br><span class="line">        maxconn 5000  </span><br><span class="line">        uid 99  </span><br><span class="line">        gid 99  </span><br><span class="line">        daemon  </span><br><span class="line">        pidfile /usr/local/haproxy/haproxy.pid  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">defaults  </span><br><span class="line">        log     global  </span><br><span class="line">        mode    http  </span><br><span class="line">        #option httplog  </span><br><span class="line">        option  dontlognull  </span><br><span class="line">        retries 3  </span><br><span class="line">        option redispatch  </span><br><span class="line">        maxconn 2000  </span><br><span class="line">        contimeout      5000  </span><br><span class="line">        clitimeout      50000  </span><br><span class="line">        srvtimeout      50000  </span><br><span class="line">  </span><br><span class="line">listen  ICE01   192.168.0.100:11231  </span><br><span class="line">        mode tcp #配置TCP模式  </span><br><span class="line">        maxconn 2000  </span><br><span class="line">        balance roundrobin  </span><br><span class="line">        server  ice-192.168.0.128 192.168.0.128:11231 check inter 5000 fall 1 rise 2  </span><br><span class="line">        server  ice-192.168.0.129 192.168.0.129:11231 check inter 5000 fall 1 rise 2  </span><br><span class="line">        server  ice-192.168.0.130 192.168.0.130:11231 check inter 5000 fall 1 rise 2  </span><br><span class="line">        server  ice-192.168.0.131 192.168.0.131:11231 check inter 5000 fall 1 rise 2  </span><br><span class="line">        server  ice-192.168.0.132 192.168.0.132:11231 check inter 5000 fall 1 rise 2  </span><br><span class="line">        server  ice-192.168.0.34 192.168.0.34:11231 check inter 5000 fall 1 rise 2  </span><br><span class="line">        srvtimeout      20000  </span><br><span class="line">  </span><br><span class="line">listen stats_auth 192.168.0.20:80  </span><br><span class="line"># listen stats_auth 192.168.0.21:80 # backup config  </span><br><span class="line">        stats enable  </span><br><span class="line">        stats uri  /admin-status #管理地址  </span><br><span class="line">        stats auth  admin:123456 #管理帐号:管理密码  </span><br><span class="line">        stats admin if TRUE</span><br></pre></td></tr></table></figure><h4 id="邮件通知程序-python实现"><a href="#邮件通知程序-python实现" class="headerlink" title="邮件通知程序(python实现)"></a>邮件通知程序(python实现)</h4><p>#vim  /etc/keepalived/Mailnotify.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/local/bin/python  </span></span><br><span class="line"><span class="comment">#coding: utf-8  </span></span><br><span class="line"><span class="keyword">from</span> email.MIMEMultipart <span class="keyword">import</span> MIMEMultipart  </span><br><span class="line"><span class="keyword">from</span> email.MIMEText <span class="keyword">import</span> MIMEText  </span><br><span class="line"><span class="keyword">from</span> email.MIMEImage <span class="keyword">import</span> MIMEImage  </span><br><span class="line"><span class="keyword">from</span> email.header <span class="keyword">import</span> Header  </span><br><span class="line"><span class="keyword">import</span> sys  </span><br><span class="line"><span class="keyword">import</span> smtplib  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#---------------------------------------------------------------  </span></span><br><span class="line"><span class="comment"># Name:        Mailnotify.py  </span></span><br><span class="line"><span class="comment"># Purpose:     Mail notify to SA  </span></span><br><span class="line"><span class="comment"># Author:      Liutiansi  </span></span><br><span class="line"><span class="comment"># Email:       liutiansi@gamil.com  </span></span><br><span class="line"><span class="comment"># Created:     2011/03/09  </span></span><br><span class="line"><span class="comment"># Copyright:   (c) 2011  </span></span><br><span class="line"><span class="comment">#--------------------------------------------------------------  </span></span><br><span class="line">strFrom = <span class="string">'admin@domain.com'</span>  </span><br><span class="line">strTo = <span class="string">'liutiansi@gmail.com'</span>  </span><br><span class="line">smtp_server=<span class="string">'smtp.domain.com'</span>  </span><br><span class="line">smtp_pass=<span class="string">'123456'</span>  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> sys.argv[<span class="number">1</span>]!=<span class="string">"master"</span> <span class="keyword">and</span> sys.argv[<span class="number">1</span>]!=<span class="string">"backup"</span>  <span class="keyword">and</span> sys.argv[<span class="number">1</span>]!=<span class="string">"fault"</span>:  </span><br><span class="line">    sys.exit()  </span><br><span class="line"><span class="keyword">else</span>:  </span><br><span class="line">    notify_type=sys.argv[<span class="number">1</span>]  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">mail_title=<span class="string">'[紧急]负载均衡器邮件通知'</span>  </span><br><span class="line">mail_body_plain=notify_type+<span class="string">'被激活，请做好应急处理。'</span>  </span><br><span class="line">mail_body_html=<span class="string">'&lt;b&gt;&lt;font color=red&gt;'</span>+notify_type+<span class="string">'被激活，请做好应急处理。&lt;/font&gt;&lt;/b&gt;'</span>  </span><br><span class="line">  </span><br><span class="line">msgRoot = MIMEMultipart(<span class="string">'related'</span>)  </span><br><span class="line">msgRoot[<span class="string">'Subject'</span>] =Header(mail_title,<span class="string">'utf-8'</span>)  </span><br><span class="line">msgRoot[<span class="string">'From'</span>] = strFrom  </span><br><span class="line">msgRoot[<span class="string">'To'</span>] = strTo  </span><br><span class="line">  </span><br><span class="line">msgAlternative = MIMEMultipart(<span class="string">'alternative'</span>)  </span><br><span class="line">msgRoot.attach(msgAlternative)  </span><br><span class="line">  </span><br><span class="line">msgText = MIMEText(mail_body_plain, <span class="string">'plain'</span>, <span class="string">'utf-8'</span>)  </span><br><span class="line">msgAlternative.attach(msgText)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">msgText = MIMEText(mail_body_html, <span class="string">'html'</span>,<span class="string">'utf-8'</span>)  </span><br><span class="line">msgAlternative.attach(msgText)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">smtp = smtplib.SMTP()  </span><br><span class="line">smtp.connect(smtp_server)  </span><br><span class="line">smtp.login(smtp_user,smtp_pass)  </span><br><span class="line">smtp.sendmail(strFrom, strTo, msgRoot.as_string())  </span><br><span class="line">smtp.quit()</span><br></pre></td></tr></table></figure><p>注：修改成系统python实际路径“#!/usr/local/bin/python”(第一行)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#chmod +x /etc/keepalived/Mailnotify.py</span><br><span class="line">#/usr/local/haproxy/sbin/haproxy -f /usr/local/haproxy/etc/haproxy.cfg</span><br><span class="line">#service keepalived start</span><br></pre></td></tr></table></figure><h4 id="查看VRRP通讯记录"><a href="#查看VRRP通讯记录" class="headerlink" title="查看VRRP通讯记录"></a>查看VRRP通讯记录</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#tcpdump vrrp</span><br><span class="line"></span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span><br><span class="line">listening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes</span><br><span class="line">15:49:05.270017  IP 192.168.0.20 &gt; VRRP.MCAST.NET: VRRPv2, Advertisement, vrid 50,  prio 100, authtype simple, intvl 1s, length 20</span><br></pre></td></tr></table></figure><h2 id="Haproxy界面"><a href="#Haproxy界面" class="headerlink" title="Haproxy界面"></a>Haproxy界面</h2><p>访问<a href="http://192.168.0.20/admin-status，输入帐号admin密码123456进入管理监控平台。" target="_blank" rel="noopener">http://192.168.0.20/admin-status，输入帐号admin密码123456进入管理监控平台。</a></p><p><img src="/articles/95471f15/0.39497361121703545.png" alt="点击在新窗口中浏览此图片"></p><p>haproxy-1.4.9以后版本最大的亮点是添加了手工启用/禁用功能，对升级变更应用时非常有用。</p><h2 id="邮件通知"><a href="#邮件通知" class="headerlink" title="邮件通知"></a>邮件通知</h2><p><img src="/articles/95471f15/0.6085717838496976.png" alt="点击在新窗口中浏览此图片"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;​        Haproxy是稳定、高性能、高可用性的负载均衡解决方案，支持HTTP及TCP代理后端服务器池，因支持强大灵活的7层acl规则，广泛作为HTTP反向代理。本文则详细介绍如何利用它的四层交换与Keepalived实现一个负载均衡器，适用于Socket、ICE、Mail、Mysql、私有通讯等任意TCP服务。系统架构图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/95471f15/0.027865917857136546.png&quot; alt=&quot;点击在新窗口中浏览此图片&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Haproxy" scheme="https://wandouduoduo.netlify.com/tags/Haproxy/"/>
    
      <category term="Keepalived" scheme="https://wandouduoduo.netlify.com/tags/Keepalived/"/>
    
  </entry>
  
  <entry>
    <title>centos7安装redis教程</title>
    <link href="https://wandouduoduo.netlify.com/articles/39f481b5.html"/>
    <id>https://wandouduoduo.netlify.com/articles/39f481b5.html</id>
    <published>2019-11-02T02:54:48.000Z</published>
    <updated>2019-11-04T01:49:45.698Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a><strong>安装</strong></h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过wget方式直接在linux上下载Redis</span></span><br><span class="line">wget http://download.redis.io/releases/redis-4.0.9.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment">#解压下载的redis-2.6.17.tar.gz 文件</span></span><br><span class="line">tar xzf redis-4.0.9.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment">#进入解压后的文件夹</span></span><br><span class="line"><span class="built_in">cd</span>  redis-4.0.9</span><br><span class="line"></span><br><span class="line"><span class="comment">#编译安装</span></span><br><span class="line">make</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><ul><li><p>通过执行src文件夹下的redis-server，可以启动redis服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./src/redis-server</span><br></pre></td></tr></table></figure></li><li><p>通过执行src文件夹下的redis-cli， 可以访问redis服务。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">./src/redis-cli</span><br><span class="line">redis&gt; <span class="built_in">set</span> foo bar</span><br><span class="line">Ok</span><br><span class="line">redis&gt; get foo</span><br><span class="line"><span class="string">"bar"</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="排错"><a href="#排错" class="headerlink" title="排错"></a><strong>排错</strong></h2><p>CentOS5.7默认没有安装gcc，这会导致我们无法make成功。使用yum安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install gcc</span><br></pre></td></tr></table></figure><p>make时报如下错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">zmalloc.h:50:31: error: jemalloc/jemalloc.h: No such file or directory</span><br><span class="line">zmalloc.h:55:2: error: #error &quot;Newer version of jemalloc required&quot;</span><br><span class="line">make[1]: *** [adlist.o] Error 1</span><br><span class="line">make[1]: Leaving directory `/data0/src/redis-2.6.2/src&apos;</span><br><span class="line">make: *** [all] Error 2</span><br></pre></td></tr></table></figure><p>原因是jemalloc重载了Linux下的ANSI C的malloc和free函数。解决办法：make时添加参数。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make MALLOC=libc</span><br></pre></td></tr></table></figure><p>make之后，会出现一句提示</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hint: To run <span class="string">'make test'</span> is a good idea ;)</span><br></pre></td></tr></table></figure><p>但是不测试，通常是可以使用的。若我们运行make test ，会有如下提示</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[devnote@devnote src]$ make <span class="built_in">test</span></span><br><span class="line">You need tcl 8.5 or newer <span class="keyword">in</span> order to run the Redis <span class="built_in">test</span></span><br><span class="line">make: ***[<span class="built_in">test</span>] Error_1</span><br></pre></td></tr></table></figure><p>解决办法是用yum安装tcl8.5（或去tcl的官方网站<a href="http://www.tcl.tk/下载8.5版本，并参考官网介绍进行安装）" target="_blank" rel="noopener">http://www.tcl.tk/下载8.5版本，并参考官网介绍进行安装）</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install tcl</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;&lt;strong&gt;安装&lt;/strong&gt;&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#通过wget方式直接在linux上下载Redis&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;wget http://download.redis.io/releases/redis-4.0.9.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#解压下载的redis-2.6.17.tar.gz 文件&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tar xzf redis-4.0.9.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#进入解压后的文件夹&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt;  redis-4.0.9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#编译安装&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;make&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Redis" scheme="https://wandouduoduo.netlify.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>haproxy+keepalived实现Web服务器负载均衡</title>
    <link href="https://wandouduoduo.netlify.com/articles/c0e454fd.html"/>
    <id>https://wandouduoduo.netlify.com/articles/c0e454fd.html</id>
    <published>2019-11-02T02:17:03.000Z</published>
    <updated>2019-11-04T01:49:45.699Z</updated>
    
    <content type="html"><![CDATA[<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p><strong>操作系统</strong>：CentOS 6.X 64位</p><p><strong>Web服务器</strong>：192.168.21.127、192.168.21.128</p><p><strong>站点</strong>：bbs.osyunwei.com和sns.osyunwei.com部署在两台Web服务器上</p><h2 id="实现目的"><a href="#实现目的" class="headerlink" title="实现目的"></a><strong>实现目的</strong></h2><p>增加两台服务器（主主模式），通过HAProxy+Keepalived实现Web服务器负载均衡</p><h2 id="架构规划"><a href="#架构规划" class="headerlink" title="架构规划"></a><strong>架构规划</strong></h2><p>HAProxy服务器：192.168.21.129、192.168.21.130</p><p>虚拟服务器（VIP）：192.168.21.253、192.168.21.254</p><h2 id="验证说明"><a href="#验证说明" class="headerlink" title="验证说明"></a><strong>验证说明</strong></h2><ol><li>VIP：192.168.21.253指向192.168.21.129；VIP：192.168.21.254指向192.168.21.130；</li><li>当192.168.21.129宕机时，VIP：192.168.21.253漂移到192.168.21.130上；</li><li>当192.168.21.130宕机时，VIP：192.168.21.254漂移到192.168.21.129上；</li></ol><p>这样的主主模式好处是，两台服务器在提供服务的同时，又互为对方的备份服务器。</p><a id="more"></a><h2 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a><strong>操作步骤</strong></h2><p><strong>两台HAProxy服务器上分别操作</strong></p><h4 id="关闭SElinux"><a href="#关闭SElinux" class="headerlink" title="关闭SElinux"></a>关闭SElinux</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/selinux/config</span><br><span class="line"></span><br><span class="line"><span class="comment">#SELINUX=enforcing #注释掉</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#SELINUXTYPE=targeted #注释掉</span></span><br><span class="line"></span><br><span class="line">SELINUX=disabled <span class="comment">#增加</span></span><br><span class="line"></span><br><span class="line">:wq!  <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">setenforce 0 <span class="comment">#使配置立即生效</span></span><br></pre></td></tr></table></figure><h4 id="配置防火墙"><a href="#配置防火墙" class="headerlink" title="配置防火墙"></a>配置防火墙</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sysconfig/iptables  <span class="comment">#编辑</span></span><br><span class="line"></span><br><span class="line">-A RH-Firewall-1-INPUT -d 224.0.0.18 -j ACCEPT  <span class="comment">#允许组播地址通信</span></span><br><span class="line"></span><br><span class="line">-A RH-Firewall-1-INPUT -p    vrrp    -j ACCEPT  <span class="comment">#允许VRRP（虚拟路由器冗余协）通信</span></span><br><span class="line"></span><br><span class="line">-A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT  <span class="comment">#允许80端口通过防火墙</span></span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">/etc/init.d/iptables restart <span class="comment">#重启防火墙使配置生效</span></span><br></pre></td></tr></table></figure><h4 id="安装HAProxy"><a href="#安装HAProxy" class="headerlink" title="安装HAProxy"></a>安装HAProxy</h4><h6 id="创建HAProxy运行账户和组"><a href="#创建HAProxy运行账户和组" class="headerlink" title="创建HAProxy运行账户和组"></a>创建HAProxy运行账户和组</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">groupadd haproxy #添加haproxy组</span><br><span class="line"></span><br><span class="line">useradd -g haproxy haproxy -s /bin/false #创建nginx运行账户haproxy并加入到haproxy组，不允许haproxy用户直接登录系统</span><br></pre></td></tr></table></figure><h6 id="安装编译工具"><a href="#安装编译工具" class="headerlink" title="安装编译工具"></a>安装编译工具</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install  gcc gcc-c++ make openssl-devel kernel-devel</span><br></pre></td></tr></table></figure><h6 id="安装HAProxy-1"><a href="#安装HAProxy-1" class="headerlink" title="安装HAProxy"></a>安装HAProxy</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">HAProxy下载地址：http://haproxy.1wt.eu/download/1.4/src/haproxy-1.4.24.tar.gz</span><br><span class="line"></span><br><span class="line">上传haproxy-1.4.24.tar.gz到/usr/<span class="built_in">local</span>/src目录中</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src <span class="comment">#进入软件包存放目录</span></span><br><span class="line"></span><br><span class="line">tar zxvf haproxy-1.4.24.tar.gz <span class="comment">#解压</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span>  haproxy-1.4.24  <span class="comment">#进入安装目录</span></span><br><span class="line"></span><br><span class="line">make  TARGET=linux26 CPU=x86_64  PREFIX=/usr/<span class="built_in">local</span>/haprpxy  <span class="comment">#编译</span></span><br><span class="line"></span><br><span class="line">make install PREFIX=/usr/<span class="built_in">local</span>/haproxy  <span class="comment">#安装</span></span><br><span class="line"></span><br><span class="line">参数说明：</span><br><span class="line"></span><br><span class="line">TARGET=linux26</span><br><span class="line"></span><br><span class="line">\<span class="comment">#使用uname -r查看内核，如：2.6.18-371.el5，此时该参数就为linux26</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#kernel 大于2.6.28的用：TARGET=linux2628</span></span><br><span class="line"></span><br><span class="line">CPU=x86_64   <span class="comment">#使用uname -r查看系统信息，如x86_64 x86_64 x86_64 GNU/Linux，此时该参数就为x86_64</span></span><br><span class="line"></span><br><span class="line">PREFIX=/usr/<span class="built_in">local</span>/haprpxy   <span class="comment">#/usr/local/haprpxy为haprpxy安装路径</span></span><br></pre></td></tr></table></figure><h6 id="设置HAProxy"><a href="#设置HAProxy" class="headerlink" title="设置HAProxy"></a>设置HAProxy</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p  /usr/<span class="built_in">local</span>/haproxy/conf  <span class="comment">#创建配置文件目录</span></span><br><span class="line"></span><br><span class="line">mkdir -p /etc/haproxy  <span class="comment">#创建配置文件目录</span></span><br><span class="line"></span><br><span class="line">cp /usr/<span class="built_in">local</span>/src/haproxy-1.4.24/examples/haproxy.cfg  /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg  <span class="comment">#拷贝配置模板文件</span></span><br><span class="line"></span><br><span class="line">ln -s  /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg   /etc/haproxy/haproxy.cfg  <span class="comment">#添加配置文件软连接</span></span><br><span class="line"></span><br><span class="line">cp -r  /usr/<span class="built_in">local</span>/src/haproxy-1.4.24/examples/errorfiles  /usr/<span class="built_in">local</span>/haproxy/errorfiles  <span class="comment">#拷贝错误页面</span></span><br><span class="line"></span><br><span class="line">ln -s  /usr/<span class="built_in">local</span>/haproxy/errorfiles  /etc/haproxy/errorfiles  <span class="comment">#添加软连接</span></span><br><span class="line"></span><br><span class="line">mkdir -p  /usr/<span class="built_in">local</span>/haproxy/<span class="built_in">log</span>  <span class="comment">#创建日志文件目录</span></span><br><span class="line"></span><br><span class="line">touch  /usr/<span class="built_in">local</span>/haproxy/<span class="built_in">log</span>/haproxy.log  <span class="comment">#创建日志文件</span></span><br><span class="line"></span><br><span class="line">ln -s  /usr/<span class="built_in">local</span>/haproxy/<span class="built_in">log</span>/haproxy.log  /var/<span class="built_in">log</span>/haproxy.log  <span class="comment">#添加软连接</span></span><br><span class="line"></span><br><span class="line">cp /usr/<span class="built_in">local</span>/src/haproxy-1.4.24/examples/haproxy.init  /etc/rc.d/init.d/haproxy  <span class="comment">#拷贝开机启动文件</span></span><br><span class="line"></span><br><span class="line">chmod +x  /etc/rc.d/init.d/haproxy  <span class="comment">#添加脚本执行权限</span></span><br><span class="line"></span><br><span class="line">chkconfig haproxy on  <span class="comment">#设置开机启动</span></span><br><span class="line"></span><br><span class="line">ln -s  /usr/<span class="built_in">local</span>/haproxy/sbin/haproxy  /usr/sbin  <span class="comment">#添加软连接</span></span><br></pre></td></tr></table></figure><h6 id="配置haproxy-cfg参数"><a href="#配置haproxy-cfg参数" class="headerlink" title="配置haproxy.cfg参数"></a>配置haproxy.cfg参数</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line">cp  /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg   /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg-bak  <span class="comment">#备份</span></span><br><span class="line"></span><br><span class="line">vim  /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg  <span class="comment">#编辑，修改</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#####################################################################</span></span><br><span class="line"></span><br><span class="line">\<span class="comment"># this config needs haproxy-1.1.28 or haproxy-1.2.1</span></span><br><span class="line"></span><br><span class="line">global</span><br><span class="line"></span><br><span class="line"><span class="built_in">log</span> 127.0.0.1   local0 <span class="comment">#在本机记录日志</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">log</span> 127.0.0.1   local1 notice</span><br><span class="line"></span><br><span class="line">\<span class="comment">#log loghost    local0 info</span></span><br><span class="line"></span><br><span class="line">maxconn 65535   <span class="comment">#每个进程可用的最大连接数</span></span><br><span class="line"></span><br><span class="line">nbproc  8  <span class="comment">#进程数量，可以设置多个，提高处理效率</span></span><br><span class="line"></span><br><span class="line">chroot /usr/<span class="built_in">local</span>/haproxy  <span class="comment">#haproxy安装目录</span></span><br><span class="line"></span><br><span class="line">uid 500  <span class="comment">#运行haproxy的用户uid（cat /etc/passwd查看）</span></span><br><span class="line"></span><br><span class="line">gid 500  <span class="comment">#运行haproxy的组uid（cat /etc/group查看）</span></span><br><span class="line"></span><br><span class="line">daemon   <span class="comment">#以后台守护进程运行</span></span><br><span class="line"></span><br><span class="line">pidfile /usr/<span class="built_in">local</span>/haproxy/haproxy.pid  <span class="comment">#将所有进程写入pid文件</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#debug   #调试模式</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#quiet   #安装模式</span></span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line"></span><br><span class="line">\<span class="comment">#log     global</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">log</span>  127.0.0.1   local3  <span class="comment">#日志文件设置</span></span><br><span class="line"></span><br><span class="line">mode    http  <span class="comment">#运行模式tcp、http、health</span></span><br><span class="line"></span><br><span class="line">option  httplog</span><br><span class="line"></span><br><span class="line">option  http-pretend-keepalive  <span class="comment">#服务器端保持长连接</span></span><br><span class="line"></span><br><span class="line">option  http-server-close   <span class="comment">#每次请求完毕后主动关闭http通道</span></span><br><span class="line"></span><br><span class="line">option  forceclose    <span class="comment">#服务端响应后主动关闭请求连接，及早释放服务连接，不必等到客户端应答确认</span></span><br><span class="line"></span><br><span class="line">option  httpclose       <span class="comment">#每次请求完毕后主动关闭http通道</span></span><br><span class="line"></span><br><span class="line">option  accept-invalid-http-request       <span class="comment">#接受无效的http请求，一般建议不设置，但是可解决部分杂牌浏览器访问打不开页面问题</span></span><br><span class="line"></span><br><span class="line">option  dontlognull     <span class="comment">#不记录健康检查的日志信息</span></span><br><span class="line"></span><br><span class="line">option  redispatch  <span class="comment">#如果后端有服务器宕机，强制切换到正常服务器</span></span><br><span class="line"></span><br><span class="line">option  abortonclose  <span class="comment">#丢弃由于客户端等待时间过长而关闭连接但仍在haproxy等待队列中的请求</span></span><br><span class="line"></span><br><span class="line">option  forwardfor  except 127.0.0.0/8  <span class="comment">#不记录本机转发的日志</span></span><br><span class="line"></span><br><span class="line">option  originalto  <span class="comment">#记录客户端访问的目的IP</span></span><br><span class="line"></span><br><span class="line">maxconn  65535  <span class="comment">#每个进程可用的最大连接数</span></span><br><span class="line"></span><br><span class="line">balance <span class="built_in">source</span>  <span class="comment">#同一IP地址的所有请求都发送到同一服务器</span></span><br><span class="line"></span><br><span class="line">retries 3   <span class="comment">#三次连接失败，则判断服务不可用</span></span><br><span class="line"></span><br><span class="line">contimeout      5000  <span class="comment">#连接超时</span></span><br><span class="line"></span><br><span class="line">clitimeout      50000 <span class="comment">#客户端超时</span></span><br><span class="line"></span><br><span class="line">srvtimeout      50000 <span class="comment">#服务器超时</span></span><br><span class="line"></span><br><span class="line">timeout check 5s  <span class="comment">#检测超时</span></span><br><span class="line"></span><br><span class="line">timeout http-request 5s  <span class="comment">#http请求超时时间</span></span><br><span class="line"></span><br><span class="line">timeout queue 30s  <span class="comment">#一个请求在队列里的超时时间</span></span><br><span class="line"></span><br><span class="line">timeout http-keep-alive  5s  <span class="comment">#设置http-keep-alive的超时时间</span></span><br><span class="line"></span><br><span class="line">stats refresh 30s <span class="comment">#统计页面自动刷新时间</span></span><br><span class="line"></span><br><span class="line">stats uri  /haproxy-status  <span class="comment">#统计页面URL路径</span></span><br><span class="line"></span><br><span class="line">stats realm haproxy-status  <span class="comment">#统计页面输入密码框提示信息</span></span><br><span class="line"></span><br><span class="line">stats auth admin:123456     <span class="comment">#统计页面用户名和密码</span></span><br><span class="line"></span><br><span class="line">stats hide-version          <span class="comment">#隐藏统计页面上HAProxy版本信息</span></span><br><span class="line"></span><br><span class="line">frontend    web  <span class="comment">#自定义描述信息</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">bind</span> :80  <span class="comment">#监听80端口</span></span><br><span class="line"></span><br><span class="line">acl bbs.osyunwei.com  hdr(host) -i bbs.osyunwei.com  <span class="comment">#规则设置，-i后面是要访问的域名，如果访问bbs.osyunwei.com这个域名，就负载均衡到bbs.osyunwei.com作用域</span></span><br><span class="line"></span><br><span class="line">use_backend bbs.osyunwei.com <span class="keyword">if</span> bbs.osyunwei.com   <span class="comment">#acl和if后面的名称必须相同这里为bbs.osyunwei.com</span></span><br><span class="line"></span><br><span class="line">acl sns.osyunwei.com  hdr(host) -i sns.osyunwei.com  <span class="comment">#规则设置，-i后面是要访问的域名，如果访问sns.osyunwei.com这个域名，就负载均衡到sns.osyunwei.com作用域</span></span><br><span class="line"></span><br><span class="line">use_backend sns.osyunwei.com <span class="keyword">if</span> sns.osyunwei.com</span><br><span class="line"></span><br><span class="line">backend     bbs.osyunwei.com</span><br><span class="line"></span><br><span class="line">mode http</span><br><span class="line"></span><br><span class="line">balance   <span class="built_in">source</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#option  httpchk /index.php  #检测服务器此文件是否存在，如果没有，则认为服务器连接异常，此参数可以不设置</span></span><br><span class="line"></span><br><span class="line">server     192.168.21.127  192.168.21.127:80   check  inter  2000  rise 3  fall  3  weight 100   <span class="comment">#inter  2000 心跳检测时间；rise 3 三次连接成功，表示服务器正常；fall  3 三次连接失败，表示服务器异常； weight 100 权重设置</span></span><br><span class="line"></span><br><span class="line">server     192.168.21.128  192.168.21.128:80   check  inter  2000  rise 3  fall  3  weight 100</span><br><span class="line"></span><br><span class="line">backend     sns.osyunwei.com</span><br><span class="line"></span><br><span class="line">mode http</span><br><span class="line"></span><br><span class="line">balance   <span class="built_in">source</span>  <span class="comment">#设置负载均衡模式，source保存session值，roundrobin轮询模式</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#option  httpchk /index.php  #检测服务器此文件是否存在，如果没有，则认为服务器连接异常，此参数可以不设置</span></span><br><span class="line"></span><br><span class="line">server     192.168.21.127  192.168.21.127:80   check  inter  2000  rise 3  fall  3  weight 100</span><br><span class="line"></span><br><span class="line">server     192.168.21.128  192.168.21.128:80   check  inter  2000  rise 3  fall  3  weight 100</span><br><span class="line"></span><br><span class="line">\<span class="comment">#errorloc  503  http://www.osyunwei.com/404.html</span></span><br><span class="line"></span><br><span class="line">errorfile 403 /etc/haproxy/errorfiles/403.http</span><br><span class="line"></span><br><span class="line">errorfile 500 /etc/haproxy/errorfiles/500.http</span><br><span class="line"></span><br><span class="line">errorfile 502 /etc/haproxy/errorfiles/502.http</span><br><span class="line"></span><br><span class="line">errorfile 503 /etc/haproxy/errorfiles/503.http</span><br><span class="line"></span><br><span class="line">errorfile 504 /etc/haproxy/errorfiles/504.http</span><br><span class="line"></span><br><span class="line">\<span class="comment">#####################################################################</span></span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">service haproxy start <span class="comment">#启动</span></span><br><span class="line"></span><br><span class="line">service haproxy stop  <span class="comment">#关闭</span></span><br><span class="line"></span><br><span class="line">service haproxy restart  <span class="comment">#重启</span></span><br></pre></td></tr></table></figure><h6 id="设置HAProxy日志"><a href="#设置HAProxy日志" class="headerlink" title="设置HAProxy日志"></a>设置HAProxy日志</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">vim  /etc/syslog.conf  <span class="comment">#编辑，在最下边增加</span></span><br><span class="line"></span><br><span class="line">\<span class="comment"># haproxy.log</span></span><br><span class="line"></span><br><span class="line">local0.*          /var/<span class="built_in">log</span>/haproxy.log</span><br><span class="line"></span><br><span class="line">local3.*          /var/<span class="built_in">log</span>/haproxy.log</span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">vi  /etc/sysconfig/syslog   <span class="comment">#编辑修改</span></span><br><span class="line"></span><br><span class="line">SYSLOGD_OPTIONS=<span class="string">"-r -m 0"</span>   <span class="comment">#接收远程服务器日志</span></span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">service syslog restart  <span class="comment">#重启syslog</span></span><br></pre></td></tr></table></figure><h4 id="安装keepalived"><a href="#安装keepalived" class="headerlink" title="安装keepalived"></a>安装keepalived</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">下载keeplived：http://www.keepalived.org/software/keepalived-1.2.12.tar.gz</span><br><span class="line"></span><br><span class="line">上传keepalived-1.2.12.tar.gz到/usr/<span class="built_in">local</span>/src目录</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src</span><br><span class="line"></span><br><span class="line">tar zxvf keepalived-1.2.12.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> keepalived-1.2.12</span><br><span class="line"></span><br><span class="line">./configure  <span class="comment">#配置，必须看到以下提示，说明配置正确，才能继续安装</span></span><br><span class="line"></span><br><span class="line">Use IPVS Framework : Yes</span><br><span class="line"></span><br><span class="line">IPVS sync daemon support : Yes</span><br><span class="line"></span><br><span class="line">Use VRRP Framework       : Yes</span><br><span class="line"></span><br><span class="line">make <span class="comment">#编辑</span></span><br><span class="line"></span><br><span class="line">make install  <span class="comment">#安装</span></span><br><span class="line"></span><br><span class="line">cp /usr/<span class="built_in">local</span>/etc/sysconfig/keepalived  /etc/sysconfig/</span><br><span class="line"></span><br><span class="line">mkdir /etc/keepalived</span><br><span class="line"></span><br><span class="line">cp /usr/<span class="built_in">local</span>/etc/keepalived/keepalived.conf /etc/keepalived/</span><br><span class="line"></span><br><span class="line">cp /usr/<span class="built_in">local</span>/sbin/keepalived /usr/sbin/</span><br><span class="line"></span><br><span class="line">cp /usr/<span class="built_in">local</span>/etc/rc.d/init.d/keepalived  /etc/rc.d/init.d/</span><br><span class="line"></span><br><span class="line">chmod +x /etc/rc.d/init.d/keepalived  <span class="comment">#添加执行权限</span></span><br><span class="line"></span><br><span class="line">chkconfig keepalived on  <span class="comment">#设置开机启动</span></span><br><span class="line"></span><br><span class="line">service keepalived start <span class="comment">#启动</span></span><br><span class="line"></span><br><span class="line">service keepalived stop  <span class="comment">#关闭</span></span><br><span class="line"></span><br><span class="line">service keepalived restart  <span class="comment">#重启</span></span><br></pre></td></tr></table></figure><h6 id="配置keepalived"><a href="#配置keepalived" class="headerlink" title="配置keepalived"></a>配置keepalived</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line">cp /etc/keepalived/keepalived.conf  /etc/keepalived/keepalived.conf-bak</span><br><span class="line"></span><br><span class="line">vi /etc/keepalived/keepalived.conf  <span class="comment">#编辑，修改为以下代码</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#########################################################</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#以下为192.168.21.129服务器：</span></span><br><span class="line"></span><br><span class="line">! Configuration File <span class="keyword">for</span> keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line"></span><br><span class="line">notification_email &#123;</span><br><span class="line"></span><br><span class="line">acassen@firewall.loc</span><br><span class="line"></span><br><span class="line">failover@firewall.loc</span><br><span class="line"></span><br><span class="line">sysadmin@firewall.loc</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">notification_email_from Alexandre.Cassen@firewall.loc</span><br><span class="line"></span><br><span class="line">smtp_server 192.168.200.1</span><br><span class="line"></span><br><span class="line">smtp_connect_timeout 30</span><br><span class="line"></span><br><span class="line">router_id LVS_DEVEL</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script chk_haproxy &#123;</span><br><span class="line"></span><br><span class="line">script <span class="string">"/etc/keepalived/check_haproxy.sh"</span>  <span class="comment">#HAproxy服务监控脚本</span></span><br><span class="line"></span><br><span class="line">interval 2</span><br><span class="line"></span><br><span class="line">weight 2</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line"></span><br><span class="line">state MASTER</span><br><span class="line"></span><br><span class="line">interface eth0</span><br><span class="line"></span><br><span class="line">virtual_router_id 51</span><br><span class="line"></span><br><span class="line">priority 100</span><br><span class="line"></span><br><span class="line">advert_int 1</span><br><span class="line"></span><br><span class="line">authentication &#123;</span><br><span class="line"></span><br><span class="line">auth_type PASS</span><br><span class="line"></span><br><span class="line">auth_pass 1111</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">track_script &#123;</span><br><span class="line"></span><br><span class="line">chk_haproxy <span class="comment">#监测haproxy进程状态</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_ipaddress &#123;</span><br><span class="line"></span><br><span class="line">192.168.21.253</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">notify_master <span class="string">"/etc/keepalived/clean_arp.sh  192.168.21.253"</span>  <span class="comment">#更新虚拟服务器（VIP）地址的arp记录到网关</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_2 &#123;</span><br><span class="line"></span><br><span class="line">state BACKUP</span><br><span class="line"></span><br><span class="line">interface eth0</span><br><span class="line"></span><br><span class="line">virtual_router_id 52</span><br><span class="line"></span><br><span class="line">priority 99</span><br><span class="line"></span><br><span class="line">advert_int 1</span><br><span class="line"></span><br><span class="line">authentication &#123;</span><br><span class="line"></span><br><span class="line">auth_type PASS</span><br><span class="line"></span><br><span class="line">auth_pass 1111</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_ipaddress &#123;</span><br><span class="line"></span><br><span class="line">192.168.21.254</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">notify_master <span class="string">"/etc/keepalived/clean_arp.sh  192.168.21.254"</span>  <span class="comment">#更新虚拟服务器（VIP）地址的arp记录到网关</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">\<span class="comment">#########################################################</span></span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#########################################################</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#以下为192.168.21.130服务器：</span></span><br><span class="line"></span><br><span class="line">192.168.21.130</span><br><span class="line"></span><br><span class="line">! Configuration File <span class="keyword">for</span> keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line"></span><br><span class="line">notification_email &#123;</span><br><span class="line"></span><br><span class="line">acassen@firewall.loc</span><br><span class="line"></span><br><span class="line">failover@firewall.loc</span><br><span class="line"></span><br><span class="line">sysadmin@firewall.loc</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">notification_email_from Alexandre.Cassen@firewall.loc</span><br><span class="line"></span><br><span class="line">smtp_server 192.168.200.1</span><br><span class="line"></span><br><span class="line">smtp_connect_timeout 30</span><br><span class="line"></span><br><span class="line">router_id LVS_DEVEL</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script chk_haproxy &#123;</span><br><span class="line"></span><br><span class="line">script <span class="string">"/etc/keepalived/check_haproxy.sh"</span>  <span class="comment">#HAproxy服务监控脚本</span></span><br><span class="line"></span><br><span class="line">interval 2</span><br><span class="line"></span><br><span class="line">weight 2</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line"></span><br><span class="line">state BACKUP</span><br><span class="line"></span><br><span class="line">interface eth0</span><br><span class="line"></span><br><span class="line">virtual_router_id 51</span><br><span class="line"></span><br><span class="line">priority 99</span><br><span class="line"></span><br><span class="line">advert_int 1</span><br><span class="line"></span><br><span class="line">authentication &#123;</span><br><span class="line"></span><br><span class="line">auth_type PASS</span><br><span class="line"></span><br><span class="line">auth_pass 1111</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">track_script &#123;</span><br><span class="line"></span><br><span class="line">chk_haproxy <span class="comment">#监测haproxy进程状态</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_ipaddress &#123;</span><br><span class="line"></span><br><span class="line">192.168.21.253</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">notify_master <span class="string">"/etc/keepalived/clean_arp.sh  192.168.21.253"</span>  <span class="comment">#更新虚拟服务器（VIP）地址的arp记录到网关</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_2 &#123;</span><br><span class="line"></span><br><span class="line">state MASTER</span><br><span class="line"></span><br><span class="line">interface eth0</span><br><span class="line"></span><br><span class="line">virtual_router_id 52</span><br><span class="line"></span><br><span class="line">priority 100</span><br><span class="line"></span><br><span class="line">advert_int 1</span><br><span class="line"></span><br><span class="line">authentication &#123;</span><br><span class="line"></span><br><span class="line">auth_type PASS</span><br><span class="line"></span><br><span class="line">auth_pass 1111</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_ipaddress &#123;</span><br><span class="line"></span><br><span class="line">192.168.21.254</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">notify_master <span class="string">"/etc/keepalived/clean_arp.sh  192.168.21.254"</span>  <span class="comment">#更新虚拟服务器（VIP）地址的arp记录到网关</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">\<span class="comment">#########################################################</span></span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br></pre></td></tr></table></figure><h4 id="设置HAproxy服务监控脚本"><a href="#设置HAproxy服务监控脚本" class="headerlink" title="设置HAproxy服务监控脚本"></a>设置HAproxy服务监控脚本</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">vim  /etc/keepalived/check_haproxy.sh <span class="comment">#编辑，添加以下代码</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#########################################################</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">A=`ps -C haproxy --no-header | wc -l`</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$A</span> -eq 0 ]</span><br><span class="line"></span><br><span class="line"><span class="keyword">then</span> service haproxy start</span><br><span class="line"></span><br><span class="line">sleep 3</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ `ps -C haproxy --no-header | wc -l ` -eq 0 ]</span><br><span class="line"></span><br><span class="line"><span class="keyword">then</span> service keepalived stop</span><br><span class="line"></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#########################################################</span></span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">chmod +x /etc/keepalived/check_haproxy.sh   <span class="comment">#添加执行权限</span></span><br></pre></td></tr></table></figure><h4 id="设置更新虚拟服务器（VIP）地址的arp记录到网关脚本"><a href="#设置更新虚拟服务器（VIP）地址的arp记录到网关脚本" class="headerlink" title="设置更新虚拟服务器（VIP）地址的arp记录到网关脚本"></a>设置更新虚拟服务器（VIP）地址的arp记录到网关脚本</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">vim  /etc/keepalived/clean_arp.sh  <span class="comment">#编辑，添加以下代码</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">VIP=<span class="variable">$1</span></span><br><span class="line"></span><br><span class="line">GATEWAY=192.168.21.2 <span class="comment">#网关地址</span></span><br><span class="line"></span><br><span class="line">/sbin/arping -I eth0 -c 5 -s <span class="variable">$VIP</span> <span class="variable">$GATEWAY</span> &amp;&gt;/dev/null</span><br><span class="line"></span><br><span class="line">:wq!  <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">chmod +x /etc/keepalived/clean_arp.sh  <span class="comment">#添加脚本执行权限</span></span><br></pre></td></tr></table></figure><h4 id="系统内核优化"><a href="#系统内核优化" class="headerlink" title="系统内核优化"></a>系统内核优化</h4><p>在两台HAProxy服务器上分别操作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">sed -i &quot;s/net.ipv4.ip_forward = 0/net.ipv4.ip_forward = 1/g&quot; &apos;/etc/sysctl.conf&apos;</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.core.somaxconn = 262144&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.core.netdev_max_backlog = 262144&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.core.wmem_default = 8388608&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.core.rmem_default = 8388608&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.core.rmem_max = 16777216&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.core.wmem_max = 16777216&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.route.gc_timeout = 20&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.ip_local_port_range = 1025 65535&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_retries2 = 5&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_fin_timeout = 30&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_syn_retries = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_synack_retries = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_timestamps = 0&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_tw_recycle = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_tw_reuse = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_keepalive_time = 120&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_keepalive_probes = 3&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_keepalive_intvl = 15&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_max_tw_buckets = 200000&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_max_orphans = 3276800&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_max_syn_backlog = 262144&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_wmem = 8192 131072 16777216&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_rmem = 32768 131072 16777216&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_mem = 94500000 915000000 927000000&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.ip_conntrack_max = 25000000&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.netfilter.ip_conntrack_max = 25000000&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.netfilter.ip_conntrack_tcp_timeout_established = 180&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.netfilter.ip_conntrack_tcp_timeout_time_wait = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.netfilter.ip_conntrack_tcp_timeout_close_wait = 60&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.netfilter.ip_conntrack_tcp_timeout_fin_wait = 120&quot; &gt;&gt; /etc/sysctl.conf</span><br></pre></td></tr></table></figure><h2 id="测试验证"><a href="#测试验证" class="headerlink" title="测试验证"></a>测试验证</h2><h4 id="测试HAProxy-Keepalived是否正常运行"><a href="#测试HAProxy-Keepalived是否正常运行" class="headerlink" title="测试HAProxy+Keepalived是否正常运行"></a><strong>测试HAProxy+Keepalived是否正常运行</strong></h4><h6 id="打开HAProxy监控页面"><a href="#打开HAProxy监控页面" class="headerlink" title="打开HAProxy监控页面"></a>打开HAProxy监控页面</h6><p><a href="http://bbs.osyunwei.com/haproxy-status" target="_blank" rel="noopener">http://bbs.osyunwei.com/haproxy-status</a></p><p>输入用户名/密码： admin/123456</p><p>登录之后如下图所示</p><p><img src="/articles/c0e454fd/2883.jpg" alt="2883"></p><p><img src="/articles/c0e454fd/2884.jpg" alt="2884"></p><h6 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h6><p>bbs.osyunwei.com 解析到192.168.21.253；</p><p>sns.osyunwei.com 解析到192.168.21.254；</p><p>在两台HAProxy服务器：192.168.21.129、192.168.21.130上执行命令：ip addr</p><p>如下图所示:</p><p><img src="/articles/c0e454fd/2885.jpg" alt="2885"></p><p><img src="/articles/c0e454fd/haproxy-keepalived%E5%AE%9E%E7%8E%B0Web%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%5C2886.jpg" alt="2886"></p><p>可以看出现在VIP：192.168.21.253指向192.168.21.129；VIP：192.168.21.254指向192.168.21.130；</p><p>在浏览器中打开</p><p><a href="http://bbs.osyunwei.com/" target="_blank" rel="noopener">http://bbs.osyunwei.com/</a></p><p><a href="http://sns.osyunwei.com/" target="_blank" rel="noopener">http://sns.osyunwei.com/</a></p><p>如下图所示：</p><p><img src="/articles/c0e454fd/2887.jpg" alt="2887"></p><p>此时，bbs和sns域名都被均衡到192.168.21.127上面</p><h6 id="停止192-168-21-127上面的nginx服务"><a href="#停止192-168-21-127上面的nginx服务" class="headerlink" title="停止192.168.21.127上面的nginx服务"></a>停止192.168.21.127上面的nginx服务</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service nginx stop</span><br></pre></td></tr></table></figure><p>继续打开上面的两个网址，如下图所示：</p><p><img src="/articles/c0e454fd/2888.jpg" alt="2888"></p><p>此时，bbs和sns域名都被均衡到192.168.21.128上面（由于192.168.21.127服务器nginx服务被关闭，实现了故障转移）</p><h6 id="关闭192-168-21-129上面的keepalived服务"><a href="#关闭192-168-21-129上面的keepalived服务" class="headerlink" title="关闭192.168.21.129上面的keepalived服务"></a>关闭192.168.21.129上面的keepalived服务</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service  keepalived  stop</span><br></pre></td></tr></table></figure><p>此时，在两台HAProxy服务器：192.168.21.129、192.168.21.130上执行命令：ip addr</p><p>如下图所示：</p><p><img src="/articles/c0e454fd/2889.jpg" alt="2889"></p><p><img src="/articles/c0e454fd/2890.jpg" alt="2890"></p><p>可以看出VIP：192.168.21.253和192.168.21.254均指向到192.168.21.130；</p><p>此时，打开<a href="http://bbs.osyunwei.com/如下图所示：" target="_blank" rel="noopener">http://bbs.osyunwei.com/如下图所示：</a></p><p><img src="/articles/c0e454fd/2891.jpg" alt="2891"></p><p>可以正常访问</p><h6 id="恢复192-168-21-129上面的keepalived服务，恢复192-168-21-127上面的nginx服务"><a href="#恢复192-168-21-129上面的keepalived服务，恢复192-168-21-127上面的nginx服务" class="headerlink" title="恢复192.168.21.129上面的keepalived服务，恢复192.168.21.127上面的nginx服务"></a>恢复192.168.21.129上面的keepalived服务，恢复192.168.21.127上面的nginx服务</h6><p>停止192.168.21.130上面的Keepalived服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service keepalived stop</span><br></pre></td></tr></table></figure><p>在两台HAProxy服务器：192.168.21.129、192.168.21.130上执行命令：ip addr</p><p>如下图所示：</p><p><img src="/articles/c0e454fd/2892.jpg" alt="2892"></p><p><img src="/articles/c0e454fd/2893.jpg" alt="2893"></p><p>可以看出VIP：192.168.21.253和192.168.21.254均指向到192.168.21.129；</p><p>此时，打开<a href="http://sns.osyunwei.com/如下图所示：" target="_blank" rel="noopener">http://sns.osyunwei.com/如下图所示：</a></p><p><img src="/articles/c0e454fd/2894.jpg" alt="2894"></p><p>可以正常访问</p><p>备注：</p><p>查看HAProxy日志文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tail -f /var/log/haproxy.log</span><br></pre></td></tr></table></figure><p><strong>至此，HAProxy+Keepalived实现Web服务器负载均衡配置完成。</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;环境&quot;&gt;&lt;a href=&quot;#环境&quot; class=&quot;headerlink&quot; title=&quot;环境&quot;&gt;&lt;/a&gt;环境&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;操作系统&lt;/strong&gt;：CentOS 6.X 64位&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Web服务器&lt;/strong&gt;：192.168.21.127、192.168.21.128&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;站点&lt;/strong&gt;：bbs.osyunwei.com和sns.osyunwei.com部署在两台Web服务器上&lt;/p&gt;
&lt;h2 id=&quot;实现目的&quot;&gt;&lt;a href=&quot;#实现目的&quot; class=&quot;headerlink&quot; title=&quot;实现目的&quot;&gt;&lt;/a&gt;&lt;strong&gt;实现目的&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;增加两台服务器（主主模式），通过HAProxy+Keepalived实现Web服务器负载均衡&lt;/p&gt;
&lt;h2 id=&quot;架构规划&quot;&gt;&lt;a href=&quot;#架构规划&quot; class=&quot;headerlink&quot; title=&quot;架构规划&quot;&gt;&lt;/a&gt;&lt;strong&gt;架构规划&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;HAProxy服务器：192.168.21.129、192.168.21.130&lt;/p&gt;
&lt;p&gt;虚拟服务器（VIP）：192.168.21.253、192.168.21.254&lt;/p&gt;
&lt;h2 id=&quot;验证说明&quot;&gt;&lt;a href=&quot;#验证说明&quot; class=&quot;headerlink&quot; title=&quot;验证说明&quot;&gt;&lt;/a&gt;&lt;strong&gt;验证说明&lt;/strong&gt;&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;VIP：192.168.21.253指向192.168.21.129；VIP：192.168.21.254指向192.168.21.130；&lt;/li&gt;
&lt;li&gt;当192.168.21.129宕机时，VIP：192.168.21.253漂移到192.168.21.130上；&lt;/li&gt;
&lt;li&gt;当192.168.21.130宕机时，VIP：192.168.21.254漂移到192.168.21.129上；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这样的主主模式好处是，两台服务器在提供服务的同时，又互为对方的备份服务器。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Haproxy" scheme="https://wandouduoduo.netlify.com/tags/Haproxy/"/>
    
      <category term="Keepalived" scheme="https://wandouduoduo.netlify.com/tags/Keepalived/"/>
    
  </entry>
  
  <entry>
    <title>haproxy+keepalived实现高可用负载均衡</title>
    <link href="https://wandouduoduo.netlify.com/articles/9ad4df0e.html"/>
    <id>https://wandouduoduo.netlify.com/articles/9ad4df0e.html</id>
    <published>2019-11-02T01:53:34.000Z</published>
    <updated>2019-11-04T01:49:45.711Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>在运维的日常工作中和很多服务打交道，为了保证各个服务健康稳定运行，高可用和高负载是在一个服务搭建好后，必须要考虑的问题。本文介绍了一种常用的高可用和负载均衡的解决方案：KA+HA(haproxy+keepalived)</p><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>haproxy keepalived  主：192.168.1.192<br>haproxy keepalived  备：192.168.1.193<br>vip：192.168.1.200<br>web：192.168.1.187:80 </p><p>​            192.168.1.187:8000</p><h2 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h2><p><img src="/articles/9ad4df0e/0.115069789831175.png" alt="img"></p><a id="more"></a><h2 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h2><p>在192.168.1.192上：<br><strong>keepalived</strong>的安装:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf keepalived-1.1.17.tar.gz</span><br><span class="line">ln -s /usr/src/kernels/2.6.18-128.el5-i686/ /usr/src/linux</span><br><span class="line"><span class="built_in">cd</span> keepalived-1.1.17</span><br><span class="line">./configure --prefix=/ --mandir=/usr/<span class="built_in">local</span>/share/man/ --with-kernel-dir=/usr/src/kernels/2.6.18-128.el5-i686/</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"><span class="built_in">cd</span> /etc/keepalived/</span><br><span class="line">mv keepalived.conf keepalived.conf.default</span><br><span class="line">vim keepalived.conf</span><br><span class="line"></span><br><span class="line">! Configuration File <span class="keyword">for</span> keepalived</span><br><span class="line">vrrp_script chk_http_port &#123;</span><br><span class="line">script <span class="string">"/etc/keepalived/check_haproxy.sh"</span></span><br><span class="line">interval 2</span><br><span class="line">weight 2</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">state MASTER <span class="comment">#192.168.1.193上改为BACKUP</span></span><br><span class="line">interface eth0</span><br><span class="line">virtual_router_id 51 </span><br><span class="line">priority 150 <span class="comment">#192.168.1.193上改为120</span></span><br><span class="line">advert_int 1</span><br><span class="line">authentication &#123;</span><br><span class="line">auth_type PASS</span><br><span class="line">auth_pass 1111</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">track_script &#123;</span><br><span class="line">chk_http_port</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_ipaddress &#123;</span><br><span class="line">192.168.1.200 </span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vi /etc/keepalived/check_haproxy.sh</span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">A=`ps -C haproxy --no-header |wc -l`</span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$A</span> -eq 0 ];<span class="keyword">then</span></span><br><span class="line">/usr/<span class="built_in">local</span>/haproxy/sbin/haproxy -f /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg</span><br><span class="line">sleep 3</span><br><span class="line"><span class="keyword">if</span> [ `ps -C haproxy --no-header |wc -l` -eq 0 ];<span class="keyword">then</span></span><br><span class="line">/etc/init.d/keepalived stop</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">chmod 755 /etc/keepalived/check_haproxy.sh</span><br></pre></td></tr></table></figure><p><strong>haproxy</strong>的安装(主备都一样)：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf haproxy-1.4.9.tar.gz</span><br><span class="line"><span class="built_in">cd</span> haproxy-1.4.9</span><br><span class="line">make TARGET=linux26 PREFIX=/usr/<span class="built_in">local</span>/haproxy install</span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/haproxy/</span><br><span class="line">mkdir conf logs</span><br><span class="line"><span class="built_in">cd</span> conf</span><br><span class="line">vim haproxy.cfg</span><br><span class="line"></span><br><span class="line">global</span><br><span class="line"><span class="built_in">log</span> 127.0.0.1 local3 info</span><br><span class="line">maxconn 4096</span><br><span class="line">user nobody</span><br><span class="line">group nobody</span><br><span class="line">daemon</span><br><span class="line">nbproc 1</span><br><span class="line">pidfile /usr/<span class="built_in">local</span>/haproxy/logs/haproxy.pid</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">maxconn 2000</span><br><span class="line">contimeout 5000</span><br><span class="line">clitimeout 30000</span><br><span class="line">srvtimeout 30000</span><br><span class="line">mode http</span><br><span class="line"><span class="built_in">log</span> global</span><br><span class="line"><span class="built_in">log</span> 127.0.0.1 local3 info</span><br><span class="line">stats uri /admin?stats</span><br><span class="line">option forwardfor</span><br><span class="line"></span><br><span class="line">frontend http_server</span><br><span class="line"><span class="built_in">bind</span> :80</span><br><span class="line"><span class="built_in">log</span> global</span><br><span class="line">default_backend info_cache</span><br><span class="line">acl <span class="built_in">test</span> hdr_dom(host) -i test.domain.com</span><br><span class="line">use_backend cache_test <span class="keyword">if</span> <span class="built_in">test</span></span><br><span class="line"></span><br><span class="line">backend info_cache</span><br><span class="line"><span class="comment">#balance roundrobin</span></span><br><span class="line">balance <span class="built_in">source</span></span><br><span class="line">option httpchk HEAD /haproxy.txt HTTP/1.1\r\nHost:192.168.1.187</span><br><span class="line">server inst2 192.168.1.187:80 check inter 5000 fall 3</span><br><span class="line"></span><br><span class="line">backend cache_test</span><br><span class="line">balance roundrobin</span><br><span class="line"><span class="comment">#balance source</span></span><br><span class="line">option httpchk HEAD /haproxy.txt HTTP/1.1\r\nHost:test.domain.com</span><br><span class="line">server inst1 192.168.1.187:8000 check inter 5000 fall 3</span><br></pre></td></tr></table></figure><h2 id="两台机器上分别启动"><a href="#两台机器上分别启动" class="headerlink" title="两台机器上分别启动"></a>两台机器上分别启动</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/keepalived start （这条命令会自动把haproxy启动）</span><br></pre></td></tr></table></figure><h2 id="验证测试"><a href="#验证测试" class="headerlink" title="验证测试"></a>验证测试</h2><h4 id="两台机器上分别执行"><a href="#两台机器上分别执行" class="headerlink" title="两台机器上分别执行"></a>两台机器上分别执行</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip add</span><br></pre></td></tr></table></figure><p>主: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000<br>link/ether 00:0c:29:98:cd:c0 brd ff:ff:ff:ff:ff:ff<br>inet 192.168.1.192/24 brd 192.168.1.255 scope global eth0<br><strong>inet 192.168.1.200/32 scope global eth0</strong><br>inet6 fe80::20c:29ff:fe98:cdc0/64 scope link<br>valid_lft forever preferred_lft forever</p><p>备: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000<br>link/ether 00:0c:29:a6:0c:7e brd ff:ff:ff:ff:ff:ff<br>inet 192.168.1.193/24 brd 255.255.255.254 scope global eth0<br>inet6 fe80::20c:29ff:fea6:c7e/64 scope link<br>valid_lft forever preferred_lft forever</p><h4 id="停掉主上的haproxy"><a href="#停掉主上的haproxy" class="headerlink" title="停掉主上的haproxy"></a>停掉主上的haproxy</h4><p>3秒后keepalived会自动将其再次启动</p><h4 id="停掉主的keepalived"><a href="#停掉主的keepalived" class="headerlink" title="停掉主的keepalived"></a>停掉主的keepalived</h4><p>备机马上接管服务<br>备: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000<br>link/ether 00:0c:29:a6:0c:7e brd ff:ff:ff:ff:ff:ff<br>inet 192.168.1.193/24 brd 255.255.255.254 scope global eth0<br><strong>inet 192.168.1.200/32 scope global eth0</strong><br>inet6 fe80::20c:29ff:fea6:c7e/64 scope link<br>valid_lft forever preferred_lft forever</p><h4 id="更改hosts"><a href="#更改hosts" class="headerlink" title="更改hosts"></a>更改hosts</h4><p>192.168.1.200 test.com<br>192.168.1.200 test.domain.com<br>通过IE测试，可以发现<br>test.com的请求发向了192.168.1.187:80<br>test.domain.com的请求发向了192.168.1.187:8000<br><img src="/articles/9ad4df0e/0.6843823240075992.png" alt="img"></p><p><img src="/articles/9ad4df0e/0.9408829897802136.png" alt="img"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;在运维的日常工作中和很多服务打交道，为了保证各个服务健康稳定运行，高可用和高负载是在一个服务搭建好后，必须要考虑的问题。本文介绍了一种常用的高可用和负载均衡的解决方案：KA+HA(haproxy+keepalived)&lt;/p&gt;
&lt;h2 id=&quot;环境&quot;&gt;&lt;a href=&quot;#环境&quot; class=&quot;headerlink&quot; title=&quot;环境&quot;&gt;&lt;/a&gt;环境&lt;/h2&gt;&lt;p&gt;haproxy keepalived  主：192.168.1.192&lt;br&gt;haproxy keepalived  备：192.168.1.193&lt;br&gt;vip：192.168.1.200&lt;br&gt;web：192.168.1.187:80 &lt;/p&gt;
&lt;p&gt;​            192.168.1.187:8000&lt;/p&gt;
&lt;h2 id=&quot;架构图&quot;&gt;&lt;a href=&quot;#架构图&quot; class=&quot;headerlink&quot; title=&quot;架构图&quot;&gt;&lt;/a&gt;架构图&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/articles/9ad4df0e/0.115069789831175.png&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Haproxy" scheme="https://wandouduoduo.netlify.com/tags/Haproxy/"/>
    
      <category term="Keepalived" scheme="https://wandouduoduo.netlify.com/tags/Keepalived/"/>
    
  </entry>
  
  <entry>
    <title>ssh端口转发：ssh隧道</title>
    <link href="https://wandouduoduo.netlify.com/articles/b406f6c6.html"/>
    <id>https://wandouduoduo.netlify.com/articles/b406f6c6.html</id>
    <published>2019-10-30T02:43:48.000Z</published>
    <updated>2019-10-31T10:44:34.902Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>“ssh端口转发”还有一个更加形象的名字，叫做”ssh隧道”，当然，只是纯粹的通过”ssh隧道”这几个字去理解它可能不太容易，我们来描述一些实际的场景，在这些场景中我们可能会遇到一些问题，而这些问题可以通过”ssh隧道”解决，通过这样的方式，我们反而更加容易理解”ssh隧道”是什么以及它的作用。</p><p>假如我们现在有两个台主机，主机A与主机B，主机A上安装有mysql客户端，主机B上安装有mysql服务端，现在，主机A中的mysql客户端需要与主机B中的mysql服务端进行通讯，则需要从mysql的客户端连接到mysql服务端。如下图所示</p><p><img src="/articles/b406f6c6/1.png" alt="ssh端口转发：ssh隧道"></p><p>然而我们知道，mysql在传输数据时是进行明文传输的，如果主机A与主机B只能通过公网进行通讯，那么暴露在公网的mysql通讯是非常不安全的，所以，我们需要借助一些手段，提高访问mysql服务时的安全性，比如，我们可以使用SSL证书为数据加密，或者使用stunnel加密隧道，我们还可以使用VPN，当然，这些方法都不是这篇文章所要描述的重点，我们此处要总结的是”ssh隧道”这种方法，我们可以利用ssh，搭建出一条”通道”，然后将mysq的客户端与服务端通过这条”ssh通道”连接起来，如下图所示</p><p><img src="/articles/b406f6c6/2.png" alt="ssh端口转发：ssh隧道"></p><p>mysql的客户端与服务端的连接方式从原来直连的方式变成了如上图所示的连接方式，它们之间并不直接进行通讯，而是借助ssh隧道将通讯数据转发，虽然仍然跨越了公网，但是由于ssh本身的安全特性，所以别人无法看到明文传输的数据，数据依靠ssh隧道实现了加密的效果，达到了保护数据安全的作用，提升了mysql的客户端与服务端通讯的安全性。</p><a id="more"></a><h2 id="本地转发"><a href="#本地转发" class="headerlink" title="本地转发"></a>本地转发</h2><p>经过上述描述，我想你对”ssh隧道”应该已经有了初步的理解，那么现在我们来实际动手配置一下。</p><p>首选，将实验环境准备好，两台主机的信息如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ServerA：10.1.0.1</span><br><span class="line"></span><br><span class="line">ServerB：10.1.0.2</span><br><span class="line"></span><br><span class="line">ServerA中并不存在mysql服务。</span><br><span class="line"></span><br><span class="line">ServerB中已经安装了mysql服务，mysql服务已经启动并监听了3306端口。</span><br></pre></td></tr></table></figure><p>现在，我们只要在ServerA中执行如下命令，即可在ServerA与ServerB之间建立一条ssh隧道，执行如下命令时会提示输入ServerB的密码</p><p><img src="/articles/b406f6c6/3.png" alt="ssh端口转发：ssh隧道"></p><p>如上图所示，执行上图中的命令后，我们直接从主机A连接到了主机B，这条连接就是我们创建的”ssh隧道”。</p><p>我们先来简单的解释一下上图中命令的含义，为了方便解释，我们把命令分成3部分理解，如下图所示。</p><p><img src="/articles/b406f6c6/4.png" alt="ssh端口转发：ssh隧道"></p><p>第1部分为-L选项，-L 选项表示使用”本地转发”建立ssh隧道，本地转发是什么意思呢？</p><p>“本地转发”表示本地的某个端口上的通讯数据会被转发到目标主机的对应端口，你可以把它抽象的理解成一种”映射”，注意，我们把执行上述命令的主机称为”本地主机”。</p><p>比如，访问本地(当前主机)的端口A，就相当于访问目标主机的端口B，因为当你访问本地的端口A时，通讯数据会被转发到目标主机的端口B，这就是本地转发，其实，”本地转发”是与”远程转发”相对应的，但是我们还没有介绍到远程转发，所以并不用在意那么多，我们只要先了解本地转发的作用就行了。</p><p>刚才说过，”本地转发”表示本地的某个端口上的通讯数据会被转发到目标主机的对应端口，那么你一定能够理解上述命令中第2部分的含义了</p><p>第2部分表示：通讯数据会从本地的9906端口上被转发，最终被转发到10.1.0.2的3306端口。</p><p>第3部分表示：我们创建的ssh隧道是连接到10.1.0.2上的root用户的，其实，第3部分可以与之前的ssh连在一起去理解，比如，ssh <a href="mailto:root@10.1.0.2" target="_blank" rel="noopener">root@10.1.0.2</a>，其实就是使用ssh命令从ServerA中连接到ServerB的root用户，这就是为什么执行上述命令以后，会提示我们输入10.1.0.2中root用户的密码，当然，如果你已经在ServerB中配置好了ServerA对应用户的公钥，那么则可以省去输入密码的步骤直接连接，此时，ServerA的角色是ssh的客户端，ServerB的角色是ssh的服务端，而这条ssh隧道就是建立在ServerA与ServerB之间的。</p><p>了解完上述命令的3个部分，我们来把它当做一个整体去理解一下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -L 9906:10.1.0.2:3306 root@10.1.0.2</span><br></pre></td></tr></table></figure><p>上述命令表示从本机(ServerA)建立一个到ServerB(10.1.0.2)的ssh隧道，使用本地端口转发模式，监听ServerA本地的9906端口，访问本机的9906端口时，通讯数据将会被转发到ServerB(10.1.0.2)的3306端口。</p><p>好了，命令解释完了，现在我们来试试实际的使用效果，注意，此刻我们已经创建了ssh隧道，从serverA中已经连接到了ServerB，不要退出这个ssh连接，否则刚才创建的ssh隧道将会消失（稍后会介绍怎样后台建立连接），此刻，我们再打开一个新的ssh连接，连接到ServerA，如下图所示</p><p><img src="/articles/b406f6c6/5.png" alt="ssh端口转发：ssh隧道"></p><p>在新链接中查看对应的端口号，本地回环地址的9906端口已经被监听了（稍后介绍怎样监听ServerA中指定的IP，即非本地回环地址）。</p><p>此时，我们直接在ServerA中通过mysql命令访问127.0.0.1的9906端口，就相当于访问ServerB的mysql服务了，我们来试试。</p><p>执行mysql命令时需要指定IP与端口号，因为我的ServerB中的mysql只是用于测试，所以没有为用户设置密码，如下图即可连接</p><p><img src="/articles/b406f6c6/6.png" alt="ssh端口转发：ssh隧道"></p><p>如上图所示，已经可以正常在ServerA中连接到数据库，但是连接的数据库其实是ServerB中的mysql服务。</p><p>这就是通过ssh隧道访问远程主机的mysql服务的示例，这样做就是利用ssh的安全特性加密了mysql的通讯数据。</p><p>在没有使用ssh隧道时，直接从ServerA跨越公网访问ServerB的mysql服务时，如果在ServerB中通过抓包工具对通讯网卡进行抓包，可以直接从抓到的数据包中看到mysql的传输数据。</p><p>但是如果使用了ssh隧道，并且在ServerB中仅对通讯网卡进行抓包时，则只能看到经过加密的ssh数据包，此时，如果对ServerB的本地回环网卡同时进行抓包，则可以看到未加密的mysql传输数据，不过，这并不影响mysql通讯数据跨越公网时的安全性，因为这时已经是ServerB本机中的数据传输了，也就是说，mysql通讯数据在跨越公网时，是经过ssh隧道加密的，mysql通讯数据到达ServerB本机以后，是明文传输的。</p><p>不过，当我们执行上述命令创建ssh隧道时，总会从ServerA中连接到ServerB中，而通常，我们只希望建立ssh隧道，并不会使用到这个新建立的ssh连接，而且在实际使用中，我们往往会在建立隧道以后，退出当前的ssh会话，所以，上述命令并不能满足我们的需求，因为，我们一旦退出对应的ssh会话，相应的ssh隧道也会消失，所以，我们还需要配合另外两个选项，”-N选项”与”-f选项”，我们一一道来。</p><p>首先来试试”-N选项”，当配合此选项创建ssh隧道时，并不会打开远程shell连接到目标主机，我们来试试，如下图所示，配合-N选项创建隧道，输入ServerB的密码以后，并没有连接到ServerB，而是停留在了如下图的位置</p><p><img src="/articles/b406f6c6/7.png" alt="ssh端口转发：ssh隧道"></p><p>此时，再打开一个新的ssh会话连接到ServerA，可以看到，9906端口已经被监听。</p><p>但是，这样仍然不能满足我们的要求，虽然建立隧道时并没有连接到ServerB，但是，我们仍然不能关闭创建ssh隧道时所使用的ssh会话。</p><p>这时，只要配合”-f”选项即可，”-f”选项表示后台运行ssh隧道，即使我们关闭了创建隧道时所使用的ssh会话，对应的ssh隧道也不会消失，”-f”选项需要跟”-N”选项配合使用，所以通常，我们会使用如下命令创建ssh隧道</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -f -N -L 9906:10.1.0.2:3306 root@10.1.0.2</span><br></pre></td></tr></table></figure><p>配合上述选项创建ssh隧道时，即使我们完全关闭了执行命令时的ssh会话，对应创建的隧道也可以完全正常运行。</p><p>不过，当我们使用上述命令建立隧道时，只有127.0.0.1这个回环地址的9906端口会被监听，这样就会出现一个小问题，也就是说，我们只能在ServerA本机上访问9906端口，并不能通过其他主机访问ServerA的9906端口，因为ServerA其他IP的9906端口并未被监听，那么怎么办呢？很简单，使用如下命令，即可让9906端口监听在ServerA中指定的IP上</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -f -N -L 10.1.0.1:9906:10.1.0.2:3306 root@10.1.0.2</span><br></pre></td></tr></table></figure><p>在ServerA中执行上述命令时，ServerA的10.1.0.1的9906端口会被监听，此刻，我们可以通过其他主机访问10.1.0.1的9906端口，即可访问到ServerB中的mysql服务，其实，与之前的命令相比，只是在9906前增加了ServerA中对应的IP地址罢了，很简单吧。</p><p>如果你觉得这还不够，希望ServerA中的所有IP地址的9906端口都被监听，那么可以在建立隧道时开启”网关功能”，使用”-g”选项可以开启”网关功能”，开启网关功能以后，ServerA中的所有IP都会监听对应端口，示例如下</p><p><img src="/articles/b406f6c6/8.png" alt="ssh端口转发：ssh隧道"></p><p>好了，说了这么多，终于把ssh隧道(本地转发)给解释明白了，不过，我们也只是说明了本地转发，现在，我们来聊聊远程转发。</p><h2 id="远程转发"><a href="#远程转发" class="headerlink" title="远程转发"></a>远程转发</h2><p>在了解远程转发之前，请先确定你已经理解了”本地转发”。</p><p>老规矩，为了方便理解，我们先来描述一个场景。</p><p>公司有一台服务器ServerB，ServerB处于公司的内网中，公司内网中的所有主机都通过路由器访问互联网（典型的NAT网络），ServerB中有提供mysql服务，如果此时，我们想要通过外网访问到ServerB中的mysql服务，该怎么办呢？通常的做法是，通过路由器或者防火墙，将公司的固定外网IP上的某个端口映射到ServerB内网IP的3306端口上，这样，我们只要访问公司外网IP的对应端口，即可访问到内网ServerB中的mysql服务了，但是，如果你没有权限控制公司的防火墙或者路由器呢，这时该怎么办呢？</p><p>假设，你无法控制防火墙去进行端口映射，但是，公司在公网上有另外一台服务器ServerA，ServerA有自己的公网IP，你有权控制ServerA，这时，我们就可以利用ServerA达到我们的目的，聪明如你，一定想到了解决方案，没错，我们可以在ServerA与ServerB之间创建一条SSH隧道，利用这条隧道将ServerA中的某个端口(假设仍然使用9906端口)与ServerB中的3306端口连接起来，这样，当我们访问ServerA的9906端口时，就相当于访问到内网ServerB中的mysql服务了，那么，我们能不能使用之前的”本地转发”的方式，在ServerA中创建SSH隧道呢？我们来模拟一下，看看会不会遇到什么问题，如果想要使用之前的命令创建SSH隧道，那么我们则需要在ServerA中执行如下命令。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -f -N -L AIP:9906:BIP:3306 root@BIP</span><br></pre></td></tr></table></figure><p>问题来了，ServerA有自己的公网IP，我们只要把上述命令中的AIP替换成ServerA的公网IP即可，但是ServerB是内网主机，虽然ServerB能够通过公司内的路由器访问到互联网，但是ServerB并不持有任何公网IP，ServerB只有内网IP，所以，我们并不可能把上述命令中的BIP替换成B主机的内网IP，所以，使用上述命令是无法在ServerA中创建ssh隧道连接到ServerB的，那么该怎么办呢？</p><p>虽然我们无法从ServerA中使用ssh命令连接到ServerB，但是，我们可以从ServerB中使用ssh命令连接到ServerA啊，虽然ServerB是没有公网IP的内网主机，但是它仍然可以依靠公司的路由器访问互联网，所以，我们只要在ServerB中执行如下命令，即可从ServerB中连接到ServerA中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh root@AIP</span><br></pre></td></tr></table></figure><p>那么，按照这个思路，我们似乎找到了方向，我们现在需要一种方法，能够从ServerB中创建SSH隧道连接到ServerA，并且，隧道创建后，ServerA中会监听9906端口，以便别人能够通过外网访问，也就是说，我们需要一种方法，能够满足如下两个条件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">条件1：从ServerB中主动连接到ServerA，即在ServerB中执行创建隧道的命令，连接到ServerA。</span><br><span class="line"></span><br><span class="line">条件2：隧道创建后，转发端口需要监听在ServerA中，以便利用ServerA访问到内网的ServerB。</span><br></pre></td></tr></table></figure><p>这种方法就是”远程转发”。</p><p>你可能还是不太明白，没有关系，我们先来实际动手操作一下，稍后，我们会对比本地转发与远程转发的具体区别。</p><p>为了方便，我们仍然使用之前的实验环境，假设ServerA是外网主机，ServerB是内网主机，ServerA的IP为10.1.0.1（假设此IP为公网IP），ServerB的IP为10.1.0.2，并且已经将之前本地转发的进程关闭，相当于一个没有任何隧道的新的实验环境。</p><p>使用”-R选项”，可以创建一个”远程转发”模式的ssh隧道，我们在ServerB中，执行如下命令即可</p><p><img src="/articles/b406f6c6/9.png" alt="ssh端口转发：ssh隧道"></p><p>上述命令在ServerB中执行，执行后，即可在ServerA与ServerB之间建立ssh隧道，此时，ServerB是ssh客户端，ServerA是ssh服务端，隧道建立后，ServerA中的9906端口会被监听，在ServerA中查看对应端口，如下图所示</p><p><img src="/articles/b406f6c6/10.png" alt="ssh端口转发：ssh隧道"></p><p>从图中可以看出，ServerA中的9906端口已经被监听，此刻，我们通过外网IP登录到ServerA，在ServerA中访问本地回环地址的9906端口，即可访问到内网ServerB中的mysql服务，如下图所示。</p><p><img src="/articles/b406f6c6/11.png" alt="ssh端口转发：ssh隧道"></p><p>不过你肯定注意到了，当使用远程转发的命令时，我并没有指定监听ServerA的外网IP，也没有使用”-g选项”开启网关功能，这是因为，即使你在命令中指定了IP地址，最终在ServerA中还是会只监听127.0.0.1的9906端口，你可以在ServerB中尝试一下如下命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -f -N -R 10.1.0.1:9906:10.1.0.2:3306 root@10.1.0.1</span><br></pre></td></tr></table></figure><p>即使在ServerB中执行上述命令时指定了IP或者开启了网关功能，ServerA的9906端口仍然只监听在127.0.0.1上，当然，如果你一心想要通过别的主机访问ServerA的9906端口，也可以使用其他程序去反代ServerA的9906端口，还有，我在实际的使用过程中，如果使用远程转发穿透到内网，ssh隧道将会非常不稳定，隧道会莫名其妙的消失或者失效，特别是在没有固定IP的网络内，网上有些朋友提供了autossh的解决方案，不过我并没有尝试过，如果你有兴趣，可以试一试。</p><h2 id="本地转发与远程转发的区别"><a href="#本地转发与远程转发的区别" class="headerlink" title="本地转发与远程转发的区别"></a>本地转发与远程转发的区别</h2><p>读到此处，你可能会有些蒙圈，”远程转发”与”本地转发”到底有什么不一样，我们来对比一下</p><p>在对比之前，再强调一点，我们把执行创建隧道命令的主机称为本地主机(本地)。</p><p><strong>“本地转发”</strong></p><p>在本机执行创建隧道的命令时，本地是ssh客户端，隧道的另一头是远程主机(ssh服务端)，本地主机(也就是ssh客户端)会监听一个端口，当访问本地主机的这个端口时，通讯数据会通过ssh隧道转发到ssh服务端(即远程主机)，远程主机再将通讯数据发往应用服务所监听端口，在本地转发中，本地主机不仅扮演了ssh客户端的角色，也扮演了应用程序的客户端(比如mysql客户端)，远程主机不仅扮演了ssh服务端，也扮演了应用程序服务端(比如mysql服务端)，那么我们可以总结一下，本地转发的特性如下</p><p>本地主机：隧道的一头，本地主机既是ssh客户端，又是应用客户端</p><p>远程主机：隧道的另一头，远程主机既是ssh服务端，又是应用服务端</p><p>隧道创建以后，转发端口监听在本地主机中，即监听在ssh客户端主机中。</p><p><strong>“远程转发”</strong></p><p>在本机执行创建隧道的命令时，本地是ssh客户端，隧道的另一头是远程主机(ssh服务端)，远程主机(也就是ssh服务端)会监听一个端口，当访问远程主机的这个端口时，通讯数据会通过ssh隧道转发到ssh客户端(即本地主机)，本地主机再将通讯数据发往应用服务所监听端口，在远程转发中，本地主机不仅扮演了ssh客户端的角色，也扮演了应用程序的服务端(比如mysql服务端)，远程主机不仅扮演了ssh服务端，也扮演了应用程序客户端(比如mysql客户端)，那么我们可以总结一下，远程转发的特性如下</p><p>本地主机：隧道的一头，本地主机既是ssh客户端，又是应用服务端</p><p>远程主机：隧道的另一头，远程主机既是ssh服务端，又是应用客户端</p><p>隧道创建以后，转发端口监听在远程主机中，即监听在ssh服务端主机中。</p><p>“本地转发”与”远程转发”都属于ssh端口转发，也可以称呼它们为”ssh隧道”，只不过，有的朋友喜欢将”远程转发”称呼为为”ssh反向隧道”或者”ssh逆向隧道”</p><p>经过上述描述，我想你应该已经明白了它们之间的区别。</p><h2 id="一些扩展"><a href="#一些扩展" class="headerlink" title="一些扩展"></a>一些扩展</h2><p>在之前的示例中，ServerB是ssh隧道的一头，同时，ServerB也是应用的服务端，也就是说，应用程序的服务端与ssh隧道的连接端在同一台服务器上，那么，当应用程序的服务端处于其他主机时（比如ServerC），我们还能够通过ServerB去转发通讯数据吗？我们来动手试试，不过在动手之前，先来描述一下实验场景，实验场景如下图所示</p><p><img src="/articles/b406f6c6/12.png" alt="ssh端口转发：ssh隧道"></p><p>如上图所示，我们想要在A与B之间创建隧道，最终通过隧道访问到ServerC中的mysql服务。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ServerAIP：10.1.0.1</span><br><span class="line"></span><br><span class="line">ServerBIP：10.1.0.2</span><br><span class="line"></span><br><span class="line">ServerCIP：10.1.0.3</span><br><span class="line"></span><br><span class="line">ServerA与ServerB上没有开启任何mysql服务。</span><br><span class="line"></span><br><span class="line">ServerC中开启了mysql服务，监听了3306端口。</span><br></pre></td></tr></table></figure><p>之前用于示例所创建的ssh隧道已经全部关闭，相当于一个全新的实验环境。</p><p>好了，实验环境描述完毕，现在开始实际操作，就以本地转发为例，在ServerA中执行如下命令，即可创建一条隧道并满足上图中的应用场景。</p><p><img src="/articles/b406f6c6/13.png" alt="ssh端口转发：ssh隧道"></p><p>如上图所示，ServerA的9906端口已经被监听，细心如你一定发现了，上图中的命令与之前创建隧道时所使用的命令在结构上并没有什么不同，只是目标端口所对应的IP地址变为了ServerC的IP，是不是很简单，我再来啰嗦一遍，上述命令表示，从本机（ServerA）建立一条ssh隧道连接到10.1.0.2（ServerB），隧道使用本地转发模式建立，转发端口监听在本地的9906端口上，访问本机的9906端口时，数据会被ssh隧道转发到10.1.0.3（ServerC)的3306端口。</p><p>我们来测试一下实际的使用效果，如下图所示，一切正常。</p><p><img src="/articles/b406f6c6/14.png" alt="ssh端口转发：ssh隧道"></p><p>上述场景中存在一个问题，就是数据安全性的问题，我们之所以使用ssh隧道，就是为了用它来保护明文传输的数据，从而提升安全性，不过，在上例的场景中，只有ServerA与ServerB之间的传输是受ssh隧道保护的，ServerB与ServerC之间的传输，仍然是明文的，所以，如果想要在上述场景中使用ssh隧道进行数据转发，首先要考虑ServerB与ServerC之间的网络是否可靠。</p><p>其实，当我们在创建隧道时如果开启了网关功能，那么应用客户端与ServerA之间的通讯也会面临同样的问题，如下图所示</p><p><img src="/articles/b406f6c6/15.png" alt="ssh端口转发：ssh隧道"></p><p>既然上述场景中存在没有办法通过ssh隧道保护的连接，那么为什么还要使用上述方式进行转发呢？</p><p>这是因为，在某些实际的使用场景中，我们使用ssh隧道的目的并不是提升数据的安全性，而是为了”绕过防火墙”，比如如下场景</p><p><img src="/articles/b406f6c6/16.png" alt="ssh端口转发：ssh隧道"></p><p>上图中，ServerC中提供了mysql服务，我们想要通过ServerA访问ServerC中的mysql服务，但是，ServerA与ServerC之间存在防火墙，阻断了它们的通讯，所以，我们无法从ServerA中直接访问ServerC中的服务，不过幸运的是，我们还有另外一台机器：ServerB，ServerA与ServerB之间可以自由通讯，同时，ServerB与ServerC之间也可以自由通讯，没错，你一定想到了，我们可以利用ServerB，在ServerA与ServerB之间建立ssh隧道，达到我们的最终目的：使得ServerA可以访问到ServerC中的mysql服务，如下图所示</p><p><img src="/articles/b406f6c6/17.png" alt="ssh端口转发：ssh隧道"></p><p>当上图中的ssh隧道建立以后，访问ServerA中的转发端口，即可访问到ServerC中的mysql服务，因为对于ServerC来说，ServerA是透明的，ServerC并不知道ServerA的存在，它只能看到ServerB，当你在ServerA中使用ssh隧道访问ServerC的mysql服务时，如果你在ServerC中的网卡上进行抓包，只会看到ServerB的IP地址，因为数据经过ServerB转发了。</p><h2 id="一些配置"><a href="#一些配置" class="headerlink" title="一些配置"></a>一些配置</h2><p>其实，如果想要能够正常的使用ssh端口转发，我们还需要做出正确的配置才行，之前一直没有说明，是因为openssh默认的配置就是支持端口转发的。</p><p>如果想要ssh端口转发能够正常工作，需要在ssh服务端的配置文件中将AllowTcpForwarding的值设置为yes。</p><p>此处所指的ssh服务端即ssh隧道中的一头，扮演ssh服务端角色的那台主机。</p><p>当隧道建立以后，经过一段时间后，ssh隧道链接可能会被断开，这有可能是因为ssh客户端和ssh服务端长时间没有通讯，于是ssh服务端主动断开了链接，如果想要解决这个问题，可以在ssh服务端进行配置，调整ssh服务端的ClientAliveInterval配置和ClientAliveCountMax配置即可。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>经过上述描述，我想你应该已经了解的ssh隧道的作用。</p><p>通常，ssh隧道可以帮助我们达到如下目的：</p><p>1、保护tcp会话，保护会话中明文传输的内容。</p><p>2、绕过防火墙或者穿透到内网，访问对应的服务。</p><p>为了以后方便回顾，我们将上文中使用到的命令及选项进行总结</p><p>创建隧道时的常用选项有：</p><p>“-L选项”：表示使用本地端口转发创建ssh隧道</p><p>“-R选项”：表示使用远程端口转发创建ssh隧道</p><p>“-N选项”： 表示创建隧道以后不连接到sshServer端，通常与”-f”选项连用</p><p>“-f选项”：表示在后台运行ssh隧道，通常与”-N”选项连用</p><p>“-g选项”：表示ssh隧道对应的转发端口将监听在主机的所有IP中，不使用”-g选项”时，转发端口默认只监听在主机的本地回环地址中，”-g”表示开启网关模式，远程端口转发中，无法开启网关功能。</p><p>创建本地转发模式的ssh隧道，命令如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -g -f -N -L forwardingPort:targetIP:targetPort user@sshServerIP</span><br></pre></td></tr></table></figure><p>本机上的forwardingPort将会被监听，访问本机的forwardingPort，就相当于访问targetIP的targetPort，ssh隧道建立在本机与sshServer之间。</p><p>创建远程转发模式的ssh隧道，命令如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -f -N -R forwardingPort:targetIP:targetPort user@sshServerIP</span><br></pre></td></tr></table></figure><p>sshServer上的forwardingPort将会被监听，访问sshServer上的forwardingPort，就相当于访问targetIP的targetPort，ssh隧道建立在本机与sshServer之间。</p><p>关于ssh的端口转发就总结到这里，希望可以帮助到你。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;“ssh端口转发”还有一个更加形象的名字，叫做”ssh隧道”，当然，只是纯粹的通过”ssh隧道”这几个字去理解它可能不太容易，我们来描述一些实际的场景，在这些场景中我们可能会遇到一些问题，而这些问题可以通过”ssh隧道”解决，通过这样的方式，我们反而更加容易理解”ssh隧道”是什么以及它的作用。&lt;/p&gt;
&lt;p&gt;假如我们现在有两个台主机，主机A与主机B，主机A上安装有mysql客户端，主机B上安装有mysql服务端，现在，主机A中的mysql客户端需要与主机B中的mysql服务端进行通讯，则需要从mysql的客户端连接到mysql服务端。如下图所示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/b406f6c6/1.png&quot; alt=&quot;ssh端口转发：ssh隧道&quot;&gt;&lt;/p&gt;
&lt;p&gt;然而我们知道，mysql在传输数据时是进行明文传输的，如果主机A与主机B只能通过公网进行通讯，那么暴露在公网的mysql通讯是非常不安全的，所以，我们需要借助一些手段，提高访问mysql服务时的安全性，比如，我们可以使用SSL证书为数据加密，或者使用stunnel加密隧道，我们还可以使用VPN，当然，这些方法都不是这篇文章所要描述的重点，我们此处要总结的是”ssh隧道”这种方法，我们可以利用ssh，搭建出一条”通道”，然后将mysq的客户端与服务端通过这条”ssh通道”连接起来，如下图所示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/b406f6c6/2.png&quot; alt=&quot;ssh端口转发：ssh隧道&quot;&gt;&lt;/p&gt;
&lt;p&gt;mysql的客户端与服务端的连接方式从原来直连的方式变成了如上图所示的连接方式，它们之间并不直接进行通讯，而是借助ssh隧道将通讯数据转发，虽然仍然跨越了公网，但是由于ssh本身的安全特性，所以别人无法看到明文传输的数据，数据依靠ssh隧道实现了加密的效果，达到了保护数据安全的作用，提升了mysql的客户端与服务端通讯的安全性。&lt;/p&gt;
    
    </summary>
    
      <category term="网络技术" scheme="https://wandouduoduo.netlify.com/categories/%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Network" scheme="https://wandouduoduo.netlify.com/tags/Network/"/>
    
  </entry>
  
</feed>
