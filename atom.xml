<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>豌豆多多</title>
  
  <subtitle>Senior O &amp; M Architect</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://wandouduoduo.netlify.com/"/>
  <updated>2020-07-02T09:53:22.725Z</updated>
  <id>https://wandouduoduo.netlify.com/</id>
  
  <author>
    <name>WanDouDuoDuo</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>容器版Jenkins连接K8s</title>
    <link href="https://wandouduoduo.netlify.com/articles/3cfe518.html"/>
    <id>https://wandouduoduo.netlify.com/articles/3cfe518.html</id>
    <published>2020-07-02T09:08:51.000Z</published>
    <updated>2020-07-02T09:53:22.725Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文详解介绍了容器版jenkins连接k8s的配置和使用详情。特别注意：必须用谷歌浏览器，而且非容器版jenkins是无法安装kubernetes插件的，所以无法连接k8s。<a href="https://wandouduoduo.github.io/articles/87f87b20.html" target="_blank" rel="noopener">搭建k8s集群教程</a></p><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>操作系统版本:     Ubuntu 18.04 TLS</p><p>软件版本:                       Jenkins 2.121.2</p><a id="more"></a><h2 id="教程"><a href="#教程" class="headerlink" title="教程"></a>教程</h2><h4 id="安装k8s插件"><a href="#安装k8s插件" class="headerlink" title="安装k8s插件"></a>安装k8s插件</h4><p>系统管理-&gt;管理插件-&gt;可选插件,   搜索kubernetes plugin（没有选择kubernetes）并选择安装。</p><h4 id="配置插件连接k8s集群"><a href="#配置插件连接k8s集群" class="headerlink" title="配置插件连接k8s集群"></a>配置插件连接k8s集群</h4><p>点击系统管理-&gt;系统设置-&gt;添加一个云,  在下拉菜单中选择kubernets并添加，如下图所示：</p><p><img src="/articles/3cfe518/1.png" alt></p><h4 id="云kubernetes配置"><a href="#云kubernetes配置" class="headerlink" title="云kubernetes配置"></a>云kubernetes配置</h4><p>注：Name值任意添加，Kubernetes URL值添加K8S  apiserver连接地址和端口，jenkins URL值添加jenkins UI访问地址和端口,如下图所示：</p><p><img src="/articles/3cfe518/2.png" alt></p><h4 id="添加云pod-template并配置"><a href="#添加云pod-template并配置" class="headerlink" title="添加云pod template并配置"></a>添加云pod template并配置</h4><p><a href="https://wandouduoduo.github.io/articles/7aff7329.html" target="_blank" rel="noopener">参考教程</a></p><h4 id="配置云连接K8S集群的验证文件"><a href="#配置云连接K8S集群的验证文件" class="headerlink" title="配置云连接K8S集群的验证文件"></a>配置云连接K8S集群的验证文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在jenkins所在的node节点上操作</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建目录</span></span><br><span class="line">mkdir -p /opt/crt/</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取K8S的/root/.kube/config文件</span></span><br><span class="line"><span class="comment">#获取/root/.kube/config中certificate-authority-data的内容并转化成base64 encoded文件</span></span><br><span class="line"></span><br><span class="line">[root@test2 ~]<span class="comment"># echo LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUR2akNDQXFhZ0F3SUJBZ0lVYTdJRGZlOENZdmc0ZGpBR0cxQS81WHBLZVRNd0RRWUpLb1pJaHZjTkFRRUwKQlFBd1pURUxNQWtHQTFVRUJoTUNRMDR4RURBT0JnTlZCQWdUQjBKbGFVcHBibWN4RURBT0JnTlZCQWNUQjBKbAphVXBwYm1jeEREQUtCZ05WQkFvVEEyczRjekVQTUEwR0ExVUVDeE1HVTNsemRHVnRNUk13RVFZRFZRUURFd3ByCmRXSmxjbTVsZEdWek1CNFhEVEU0TURjeE9UQTBNVEl3TUZvWERUSXpNRGN4T0RBME1USXdNRm93WlRFTE1Ba0cKQTFVRUJoTUNRMDR4RURBT0JnTlZCQWdUQjBKbGFVcHBibWN4RURBT0JnTlZCQWNUQjBKbGFVcHBibWN4RERBSwpCZ05WQkFvVEEyczRjekVQTUEwR0ExVUVDeE1HVTNsemRHVnRNUk13RVFZRFZRUURFd3ByZFdKbGNtNWxkR1Z6Ck1JSUJJakFOQmdrcWhraUc5dzBCQVFFRkFBT0NBUThBTUlJQkNnS0NBUUVBdTRxK1l2TDZMMjRZcEx3Y0cvMmoKdllFTTY5QmIxMmFzZFBtNXBLekMzc3o5Q2JnZ3llb2ZzZFNxSmFIVkNHRkFmNjBEN3J5elhPMVgxY1RGaGdYdQp5SGtrcnBLdGVyNm1aNXpRVGxrQXlyM1AyOXd0NXhJRHJINkhKOE9FcGZNYWlCRlkrcHhTKzJicEZNVUJ3UTcwCksxVE5tWXFsN0lIOEt5V290UXhKQURtQS9VWUpDWHgwNnB5bVlvRzRmcTVjeUVJK3hBSkRsZ3l5blZpc2Y1cEkKUGo2dEl3SHc1UzVGbGVNUE04WVFMSE5JNUlwUEYvR0txNmdaYldLTHFOamNvL2dVTExXSThsWm5mSlVSbE16VwpLa05XYkxETktwSzZOOG5jc09Yc2lFTjNvMW0zeGg2RjlJUWsyWU95d3hTM1dvWTlUQWp3d0VxdTV0bUtVZ1lhCjN3SURBUUFCbzJZd1pEQU9CZ05WSFE4QkFmOEVCQU1DQVFZd0VnWURWUjBUQVFIL0JBZ3dCZ0VCL3dJQkFqQWQKQmdOVkhRNEVGZ1FVQ1QyM3ora3J5clcvNHJGblR4cFlBalJqa253d0h3WURWUjBqQkJnd0ZvQVVDVDIzeitrcgp5clcvNHJGblR4cFlBalJqa253d0RRWUpLb1pJaHZjTkFRRUxCUUFEZ2dFQkFHNmRWZitPTnlUcVJzRlBVaWRxClVvODJSUSs3RytVOWdxN3VpRjFyamx6cms4d0JxQ0J3SEVwOGFKbzhKa1hBN3JNZUptVk9hcmJPK1lsempmbTcKUlM5QnJNV3I0ZEt5TUw0UTIvWHgreCs5Um1GemxabmZoTFR4SE9XTTJiam9HTjliNk90RnF1VmFqaWtjU0Zkdwp3cTF2cS9Ud05ock41aXlIRko1V3h6YXRpa3BlVmZQdnhsS0xKbmpQOGhxeVh2RWxYcEIydnV1ZStJeEdmUWJiCjROQUFJcVIwOUsvS1FVQ3dQK0lQNjlxK0FMazJIWWRrNVB0SmpOMnpOSEw5SUppWHVQUGViZGtSYVNnMGIvZzMKc3BNeFZTY05jNDR3MGFyQ0ZFU2Foa0tMbHJFRGNjbjcxSVpPb2dEMStaMHgycFB4RDc5OWNlQjlxMUtsNnhOWQp6T2s9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K | base64 -d &gt; /opt/crt/ca.crt</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#获取/root/.kube/config中client-certificate-data和client-key-data的内容并转化成base64 encoded文件</span></span><br><span class="line"></span><br><span class="line">[root@test2 ~]<span class="comment"># echo LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUQzVENDQXNXZ0F3SUJBZ0lVSkw2RzR5YjlsaGwvWlIyT01laENmbVBOK2s4d0RRWUpLb1pJaHZjTkFRRUwKQlFBd1pURUxNQWtHQTFVRUJoTUNRMDR4RURBT0JnTlZCQWdUQjBKbGFVcHBibWN4RURBT0JnTlZCQWNUQjBKbAphVXBwYm1jeEREQUtCZ05WQkFvVEEyczRjekVQTUEwR0ExVUVDeE1HVTNsemRHVnRNUk13RVFZRFZRUURFd3ByCmRXSmxjbTVsZEdWek1CNFhEVEU0TURjeE9UQTJORFF3TUZvWERUSTRNRGN4TmpBMk5EUXdNRm93YXpFTE1Ba0cKQTFVRUJoTUNRMDR4RURBT0JnTlZCQWdUQjBKbGFVcHBibWN4RURBT0JnTlZCQWNUQjBKbGFVcHBibWN4RnpBVgpCZ05WQkFvVERuTjVjM1JsYlRwdFlYTjBaWEp6TVE4d0RRWURWUVFMRXdaVGVYTjBaVzB4RGpBTUJnTlZCQU1UCkJXRmtiV2x1TUlJQklqQU5CZ2txaGtpRzl3MEJBUUVGQUFPQ0FROEFNSUlCQ2dLQ0FRRUF2Ui9GZ2krKzJMdmUKU0ttNU11TG9DeVZ6aUVsOEVCVFhIS0tacWczMG5iOWgvUHAxZEV2a3JFbHFtOFJHN3JOOGFFRkkyZi9mcHF4SwpMdFlTWmVYTjEybWFRQTBiV1JlSG1nYWxnTzBZbVpYV1psc0FOR0xLcEtJOEF4czVXeDB3WlNIdWlxeFlCOXlnCkdPR0dhMW41SmZPUDBRWFZNeTVDZlcweWtLRnZmbDJ6TENwSnRNTzJtdWZxR20zM2wrd0l0SlNKaEJUdUc0RDUKa0pnOFFSNUZzUDk1eXF2RWNnT1NrNUZpNFVKZkcwakY1Rnd3UGt1ekhnTmNFQ29YMVNrTlkrZFJ3aSt5OUNZYQpSdWcvbXBrd1F5RWFBVW5BbzNhaTlWTFd5dnRkc3h1YlFMMUJMUGczZE4xTFRPeUxFaGMzZVJNdWFUR0dhNDc4CmwxUWJYeTV2K3dJREFRQUJvMzh3ZlRBT0JnTlZIUThCQWY4RUJBTUNCYUF3SFFZRFZSMGxCQll3RkFZSUt3WUIKQlFVSEF3RUdDQ3NHQVFVRkJ3TUNNQXdHQTFVZEV3RUIvd1FDTUFBd0hRWURWUjBPQkJZRUZCRFdIRTIxUzhLSApHeFBCT3lNem1LQjZqc1V3TUI4R0ExVWRJd1FZTUJhQUZBazl0OC9wSzhxMXYrS3haMDhhV0FJMFk1SjhNQTBHCkNTcUdTSWIzRFFFQkN3VUFBNElCQVFBRkpaSFpYbmR3ZGJQQVcxSUtMTFUzNlRTUm9pUXVIVk5nWWwzZFRJcVYKMzllTFcxSFJ5djIzdTlOSkhXRkhyZHBWbjNWM0ZTR1lsUW5jRSsxU1o5MUFWZXhGcDMxeWNnbVo0WEdjZ0pVZwphcExoZFJOdHNSVmpHKzF0OFplL2VCdHVXYXFlNXluZUFtT3ZzdmpPcDU5cVpDakxSbDk0YWZ4WVYrVlNiVFByCnAvZHRCcHh3MUlOK3puajh1SXRnRDhQTEpzUXViYWsyeTU2QThWUTJCTmVkSG5ZK3lVaC9NVHgzQ1BkSlB3OTUKbnk3T0ovaWNCV1drbS95Qy9weURqSFhEczdtNVkvWG80VnJ2YUQwd05ucllOWWluTTh0VHRReU1zUEpBaVlLYQpmZDAycEs1eGFzVjUweWdpL3AxaUl4MzEybHMxaWc1eG8zRjAyb2xocWtNKwotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg== | base64 -d &gt; /opt/crt/client.crt</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@test2 ~]<span class="comment"># echo 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 | base64 -d &gt; /opt/crt/client.key</span></span><br></pre></td></tr></table></figure><h4 id="生产Client-P12认证文件cert-pfx，并下载至本地windows"><a href="#生产Client-P12认证文件cert-pfx，并下载至本地windows" class="headerlink" title="生产Client P12认证文件cert.pfx，并下载至本地windows"></a>生产Client P12认证文件cert.pfx，并下载至本地windows</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">openssl pkcs12 -<span class="built_in">export</span> -out /opt/crt/cert.pfx -inkey /opt/crt/client.key -<span class="keyword">in</span> /opt/crt/client.crt -certfile /opt/crt/ca.crt</span><br><span class="line">Enter Export Password: 123</span><br><span class="line">Verifying - Enter Export Password: 123</span><br><span class="line"></span><br><span class="line">sz /opt/crt/cert.pfx</span><br><span class="line"></span><br><span class="line"><span class="comment">#注：自定义一个password并牢记</span></span><br></pre></td></tr></table></figure><h4 id="在云k8s中添加凭证"><a href="#在云k8s中添加凭证" class="headerlink" title="在云k8s中添加凭证"></a>在云k8s中添加凭证</h4><p>添加凭证–&gt; 首先密码填写123–&gt; 类型 –&gt; Certificate –&gt;  Upload PKCS#12 certificate –&gt; 上传证书 –&gt; 选择文件–&gt; cert –&gt; 打开 –&gt; 上传 –&gt; 添加 –&gt; 选择凭证</p><p>注：Upload certificate上次刚生成并下载至本地的cert.pfx文件，Password值添加生成cert.pfx文件时输入的密钥</p><p><img src="/articles/3cfe518/3.png" alt></p><p><img src="/articles/3cfe518/4.png" alt></p><p><img src="/articles/3cfe518/5.png" alt></p><p><img src="/articles/3cfe518/6.png" alt></p><p><img src="/articles/3cfe518/7.png" alt></p><p><img src="/articles/3cfe518/8.png" alt></p><h4 id="添加命名空间"><a href="#添加命名空间" class="headerlink" title="添加命名空间"></a>添加命名空间</h4><p>Kubernetes 命名空间中的值添加/root/.kube/config文件中cluster部分中name的内容（否则连接失败）</p><p><img src="/articles/3cfe518/9.png" alt></p><h4 id="测试连接kubernetes集群"><a href="#测试连接kubernetes集群" class="headerlink" title="测试连接kubernetes集群"></a>测试连接kubernetes集群</h4><p><img src="/articles/3cfe518/10.png" alt></p><p><img src="/articles/3cfe518/11.png" alt></p><h4 id="配置jenkins-jnlp代理端口"><a href="#配置jenkins-jnlp代理端口" class="headerlink" title="配置jenkins jnlp代理端口"></a>配置jenkins jnlp代理端口</h4><p>系统管理-&gt;全局安全配置中的”代理”项,指定端口为50000</p><h2 id="拍错"><a href="#拍错" class="headerlink" title="拍错"></a>拍错</h2><h4 id="显示证书不对"><a href="#显示证书不对" class="headerlink" title="显示证书不对"></a>显示证书不对</h4><p>Error testing connection <a href="https://192.168.0.91:6443" target="_blank" rel="noopener">https://192.168.0.91:6443</a>: Get Key failed: Given final block not properly padded. Such issues can arise if a bad key is used during decryption</p><p>解决：</p><p>是因为添加平局那一界面的下面没有输入之前设置的密码（123）。输入密码、再次导入即可解决</p><h4 id="显示无法连接"><a href="#显示无法连接" class="headerlink" title="显示无法连接"></a>显示无法连接</h4><p>解决：</p><p>cert.pfx 可能没有生成好 ；或者ca.cert没有生成好，有空格， 重新生成一遍就好</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;本文详解介绍了容器版jenkins连接k8s的配置和使用详情。特别注意：必须用谷歌浏览器，而且非容器版jenkins是无法安装kubernetes插件的，所以无法连接k8s。&lt;a href=&quot;https://wandouduoduo.github.io/articles/87f87b20.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;搭建k8s集群教程&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;环境&quot;&gt;&lt;a href=&quot;#环境&quot; class=&quot;headerlink&quot; title=&quot;环境&quot;&gt;&lt;/a&gt;环境&lt;/h2&gt;&lt;p&gt;操作系统版本:     Ubuntu 18.04 TLS&lt;/p&gt;
&lt;p&gt;软件版本:                       Jenkins 2.121.2&lt;/p&gt;
    
    </summary>
    
      <category term="容器化" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Docker" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/Docker/"/>
    
    
      <category term="K8s" scheme="https://wandouduoduo.netlify.com/tags/K8s/"/>
    
      <category term="Jenkins" scheme="https://wandouduoduo.netlify.com/tags/Jenkins/"/>
    
  </entry>
  
  <entry>
    <title>k8s版jenkins带maven、jdk、git各种工具用master/slave模式实现CI/CD</title>
    <link href="https://wandouduoduo.netlify.com/articles/7aff7329.html"/>
    <id>https://wandouduoduo.netlify.com/articles/7aff7329.html</id>
    <published>2020-07-02T06:56:01.000Z</published>
    <updated>2020-07-02T09:52:56.134Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文在k8s集群中把各种工具（jdk，git, maven等）集成到jenkins，用master/slave模式实现CI/CD。</p><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>k8s集群    <a href="https://wandouduoduo.github.io/articles/87f87b20.html" target="_blank" rel="noopener">参考教程</a></p><p>Hubor镜像服务  <a href="https://wandouduoduo.github.io/articles/b9ccc582.html" target="_blank" rel="noopener">参考教程</a></p><p>nfs/Ceph持久存储   <a href="https://wandouduoduo.github.io/articles/3acab424.html" target="_blank" rel="noopener">参考教程</a></p><p><a href="https://wandouduoduo.github.io/articles/12aa61a7.html" target="_blank" rel="noopener">K8s中Jenkins实践教程</a></p><a id="more"></a><h2 id="M-S模式实现"><a href="#M-S模式实现" class="headerlink" title="M/S模式实现"></a>M/S模式实现</h2><h4 id="创建Master镜像文件"><a href="#创建Master镜像文件" class="headerlink" title="创建Master镜像文件"></a>创建Master镜像文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#编写Dockerfile：</span></span><br><span class="line"></span><br><span class="line">cat&gt;/home/jenkins-dockerfile/Dockerfile &lt;&lt;EOF</span><br><span class="line">FROM jenkinsci/jenkins</span><br><span class="line">USER root</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y libltdl7.*</span><br><span class="line">RUN apt-get install vim -y</span><br><span class="line">RUN apt-get install maven -y</span><br><span class="line">RUN apt-get install git -y</span><br><span class="line">ARG dockerGid=999</span><br><span class="line">RUN <span class="built_in">echo</span> <span class="string">"docker:x:<span class="variable">$&#123;dockerGid&#125;</span>:jenkins"</span> &gt;&gt; /etc/group</span><br><span class="line">RUN <span class="built_in">echo</span> <span class="string">"jenkins ALL=NOPASSWD: ALL"</span> &gt;&gt; /etc/sudoers</span><br><span class="line">RUN mkdir -p /opt/maven/repository</span><br><span class="line">RUN mkdir -p /ceph/maven/repository</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment">#该Dockerfile所做的工作为：</span></span><br><span class="line"><span class="comment">#安装Maven，git,vim</span></span><br><span class="line"><span class="comment">#配置Maven仓库位置，以便启动时挂载宿主机仓库为容器中Maven仓库</span></span><br><span class="line"><span class="comment">#设置启动用户为root把jenkins加入docker组，否则无法使用宿主机的docker</span></span><br><span class="line"><span class="comment">#安装libltdl7.* 库，否则无法使用宿主机的docker</span></span><br></pre></td></tr></table></figure><h4 id="构建Master镜像"><a href="#构建Master镜像" class="headerlink" title="构建Master镜像"></a>构建Master镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t jenkinsci/jenkins:v1 /home/jenkins-dockerfile/</span><br></pre></td></tr></table></figure><h4 id="启动YAML配置文件"><a href="#启动YAML配置文件" class="headerlink" title="启动YAML配置文件"></a>启动YAML配置文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#jenkins命令空间创建</span></span><br><span class="line"></span><br><span class="line">cat &gt;namespace-jenkins.yaml&lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Namespace</span><br><span class="line">metadata:</span><br><span class="line">   name: jenkins</span><br><span class="line">   labels:</span><br><span class="line">     name: jenkins</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment">#Jenkins 权限配置</span></span><br><span class="line"><span class="comment">#此处直接将jenkins-admin集成了cluster-admin权限，可根据自己具体需要进行权限的设置</span></span><br><span class="line"></span><br><span class="line">cat&gt;jenkins-account.yaml&lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: jenkins</span><br><span class="line">  name: jenkins-admin</span><br><span class="line">  namespace: jenkins</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: jenkins-admin</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: jenkins</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: jenkins-admin</span><br><span class="line">    namespace: jenkins</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Jenkins Deployment配置</span></span><br><span class="line"><span class="comment">#此处配置简单明了，需要说明的地方是挂在卷，此处挂载了四个目录，下面分别做出挂载原因：</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#/var/jenkins_home（容器） –&gt; /ceph/jenkins_home（宿主机） </span></span><br><span class="line"><span class="comment">#我们需要将容器中的Jenkins源目录挂载导本地宿主机，因为该目录下保存了Jenkins产生的所有配置、我们的自定义配置、任务配置及详情等等信息，所以需要持久化导宿主机，以便重新启动Jenkins容器的时候能够找到相应数据，防止数据丢失。此处我们使用的ceph，保证整个kubernetes集群所有机器能够共享同一个目录。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#/opt/maven/repository（容器） –&gt; /ceph/maven/repository（宿主机） </span></span><br><span class="line"><span class="comment">#这一对挂载目录是Maven仓库的挂载目录，不管是Jenkins master容器或者是Jenkins slave目录都需要挂载该目录，以便容器中maven能够在下载编译代码时能够从该仓库中找到相应Jar包，同时也保证了数据的持久化。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#/usr/bin/docker（容器） –&gt; /usr/bin/docker（宿主机）</span></span><br><span class="line"><span class="comment">#/var/run/docker.sock（容器） –&gt; /var/run/docker.sock（宿主机） </span></span><br><span class="line"><span class="comment">#这两对挂载目录作用是能够在容器中操作宿主机docker，具体的用途是在slave容器中编辑maven代码并生成jar之后，需要生成该代码服务的docker镜像,并上传至本地私有仓库。因此需要操作宿主机docker以便完成这一系列操作</span></span><br><span class="line"></span><br><span class="line">cat&gt;jenkins-deployment.yaml&lt;&lt;EOF</span><br><span class="line">apiVersion: apps/v1beta2</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: jenkins</span><br><span class="line">  namespace: jenkins</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: jenkins</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: jenkins</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: jenkins</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: jenkins</span><br><span class="line">        image: jenkinsci/jenkins:v1</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: jenkins-home</span><br><span class="line">          mountPath: /var/jenkins_home</span><br><span class="line">        - name: maven-repository</span><br><span class="line">          mountPath: /opt/maven/repository</span><br><span class="line">        - name: docker</span><br><span class="line">          mountPath: /usr/bin/docker</span><br><span class="line">        - name: docker-sock</span><br><span class="line">          mountPath: /var/run/docker.sock</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8080</span><br><span class="line">        - containerPort: 50000</span><br><span class="line">      volumes:</span><br><span class="line">        - name: jenkins-home</span><br><span class="line">          hostPath:</span><br><span class="line">            path: /ceph/jenkins_home</span><br><span class="line">        - name: maven-repository</span><br><span class="line">          hostPath:</span><br><span class="line">            path: /ceph/maven/repository</span><br><span class="line">        - name: docker</span><br><span class="line">          hostPath:</span><br><span class="line">            path: /usr/bin/docker</span><br><span class="line">        - name: docker-sock</span><br><span class="line">          hostPath:</span><br><span class="line">            path: /var/run/docker.sock</span><br><span class="line">      serviceAccountName: jenkins-admin</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Jenkins Service配置</span></span><br><span class="line"><span class="comment">#该Service配置作用是能够让用户访问到Jenkins。此处开放并配置了8080、32000端口，这两个端口在Deployment 中也应该开放。此处配置的宿主机开放端口分别为：31888、32000</span></span><br><span class="line"></span><br><span class="line">cat&gt;jenkins-service.yaml&lt;&lt;EOF</span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: jenkins</span><br><span class="line">  name: jenkins</span><br><span class="line">  namespace: jenkins</span><br><span class="line">  annotations:</span><br><span class="line">    prometheus.io/scrape: <span class="string">'true'</span></span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - name: jenkins</span><br><span class="line">      port: 8080</span><br><span class="line">      nodePort: 31888</span><br><span class="line">      targetPort: 8080</span><br><span class="line">    - name: jenkins-agent</span><br><span class="line">      port: 50000</span><br><span class="line">      nodePort: 50000</span><br><span class="line">      targetPort: 50000</span><br><span class="line">  <span class="built_in">type</span>: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: jenkins</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="启动Jenkins-Master容器"><a href="#启动Jenkins-Master容器" class="headerlink" title="启动Jenkins Master容器"></a>启动Jenkins Master容器</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f namespace-jenkins.yaml</span><br><span class="line">kubectl apply -f jenkins-account.yaml</span><br><span class="line">kubectl apply -f jenkins-deployment.yaml</span><br><span class="line">kubectl apply -f jenkins-service.yaml</span><br></pre></td></tr></table></figure><h4 id="创建Jenkins-slave镜像文件"><a href="#创建Jenkins-slave镜像文件" class="headerlink" title="创建Jenkins slave镜像文件"></a>创建Jenkins slave镜像文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#需要使用官方镜像cnych-jenkins，其他的镜像里面都没有kubectl工具，都试过。</span></span><br><span class="line"><span class="comment">#编写Dockerfile： </span></span><br><span class="line"></span><br><span class="line">cat&gt;/home/jenkins-dockerfile/Dockerfile &lt;&lt;EOF</span><br><span class="line">FROM cnych/jenkins:jnlp</span><br><span class="line">USER root</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y libltdl7.*</span><br><span class="line">RUN apt-get install maven -y</span><br><span class="line">RUN apt-get install vim -y</span><br><span class="line">RUN apt-get install git -y</span><br><span class="line">ARG dockerGid=999</span><br><span class="line">RUN <span class="built_in">echo</span> <span class="string">"docker:x:<span class="variable">$&#123;dockerGid&#125;</span>:jenkins"</span> &gt;&gt; /etc/group</span><br><span class="line">RUN <span class="built_in">echo</span> <span class="string">"jenkins ALL=NOPASSWD: ALL"</span> &gt;&gt; /etc/sudoers</span><br><span class="line">RUN mkdir -p /opt/maven/repository</span><br><span class="line">RUN mkdir -p /ceph/maven/repository</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment">#该Dockerfile所做的工作为：</span></span><br><span class="line"><span class="comment">#安装Maven,git,vim</span></span><br><span class="line"><span class="comment">#配置Maven仓库位置，以便启动时挂载宿主机仓库为容器中Maven仓库</span></span><br><span class="line"><span class="comment">#设置启动用户为root</span></span><br></pre></td></tr></table></figure><h4 id="构建Slave镜像"><a href="#构建Slave镜像" class="headerlink" title="构建Slave镜像"></a>构建Slave镜像</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t cnych/jenkins:v1 /home/jenkins-dockerfile/</span><br></pre></td></tr></table></figure><h4 id="查看镜像列表"><a href="#查看镜像列表" class="headerlink" title="查看镜像列表"></a>查看镜像列表</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker images</span><br></pre></td></tr></table></figure><h4 id="浏览器访问"><a href="#浏览器访问" class="headerlink" title="浏览器访问"></a>浏览器访问</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#访问jenkins</span></span><br><span class="line">http://192.168.0.92:31888</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看密码</span></span><br><span class="line">[root@test2 ~]<span class="comment"># docker ps -l</span></span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">6f8a62f8a0f7        2114cb298e17        <span class="string">"/sbin/tini -- /us..."</span>   About an hour ago   Up About an hour                        k8s_jenkins_jenkins-7b46757695-4hx6f_jenkins_e8cb1035-3fe6-11e9-a258-000c2980fc47_0</span><br><span class="line"></span><br><span class="line">[root@test2 ~]<span class="comment"># docker exec 6f8a62f8a0f7 cat /var/jenkins_home/secrets/initialAdminPassword</span></span><br><span class="line">471234cd0eb44ec3bfc4015fbacd599b</span><br></pre></td></tr></table></figure><h4 id="页面配置master"><a href="#页面配置master" class="headerlink" title="页面配置master"></a>页面配置master</h4><h6 id="升级和重置密码"><a href="#升级和重置密码" class="headerlink" title="升级和重置密码"></a>升级和重置密码</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#然后会要求安装一些插件，这里选择默认安装即可，否则下一步打开是空白页</span></span><br><span class="line"><span class="comment">#设置登录用户名密码：</span></span><br><span class="line">admin/jenkins@123</span><br><span class="line"></span><br><span class="line"><span class="comment">#这时候会跳转到首页， 此时Jenkins就可以真正使用了： </span></span><br><span class="line"><span class="comment">#对jenkins进行升级</span></span><br><span class="line"><span class="comment">#重启jenkins（有点慢，等5分钟）</span></span><br><span class="line"><span class="comment">#刷新网页重新登录</span></span><br><span class="line">admin/471234cd0eb44ec3bfc4015fbacd599b</span><br><span class="line"><span class="comment">#查看更新后的版本</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#重置admin密码方法：</span></span><br><span class="line"><span class="comment">#进入首页-》系统管理-》全局安全配置</span></span><br><span class="line"><span class="comment">#把“启用安全”勾上和把Jenkins专有用户数据库勾上、允许用户注册勾上-》保存</span></span><br><span class="line"><span class="comment">#点击右上角的admin-》设置-》修改里面的密码为（jenkins@123）-》保存-》重新登录-》输入账号密码</span></span><br></pre></td></tr></table></figure><h6 id="安装插件"><a href="#安装插件" class="headerlink" title="安装插件"></a>安装插件</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Kubernetes Cli Plugin：该插件可直接在Jenkins中使用kubernetes命令行进行操作。</span></span><br><span class="line"><span class="comment">#Kubernetes plugin： 使用kubernetes则需要安装该插件</span></span><br><span class="line"><span class="comment">#Kubernetes Continuous Deploy Plugin：kubernetes部署deploymrnt.yaml 时候需要使用</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#安装步骤：</span></span><br><span class="line"><span class="comment">#进入首页-》系统管理-》插件管理-》可选插件-》输入kubernetes-》选中所有带kubernetes的插件进行安装-》安装完返回首页</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#查看所有带kubernetes的插件是否安装上</span></span><br><span class="line"><span class="comment">#进入首页-》系统管理-》插件管理-》已安装-》输入kubernetes查看</span></span><br><span class="line"><span class="comment">#也可登录该网站：https://plugins.jenkins.io/，查找需要的插件</span></span><br></pre></td></tr></table></figure><h6 id="增加一个kubernetes云"><a href="#增加一个kubernetes云" class="headerlink" title="增加一个kubernetes云"></a>增加一个kubernetes云</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#系统管理-&gt;系统设置，往下拉可看到云，点击新增一个云来新增一个kubernetes云</span></span><br></pre></td></tr></table></figure><p><a href="https://wandouduoduo.github.io/articles/3cfe518.html" target="_blank" rel="noopener">配置jenkins连接kubernetes教程</a></p><h6 id="配置K8s-Pod-Template"><a href="#配置K8s-Pod-Template" class="headerlink" title="配置K8s Pod Template"></a>配置K8s Pod Template</h6><p>其实就是配置Jenkins的jnlp-slave</p><p>在该kubernetes云下，新增Kubernetes Pod Template，配置一个模板容器配置，如下图所示：</p><p><img src="/articles/7aff7329/1.png" alt></p><p><img src="/articles/7aff7329/2.png" alt></p><p>配置镜像，下面里面的镜像一定要写对，否则写成别的镜像，到最后编译时候就一直报错没有mvn</p><p><img src="/articles/7aff7329/3.png" alt></p><p>配置卷：就是deployment.yaml 里面的挂载路径</p><p><img src="/articles/7aff7329/4.png" alt></p><h6 id="全局配置"><a href="#全局配置" class="headerlink" title="全局配置"></a>全局配置</h6><p>点击 系统管理-&gt;全局工具配置，此处可配置配置一些常用的工具配置，比如java、ant、maven、docker</p><p><a href="https://wandouduoduo.github.io/articles/6f80621c.html" target="_blank" rel="noopener">参照教程</a></p><h4 id="创建流水线任务项目"><a href="#创建流水线任务项目" class="headerlink" title="创建流水线任务项目"></a>创建流水线任务项目</h4><h6 id="新建任务项目"><a href="#新建任务项目" class="headerlink" title="新建任务项目"></a>新建任务项目</h6><p>点击新建Item –&gt; 进入任务配置界面–&gt;选择Pipeline（中文版为：流水线）–&gt;确定。则可编写Pipeline，进行任务配置</p><p><img src="/articles/7aff7329/5.png" alt></p><p><img src="/articles/7aff7329/6.png" alt></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Pipeline任务采用流式的处理方法，步骤清晰，非常适合进行任务配置。</span></span><br><span class="line"><span class="comment">#下面pipline里面的简单任务：查看slave镜像里面是否有java的家目录、查看maven的版本等操作，</span></span><br><span class="line"></span><br><span class="line">def label = <span class="string">"jnlp-slave"</span></span><br><span class="line">podTemplate(label: label, cloud: <span class="string">'kubernetes'</span>,containers: [</span><br><span class="line">    containerTemplate(name: <span class="string">'jnlp-slave'</span>, image: <span class="string">'cnych/jenkins:v1'</span>)</span><br><span class="line">  ],</span><br><span class="line">  volumes: [hostPathVolume(mounntPath:<span class="string">'/opt/maven/repository'</span>,hostPath:<span class="string">'/ceph/maven/repository'</span>),</span><br><span class="line">            hostPathVolume(mounntPath:<span class="string">'/usr/bin/docker'</span>,hostPath:<span class="string">'/usr/bin/docker'</span>),</span><br><span class="line">            hostPathVolume(mounntPath:<span class="string">'/var/run/docker.sock'</span>,hostPath:<span class="string">'/var/run/docker.sock'</span>)]) &#123;</span><br><span class="line">    node(label) &#123;</span><br><span class="line">        stage(<span class="string">'Get a Maven project'</span>) &#123;</span><br><span class="line">            container(label) &#123;</span><br><span class="line">                stage(<span class="string">'wait for exec check'</span>)&#123;</span><br><span class="line">                    sh <span class="string">'sleep 1'</span></span><br><span class="line">                    sh <span class="string">'echo $JAVA_HOME'</span></span><br><span class="line">                    sh <span class="string">'mvn -v'</span></span><br><span class="line">                &#125;</span><br><span class="line"> </span><br><span class="line">                stage(<span class="string">'get maven env'</span>) &#123;</span><br><span class="line">                    sh <span class="string">'cat /etc/resolv.conf'</span></span><br><span class="line">                    sh <span class="string">'cat /etc/issue'</span></span><br><span class="line">                    sh <span class="string">'uname -a'</span></span><br><span class="line">                    sh <span class="string">'env'</span></span><br><span class="line">                &#125;</span><br><span class="line">              </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/articles/7aff7329/7.png" alt></p><h6 id="构建"><a href="#构建" class="headerlink" title="构建"></a>构建</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看构建前的pod个数</span></span><br><span class="line">kubectl get pod -n [namespace]</span><br></pre></td></tr></table></figure><p>页面点击立即构建</p><p><img src="/articles/7aff7329/8.png" alt></p><p><img src="/articles/7aff7329/9.png" alt></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看构建时的pod数量</span></span><br><span class="line">kubectl get pod -n [NAMEspace]  </span><br><span class="line"></span><br><span class="line"><span class="comment">#再次查看pod个数：发现消失从上边的pod个数变化中，我们可以清晰的看到 Jenkins Slave 自动创建到注销删除的过程，整个过程是自动完成的，不需要人工干预。</span></span><br></pre></td></tr></table></figure><h2 id="使用宿主机的kubectl命令"><a href="#使用宿主机的kubectl命令" class="headerlink" title="使用宿主机的kubectl命令"></a>使用宿主机的kubectl命令</h2><h4 id="镜像选择"><a href="#镜像选择" class="headerlink" title="镜像选择"></a>镜像选择</h4><p>slave镜像需要使用cnych/jenkins:jnlp，这个官方镜像里面有kubectl工具，其他的没有，都试过，上面就是用的这个镜像，所以直接下一步</p><h4 id="挂载kubectl工具"><a href="#挂载kubectl工具" class="headerlink" title="挂载kubectl工具"></a>挂载kubectl工具</h4><p>/root/.kube 目录，我们将这个目录挂载到容器的 /home/jenkins/.kube 目录下面这是为了让我们能够在 Pod 的容器中能够使用 kubectl 工具来访问我们的 Kubernetes 集群，方便我们后面在 Slave Pod 部署 Kubernetes 应用。添加一个挂在路径，如下图所示：</p><p><img src="/articles/7aff7329/10.png" alt></p><h4 id="pipline脚本"><a href="#pipline脚本" class="headerlink" title="pipline脚本"></a>pipline脚本</h4><p>先试试是否能使用宿主机的kubectl命令，只查看一个pod情况：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">def label = <span class="string">"jnlp-slave"</span></span><br><span class="line">podTemplate(label: label, cloud: <span class="string">'kubernetes'</span>,containers: [</span><br><span class="line">    containerTemplate(name: <span class="string">'jnlp-slave'</span>, image: <span class="string">'cnych/jenkins:v1'</span>)</span><br><span class="line">  ],</span><br><span class="line">  volumes: [hostPathVolume(mounntPath:<span class="string">'/opt/maven/repository'</span>,hostPath:<span class="string">'/ceph/maven/repository'</span>),</span><br><span class="line">            hostPathVolume(mounntPath:<span class="string">'/usr/bin/docker'</span>,hostPath:<span class="string">'/usr/bin/docker'</span>),</span><br><span class="line">            hostPathVolume(mounntPath:<span class="string">'/var/run/docker.sock'</span>,hostPath:<span class="string">'/var/run/docker.sock'</span>),</span><br><span class="line">            hostPathVolume(mounntPath:<span class="string">' /home/jenkins/.kube'</span>,hostPath:<span class="string">'/root/.kube'</span>)]) &#123;</span><br><span class="line">    node(label) &#123;</span><br><span class="line">        stage(<span class="string">'Get a Maven project'</span>) &#123;</span><br><span class="line">            container(label) &#123;</span><br><span class="line">                stage(<span class="string">'wait for exec check'</span>)&#123;</span><br><span class="line">                    sh <span class="string">'kubectl get pod -n jenkins'</span></span><br><span class="line">                &#125;</span><br><span class="line"> </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="构建，查看控制台输出"><a href="#构建，查看控制台输出" class="headerlink" title="构建，查看控制台输出"></a>构建，查看控制台输出</h4><p><img src="/articles/7aff7329/11.png" alt></p><h4 id="使用jenkins-salve创建nignx项目"><a href="#使用jenkins-salve创建nignx项目" class="headerlink" title="使用jenkins-salve创建nignx项目"></a>使用jenkins-salve创建nignx项目</h4><h6 id="pipline脚本-1"><a href="#pipline脚本-1" class="headerlink" title="pipline脚本"></a>pipline脚本</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line">def label = <span class="string">"jnlp-slave"</span></span><br><span class="line">podTemplate(label: label, cloud: <span class="string">'kubernetes'</span>,containers: [</span><br><span class="line">    containerTemplate(name: <span class="string">'jnlp-slave'</span>, image: <span class="string">'cnych/jenkins:v1'</span>)</span><br><span class="line">  ],</span><br><span class="line">  volumes: [hostPathVolume(mounntPath:<span class="string">'/opt/maven/repository'</span>,hostPath:<span class="string">'/ceph/maven/repository'</span>),</span><br><span class="line">            hostPathVolume(mounntPath:<span class="string">'/usr/bin/docker'</span>,hostPath:<span class="string">'/usr/bin/docker'</span>),</span><br><span class="line">            hostPathVolume(mounntPath:<span class="string">'/usr/bin/docker'</span>,hostPath:<span class="string">'/usr/bin/docker'</span>),</span><br><span class="line">            hostPathVolume(mounntPath:<span class="string">' /home/jenkins/.kube'</span>,hostPath:<span class="string">'/root/.kube'</span>)]) &#123;</span><br><span class="line">    node(label) &#123;</span><br><span class="line">        stage(<span class="string">'create a pod'</span>) &#123;</span><br><span class="line">            container(label) &#123;</span><br><span class="line">                stage(<span class="string">'cat the pod'</span>)&#123;</span><br><span class="line">                    sh <span class="string">'kubectl get pod -n jenkins'</span></span><br><span class="line">                &#125;</span><br><span class="line"> </span><br><span class="line">        stage(<span class="string">'create the deploy-nginx.yaml'</span>)&#123;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'create the deploy-nginx.yaml'</span></span><br><span class="line">sh <span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">cat &gt;deploy-nginx.yaml&lt;&lt;EOF</span></span><br><span class="line"><span class="string">apiVersion: extensions/v1beta1</span></span><br><span class="line"><span class="string">kind: Deployment</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: http-test-dm2</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  replicas: 1</span></span><br><span class="line"><span class="string">  template:</span></span><br><span class="line"><span class="string">    metadata:</span></span><br><span class="line"><span class="string">      labels:</span></span><br><span class="line"><span class="string">        name: http-test-dm2</span></span><br><span class="line"><span class="string">    spec:</span></span><br><span class="line"><span class="string">      containers:</span></span><br><span class="line"><span class="string">      - name: http-test-con</span></span><br><span class="line"><span class="string">        image: nginx</span></span><br><span class="line"><span class="string">        imagePullPolicy: Never      </span></span><br><span class="line"><span class="string">        ports:</span></span><br><span class="line"><span class="string">        - containerPort: 80</span></span><br><span class="line"><span class="string">---</span></span><br><span class="line"><span class="string">apiVersion: v1</span></span><br><span class="line"><span class="string">kind: Service</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: http-nginx-ser</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  type: NodePort</span></span><br><span class="line"><span class="string">  ports: </span></span><br><span class="line"><span class="string">  - port: 80</span></span><br><span class="line"><span class="string">    nodePort: 31000</span></span><br><span class="line"><span class="string">    targetPort: 80</span></span><br><span class="line"><span class="string">  selector:</span></span><br><span class="line"><span class="string">    name: http-test-dm2</span></span><br><span class="line"><span class="string">---</span></span><br><span class="line"><span class="string">apiVersion: extensions/v1beta1</span></span><br><span class="line"><span class="string">kind: Ingress</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: nginx</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  rules:</span></span><br><span class="line"><span class="string">  - host: www.nginx2.com      </span></span><br><span class="line"><span class="string">    http:</span></span><br><span class="line"><span class="string">      paths:</span></span><br><span class="line"><span class="string">      - path: /</span></span><br><span class="line"><span class="string">        backend:</span></span><br><span class="line"><span class="string">          serviceName: http-nginx-ser</span></span><br><span class="line"><span class="string">          servicePort: 80</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">'</span><span class="string">''</span></span><br><span class="line">            &#125;</span><br><span class="line">                stage(<span class="string">'deploy to k8s'</span>)&#123;</span><br><span class="line">                    sh <span class="string">'kubectl create -f deploy-nginx.yaml'</span></span><br><span class="line">                    </span><br><span class="line">                &#125;</span><br><span class="line">              </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="开始构建"><a href="#开始构建" class="headerlink" title="开始构建"></a>开始构建</h6><p><img src="/articles/7aff7329/12.png" alt></p><h6 id="查看命名空间下的pod验证"><a href="#查看命名空间下的pod验证" class="headerlink" title="查看命名空间下的pod验证"></a>查看命名空间下的pod验证</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#多次执行下面命令，对比输出结果</span></span><br><span class="line">kubectl get pod -n jenkins</span><br></pre></td></tr></table></figure><h6 id="测试访问nginx"><a href="#测试访问nginx" class="headerlink" title="测试访问nginx"></a>测试访问nginx</h6><p>浏览器访问<a href="http://x.x.x.x:31000" target="_blank" rel="noopener">http://x.x.x.x:31000</a></p><p><img src="/articles/7aff7329/13.png" alt></p><h6 id="编写pipline脚本"><a href="#编写pipline脚本" class="headerlink" title="编写pipline脚本"></a>编写pipline脚本</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#注意下面pipline脚本里面的 maven build步骤，里面的JAVA_HOME和mvn工具 都是jenkins-slave里面的，而不是jenkins-master里面的工具，</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#如何查看jenkins-slave里面JAVA_HOME位置：只有通过构建的时候，在pipline里面写shell命令进行查看，因为制作jenkins-slave镜像的基础</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#镜像是从官方镜像拉取的，而这个官方jenkins-slave镜像是不能独立启动的，试过，用docker无法启动，只能当slave使用。但是为什么还要用这个镜像，就是因为这个基础镜像里面包含kubectl工具， 自己之前尝试往jenkins-master镜像里面添加kubectl工具，但是失败，</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#注意：下面piplene里面的第三个stage步骤里面的JAVA_HOME路径是第一个stage步骤mvn -v 得到的结果有java路径，要填写这个，不要填写echo $JAVA_HOME得到的结果</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#先编译构建一下，然后得到mvn -v 结果后，及时暂停，然后把java路径填写到第三个stage步骤里面，从新编译打包</span></span><br><span class="line"></span><br><span class="line">def label = <span class="string">"jnlp-slave"</span></span><br><span class="line">podTemplate(label: label, cloud: <span class="string">'kubernetes'</span>,containers: [</span><br><span class="line">    containerTemplate(name: <span class="string">'jnlp-slave'</span>, image: <span class="string">'cnych/jenkins:v1'</span>)</span><br><span class="line">  ],</span><br><span class="line">  volumes: [hostPathVolume(mounntPath:<span class="string">'/opt/maven/repository'</span>,hostPath:<span class="string">'/ceph/maven/repository'</span>),</span><br><span class="line">            hostPathVolume(mounntPath:<span class="string">'/usr/bin/docker'</span>,hostPath:<span class="string">'/usr/bin/docker'</span>),</span><br><span class="line">            hostPathVolume(mounntPath:<span class="string">'/usr/bin/docker'</span>,hostPath:<span class="string">'/usr/bin/docker'</span>),</span><br><span class="line">            hostPathVolume(mounntPath:<span class="string">' /home/jenkins/.kube'</span>,hostPath:<span class="string">'/root/.kube'</span>)]) &#123;</span><br><span class="line">    node(label) &#123;</span><br><span class="line">        stage(<span class="string">'create a pod'</span>) &#123;</span><br><span class="line">            container(label) &#123;</span><br><span class="line">                stage(<span class="string">'cat the pod'</span>)&#123;</span><br><span class="line">                    sh <span class="string">'kubectl get pod -n jenkins'</span></span><br><span class="line">                    sh <span class="string">'echo $JAVA_HOME'</span></span><br><span class="line">                    sh <span class="string">'mvn -v'</span></span><br><span class="line">                &#125;</span><br><span class="line">                stage(<span class="string">'git checkout'</span>)&#123;</span><br><span class="line">            </span><br><span class="line">                <span class="built_in">echo</span> <span class="string">'git clone'</span></span><br><span class="line">                checkout([<span class="variable">$class</span>: <span class="string">'GitSCM'</span>, branches: [[name: <span class="string">'*/master'</span>]], doGenerateSubmoduleConfigurations: <span class="literal">false</span>, extensions: [], submoduleCfg: [], userRemoteConfigs: [[credentialsId: <span class="string">'c2ca4523-96d0-4fdc-a427-bfefc36a3aa5'</span>, url: <span class="string">'http://192.168.0.96:8081/root/hello.git'</span>]]])</span><br><span class="line">           </span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">                stage(<span class="string">'maven build'</span>)&#123;</span><br><span class="line"></span><br><span class="line">                <span class="built_in">echo</span> <span class="string">'maven build'</span></span><br><span class="line">                    sh <span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">                export JAVA_HOME=/usr/local/newhope/java1.8</span></span><br><span class="line"><span class="string">                /usr/bin/mvn clean package -Dmaven.test.skip=true</span></span><br><span class="line"><span class="string">                '</span><span class="string">''</span></span><br><span class="line"></span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">        stage(<span class="string">'docker build and push images'</span>)&#123;</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'docker build and push images'</span></span><br><span class="line">sh <span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">REPOSITORY=192.168.0.98:5000/library/solo/solo:$&#123;Tag&#125;</span></span><br><span class="line"><span class="string">cat &gt;Dockerfile&lt;&lt;EOF</span></span><br><span class="line"><span class="string">FROM 192.168.0.98:5000/library/tomcat-85:latest</span></span><br><span class="line"><span class="string">RUN rm -rf /usr/local/tomcat/webapps/ROOT/</span></span><br><span class="line"><span class="string">COPY target/*.war /usr/local/tomcat/webapps/ROOT.war</span></span><br><span class="line"><span class="string">WORKDIR /usr/local/tomcat</span></span><br><span class="line"><span class="string">EXPOSE 8080</span></span><br><span class="line"><span class="string">CMD ["./bin/catalina.sh", "run"]</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="string">docker build -t $REPOSITORY .</span></span><br><span class="line"><span class="string">docker login -u admin -p Harbor12345 192.168.0.98:5000</span></span><br><span class="line"><span class="string">docker push $REPOSITORY</span></span><br><span class="line"><span class="string">'</span><span class="string">''</span></span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line">        stage(<span class="string">'create the deploy-solo.yaml'</span>)&#123;</span><br><span class="line"><span class="built_in">echo</span> <span class="string">'create the deploy-solo.yaml'</span></span><br><span class="line">sh <span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">REPOSITORY=192.168.0.98:5000/library/solo/solo:$&#123;Tag&#125;</span></span><br><span class="line"><span class="string">cat &gt;deploy-solo.yaml&lt;&lt;EOF</span></span><br><span class="line"><span class="string">apiVersion: extensions/v1beta1</span></span><br><span class="line"><span class="string">kind: Deployment</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: http-solo-dm2</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  replicas: 1</span></span><br><span class="line"><span class="string">  template:</span></span><br><span class="line"><span class="string">    metadata:</span></span><br><span class="line"><span class="string">      labels:</span></span><br><span class="line"><span class="string">        name: http-solo-dm2</span></span><br><span class="line"><span class="string">    spec:</span></span><br><span class="line"><span class="string">      containers:</span></span><br><span class="line"><span class="string">      - name: http-solo-con</span></span><br><span class="line"><span class="string">        image: $REPOSITORY</span></span><br><span class="line"><span class="string">        imagePullPolicy: Never      </span></span><br><span class="line"><span class="string">        ports:</span></span><br><span class="line"><span class="string">        - containerPort: 80</span></span><br><span class="line"><span class="string">---</span></span><br><span class="line"><span class="string">apiVersion: v1</span></span><br><span class="line"><span class="string">kind: Service</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: http-solo-ser</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  type: NodePort</span></span><br><span class="line"><span class="string">  ports: </span></span><br><span class="line"><span class="string">  - port: 8080</span></span><br><span class="line"><span class="string">    nodePort: 33580</span></span><br><span class="line"><span class="string">    targetPort: 8080</span></span><br><span class="line"><span class="string">  selector:</span></span><br><span class="line"><span class="string">    name: http-solo-dm2</span></span><br><span class="line"><span class="string">---</span></span><br><span class="line"><span class="string">apiVersion: extensions/v1beta1</span></span><br><span class="line"><span class="string">kind: Ingress</span></span><br><span class="line"><span class="string">metadata:</span></span><br><span class="line"><span class="string">  name: solo</span></span><br><span class="line"><span class="string">spec:</span></span><br><span class="line"><span class="string">  rules:</span></span><br><span class="line"><span class="string">  - host: www.solo.com      </span></span><br><span class="line"><span class="string">    http:</span></span><br><span class="line"><span class="string">      paths:</span></span><br><span class="line"><span class="string">      - path: /</span></span><br><span class="line"><span class="string">        backend:</span></span><br><span class="line"><span class="string">          serviceName: http-solo-ser</span></span><br><span class="line"><span class="string">          servicePort: 8080</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">'</span><span class="string">''</span></span><br><span class="line">            &#125;</span><br><span class="line">                stage(<span class="string">'deploy to k8s'</span>)&#123;</span><br><span class="line">                    sh <span class="string">'kubectl create -f deploy-solo.yaml'</span></span><br><span class="line">                    </span><br><span class="line">                &#125;</span><br><span class="line">              </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#上面pipline脚本做的事情如下：</span></span><br><span class="line"><span class="comment">#查看JAVA_HOME</span></span><br><span class="line"><span class="comment">#查看maven版本</span></span><br><span class="line"><span class="comment">#拉取代码：git checkout</span></span><br><span class="line"><span class="comment">#编译打包：maven build</span></span><br><span class="line"><span class="comment">#构建并推送镜像：docker build and push images</span></span><br><span class="line"><span class="comment">#创建yaml文件：create the deploy-solo.yaml</span></span><br><span class="line"><span class="comment">#部署到k8s集群里面：deploy to k8s</span></span><br></pre></td></tr></table></figure><h6 id="查看harbor仓库"><a href="#查看harbor仓库" class="headerlink" title="查看harbor仓库"></a>查看harbor仓库</h6><p><a href="http://192.168.0.98:5000" target="_blank" rel="noopener">http://192.168.0.98:5000</a></p><h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><h4 id="生成自定义Jenkins-master镜像"><a href="#生成自定义Jenkins-master镜像" class="headerlink" title="生成自定义Jenkins master镜像"></a>生成自定义Jenkins master镜像</h4><p>Dockerfile：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> <span class="number">192.168</span>.<span class="number">1.184</span>:<span class="number">5000</span>/jenkins/jenkins:<span class="number">2.89</span>.<span class="number">3</span></span><br><span class="line"><span class="keyword">ENV</span> MAVEN_VERSION <span class="number">3.0</span>.<span class="number">5</span></span><br><span class="line"><span class="keyword">ENV</span> JAVA_HOME /usr/java/jdk1.<span class="number">8.0</span>_121</span><br><span class="line"><span class="keyword">ENV</span> MAVEN_HOME /opt/maven/apache-maven-$&#123;MAVEN_VERSION&#125;</span><br><span class="line"><span class="keyword">ENV</span> CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"></span><br><span class="line"><span class="comment"># build java</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> ./jdk1.8.0_121 <span class="variable">$&#123;JAVA_HOME&#125;</span></span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> ./libltdl.so.7 /usr/lib/libltdl.so.7</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># build maven</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> apache-maven-<span class="variable">$&#123;MAVEN_VERSION&#125;</span>-bin.tar.gz /tmp/maven/apache-maven-<span class="variable">$&#123;MAVEN_VERSION&#125;</span>-bin.tar.gz</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> settings.xml /tmp/maven/settings.xml</span></span><br><span class="line"><span class="keyword">USER</span> root:root</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir -p /opt/maven/repository \</span></span><br><span class="line"><span class="bash">&amp;&amp; <span class="built_in">cd</span> /opt/maven \</span></span><br><span class="line"><span class="bash">&amp;&amp; tar -zxvf /tmp/maven/apache-maven-<span class="variable">$&#123;MAVEN_VERSION&#125;</span>-bin.tar.gz \</span></span><br><span class="line"><span class="bash">&amp;&amp; cp /tmp/maven/settings.xml <span class="variable">$&#123;MAVEN_HOME&#125;</span>/conf/settings.xml \</span></span><br><span class="line"><span class="bash">&amp;&amp; rm -rf /tmp/maven</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> PATH $&#123;JAVA_HOME&#125;/bin:$&#123;MAVEN_HOME&#125;/bin:$&#123;PATH&#125;</span><br></pre></td></tr></table></figure><p>该Dockerfile所做的工作为：</p><ol><li>重新安装Java环境并配置环境变量；</li><li>安装Maven并配置环境变量；</li><li>配置Maven仓库位置，以便启动时挂载宿主机仓库为容器中Maven仓库;</li><li>设置启动用户为root。</li></ol><h4 id="生成自定义Jenkins-slave镜像"><a href="#生成自定义Jenkins-slave镜像" class="headerlink" title="生成自定义Jenkins slave镜像"></a>生成自定义Jenkins slave镜像</h4><p>Dockerfile：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> jenkinsci/jnlp-slave:latest</span><br><span class="line"><span class="keyword">ENV</span> MAVEN_VERSION <span class="number">3.0</span>.<span class="number">5</span></span><br><span class="line"><span class="keyword">ENV</span> JAVA_HOME /usr/java/jdk1.<span class="number">8.0</span>_121</span><br><span class="line"><span class="keyword">ENV</span> MAVEN_HOME /opt/maven/apache-maven-$&#123;MAVEN_VERSION&#125;</span><br><span class="line"><span class="keyword">ENV</span> CLASSPATH .:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line"></span><br><span class="line"><span class="comment"># build java</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> ./jdk1.8.0_121 <span class="variable">$&#123;JAVA_HOME&#125;</span></span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> ./libltdl.so.7 /usr/lib/libltdl.so.7</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># build maven</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> apache-maven-<span class="variable">$&#123;MAVEN_VERSION&#125;</span>-bin.tar.gz /tmp/maven/apache-maven-<span class="variable">$&#123;MAVEN_VERSION&#125;</span>-bin.tar.gz</span></span><br><span class="line"><span class="keyword">COPY</span><span class="bash"> settings.xml /tmp/maven/settings.xml</span></span><br><span class="line"><span class="keyword">USER</span> root:root</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir -p /opt/maven/repository \</span></span><br><span class="line"><span class="bash">&amp;&amp; <span class="built_in">cd</span> /opt/maven \</span></span><br><span class="line"><span class="bash">&amp;&amp; tar -zxvf /tmp/maven/apache-maven-<span class="variable">$&#123;MAVEN_VERSION&#125;</span>-bin.tar.gz \</span></span><br><span class="line"><span class="bash">&amp;&amp; cp /tmp/maven/settings.xml <span class="variable">$&#123;MAVEN_HOME&#125;</span>/conf/settings.xml \</span></span><br><span class="line"><span class="bash">&amp;&amp; rm -rf /tmp/maven \</span></span><br><span class="line"><span class="bash">&amp;&amp; apt-get -yq update \</span></span><br><span class="line"><span class="bash">&amp;&amp; apt-get -yq --no-install-recommends --no-install-suggests install sshpass \</span></span><br><span class="line"><span class="bash">&amp;&amp; apt-get clean -y</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ENV</span> PATH $&#123;MAVEN_HOME&#125;/bin:$&#123;PATH&#125;</span><br></pre></td></tr></table></figure><p>该Dockerfile操作与Jenkins master的Dockerfile基本一致。不过该镜像中缺少libltdl.so.7文件，需要从宿主机中拷贝进去，该文件在slave节点容器中使用docker时会用到，因此十分重要</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;本文在k8s集群中把各种工具（jdk，git, maven等）集成到jenkins，用master/slave模式实现CI/CD。&lt;/p&gt;
&lt;h2 id=&quot;环境&quot;&gt;&lt;a href=&quot;#环境&quot; class=&quot;headerlink&quot; title=&quot;环境&quot;&gt;&lt;/a&gt;环境&lt;/h2&gt;&lt;p&gt;k8s集群    &lt;a href=&quot;https://wandouduoduo.github.io/articles/87f87b20.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考教程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Hubor镜像服务  &lt;a href=&quot;https://wandouduoduo.github.io/articles/b9ccc582.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考教程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;nfs/Ceph持久存储   &lt;a href=&quot;https://wandouduoduo.github.io/articles/3acab424.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;参考教程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://wandouduoduo.github.io/articles/12aa61a7.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;K8s中Jenkins实践教程&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="容器化" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Docker" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/Docker/"/>
    
    
      <category term="K8s" scheme="https://wandouduoduo.netlify.com/tags/K8s/"/>
    
      <category term="Jenkins" scheme="https://wandouduoduo.netlify.com/tags/Jenkins/"/>
    
  </entry>
  
  <entry>
    <title>CentOS7安装指定版本Docker-ce</title>
    <link href="https://wandouduoduo.netlify.com/articles/e09b4ef6.html"/>
    <id>https://wandouduoduo.netlify.com/articles/e09b4ef6.html</id>
    <published>2020-07-02T06:09:58.000Z</published>
    <updated>2020-07-02T06:46:50.242Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Docker版本说明"><a href="#Docker版本说明" class="headerlink" title="Docker版本说明"></a><strong>Docker版本说明</strong></h2><p>Docker-CE指Docker社区版，由社区维护和提供技术支持，为免费版本，适合个人开发人员和小团队使用。</p><p>Docker-EE指Docker企业版，为收费版本，由售后团队和技术团队提供技术支持，专为企业开发和IT团队而设计。</p><p>相比Docker-EE，增加一些额外功能，更重要的是提供了更安全的保障。</p><p>此外，Docker的发布版本分为Stable版和Edge版，区别在于前者是按季度发布的稳定版(发布慢)，后者是按月发布的边缘版(发布快)。</p><p>通常情况下，Docker-CE足以满足我们的需求。</p><a id="more"></a><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h4 id="配置docker-yum源"><a href="#配置docker-yum源" class="headerlink" title="配置docker yum源"></a>配置docker yum源</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo</span><br></pre></td></tr></table></figure><p><img src="/articles/e09b4ef6/1.png" alt></p><h4 id="安装指定版本docker-ce"><a href="#安装指定版本docker-ce" class="headerlink" title="安装指定版本docker-ce"></a>安装指定版本docker-ce</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sudo yum update</span><br><span class="line">sudo yum install -y yum-utils</span><br><span class="line">sudo yum install docker-ce</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看可安装的版本</span></span><br><span class="line">yum list docker-ce --showduplicates | sort -r</span><br><span class="line"></span><br><span class="line"><span class="comment">#安装指定版本</span></span><br><span class="line">yum install docker-ce-&lt;VERSION STRING&gt;</span><br><span class="line"><span class="comment">#如果不指定，默认安装最新版本</span></span><br></pre></td></tr></table></figure><p><img src="/articles/e09b4ef6/2.png" alt></p><h4 id="启动docker"><a href="#启动docker" class="headerlink" title="启动docker"></a>启动docker</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl start docker</span><br><span class="line"><span class="comment">#加入开机启动</span></span><br><span class="line">systemctl <span class="built_in">enable</span> docker</span><br></pre></td></tr></table></figure><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker -v</span><br><span class="line">docker run hello-world</span><br></pre></td></tr></table></figure><p><img src="/articles/e09b4ef6/3.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Docker版本说明&quot;&gt;&lt;a href=&quot;#Docker版本说明&quot; class=&quot;headerlink&quot; title=&quot;Docker版本说明&quot;&gt;&lt;/a&gt;&lt;strong&gt;Docker版本说明&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Docker-CE指Docker社区版，由社区维护和提供技术支持，为免费版本，适合个人开发人员和小团队使用。&lt;/p&gt;
&lt;p&gt;Docker-EE指Docker企业版，为收费版本，由售后团队和技术团队提供技术支持，专为企业开发和IT团队而设计。&lt;/p&gt;
&lt;p&gt;相比Docker-EE，增加一些额外功能，更重要的是提供了更安全的保障。&lt;/p&gt;
&lt;p&gt;此外，Docker的发布版本分为Stable版和Edge版，区别在于前者是按季度发布的稳定版(发布慢)，后者是按月发布的边缘版(发布快)。&lt;/p&gt;
&lt;p&gt;通常情况下，Docker-CE足以满足我们的需求。&lt;/p&gt;
    
    </summary>
    
      <category term="容器化" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Docker" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/Docker/"/>
    
    
      <category term="Docker" scheme="https://wandouduoduo.netlify.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>jenkins配置jdk、git、maven等工具</title>
    <link href="https://wandouduoduo.netlify.com/articles/6f80621c.html"/>
    <id>https://wandouduoduo.netlify.com/articles/6f80621c.html</id>
    <published>2020-07-01T11:26:55.000Z</published>
    <updated>2020-07-01T11:45:54.654Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文详细介绍jenkins配置各种打包工具。</p><a id="more"></a><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>进入首页-》系统管理-》全局工具配置</p><p><img src="/articles/6f80621c/1.png" alt></p><h4 id="配置jdk"><a href="#配置jdk" class="headerlink" title="配置jdk"></a>配置jdk</h4><p><strong>查找jdk安装路径</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果是容器版jenkins，就登进容器里面查看jdk路径</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$JAVA_HOME</span></span><br><span class="line"></span><br><span class="line">/docker-java-home</span><br></pre></td></tr></table></figure><p><strong>配置路径</strong></p><p>新增JDK-》去掉自动安装对勾-》填写JAVA_HOME-》保存,如下图所示：</p><p><img src="/articles/6f80621c/2.png" alt></p><p><img src="/articles/6f80621c/3.png" alt></p><h4 id="配置git"><a href="#配置git" class="headerlink" title="配置git"></a>配置git</h4><p><strong>查找git安装路径</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果是容器版jenkins，就登进容器里面查看</span></span><br><span class="line"></span><br><span class="line">whereis git</span><br><span class="line"></span><br><span class="line">git: /usr/bin/git /usr/share/man/man1/git.1.gz</span><br></pre></td></tr></table></figure><p><strong>配置路径</strong></p><p><img src="/articles/6f80621c/4.png" alt></p><h4 id="配置maven"><a href="#配置maven" class="headerlink" title="配置maven"></a>配置maven</h4><p><strong>查找maven安装路径</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#如果是容器版jenkins，就登进容器里面查看</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$MAVEN_HOME</span></span><br><span class="line"></span><br><span class="line">/usr/<span class="built_in">local</span>/apache-maven-3.5.4</span><br></pre></td></tr></table></figure><p><strong>配置路径</strong></p><p>新增Maven -》去掉自动安装对勾-》填写MAVEN_HOME-》保存  ，如下图所示：</p><p><img src="/articles/6f80621c/5.png" alt></p><p>配置完成，保存即可。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;本文详细介绍jenkins配置各种打包工具。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="CI/CD" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/CI-CD/"/>
    
    
      <category term="Jenkins" scheme="https://wandouduoduo.netlify.com/tags/Jenkins/"/>
    
  </entry>
  
  <entry>
    <title>DevOps工具链</title>
    <link href="https://wandouduoduo.netlify.com/articles/f23d9353.html"/>
    <id>https://wandouduoduo.netlify.com/articles/f23d9353.html</id>
    <published>2020-07-01T08:58:32.000Z</published>
    <updated>2020-07-01T09:30:59.833Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>DevOps 是一个完整的面向IT运维的工作流，以 IT 自动化以及持续集成（CI）、持续部署（CD）为基础，来优化程式开发、测试、系统运维等所有环节。</p><p>DevOps一词的来自于Development和Operations的组合，突出重视软件开发人员和运维人员的沟通合作，通过自动化流程来使得软件构建、测试、发布更加快捷、频繁和可靠。</p><p>DevOps是为了填补开发端和运维端之间的信息鸿沟，改善团队之间的协作关系。不过需要澄清的一点是，从开发到运维，中间还有测试环节。DevOps其实包含了三个部分：开发、测试和运维</p><p>DevOps希望做到的是软件产品交付过程中IT工具链的打通，使得各个团队减少时间损耗，更加高效地协同工作。专家们总结出了下面这个DevOps能力图，良好的闭环可以大大增加整体的产出。</p><a id="more"></a><h2 id="工具链"><a href="#工具链" class="headerlink" title="工具链"></a>工具链</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">现将工具类型及对应的不完全列举整理如下：</span><br><span class="line"></span><br><span class="line">代码管理（SCM）：GitHub、GitLab、BitBucket、SubVersion</span><br><span class="line"></span><br><span class="line">构建工具：Ant、Gradle、maven</span><br><span class="line"></span><br><span class="line">自动部署：Capistrano、CodeDeploy</span><br><span class="line"></span><br><span class="line">持续集成（CI）：Bamboo、Hudson、Jenkins</span><br><span class="line"></span><br><span class="line">配置管理：Ansible、Chef、Puppet、SaltStack、ScriptRock GuardRail</span><br><span class="line"></span><br><span class="line">容器：Docker、LXC、第三方厂商如AWS</span><br><span class="line"></span><br><span class="line">编排：Kubernetes、Core、Apache Mesos、DC/OS</span><br><span class="line"></span><br><span class="line">服务注册与发现：Zookeeper、etcd、Consul</span><br><span class="line"></span><br><span class="line">脚本语言：python、ruby、shell</span><br><span class="line"></span><br><span class="line">日志管理：ELK、Logentries</span><br><span class="line"></span><br><span class="line">系统监控：Datadog、Graphite、Icinga、Nagios</span><br><span class="line"></span><br><span class="line">性能监控：AppDynamics、New Relic、Splunk</span><br><span class="line"></span><br><span class="line">压力测试：JMeter、Blaze Meter、loader.io</span><br><span class="line"></span><br><span class="line">预警：PagerDuty、pingdom、厂商自带如AWS SNS</span><br><span class="line"></span><br><span class="line">HTTP加速器：Varnish</span><br><span class="line"></span><br><span class="line">消息总线：ActiveMQ、SQS</span><br><span class="line"></span><br><span class="line">应用服务器：Tomcat、JBoss</span><br><span class="line"></span><br><span class="line">Web服务器：Apache、Nginx、IIS</span><br><span class="line"></span><br><span class="line">数据库：MySQL、Oracle、PostgreSQL等关系型数据库；cassandra、mongoDB、redis等NoSQL数据库</span><br><span class="line"></span><br><span class="line">项目管理（PM）：Jira、Asana、Taiga、Trello、Basecamp、Pivotal Tracker</span><br><span class="line"></span><br><span class="line">在工具的选择上，需要结合公司业务需求和技术团队情况而定。（注：更多关于工具的详细介绍可以参见此文：51 Best DevOps Tools <span class="keyword">for</span> <span class="comment">#DevOps Engineers）</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;DevOps 是一个完整的面向IT运维的工作流，以 IT 自动化以及持续集成（CI）、持续部署（CD）为基础，来优化程式开发、测试、系统运维等所有环节。&lt;/p&gt;
&lt;p&gt;DevOps一词的来自于Development和Operations的组合，突出重视软件开发人员和运维人员的沟通合作，通过自动化流程来使得软件构建、测试、发布更加快捷、频繁和可靠。&lt;/p&gt;
&lt;p&gt;DevOps是为了填补开发端和运维端之间的信息鸿沟，改善团队之间的协作关系。不过需要澄清的一点是，从开发到运维，中间还有测试环节。DevOps其实包含了三个部分：开发、测试和运维&lt;/p&gt;
&lt;p&gt;DevOps希望做到的是软件产品交付过程中IT工具链的打通，使得各个团队减少时间损耗，更加高效地协同工作。专家们总结出了下面这个DevOps能力图，良好的闭环可以大大增加整体的产出。&lt;/p&gt;
    
    </summary>
    
      <category term="心得体会" scheme="https://wandouduoduo.netlify.com/categories/%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/"/>
    
      <category term="Devops" scheme="https://wandouduoduo.netlify.com/categories/%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/Devops/"/>
    
    
      <category term="Devops" scheme="https://wandouduoduo.netlify.com/tags/Devops/"/>
    
  </entry>
  
  <entry>
    <title>Centos7安装gitlab详细教程</title>
    <link href="https://wandouduoduo.netlify.com/articles/adf03e2d.html"/>
    <id>https://wandouduoduo.netlify.com/articles/adf03e2d.html</id>
    <published>2020-06-30T10:09:38.000Z</published>
    <updated>2020-06-30T11:38:55.028Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>博客中有docker直接启动gitlab服务，这里再补充下直接裸机部署gitlab服务的教程。</p><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>操作系统：centos7.5</p><p>服务端：192.168.0.74</p><p>客户端：192.168.0.73</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h4 id="服务端终端操作"><a href="#服务端终端操作" class="headerlink" title="服务端终端操作"></a>服务端终端操作</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#打开系统防火墙HTTP和SSH访问</span></span><br><span class="line">yum install curl policycoreutils openssh-server openssh-clients -y</span><br><span class="line">systemctl <span class="built_in">enable</span> sshd</span><br><span class="line">systemctl start sshd</span><br><span class="line">yum install postfix -y</span><br><span class="line">systemctl <span class="built_in">enable</span> postfix</span><br><span class="line">systemctl start postfix</span><br><span class="line">firewall-cmd --permanent --add-service=http</span><br><span class="line">systemctl reload firewalld </span><br><span class="line"></span><br><span class="line"><span class="comment">#添加GitLab镜像源并安装</span></span><br><span class="line">curl -sS http://packages.gitlab.com.cn/install/gitlab-ce/script.rpm.sh | sudo bash</span><br><span class="line"></span><br><span class="line"><span class="comment">#这是官方的yum源，安装速度会比较慢，可以使用国内源，修改如下文件即可：</span></span><br><span class="line">cat&gt;&gt;/etc/yum.repos.d/gitlab_gitlab-ce.repo&lt;&lt;EOF</span><br><span class="line">[gitlab-ce]</span><br><span class="line">name=gitlab-ce</span><br><span class="line">baseurl=http://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el7</span><br><span class="line">repo_gpgcheck=0</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=1</span><br><span class="line">gpgkey=https://packages.gitlab.com/gpg.key</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment">#安装</span></span><br><span class="line">yum install gitlab-ce -y</span><br><span class="line"></span><br><span class="line"><span class="comment">#修改配置，指定服务器ip和自定义端口</span></span><br><span class="line">vim /etc/gitlab/gitlab.rb</span><br><span class="line"></span><br><span class="line">external_url <span class="string">'http://192.168.0.94:8081'</span>       <span class="comment">#本地ip+端口</span></span><br><span class="line"><span class="comment">#注意这里设置的端口不能被占用，默认是8080端口，如果8080已经使用，请自定义其它端口，并在防火墙设置开放相对应得端口</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 重置GitLab</span></span><br><span class="line">gitlab-ctl reconfigure   <span class="comment">#需要很长时间不要按ctrl+c  每次修改配置文件都需要重置，否则不生效</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#出现如下结果表明重置成功</span></span><br><span class="line">Running handlers:</span><br><span class="line">Running handlers complete</span><br><span class="line">Chef Client finished, 454/655 resources updated <span class="keyword">in</span> 04 minutes 29 seconds</span><br><span class="line">gitlab Reconfigured!</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动GitLab</span></span><br><span class="line">gitlab-ctl start</span><br><span class="line"></span><br><span class="line">ok: run: gitlab-git-http-server: (pid 3922) 1s</span><br><span class="line">ok: run: logrotate: (pid 3929) 0s</span><br><span class="line">ok: run: nginx: (pid 3936) 1s</span><br><span class="line">ok: run: postgresql: (pid 3941) 0s</span><br><span class="line">ok: run: redis: (pid 3950) 0s</span><br><span class="line">ok: run: sidekiq: (pid 3955) 0s</span><br><span class="line">ok: run: unicorn: (pid 3961) 1s</span><br><span class="line"><span class="comment">#提示“ok: run:”表示启动成功</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止gilab</span></span><br><span class="line">gitlab-ctl stop</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启</span></span><br><span class="line">gitlab-ctl restart</span><br></pre></td></tr></table></figure><h4 id="服务端页面操作"><a href="#服务端页面操作" class="headerlink" title="服务端页面操作"></a>服务端页面操作</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#如果没有域名，直接输入服务器ip和指定端口进行访问</span></span><br><span class="line"><span class="comment">#第一次访问GitLab，系统会重定向页面到重定向到重置密码页面，你需要输入初始化管理员账号的密码，管理员的用户名为root，初始密码为5iveL!fe。重置密码后，新密码即为刚输入的密码。</span></span><br><span class="line"></span><br><span class="line">http://192.168.0.94:8081</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始账户: root 密码: 5iveL!fe</span></span><br><span class="line"><span class="comment">#第一次登录需要修改密码</span></span><br><span class="line"><span class="comment">#修改密码为：</span></span><br><span class="line">jenkins@123</span><br><span class="line"></span><br><span class="line"><span class="comment">#重新登录</span></span><br><span class="line">root/jenkins@123</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建项目</span></span><br><span class="line"><span class="comment">#创建一个hello项目 --&gt; 点击小扳手（管理区域）--&gt; 新建项目</span></span><br><span class="line"></span><br><span class="line">Project name为项目的名称</span><br><span class="line">Import project from从其他代码仓库导入代码</span><br><span class="line">Project description项目说明</span><br><span class="line">Visibility Level项目等级</span><br><span class="line">private只有你自己跟你指定的人能看</span><br><span class="line">internal只有拥有gitlab账号的用户可以查看与拉取</span><br><span class="line">public该项目能被所有人访问到并<span class="built_in">clone</span></span><br></pre></td></tr></table></figure><h4 id="客户端操作"><a href="#客户端操作" class="headerlink" title="客户端操作"></a>客户端操作</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#安装git</span></span><br><span class="line">yum install -y git</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成ssh密钥</span></span><br><span class="line">ssh-keygen -t rsa -f /root/.ssh/id_rsa -P <span class="string">""</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#添加ssh-key公钥到gitlab， 需要连接gitlab服务器，就需要把他的公钥添加到gitlab服务器上</span></span><br><span class="line"><span class="comment">#查看</span></span><br><span class="line">cat ~/.ssh/id_rsa.pub</span><br><span class="line"></span><br><span class="line">ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCxiS/XYe2x+iwhU6PuiV8XTmNgQ9w3FMgC4JuPkyHwIhHxh+1M/Evj7AqGJIURcrl1CHqJKng8d/M8WT+NoqwlA524hKpjv4RgEW2dl1kLfQLVVJmoB9NOvr5+cdmQ1V8xuhhxtcLw7JhigXu7HNCEs6bJ+MVwD83oc9jV7HVB3mgmZrk2+Ntxz8cr/W9MoLmkqEQJ3JYmsXmJsofcMPOQJNpmIScAu7kWJ4tIJAN5SuhNjQTw+v5HgLJT/LTdf/0DUCP55ulsDWP03ilIsEMT1FX1mz2tkQsopim2Z/Tqtk96OTNYB5svNb+nJXkRUskbQ+pYjU3hr0kxkAr/NEzX root@test3</span><br><span class="line"></span><br><span class="line"><span class="comment">#页面登录gitlab，在右上角设置中找到SSH密钥</span></span><br><span class="line"><span class="comment">#将刚才生成的公钥内容复制到密钥中，标题名字随意</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#克隆项目</span></span><br><span class="line">mkdir /root/<span class="built_in">test</span>/</span><br><span class="line"><span class="built_in">cd</span> /root/<span class="built_in">test</span>/</span><br><span class="line">git <span class="built_in">clone</span> git@192.168.0.94:root/hello.git</span><br><span class="line"><span class="comment">#这里有个警告，因为刚才创建的版本库是空的，所以这里提醒，克隆了一个空库</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#推送代码</span></span><br><span class="line"><span class="comment">#创建一个文件</span></span><br><span class="line"><span class="built_in">cd</span> /root/<span class="built_in">test</span>/hello/</span><br><span class="line">touch read.txt</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Hello world"</span> &gt;&gt; read.txt </span><br><span class="line"></span><br><span class="line"><span class="comment">#将文件添加到仓库</span></span><br><span class="line">git add read.txt</span><br><span class="line"></span><br><span class="line"><span class="comment">#配置用户名和邮箱</span></span><br><span class="line">git config --global user.email <span class="string">"wandouduoduo@163.com"</span></span><br><span class="line">git config --global user.name <span class="string">"wandouduoduo"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#提交文件到仓库</span></span><br><span class="line">git commit -m <span class="string">"wandouduoduo"</span>    </span><br><span class="line"><span class="comment">#2nd Commit是本次提交的说明</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建tag版本</span></span><br><span class="line">git tag 1.0.2</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看git版本号</span></span><br><span class="line">git tag</span><br><span class="line"></span><br><span class="line"><span class="comment">#推送</span></span><br><span class="line">git push origin master</span><br><span class="line"></span><br><span class="line"><span class="comment">#在gitlab上看到，已经推送成功了</span></span><br></pre></td></tr></table></figure><h2 id="汉化"><a href="#汉化" class="headerlink" title="汉化"></a>汉化</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建目录</span></span><br><span class="line">mkdir /home/<span class="built_in">local</span>/gitlab</span><br><span class="line"><span class="built_in">cd</span> /home/<span class="built_in">local</span>/gitlab</span><br><span class="line"></span><br><span class="line"><span class="comment">#安装git</span></span><br><span class="line">yum install -y git</span><br><span class="line"></span><br><span class="line"><span class="comment">#下载最新的汉化包：</span></span><br><span class="line">git <span class="built_in">clone</span> https://gitlab.com/xhang/gitlab.git</span><br><span class="line"><span class="comment">#如果是要下载老版本的汉化包，需要加上老版本的分支。以10.0.2为例，可以运行如下语句：</span></span><br><span class="line">git <span class="built_in">clone</span> https://gitlab.com/xhang/gitlab.git -b v10.0.2-zh</span><br><span class="line"></span><br><span class="line"><span class="comment">#停止GitLab并执行如下语句：</span></span><br><span class="line">gitlab-ctl stop</span><br><span class="line">\cp -rf /home/<span class="built_in">local</span>/gitlab/* /opt/gitlab/embedded/service/gitlab-rails/ </span><br><span class="line"></span><br><span class="line"><span class="comment">#配置和重启</span></span><br><span class="line">sudo gitlab-ctl reconfigure</span><br><span class="line">sudo gitlab-ctl restart</span><br></pre></td></tr></table></figure><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#启动所有服务</span></span><br><span class="line">gitlab-ctl start</span><br><span class="line"></span><br><span class="line"><span class="comment">#启动单独一个服务</span></span><br><span class="line">gitlab-ctl start nginx</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看日志，查看所有日志</span></span><br><span class="line">gitlab-ctl tail</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看具体一个日志,类似tail -f</span></span><br><span class="line">gitlab-ctl tail nginx</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;博客中有docker直接启动gitlab服务，这里再补充下直接裸机部署gitlab服务的教程。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Git" scheme="https://wandouduoduo.netlify.com/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>k8s之jenkins动态创建slave</title>
    <link href="https://wandouduoduo.netlify.com/articles/12aa61a7.html"/>
    <id>https://wandouduoduo.netlify.com/articles/12aa61a7.html</id>
    <published>2020-06-30T07:42:05.000Z</published>
    <updated>2020-07-01T11:27:39.674Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h2><p>持续构建与发布是我们日常工作中必不可少的一个步骤，目前大多公司都采用 Jenkins 集群来搭建符合需求的 CI/CD 流程，然而传统的 Jenkins Slave 一主多从方式会存在一些痛点，比如：</p><ul><li>主 Master 发生单点故障时，整个流程都不可用了</li><li>每个 Slave 的配置环境不一样，来完成不同语言的编译打包等操作，但是这些差异化的配置导致管理起来非常不方便，维护起来也是比较费劲</li><li>资源分配不均衡，有的 Slave 要运行的 job 出现排队等待，而有的 Slave 处于空闲状态</li><li>资源有浪费，每台 Slave 可能是物理机或者虚拟机，当 Slave 处于空闲状态时，也不会完全释放掉资源。</li></ul><p>正因为上面的这些种种痛点，我们渴望一种更高效更可靠的方式来完成这个 CI/CD 流程，而 Docker 虚拟化容器技术能很好的解决这个痛点，又特别是在 Kubernetes 集群环境下面能够更好来解决上面的问题，下图是基于 Kubernetes 搭建 Jenkins 集群的简单示意图：<br><img src="/articles/12aa61a7/1.png" alt></p><p>从图上可以看到 Jenkins Master 和 Jenkins Slave 以 Pod 形式运行在 Kubernetes 集群的 Node 上，Master 运行在其中一个节点，并且将其配置数据存储到一个 Volume 上去，Slave 运行在各个节点上，并且它不是一直处于运行状态，它会按照需求动态的创建并自动删除。</p><p>这种方式的工作流程大致为：当 Jenkins Master 接受到 Build 请求时，会根据配置的 Label 动态创建一个运行在 Pod 中的 Jenkins Slave 并注册到 Master 上，当运行完 Job 后，这个 Slave 会被注销并且这个 Pod 也会自动删除，恢复到最初状态。</p><p>使用jenkins动态slave的优势：</p><ul><li><strong>服务高可用</strong>，当 Jenkins Master 出现故障时，Kubernetes 会自动创建一个新的 Jenkins Master 容器，并且将 Volume 分配给新创建的容器，保证数据不丢失，从而达到集群服务高可用。</li><li><strong>动态伸缩</strong>，合理使用资源，每次运行 Job 时，会自动创建一个 Jenkins Slave，Job 完成后，Slave 自动注销并删除容器，资源自动释放，而且 Kubernetes 会根据每个资源的使用情况，动态分配 Slave 到空闲的节点上创建，降低出现因某节点资源利用率高，还排队等待在该节点的情况。</li><li><strong>扩展性好</strong>，当 Kubernetes 集群的资源严重不足而导致 Job 排队等待时，可以很容易的添加一个 Kubernetes Node 到集群中，从而实现扩展。</li></ul><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p><a href="https://wandouduoduo.github.io/articles/87f87b20.html" target="_blank" rel="noopener">k8s 集群</a> </p><p>版本:  1.18.3</p><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="https://www.cnblogs.com/effortsing/p/10486960.html" target="_blank" rel="noopener">网友博客</a></p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h4 id="创建namespace"><a href="#创建namespace" class="headerlink" title="创建namespace"></a>创建namespace</h4><p>创建一个kube-ops的 namespace（为了方便管理）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create namespace kube-ops</span><br></pre></td></tr></table></figure><h4 id="创建pv和pvc"><a href="#创建pv和pvc" class="headerlink" title="创建pv和pvc"></a>创建pv和pvc</h4><p>创建pv、pvc或使用storageclass都可以，本实验使用前者（pvc.yaml）</p><p><em>注意：下面使用的是nfs的存储方式。</em><a href="https://wandouduoduo.github.io/articles/3acab424.html#more" target="_blank" rel="noopener">详情参考</a></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">opspv</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  capacity:</span></span><br><span class="line"><span class="attr">    storage:</span> <span class="number">3</span><span class="string">Gi</span></span><br><span class="line"><span class="attr">  accessModes:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">ReadWriteMany</span></span><br><span class="line"><span class="attr">  persistentVolumeReclaimPolicy:</span> <span class="string">Recycle</span></span><br><span class="line"><span class="attr">  storageClassName:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">  nfs:</span></span><br><span class="line"><span class="attr">    server:</span> <span class="number">10.220</span><span class="number">.169</span><span class="number">.231</span></span><br><span class="line"><span class="attr">    path:</span> <span class="string">/data/k8s-volume</span></span><br><span class="line">    </span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">opspvc</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-ops</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  accessModes:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ReadWriteMany</span></span><br><span class="line"><span class="attr">  storageClassName:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="attr">    requests:</span></span><br><span class="line"><span class="attr">      storage:</span> <span class="number">3</span><span class="string">Gi</span></span><br></pre></td></tr></table></figure><p>创建需要用到的 PVC 对象：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f pvc.yaml</span><br></pre></td></tr></table></figure><h4 id="权限绑定"><a href="#权限绑定" class="headerlink" title="权限绑定"></a>权限绑定</h4><p>给jenkins绑定权限（rbac.yaml），如果对rbac不熟悉，可以先给定cluster-admin权限</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">jenkins</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-ops</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">jenkins</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="attr">  - apiGroups:</span> <span class="string">["extensions",</span> <span class="string">"apps"</span><span class="string">]</span></span><br><span class="line"><span class="attr">    resources:</span> <span class="string">["deployments"]</span></span><br><span class="line"><span class="attr">    verbs:</span> <span class="string">["create",</span> <span class="string">"delete"</span><span class="string">,</span> <span class="string">"get"</span><span class="string">,</span> <span class="string">"list"</span><span class="string">,</span> <span class="string">"watch"</span><span class="string">,</span> <span class="string">"patch"</span><span class="string">,</span> <span class="string">"update"</span><span class="string">]</span></span><br><span class="line"><span class="attr">  - apiGroups:</span> <span class="string">[""]</span></span><br><span class="line"><span class="attr">    resources:</span> <span class="string">["services"]</span></span><br><span class="line"><span class="attr">    verbs:</span> <span class="string">["create",</span> <span class="string">"delete"</span><span class="string">,</span> <span class="string">"get"</span><span class="string">,</span> <span class="string">"list"</span><span class="string">,</span> <span class="string">"watch"</span><span class="string">,</span> <span class="string">"patch"</span><span class="string">,</span> <span class="string">"update"</span><span class="string">]</span></span><br><span class="line"><span class="attr">  - apiGroups:</span> <span class="string">[""]</span></span><br><span class="line"><span class="attr">    resources:</span> <span class="string">["pods"]</span></span><br><span class="line"><span class="attr">    verbs:</span> <span class="string">["create","delete","get","list","patch","update","watch"]</span></span><br><span class="line"><span class="attr">  - apiGroups:</span> <span class="string">[""]</span></span><br><span class="line"><span class="attr">    resources:</span> <span class="string">["pods/exec"]</span></span><br><span class="line"><span class="attr">    verbs:</span> <span class="string">["create","delete","get","list","patch","update","watch"]</span></span><br><span class="line"><span class="attr">  - apiGroups:</span> <span class="string">[""]</span></span><br><span class="line"><span class="attr">    resources:</span> <span class="string">["pods/log"]</span></span><br><span class="line"><span class="attr">    verbs:</span> <span class="string">["get","list","watch"]</span></span><br><span class="line"><span class="attr">  - apiGroups:</span> <span class="string">[""]</span></span><br><span class="line"><span class="attr">    resources:</span> <span class="string">["secrets"]</span></span><br><span class="line"><span class="attr">    verbs:</span> <span class="string">["get"]</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">jenkins</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-ops</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">jenkins</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">  - kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">jenkins</span></span><br><span class="line"><span class="attr">    namespace:</span> <span class="string">kube-ops</span></span><br></pre></td></tr></table></figure><p>创建 rbac 相关的资源对象：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f rbac.yaml</span><br><span class="line">serviceaccount <span class="string">"jenkins"</span> created</span><br><span class="line">role.rbac.authorization.k8s.io <span class="string">"jenkins"</span> created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io <span class="string">"jenkins"</span> created</span><br></pre></td></tr></table></figure><h4 id="创建jenkins-master"><a href="#创建jenkins-master" class="headerlink" title="创建jenkins  master"></a>创建jenkins  master</h4><p>新建一个 Deployment：(jenkins.yaml)</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">jenkins</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-ops</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">jenkins</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">jenkins</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      terminationGracePeriodSeconds:</span> <span class="number">10</span></span><br><span class="line"><span class="attr">      serviceAccount:</span> <span class="string">jenkins</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">jenkins</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">jenkins/jenkins:lts</span></span><br><span class="line"><span class="attr">        imagePullPolicy:</span> <span class="string">IfNotPresent</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">          protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">50000</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">agent</span></span><br><span class="line"><span class="attr">          protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">        resources:</span></span><br><span class="line"><span class="attr">          limits:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">1000</span><span class="string">m</span></span><br><span class="line"><span class="attr">            memory:</span> <span class="number">1</span><span class="string">Gi</span></span><br><span class="line"><span class="attr">          requests:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">500</span><span class="string">m</span></span><br><span class="line"><span class="attr">            memory:</span> <span class="number">512</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">        livenessProbe:</span></span><br><span class="line"><span class="attr">          httpGet:</span></span><br><span class="line"><span class="attr">            path:</span> <span class="string">/login</span></span><br><span class="line"><span class="attr">            port:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">          initialDelaySeconds:</span> <span class="number">60</span></span><br><span class="line"><span class="attr">          timeoutSeconds:</span> <span class="number">5</span></span><br><span class="line"><span class="attr">          failureThreshold:</span> <span class="number">12</span></span><br><span class="line"><span class="attr">        readinessProbe:</span></span><br><span class="line"><span class="attr">          httpGet:</span></span><br><span class="line"><span class="attr">            path:</span> <span class="string">/login</span></span><br><span class="line"><span class="attr">            port:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">          initialDelaySeconds:</span> <span class="number">60</span></span><br><span class="line"><span class="attr">          timeoutSeconds:</span> <span class="number">5</span></span><br><span class="line"><span class="attr">          failureThreshold:</span> <span class="number">12</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">jenkinshome</span></span><br><span class="line"><span class="attr">          subPath:</span> <span class="string">jenkins</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/var/jenkins_home</span></span><br><span class="line"><span class="attr">        env:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">LIMITS_MEMORY</span></span><br><span class="line"><span class="attr">          valueFrom:</span></span><br><span class="line"><span class="attr">            resourceFieldRef:</span></span><br><span class="line"><span class="attr">              resource:</span> <span class="string">limits.memory</span></span><br><span class="line"><span class="attr">              divisor:</span> <span class="number">1</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">JAVA_OPTS</span></span><br><span class="line"><span class="attr">          value:</span> <span class="bullet">-Xmx$(LIMITS_MEMORY)m</span> <span class="attr">-XshowSettings:vm</span> <span class="bullet">-Dhudson.slaves.NodeProvisioner.initialDelay=0</span> <span class="bullet">-Dhudson.slaves.NodeProvisioner.MARGIN=50</span> <span class="bullet">-Dhudson.slaves.NodeProvisioner.MARGIN0=0.85</span> <span class="bullet">-Duser.timezone=Asia/Shanghai</span></span><br><span class="line"><span class="attr">      securityContext:</span></span><br><span class="line"><span class="attr">        fsGroup:</span> <span class="number">1000</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">jenkinshome</span></span><br><span class="line"><span class="attr">        persistentVolumeClaim:</span></span><br><span class="line"><span class="attr">          claimName:</span> <span class="string">opspvc</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">jenkins</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-ops</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">jenkins</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">jenkins</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">NodePort</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">    port:</span> <span class="number">8080</span></span><br><span class="line"><span class="attr">    targetPort:</span> <span class="string">web</span></span><br><span class="line"><span class="attr">    nodePort:</span> <span class="number">30002</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">agent</span></span><br><span class="line"><span class="attr">    port:</span> <span class="number">50000</span></span><br><span class="line"><span class="attr">    targetPort:</span> <span class="string">agent</span></span><br></pre></td></tr></table></figure><p>这里为了方便，通过 NodePort 的形式来暴露 Jenkins 的 web 服务，固定为30002端口，另外还需要暴露一个 agent 的端口，这个端口主要是用于 Jenkins 的 master 和 slave 之间通信使用的。<br>创建 Jenkins 服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create -f jenkins.yaml</span><br><span class="line">deployment.extensions <span class="string">"jenkins"</span> created</span><br><span class="line">service <span class="string">"jenkins"</span> created</span><br></pre></td></tr></table></figure><h4 id="排错"><a href="#排错" class="headerlink" title="排错"></a>排错</h4><p>创建完成后，要去拉取镜像可能需要等待一会儿，查看下 Pod 的状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods -n kube-ops</span><br><span class="line">NAME                        READY     STATUS    RESTARTS   AGE</span><br><span class="line">jenkins-7f5494cd44-pqpzs   0/1       Running   0          2m</span><br></pre></td></tr></table></figure><p>可以看到该 Pod 处于 Running 状态，但是 READY 值确为0，然后我们用 describe 命令去查看下该 Pod 的详细信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl describe pod jenkins-7f5494cd44-pqpzs -n kube-ops</span><br><span class="line">...</span><br><span class="line">Normal   Created                3m                kubelet, node01    Created container</span><br><span class="line">  Normal   Started                3m                kubelet, node01    Started container</span><br><span class="line">  Warning  Unhealthy              1m (x10 over 2m)  kubelet, node01    Liveness probe failed: Get http://10.244.1.165:8080/login: dial tcp 10.244.1.165:8080: getsockopt: connection refused</span><br><span class="line">  Warning  Unhealthy              1m (x10 over 2m)  kubelet, node01    Readiness probe failed: Get http://10.244.1.165:8080/login: dial tcp 10.244.1.165:8080: getsockopt: connection refused</span><br></pre></td></tr></table></figure><p>可以看到上面的 Warning 信息，健康检查没有通过，具体原因是什么引起的呢？可以通过查看日志进一步了解：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl logs -f jenkins-7f5494cd44-pqpzs -n kube-ops</span><br><span class="line">touch: cannot touch <span class="string">'/var/jenkins_home/copy_reference_file.log'</span>: Permission denied</span><br><span class="line">Can not write to /var/jenkins_home/copy_reference_file.log. Wrong volume permissions?</span><br></pre></td></tr></table></figure><p>很明显可以看到上面的错误信息，意思就是我们没有权限在 jenkins 的 home 目录下面创建文件，这是因为默认的镜像使用的是 jenkins 这个用户，而我们通过 PVC 挂载到 nfs 服务器的共享数据目录下面却是 root 用户的，所以没有权限访问该目录，要解决该问题，也很简单，我只需要在 nfs 共享数据目录下面把我们的目录权限重新分配下即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mount -t nfs 10.220.169.231:/data/k8s-volume /data/k8s</span><br><span class="line">chown -R 1000 /data/k8s</span><br></pre></td></tr></table></figure><p>然后重新创建：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl delete -f jenkins.yaml</span><br><span class="line">deployment.extensions <span class="string">"jenkins"</span> deleted</span><br><span class="line">service <span class="string">"jenkins"</span> deleted</span><br><span class="line">$ kubectl create -f jenkins.yaml</span><br><span class="line">deployment.extensions <span class="string">"jenkins"</span> created</span><br><span class="line">service <span class="string">"jenkins"</span> created</span><br></pre></td></tr></table></figure><p>现在再去查看新生成的 Pod 已经没有错误信息了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pods -n kube-ops</span><br><span class="line">NAME                        READY     STATUS        RESTARTS   AGE</span><br><span class="line">jenkins-7f5494cd44-smn2r   1/1       Running       0          25s</span><br></pre></td></tr></table></figure><h4 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h4><p>等到服务启动成功后，可以根据Node节点的 IP:30002 端口就可以访问 jenkins 服务了，可以根据提示信息进行安装配置即可：</p><p><img src="/articles/12aa61a7/3.png" alt></p><p>初始化的密码可以在 jenkins 的容器的日志中进行查看，也可以直接在 nfs 的共享数据目录中查看：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cat /data/k8s/jenkins/secrets/initialAdminPassword</span><br><span class="line">1974d7a773574a9ca58a6611bc1bed7f</span><br></pre></td></tr></table></figure><p>然后选择安装推荐的插件即可。</p><p><img src="/articles/12aa61a7/2.png" alt></p><p>安装完成后添加管理员帐号即可进入到 jenkins 主界面：</p><p><img src="/articles/12aa61a7/4.png" alt></p><h4 id="配置jenkins动态slave"><a href="#配置jenkins动态slave" class="headerlink" title="配置jenkins动态slave"></a>配置jenkins动态slave</h4><p><strong>安装kubernetes 插件</strong></p><p>点击 Manage Jenkins -&gt; 插件管理-&gt; 可用 -&gt; Kubernetes plugin 勾选安装即可。（如果搜索没有Kubernetes plugin，即选择Kubernetes），然后重启jenkins，使之生效。<br><img src="/articles/12aa61a7/5.png" alt></p><p><strong>插件配置</strong></p><p>点击 Manage Jenkins —&gt; 系统配置 —&gt; (拖到最下方)Add a new cloud —&gt; 选择 Kubernetes，然后填写 Kubernetes 和 Jenkins 配置信息。<br><img src="/articles/12aa61a7/7.png" alt></p><p><img src="/articles/12aa61a7/8.png" alt></p><p><em>另外需要注意，如果这里 Test Connection 失败的话，很有可能是权限问题，这里就需要把 jenkins 的 serviceAccount 对应的 secret 添加到这里的 Credentials 里面。</em></p><p><strong>配置 Pod Template</strong></p><p>其实就是配置 Jenkins Slave 运行的 Pod 模板，命名空间同样使用 kube-ops，Labels 这里也非常重要，对于后面执行 Job 的时候需要用到该值，这里使用的是 cnych/jenkins:jnlp 这个镜像，这个镜像是在官方的 jnlp 镜像基础上定制的，加入了 kubectl 等一些实用的工具。</p><p><img src="/articles/12aa61a7/9.png" alt></p><p>需要在下面挂载两个主机目录，一个是/var/run/docker.sock，该文件是用于 Pod 中的容器能够共享宿主机的 Docker，使用 docker in docker 的方式，Docker 二进制文件已经打包到上面的镜像中了，另外一个目录下/root/.kube目录，将这个目录挂载到容器的/root/.kube目录下面这是为了能够在 Pod 的容器中能够使用 kubectl 工具来访问 Kubernetes 集群，方便后面在 Slave Pod 部署 Kubernetes 应用。<br><img src="/articles/12aa61a7/10.png" alt></p><p>另外还有几个参数需要注意，如下图中的  <strong>代理的空闲存活时间（分）(Time in minutes to retain slave when idle)</strong>，这个参数表示的意思是当处于空闲状态的时候保留 Slave Pod 多长时间，这个参数最好保存默认就行了，如果你设置过大的话，Job 任务执行完成后，对应的 Slave Pod 就不会立即被销毁删除。（如没有，请忽略））<br><img src="/articles/12aa61a7/11.png" alt></p><p>另外在配置了后运行 Slave Pod 的时候出现了权限问题，因为 Jenkins Slave Pod 中没有配置权限，所以需要配置上 ServiceAccount，在 Slave Pod 配置的地方点击下面的高级，添加上对应的 ServiceAccount 即可：</p><p><img src="/articles/12aa61a7/12.png" alt></p><p>还有一个问题在配置完成后发现启动 Jenkins Slave Pod 的时候，出现 Slave Pod 连接不上，然后尝试100次连接之后销毁 Pod，然后会再创建一个 Slave Pod 继续尝试连接，无限循环，类似于下面的信息：（如没有，请忽略）<br><img src="/articles/12aa61a7/13.png" alt></p><p>如果出现这种情况的话就需要将 Slave Pod 中的运行命令和参数两个值给清空掉</p><p><img src="/articles/12aa61a7/14.png" alt></p><p>到这里 Kubernetes Plugin 插件就算配置完成了。</p><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>Kubernetes 插件的配置工作完成了，接下来添加一个 Job 任务，看是否能够在 Slave Pod 中执行，任务执行完成后看 Pod 是否会被销毁。</p><p>在 Jenkins 首页点击create new jobs，创建一个测试的任务，输入任务名称，然后我们选择 Freestyle project 类型的任务：<br> 注意在下面的 Label Expression 这里要填入hwzx-cmp，就是前面我们配置的 Slave Pod 中的 Label，这两个地方必须保持一致</p><p><img src="/articles/12aa61a7/15.png" alt></p><p>然后往下拉，在 Build 区域选择Execute shell</p><p><img src="/articles/12aa61a7/16.png" alt></p><p>然后输入测试命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"测试 Kubernetes 动态生成 jenkins slave"</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"==============docker in docker==========="</span></span><br><span class="line">docker info</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"=============kubectl============="</span></span><br><span class="line">kubectl get pods</span><br></pre></td></tr></table></figure><p><img src="/articles/12aa61a7/17.png" alt></p><p>现在直接在页面点击做成的 Build now 触发构建即可，然后观察 Kubernetes 集群中 Pod 的变化</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod -n kube-ops -o wide</span><br></pre></td></tr></table></figure><p><img src="/articles/12aa61a7/18.png" alt></p><p>可以看到在击立刻构建的时候可以看到一个新的 Pod：jnlp-r0wt6   被创建了，这就是我们的 Jenkins Slave。</p><p>查看控制台信息</p><p><img src="/articles/12aa61a7/20.png" alt></p><p><img src="/articles/12aa61a7/21.png" alt></p><p>到这里证明任务已经构建完成，然后这个时候再去集群查看 Pod 列表，发现 kube-ops 这个 namespace 下面已经没有之前的 Slave 这个 Pod 了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod -n kube-ops -o wide</span><br></pre></td></tr></table></figure><p><img src="/articles/12aa61a7/22.png" alt></p><p>到这里就完成了使用 Kubernetes 动态生成 Jenkins Slave 的方法。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简述&quot;&gt;&lt;a href=&quot;#简述&quot; class=&quot;headerlink&quot; title=&quot;简述&quot;&gt;&lt;/a&gt;简述&lt;/h2&gt;&lt;p&gt;持续构建与发布是我们日常工作中必不可少的一个步骤，目前大多公司都采用 Jenkins 集群来搭建符合需求的 CI/CD 流程，然而传统的 Jenkins Slave 一主多从方式会存在一些痛点，比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;主 Master 发生单点故障时，整个流程都不可用了&lt;/li&gt;
&lt;li&gt;每个 Slave 的配置环境不一样，来完成不同语言的编译打包等操作，但是这些差异化的配置导致管理起来非常不方便，维护起来也是比较费劲&lt;/li&gt;
&lt;li&gt;资源分配不均衡，有的 Slave 要运行的 job 出现排队等待，而有的 Slave 处于空闲状态&lt;/li&gt;
&lt;li&gt;资源有浪费，每台 Slave 可能是物理机或者虚拟机，当 Slave 处于空闲状态时，也不会完全释放掉资源。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;正因为上面的这些种种痛点，我们渴望一种更高效更可靠的方式来完成这个 CI/CD 流程，而 Docker 虚拟化容器技术能很好的解决这个痛点，又特别是在 Kubernetes 集群环境下面能够更好来解决上面的问题，下图是基于 Kubernetes 搭建 Jenkins 集群的简单示意图：&lt;br&gt;&lt;img src=&quot;/articles/12aa61a7/1.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;从图上可以看到 Jenkins Master 和 Jenkins Slave 以 Pod 形式运行在 Kubernetes 集群的 Node 上，Master 运行在其中一个节点，并且将其配置数据存储到一个 Volume 上去，Slave 运行在各个节点上，并且它不是一直处于运行状态，它会按照需求动态的创建并自动删除。&lt;/p&gt;
&lt;p&gt;这种方式的工作流程大致为：当 Jenkins Master 接受到 Build 请求时，会根据配置的 Label 动态创建一个运行在 Pod 中的 Jenkins Slave 并注册到 Master 上，当运行完 Job 后，这个 Slave 会被注销并且这个 Pod 也会自动删除，恢复到最初状态。&lt;/p&gt;
&lt;p&gt;使用jenkins动态slave的优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;服务高可用&lt;/strong&gt;，当 Jenkins Master 出现故障时，Kubernetes 会自动创建一个新的 Jenkins Master 容器，并且将 Volume 分配给新创建的容器，保证数据不丢失，从而达到集群服务高可用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动态伸缩&lt;/strong&gt;，合理使用资源，每次运行 Job 时，会自动创建一个 Jenkins Slave，Job 完成后，Slave 自动注销并删除容器，资源自动释放，而且 Kubernetes 会根据每个资源的使用情况，动态分配 Slave 到空闲的节点上创建，降低出现因某节点资源利用率高，还排队等待在该节点的情况。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;扩展性好&lt;/strong&gt;，当 Kubernetes 集群的资源严重不足而导致 Job 排队等待时，可以很容易的添加一个 Kubernetes Node 到集群中，从而实现扩展。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="容器化" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Docker" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/Docker/"/>
    
    
      <category term="K8s" scheme="https://wandouduoduo.netlify.com/tags/K8s/"/>
    
      <category term="Jenkins" scheme="https://wandouduoduo.netlify.com/tags/Jenkins/"/>
    
  </entry>
  
  <entry>
    <title>k8s之存储服务</title>
    <link href="https://wandouduoduo.netlify.com/articles/3acab424.html"/>
    <id>https://wandouduoduo.netlify.com/articles/3acab424.html</id>
    <published>2020-06-30T04:19:41.000Z</published>
    <updated>2020-06-30T10:01:34.455Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文详细介绍了kubernentes的存储，使用NFS进行演示，让你充分了解和使用pv和pvc，可以举一反三的使用持久化存储。</p><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><h4 id="Volume"><a href="#Volume" class="headerlink" title="Volume"></a>Volume</h4><p>Volume可以支持<code>local</code>、<code>nfs</code>、<code>cephfs</code>、<code>glusterfs</code>以及各种云计算平台。</p><p>官网Volume的配置都是在一个创建pod的yaml文件中，例如</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-pd</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - image:</span> <span class="string">k8s.gcr.io/test-webserver</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">test-container</span></span><br><span class="line"><span class="attr">    volumeMounts:</span></span><br><span class="line"><span class="attr">    - mountPath:</span> <span class="string">/test-pd</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">test-volume</span></span><br><span class="line"><span class="attr">  volumes:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">test-volume</span></span><br><span class="line"><span class="attr">    hostPath:</span></span><br><span class="line">      <span class="comment"># directory location on host</span></span><br><span class="line"><span class="attr">      path:</span> <span class="string">/data</span></span><br><span class="line">      <span class="comment"># this field is optional</span></span><br><span class="line"><span class="attr">      type:</span> <span class="string">Directory</span></span><br></pre></td></tr></table></figure><h4 id="PV和PVC"><a href="#PV和PVC" class="headerlink" title="PV和PVC"></a><strong>PV和PVC</strong></h4><p>PV的全称是: PersistentVolume (持久化卷)，是对底层的共享存储的一种抽象，PV由管理员进行创建和配置，它和具体的底层的共享存储技术的实现方式有关，比如Ceph、GlusterFS、NFS等，都是通过插件机制完成与共享存储的对接.</p><p>PVC的全称是: PersistenVolumeClaim (持久化卷声明)，PVC是用户存储的一种声明，PVC和Pod比较类型，Pod是消耗节点，PVC消耗的是PV资源，Pod可以请求CPU的内存，而PVC可以请求特定的存储空间和访问模式。对于真正存储的用户不需要关心底层的存储实现细节，只需要直接使用PVC即可.</p><p><em>但是通过PVC请求一定的存储空间也很有可能不足以满足对于存储设备的各种需求，而且不同的应用程序对于存储性能的要求也能也不尽相同，比如读写速度、并发性能等，为了解决这一问题，Kubernetes又为我们引入了一个新的资源对象: StorageClass,通过StorageClass的定义，管理员可以将存储资源定义为某种类型的资源，比如快速存储、慢速存储等，用户根据StorageClass的描述就可以非常直观的知道各种存储资源特性了，这样就可以根据应用的特性去申请合适的存储资源了</em></p><h2 id="演示"><a href="#演示" class="headerlink" title="演示"></a>演示</h2><h4 id="安装NFS服务"><a href="#安装NFS服务" class="headerlink" title="安装NFS服务"></a>安装NFS服务</h4><p>#这里我使用单独服务器进行演示，实际上随便一台服务器安装nfs都可以 (建议和kubernetes集群分开，找单独一台机器)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装</span></span><br><span class="line">yum install nfs-utils -y rpcbind</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置nfs存储目录</span></span><br><span class="line">mkdir /data1/k8s-volume</span><br><span class="line">chmod 755 /data1/k8s-volume/</span><br><span class="line"></span><br><span class="line"><span class="comment">#编辑nfs配置文件</span></span><br><span class="line">cat /etc/exports</span><br><span class="line">/data1/k8s-volume *(rw,no_root_squash,sync)</span><br><span class="line"><span class="comment">#存储目录，*允许所有人连接，rw读写权限，sync文件同时写入硬盘及内存，no_root_squash 使用者root用户自动修改为普通用户</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#由于nfs需要向rpcbind进行注册，所以我们需要优先启动rpcbind</span></span><br><span class="line"><span class="comment">#启动rpcbind</span></span><br><span class="line">systemctl start rpcbind</span><br><span class="line">systemctl <span class="built_in">enable</span> rpcbind</span><br><span class="line">systemctl status rpcbind</span><br><span class="line"></span><br><span class="line"><span class="comment">#启动nfs</span></span><br><span class="line">systemctl restart nfs</span><br><span class="line">systemctl <span class="built_in">enable</span> nfs</span><br><span class="line">systemctl status nfs</span><br><span class="line"></span><br><span class="line"><span class="comment">#检查rpcbind及nfs是否正常</span></span><br><span class="line"> rpcinfo |grep nfs</span><br></pre></td></tr></table></figure><h4 id="NFS客户端"><a href="#NFS客户端" class="headerlink" title="NFS客户端"></a>NFS客户端</h4><p><strong>我们nfs server端已经完毕，接下来在所有需要nfs挂载的集群节点安装以下</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">yum install -y nfs-utils rpcbind</span><br><span class="line">systemctl start rpcbind</span><br><span class="line">systemctl <span class="built_in">enable</span> rpcbind</span><br><span class="line">systemctl start nfs</span><br><span class="line">ystemctl <span class="built_in">enable</span> nfs</span><br></pre></td></tr></table></figure><p><strong>客户端挂载测试</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先检查nfs服务端挂载目录是否正常</span></span><br><span class="line">showmount -e localhost</span><br><span class="line"></span><br><span class="line">Export list <span class="keyword">for</span> localhost:</span><br><span class="line">/data1/k8s-volume *</span><br><span class="line"></span><br><span class="line"><span class="comment">#现在进行节点挂载</span></span><br><span class="line"><span class="comment">#先在客户端创建数据目录（挂载点位置）</span></span><br><span class="line">mkdir -p /data1/k8s/</span><br><span class="line"></span><br><span class="line"><span class="comment">#现在进行挂载 分别是ip:nfs目录 节点存储目录</span></span><br><span class="line">mount -t nfs 10.4.82.118:/data1/k8s-volume /data1/k8s</span><br><span class="line"></span><br><span class="line"><span class="comment">#挂在完成后我们使用df -h 就可以看到挂载点</span></span><br><span class="line"> df -h</span><br><span class="line"><span class="comment">#所有需要nfs节点这样挂载就可以</span></span><br></pre></td></tr></table></figure><h4 id="创建PV"><a href="#创建PV" class="headerlink" title="创建PV"></a>创建PV</h4><p>有了我们NFS共享存储，下面就可以来使用PV和PVC。PV作为存储资源，主要包括存储能力、访问模式、存储类型、回收策略等关键信息。pv.yaml如下</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span><span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">pv1</span> <span class="comment">#pv名称</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">capacity:</span>             <span class="comment">#存储能力，一个pv对象都要指定一个存储能力，目前仅支持存储空间的设置</span></span><br><span class="line"><span class="attr">storage:3Gi</span>                         <span class="comment">#存储空间</span></span><br><span class="line"><span class="attr">accessModes:</span></span><br><span class="line"><span class="bullet">-ReadWriteMany</span>                      <span class="comment">#访问模式</span></span><br><span class="line"><span class="attr">persistentVolumeReclaimPolicy:Recycle</span>   <span class="comment">#回收策略</span></span><br><span class="line"><span class="attr">nfs:</span>                              <span class="comment">#服务模式 (nfs、ceph、hostpath等)</span></span><br><span class="line"><span class="attr">path:/data1/k8s-volume</span>       <span class="comment">#共享数据目录挂载点</span></span><br><span class="line"><span class="attr">server:10.4.82.118</span>           <span class="comment">#nfs服务器地址</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建</span></span><br><span class="line">kubectl apply -f pv.yaml</span><br><span class="line"><span class="comment"># 查看状态</span></span><br><span class="line">kubectl get pv</span><br></pre></td></tr></table></figure><p><strong>PV相关配置说明</strong></p><p>Capacity 存储能力 通过PV的capacity属性来设置存储空间，目前仅支持storage=数据大小，未来可能会加入IOPS、吞吐量等指标配置</p><p><strong>AccessModes 访问模式</strong></p><p>AccessModes 是用来对PV进行访问模式的设置，用于描述用户应用对存储资源的访问权限, 访问权限包括下面几种方式：</p><ul><li>ReadWriteOnce (RWO):  读写权限，但是只能被单个节点挂载 </li><li>ReadOnlyMany (ROX):  只读权限，可能被多个节点挂载 </li><li>ReadWriteMany (RWX):  读写权限，可以被多个节点挂载</li></ul><p><em>注意:一些PV可能支持多种访问模式，但是在挂载点时候只能使用一种访问模式，多种访问模式不生效</em></p><p>下面是一些常用的Volume插件支持的访问模式（需要根据我们配置的类型进行选择对应的访问模式）</p><p><img src="/articles/3acab424/1.png" alt></p><p><strong>persistentVolumeReclaimPolicy回收策略</strong> </p><ul><li>Retain (保留) 保留数据，需要管理员手动清理 </li><li>Recycle (回收) 清除PV中的数据，效果相当于执行删除命令 </li><li>Delete (删除) 与PV相连的后端存储完成volume的删除操作，常见于云服务商的存储服务</li></ul><p><em>不过需要注意的是，目前只有NFS和HostPath两类支持回收策略，一般设置Retain比较保险</em></p><p><strong>状态</strong></p><ul><li><p>Available (可用): 表示可用状态，还未被任何PVC绑定</p></li><li><p>Bound (已绑定)：已经绑定到某个PVC </p></li><li><p>Released (已释放)：对应的PVC已经删除,但资源还没有被集群收回 </p></li><li><p>Failed：PV自动回收失败</p></li></ul><h4 id="创建PVC"><a href="#创建PVC" class="headerlink" title="创建PVC"></a><strong>创建PVC</strong></h4><p>前面说过，PV实际上没有创建存储，相当于我们node一样，还需要创建Pod进行消费，接下来我们进行PVC的创建与配置</p><p>#前面我们已经在集群上都安装nfs客户端，并且进行挂载了。下面进行创建pvc</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建pvc同样需要建立一个数据卷声明</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span><span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">pvc-nfs</span></span><br><span class="line"><span class="attr">namespace:</span> <span class="string">kube-ops</span>                     <span class="comment">#指定命名空间，如没指定为默认</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">accessModes:</span></span><br><span class="line"><span class="bullet">-ReadWriteMany</span></span><br><span class="line"><span class="attr">resources:</span></span><br><span class="line"><span class="attr">requests:</span></span><br><span class="line"><span class="attr">storage:3Gi</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建，pvc的yaml文件基本上和pv相同，这里不过多解释。</span></span><br><span class="line">kubectl apply -f pvc-nfs.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看pvc</span></span><br><span class="line">kubectl get pvc -n kube-ops</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看pv</span></span><br><span class="line">kubectl get pv</span><br><span class="line"><span class="comment">#这里我们可以看到，当我们创建pvc之后，pv的状态变成了Bound绑定状态，并且和pvc的状态相同。并且可以看到pvc已经绑定到名称为pv1的volume上，同时在pv上可以看到绑定到名称为pvc-nfs的pvc中</span></span><br><span class="line"><span class="comment">#在Kubernetes中会自动帮我们查看pv状态为Available并且根据声明pvc容量storage的大小进行筛选匹配，同时还会根据AccessMode进行匹配。如果pvc匹配不到pv会一直处于pending状态</span></span><br></pre></td></tr></table></figure><h4 id="使用Labels匹配PV与PVC"><a href="#使用Labels匹配PV与PVC" class="headerlink" title="使用Labels匹配PV与PVC"></a><strong>使用Labels匹配PV与PVC</strong></h4><p>pv与pvc中间还可以通过label标签进行匹配，配置如下</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#记得我们需要修改一下名字，名字是不可以重复的</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span><span class="string">PersistentVolume</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">pv2</span></span><br><span class="line"><span class="attr">labels:</span>           <span class="comment">#这里将pv设置一个labels</span></span><br><span class="line"><span class="attr">app:</span> <span class="string">nfs</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">capacity:</span></span><br><span class="line"><span class="attr">storage:10Gi</span></span><br><span class="line"><span class="attr">accessModes:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ReadWriteOnce</span></span><br><span class="line"><span class="attr">persistentVolumeReclaimPolicy:Recycle</span></span><br><span class="line"><span class="attr">nfs:</span></span><br><span class="line"><span class="attr">path:/data1/k8s-volume</span></span><br><span class="line"><span class="attr">server:192.168.0.14</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span><span class="string">PersistentVolumeClaim</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">pvc2-nfs</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">accessModes:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ReadWriteOnce</span></span><br><span class="line"><span class="attr">resources:</span></span><br><span class="line"><span class="attr">requests:</span></span><br><span class="line"><span class="attr">storage:10Gi</span></span><br><span class="line"><span class="attr">selector:</span>             <span class="comment">##pvc匹配标签为app=nfs的pv</span></span><br><span class="line"><span class="attr">matchLabels:</span></span><br><span class="line"><span class="attr">app:</span> <span class="string">nfs</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f test.yaml</span><br><span class="line">kubectl get pv, pvc</span><br><span class="line"><span class="comment">#这里我们可以看到创建的名称为pv2何pv2-nfs已经进行绑定</span></span><br><span class="line"><span class="comment">#需要注意，当我们pvc申请的容量小于我们pv的容量是可以进行绑定的，当我们申请pvc的容量大于pv的容量是无法进行绑定的。</span></span><br></pre></td></tr></table></figure><h4 id="Deployment引用pvc"><a href="#Deployment引用pvc" class="headerlink" title="Deployment引用pvc"></a><strong>Deployment引用pvc</strong></h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span><span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">pv-nfs-nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">replicas:3</span></span><br><span class="line"><span class="attr">selector:</span></span><br><span class="line"><span class="attr">matchLabels:</span></span><br><span class="line"><span class="attr">app:</span> <span class="string">pv-nfs-nginx</span></span><br><span class="line"><span class="attr">template:</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">            labels:</span></span><br><span class="line"><span class="attr">                app:</span> <span class="string">pv-nfs-nginx</span></span><br><span class="line"><span class="attr">        spec:</span></span><br><span class="line"><span class="attr">            containers:</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">pv-nfs-nginx</span></span><br><span class="line"><span class="attr">                image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">                ports:</span></span><br><span class="line"><span class="attr">                - containerPort:</span><span class="number">80</span></span><br><span class="line"><span class="attr">                volumeMounts:</span>            <span class="comment">#挂载，首先添加需要挂载的目录</span></span><br><span class="line"><span class="attr">                - name:</span> <span class="string">pv-nginx</span>     <span class="comment">#挂载点的名称</span></span><br><span class="line"><span class="attr">                mountPath:</span><span class="string">/usr/share/nginx/html</span> <span class="comment">#挂载点的路径</span></span><br><span class="line"><span class="attr">            volumes:</span><span class="comment">#绑定</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">pv-nginx</span></span><br><span class="line"><span class="attr">                persistentVolumeClaim:</span>      <span class="comment">#将镜像中的nginx目录挂载到下面名称的pvc中</span></span><br><span class="line">                <span class="attr">claimName:</span> <span class="string">pvc-nfs</span>      <span class="comment">#pvc名称</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span><span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">nfs-pvc</span></span><br><span class="line"><span class="attr">labels:</span></span><br><span class="line"><span class="attr">app:</span> <span class="string">pv-nfs-nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">type:NodePort</span></span><br><span class="line"><span class="attr">ports:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">port:80</span></span><br><span class="line"><span class="attr">targetPort:80</span></span><br><span class="line"><span class="attr">    selector:</span></span><br><span class="line"><span class="attr">app:</span> <span class="string">pv-nfs-nginx</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建nginx deployment</span></span><br><span class="line">kubectl apply -f pv-nginx.yaml</span><br><span class="line"><span class="comment">#检查pod和svc状态</span></span><br><span class="line">kubectl get pod,svc|grep pv</span><br><span class="line"><span class="comment">#这里我们可以看到pod已经正常启动，并且svc也已经暴露端口了。</span></span><br></pre></td></tr></table></figure><p>接下来我们直接访问nginx是无法访问的，因为在我们nfs挂载点的目录下面没有文件，所以无法访问</p><p><img src="/articles/3acab424/2.png" alt></p><p>接下来我们到nfs挂载点创建一个index.html</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"I am abcdocker"</span>&gt;&gt;/data1/k8s/index.html</span><br></pre></td></tr></table></figure><p>然后我们在进行访问查看</p><p><img src="/articles/3acab424/3.png" alt></p><p>由于我们的index.html直接挂在到了/data1/k8s目录下面，如果有很多个pod都使用pvc进行挂载，会造成我们数据目录的文件比较乱</p><p>这里我们添加一个subpathsubPath的目的是为了在单一Pod中多次使用同一个volume而设计的。</p><p><img src="/articles/3acab424/4.png" alt></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#deployment文件如下</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span><span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">pv-nfs-nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">replicas:3</span></span><br><span class="line"><span class="attr">selector:</span></span><br><span class="line"><span class="attr">matchLabels:</span></span><br><span class="line"><span class="attr">app:</span> <span class="string">pv-nfs-nginx</span></span><br><span class="line"><span class="attr">template:</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">labels:</span></span><br><span class="line"><span class="attr">app:</span> <span class="string">pv-nfs-nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">containers:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pv-nfs-nginx</span></span><br><span class="line"><span class="attr">image:</span> <span class="string">nginx</span></span><br><span class="line"><span class="attr">ports:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">containerPort:80</span></span><br><span class="line"><span class="attr">volumeMounts:</span>       <span class="comment">#挂载，首先添加需要挂载的目录</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pv-nginx</span>    <span class="comment">#挂载点的名称</span></span><br><span class="line"><span class="attr">mountPath:/usr/share/nginx/html</span>  <span class="comment">#挂载点的路径</span></span><br><span class="line"><span class="attr">subPath:</span> <span class="string">nginx-pvc</span></span><br><span class="line"></span><br><span class="line"><span class="attr">volumes:</span> <span class="comment">#绑定</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">pv-nginx</span></span><br><span class="line"><span class="attr">persistentVolumeClaim:</span> <span class="comment">#将镜像中的nginx目录挂载到下面名称的pvc中</span></span><br><span class="line"><span class="attr">claimName:</span> <span class="string">pvc-nfs</span>  <span class="comment">#pvc名称</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span><span class="string">Service</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">nfs-pvc</span></span><br><span class="line"><span class="attr">labels:</span></span><br><span class="line"><span class="attr">app:</span> <span class="string">pv-nfs-nginx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">type:NodePort</span></span><br><span class="line"><span class="attr">ports:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">port:80</span></span><br><span class="line"><span class="attr">targetPort:80</span></span><br><span class="line"><span class="attr">selector:</span></span><br><span class="line"><span class="attr">app:</span> <span class="string">pv-nfs-nginx</span></span><br></pre></td></tr></table></figure><p>当我们更新完pod之后，等pod正常启动。就可以看到在我们nfs存储目录下面单独创建了一个名称为nginx-pvc的目录，这个目录实际上就是我们subpath后面指定的名称</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f pv-nginx.yaml</span><br><span class="line">ls /data1/k8s/</span><br></pre></td></tr></table></figure><p>这个目录下面也是没有任何文件的，我们需要将原来index.html拷贝过去即可</p><p>现在我们删除deployment，下面的数据并不会删除。这样使用pv和pvc持久化就完成</p><p><strong>如果我们直接删除或者有pod在使用pv或者pvc是无法直接删除的,当我们使用Recycle模式时，删除所有pv和pvc后，数据也会进行删除。所以删除pv和pvc请谨慎操作</strong></p><h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>系统内有一个已经不再使用的 PV ，已经删除了与其关联的 Pod 及 PVC ，并对其执行了删除命令，但是无法正常删除，一直出于如下状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get pv</span><br><span class="line">NAME          CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS        CLAIM                                    STORAGECLASS          REASON   AGE</span><br><span class="line">pv-nfs-gysl   1Gi        RWO            Recycle          Terminating   default/www-vct-statefulset-pvc-gysl-0   managed-nfs-storage            22h</span><br></pre></td></tr></table></figure><p><strong>解决方法</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl patch pv pv-nfs-gysl -p <span class="string">'&#123;"metadata":&#123;"finalizers":null&#125;&#125;'</span></span><br><span class="line">persistentvolume/pv-nfs-gysl patched</span><br><span class="line"></span><br><span class="line">$ kubectl get pv</span><br><span class="line">No resources found.</span><br></pre></td></tr></table></figure><p>通过系统帮助信息，我们可以获取patch的简要使用说明：</p><p>patch： 使用 strategic merge patch 更新一个资源的 field(s)。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;本文详细介绍了kubernentes的存储，使用NFS进行演示，让你充分了解和使用pv和pvc，可以举一反三的使用持久化存储。&lt;/p&gt;
    
    </summary>
    
      <category term="容器化" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Docker" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/Docker/"/>
    
    
      <category term="K8s" scheme="https://wandouduoduo.netlify.com/tags/K8s/"/>
    
  </entry>
  
  <entry>
    <title>详解nexus私服仓库</title>
    <link href="https://wandouduoduo.netlify.com/articles/79a09f66.html"/>
    <id>https://wandouduoduo.netlify.com/articles/79a09f66.html</id>
    <published>2020-06-28T10:43:34.000Z</published>
    <updated>2020-06-29T11:32:20.088Z</updated>
    
    <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>Nexus 是Maven仓库管理器，如果你使用Maven，你可以从Maven中央仓库 下载所需要的构件（artifact），但这通常不是一个好的做法，你应该在本地架设一个Maven仓库服务器，在代理远程仓库的同时维护本地仓库，以节省带宽和时间，Nexus就可以满足这样的需要。此外，他还提供了强大的仓库管理功能，构件搜索功能，它基于REST，友好的UI是一个extjs的REST客户端，它占用较少的内存，基于简单文件系统而非数据库。这些优点使其日趋成为最流行的Maven仓库管理器。</p><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>操作系统：Linux（以CentOS为例）</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h4 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h4><p>从<a href="http://www.sonatype.org/nexus/" target="_blank" rel="noopener">官方地址</a>下载</p><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><p>将压缩包解压到/usr目录下。</p><p>nexus里面有2个文件夹，第一个是核心文件，第二个用来存储下载下来的jar，如下图<br><img src="/articles/79a09f66/1.png" alt="这里写图片描述"><br><img src="/articles/79a09f66/2.png" alt="这里写图片描述"></p><p><strong>修改端口</strong></p><p>进入nexus/nexubs-2.13.0-01/conf目录下，编辑nexus.properties文件<br><img src="/articles/79a09f66/3.png" alt="这里写图片描述"><br><img src="/articles/79a09f66/4.png" alt="这里写图片描述"></p><h4 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h4><p>进入nexus/nexubs-2.13.0-01/bin目录<br><img src="/articles/79a09f66/5.png" alt="这里写图片描述"><br>运行命令：./nexus </p><p>//可以查看有那些运行命令<br><img src="/articles/79a09f66/6.png" alt="这里写图片描述"><br>运行命令：./nexus start </p><p>//启动nexus<br><img src="/articles/79a09f66/7.png" alt="这里写图片描述"><br><em>注意：可能会报错，报上面错误时：需要修改运行的用户</em></p><p>修改运行文件 nexus，将RUN_AS_USER修改为root；<br><img src="/articles/79a09f66/8.png" alt="这里写图片描述"></p><p><img src="/articles/79a09f66/9.png" alt="这里写图片描述"><br>保存之后，再次启动nexus<br><img src="/articles/79a09f66/10.png" alt="这里写图片描述"></p><h4 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h4><p>查看nexus 控制台，命令：./nexus console<br><img src="/articles/79a09f66/11.png" alt="这里写图片描述"></p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>设置nexus为Linux系统的服务，并开机自动启动</p><ol><li><p>复制$NEXUS_HOME/bin/jsw/linux-x86-64/nexus 到/etc/init.d/nexus</p></li><li><p>授于nexus脚本有可执行的权限：</p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`    ``chmod` `755 ``/etc/init``.d``/nexus`</span><br></pre></td></tr></table></figure><ol start="3"><li>修改nexus文件，配置以下参数：</li></ol><p>​      a) 修改NEXUS_HOME 绝对路径，如：NEXUS_HOME=”/usr/local/nexus”</p><p>​      b) 设置RUN_AS_USER=nexus，或都其它的用户，前提是创建了此用户。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`        ``NEXUS_HOME=``/usr/local/nexus` `        ``PLATFORM=linux-x86-64` `        ``PLATFORM_DIR=``&quot;$&#123;NEXUS_HOME&#125;/bin/jsw/$&#123;PLATFORM&#125;&quot;` `        ``WRAPPER_CMD=``&quot;$&#123;PLATFORM_DIR&#125;/wrapper&quot;` `        ``WRAPPER_CONF=``&quot;$&#123;PLATFORM_DIR&#125;/../conf/wrapper.conf&quot;` `        ``PIDDIR=``&quot;$&#123;NEXUS_HOME&#125;&quot;`</span><br></pre></td></tr></table></figure><ol start="4"><li>Red Hat, Fedora, CentOS增加nexus服务：       </li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`    ``<span class="built_in">cd</span>` `/etc/init``.d` `        ``chkconfig --add nexus` `        ``chkconfig --levels 345 nexus on` `        ``service nexus start` `        ``tail` `-f ``/usr/<span class="built_in">local</span>/nexus/logs/wrapper``.<span class="built_in">log</span>`</span><br></pre></td></tr></table></figure><p>Ubuntu and Debian增加nexus服务        </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">`    ``<span class="built_in">cd</span>` `/etc/init``.d` `        ``update-rc.d nexus defaults` `        ``chkconfig --levels 345 nexus on` `        ``service nexus start` `        ``tail` `-f ``/usr/<span class="built_in">local</span>/nexus/logs/wrapper``.<span class="built_in">log</span>`</span><br></pre></td></tr></table></figure><p>配置完成后，在浏览器进行访问。地址：<a href="http://ip/" target="_blank" rel="noopener">http://ip</a>:端口/nexus </p><p><em><img src="/articles/79a09f66/12.png" alt="这里写图片描述">在网页上的右上角进行登录，默认用户名：admin，密码：admin123</em> </p><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>常用功能：<br>Nexus常用功能就是：指定私服的中央地址、将自己的Maven项目指定到私服地址、从私服下载中央库的项目索引、从私服仓库下载依赖组件、将第三方项目jar上传到私服供其他项目组使用。<br>开启Nexus服务后访问url地址<a href="http://localhost:8081/nexus/(推荐使用自己的ip地址)，之后登录系统，用户名密码分别是：admin/admin123" target="_blank" rel="noopener">http://localhost:8081/nexus/(推荐使用自己的ip地址)，之后登录系统，用户名密码分别是：admin/admin123</a>.<br>最频繁的就是点击左侧菜单栏的Repositories按钮<br><img src="/articles/79a09f66/13.png" alt="这里写图片描述"><br>一般用到的仓库种类是hosted、proxy。Hosted代表宿主仓库，用来发布一些第三方不允许的组件，比如Oracle驱动、比如商业软件jar包。Proxy代表代理远程的仓库，最典型的就是Maven官方中央仓库、JBoss仓库等等。如果构建的Maven项目本地仓库没有依赖包，那么就会去这个代理站点去下载，那么如果代理站点也没有此依赖包，就回去远程中央仓库下载依赖，这些中央仓库就是proxy。代理站点下载成功后再下载至本机。笔者认为，其实Maven这个自带的默认仓库一般情况下已经够大多数项目使用了。特殊情况时在配置新的仓库，指定url即可，一般熟悉ExtJS的人操作这个Nexus都没什么问题，单词不是很难，不明白的查查单词基本差不多。就是如果Sonatype公司对其做了国际化的处理就更好了。</p><ul><li>hosted 类型的仓库，内部项目的发布仓库</li><li>releases内部的模块中release模块的发布仓库</li><li>snapshots发布内部的SNAPSHOT模块的仓库</li><li>3rd party第三方依赖的仓库，这个数据通常是由内部人员自行下载之后发布上去</li><li>proxy 类型的仓库，从远程中央仓库中寻找数据的仓库</li><li>group 类型的仓库，组仓库用来方便我们开发人员进行设置的仓库</li></ul><p>maven项目索引<br>下载Maven项目索引，项目索引是为了使用者能够在私服站点查找依赖使用的功能<br><img src="/articles/79a09f66/14.png" alt="这里写图片描述"><br>保存后后台会运行一个任务，点击菜单栏的Scheduled Tasks选项即可看到有个任务在RUNNING。 下载完成后，Maven索引就可以使用了，在搜索栏输入要搜索的项，就可以查到相关的信息。例如spring-core<br><img src="/articles/79a09f66/15.png" alt="这里写图片描述"><br>就可以检索出它的相关信息，包括怎么配置依赖信息。我们要想使用这个私服仓库，先在项目pom中配置相关私服信息指定仓库</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">repositories</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">repository</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>nexus<span class="tag">&lt;/<span class="name">id</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>nexus<span class="tag">&lt;/<span class="name">name</span>&gt;</span>             <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://xxx:8081/nexus/content/groups/public/<span class="tag">&lt;/<span class="name">url</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">releases</span>&gt;</span>  </span><br><span class="line">            <span class="tag">&lt;<span class="name">enabled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;/<span class="name">releases</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">snapshots</span>&gt;</span>  </span><br><span class="line">            <span class="tag">&lt;<span class="name">enabled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;/<span class="name">snapshots</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">repository</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span><br></pre></td></tr></table></figure><p>指定插件仓库</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">pluginRepositories</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">pluginRepository</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>nexus<span class="tag">&lt;/<span class="name">id</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>nexus<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://192.168.1.103:8081/nexus/content/groups/public/<span class="tag">&lt;/<span class="name">url</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">releases</span>&gt;</span>  </span><br><span class="line">            <span class="tag">&lt;<span class="name">enabled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;/<span class="name">releases</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">snapshots</span>&gt;</span>  </span><br><span class="line">            <span class="tag">&lt;<span class="name">enabled</span>&gt;</span>true<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;/<span class="name">snapshots</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">pluginRepository</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">pluginRepositories</span>&gt;</span></span><br></pre></td></tr></table></figure><p>这样只有本项目才在私服下载组件<br>这样这个Maven项目构建的时候会从私服下载相关依赖。当然这个配置仅仅是在此项目中生效，对于其他项目还是不起作用。如果相对Maven的其他项目也生效的话。需要修改全局的settings.xml文件。</p><p>修改settings.xml为<br><img src="/articles/79a09f66/16.png" alt="这里写图片描述"></p><p>追加激活profile</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">activeProfiles</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">activeProfile</span>&gt;</span>central<span class="tag">&lt;/<span class="name">activeProfile</span>&gt;</span>        </span><br><span class="line"><span class="tag">&lt;/<span class="name">activeProfiles</span>&gt;</span></span><br></pre></td></tr></table></figure><p>之后所有本机的Maven项目就在私服下载组件。（这样比较好）</p><p>项目的发布</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">distributionManagement</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">repository</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>user-release<span class="tag">&lt;/<span class="name">id</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>User Project Release<span class="tag">&lt;/<span class="name">name</span>&gt;</span>        <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://192.168.1.103:8081/nexus/content/repositories/releases/<span class="tag">&lt;/<span class="name">url</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">repository</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">snapshotRepository</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>user-snapshots<span class="tag">&lt;/<span class="name">id</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>User Project SNAPSHOTS<span class="tag">&lt;/<span class="name">name</span>&gt;</span>    <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://192.168.1.103:8081/nexus/content/repositories/snapshots/<span class="tag">&lt;/<span class="name">url</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">snapshotRepository</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">distributionManagement</span>&gt;</span></span><br></pre></td></tr></table></figure><p>注意配置了还是发布项目到私服失败，原因为没有权限<br>配置权限在settings.xml<br><img src="/articles/79a09f66/17.png" alt="这里写图片描述"><br><img src="/articles/79a09f66/18.png" alt="这里写图片描述"><br>然后运行发布<br>clean deploy<br>在控制台发布成功<br>然后进入到私服上的仓库中，看一下确实存在刚刚发布的项目<br><img src="/articles/79a09f66/19.png" alt="这里写图片描述"></p><p>宿主库——3rd party<br>假如我们下载了Oracle的驱动程序jar包想给其他项目组使用，就需要上传该jar包。选中宿主库——3rd party，之后选择Artifact Upload上传至宿主空间。<br><img src="/articles/79a09f66/20.png" alt="这里写图片描述"><br><img src="/articles/79a09f66/21.png" alt="这里写图片描述"><br>最后点击上传<br><img src="/articles/79a09f66/22.png" alt="这里写图片描述"> </p><h2 id="索引更新"><a href="#索引更新" class="headerlink" title="索引更新"></a>索引更新</h2><p>索引好比目录，只有有了索引，才能根据索引去仓库下载需要的构件jar包。由于中央仓库向全世界提供下载服务，有很多构件，其索引文件也很大，大概1G左右。 </p><p>更新索引方式有两种</p><ol><li>在线更新索引<br>安装配置完成Nexus后，电脑联网状态下，Nexus会自动下载索引文件。下载好的索引文件存放在目录：sonatype-work\nexus\indexer</li><li>手动更新索引<br>网络环境不佳，或者在线更新有问题时，可以选择手动添加索引方式。<br>首先准备这几个文件:<br><img src="/articles/79a09f66/25.png" alt="这里写图片描述"><br>到<a href="http://repo.maven.apache.org/maven2/.index/页面下载下面这两个文件，如图所示文件" target="_blank" rel="noopener">http://repo.maven.apache.org/maven2/.index/页面下载下面这两个文件，如图所示文件</a>:<br><img src="/articles/79a09f66/23.png" alt="这里写图片描述"><br>到<a href="http://search.maven.org/" target="_blank" rel="noopener">http://search.maven.org</a>，搜索g:”org.apache.maven.indexer” AND a:”indexer-cli”下载特定解压文<br>indexer-cli-5.1.1.jar，如下图：<br><img src="/articles/79a09f66/24.png" alt="这里写图片描述"><br>把这几个文件放在同一个文件路径下面，从cmd进入到这个路径里，输入命令：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -jar indexer-cli-5.1.1.jar -u nexus-maven-repository-index.gz -d indexer</span><br></pre></td></tr></table></figure><p>执行完之后，把indexer文件夹下的所有内容都复制到%nexus-home%\sonatype-work\nexus\indexer\central-ctx下面。<br>重新启动nexus，进入管理界面，选择central-&gt;Browse Index，就看到更新的索引了。<br>注意：nexus是需要重新启动的，我是在做上面的所有步骤之前，先停掉nexus，等上面四个步骤完成之后，再启动nexus的。</p><h2 id="仓库迁移"><a href="#仓库迁移" class="headerlink" title="仓库迁移"></a>仓库迁移</h2><p>Nexus的构件仓库都保存在sonatype-work目录中，该目录的位置由nexus/conf/nexus.properties配置文件指定。<br>仓库迁移需要两个过程：备份和还原</p><ul><li><ul><li>备份仓库：将sonatype-work文件夹整体备份即可，也可以选择只备份最重要的两个文件夹索引（indexer）和仓库（storage）</li><li>还原仓库：将备份好的sonatype-work文件拷贝到新的服务器中。然后修改nexus/conf/nexus.properties配置文件，重新指定仓库的目录。</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h3&gt;&lt;p&gt;Nexus 是Maven仓库管理器，如果你使用Maven，你可以从Maven中央仓库 下载所需要的构件（artifact），但这通常不是一个好的做法，你应该在本地架设一个Maven仓库服务器，在代理远程仓库的同时维护本地仓库，以节省带宽和时间，Nexus就可以满足这样的需要。此外，他还提供了强大的仓库管理功能，构件搜索功能，它基于REST，友好的UI是一个extjs的REST客户端，它占用较少的内存，基于简单文件系统而非数据库。这些优点使其日趋成为最流行的Maven仓库管理器。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Nexus" scheme="https://wandouduoduo.netlify.com/tags/Nexus/"/>
    
  </entry>
  
  <entry>
    <title>K8S之CI/CD自动化</title>
    <link href="https://wandouduoduo.netlify.com/articles/8a3a5c96.html"/>
    <id>https://wandouduoduo.netlify.com/articles/8a3a5c96.html</id>
    <published>2020-06-28T09:27:59.000Z</published>
    <updated>2020-06-28T10:04:39.632Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>CICD 是 持续集成（Continuous Integration）和持续部署（Continuous Deployment）简称。指在开发过程中自动执行一系列脚本来减低开发引入 bug 的概率，在新代码从开发到部署的过程中，尽量减少人工的介入。</p><p><img src="/articles/8a3a5c96/1.png" alt></p><a id="more"></a><h2 id="部署流程"><a href="#部署流程" class="headerlink" title="部署流程"></a>部署流程</h2><h4 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h4><p>大致的部署流程是这样的：开发人员把做好的项目代码通过git推送到gitlab，然后Jenkins通过 gitlab  webhook ，自动从拉取gitlab上面拉取代码下来，然后进行build，编译、生成镜像。然后把镜像推送到Harbor仓库；然后在部署的时候通过k8s拉取Harbor上面的镜像进行创建容器和服务，最终发布完成，然后可以用外网访问。</p><p><img src="/articles/8a3a5c96/2.png" alt></p><p>当然啦，上面只是粗略的，请看下图才更加形象。</p><p><img src="/articles/8a3a5c96/3.png" alt></p><p>未完待续！！！</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;CICD 是 持续集成（Continuous Integration）和持续部署（Continuous Deployment）简称。指在开发过程中自动执行一系列脚本来减低开发引入 bug 的概率，在新代码从开发到部署的过程中，尽量减少人工的介入。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/8a3a5c96/1.png&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="容器化" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Docker" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/Docker/"/>
    
    
      <category term="K8s" scheme="https://wandouduoduo.netlify.com/tags/K8s/"/>
    
  </entry>
  
  <entry>
    <title>K8S之镜像管理服务</title>
    <link href="https://wandouduoduo.netlify.com/articles/b9ccc582.html"/>
    <id>https://wandouduoduo.netlify.com/articles/b9ccc582.html</id>
    <published>2020-06-28T07:41:52.000Z</published>
    <updated>2020-06-30T05:50:51.251Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Harbor是构建企业级私有docker镜像的仓库的开源解决方案，它是Docker Registry的更高级封装，它除了提供友好的Web UI界面，角色和用户权限管理，用户操作审计等功能外，它还整合了K8s的插件(Add-ons)仓库，即Helm通过chart方式下载，管理，安装K8s插件，而chartmuseum可以提供存储chart数据的仓库【注:helm就相当于k8s的yum】。另外它还整合了两个开源的安全组件，一个是Notary，另一个是Clair，Notary类似于私有CA中心，而Clair则是容器安全扫描工具，它通过各大厂商提供的CVE漏洞库来获取最新漏洞信息，并扫描用户上传的容器是否存在已知的漏洞信息，这两个安全功能对于企业级私有仓库来说是非常具有意义的。</p><a id="more"></a><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><h4 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a>安装docker</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装必要软件包</span></span><br><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 设置docker镜像源</span></span><br><span class="line">yum-config-manager --add-repo \</span><br><span class="line">  http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 安装docker-ce</span></span><br><span class="line">yum update -y &amp;&amp; yum install -y \</span><br><span class="line">  containerd.io-1.2.13 \</span><br><span class="line">  docker-ce-19.03.8 \</span><br><span class="line">  docker-ce-cli-19.03.8</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 启动docker，并设置开机自启</span></span><br><span class="line">systemctl <span class="built_in">enable</span> docker &amp;&amp; systemctl start docker</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 配置docker镜像加速</span></span><br><span class="line">cat &lt;&lt;EOF &gt;  /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"exec-opts"</span>: [<span class="string">"native.cgroupdriver=systemd"</span>],</span><br><span class="line">  <span class="string">"registry-mirrors"</span>: [ <span class="string">"https://gcr.azk8s.cn"</span>, <span class="string">"https://docker.mirrors.ustc.edu.cn"</span>, <span class="string">"http://hub-mirror.c.163.com"</span>, <span class="string">"https://registry.docker-cn.com"</span>]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 重启docker</span></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><h4 id="下载harbor软件包"><a href="#下载harbor软件包" class="headerlink" title="下载harbor软件包"></a>下载harbor软件包</h4><p>从<a href="https://github.com/goharbor/harbor/releases" target="_blank" rel="noopener">官方下载地址</a>下载稳定软件包，这里用   harbor-offline-installer-v1.10.3.tgz。可以参考<a href="https://github.com/goharbor/harbor/blob/master/docs/install-config/_index.md" target="_blank" rel="noopener">官方安装文档</a></p><h4 id="Docker-compose安装"><a href="#Docker-compose安装" class="headerlink" title="Docker-compose安装"></a>Docker-compose安装</h4><p><a href="https://docs.docker.com/compose/install/" target="_blank" rel="noopener">官方文档</a></p><p><strong>方法一</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载</span></span><br><span class="line">curl -L <span class="string">"https://github.com/docker/compose/releases/download/1.26.0/docker-compose-<span class="variable">$(uname -s)</span>-<span class="variable">$(uname -m)</span>"</span> -o /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line"></span><br><span class="line"><span class="comment"># 授权</span></span><br><span class="line">chmod +x /usr/<span class="built_in">local</span>/bin/docker-compose</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证</span></span><br><span class="line">docker-compose --version</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如有报错，可能为路径没有包含/usr/local/bin/</span></span><br><span class="line">ln -s /usr/<span class="built_in">local</span>/bin/docker-compose /usr/bin/docker-compose</span><br></pre></td></tr></table></figure><p><strong>方法二</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装python-pip</span></span><br><span class="line">yum -y install epel-release</span><br><span class="line">yum -y install python-pip</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装docker-compose</span></span><br><span class="line">pip install docker-compose</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证</span></span><br><span class="line">docker-compose --version</span><br></pre></td></tr></table></figure><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将下载好的Harbor二进制包上传到服务器上面，然后解压出来</span></span><br><span class="line">tar -xzvf harbor-offline-installer-v1.10.3.tgz -C /usr/<span class="built_in">local</span></span><br></pre></td></tr></table></figure><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入解压出来的文件夹harbor中，查看</span></span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/harbor</span><br><span class="line">ls </span><br><span class="line"></span><br><span class="line">common.sh  harbor.v1.10.3.tar.gz  harbor.yml  install.sh  LICENSE  prepare</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改配置</span></span><br><span class="line">vim harbor.yml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置为外网ip</span></span><br><span class="line">hostname: 10.145.197.182</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭https</span></span><br><span class="line"><span class="comment"># https related config</span></span><br><span class="line"><span class="comment">#https:</span></span><br><span class="line">  <span class="comment">#https port for harbor, default is 443</span></span><br><span class="line">  <span class="comment">#port: 443</span></span><br><span class="line">  <span class="comment">#The path of cert and key files for nginx</span></span><br><span class="line">  <span class="comment">#certificate: /your/certificate/path</span></span><br><span class="line">  <span class="comment">#private_key: /your/private/key/path</span></span><br><span class="line">  </span><br><span class="line"><span class="comment"># 修改harbor的登录密码：为了方便起见，我修改为123456,大家可自行修改</span></span><br><span class="line">harbor_admin_password: 123456</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预执行</span></span><br><span class="line">./prepare</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line">./install.sh</span><br></pre></td></tr></table></figure><p><img src="/articles/b9ccc582/1.png" alt></p><p><img src="/articles/b9ccc582/2.png" alt></p><h4 id="查看状态"><a href="#查看状态" class="headerlink" title="查看状态"></a>查看状态</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose ps</span><br></pre></td></tr></table></figure><p><img src="/articles/b9ccc582/3.png" alt></p><h4 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h4><p>用浏览器访问，方式为：<a href="http://ip，用户名：admin/自行配置的密码" target="_blank" rel="noopener">http://ip，用户名：admin/自行配置的密码</a></p><p><img src="/articles/b9ccc582/4.png" alt></p><h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><h4 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h4><p>进入到里面后，在用户管理中创建了一个用户  sun 。大家自行创建，为了后期需要把一些依赖镜像先推送到harbor仓库中。</p><p><img src="/articles/b9ccc582/5.png" alt></p><h4 id="项目规划"><a href="#项目规划" class="headerlink" title="项目规划"></a>项目规划</h4><p>创建项目，并且在每个项目中都加入了刚才所创建的用户，方便后期登录并推送镜像</p><p><img src="/articles/b9ccc582/6.png" alt></p><p>ops主要是用来存放的jenkins和slave等运维镜像；appimages 主要存放应用镜像，供k8s拉取发布。</p><p>至此，harbor部署完成。</p><h4 id="镜像操作"><a href="#镜像操作" class="headerlink" title="镜像操作"></a>镜像操作</h4><h6 id="配置私有库"><a href="#配置私有库" class="headerlink" title="配置私有库"></a>配置私有库</h6><p>docker 默认是按 https 请求的，由于搭建的私有库是 http 的，所以需要修改 docker 配置，将信任的库的地址写上修改文件 <code>/etc/docker/daemon.json</code></p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/docker/daemon.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  <span class="attr">"registry-mirrors"</span>: [ <span class="string">"https://gcr.azk8s.cn"</span>, <span class="string">"https://docker.mirrors.ustc.edu.cn"</span>, <span class="string">"http://hub-mirror.c.163.com"</span>, <span class="string">"https://registry.docker-cn.com"</span>],</span><br><span class="line">  <span class="attr">"insecure-registries"</span>: [<span class="string">"10.145.197.182"</span>]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="重启docker"><a href="#重启docker" class="headerlink" title="重启docker"></a>重启docker</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><h6 id="配置验证"><a href="#配置验证" class="headerlink" title="配置验证"></a>配置验证</h6><p>执行 docker info,  看一下IP地址是否生效，发现已加入。再试一下登录，发现登录成功，然后开始推送把。</p><p><img src="/articles/b9ccc582/7.png" alt></p><h6 id="登录harbor仓库"><a href="#登录harbor仓库" class="headerlink" title="登录harbor仓库"></a>登录harbor仓库</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker login 10.145.197.182</span><br></pre></td></tr></table></figure><p><img src="/articles/b9ccc582/8.png" alt></p><h6 id="制作镜像和上传"><a href="#制作镜像和上传" class="headerlink" title="制作镜像和上传"></a>制作镜像和上传</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拉取镜像</span></span><br><span class="line">docker pull jenkins</span><br><span class="line"><span class="comment"># 重新打tag</span></span><br><span class="line">docker tag jenkins:latest 10.145.197.182/ops/jenkins</span><br><span class="line"><span class="comment"># 推送</span></span><br><span class="line">docker push 10.145.197.182/ops/jenkins</span><br></pre></td></tr></table></figure><p><img src="/articles/b9ccc582/9.png" alt></p><h6 id="上传验证"><a href="#上传验证" class="headerlink" title="上传验证"></a>上传验证</h6><p>web页面查看</p><p><img src="/articles/b9ccc582/10.png" alt></p><h2 id="管理"><a href="#管理" class="headerlink" title="管理"></a>管理</h2><h4 id="修改端口号"><a href="#修改端口号" class="headerlink" title="修改端口号"></a>修改端口号</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#对于http发布方式，Harbor默认使用80端口</span></span><br><span class="line"><span class="comment">#需要修改端口按照如下方法： 修改docker-compose.yml中nginx的配置，将80:80的第一个80改为自定义的端口号。 修改common/templates/registry/config.yml，在auth部分#ui_url后面加上自定义的端口号 修改完成后，运行下面的命令重新配置Harbor</span></span><br><span class="line"></span><br><span class="line">docker-compose down</span><br><span class="line">./install.sh</span><br><span class="line"><span class="comment">#对于第一次安装，直接修改完所有配置文件后执行install.sh就可以。</span></span><br></pre></td></tr></table></figure><h4 id="停止-启动"><a href="#停止-启动" class="headerlink" title="停止/启动"></a>停止/启动</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker-compose stop</span><br><span class="line">docker-compose start</span><br></pre></td></tr></table></figure><h4 id="卸载Harbor"><a href="#卸载Harbor" class="headerlink" title="卸载Harbor"></a>卸载Harbor</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#执行如下步骤彻底删除Harbor，以便重新安装：</span></span><br><span class="line">sudo docker-compose down</span><br><span class="line">rm -rf /data/database</span><br><span class="line">rm -rf /data/registry</span><br></pre></td></tr></table></figure><h4 id="修改Harbor配置"><a href="#修改Harbor配置" class="headerlink" title="修改Harbor配置"></a>修改Harbor配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#首先删除container，修改配置，然后运行install.sh重新启动container，命令如下：</span></span><br><span class="line">docker-compose down</span><br><span class="line">vim harbor.cfg</span><br><span class="line">./install.sh</span><br></pre></td></tr></table></figure><h4 id="部署镜像服Registry"><a href="#部署镜像服Registry" class="headerlink" title="部署镜像服Registry"></a>部署镜像服Registry</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 由于Harbor已经包含了registry的镜像,这里就将就使用这个镜像来部署。</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个存储registery配置的文件夹:</span></span><br><span class="line">mkdir registry</span><br><span class="line"><span class="comment">#拷贝harbor内registry的配置文件</span></span><br><span class="line">cp harbor/common/config/registry/* registry/</span><br><span class="line"></span><br><span class="line"><span class="comment">#向config.yml追加代理配置</span></span><br><span class="line">cat&gt;&gt;registry/config.yml&lt;&lt;<span class="string">'EOF'</span></span><br><span class="line">proxy:</span><br><span class="line">  remoteurl: https://registry-1.docker.io</span><br><span class="line">EOF</span><br><span class="line"><span class="comment">#创建一个docker-compose.yml文件,内容如下:</span></span><br><span class="line">version: <span class="string">'2'</span></span><br><span class="line">services:</span><br><span class="line">  registry:</span><br><span class="line">    image: vmware/registry-photon:v2.6.2-v1.4.0</span><br><span class="line">    container_name: registry-mirror</span><br><span class="line">    restart: always</span><br><span class="line">    volumes:</span><br><span class="line">      - /data/registry:/storage:z</span><br><span class="line">      - ../registry/:/etc/registry/:z</span><br><span class="line">    networks:</span><br><span class="line">      - harbor</span><br><span class="line">    ports:</span><br><span class="line">      - <span class="string">'5000:5000'</span></span><br><span class="line">    environment:</span><br><span class="line">      - GODEBUG=netdns=cgo</span><br><span class="line">    <span class="built_in">command</span>:</span><br><span class="line">      [<span class="string">"serve"</span>, <span class="string">"/etc/registry/config.yml"</span>]</span><br><span class="line">networks:</span><br><span class="line">  harbor:</span><br><span class="line">    external: <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动</span></span><br><span class="line"><span class="built_in">cd</span> registry &amp;&amp; docker-compose start<span class="comment"># </span></span><br><span class="line"><span class="comment">#停止</span></span><br><span class="line"><span class="built_in">cd</span> registry &amp;&amp; docker-compose stop</span><br><span class="line"><span class="comment"># 使用</span></span><br><span class="line"><span class="comment"># 同阿里云设置,地址改一下就可以。 这里地址根据配置文件是：</span></span><br><span class="line">http://192.168.0.65:5000</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;Harbor是构建企业级私有docker镜像的仓库的开源解决方案，它是Docker Registry的更高级封装，它除了提供友好的Web UI界面，角色和用户权限管理，用户操作审计等功能外，它还整合了K8s的插件(Add-ons)仓库，即Helm通过chart方式下载，管理，安装K8s插件，而chartmuseum可以提供存储chart数据的仓库【注:helm就相当于k8s的yum】。另外它还整合了两个开源的安全组件，一个是Notary，另一个是Clair，Notary类似于私有CA中心，而Clair则是容器安全扫描工具，它通过各大厂商提供的CVE漏洞库来获取最新漏洞信息，并扫描用户上传的容器是否存在已知的漏洞信息，这两个安全功能对于企业级私有仓库来说是非常具有意义的。&lt;/p&gt;
    
    </summary>
    
      <category term="容器化" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Docker" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/Docker/"/>
    
    
      <category term="K8s" scheme="https://wandouduoduo.netlify.com/tags/K8s/"/>
    
  </entry>
  
  <entry>
    <title>Centos7.x安装opensips并实现通话成功</title>
    <link href="https://wandouduoduo.netlify.com/articles/a63421f.html"/>
    <id>https://wandouduoduo.netlify.com/articles/a63421f.html</id>
    <published>2020-06-23T02:51:42.000Z</published>
    <updated>2020-06-24T05:41:15.980Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>先是使用<code>opensips</code>官方的<code>docker</code>尝试，好不容易装好了，软电话（<code>sipphone</code>）上注册不成功，主要是我<code>docker</code>又是装在<code>VirtualBox</code>的虚拟机里的，网络结构致使调试困难，直接新开一个虚拟机，很顺利的就安装成功并且实现局域网终端之间通话。</p><a id="more"></a><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h4 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install mysql mysql-server mysql-devel gcc gcc-c++ ncurses-devel flex bison -y</span><br></pre></td></tr></table></figure><p>机器上已经又<code>mysql</code>正常运行的话就跳过<code>mysql</code>相关的安装了。<br>注意在安装<code>mysql-server</code>的时候可能会出现找不到包，提示使用<code>mariadb-server</code>替代，那就老实使用<code>yum install mariadb-server mariadb</code>安装吧。</p><h4 id="mysql-设置密码并打开远程访问权限"><a href="#mysql-设置密码并打开远程访问权限" class="headerlink" title="mysql 设置密码并打开远程访问权限"></a>mysql 设置密码并打开远程访问权限</h4><p>装好的<code>mysql</code>启动默认是没有密码的，进入<code>mysql</code>后进去运行下面的代码。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 设置密码</span><br><span class="line"><span class="built_in">set</span> password <span class="keyword">for</span> <span class="string">'root'</span>@<span class="string">'localhost'</span> =password(<span class="string">'123456'</span>);</span><br><span class="line">// 设置远程访问及全表权限</span><br><span class="line">grant all privileges on *.* to root@<span class="string">'%'</span>identified by <span class="string">'123456'</span>;</span><br><span class="line">// 更新权限</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure><p>这里的设置根据需要来就好了。</p><h4 id="开启防火墙5060端口"><a href="#开启防火墙5060端口" class="headerlink" title="开启防火墙5060端口"></a>开启防火墙5060端口</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --zone=public --add-port=5060/udp --permanent</span><br><span class="line">firewall-cmd --reload</span><br></pre></td></tr></table></figure><h2 id="安装opensips"><a href="#安装opensips" class="headerlink" title="安装opensips"></a>安装opensips</h2><h4 id="下载源码并选择模块"><a href="#下载源码并选择模块" class="headerlink" title="下载源码并选择模块"></a>下载源码并选择模块</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src </span><br><span class="line">git <span class="built_in">clone</span> https://github.com/OpenSIPS/opensips.git -b 2.4 opensips-2.4</span><br><span class="line"><span class="built_in">cd</span> opensips-2.4</span><br><span class="line">make all</span><br><span class="line"><span class="comment"># 如果这里报错，停止，装好依赖再make all</span></span><br><span class="line">make menuconfig</span><br></pre></td></tr></table></figure><p><img src="/articles/a63421f/1.png" alt></p><p>进入这个菜单后，根据需要使用这个工具（左右键进入返回，空格键选中，回车键确定），但有个必须的是进入<code>Configure Compile Options</code>，选中<code>db_mysql</code>保存，返回主菜单选择<code>Compile And Install OpenSIPS</code>编译安装即可。完成后会回到这个界面，保存退出。</p><h4 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置文件目录</span></span><br><span class="line">ls /usr/<span class="built_in">local</span>/etc/opensips/</span><br><span class="line"></span><br><span class="line">opensips.cfg  opensipsctlrc  osipsconsolerc  scenario_callcenter.xml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行程序目录</span></span><br><span class="line">ls /usr/<span class="built_in">local</span>/sbin</span><br><span class="line"></span><br><span class="line">opensips  opensipsctl  opensipsdbctl  opensipsunix  osipsconfig  osipsconsole</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改配置</span></span><br><span class="line">vim opensipsctlrc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改后的配置</span></span><br><span class="line"><span class="comment"># $Id$</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># The OpenSIPS configuration file for the control tools.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Here you can set variables used in the opensipsctl and opensipsdbctl setup</span></span><br><span class="line"><span class="comment"># scripts. Per default all variables here are commented out, the control tools</span></span><br><span class="line"><span class="comment"># will use their internal default values.</span></span><br><span class="line"><span class="comment">## your SIP domain</span></span><br><span class="line">SIP_DOMAIN=192.168.0.191</span><br><span class="line"><span class="comment">## chrooted directory</span></span><br><span class="line"><span class="comment"># $CHROOT_DIR="/path/to/chrooted/directory"</span></span><br><span class="line"><span class="comment">## database type: MYSQL, PGSQL, ORACLE, DB_BERKELEY, DBTEXT, or SQLITE</span></span><br><span class="line"><span class="comment">## by default none is loaded</span></span><br><span class="line"><span class="comment"># If you want to setup a database with opensipsdbctl, you must at least specify</span></span><br><span class="line"><span class="comment"># this parameter.</span></span><br><span class="line">DBENGINE=MYSQL</span><br><span class="line"><span class="comment">## database port (PostgreSQL=5432 default; MYSQL=3306 default)</span></span><br><span class="line">DBPORT=3306</span><br><span class="line"><span class="comment">## database host</span></span><br><span class="line">DBHOST=localhost</span><br><span class="line"><span class="comment">## database name (for ORACLE this is TNS name)</span></span><br><span class="line">DBNAME=opensips</span><br><span class="line"><span class="comment"># database path used by dbtext, db_berkeley, or sqlite</span></span><br><span class="line">DB_PATH=<span class="string">"/usr/local/etc/opensips/dbtext"</span></span><br><span class="line"><span class="comment">## database read/write user</span></span><br><span class="line">DBRWUSER=opensips</span><br><span class="line"><span class="comment">## password for database read/write user</span></span><br><span class="line">DBRWPW=<span class="string">"opensipsrw"</span></span><br><span class="line"><span class="comment">## engine type for the MySQL/MariaDB tabels (default InnoDB)</span></span><br><span class="line">MYSQL_ENGINE=<span class="string">"MyISAM"</span></span><br><span class="line"><span class="comment">## database super user (for ORACLE this is 'scheme-creator' user)</span></span><br><span class="line">DBROOTUSER=<span class="string">"root"</span></span><br></pre></td></tr></table></figure><p>这里主要是<code>mysql</code>连接信息，保证能正常连接即可。还有一个<code>SIP_DOMAIN</code>能连接到本服务的域名或者<code>IP地址</code>即可。</p><p><strong>修改opensips.cfg</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim opensips.cfg</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改配置项</span></span><br><span class="line">listen=udp:192.168.0.191:5060 <span class="comment"># CUSTOMIZE ME</span></span><br></pre></td></tr></table></figure><p>这里如果你不确定该怎么填的话，运行下面的命令看一下，一般是本机<code>IP</code>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip route get 8.8.8.8 | head -n +1 | tr -s <span class="string">" "</span> | cut -d <span class="string">" "</span> -f 7</span><br></pre></td></tr></table></figure><h4 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/sbin</span><br><span class="line"></span><br><span class="line">opensipsdbctl create</span><br><span class="line">……</span><br><span class="line">INFO: creating database opensips ...</span><br><span class="line">INFO: Using table engine MyISAM.</span><br><span class="line">INFO: Core OpenSIPS tables successfully created.</span><br><span class="line">Install presence related tables? (Y/n): y</span><br><span class="line">INFO: creating presence tables into opensips ...</span><br><span class="line">INFO: Presence tables successfully created.</span><br><span class="line">Install tables <span class="keyword">for</span> </span><br><span class="line">    b2b</span><br><span class="line">    cachedb_sql</span><br><span class="line">    call_center</span><br><span class="line">    carrierroute</span><br><span class="line">    cpl</span><br><span class="line">    domainpolicy</span><br><span class="line">    emergency</span><br><span class="line">    fraud_detection</span><br><span class="line">    freeswitch_scripting</span><br><span class="line">    imc</span><br><span class="line">    registrant</span><br><span class="line">    siptrace</span><br><span class="line">    userblacklist</span><br><span class="line">? (Y/n): y</span><br><span class="line">INFO: creating extra tables into opensips ...</span><br><span class="line">INFO: Extra tables successfully created.</span><br></pre></td></tr></table></figure><p>之后就是根据提示傻瓜操作创建数据库就好了，如果前面的<code>mysql</code>环境没装好，数据库连接有问题，这里就会报错，如果提示类似下面的编码问题，输入<code>latin1</code>即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WARNING: Your current default mysql characters <span class="built_in">set</span> cannot be used to create DB. Please choice another one from the following list:</span><br></pre></td></tr></table></figure><p>这一步完成之后，会在数据库新建一个<code>opensips</code>（名字是在上面的配置文件里设置的）的数据库。</p><h4 id="启动opensips"><a href="#启动opensips" class="headerlink" title="启动opensips"></a>启动opensips</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">[root@localhost sbin]<span class="comment"># opensipsctl start</span></span><br><span class="line">INFO: Starting OpenSIPS : </span><br><span class="line">INFO: started (pid: 26051)</span><br><span class="line"><span class="comment"># 查看opensips进程</span></span><br><span class="line">[root@localhost sbin]<span class="comment"># ps -aux | grep opensips</span></span><br><span class="line">root      3504  0.0  0.4  70536  4420 ?        S    3月07   0:00 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3505  3.1  0.1  70776  1368 ?        S    3月07  12:35 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3506  0.1  0.0  70536   476 ?        S    3月07   0:29 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3507  0.0  0.0  70536   688 ?        S    3月07   0:08 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3508  0.0  0.2  70536  2396 ?        S    3月07   0:03 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3509  0.0  0.1  70536  1424 ?        S    3月07   0:01 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3510  0.0  0.1  70536  1912 ?        S    3月07   0:01 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3511  0.0  0.2  70536  2392 ?        S    3月07   0:01 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3512  0.0  0.1  70536  1164 ?        S    3月07   0:01 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line"><span class="comment"># 注册用户格式 opensipsctl 用户名 密码</span></span><br><span class="line">[root@localhost sbin]<span class="comment"># opensipsctl add 1001 1001</span></span><br><span class="line">new user <span class="string">'1001'</span> added</span><br><span class="line">[root@localhost sbin]<span class="comment"># opensipsctl add 1002 1002</span></span><br><span class="line">new user <span class="string">'1002'</span> added</span><br></pre></td></tr></table></figure><p>到这里就成功的启动了服务并添加了两个用户（1001，1002），下面我们来在局域网测试一下。</p><h4 id="测试通话"><a href="#测试通话" class="headerlink" title="测试通话"></a>测试通话</h4><p>在同一个局域网的手机上装上支持<code>sip</code>的软电话应用市场搜<code>sip phone</code>应该能找到不少，电脑端也有。<br>配置一般是这样的</p><p><img src="/articles/a63421f/2.png" alt></p><p>拨打电话成功</p><p><img src="/articles/a63421f/3.png" alt></p><p>配置好两个终端直接拨号就行了，号码就是1001，1002，经测试视频通话也是默认就支持的，很6哦。至此，借助<code>opensips</code>实现<code>sip</code>通话已经完成，只是实现最基本的功能，<code>opensips</code>还有很多好用的功能供大家来挖掘。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;先是使用&lt;code&gt;opensips&lt;/code&gt;官方的&lt;code&gt;docker&lt;/code&gt;尝试，好不容易装好了，软电话（&lt;code&gt;sipphone&lt;/code&gt;）上注册不成功，主要是我&lt;code&gt;docker&lt;/code&gt;又是装在&lt;code&gt;VirtualBox&lt;/code&gt;的虚拟机里的，网络结构致使调试困难，直接新开一个虚拟机，很顺利的就安装成功并且实现局域网终端之间通话。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Opensips" scheme="https://wandouduoduo.netlify.com/tags/Opensips/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes1.18安装Dashboard</title>
    <link href="https://wandouduoduo.netlify.com/articles/674d1146.html"/>
    <id>https://wandouduoduo.netlify.com/articles/674d1146.html</id>
    <published>2020-06-22T04:06:34.000Z</published>
    <updated>2020-06-22T07:31:26.740Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>k8s的集群搭建已经完成，那么页面怎么管理呢？本文详细介绍k8s-dashboard页面管理。</p><a id="more"></a><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h4 id="下载yaml文件"><a href="#下载yaml文件" class="headerlink" title="下载yaml文件"></a>下载yaml文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yaml</span><br></pre></td></tr></table></figure><h4 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h4><p>修改kubernetes-dashboard的service类型为NodePort类型，使用nodeport方式访问Dashboard 。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[root@k8s-master</span> <span class="string">dashboard]#</span> <span class="string">vim</span> <span class="string">recommended.yaml</span> </span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">NodePort</span> <span class="comment"># 新增</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">443</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="number">8443</span></span><br><span class="line"><span class="attr">      nodePort:</span> <span class="number">30443</span> <span class="comment"># 新增</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br></pre></td></tr></table></figure><h4 id="安装Dashboard"><a href="#安装Dashboard" class="headerlink" title="安装Dashboard"></a>安装Dashboard</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master dashboard]# kubectl create -f recommended.yaml </span><br><span class="line">namespace/kubernetes-dashboard created</span><br><span class="line">serviceaccount/kubernetes-dashboard created</span><br><span class="line">service/kubernetes-dashboard created</span><br><span class="line">secret/kubernetes-dashboard-certs created</span><br><span class="line">secret/kubernetes-dashboard-csrf created</span><br><span class="line">secret/kubernetes-dashboard-key-holder created</span><br><span class="line">configmap/kubernetes-dashboard-settings created</span><br><span class="line">role.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">deployment.apps/kubernetes-dashboard created</span><br><span class="line">service/dashboard-metrics-scraper created</span><br><span class="line">deployment.apps/dashboard-metrics-scraper created</span><br></pre></td></tr></table></figure><h4 id="确认状态"><a href="#确认状态" class="headerlink" title="确认状态"></a>确认状态</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master dashboard]# kubectl get pod,svc -n kubernetes-dashboard</span><br><span class="line">NAME                                            READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/dashboard-metrics-scraper-c79c65bb7-bpnbq   1/1     Running   0          2m52s</span><br><span class="line">pod/kubernetes-dashboard-56484d4c5-cthdm        1/1     Running   0          2m52s</span><br><span class="line"> </span><br><span class="line">NAME                                TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">service/dashboard-metrics-scraper   ClusterIP   10.105.74.63   &lt;none&gt;        8000/TCP        2m52s</span><br><span class="line">service/kubernetes-dashboard        NodePort    10.98.84.244   &lt;none&gt;        443:30444/TCP   2m52s</span><br></pre></td></tr></table></figure><h4 id="创建管理员用户yaml"><a href="#创建管理员用户yaml" class="headerlink" title="创建管理员用户yaml"></a>创建管理员用户yaml</h4><p>默认Dashboard为最小RBAC权限，添加集群管理员权限以便从Dashboard操作集群资源</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[root@k8s-master</span> <span class="string">dashboard]#</span> <span class="string">vim</span> <span class="string">adminuser.yaml</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">admin-user</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">admin-user</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">cluster-admin</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">- kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">admin-user</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kubernetes-dashboard</span></span><br></pre></td></tr></table></figure><h4 id="创建管理员权限"><a href="#创建管理员权限" class="headerlink" title="创建管理员权限"></a>创建管理员权限</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master dashboard]<span class="comment"># kubectl create -f adminuser.yaml</span></span><br><span class="line">serviceaccount/admin-user created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/admin-user created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 补充</span></span><br><span class="line"><span class="comment"># 如有报错，可以先删掉再重新创建</span></span><br><span class="line">kubectl delete -f ***.yaml</span><br></pre></td></tr></table></figure><h2 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h2><h4 id="浏览器访问https-IP-30443"><a href="#浏览器访问https-IP-30443" class="headerlink" title="浏览器访问https://IP:30443"></a>浏览器访问<a href="https://ip:30001/" target="_blank" rel="noopener">https://IP:304</a>43</h4><p><img src="/articles/674d1146/1.png" alt></p><h4 id="查看token"><a href="#查看token" class="headerlink" title="查看token"></a>查看token</h4><p>获取token，用于登录Dashboard UI</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master dashboard]<span class="comment"># kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk '&#123;print $1&#125;')</span></span><br><span class="line">Name:         admin-user-token-k4gdg</span><br><span class="line">Namespace:    kubernetes-dashboard</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name: admin-user</span><br><span class="line">              kubernetes.io/service-account.uid: d116f560-15a2-45ca-930f-40f4fc12ce44</span><br><span class="line"> </span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"> </span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">ca.crt:     1025 bytes</span><br><span class="line">namespace:  20 bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IlNEa2dTVGZhM09xd0MyNWtqaGFoZEc5R0NuYnVsZ0FfVlJQODNaQUFhZjgifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLWs0Z2RnIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJkMTE2ZjU2MC0xNWEyLTQ1Y2EtOTMwZi00MGY0ZmMxMmNlNDQiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.qn98x11n4rPUGkDBU6ceImElgeVbM-b2SeXeeiUEm0rj41_vWXzlpd-r1Z1leuRHuveYnLpquR3QhMlFdjxLAIVAQ83KnDNhHyXYY08ZFeoGqGqlOWIAI-OCS9_IhClIskmmqYwA0kQ5AkHWbEsCKEMiYL-dZH7ECPziV0icFfBIYa6zK8-RLUBHR56rvzgjcap1WeTPdu84vr1jl8a4ZLMrzdwW_WmC4rsesA67DH6cQLgoKZRejGf6Sp4h7izO3DEwcGCUrNbg8biDRoqJwzusKoM7IJbC_C14Omg1kGrozFrMufHs8n7ujjpyuLeUyGjseX9eazlnyNkAwY0XIw</span><br></pre></td></tr></table></figure><h4 id="登录"><a href="#登录" class="headerlink" title="登录"></a>登录</h4><p>输入第二部获取到的token值，点击登录按钮</p><p><img src="/articles/674d1146/2.png" alt></p><p>Dashboard 概况画面如下</p><p><img src="/articles/674d1146/3.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;k8s的集群搭建已经完成，那么页面怎么管理呢？本文详细介绍k8s-dashboard页面管理。&lt;/p&gt;
    
    </summary>
    
      <category term="容器化" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Docker" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/Docker/"/>
    
    
      <category term="K8s" scheme="https://wandouduoduo.netlify.com/tags/K8s/"/>
    
  </entry>
  
  <entry>
    <title>centos7使用kubeadm安装kubernetes集群</title>
    <link href="https://wandouduoduo.netlify.com/articles/87f87b20.html"/>
    <id>https://wandouduoduo.netlify.com/articles/87f87b20.html</id>
    <published>2020-06-22T02:25:57.000Z</published>
    <updated>2020-06-28T03:25:06.972Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>Kubernetes是Google 2014年创建管理的，是Google 10多年大规模容器管理技术Borg的开源版本。它是容器集群管理系统，是一个开源的平台，可以实现容器集群的自动化部署、自动扩缩容、维护等功能。本文详细介绍了集群的搭建。</p><a id="more"></a><h2 id="规划"><a href="#规划" class="headerlink" title="规划"></a>规划</h2><p>一台master结点，两台node结点</p><table><thead><tr><th align="center">主机名</th><th align="center">IP</th><th align="center">OS</th><th align="center">配置</th></tr></thead><tbody><tr><td align="center">k8s-master</td><td align="center">192.168.6.201</td><td align="center">CentOS 7</td><td align="center">2 CPUs， 2G</td></tr><tr><td align="center">k8s-node1</td><td align="center">192.168.6.202</td><td align="center">CentOS 7</td><td align="center">2 CPUs， 2G</td></tr><tr><td align="center">k8s-node2</td><td align="center">192.168.6.203</td><td align="center">CentOS 7</td><td align="center">2 CPUs， 2G</td></tr></tbody></table><p>组件功能：</p><p><img src="/articles/87f87b20/1.png" alt></p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h4 id="设置主机名"><a href="#设置主机名" class="headerlink" title="设置主机名"></a>设置主机名</h4><p>192.168.6.201上执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置master节点主机名</span></span><br><span class="line">hostnamectl <span class="built_in">set</span>-hostname --static k8s-master</span><br></pre></td></tr></table></figure><p>192.168.6.202上执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置node1节点主机名</span></span><br><span class="line">hostnamectl <span class="built_in">set</span>-hostname --static k8s-node1</span><br></pre></td></tr></table></figure><p>192.168.6.203上执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置node2节点主机名</span></span><br><span class="line">hostnamectl <span class="built_in">set</span>-hostname --static k8s-node2</span><br></pre></td></tr></table></figure><p>所有节点上添加hosts</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.6.201  k8s-master</span><br><span class="line">192.168.6.202  k8s-node1</span><br><span class="line">192.168.6.203  k8s-node2</span><br></pre></td></tr></table></figure><h4 id="安装docker-ce"><a href="#安装docker-ce" class="headerlink" title="安装docker-ce"></a>安装docker-ce</h4><p>所有节点上（k8s-master, k8s-node1, k8s-node2）安装docker-ce：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装必要软件包</span></span><br><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 设置docker镜像源</span></span><br><span class="line">yum-config-manager --add-repo \</span><br><span class="line">  http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 安装docker-ce</span></span><br><span class="line">yum update -y &amp;&amp; yum install -y \</span><br><span class="line">  containerd.io-1.2.13 \</span><br><span class="line">  docker-ce-19.03.8 \</span><br><span class="line">  docker-ce-cli-19.03.8</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 启动docker，并设置开机自启</span></span><br><span class="line">systemctl <span class="built_in">enable</span> docker &amp;&amp; systemctl start docker</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 配置docker镜像加速</span></span><br><span class="line">cat &lt;&lt;EOF &gt;  /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"exec-opts"</span>: [<span class="string">"native.cgroupdriver=systemd"</span>],</span><br><span class="line">  <span class="string">"registry-mirrors"</span>: [ <span class="string">"https://gcr.azk8s.cn"</span>, <span class="string">"https://docker.mirrors.ustc.edu.cn"</span>, <span class="string">"http://hub-mirror.c.163.com"</span>, <span class="string">"https://registry.docker-cn.com"</span>]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 重启docker</span></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><h4 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h4><p>所有节点上（k8s-master, k8s-node1, k8s-node2）做如下准备工作</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭firewalld</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 关闭SELinux</span></span><br><span class="line">setenforce 0</span><br><span class="line">sed -i <span class="string">'s/^SELINUX=enforcing$/SELINUX=disabled/'</span> /etc/selinux/config</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 关闭swap</span></span><br><span class="line">swapoff -a</span><br><span class="line">sed -i <span class="string">"s/\/dev\/mapper\/centos-swap/# \/dev\/mapper\/centos-swap/"</span> /etc/fstab</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 设置iptables</span></span><br><span class="line">cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line">sysctl --system</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 载入br_netfilter模块</span></span><br><span class="line">modprobe br_netfilter</span><br></pre></td></tr></table></figure><h4 id="安装kubelet-kubeadm-kubectl"><a href="#安装kubelet-kubeadm-kubectl" class="headerlink" title="安装kubelet kubeadm kubectl"></a>安装kubelet kubeadm kubectl</h4><p>所有节点上（k8s-master, k8s-node1, k8s-node2）安装kubelet kubeadm kubectl：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置kubernetes镜像源</span></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 安装kubelet kubeadm kubectl</span></span><br><span class="line"><span class="comment"># 查看所有版本</span></span><br><span class="line">yum list kubelet kubeadm kubectl  --showduplicates|sort -r</span><br><span class="line"></span><br><span class="line">yum install -y kubelet-&lt;version&gt; kubectl-&lt;version&gt; kubeadm-&lt;version&gt;</span><br><span class="line"></span><br><span class="line">yum install kubelet-1.18.3 kubectl-1.18.3 kubeadm-1.18.3 --<span class="built_in">setopt</span>=obsoletes=0</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 启动kubelet kubeadm kubectl，并设置开机自启</span></span><br><span class="line">systemctl <span class="built_in">enable</span> kubelet &amp;&amp; systemctl start kubelet</span><br></pre></td></tr></table></figure><h4 id="下载镜像"><a href="#下载镜像" class="headerlink" title="下载镜像"></a>下载镜像</h4><p>k8s-master节点上执行如下命令获取下载镜像所需列表</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取所需镜像列表</span></span><br><span class="line">[root@k8s-master ~]<span class="comment"># kubeadm config images list</span></span><br><span class="line">W0523 16:59:15.466625   24669 configset.go:202] WARNING: kubeadm cannot validate component configs <span class="keyword">for</span> API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]</span><br><span class="line">k8s.gcr.io/kube-apiserver:v1.18.3</span><br><span class="line">k8s.gcr.io/kube-controller-manager:v1.18.3</span><br><span class="line">k8s.gcr.io/kube-scheduler:v1.18.3</span><br><span class="line">k8s.gcr.io/kube-proxy:v1.18.3</span><br><span class="line">k8s.gcr.io/pause:3.2</span><br><span class="line">k8s.gcr.io/etcd:3.4.3-0</span><br><span class="line">k8s.gcr.io/coredns:1.6.7</span><br></pre></td></tr></table></figure><p>由于国内无法访问k8s.gcr.io镜像仓库，先从daocloud.io镜像仓库下载所需镜像，然后修改镜像标签</p><p>所有节点上（k8s-master, k8s-node1, k8s-node2）下载安装kubernetes集群所需镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载镜像</span></span><br><span class="line">docker pull daocloud.io/daocloud/kube-apiserver:v1.18.3</span><br><span class="line">docker pull daocloud.io/daocloud/kube-controller-manager:v1.18.3</span><br><span class="line">docker pull daocloud.io/daocloud/kube-scheduler:v1.18.3</span><br><span class="line">docker pull daocloud.io/daocloud/kube-proxy:v1.18.3</span><br><span class="line">docker pull daocloud.io/daocloud/pause:3.2</span><br><span class="line">docker pull daocloud.io/daocloud/etcd:3.4.3-0</span><br><span class="line">docker pull daocloud.io/daocloud/coredns:1.6.7</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 给镜像打tag</span></span><br><span class="line">docker tag daocloud.io/daocloud/kube-apiserver:v1.18.3 k8s.gcr.io/kube-apiserver:v1.18.3</span><br><span class="line">docker tag daocloud.io/daocloud/kube-controller-manager:v1.18.3 k8s.gcr.io/kube-controller-manager:v1.18.3</span><br><span class="line">docker tag daocloud.io/daocloud/kube-scheduler:v1.18.3 k8s.gcr.io/kube-scheduler:v1.18.3</span><br><span class="line">docker tag daocloud.io/daocloud/kube-proxy:v1.18.3 k8s.gcr.io/kube-proxy:v1.18.3</span><br><span class="line">docker tag daocloud.io/daocloud/pause:3.2 k8s.gcr.io/pause:3.2</span><br><span class="line">docker tag daocloud.io/daocloud/etcd:3.4.3-0 k8s.gcr.io/etcd:3.4.3-0</span><br><span class="line">docker tag daocloud.io/daocloud/coredns:1.6.7 k8s.gcr.io/coredns:1.6.7</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 清理原镜像</span></span><br><span class="line">docker rmi daocloud.io/daocloud/kube-apiserver:v1.18.3</span><br><span class="line">docker rmi daocloud.io/daocloud/kube-controller-manager:v1.18.3</span><br><span class="line">docker rmi daocloud.io/daocloud/kube-scheduler:v1.18.3</span><br><span class="line">docker rmi daocloud.io/daocloud/kube-proxy:v1.18.3</span><br><span class="line">docker rmi daocloud.io/daocloud/pause:3.2</span><br><span class="line">docker rmi daocloud.io/daocloud/etcd:3.4.3-0</span><br><span class="line">docker rmi daocloud.io/daocloud/coredns:1.6.7</span><br></pre></td></tr></table></figure><p>为了简化上述拉取镜像操作，特意写了个批量脚本:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">vim sun-k8s.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ImageLists可以指定版本或拉取最新版本，但只能用一个</span></span><br><span class="line">ImageLists=(</span><br><span class="line">k8s.gcr.io/kube-apiserver:v1.18.3 </span><br><span class="line">k8s.gcr.io/kube-controller-manager:v1.18.3 </span><br><span class="line">k8s.gcr.io/kube-scheduler:v1.18.3 </span><br><span class="line">k8s.gcr.io/kube-proxy:v1.18.3</span><br><span class="line">k8s.gcr.io/pause:3.2</span><br><span class="line">k8s.gcr.io/etcd:3.4.3-0 </span><br><span class="line">k8s.gcr.io/coredns:1.6.7</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#ImageLists=`kubeadm config images list 2&gt;/dev/null`</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;ImageLists[@]&#125;</span>;<span class="keyword">do</span></span><br><span class="line">imagename=`<span class="built_in">echo</span> <span class="variable">$i</span>|awk -F\/ <span class="string">'&#123;print $2&#125;'</span>`</span><br><span class="line">srcimage=<span class="string">"daocloud.io/daocloud/<span class="variable">$&#123;imagename&#125;</span>"</span></span><br><span class="line">docker pull <span class="variable">$&#123;srcimage&#125;</span></span><br><span class="line">docker tag <span class="variable">$&#123;srcimage&#125;</span> k8s.gcr.io/<span class="variable">$&#123;imagename&#125;</span></span><br><span class="line">docker rmi <span class="variable">$&#123;srcimage&#125;</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h4 id="初始化master节点"><a href="#初始化master节点" class="headerlink" title="初始化master节点"></a>初始化master节点</h4><p>在k8s-master节点上执行初始化操作</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化master</span></span><br><span class="line">kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address 192.168.92.201</span><br></pre></td></tr></table></figure><p>日志如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化master</span></span><br><span class="line">[root@k8s-master ~]<span class="comment"># kubeadm init --kubernetes-version=v1.18.3 --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address 192.168.92.201</span></span><br><span class="line">W0523 16:21:59.515265   10688 version.go:102] could not fetch a Kubernetes version from the internet: unable to get URL <span class="string">"https://dl.k8s.io/release/stable-1.txt"</span>: Get https://dl.k8s.io/release/stable-1.txt: net/http: request canceled <span class="keyword">while</span> waiting <span class="keyword">for</span> connection (Client.Timeout exceeded <span class="keyword">while</span> awaiting headers)</span><br><span class="line">W0523 16:21:59.515315   10688 version.go:103] falling back to the <span class="built_in">local</span> client version: v1.18.3</span><br><span class="line">W0523 16:21:59.515387   10688 configset.go:202] WARNING: kubeadm cannot validate component configs <span class="keyword">for</span> API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]</span><br><span class="line">[init] Using Kubernetes version: v1.18.3</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">error execution phase preflight: [preflight] Some fatal errors occurred:</span><br><span class="line">        [ERROR Swap]: running with swap on is not supported. Please <span class="built_in">disable</span> swap</span><br><span class="line">[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`</span><br><span class="line">To see the stack trace of this error execute with --v=5 or higher</span><br><span class="line">[root@k8s-master ~]<span class="comment"># swapoff -a    </span></span><br><span class="line">[root@k8s-master ~]<span class="comment"># kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address 192.168.92.201</span></span><br><span class="line">W0523 16:22:26.828070   10824 configset.go:202] WARNING: kubeadm cannot validate component configs <span class="keyword">for</span> API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]</span><br><span class="line">[init] Using Kubernetes version: v1.18.3</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Pulling images required <span class="keyword">for</span> setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action <span class="keyword">in</span> beforehand using <span class="string">'kubeadm config images pull'</span></span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file <span class="string">"/var/lib/kubelet/kubeadm-flags.env"</span></span><br><span class="line">[kubelet-start] Writing kubelet configuration to file <span class="string">"/var/lib/kubelet/config.yaml"</span></span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[certs] Using certificateDir folder <span class="string">"/etc/kubernetes/pki"</span></span><br><span class="line">[certs] Generating <span class="string">"ca"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"apiserver"</span> certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed <span class="keyword">for</span> DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.92.201]</span><br><span class="line">[certs] Generating <span class="string">"apiserver-kubelet-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"front-proxy-ca"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"front-proxy-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"etcd/ca"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"etcd/server"</span> certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed <span class="keyword">for</span> DNS names [k8s-master localhost] and IPs [192.168.92.201 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating <span class="string">"etcd/peer"</span> certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed <span class="keyword">for</span> DNS names [k8s-master localhost] and IPs [192.168.92.201 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating <span class="string">"etcd/healthcheck-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"apiserver-etcd-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"sa"</span> key and public key</span><br><span class="line">[kubeconfig] Using kubeconfig folder <span class="string">"/etc/kubernetes"</span></span><br><span class="line">[kubeconfig] Writing <span class="string">"admin.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"kubelet.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"controller-manager.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"scheduler.conf"</span> kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-apiserver"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-controller-manager"</span></span><br><span class="line">W0523 16:22:29.441917   10824 manifests.go:225] the default kube-apiserver authorization-mode is <span class="string">"Node,RBAC"</span>; using <span class="string">"Node,RBAC"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-scheduler"</span></span><br><span class="line">W0523 16:22:29.442422   10824 manifests.go:225] the default kube-apiserver authorization-mode is <span class="string">"Node,RBAC"</span>; using <span class="string">"Node,RBAC"</span></span><br><span class="line">[etcd] Creating static Pod manifest <span class="keyword">for</span> <span class="built_in">local</span> etcd <span class="keyword">in</span> <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line">[<span class="built_in">wait</span>-control-plane] Waiting <span class="keyword">for</span> the kubelet to boot up the control plane as static Pods from directory <span class="string">"/etc/kubernetes/manifests"</span>. This can take up to 4m0s</span><br><span class="line">[apiclient] All control plane components are healthy after 15.006156 seconds</span><br><span class="line">[upload-config] Storing the configuration used <span class="keyword">in</span> ConfigMap <span class="string">"kubeadm-config"</span> <span class="keyword">in</span> the <span class="string">"kube-system"</span> Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap <span class="string">"kubelet-config-1.18"</span> <span class="keyword">in</span> namespace kube-system with the configuration <span class="keyword">for</span> the kubelets <span class="keyword">in</span> the cluster</span><br><span class="line">[upload-certs] Skipping phase. Please see --upload-certs</span><br><span class="line">[mark-control-plane] Marking the node k8s-master as control-plane by adding the label <span class="string">"node-role.kubernetes.io/master=''"</span></span><br><span class="line">[mark-control-plane] Marking the node k8s-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[bootstrap-token] Using token: 19jjaa.6q8jc5u15ykqqoyf</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs <span class="keyword">in</span> order <span class="keyword">for</span> nodes to get long term certificate credentials</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow certificate rotation <span class="keyword">for</span> all node client certificates <span class="keyword">in</span> the cluster</span><br><span class="line">[bootstrap-token] Creating the <span class="string">"cluster-info"</span> ConfigMap <span class="keyword">in</span> the <span class="string">"kube-public"</span> namespace</span><br><span class="line">[kubelet-finalize] Updating <span class="string">"/etc/kubernetes/kubelet.conf"</span> to point to a rotatable kubelet client certificate and key</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"> </span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"> </span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"> </span><br><span class="line">  mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"> </span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">"kubectl apply -f [podnetwork].yaml"</span> with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"> </span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"> </span><br><span class="line">kubeadm join 192.168.92.201:6443 --token 19jjaa.6q8jc5u15ykqqoyf \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:36f3a6a07d7007712a6c103fd276716716bbe420101374186ddf01fb4dc24f2b </span><br><span class="line">[root@k8s-master ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure><p>在k8s-master节点上按照提示执行如下命令:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><h4 id="安装网络插件"><a href="#安装网络插件" class="headerlink" title="安装网络插件"></a>安装网络插件</h4><p>这里选择安装flannel网络插件，也可以安装其他网络插件。master节点上安装flannel网络插件:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载kube-flannel.yaml</span></span><br><span class="line">wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 安装flannel插件</span></span><br><span class="line">kubectl apply -f kube-flannel.yml</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 确认pod状态，直到所有pod变为running</span></span><br><span class="line">kubectl get pod --all-namespaces</span><br></pre></td></tr></table></figure><p>pod状态确认结果如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]# kubectl get pod --all-namespaces</span><br><span class="line">NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   coredns-66bff467f8-d47nh             1/1     Running   0          11m</span><br><span class="line">kube-system   coredns-66bff467f8-xh6rc             1/1     Running   0          11m</span><br><span class="line">kube-system   etcd-k8s-master                      1/1     Running   0          12m</span><br><span class="line">kube-system   kube-apiserver-k8s-master            1/1     Running   0          12m</span><br><span class="line">kube-system   kube-controller-manager-k8s-master   1/1     Running   0          12m</span><br><span class="line">kube-system   kube-flannel-ds-amd64-sb6vm          1/1     Running   0          2m17s</span><br><span class="line">kube-system   kube-proxy-lxhjf                     1/1     Running   0          11m</span><br><span class="line">kube-system   kube-scheduler-k8s-master            1/1     Running   0          12m</span><br><span class="line">[root@k8s-master ~]#</span><br></pre></td></tr></table></figure><h4 id="加入node节点"><a href="#加入node节点" class="headerlink" title="加入node节点"></a>加入node节点</h4><p>master初始化成功时，屏幕会输出加入节点的命令如下所示:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加入节点</span></span><br><span class="line"><span class="comment"># Then you can join any number of worker nodes by running the following on each as root:</span></span><br><span class="line"> </span><br><span class="line">kubeadm join 192.168.92.201:6443 --token 19jjaa.6q8jc5u15ykqqoyf \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:36f3a6a07d7007712a6c103fd276716716bbe420101374186ddf01fb4dc24f2b</span><br></pre></td></tr></table></figure><p>两台node节点上都执行加入节点命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node1 ~]<span class="comment"># kubeadm join 192.168.92.201:6443 --token 19jjaa.6q8jc5u15ykqqoyf \</span></span><br><span class="line">&gt;     --discovery-token-ca-cert-hash sha256:36f3a6a07d7007712a6c103fd276716716bbe420101374186ddf01fb4dc24f2b </span><br><span class="line">W0523 16:37:35.582972   11590 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not <span class="built_in">set</span>.</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with <span class="string">'kubectl -n kube-system get cm kubeadm-config -oyaml'</span></span><br><span class="line">[kubelet-start] Downloading configuration <span class="keyword">for</span> the kubelet from the <span class="string">"kubelet-config-1.18"</span> ConfigMap <span class="keyword">in</span> the kube-system namespace</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file <span class="string">"/var/lib/kubelet/config.yaml"</span></span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file <span class="string">"/var/lib/kubelet/kubeadm-flags.env"</span></span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting <span class="keyword">for</span> the kubelet to perform the TLS Bootstrap...</span><br><span class="line"> </span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"> </span><br><span class="line">Run <span class="string">'kubectl get nodes'</span> on the control-plane to see this node join the cluster.</span><br><span class="line"> </span><br><span class="line">[root@k8s-node1 ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure><h4 id="确认集群状态"><a href="#确认集群状态" class="headerlink" title="确认集群状态"></a>确认集群状态</h4><p>kubernetes集群安装完成，确认集群状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 确认node状态</span></span><br><span class="line">[root@k8s-master ~]<span class="comment"># kubectl get nodes</span></span><br><span class="line">NAME         STATUS   ROLES    AGE     VERSION</span><br><span class="line">k8s-master   Ready    master   21m     v1.18.3</span><br><span class="line">k8s-node1    Ready    &lt;none&gt;   6m19s   v1.18.3</span><br><span class="line">k8s-node2    Ready    &lt;none&gt;   6m14s   v1.18.3</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 确认pod状态</span></span><br><span class="line">[root@k8s-master ~]<span class="comment"># kubectl get pod --all-namespaces -o wide</span></span><br><span class="line">NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE     IP               NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">kube-system   coredns-66bff467f8-d47nh             1/1     Running   0          21m     10.244.0.2       k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   coredns-66bff467f8-xh6rc             1/1     Running   0          21m     10.244.0.3       k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   etcd-k8s-master                      1/1     Running   0          21m     192.168.92.201   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-apiserver-k8s-master            1/1     Running   0          21m     192.168.92.201   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-controller-manager-k8s-master   1/1     Running   0          21m     192.168.92.201   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-47tnz          1/1     Running   0          23s     192.168.92.201   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-74smd          1/1     Running   0          23s     192.168.92.202   k8s-node1    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-srstj          1/1     Running   0          23s     192.168.92.203   k8s-node2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-2j7m8                     1/1     Running   0          6m22s   192.168.92.203   k8s-node2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-lxhjf                     1/1     Running   0          21m     192.168.92.201   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-zwxhp                     1/1     Running   0          6m27s   192.168.92.202   k8s-node1    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-scheduler-k8s-master            1/1     Running   0          21m     192.168.92.201   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><p>至此，k8s集群已搭建完成，enjoy  it。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;Kubernetes是Google 2014年创建管理的，是Google 10多年大规模容器管理技术Borg的开源版本。它是容器集群管理系统，是一个开源的平台，可以实现容器集群的自动化部署、自动扩缩容、维护等功能。本文详细介绍了集群的搭建。&lt;/p&gt;
    
    </summary>
    
      <category term="容器化" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Docker" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/Docker/"/>
    
    
      <category term="K8s" scheme="https://wandouduoduo.netlify.com/tags/K8s/"/>
    
  </entry>
  
  <entry>
    <title>如何让es保留固定天数的数据</title>
    <link href="https://wandouduoduo.netlify.com/articles/8e6c2d39.html"/>
    <id>https://wandouduoduo.netlify.com/articles/8e6c2d39.html</id>
    <published>2020-06-17T02:45:07.000Z</published>
    <updated>2020-06-20T02:45:30.603Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>elk为常见的日志分析平台，在很多公司都用使用，但是日志数据是一个不断海量增加的东西，如果没有太大的存储来存储这些日志历史数据，就会需要删除时间过长的历史数据，以保证数据量可控。</p><a id="more"></a><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>elk中elasticsearch为搜索引擎，也是数据的储存单元。要想实现只保留固定时间的数据，这里以7天为例，要想每个索引的数据都只保留最近7天的数据，大于7天的则删除，有两种方法：</p><ol><li><p>看你的索引是怎么样的，如果你的索引名称中有时间，比如logstash-2019-01-02 这样，就是每天都会生成一个新的索引，这样的话可以使用官方的Curator 工具</p></li><li><p>如果你的索引中不带时间，比如，如果是根据应用或者服务名来命名的，那么注意，Curator是无法实现删除索中的某一段数据的！！这里需要特别注意，网上很多说可以实现的，那是因为他们的索引如上面1 所说，是根据时间日期来生成的。但实际上，很多索引都不是这样的，按正常的思维，更容易用服务名或应用名作为索引，以此来区分日志所属应用，方便日志的分析对应指定的应用。这种时候需要使用elasticsearch的api：delete_by_query来进行删除指定数据。这种方法也是通用的，更推荐用这种方法。</p></li></ol><h2 id="使用API"><a href="#使用API" class="headerlink" title="使用API"></a>使用API</h2><p>删除指定的数据，需要使用到delete_by_query接口，这里需要科普一下，在elk中，每一条日志数据就是一个doc文档，如下：每条数据都会有一个_index,_type,_id 分别就是索引，类型，id。</p><p><img src="/articles/8e6c2d39/1.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">delete_by_query的接口格式如下：</span><br><span class="line">请求方式为：post  </span><br><span class="line">url为： http://elasticsearch-host:9200/&#123;index&#125;/_delete_by_query?conflicts=proceed</span><br><span class="line">需要传参数，通过参数执行选择的数据，传参格式为json。</span><br></pre></td></tr></table></figure><p>下面以删除所有索引，超过7天的历史数据为例，用python写成的脚本如下，可以直接拿去用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"> </span><br><span class="line">es_host = <span class="string">'127.0.0。1'</span> <span class="comment"># Elasticsearch访问地址</span></span><br><span class="line"> </span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'Content-Type'</span>: <span class="string">'application/json'</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 这里url中，用*匹配所有的索引，也可以写成logstash-* 匹配所有以logstash-开头的索引等等。</span></span><br><span class="line">url = <span class="string">'http://&#123;&#125;:9200/*/_delete_by_query?conflicts=proceed'</span>.format(es_host)</span><br><span class="line"> </span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">"query"</span>: &#123;</span><br><span class="line">        <span class="string">"range"</span>: &#123;</span><br><span class="line">            <span class="string">"@timestamp"</span>: &#123;    <span class="comment"># 这里我根据默认的时间来作为查询的时间字段，也可以是自定义的</span></span><br><span class="line">                <span class="string">"lt"</span>: <span class="string">"now-7d"</span>,    <span class="comment"># 这里是7天，时间可自定义</span></span><br><span class="line">                <span class="string">"format"</span>: <span class="string">"epoch_millis"</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">response = requests.post(url, headers=headers, data=json.dumps(data))</span><br><span class="line">print(response.json())</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 删除后，需要执行forcemerge操作，手动释放磁盘空间</span></span><br><span class="line">url2 =<span class="string">'http://&#123;&#125;:9200/_forcemerge?only_expunge_deletes=true&amp;max_num_segments=1'</span>.format(es_host)</span><br><span class="line">response = requests.post(url2)</span><br><span class="line"> </span><br><span class="line">print(response.json())</span><br></pre></td></tr></table></figure><p>以上，就是一个完整的删除索引的历史数据的一个脚本，然后只需要将此脚本添加到crontab中，每天定时执行以此就可以实现只保留固定时间的数据了。</p><h2 id="Es-Curator"><a href="#Es-Curator" class="headerlink" title="Es Curator"></a>Es Curator</h2><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>curator 是一个官方的，可以管理elasticsearch索引的工具，可以实现创建，删除，段合并等等操作。</p><h4 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h4><p><a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.html" target="_blank" rel="noopener">官方文档</a></p><h4 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h4><p><img src="/articles/8e6c2d39/2.png" alt></p><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>安装非常简单，直接通过pip安装即可。 其他安装方案，详见官方文档：<a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/installation.html" target="_blank" rel="noopener">安装</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install elasticsearch-curator</span><br></pre></td></tr></table></figure><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><p> 安装后，便可以在命令行中直接使用，使用–help查看一下使用方法</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">curator --<span class="built_in">help</span></span><br><span class="line">Usage: curator [OPTIONS] ACTION_FILE</span><br><span class="line"> </span><br><span class="line">  Curator <span class="keyword">for</span> Elasticsearch indices.</span><br><span class="line"> </span><br><span class="line">  See http://elastic.co/guide/en/elasticsearch/client/curator/current</span><br><span class="line"> </span><br><span class="line">Options:</span><br><span class="line">  --config PATH  Path to configuration file. Default: ~/.curator/curator.yml</span><br><span class="line">  --dry-run      Do not perform any changes.</span><br><span class="line">  --version      Show the version and <span class="built_in">exit</span>.</span><br><span class="line">  --<span class="built_in">help</span>         Show this message and <span class="built_in">exit</span>.</span><br></pre></td></tr></table></figure><p>看到使用需要定义两个文件，一个配置文件 curator,.yml 和 操作文件 action.yml</p><p>配置文件 curator.yml 示例如下： 详细的配置文件配置方法，详见官方文档： <a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/configfile.html" target="_blank" rel="noopener">配置文件curator.yml</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">client:</span><br><span class="line">  hosts:</span><br><span class="line">    - 127.0.0.1</span><br><span class="line">  port: 9200</span><br><span class="line">  url_prefix:</span><br><span class="line">  use_ssl: False</span><br><span class="line">  certificate:</span><br><span class="line">  client_cert:</span><br><span class="line">  client_key:</span><br><span class="line">  ssl_no_validate: False</span><br><span class="line">  <span class="comment"># 下面用户名密码修改为自己es的用户密码</span></span><br><span class="line">  http_auth: elastic:123456</span><br><span class="line">  timeout:</span><br><span class="line">  master_only: True</span><br><span class="line"> </span><br><span class="line">logging:</span><br><span class="line">  loglevel: INFO</span><br><span class="line">  logfile:</span><br><span class="line">  logformat: default</span><br><span class="line">  blacklist: [<span class="string">'elasticsearch'</span>, <span class="string">'urllib3'</span>]</span><br></pre></td></tr></table></figure><p>然后就是action.yml 文件，定义需要执行的操作，我们这里需要删除索引中时间过长的历史数据，详细的操作文件action.yml配置的字段和用法，详见官方文档： </p><p><a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/actions.html" target="_blank" rel="noopener">action操作类型定义</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/filters.html" target="_blank" rel="noopener">filters过滤器定义</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">actions:</span><br><span class="line">  1:</span><br><span class="line">    action: delete_indices    <span class="comment"># 这里执行操作类型为删除索引</span></span><br><span class="line">    description: <span class="string">"delete index expire date"</span></span><br><span class="line">    options:</span><br><span class="line">      ignore_empty_list: True</span><br><span class="line">      timeout_override:</span><br><span class="line">      continue_if_exception: False</span><br><span class="line">      disable_action: False</span><br><span class="line">    filters:</span><br><span class="line">    - filtertype: pattern</span><br><span class="line">      kind: prefix    <span class="comment"># 这里是指匹配前缀为 “yaobili-” 的索引，还可以支持正则匹配等，详见官方文档</span></span><br><span class="line">      value: logstash-</span><br><span class="line">    <span class="comment"># 这里匹配时间</span></span><br><span class="line">    - filtertype: age</span><br><span class="line">      <span class="built_in">source</span>: name    <span class="comment"># 这里不单可以根据name来匹配，还可以根据字段等，详见官方文档</span></span><br><span class="line">      direction: older</span><br><span class="line">    <span class="comment"># 这里定义的是days，还有weeks，months等，总时间为unit * unit_count</span></span><br><span class="line">      unit: days</span><br><span class="line">      unit_count: 7</span><br><span class="line">      timestring: <span class="string">'%Y.%m.%d'</span>    <span class="comment"># 这里是跟在logstash-后面的时间的格式</span></span><br></pre></td></tr></table></figure><p>ok，定义了两个文件后，则可以直接使用命令行进行执行：指定两个文件的路径即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">curator --config curator.yml action.yml </span><br><span class="line">输出日志：</span><br><span class="line">2020-06-17 13:53:39,840 INFO      Preparing Action ID: 1, <span class="string">"delete_indices"</span></span><br><span class="line">2020-06-17 13:53:39,840 INFO      Creating client object and testing connection</span><br><span class="line">2020-06-17 13:53:39,842 INFO      Instantiating client object</span><br><span class="line">2020-06-17 13:53:39,843 INFO      Testing client connectivity</span><br><span class="line">2020-06-17 13:53:39,847 INFO      Successfully created Elasticsearch client object with provided settings</span><br><span class="line">2020-06-17 13:53:39,849 INFO      Connecting only to <span class="built_in">local</span> master node...</span><br><span class="line">2020-06-17 13:53:39,858 INFO      Trying Action ID: 1, <span class="string">"delete_indices"</span>: delete index expire date</span><br><span class="line">2020-06-17 13:53:39,991 INFO      Skipping action <span class="string">"delete_indices"</span> due to empty list: &lt;class <span class="string">'curator.exceptions.NoIndices'</span>&gt;</span><br><span class="line">2020-06-17 13:53:39,992 INFO      Action ID: 1, <span class="string">"delete_indices"</span> completed.</span><br><span class="line">2020-06-17 13:53:39,992 INFO      Job completed.</span><br></pre></td></tr></table></figure><p>最后，将此命令添加到crontab中即可。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;elk为常见的日志分析平台，在很多公司都用使用，但是日志数据是一个不断海量增加的东西，如果没有太大的存储来存储这些日志历史数据，就会需要删除时间过长的历史数据，以保证数据量可控。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Elk" scheme="https://wandouduoduo.netlify.com/tags/Elk/"/>
    
  </entry>
  
  <entry>
    <title>lvs的三次实践</title>
    <link href="https://wandouduoduo.netlify.com/articles/eb3c6886.html"/>
    <id>https://wandouduoduo.netlify.com/articles/eb3c6886.html</id>
    <published>2020-06-11T11:31:15.000Z</published>
    <updated>2020-06-11T12:08:05.913Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文详细介绍了lvs的三次实践。</p><a id="more"></a><h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><h4 id="NAT模式"><a href="#NAT模式" class="headerlink" title="NAT模式"></a><strong>NAT模式</strong></h4><p><strong>实验环境</strong></p><p>三台服务器，一台作为 director，两台作为 real server。</p><p>director 有一个外网网卡(172.16.254.200) 和一个内网ip(192.168.0.8)，两个 real server 上只有内网 ip (192.168.0.18) 和 (192.168.0.28)，并且需要把两个 real server 的内网网关设置为 director 的内网 ip(192.168.0.8)。</p><p><strong>安装和配置</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#两个 real server 上都安装 nginx 服务</span></span><br><span class="line">yum install -y nginx</span><br><span class="line"></span><br><span class="line"><span class="comment">#Director 上安装 ipvsadm</span></span><br><span class="line">yum install -y ipvsadm</span><br></pre></td></tr></table></figure><p>Director 上编辑 nat 实现脚本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /usr/local/sbin/lvs_nat.sh</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑写入如下内容：</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"><span class="comment"># director服务器上开启路由转发功能:</span></span><br><span class="line"><span class="built_in">echo</span> 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br><span class="line"><span class="comment"># 关闭 icmp 的重定向</span></span><br><span class="line"><span class="built_in">echo</span> 0 &gt; /proc/sys/net/ipv4/conf/all/send_redirects</span><br><span class="line"><span class="built_in">echo</span> 0 &gt; /proc/sys/net/ipv4/conf/default/send_redirects</span><br><span class="line"><span class="built_in">echo</span> 0 &gt; /proc/sys/net/ipv4/conf/eth0/send_redirects</span><br><span class="line"><span class="built_in">echo</span> 0 &gt; /proc/sys/net/ipv4/conf/eth1/send_redirects</span><br><span class="line"></span><br><span class="line"><span class="comment"># director设置 nat 防火墙</span></span><br><span class="line">iptables -t nat -F</span><br><span class="line">iptables -t nat -X</span><br><span class="line">iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -j MASQUERADE</span><br><span class="line"></span><br><span class="line"><span class="comment"># director设置 ipvsadm</span></span><br><span class="line">IPVSADM=<span class="string">'/sbin/ipvsadm'</span></span><br><span class="line"><span class="variable">$IPVSADM</span> -C</span><br><span class="line"><span class="variable">$IPVSADM</span> -A -t 172.16.254.200:80 -s wrr</span><br><span class="line"><span class="variable">$IPVSADM</span> -a -t 172.16.254.200:80 -r 192.168.0.18:80 -m -w 1</span><br><span class="line"><span class="variable">$IPVSADM</span> -a -t 172.16.254.200:80 -r 192.168.0.28:80 -m -w 1</span><br></pre></td></tr></table></figure><p>保存后，在 Director 上直接运行这个脚本就可以完成 lvs/nat 的配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/bin/bash   /usr/<span class="built_in">local</span>/sbin/lvs_nat.sh</span><br></pre></td></tr></table></figure><p>查看ipvsadm设置的规则</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipvsadm -ln</span><br></pre></td></tr></table></figure><p><strong>测试LVS的效果</strong></p><p>通过浏览器测试2台机器上的web内容 <a href="http://172.16.254.200" target="_blank" rel="noopener">http://172.16.254.200</a> 。</p><p>为了区分开，我们可以把 nginx 的默认页修改一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在 RS1 上执行</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"rs1rs1"</span> &gt;/usr/share/nginx/html/index.html</span><br><span class="line"></span><br><span class="line"><span class="comment">#在 RS2 上执行</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"rs2rs2"</span> &gt;/usr/share/nginx/html/index.html</span><br></pre></td></tr></table></figure><p><em>注意，切记一定要在两台 RS 上设置网关的 IP 为 director 的内网 IP。</em></p><h4 id="DR模式"><a href="#DR模式" class="headerlink" title="DR模式"></a><strong>DR模式</strong></h4><p><strong>实验环境</strong></p><p>三台机器：</p><ul><li>Director节点：  (eth0 192.168.0.8  vip eth0:0 192.168.0.38)</li><li>Real server1： (eth0 192.168.0.18 vip lo:0 192.168.0.38)</li><li>Real server2： (eth0 192.168.0.28 vip lo:0 192.168.0.38)</li></ul><p><strong>安装</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#两个 real server 上都安装 nginx 服务</span></span><br><span class="line">yum install -y nginx</span><br><span class="line"></span><br><span class="line"><span class="comment">#Director 上安装 ipvsadm</span></span><br><span class="line">yum install -y ipvsadm</span><br></pre></td></tr></table></figure><p><strong>Director 上配置脚本</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">vim /usr/<span class="built_in">local</span>/sbin/lvs_dr.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">echo</span> 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br><span class="line">ipv=/sbin/ipvsadm</span><br><span class="line">vip=192.168.0.38</span><br><span class="line">rs1=192.168.0.18</span><br><span class="line">rs2=192.168.0.28</span><br><span class="line"></span><br><span class="line">ifconfig eth0:0 down</span><br><span class="line">ifconfig eth0:0 <span class="variable">$vip</span> broadcast <span class="variable">$vip</span> netmask 255.255.255.255 up</span><br><span class="line">route add -host <span class="variable">$vip</span> dev eth0:0</span><br><span class="line"><span class="variable">$ipv</span> -C</span><br><span class="line"><span class="variable">$ipv</span> -A -t <span class="variable">$vip</span>:80 -s wrr</span><br><span class="line"><span class="variable">$ipv</span> -a -t <span class="variable">$vip</span>:80 -r <span class="variable">$rs1</span>:80 -g -w 3</span><br><span class="line"><span class="variable">$ipv</span> -a -t <span class="variable">$vip</span>:80 -r <span class="variable">$rs2</span>:80 -g -w 1</span><br></pre></td></tr></table></figure><p>执行脚本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash /usr/<span class="built_in">local</span>/sbin/lvs_dr.sh</span><br></pre></td></tr></table></figure><p><strong>在2台 rs 上配置脚本：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vim /usr/<span class="built_in">local</span>/sbin/lvs_dr_rs.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">vip=192.168.0.38</span><br><span class="line">ifconfig lo:0 <span class="variable">$vip</span> broadcast <span class="variable">$vip</span> netmask 255.255.255.255 up</span><br><span class="line">route add -host <span class="variable">$vip</span> lo:0</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"1"</span> &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"2"</span> &gt;/proc/sys/net/ipv4/conf/lo/arp_announce</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"1"</span> &gt;/proc/sys/net/ipv4/conf/all/arp_ignore</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"2"</span> &gt;/proc/sys/net/ipv4/conf/all/arp_announce</span><br></pre></td></tr></table></figure><p>rs 上分别执行脚本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash /usr/<span class="built_in">local</span>/sbin/lvs_dr_rs.sh</span><br></pre></td></tr></table></figure><p><strong>实验测试</strong></p><p>测试方式同上，浏览器访问 <a href="http://192.168.0.38" target="_blank" rel="noopener">http://192.168.0.38</a></p><p><em>注意：在 DR 模式下，2台 rs 节点的 gateway 不需要设置成 dir 节点的 IP 。</em></p><h4 id="LVS结合keepalive"><a href="#LVS结合keepalive" class="headerlink" title="LVS结合keepalive"></a><strong>LVS结合keepalive</strong></h4><p>LVS可以实现负载均衡，但是不能够进行健康检查，比如一个rs出现故障，LVS 仍然会把请求转发给故障的rs服务器，这样就会导致请求的无效性。keepalive 软件可以进行健康检查，而且能同时实现 LVS 的高可用性，解决 LVS 单点故障的问题，其实 keepalive 就是为 LVS 而生的。</p><p><strong>实验环境</strong></p><p>4台节点</p><ul><li><p>Keepalived1 + lvs1(Director1)：192.168.0.48</p></li><li><p>Keepalived2 + lvs2(Director2)：192.168.0.58</p></li><li><p>Real server1：192.168.0.18</p></li><li><p>Real server2：192.168.0.28</p></li><li><p>IP: 192.168.0.38</p></li></ul><p><strong>安装系统软件</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Lvs + keepalived的2个节点安装</span></span><br><span class="line">yum install ipvsadm keepalived -y</span><br><span class="line"></span><br><span class="line"><span class="comment">#Real server + nginx服务的2个节点安装</span></span><br><span class="line">yum install epel-release -y</span><br><span class="line">yum install nginx -y</span><br></pre></td></tr></table></figure><p><strong>设置配置脚本</strong></p><p>Real server节点2台配置脚本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vim /usr/<span class="built_in">local</span>/sbin/lvs_dr_rs.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line">vip=192.168.0.38</span><br><span class="line">ifconfig lo:0 <span class="variable">$vip</span> broadcast <span class="variable">$vip</span> netmask 255.255.255.255 up</span><br><span class="line">route add -host <span class="variable">$vip</span> lo:0</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"1"</span> &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"2"</span> &gt;/proc/sys/net/ipv4/conf/lo/arp_announce</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"1"</span> &gt;/proc/sys/net/ipv4/conf/all/arp_ignore</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"2"</span> &gt;/proc/sys/net/ipv4/conf/all/arp_announce</span><br></pre></td></tr></table></figure><p>2个节点rs 上分别执行脚本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash /usr/<span class="built_in">local</span>/sbin/lvs_dr_rs.sh</span><br></pre></td></tr></table></figure><p>keepalived节点配置(2节点)：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#主节点( MASTER )配置文件</span></span><br><span class="line"></span><br><span class="line">vim /etc/keepalived/keepalived.conf</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface eth0</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.0.38</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_server 192.168.0.38 80 &#123;</span><br><span class="line">    delay_loop 6</span><br><span class="line">    lb_algo rr</span><br><span class="line">    lb_kind DR</span><br><span class="line">    persistence_timeout 0</span><br><span class="line">    protocol TCP</span><br><span class="line"></span><br><span class="line">    real_server 192.168.0.18 80 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        TCP_CHECK &#123;</span><br><span class="line">            connect_timeout 10</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">            connect_port 80</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    real_server 192.168.0.28 80 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        TCP_CHECK &#123;</span><br><span class="line">            connect_timeout 10</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">            connect_port 80</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从节点( BACKUP )配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#拷贝主节点的配置文件keepalived.conf，然后修改如下内容：</span><br><span class="line"></span><br><span class="line">state MASTER -&gt; state BACKUP</span><br><span class="line">priority 100 -&gt; priority 90</span><br></pre></td></tr></table></figure><p>keepalived的2个节点执行如下命令，开启转发功能：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure><p><strong>启动keepalive</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;strong&gt;先主后从分别启动keepalive&lt;/strong&gt;</span><br><span class="line"></span><br><span class="line">service keepalived start</span><br></pre></td></tr></table></figure><h2 id="验证结果"><a href="#验证结果" class="headerlink" title="验证结果"></a>验证结果</h2><p>实验1</p><p>手动关闭192.168.0.18节点的nginx，service nginx stop 在客户端上去测试访问 <a href="http://192.168.0.38" target="_blank" rel="noopener">http://192.168.0.38</a> 结果正常，不会出现访问18节点，一直访问的是28节点的内容。</p><p>实验2</p><p>手动重新开启 192.168.0.18 节点的nginx， service nginx start 在客户端上去测试访问 <a href="http://192.168.0.38" target="_blank" rel="noopener">http://192.168.0.38</a> 结果正常，按照 rr 调度算法访问18节点和28节点。</p><p>实验3</p><p>测试 keepalived 的HA特性，首先在master上执行命令 ip addr ，可以看到38的vip在master节点上的；这时如果在master上执行 service keepalived stop 命令，这时vip已经不再master上，在slave节点上执行 ip addr 命令可以看到 vip 已经正确漂到slave节点，这时客户端去访问 <a href="http://192.168.0.38" target="_blank" rel="noopener">http://192.168.0.38</a> 访问依然正常，验证了 keepalived的HA特性。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;本文详细介绍了lvs的三次实践。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Lvs" scheme="https://wandouduoduo.netlify.com/tags/Lvs/"/>
    
  </entry>
  
  <entry>
    <title>详解lvs安装部署</title>
    <link href="https://wandouduoduo.netlify.com/articles/2fd6b41.html"/>
    <id>https://wandouduoduo.netlify.com/articles/2fd6b41.html</id>
    <published>2020-06-11T08:44:46.000Z</published>
    <updated>2020-06-11T12:08:05.915Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>负载均衡器分为硬件和软件。硬件如F5等，但是像F5这些设备费用高昂，不是每个公司都有财力用的。而软件业界用的最多的就是lvs，haproxy和nginx，而负载能力最强的就是lvs。本文详细介绍了lvs的安装部署。</p><p><img src="/articles/2fd6b41/1.jpeg" alt="img"></p><p>在实际应用中，在 Web 服务器集群之前总会有一台负载均衡服务器，负载均衡设备的任务就是作为 Web 服务器流量的入口，挑选最合适的一台 Web 服务器，将客户端的请求转发给它处理，实现客户端到真实服务端的透明转发。</p><p>最近几年很火的「云计算」以及分布式架构，本质上也是将后端服务器作为计算资源、存储资源，由某台管理服务器封装成一个服务对外提供，客户端不需要关心真正提供服务的是哪台机器，在它看来，就好像它面对的是一台拥有近乎无限能力的服务器，而本质上，真正提供服务的，是后端的集群。</p><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>环境如下:centos6.5<br>Lvs主调度器：192.168.65.128 vip:192.168.65.200<br>真实服务器：192.168.65.150 vip:192.168.65.200<br>真实服务器：192.168.65.151 vip:192.168.65.200<br>特别注意的是:虚拟地址由keepalived提供</p><h2 id="优劣势分析"><a href="#优劣势分析" class="headerlink" title="优劣势分析"></a>优劣势分析</h2><p>LVS、Nginx、HAProxy 是目前使用最广泛的三种软件负载均衡软件。</p><p>一般对负载均衡的使用是随着网站规模的提升根据不同的阶段来使用不同的技术。具体的应用需求还得具体分析，如果是中小型的 Web 应用，比如日 PV 小于1000万，用 Nginx 就完全可以了；如果机器不少，可以用 DNS 轮询，LVS 所耗费的机器还是比较多的；大型网站或重要的服务，且服务器比较多时，可以考虑用 LVS。</p><p>目前关于网站架构一般比较合理流行的架构方案：Web 前端采用 Nginx/HAProxy+Keepalived 作负载均衡器；后端采用 MySQ L数据库一主多从和读写分离，采用 LVS+Keepalived 的架构。</p><h4 id="LVS"><a href="#LVS" class="headerlink" title="LVS"></a><strong>LVS</strong></h4><p>LVS 是 Linux Virtual Server 的简称，也就是 Linux 虚拟服务器。现在 LVS 已经是 Linux 标准内核的一部分，从 Linux2.4 内核以后，已经完全内置了 LVS 的各个功能模块，无需给内核打任何补丁，可以直接使用 LVS 提供的各种功能。</p><p>LVS 自从1998年开始，发展到现在已经是一个比较成熟的技术项目了。</p><p><strong>LVS 的体系结构</strong></p><p><img src="/articles/2fd6b41/2.jpeg" alt="img"></p><p>LVS 架设的服务器集群系统有三个部分组成：</p><ol><li>最前端的负载均衡层，用 Load Balancer 表示</li><li>中间的服务器集群层，用 Server Array 表示</li><li>最底端的数据共享存储层，用 Shared Storage 表示</li></ol><p><strong>LVS 负载均衡机制</strong></p><p>LVS 是四层负载均衡，也就是说建立在 OSI 模型的第四层——传输层之上，传输层上有我们熟悉的 TCP/UDP，LVS 支持 TCP/UDP 的负载均衡。因为 LVS 是四层负载均衡，因此它相对于其它高层负载均衡的解决办法，比如 DNS 域名轮流解析、应用层负载的调度、客户端的调度等，它的效率是非常高的。</p><p>所谓四层负载均衡 ，也就是主要通过报文中的目标地址和端口。七层负载均衡 ，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容。</p><p><img src="/articles/2fd6b41/3.jpeg" alt="img"></p><p>LVS 的转发主要通过修改 IP 地址（NAT 模式，分为源地址修改 SNAT 和目标地址修改 DNAT）、修改目标 MAC（DR 模式）来实现。</p><p><strong>NAT 模式：网络地址转换</strong></p><p>NAT（Network Address Translation）是一种外网和内网地址映射的技术。</p><p>NAT 模式下，网络数据报的进出都要经过 LVS 的处理。LVS 需要作为 RS（真实服务器）的网关。</p><p>当包到达 LVS 时，LVS 做目标地址转换（DNAT），将目标 IP 改为 RS 的 IP。RS 接收到包以后，仿佛是客户端直接发给它的一样。RS 处理完，返回响应时，源 IP 是 RS IP，目标 IP 是客户端的 IP。这时 RS 的包通过网关（LVS）中转，LVS 会做源地址转换（SNAT），将包的源地址改为 VIP，这样，这个包对客户端看起来就仿佛是 LVS 直接返回给它的。</p><p><img src="/articles/2fd6b41/4.jpeg" alt="img"></p><p><strong>DR 模式：直接路由</strong></p><p>DR 模式下需要 LVS 和 RS 集群绑定同一个 VIP（RS 通过将 VIP 绑定在 loopback 实现），但与 NAT 的不同点在于：请求由 LVS 接受，由真实提供服务的服务器（RealServer，RS）直接返回给用户，返回的时候不经过 LVS。</p><p>详细来看，一个请求过来时，LVS 只需要将网络帧的 MAC 地址修改为某一台 RS 的 MAC，该包就会被转发到相应的 RS 处理，注意此时的源 IP 和目标 IP 都没变，LVS 只是做了一下移花接木。RS 收到 LVS 转发来的包时，链路层发现 MAC 是自己的，到上面的网络层，发现 IP 也是自己的，于是这个包被合法地接受，RS 感知不到前面有 LVS 的存在。而当 RS 返回响应时，只要直接向源 IP（即用户的 IP）返回即可，不再经过 LVS。</p><p><img src="/articles/2fd6b41/5.jpeg" alt="img"></p><p>DR 负载均衡模式数据分发过程中不修改 IP 地址，只修改 mac 地址，由于实际处理请求的真实物理 IP 地址和数据请求目的 IP 地址一致，所以不需要通过负载均衡服务器进行地址转换，可将响应数据包直接返回给用户浏览器，避免负载均衡服务器网卡带宽成为瓶颈。因此，DR 模式具有较好的性能，也是目前大型网站使用最广泛的一种负载均衡手段。</p><p><strong>LVS 的优点</strong></p><ul><li>抗负载能力强、是工作在传输层上仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的，对内存和 cpu 资源消耗比较低。</li><li>配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率。</li><li>工作稳定，因为其本身抗负载能力很强，自身有完整的双机热备方案，如 LVS+Keepalived。</li><li>无流量，LVS 只分发请求，而流量并不从它本身出去，这点保证了均衡器 IO 的性能不会受到大流量的影响。</li><li>应用范围比较广，因为 LVS 工作在传输层，所以它几乎可以对所有应用做负载均衡，包括 http、数据库、在线聊天室等等。</li></ul><p><strong>LVS 的缺点</strong></p><ul><li>软件本身不支持正则表达式处理，不能做动静分离；而现在许多网站在这方面都有较强的需求，这个是 Nginx、HAProxy+Keepalived 的优势所在。</li><li>如果是网站应用比较庞大的话，LVS/DR+Keepalived 实施起来就比较复杂了，相对而言，Nginx/HAProxy+Keepalived就简单多了。</li></ul><h4 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a><strong>Nginx</strong></h4><p>Nginx 是一个强大的 Web 服务器软件，用于处理高并发的 HTTP 请求和作为反向代理服务器做负载均衡。具有高性能、轻量级、内存消耗少，强大的负载均衡能力等优势。</p><p><img src="/articles/2fd6b41/6.jpeg" alt="img"></p><p><strong>Nignx 的架构设计</strong></p><p>相对于传统基于进程或线程的模型（Apache就采用这种模型）在处理并发连接时会为每一个连接建立一个单独的进程或线程，且在网络或者输入/输出操作时阻塞。这将导致内存和 CPU 的大量消耗，因为新起一个单独的进程或线程需要准备新的运行时环境，包括堆和栈内存的分配，以及新的执行上下文，当然，这些也会导致多余的 CPU 开销。最终，会由于过多的上下文切换而导致服务器性能变差。</p><p>反过来，Nginx 的架构设计是采用模块化的、基于事件驱动、异步、单线程且非阻塞。</p><p>Nginx 大量使用多路复用和事件通知，Nginx 启动以后，会在系统中以 daemon 的方式在后台运行，其中包括一个 master 进程，n(n&gt;=1) 个 worker 进程。所有的进程都是单线程（即只有一个主线程）的，且进程间通信主要使用共享内存的方式。</p><p>其中，master 进程用于接收来自外界的信号，并给 worker 进程发送信号，同时监控 worker 进程的工作状态。worker 进程则是外部请求真正的处理者，每个 worker 请求相互独立且平等的竞争来自客户端的请求。请求只能在一个 worker 进程中被处理，且一个 worker 进程只有一个主线程，所以同时只能处理一个请求。（原理同 Netty 很像）</p><p><img src="/articles/2fd6b41/7.jpeg" alt="img"></p><p><strong>Nginx 负载均衡</strong></p><p>Nginx 负载均衡主要是对七层网络通信模型中的第七层应用层上的 http、https 进行支持。</p><p>Nginx 是以反向代理的方式进行负载均衡的。反向代理（Reverse Proxy）方式是指以代理服务器来接受 Internet 上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 Internet 上请求连接的客户端，此时代理服务器对外就表现为一个服务器。</p><p>Nginx 实现负载均衡的分配策略有很多，Nginx 的 upstream 目前支持以下几种方式：</p><ul><li>轮询（默认）：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。</li><li>weight：指定轮询几率，weight 和访问比率成正比，用于后端服务器性能不均的情况。</li><li>ip_hash：每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 的问题。</li><li>fair（第三方）：按后端服务器的响应时间来分配请求，响应时间短的优先分配。</li><li>url_hash（第三方）：按访问 url 的 hash 结果来分配请求，使每个 url 定向到同一个后端服务器，后端服务器为缓存时比较有效。</li></ul><p><strong>Nginx 的优点</strong></p><ul><li>跨平台：Nginx 可以在大多数 Unix like OS编译运行，而且也有 Windows 的移植版本</li><li>配置异常简单：非常容易上手。配置风格跟程序开发一样，神一般的配置</li><li>非阻塞、高并发连接：官方测试能够支撑5万并发连接，在实际生产环境中跑到2～3万并发连接数</li><li>事件驱动：通信机制采用 epoll 模型，支持更大的并发连接</li><li>Master/Worker 结构：一个 master 进程，生成一个或多个 worker 进程</li><li>内存消耗小：处理大并发的请求内存消耗非常小。在3万并发连接下，开启的10个 Nginx 进程才消耗150M 内存（15M*10=150M）</li><li>内置的健康检查功能：如果 Nginx 代理的后端的某台 Web 服务器宕机了，不会影响前端访问</li><li>节省带宽：支持 GZIP 压缩，可以添加浏览器本地缓存的 Header 头</li><li>稳定性高：用于反向代理，宕机的概率微乎其微</li></ul><p><strong>Nginx 的缺点</strong></p><ul><li>Nginx 仅能支 持http、https 和 Email 协议，这样就在适用范围上面小些，这个是它的缺点</li><li>对后端服务器的健康检查，只支持通过端口来检测，不支持通过 ur l来检测。不支持 Session 的直接保持，但能通过 ip_hash 来解决</li></ul><h4 id="HAProxy"><a href="#HAProxy" class="headerlink" title="HAProxy"></a><strong>HAProxy</strong></h4><p>HAProxy 的优点能够补充 Nginx 的一些缺点，比如支持 Session 的保持，Cookie 的引导；同时支持通过获取指定的 url 来检测后端服务器的状态。</p><p>HAProxy 跟 LVS 类似，本身就只是一款负载均衡软件；单纯从效率上来讲 HAProxy 会比 Nginx 有更出色的负载均衡速度，在并发处理上也是优于 Nginx 的。</p><p>HAProxy 支持 TCP 协议的负载均衡转发，可以对 MySQL 读进行负载均衡，对后端的 MySQL 节点进行检测和负载均衡，大家可以用 LVS+Keepalived 对 MySQL 主从做负载均衡。</p><p>HAProxy 负载均衡策略非常多：Round-robin（轮循）、Weight-round-robin（带权轮循）、source（原地址保持）、RI（请求URL）、rdp-cookie（根据cookie）。</p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><h4 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h4><p>修改系统内核文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sysctl.conf 修改默认值0为1，开启内核路由转发模式</span><br><span class="line"></span><br><span class="line">net.ipv4.ip_forward = 1</span><br></pre></td></tr></table></figure><h4 id="源码安装"><a href="#源码安装" class="headerlink" title="源码安装"></a><strong>源码安装</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum install ipvsadm*</span><br><span class="line">wget http://www.linuxvirtualserver.org/software/kernel-2.6/ipvsadm-1.26.tar.gz</span><br><span class="line">tar -zxvf ipvsadm-1.26.tar.gz</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#添加虚拟IP地址，wrr表示给予权重的轮询。rr表示轮询</span></span><br><span class="line">ipvsadm -A -t 192.168.65.200:80 -s wrr</span><br><span class="line"><span class="comment">#制定后台和轮询的IP地址分别是150和151这两台机器 -g表示路由模式，-w表示权重</span></span><br><span class="line">ipvsadm -a -t 192.168.65.200:80 -r 192.168.65.150:80 -g -w 5</span><br><span class="line">ipvsadm -a -t 192.168.65.200:80 -r 192.168.65.151:80 -g -w 5</span><br><span class="line">service ipvsadm save</span><br><span class="line"></span><br><span class="line"><span class="comment">#编辑lvs的配置文件</span></span><br><span class="line">vim /etc/sysconfig/ipvsadm</span><br><span class="line">-A -t 192.168.65.200:80 -s wrr</span><br><span class="line">-a -t 192.168.65.200:80 -r 192.168.65.150:80 -g -w 5</span><br><span class="line">-a -t 192.168.65.200:80 -r 192.168.65.151:80 -g -w 5</span><br><span class="line"></span><br><span class="line"><span class="comment">#开机启动脚本 </span></span><br><span class="line">vim/etc/init.d/ipvsadm</span><br><span class="line"></span><br><span class="line"> <span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Startup script handle the initialisation of LVS</span></span><br><span class="line"><span class="comment"># chkconfig: - 28 72</span></span><br><span class="line"><span class="comment"># description: Initialise the Linux Virtual Server</span></span><br><span class="line"><span class="comment"># config: /etc/sysconfig/ipvsadm</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">### BEGIN INIT INFO</span></span><br><span class="line"><span class="comment"># Provides: ipvsadm</span></span><br><span class="line"><span class="comment"># Required-Start: $local_fs $network $named</span></span><br><span class="line"><span class="comment"># Required-Stop: $local_fs $remote_fs $network</span></span><br><span class="line"><span class="comment"># Short-Description: Initialise the Linux Virtual Server</span></span><br><span class="line"><span class="comment"># Description: The Linux Virtual Server is a highly scalable and highly</span></span><br><span class="line"><span class="comment">#   available server built on a cluster of real servers, with the load</span></span><br><span class="line"><span class="comment">#   balancer running on Linux.</span></span><br><span class="line"><span class="comment">### END INIT INFO</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Source function library</span></span><br><span class="line">. /etc/rc.d/init.d/<span class="built_in">functions</span></span><br><span class="line"></span><br><span class="line">IPVSADM=ipvsadm</span><br><span class="line">IPVSADMRESTORE=<span class="variable">$&#123;IPVSADM&#125;</span>-restore</span><br><span class="line">IPVSADMSAVE=<span class="variable">$&#123;IPVSADM&#125;</span>-save</span><br><span class="line"><span class="comment"># Saved IPVS data</span></span><br><span class="line">IPVSADM_DATA=/etc/sysconfig/<span class="variable">$IPVSADM</span></span><br><span class="line"><span class="comment"># Configuration</span></span><br><span class="line">IPVSADM_CONFIG=/etc/sysconfig/<span class="variable">$&#123;IPVSADM&#125;</span>-config</span><br><span class="line">IPVS=ip_vs</span><br><span class="line">PROC_IPVS=/proc/net/<span class="variable">$IPVS</span></span><br><span class="line">VAR_SUBSYS_IPVSADM=/var/lock/subsys/<span class="variable">$IPVSADM</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -x /sbin/<span class="variable">$IPVSADM</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> -n $<span class="string">"<span class="variable">$&#123;IPVSADM&#125;</span>: /sbin/<span class="variable">$IPVSADM</span> does not exist."</span>; warning; <span class="built_in">echo</span></span><br><span class="line">    <span class="built_in">exit</span> 5</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Old or new modutils</span></span><br><span class="line">/sbin/modprobe --version 2&gt;&amp;1 | grep -q module-init-tools \</span><br><span class="line">    &amp;&amp; NEW_MODUTILS=1 \</span><br><span class="line">    || NEW_MODUTILS=0</span><br><span class="line"></span><br><span class="line"><span class="comment"># Default IPVSADM configuration:</span></span><br><span class="line">IPVS_MODULES_UNLOAD=<span class="string">"yes"</span></span><br><span class="line">IPVS_SAVE_ON_STOP=<span class="string">"no"</span></span><br><span class="line">IPVS_SAVE_ON_RESTART=<span class="string">"no"</span></span><br><span class="line">IPVS_STATUS_NUMERIC=<span class="string">"yes"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load IPVSADM configuration.</span></span><br><span class="line">[ -f <span class="string">"<span class="variable">$IPVSADM_CONFIG</span>"</span> ] &amp;&amp; . <span class="string">"<span class="variable">$IPVSADM_CONFIG</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">rmmod_r</span></span>() &#123;</span><br><span class="line">    <span class="comment"># Unload module with all referring modules.</span></span><br><span class="line">    <span class="comment"># At first all referring modules will be unloaded, then the module itself.</span></span><br><span class="line">    <span class="built_in">local</span> mod=<span class="variable">$1</span></span><br><span class="line">    <span class="built_in">local</span> ret=0</span><br><span class="line">    <span class="built_in">local</span> ref=</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get referring modules.</span></span><br><span class="line">    <span class="comment"># New modutils have another output format.</span></span><br><span class="line">    [ <span class="variable">$NEW_MODUTILS</span> = 1 ] \</span><br><span class="line">        &amp;&amp; ref=$(lsmod | awk <span class="string">"/^<span class="variable">$&#123;mod&#125;</span>[[:space:]]/ &#123; print \$4; &#125;"</span> | tr <span class="string">','</span> <span class="string">' '</span>) \</span><br><span class="line">        || ref=$(lsmod | grep ^<span class="variable">$&#123;mod&#125;</span> | cut -d <span class="string">"["</span> -s -f 2 | cut -d <span class="string">"]"</span> -s -f 1)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># recursive call for all referring modules</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$ref</span>; <span class="keyword">do</span></span><br><span class="line">        rmmod_r <span class="variable">$i</span></span><br><span class="line">        <span class="built_in">let</span> ret+=$?;</span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Unload module.</span></span><br><span class="line">    <span class="comment"># The extra test is for 2.6: The module might have autocleaned,</span></span><br><span class="line">    <span class="comment"># after all referring modules are unloaded.</span></span><br><span class="line">    <span class="keyword">if</span> grep -q <span class="string">"^<span class="variable">$&#123;mod&#125;</span>"</span> /proc/modules ; <span class="keyword">then</span></span><br><span class="line">        modprobe -r <span class="variable">$mod</span> &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">        res=$?</span><br><span class="line">        [ <span class="variable">$res</span> -eq 0 ] || <span class="built_in">echo</span> -n <span class="string">" <span class="variable">$mod</span>"</span></span><br><span class="line">        <span class="built_in">let</span> ret+=<span class="variable">$res</span>;</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> <span class="variable">$ret</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">start</span></span>() &#123;</span><br><span class="line">    <span class="comment"># Do not start if there is no config file.</span></span><br><span class="line">    [ ! -f <span class="string">"<span class="variable">$IPVSADM_DATA</span>"</span> ] &amp;&amp; <span class="built_in">return</span> 6</span><br><span class="line"></span><br><span class="line">    <span class="comment"># check if ipvs module load is deactivated</span></span><br><span class="line">    <span class="keyword">if</span> grep -qIsE <span class="string">"^install[[:space:]]+<span class="variable">$&#123;IPVS&#125;</span>[[:space:]]+/bin/(true|false)"</span> /etc/modprobe.conf /etc/modprobe.d/* ; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> $<span class="string">"<span class="variable">$&#123;IPVSADM&#125;</span>: <span class="variable">$&#123;IPVS&#125;</span> is disabled."</span></span><br><span class="line">        <span class="built_in">return</span> 150</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># If we don't clear these first, we might be adding to pre-existing rules.</span></span><br><span class="line">    action $<span class="string">"<span class="variable">$&#123;IPVSADM&#125;</span>: Clearing the current IPVS table:"</span> <span class="variable">$IPVSADM</span> -C</span><br><span class="line"></span><br><span class="line">    <span class="built_in">echo</span> -n $<span class="string">"<span class="variable">$&#123;IPVSADM&#125;</span>: Applying IPVS configuration: "</span></span><br><span class="line">    <span class="variable">$IPVSADMRESTORE</span> &lt; <span class="variable">$&#123;IPVSADM_DATA&#125;</span></span><br><span class="line">    <span class="keyword">if</span> [ $? -eq 0 ];<span class="keyword">then</span> success; <span class="built_in">echo</span>; <span class="keyword">else</span> failure; <span class="built_in">echo</span>; <span class="built_in">return</span> 1;<span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    touch <span class="variable">$VAR_SUBSYS_IPVSADM</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">stop</span></span>() &#123;</span><br><span class="line">    <span class="comment"># Do not stop if ipvs module is not loaded.</span></span><br><span class="line">    [ ! -e <span class="string">"<span class="variable">$PROC_IPVS</span>"</span> ] &amp;&amp; <span class="built_in">return</span> 0</span><br><span class="line"></span><br><span class="line">    action $<span class="string">"<span class="variable">$&#123;IPVSADM&#125;</span>: Clearing the current IPVS table:"</span> <span class="variable">$IPVSADM</span> -C</span><br><span class="line"></span><br><span class="line">    ret=0</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">"x<span class="variable">$IPVS_MODULES_UNLOAD</span>"</span> = <span class="string">"xyes"</span> ]; <span class="keyword">then</span></span><br><span class="line">        action $<span class="string">"<span class="variable">$&#123;IPVSADM&#125;</span>: Unloading modules:"</span> rmmod_r <span class="variable">$IPVS</span></span><br><span class="line">        [ $? -ne 0 ] &amp;&amp; ret=1</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    rm -f <span class="variable">$VAR_SUBSYS_IPVSADM</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> <span class="variable">$ret</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">status</span></span>() &#123;</span><br><span class="line">    <span class="comment"># Do not print status if lockfile is missing and ipvs modules are not</span></span><br><span class="line">    <span class="comment"># loaded.</span></span><br><span class="line">    <span class="keyword">if</span> [ ! -f <span class="string">"<span class="variable">$VAR_SUBSYS_IPVSADM</span>"</span> -a ! -e <span class="string">"<span class="variable">$PROC_IPVS</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> $<span class="string">"<span class="variable">$&#123;IPVSADM&#125;</span>: IPVS is not running."</span></span><br><span class="line">        <span class="built_in">return</span> 3</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Do show status if ipvs module is not loaded.</span></span><br><span class="line">    <span class="keyword">if</span> [ ! -e <span class="string">"<span class="variable">$PROC_IPVS</span>"</span> ];<span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> $<span class="string">"<span class="variable">$&#123;IPVSADM&#125;</span>: IPVS module is not loaded."</span></span><br><span class="line">        <span class="built_in">return</span> 3</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    NUM=<span class="string">""</span></span><br><span class="line">    [ <span class="string">"x<span class="variable">$IPVS_STATUS_NUMERIC</span>"</span> = <span class="string">"xyes"</span> ] &amp;&amp; NUM=<span class="string">"-n"</span></span><br><span class="line"></span><br><span class="line">    <span class="variable">$IPVSADM</span> -L <span class="variable">$NUM</span> &amp;&amp; <span class="built_in">echo</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">save</span></span>() &#123;</span><br><span class="line">    <span class="comment"># Check if module is loaded</span></span><br><span class="line">    [ ! -e <span class="string">"<span class="variable">$PROC_IPVS</span>"</span> ] &amp;&amp; <span class="built_in">return</span> 0</span><br><span class="line"></span><br><span class="line">    <span class="built_in">echo</span> -n $<span class="string">"<span class="variable">$&#123;IPVSADM&#125;</span>: Saving IPVS table to <span class="variable">$&#123;IPVSADM_DATA&#125;</span>: "</span></span><br><span class="line">    <span class="variable">$IPVSADMSAVE</span> -n &gt; <span class="variable">$&#123;IPVSADM_DATA&#125;</span> 2&gt;/dev/null</span><br><span class="line">    <span class="keyword">if</span> [ $? -eq 0 ];<span class="keyword">then</span> success; <span class="built_in">echo</span>; <span class="keyword">else</span> failure; <span class="built_in">echo</span>; <span class="built_in">return</span> 1;<span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> 0</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">restart</span></span>() &#123;</span><br><span class="line">    [ <span class="string">"x<span class="variable">$IPVS_SAVE_ON_RESTART</span>"</span> = <span class="string">"xyes"</span> ] &amp;&amp; save</span><br><span class="line">    stop</span><br><span class="line">    start</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># See how we were called.</span></span><br><span class="line"><span class="keyword">case</span> <span class="string">"<span class="variable">$1</span>"</span> <span class="keyword">in</span></span><br><span class="line">    start)</span><br><span class="line">        [ -f <span class="string">"<span class="variable">$VAR_SUBSYS_IPVSADM</span>"</span> ] &amp;&amp; <span class="built_in">exit</span> 0</span><br><span class="line"></span><br><span class="line">        <span class="comment"># If we have no configuration, save the current one</span></span><br><span class="line">        [ -f <span class="variable">$&#123;IPVSADM_DATA&#125;</span> ] || save</span><br><span class="line">        start</span><br><span class="line">        RETVAL=$?</span><br><span class="line">        ;;</span><br><span class="line">    stop)</span><br><span class="line">        [ <span class="string">"x<span class="variable">$IPVS_SAVE_ON_STOP</span>"</span> = <span class="string">"xyes"</span> ] &amp;&amp; save</span><br><span class="line">        stop</span><br><span class="line">        RETVAL=$?</span><br><span class="line">        ;;</span><br><span class="line">    restart|force-reload)</span><br><span class="line">        restart</span><br><span class="line">        RETVAL=$?</span><br><span class="line">        ;;</span><br><span class="line">    reload)</span><br><span class="line">        <span class="comment"># Start will flush everything, so it counts as a reload</span></span><br><span class="line">        start</span><br><span class="line">        RETVAL=$?</span><br><span class="line">        ;;</span><br><span class="line">    status)</span><br><span class="line">        status</span><br><span class="line">        RETVAL=$?</span><br><span class="line">        ;;</span><br><span class="line">    save)</span><br><span class="line">        save</span><br><span class="line">        RETVAL=$?</span><br><span class="line">        ;;</span><br><span class="line">    *)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Usage: <span class="variable">$0</span> &#123;start|stop|restart|force-reload|reload|status|save&#125;"</span></span><br><span class="line">        RETVAL=2</span><br><span class="line"><span class="keyword">esac</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">exit</span> <span class="variable">$RETVA</span></span><br></pre></td></tr></table></figure><p><strong>配置real server服务器</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">service iptables stop</span><br><span class="line">iptables -F</span><br><span class="line">vim /etc/sysctl.conf 在文件的末尾添加如下内容</span><br><span class="line">net.ipv4.conf.lo.arp_ignore = 1</span><br><span class="line">net.ipv4.conf.all.arp_ignore = 1</span><br><span class="line">net.ipv4.conf.lo.arp_announce = 2</span><br><span class="line">net.ipv4.conf.all.arp_announce = 2</span><br><span class="line">立即生效配置，禁止arp相应的请求</span><br><span class="line">sysctl -p</span><br><span class="line"></span><br><span class="line">设置虚拟网卡，添加如下内容</span><br><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-lo:0</span><br><span class="line">DEVICE=lo:0</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">IPADDR=192.168.65.200</span><br><span class="line">NETMASK=255.255.255.255</span><br><span class="line">ONBOOT=yes</span><br><span class="line"></span><br><span class="line">添加路由: route add -host 192.168.65.200 dev lo:0</span><br><span class="line"></span><br><span class="line">在lvs调度器查看</span><br><span class="line">ipvsadm -Ln</span><br></pre></td></tr></table></figure><p><img src="/articles/2fd6b41/1.png" alt></p><p>查看你当前ipvsadm的轮询时间，为了使实验有比较好的效果，设置时间为1秒，可以查看转换效果<br>查看当前的的轮询时间<br>ipvsadm -L –timeout<br>设置时间为1秒<br>ipvsadm –set 1 1 1</p><p>在浏览器查看并且过一秒刷新页面地址变化则说明lvs轮询成功<br><img src="/articles/2fd6b41/2.png" alt></p><p>刷新页面之后。可以目前的当前链接的后端服务器轮询</p><p>ipvsadm -Lcn</p><p><img src="/articles/2fd6b41/3.png" alt></p><h2 id="ipvsadm命令"><a href="#ipvsadm命令" class="headerlink" title="ipvsadm命令"></a>ipvsadm命令</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">ipvsadm是LVS在应用层的管理命令，我们可以通过这个命令去管理LVS的配置。在笔者使用的fedora14系统中，已经集成了LVS相关模块，但是ipvsadm命令仍然需要使用yum单独安装。</span><br><span class="line"> </span><br><span class="line">参数：</span><br><span class="line"></span><br><span class="line">-A --add-service      在内核的虚拟服务器表中添加一条新的虚拟服务器记录。也就是增加一台新的虚拟服务器。 </span><br><span class="line">-E --edit-service     编辑内核虚拟服务器表中的一条虚拟服务器记录。 </span><br><span class="line">-D --delete-service   删除内核虚拟服务器表中的一条虚拟服务器记录。 </span><br><span class="line">-C --clear           清除内核虚拟服务器表中的所有记录。 </span><br><span class="line">-R --restore         恢复虚拟服务器规则 </span><br><span class="line">-S --save            保存虚拟服务器规则，输出为-R 选项可读的格式 </span><br><span class="line">-a --add-server      在内核虚拟服务器表的一条记录里添加一条新的真实服务器记录。也就是在一个虚拟服务器中增加一台新的真实服务器 </span><br><span class="line">-e --edit-server     编辑一条虚拟服务器记录中的某条真实服务器记录 </span><br><span class="line">-d --delete-server   删除一条虚拟服务器记录中的某条真实服务器记录 </span><br><span class="line">-L|-l --list         显示内核虚拟服务器表 </span><br><span class="line">-Z --zero            虚拟服务表计数器清零（清空当前的连接数量等） </span><br><span class="line">--<span class="built_in">set</span> tcp tcpfin udp 设置连接超时值 </span><br><span class="line">--start-daemon       启动同步守护进程。他后面可以是master 或backup，用来说明LVS Router 是aster 或是backup。在这个功能上也可以采用keepalived 的VRRP 功能。 </span><br><span class="line">--stop-daemon        停止同步守护进程 </span><br><span class="line">-h --<span class="built_in">help</span>            显示帮助信息 </span><br><span class="line"></span><br><span class="line">其他的选项: </span><br><span class="line"></span><br><span class="line">-t --tcp-service service-address     说明虚拟服务器提供的是tcp 的服务[vip:port] or [real-server-ip:port] </span><br><span class="line">-u --udp-service service-address     说明虚拟服务器提供的是udp 的服务[vip:port] or [real-server-ip:port] </span><br><span class="line">-f --fwmark-service fwmark           说明是经过iptables 标记过的服务类型。 </span><br><span class="line">-s --scheduler scheduler             使用的调度算法，有这样几个选项rr|wrr|lc|wlc|lblc|lblcr|dh|sh|sed|nq,默认的调度算法是： wlc. </span><br><span class="line">-p --persistent [timeout]            持久稳固的服务。这个选项的意思是来自同一个客户的多次请求，将被同一台真实的服务器处理。timeout 的默认值为300 秒。 </span><br><span class="line">-M --netmask                         指定客户地址的子网掩码</span><br><span class="line">-r --real-server server-address      真实的服务器[Real-Server:port] </span><br><span class="line">-g --gatewaying                      指定LVS 的工作模式为直接路由模式（也是LVS 默认的模式） </span><br><span class="line">-i --ipip                            指定LVS 的工作模式为隧道模式 </span><br><span class="line">-m --masquerading                    指定LVS 的工作模式为NAT 模式 </span><br><span class="line">-w --weight weight                   真实服务器的权值 </span><br><span class="line">--mcast-interface interface          指定组播的同步接口 </span><br><span class="line">-c --connection                      显示LVS目前的连接 如：ipvsadm -L -c </span><br><span class="line">   --timeout                         显示tcp tcpfin udp 的timeout 值 如：ipvsadm -L --timeout </span><br><span class="line">   --daemon                          显示同步守护进程状态 </span><br><span class="line">   --stats                           显示统计信息 </span><br><span class="line">   --rate                            显示速率信息 </span><br><span class="line">   --sort                            对虚拟服务器和真实服务器排序输出 </span><br><span class="line">   --numeric -n                      输出IP 地址和端口的数字形式 </span><br><span class="line">-6：                                 如果fwmark用的是ipv6地址需要指定此选项。  </span><br><span class="line"></span><br><span class="line">例1：</span><br><span class="line">ipvsadm -A -t 192.168.10.10:80 -s rr -p 600 <span class="comment">#添加地址为192.168.10.10:80的虚拟服务，指定调度算法为轮转</span></span><br><span class="line">ipvsadm -a -t 192.168.10.10:80 -r 192.168.10.1:80 -g <span class="comment">#添加真实服务器，指定传输模式为DR</span></span><br><span class="line">ipvsadm -a -t 192.168.10.10:80 -r 192.168.10.2:80 -m <span class="comment">#添加真实服务器，指定传输模式为NAT</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#以下表示在内核的虚拟服务器列表中又添加了一条192.168.60.188的虚拟服务器，此虚拟服务器的服务端口为21，即FTP服务。使用的调度策略为wlc，即加权最少链接算法。</span></span><br><span class="line">ipvsadm -A -t 192.168.10.188:21 -s wlc </span><br><span class="line"></span><br><span class="line"><span class="comment">#规则导出导入</span></span><br><span class="line">ipvsadm-save &gt; ipvs.txt  (其中ipvs.txt保存的是你的配置) </span><br><span class="line">ipvsadm-restore &lt; ipvs.txt  (将配置导入)</span><br><span class="line"></span><br><span class="line"><span class="comment">#规则恢复</span></span><br><span class="line">ipvsadm -R &lt; /root/xxx.rule</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看规则</span></span><br><span class="line">ipvsadm -Ln </span><br><span class="line">TCP  192.168.11.100:80 wrr</span><br><span class="line">  -&gt; 192.168.11.12:80             Route   3      0          0</span><br><span class="line">  -&gt; 192.168.11.13:80             Route   3      0          0</span><br><span class="line"></span><br><span class="line">ipvsadm -d -t 192.168.11.100:80 -r 192.168.11.12:80   <span class="comment">#删除一条真实服务器记录</span></span><br></pre></td></tr></table></figure><h2 id="排错"><a href="#排错" class="headerlink" title="排错"></a>排错</h2><p>报错：collect2: ld returned 1 exit status<br>make: * [ipvsadm] Error 1<br>yum install install kernel-headers popt-static</p><p>报错：unexpected argument 192.168.65.130:80<br>使用上面ipvsad的脚本，添加/etc/sysconfig/ipvsadm<br>里面的规则，重启ipvsadm服务</p><p>报错：<br>eloading ipvsadm configuration (via systemctl): Failed to issue method call: Job type reload is not applicable for unit ipvsadm.service.<br>解决办法<br>添加：/sys/fs/cgroup/systemd/system.slice/ipvsadm.service</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;负载均衡器分为硬件和软件。硬件如F5等，但是像F5这些设备费用高昂，不是每个公司都有财力用的。而软件业界用的最多的就是lvs，haproxy和nginx，而负载能力最强的就是lvs。本文详细介绍了lvs的安装部署。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/2fd6b41/1.jpeg&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;p&gt;在实际应用中，在 Web 服务器集群之前总会有一台负载均衡服务器，负载均衡设备的任务就是作为 Web 服务器流量的入口，挑选最合适的一台 Web 服务器，将客户端的请求转发给它处理，实现客户端到真实服务端的透明转发。&lt;/p&gt;
&lt;p&gt;最近几年很火的「云计算」以及分布式架构，本质上也是将后端服务器作为计算资源、存储资源，由某台管理服务器封装成一个服务对外提供，客户端不需要关心真正提供服务的是哪台机器，在它看来，就好像它面对的是一台拥有近乎无限能力的服务器，而本质上，真正提供服务的，是后端的集群。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Lvs" scheme="https://wandouduoduo.netlify.com/tags/Lvs/"/>
    
  </entry>
  
  <entry>
    <title>详解负载均衡器lvs</title>
    <link href="https://wandouduoduo.netlify.com/articles/d0d5843b.html"/>
    <id>https://wandouduoduo.netlify.com/articles/d0d5843b.html</id>
    <published>2020-06-11T03:59:11.000Z</published>
    <updated>2020-06-11T12:08:05.917Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><pre><code>LVS（Linux Virtual Server）即Linux虚拟服务器，是由章文嵩博士主导的开源负载均衡项目，目前LVS已经被集成到Linux内核模块中。该项目在Linux内核中实现了基于IP的数据请求负载均衡调度方案，其体系结构如图1所示，终端互联网用户从外部访问公司的外部负载均衡服务器，终端用户的Web请求会发送给LVS调度器，调度器根据自己预设的算法决定将该请求发送给后端的某台Web服务器，比如，轮询算法可以将外部的请求平均分发给后端的所有服务器，终端用户访问LVS调度器虽然会被转发到后端真实的服务器，但如果真实服务器连接的是相同的存储，提供的服务也是相同的服务，最终用户不管是访问哪台真实服务器，得到的服务内容都是一样的，整个集群对用户而言都是透明的。最后根据LVS工作模式的不同，真实服务器会选择不同的方式将用户需要的数据发送到终端用户，LVS工作模式分为NAT模式、TUN模式、以及DR模式。</code></pre><p><img src="/articles/d0d5843b/1.png" alt></p><p>本文详细讲解了lvs的三种模式和十种算法。让你有个清晰的认识。</p><a id="more"></a><h2 id="三种模式"><a href="#三种模式" class="headerlink" title="三种模式"></a>三种模式</h2><h4 id="基于NAT"><a href="#基于NAT" class="headerlink" title="基于NAT"></a>基于NAT</h4><pre><code>NAT（Network Address Translation）即网络地址转换，其作用是通过数据报头的修改，使得位于企业内部的私有IP地址可以访问外网，以及外部用用户可以访问位于公司内部的私有IP主机。VS/NAT工作模式拓扑结构如图2所示，LVS负载调度器可以使用两块网卡配置不同的IP地址，eth0设置为私钥IP与内部网络通过交换设备相互连接，eth1设备为外网IP与外部网络联通。</code></pre><p> 第一步，用户通过互联网DNS服务器解析到公司负载均衡设备上面的外网地址，相对于真实服务器而言，LVS外网IP又称VIP（Virtual IP Address），用户通过访问VIP，即可连接后端的真实服务器（Real Server），而这一切对用户而言都是透明的，用户以为自己访问的就是真实服务器，但他并不知道自己访问的VIP仅仅是一个调度器，也不清楚后端的真实服务器到底在哪里、有多少真实服务器。</p><p>第二步，用户将请求发送至124.126.147.168，此时LVS将根据预设的算法选择后端的一台真实服务器（192.168.0.1~192.168.0.3），将数据请求包转发给真实服务器，并且在转发之前LVS会修改数据包中的目标地址以及目标端口，目标地址与目标端口将被修改为选出的真实服务器IP地址以及相应的端口。</p><p>第三步，真实的服务器将响应数据包返回给LVS调度器，调度器在得到响应的数据包后会将源地址和源端口修改为VIP及调度器相应的端口，修改完成后，由调度器将响应数据包发送回终端用户，另外，由于LVS调度器有一个连接Hash表，该表中会记录连接请求及转发信息，当同一个连接的下一个数据包发送给调度器时，从该Hash表中可以直接找到之前的连接记录，并根据记录信息选出相同的真实服务器及端口信息。</p><p><img src="/articles/d0d5843b/2.png" alt></p><p>NAT（Network Address Translation）是一种外网和内网地址映射的技术。</p><p>NAT 模式下，网络数据报的进出都要经过 LVS 的处理。LVS 需要作为 RS（真实服务器）的网关。</p><p>当包到达 LVS 时，LVS 做目标地址转换（DNAT），将目标 IP 改为 RS 的 IP。RS 接收到包以后，仿佛是客户端直接发给它的一样。RS 处理完，返回响应时，源 IP 是 RS IP，目标 IP 是客户端的 IP。这时 RS 的包通过网关（LVS）中转，LVS 会做源地址转换（SNAT），将包的源地址改为 VIP，这样，这个包对客户端看起来就仿佛是 LVS 直接返回给它的。</p><p><img src="/articles/d0d5843b/1.jpeg" alt></p><h4 id="基于TUN"><a href="#基于TUN" class="headerlink" title="基于TUN"></a>基于TUN</h4><pre><code>在LVS（NAT）模式的集群环境中，由于所有的数据请求及响应的数据包都需要经过LVS调度器转发，如果后端服务器的数量大于10台，则调度器就会成为整个集群环境的瓶颈。我们知道，数据请求包往往远小于响应数据包的大小。因为响应数据包中包含有客户需要的具体数据，所以LVS（TUN）的思路就是将请求与响应数据分离，让调度器仅处理数据请求，而让真实服务器响应数据包直接返回给客户端。VS/TUN工作模式拓扑结构如图3所示。其中，IP隧道（IP tunning）是一种数据包封装技术，它可以将原始数据包封装并添加新的包头（内容包括新的源地址及端口、目标地址及端口），从而实现将一个目标为调度器的VIP地址的数据包封装，通过隧道转发给后端的真实服务器（Real Server），通过将客户端发往调度器的原始数据包封装，并在其基础上添加新的数据包头（修改目标地址为调度器选择出来的真实服务器的IP地址及对应端口），LVS（TUN）模式要求真实服务器可以直接与外部网络连接，真实服务器在收到请求数据包后直接给客户端主机响应数据。</code></pre><p><img src="/articles/d0d5843b/3.png" alt></p><p><strong>VS/TUN模式的工作原理</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(1)IP隧道技术又称为IP封装技术，它可以将带有源和目标IP地址的数据报文使用新的源和目标IP进行第二次封装，这样这个报文就可以发送到一个指定的目标主机上；</span><br><span class="line">(2)VS/TUN模式下，调度器和后端服务器组之间使用IP隧道技术。当客户端发送的请求(CIP--&gt;VIP)被director接收后，director修改该报文，加上IP隧道两端的IP地址作为新的源和目标地址，并将请求转发给后端被选中的一个目标；</span><br><span class="line">(3)当后端服务器接收到报文后，首先解封报文得到原有的CIP--&gt;VIP，该后端服务器发现自身的tun接口上配置了VIP，因此接受该数据包。</span><br><span class="line">(4)当请求处理完成后，结果将不会重新交给director，而是直接返回给客户端；在后端服务器返回给客户端数据包时，由于使用的是普通网卡接口，根据一般的路由条目，源IP地址将是该网卡接口上的地址，例如是RIP。因此，要让响应数据包的源IP为VIP，必须添加一条特殊的路由条目，明确指定该路由的源地址是VIP。</span><br></pre></td></tr></table></figure><p><strong>采用VS/TUN模式时的基本属性和要求</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(1)Real  Server的RIP和director的DIP不用处于同一物理网络中，且RIP必须可以和公网通信。也就是说集群节点可以跨互联网实现。</span><br><span class="line">(2)real server的 tun接口上需要配置VIP地址，以便接收director转发过来的数据包，以及作为响应报文的源IP。</span><br><span class="line">(3)director给realserver时需要借助隧道，隧道外层的IP头部的源IP是DIP，目标IP是RIP。而realsever响应给客户端的IP头部是根据隧道内层的IP头分析得到的，源IP是VIP，目标IP是CIP。这样客户端就无法区分这个VIP到底是director的还是服务器组中的。</span><br><span class="line">(4)需要添加一条特殊的路由条目，使得后端服务器返回响应给客户端时的源IP为VIP。</span><br><span class="line">(5)director只处理入站请求，响应请求由realserver完成。</span><br><span class="line"></span><br><span class="line">一般来说，VS/TUN模式会用来负载调度缓存服务器组，这些缓存服务器一般放置在不同网络环境，可以就近返回数据给客户端。在请求对象不能在Cache服务器本地命中的情况下，Cache服务器要向源服务器发请求，将结果取回，最后将结果返回给客户。</span><br></pre></td></tr></table></figure><h4 id="基于DR"><a href="#基于DR" class="headerlink" title="基于DR"></a>基于DR</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在LVS（TUN）模式下，由于需要在LVS调度器与真实服务器之间创建隧道连接，这同样会增加服务器的负担。与LVS（TUN）类似，DR模式也叫直接路由模式，其体系结构如图4所示，该模式中LVS依然仅承担数据的入站请求以及根据算法选出合理的真实服务器，最终由后端真实服务器负责将响应数据包发送返回给客户端。与隧道模式不同的是，直接路由模式（DR模式）要求调度器与后端服务器必须在同一个局域网内，VIP地址需要在调度器与后端所有的服务器间共享，因为最终的真实服务器给客户端回应数据包时需要设置源IP为VIP地址，目标IP为客户端IP，这样客户端访问的是调度器的VIP地址，回应的源地址也依然是该VIP地址（真实服务器上的VIP），客户端是感觉不到后端服务器存在的。由于多台计算机都设置了同样一个VIP地址，所以在直接路由模式中要求调度器的VIP地址是对外可见的，客户端需要将请求数据包发送到调度器主机，而所有的真实服务器的VIP地址必须配置在Non-ARP的网络设备上，也就是该网络设备并不会向外广播自己的MAC及对应的IP地址，真实服务器的VIP对外界是不可见的，但真实服务器却可以接受目标地址VIP的网络请求，并在回应数据包时将源地址设置为该VIP地址。调度器根据算法在选出真实服务器后，在不修改数据报文的情况下，将数据帧的MAC地址修改为选出的真实服务器的MAC地址，通过交换机将该数据帧发给真实服务器。整个过程中，真实服务器的VIP不需要对外界可见。</span><br></pre></td></tr></table></figure><p><img src="/articles/d0d5843b/4.png" alt></p><p>DR 模式下需要 LVS 和 RS 集群绑定同一个 VIP（RS 通过将 VIP 绑定在 loopback 实现），但与 NAT 的不同点在于：请求由 LVS 接受，由真实提供服务的服务器（RealServer，RS）直接返回给用户，返回的时候不经过 LVS。</p><p>详细来看，一个请求过来时，LVS 只需要将网络帧的 MAC 地址修改为某一台 RS 的 MAC，该包就会被转发到相应的 RS 处理，注意此时的源 IP 和目标 IP 都没变，LVS 只是做了一下移花接木。RS 收到 LVS 转发来的包时，链路层发现 MAC 是自己的，到上面的网络层，发现 IP 也是自己的，于是这个包被合法地接受，RS 感知不到前面有 LVS 的存在。而当 RS 返回响应时，只要直接向源 IP（即用户的 IP）返回即可，不再经过 LVS。</p><p><img src="/articles/d0d5843b/2.jpeg" alt></p><p>DR 负载均衡模式数据分发过程中不修改 IP 地址，只修改 mac 地址，由于实际处理请求的真实物理 IP 地址和数据请求目的 IP 地址一致，所以不需要通过负载均衡服务器进行地址转换，可将响应数据包直接返回给用户浏览器，避免负载均衡服务器网卡带宽成为瓶颈。因此，DR 模式具有较好的性能，也是目前大型网站使用最广泛的一种负载均衡手段。</p><h2 id="十种调度算法"><a href="#十种调度算法" class="headerlink" title="十种调度算法"></a>十种调度算法</h2><pre><code>根据前面的介绍，我们了解了LVS的三种工作模式，但不管实际环境中采用的是哪种模式，调度算法进行调度的策略与算法都是LVS的核心技术。LVS的调度方法分为两种，一种是静态方法，一种是动态方法：静态方法：仅根据算法本身实现调度；实现起点公平，不管服务器当前处理多少请求，分配的数量一致动态方法：根据算法及后端RS当前的负载状况实现调度；不管以前分了多少，只看分配的结果是不是公平</code></pre><h4 id="静态调度算法（4种）"><a href="#静态调度算法（4种）" class="headerlink" title="静态调度算法（4种）"></a>静态调度算法（4种）</h4><p><em>1)rr  ( round robin 轮叫,轮询)</em>  </p><p>说明：轮询调度算法的原理是每一次把来自用户的请求轮流分配给内部中的服务器，从1开始，直到N(内部服务器个数)，然后重新开始循环。算法的优点是其简洁性，它无需记录当前所有连接的状态，所以它是一种无状态调度。缺点：是不考虑每台服务器的处理能力。</p><p><em>(2)wrr  (weight round robin  加权轮询:以权重之间的比例实现在各主机之间进行调度)</em>  </p><p>说明：由于每台服务器的配置、安装的业务应用等不同，其处理能力会不一样。所以，我们根据服务器的不同处理能力，给每个服务器分配不同的权值，使其能够接受相应权值数的服务请求。</p><p><em>(3)sh  (source hashing  源地址hash实现会话绑定session affinity)</em>  </p><p>说明：简单的说就是有将同一客户端的请求发给同一个real server,源地址散列调度算法正好与目标地址散列调度算法相反，它根据请求的源IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的并且没有超负荷，将请求发送到该服务器，否则返回空。它采用的散列函数与目标地址散列调 度算法的相同。它的算法流程与目标地址散列调度算法的基本相似，除了将请求的目标IP地址换成请求的源IP地址。</p><p><em>(4)dh  (destination hashing  目标地址hash)</em>  </p><p>说明：将同样的请求发送给同一个server,一般用于缓存服务器，简单的说，LB集群后面又加了一层，在LB与realserver之间加了一层缓存服 务器，当一个客户端请求一个页面时,LB发给cache1,当第二个客户端请求同样的页面时，LB还是发给cache1,这就是我们所说的，将同样的请求 发给同一个server,来提高缓存的命中率。目标地址散列调度算法也是针对目标IP地址的负载均衡，它是一种静态映射算法，通过一个散列（Hash）函 数将一个目标IP地址映射到一台服务器。目标地址散列调度算法先根据请求的目标IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。</p><h4 id="动态调度算法（6种）"><a href="#动态调度算法（6种）" class="headerlink" title="动态调度算法（6种）"></a>动态调度算法（6种）</h4><p><em>(1)lc  (leash-connection 最少连接)</em> </p><p>说明：最少连接调度算法是把新的连接请求分配到当前连接数最小的服务器，最小连接调度是一种动态调度短算法，它通过服务器当前所活跃的连接数来估计服务器 的负载均衡，调度器需要记录各个服务器已建立连接的数目，当一个请求被调度到某台服务器，其连接数加1，当连接中止或超时，其连接数减一，在系统实现时， 我们也引入当服务器的权值为0时，表示该服务器不可用而不被调度。此算法忽略了服务器的性能问题，有的服务器性能好，有的服务器性能差，通过加权重来区分 性能，所以有了下面算法wlc。</p><p>简单算法：active*256+inactive (谁的小，挑谁)</p><p><em>(2)wlc  (加权最少连接 )</em> </p><p>说明:加权最小连接调度算法是最小连接调度的超集，各个服务器用相应的权值表示其处理性能。服务器的缺省权值为1，系统管理员可以动态地设置服务器的权限，加权 最小连接调度在调度新连接时尽可能使服务器的已建立连接数和其权值成比例。由于服务器的性能不同，我们给性能相对好的服务器，加大权重，即会接收到更多的 请求。</p><p>简单算法：（active*256+inactive）/weight（谁的小，挑谁）</p><p><em>(3)sed (最少期望延迟)</em> </p><p>说明：不考虑非活动连接，谁的权重大，我们优先选择权重大的服务器来接收请求，但会出现问题，就是权重比较大的服务器会很忙，但权重相对较小的服务器很闲，甚至会接收不到请求，所以便有了下面的算法nq。</p><p>基于wlc算法，简单算法：（active+1)*256/weight （谁的小选谁）</p><p><em>(4)nq (never queue 永不排队)</em>  </p><p>说明：在上面我们说明了，由于某台服务器的权重较小，比较空闲，甚至接收不到请求，而权重大的服务器会很忙，所此算法是sed改进，就是说不管你的权重多 大都会被分配到请求。简单说，无需队列，如果有台real server的连接数为0就直接分配过去，不需要在进行sed运算。</p><p><em>(5)LBLC  (基于局部性的最少连接)</em>  </p><p>说明：基于局部性的最少连接算法是针对请求报文的目标IP地址的负载均衡调度，主要用于Cache集群系统，因为Cache集群中客户请求报文的目标IP 地址是变化的，这里假设任何后端服务器都可以处理任何请求，算法的设计目标在服务器的负载基本平衡的情况下，将相同的目标IP地址的请求调度到同一个台服 务器，来提高服务器的访问局部性和主存Cache命中率，从而调整整个集群系统的处理能力。</p><p><em>(6)LBLCR  (基于局部性的带复制功能的最少连接)</em>   </p><p>说明：基于局部性的带复制功能的最少连接调度算法也是针对目标IP地址的负载均衡，该算法根据请求的目标IP地址找出该目标IP地 址对应的服务器组，按“最小连接”原则从服务器组中选出一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载，则按“最小连接”原则从这个 集群中选出一台服务器，将该服务器加入到服务器组中，将请求发送到该服务器。同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除， 以降低复制的程度。</p><p>总结: 在实际lvs环境中，比较常用的算法有:wlc，rr，wrr这三种，一般性能相近的server常用rr，而根据应用比如连接情况，一般用wlc</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;LVS（Linux Virtual Server）即Linux虚拟服务器，是由章文嵩博士主导的开源负载均衡项目，目前LVS已经被集成到Linux内核模块中。该项目在Linux内核中实现了基于IP的数据请求负载均衡调度方案，其体系结构如图1所示，终端互联网用户从外部访问公司的外部负载均衡服务器，终端用户的Web请求会发送给LVS调度器，调度器根据自己预设的算法决定将该请求发送给后端的某台Web服务器，比如，轮询算法可以将外部的请求平均分发给后端的所有服务器，终端用户访问LVS调度器虽然会被转发到后端真实的服务器，但如果真实服务器连接的是相同的存储，提供的服务也是相同的服务，最终用户不管是访问哪台真实服务器，得到的服务内容都是一样的，整个集群对用户而言都是透明的。最后根据LVS工作模式的不同，真实服务器会选择不同的方式将用户需要的数据发送到终端用户，LVS工作模式分为NAT模式、TUN模式、以及DR模式。&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;/articles/d0d5843b/1.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;本文详细讲解了lvs的三种模式和十种算法。让你有个清晰的认识。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Lvs" scheme="https://wandouduoduo.netlify.com/tags/Lvs/"/>
    
  </entry>
  
  <entry>
    <title>分布式定时任务调度系统Saturn安装部署</title>
    <link href="https://wandouduoduo.netlify.com/articles/8fc06fb2.html"/>
    <id>https://wandouduoduo.netlify.com/articles/8fc06fb2.html</id>
    <published>2020-06-10T11:18:15.000Z</published>
    <updated>2020-06-11T08:50:31.846Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Saturn (定时任务调度系统)是唯品会自主研发的分布式的定时任务的调度平台，目标是取代传统的Linux Cron/Spring Batch Job/Quartz的方式，做到全域统一配置，统一监控，任务高可用以及分片。目前该平台己平稳运行1年，承载着唯品会核心系统的全部定时任务的调度，监控，配置，经受住了生产环境的各种考验。 开源版本系唯品会生产使用的saturn核心，去除了唯品会的认证，监控，告警系统等依赖，可独立部署安装使用。</p><a id="more"></a><h2 id="系统特性"><a href="#系统特性" class="headerlink" title="系统特性"></a>系统特性</h2><h4 id="任务负荷，动态均衡"><a href="#任务负荷，动态均衡" class="headerlink" title="任务负荷，动态均衡"></a>任务负荷，动态均衡</h4><p><img src="/articles/8fc06fb2/1.png" alt></p><p>Saturn 给每个任务的每个分片一个负荷值，即权重。比如任务 A 每个分片的权重都是 30，任务 B每个分片的权重都是 10，在进行资源调度的时候，Saturn 可以根据分配给不同机器的总负荷值，来做一个均衡。比如说机器 1 的负荷值是 60，机器 2 的负荷值也是 60，虽然机器 1 只负责了两个任务分片，机器 2 却负责了四个任务分片，通过任务负荷来达到资源均衡的效果。</p><h4 id="优先列表"><a href="#优先列表" class="headerlink" title="优先列表"></a>优先列表</h4><p>资源自动分配时存在一个问题，若任务非常重要如唯品会的双订单任务，或者订单处理的问题非常重要，这时机器应该如何处理？</p><p><img src="/articles/8fc06fb2/2.png" alt></p><p>对此唯品会引入了优先列表概念，开发和运维人员可以给某些任务分配一些优先运行的机器列表，当优先机器任务存在的时候，只会在这些机器运行，只有当这些机器全部不在了，任务才会被迁移到其他的机器上运行，满足订单部门提出的场景化需求。</p><h4 id="本地模式"><a href="#本地模式" class="headerlink" title="本地模式"></a>本地模式</h4><p><img src="/articles/8fc06fb2/3.png" alt></p><p>有些情况下，任务的分配是不可预知的，比如唯品会在商品售卖前，会全量扫描在售商品图片，这个任务要进行大量的图片处理，这时通常就不会让这个任务跟其他任务共享资源。另外 Saturn 支持容器化，可以在高峰期自动扩展到 150 个节点去执行某个任务，然后在低谷期自动缩回到 20 个节点，这就是 Saturn 本地模式的一种场景。</p><h2 id="探索与演进"><a href="#探索与演进" class="headerlink" title="探索与演进"></a>探索与演进</h2><p>唯品会任务调度系统也经过了长期的探索， 2012 年之前采用 Crond 服务，2014 年开始使用Quartz、 Spring Batch 和各团队的个性化方案，但会遇到任务没法监控，任务出问题了不知道和成本高昂等情况，因此唯品会在 2016 年开始实行全部定时任务，并统一到 Saturn 平台。</p><p>目前 Saturn 产生的价值是：有 66 个业务应用系统在使用，包括订单、支付、库存、用户、财务等售卖相关的核心系统，每天有 350 个执行节点执行任务，每天执行任务 2000 万多次，相当于网站的全部的流量。这表明 Saturn 并不是一个纸上谈兵的产品，它已经承受住了唯品会大规模使用场景的考验。</p><h2 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h2><h4 id="术语定义"><a href="#术语定义" class="headerlink" title="术语定义"></a><strong>术语定义</strong></h4><p><img src="/articles/8fc06fb2/4.png" alt></p><h4 id="系统逻辑架构"><a href="#系统逻辑架构" class="headerlink" title="系统逻辑架构"></a>系统逻辑架构</h4><p><img src="/articles/8fc06fb2/5.png" alt></p><p><strong>执行结点</strong><br>负责作业的触发（定时），作业执行，结果上报，日志上报，告警上报，监控日志写入等功能。可独立运行在业务服务器，也可与业务代码运行在同一个JVM。 使用java开发，提供jar包和可运行的工程两种方式供业务方使用，是业务作业接入saturn最主要的组件。</p><p><strong>控制台</strong><br>负责作业的统一配置，包括作业添加、删除，作业属性配置，作业状态查看，执行日志查看，执行结点监控等功能。 控制台单独部署，提供WEB应用给全域共用，业务接入方根据申请的权限控制对应的业务作业。</p><p><strong>作业分片调度器</strong><br>Saturn的”大脑“，其基本功能是将作业分片指派到执行结点。通过调整分配算法和分配策略，可以将作业合理地安排到合适的执行结点，从而实现HA，负载均衡，动态扩容，作业隔离，资源隔离等治理功能。 作业分片调度器为后台程序，单独部署；它是公共资源，所有域共用同一套作业分片调度器。接入作业后，会自动接受作业分片调度器的调度。</p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><h3 id="控制台console部署"><a href="#控制台console部署" class="headerlink" title="控制台console部署"></a>控制台console部署</h3><h4 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a><strong>准备工作</strong></h4><p>1,  安装zookeeper(&gt;=3.4.6)jdk(&gt;=1.7)并启动zookeeper</p><p>2,  下载console包<a href="https://github.com/vipshop/Saturn/releases（建议下载源码包，自行编译，console项目是基于maven+springboot开发，可以直接打成jar包运行）" target="_blank" rel="noopener">https://github.com/vipshop/Saturn/releases（建议下载源码包，自行编译，console项目是基于maven+springboot开发，可以直接打成jar包运行）</a></p><h4 id="console部署"><a href="#console部署" class="headerlink" title="console部署"></a>console部署</h4><p>1,  准备域配置json文件</p><p>域配置json文件用于定义saturn系统中的组织名，namespace，以及ZK的连接串，格式如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    <span class="attr">"nameAndNamespace"</span>:<span class="string">"/name/namespace"</span>,</span><br><span class="line"></span><br><span class="line">   <span class="attr">"zkAddressList"</span>:<span class="string">"ip:port,ip:port,..."</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>把它保存在某个路径，比如/apps/saturn/config/regcenter.json</p><p>2,  配置环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export   REG_CENTER_JSON_PATH=/apps/saturn/config/regcenter.json</span><br></pre></td></tr></table></figure><p>3 启动saturn console</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -DSATURN_CONSOLE_LOG=/apps –jar  saturn-console-master-SNAPSHOT.jar &amp;</span><br></pre></td></tr></table></figure><p> 注意，如果是在生产环境启动console，建议增加一些JVM启动参数：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#for jdk1.7:</span></span><br><span class="line">-Xmx2G -Xms2G -XX:PermSize=256m-XX:MaxPermSize=512m -XX:+UseConcMarkSweepGC -XX:+UseCMSInitiatingOccupancyOnly-XX:CMSInitiatingOccupancyFraction=75 -XX:+ExplicitGCInvokesConcurrent-Xloggc:<span class="variable">$&#123;HOME&#125;</span>/gc_zk.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps-XX:ErrorFile=<span class="variable">$&#123;HOME&#125;</span>/hs_err_%p.log -XX:+HeapDumpOnOutOfMemoryError-XX:HeapDumpPath=<span class="variable">$&#123;HOME&#125;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#for jdk1.8:</span></span><br><span class="line">-Xmx2G -Xms2G -MetaspaceSize=256m-MaxMetaspaceSize=512m -XX:+UseConcMarkSweepGC-XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=75-XX:+ExplicitGCInvokesConcurrent -Xloggc:<span class="variable">$&#123;HOME&#125;</span>/gc_zk.log -XX:+PrintGCDetails-XX:+PrintGCDateStamps -XX:ErrorFile=<span class="variable">$&#123;HOME&#125;</span>/hs_err_%p.log-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=<span class="variable">$&#123;HOME&#125;</span></span><br></pre></td></tr></table></figure><h3 id="executor部署"><a href="#executor部署" class="headerlink" title="executor部署"></a>executor部署</h3><h4 id="准备工作-1"><a href="#准备工作-1" class="headerlink" title="准备工作"></a>准备工作</h4><p>1，安装jdk(&gt;=1.7)</p><p>2，下载executor包<a href="https://github.com/vipshop/Saturn/releases（建议下载源码包，自行编译）" target="_blank" rel="noopener">https://github.com/vipshop/Saturn/releases（建议下载源码包，自行编译）</a></p><h4 id="executor部署-1"><a href="#executor部署-1" class="headerlink" title="executor部署"></a>executor部署</h4><p>1，配置zookeeper链接地址环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export VIP_SATURN_ZK_CONNECTION=zkip:2181</span><br></pre></td></tr></table></figure><p>2，启动executor</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">chmod a+x bin/saturn-executor.sh</span><br><span class="line"></span><br><span class="line">bin/saturn-executor.sh start -n saturn-it.vip.com -e executor_001 -env dev</span><br><span class="line"></span><br><span class="line"><span class="comment">#-n：本executor所属的域名，即namespace</span></span><br><span class="line"><span class="comment">#-e: 本executor的唯一ID</span></span><br><span class="line"><span class="comment">#-env: 运行模式，可取值为dev/product， dev模式下-Xmx为512m，product模式下-Xmx为2G</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#exeucutor启动之后，日志默认保存在/apps/logs/saturn/&#123;namespace&#125;/&#123;executorname&#125;-&#123;ip&#125;/目录下； 可以通过启动参数修改日志保存路径，具体参数为：</span></span><br><span class="line"></span><br><span class="line">bin/saturn-executor.sh start -nsaturn-it.vip.com -e executor_001 -Dsaturn.log.dir=/apps/logs/otherdir</span><br></pre></td></tr></table></figure><h4 id="部署java作业"><a href="#部署java作业" class="headerlink" title="部署java作业"></a>部署java作业</h4><p>saturn executor启动时会扫描 saturn目录的同级目录下的app目录并加载这个目录下（含子目录)所有的jar包定义的类(关于这个原理，请参考Saturn架构文档 )，因此可以把开发好的jar包及其依赖包一起放在 app目录，目录结构如下：</p><p><img src="/articles/8fc06fb2/6.png" alt></p><p>可以通过 -d 参数来重新定义executor寻找作业实现类的路径，比如</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/saturn-executor.sh start -n saturn-it.vip.com -e executor_001 -d /apps/<span class="built_in">jobs</span></span><br></pre></td></tr></table></figure><p>以上面的命令启动后，exeucutor会从/apps/jobs中寻找作业实现类。</p><h3 id="Saturn-java-开发指引"><a href="#Saturn-java-开发指引" class="headerlink" title="Saturn java 开发指引"></a>Saturn java 开发指引</h3><p><a href="https://github.com/vipshop/Saturn/wiki/saturn%E5%BC%80%E5%8F%91%E6%8C%87%E5%BC%95%E4%B9%8Bjava" target="_blank" rel="noopener">https://github.com/vipshop/Saturn/wiki/saturn%E5%BC%80%E5%8F%91%E6%8C%87%E5%BC%95%E4%B9%8Bjava</a></p><h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><h4 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h4><p>A   192.168.5.24    虚拟机  zookeeper（路径：/home/qq/zookeeper）</p><p>A   192.168.5.24    虚拟机  console</p><p>A   192.168.5.24    虚拟机  executor_001</p><p>B   172.17.30.35    物理机  executor_002</p><p>目录结构：</p><p>A  </p><p><img src="/articles/8fc06fb2/7.png" alt></p><p>B</p><p><img src="/articles/8fc06fb2/8.png" alt></p><h4 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h4><p>A在/etc/profile文件末尾增加如下配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">REG_CENTER_JSON_PATH=/home/qq/saturn/regcenter.json</span><br><span class="line"></span><br><span class="line">VIP_SATURN_ZK_CONNECTION=192.168.5.24:2181</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> REG_CENTER_JSON_PATH VIP_SATURN_ZK_CONNECTION</span><br></pre></td></tr></table></figure><p>B在/etc/profile文件末尾增加如下配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">REG_CENTER_JSON_PATH=/home/qzn/regcenter.json</span><br><span class="line"></span><br><span class="line">VIP_SATURN_ZK_CONNECTION=192.168.5.24:2181</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> REG_CENTER_JSON_PATHVIP_SATURN_ZK_CONNECTION</span><br></pre></td></tr></table></figure><p>A、 B分别在对应的目录下创建regcenter.json文件，并写入如下内容：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">   <span class="attr">"nameAndNamespace"</span>:<span class="string">"/demo/saturn-it.vip.com"</span>,</span><br><span class="line"></span><br><span class="line">   <span class="attr">"zkAddressList"</span>:<span class="string">"192.168.5.24:2181"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="启动console"><a href="#启动console" class="headerlink" title="启动console"></a>启动console</h4><p>首先在A机器启动zookeeper注册中心:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/qq/zookeeper/bin</span><br><span class="line"></span><br><span class="line">./zkServer.sh start &amp;</span><br><span class="line"></span><br><span class="line">日志查看：tail -f zookeeper.out</span><br></pre></td></tr></table></figure><p>然后在A机器启动console控制台:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/qq/saturn/</span><br><span class="line"></span><br><span class="line">java -jarsaturn-console-master-SNAPSHOT.jar &amp;</span><br><span class="line"></span><br><span class="line">日志查看：tail -f  SATURN_CONSOLE_LOG_IS_UNDEFINED/saturn.console</span><br></pre></td></tr></table></figure><p> 启动后可直接在浏览器中访问：<a href="http://192.168.5.24:9088/" target="_blank" rel="noopener">http://192.168.5.24:9088/</a></p><p><img src="/articles/8fc06fb2/9.png" alt></p><h4 id="启动executor-001（带有job）"><a href="#启动executor-001（带有job）" class="headerlink" title="启动executor_001（带有job）"></a>启动executor_001（带有job）</h4><p>首先将demo打成jar放到对应目录下（executor会自动扫描此目录下的相关job），如图：</p><p><img src="/articles/8fc06fb2/10.png" alt></p><p>然后启动executor_001:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span>/home/qq/saturn/saturn-executor-master-SNAPSHOT/saturn/</span><br><span class="line"></span><br><span class="line">bin/saturn-executor.sh start -n saturn-it.vip.com -e executor_001 -env dev</span><br><span class="line"></span><br><span class="line">日志查看: </span><br><span class="line">tail -f /apps/logs/saturn/saturn-it.vip.com/executor_001-192.168.5.24/saturn-executor-log.log(executor日志)</span><br></pre></td></tr></table></figure><p>启动后查看控制台，已经有一个executor</p><h4 id="启动executor-002（带有job）"><a href="#启动executor-002（带有job）" class="headerlink" title="启动executor_002（带有job）"></a>启动executor_002（带有job）</h4><p>与上一步类似</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/qzn/saturn-executor-master-SNAPSHOT/saturn/</span><br><span class="line"></span><br><span class="line">bin/saturn-executor.sh start -n saturn-it.vip.com -e executor_002 -env dev</span><br></pre></td></tr></table></figure><h4 id="执行job"><a href="#执行job" class="headerlink" title="执行job"></a>执行job</h4><p><img src="/articles/8fc06fb2/11.png" alt></p><p>任务启动后，只有一个executor会运行job</p><p>关闭当前运行的executor，任务会在另一个executor运行 bin/saturn-executor.sh stop</p><p> 禁用job后，job可以停止运行</p><p><strong>Job并行执行**</strong></p><p> 修改job设置并启用</p><p> <img src="/articles/8fc06fb2/12.png" alt></p><p>每个executor执行一个分片</p><p>当停止一个executor时，job在另一个executor上会一次执行两个分片任务</p><p><strong>优先executor执行</strong></p><p>设置优先executor为executor_002，则job只会在002上执行</p><p><img src="/articles/8fc06fb2/13.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;Saturn (定时任务调度系统)是唯品会自主研发的分布式的定时任务的调度平台，目标是取代传统的Linux Cron/Spring Batch Job/Quartz的方式，做到全域统一配置，统一监控，任务高可用以及分片。目前该平台己平稳运行1年，承载着唯品会核心系统的全部定时任务的调度，监控，配置，经受住了生产环境的各种考验。 开源版本系唯品会生产使用的saturn核心，去除了唯品会的认证，监控，告警系统等依赖，可独立部署安装使用。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Saturn" scheme="https://wandouduoduo.netlify.com/tags/Saturn/"/>
    
  </entry>
  
  <entry>
    <title>详解统一配置中心平台：Apollo服务搭建</title>
    <link href="https://wandouduoduo.netlify.com/articles/10484a0.html"/>
    <id>https://wandouduoduo.netlify.com/articles/10484a0.html</id>
    <published>2020-05-19T07:06:21.000Z</published>
    <updated>2020-06-11T08:50:50.367Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。本文就详细讲解了Apollo这一统一配置中心的搭建过程。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/ctripcorp/apollo" target="_blank" rel="noopener">官方地址</a></p><p><a href="https://github.com/ctripcorp/apollo/wiki/Apollo%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E4%BB%8B%E7%BB%8D" target="_blank" rel="noopener">官方详细文档</a></p><p><a href="https://github.com/ctripcorp/apollo/wiki/Quick-Start" target="_blank" rel="noopener">快速部署文档</a></p><p><a href="https://github.com/ctripcorp/apollo/wiki/分布式部署指南" target="_blank" rel="noopener">生产分布式部署指南</a></p><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>系统版本：CentOS7.X</p><p>环境组件：JDK1.8，Mysql5.7</p><p>说明：本次部署是在单台上部署测试环境，这里只做研究测试，尽量不要用在生产环境。因为生产环境通常为保证服务的稳定性，需要考虑高可用和高负载等方案。</p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><h4 id="下载安装包"><a href="#下载安装包" class="headerlink" title="下载安装包"></a>下载安装包</h4><p><a href="https://github.com/ctripcorp/apollo/releases" target="_blank" rel="noopener">官方稳定包下载</a></p><p>依赖的jar包如下:</p><p>apollo-adminservice-1.6.1-github.zip</p><p>apollo-configservice-1.6.1-github.zip</p><p>apollo-portal-1.6.1-github.zip  </p><h4 id="创建ApolloPortalDB"><a href="#创建ApolloPortalDB" class="headerlink" title="创建ApolloPortalDB"></a>创建ApolloPortalDB</h4><p>通过各种MySQL客户端导入<a href="https://github.com/nobodyiam/apollo-build-scripts/blob/master/sql/apolloportaldb.sql" target="_blank" rel="noopener">sql/apolloportaldb.sql</a>即可</p><p>导入成功后，可以通过执行以下sql语句来验证</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select `Id`, `AppId`, `Name` from ApolloPortalDB.App;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">Id</th><th align="center">AppId</th><th align="center">Name</th></tr></thead><tbody><tr><td align="center">1</td><td align="center">SampleApp</td><td align="center">Sample App</td></tr></tbody></table><h4 id="创建ApolloConfigDB"><a href="#创建ApolloConfigDB" class="headerlink" title="创建ApolloConfigDB"></a>创建ApolloConfigDB</h4><p>通过各种MySQL客户端导入<a href="https://github.com/nobodyiam/apollo-build-scripts/blob/master/sql/apolloconfigdb.sql" target="_blank" rel="noopener">sql/apolloconfigdb.sql</a>即可<br>导入成功后，可以通过执行以下sql语句来验证</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select `NamespaceId`, `Key`, `Value`, `Comment` from ApolloConfigDB.Item;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">NamespaceId</th><th align="center">Key</th><th align="center">Value</th><th align="center">Comment</th></tr></thead><tbody><tr><td align="center">1</td><td align="center">timeout</td><td align="center">100</td><td align="center">sample timeout配置</td></tr></tbody></table><h4 id="修改数据库配置文件"><a href="#修改数据库配置文件" class="headerlink" title="修改数据库配置文件"></a>修改数据库配置文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建应用目录</span></span><br><span class="line">mkdir -p /usr/<span class="built_in">local</span>/&#123;apollo-adminservice,apollo-configservice,apollo-portal&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压安装包</span></span><br><span class="line">unzip apollo-adminservice-1.6.1-github.zip -d /usr/<span class="built_in">local</span>/apollo-adminservice/</span><br><span class="line">unzip apollo-configservice-1.6.1-github.zip -d /usr/<span class="built_in">local</span>/apollo-configservice/</span><br><span class="line">unzip apollo-portal-1.6.1-github.zip -d /usr/<span class="built_in">local</span>/apollo-portal/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vim /usr/<span class="built_in">local</span>/apollo-configservice/config/application-github.properties</span><br><span class="line"></span><br><span class="line"><span class="comment"># DataSource</span></span><br><span class="line">spring.datasource.url = jdbc:mysql://localhost:3306/ApolloPortalDB?characterEncoding=utf8</span><br><span class="line">spring.datasource.username = root</span><br><span class="line">spring.datasource.password = 123456</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vim /usr/<span class="built_in">local</span>/apollo-portal/config/application-github.properties</span><br><span class="line"></span><br><span class="line"><span class="comment"># DataSource</span></span><br><span class="line">spring.datasource.url = jdbc:mysql://localhost:3306/ApolloConfigDB?characterEncoding=utf8</span><br><span class="line">spring.datasource.username = root</span><br><span class="line">spring.datasource.password = 123456</span><br><span class="line"><span class="comment">#apollo.eureka.server.enabled=true</span></span><br><span class="line"><span class="comment">#apollo.eureka.client.enabled=true</span></span><br></pre></td></tr></table></figure><h4 id="启动apollo服务"><a href="#启动apollo服务" class="headerlink" title="启动apollo服务"></a>启动apollo服务</h4><p>启动顺序</p><p>configservice –&gt;   adminservice  –&gt;  portal</p><p>一切顺利的话: 通过访问  http://部署服务器地址:端口/8070,  就能看到配置登录页</p><p><img src="/articles/10484a0/1.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。本文就详细讲解了Apollo这一统一配置中心的搭建过程。&lt;/p&gt;
&lt;h2 id=&quot;参考&quot;&gt;&lt;a href=&quot;#参考&quot; class=&quot;headerlink&quot; title=&quot;参考&quot;&gt;&lt;/a&gt;参考&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/ctripcorp/apollo&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官方地址&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/ctripcorp/apollo/wiki/Apollo%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E4%BB%8B%E7%BB%8D&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官方详细文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/ctripcorp/apollo/wiki/Quick-Start&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;快速部署文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/ctripcorp/apollo/wiki/分布式部署指南&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;生产分布式部署指南&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Apollo" scheme="https://wandouduoduo.netlify.com/tags/Apollo/"/>
    
  </entry>
  
</feed>
