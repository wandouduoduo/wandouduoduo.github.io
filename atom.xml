<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>豌豆多多</title>
  
  <subtitle>Senior O &amp; M Architect</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://wandouduoduo.netlify.com/"/>
  <updated>2020-04-16T13:28:44.478Z</updated>
  <id>https://wandouduoduo.netlify.com/</id>
  
  <author>
    <name>WanDouDuoDuo</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>CentOS7安装GlusterFS集群教程</title>
    <link href="https://wandouduoduo.netlify.com/articles/afd78e52.html"/>
    <id>https://wandouduoduo.netlify.com/articles/afd78e52.html</id>
    <published>2020-04-16T11:12:47.000Z</published>
    <updated>2020-04-16T13:28:44.478Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>通过本文教程，帮助你搭建glusterfs集群共享存储。</p><h2 id="环境说明"><a href="#环境说明" class="headerlink" title="环境说明"></a>环境说明</h2><p>3台机器安装 GlusterFS 组成一个集群。<br>使用 docker volume plugin GlusterFS</p><p>服务器：<br>10.6.0.140<br>10.6.0.192<br>10.6.0.196</p><p>配置 hosts</p><p>10.6.0.140 swarm-manager<br>10.6.0.192 swarm-node-1<br>10.6.0.196 swarm-node-2</p><p>client:<br>10.6.0.94 node-94</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>CentOS 安装 glusterfs 非常的简单</p><h4 id="安装glusterfs"><a href="#安装glusterfs" class="headerlink" title="安装glusterfs"></a>安装glusterfs</h4><p>在三个节点都执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install centos-release-gluster</span><br><span class="line">yum install -y glusterfs glusterfs-server glusterfs-fuse glusterfs-rdma</span><br></pre></td></tr></table></figure><h4 id="配置-GlusterFS-集群"><a href="#配置-GlusterFS-集群" class="headerlink" title="配置 GlusterFS 集群"></a>配置 GlusterFS 集群</h4><p>启动 glusterFS</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl start glusterd.service</span><br><span class="line">systemctl enable glusterd.service</span><br></pre></td></tr></table></figure><p>在 swarm-manager 节点上配置，将 节点 加入到 集群中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@swarm-manager ~]#gluster peer probe swarm-manager</span><br><span class="line">peer probe: success. Probe on localhost not needed</span><br><span class="line"></span><br><span class="line">[root@swarm-manager ~]#gluster peer probe swarm-node-1</span><br><span class="line">peer probe: success.</span><br><span class="line"></span><br><span class="line">[root@swarm-manager ~]#gluster peer probe swarm-node-2</span><br><span class="line">peer probe: success.</span><br></pre></td></tr></table></figure><h4 id="查看集群状态"><a href="#查看集群状态" class="headerlink" title="查看集群状态"></a><strong>查看集群状态</strong></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@swarm-manager ~]#gluster peer status</span><br><span class="line">Number of Peers: 2</span><br><span class="line"></span><br><span class="line">Hostname: swarm-node-1</span><br><span class="line">Uuid: 41573e8b-eb00-4802-84f0-f923a2c7be79</span><br><span class="line">State: Peer in Cluster (Connected)</span><br><span class="line"></span><br><span class="line">Hostname: swarm-node-2</span><br><span class="line">Uuid: da068e0b-eada-4a50-94ff-623f630986d7</span><br><span class="line">State: Peer in Cluster (Connected)</span><br></pre></td></tr></table></figure><h4 id="创建数据存储目录"><a href="#创建数据存储目录" class="headerlink" title="创建数据存储目录"></a>创建数据存储目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@swarm-manager ~]#mkdir -p /opt/gluster/data</span><br><span class="line">[root@swarm-node-1 ~]# mkdir -p /opt/gluster/data</span><br><span class="line">[root@swarm-node-2 ~]# mkdir -p /opt/gluster/data</span><br></pre></td></tr></table></figure><h4 id="查看volume-状态"><a href="#查看volume-状态" class="headerlink" title="查看volume 状态"></a>查看volume 状态</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@swarm-manager ~]#gluster volume info</span><br><span class="line">No volumes present</span><br></pre></td></tr></table></figure><h4 id="创建GlusterFS磁盘："><a href="#创建GlusterFS磁盘：" class="headerlink" title="创建GlusterFS磁盘："></a>创建GlusterFS磁盘：</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@swarm-manager ~]<span class="comment">#gluster volume create models replica 3 swarm-manager:/opt/gluster/data swarm-node-1:/opt/gluster/data swarm-node-2:/opt/gluster/data force</span></span><br><span class="line">volume create: models: success: please start the volume to access data</span><br></pre></td></tr></table></figure><h2 id="volume-模式说明"><a href="#volume-模式说明" class="headerlink" title="volume 模式说明"></a>volume 模式说明</h2><p>一、 <strong>默认模式</strong>，既DHT, 也叫 分布卷: 将文件已hash算法随机分布到 一台服务器节点中存储。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume create test-volume server1:/exp1 server2:/exp2</span><br></pre></td></tr></table></figure><p><img src="/articles/afd78e52/487774-20160824150913058-603139078.png" alt="img"></p><p>二、 <strong>复制模式</strong>，既AFR, 创建volume 时带 replica x 数量: 将文件复制到 replica x 个节点中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume create test-volume replica 2 transport tcp server1:/exp1 server2:/exp2</span><br></pre></td></tr></table></figure><p><img src="/articles/afd78e52/487774-20160824150919026-1102278746.png" alt="img"></p><p>三、 <strong>条带模式</strong>，既Striped, 创建volume 时带 stripe x 数量： 将文件切割成数据块，分别存储到 stripe x 个节点中 ( 类似raid 0 )。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume create test-volume stripe 2 transport tcp server1:/exp1 server2:/exp2</span><br></pre></td></tr></table></figure><p><img src="/articles/afd78e52/487774-20160824150925136-1728170659.png" alt="img"></p><p>四、 <strong>分布式条带模式（组合型）</strong>，最少需要4台服务器才能创建。 创建volume 时 stripe 2 server = 4 个节点： 是DHT 与 Striped 的组合型。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume create test-volume stripe 2 transport tcp server1:/exp1 server2:/exp2 server3:/exp3 server4:/exp4</span><br></pre></td></tr></table></figure><p><img src="/articles/afd78e52/487774-20160824150931995-642839940.png" alt="img"></p><p>五、 <strong>分布式复制模式（组合型）</strong>, 最少需要4台服务器才能创建。 创建volume 时 replica 2 server = 4 个节点：是DHT 与 AFR 的组合型。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume create test-volume replica 2 transport tcp server1:/exp1 server2:/exp2　server3:/exp3 server4:/exp4</span><br></pre></td></tr></table></figure><p><img src="/articles/afd78e52/487774-20160824150939886-840830039.png" alt="img"></p><p>六、 <strong>条带复制卷模式（组合型）</strong>, 最少需要4台服务器才能创建。 创建volume 时 stripe 2 replica 2 server = 4 个节点： 是 Striped 与 AFR 的组合型。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume create test-volume stripe 2 replica 2 transport tcp server1:/exp1 server2:/exp2 server3:/exp3 server4:/exp4</span><br></pre></td></tr></table></figure><p><img src="/articles/afd78e52/487774-20160824150948276-1699673130.png" alt="img"></p><p>七、 三种模式混合, 至少需要8台 服务器才能创建。 stripe 2 replica 2 , 每4个节点 组成一个 组。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume create test-volume stripe 2 replica 2 transport tcp server1:/exp1 server2:/exp2 server3:/exp3 server4:/exp4 server5:/exp5 server6:/exp6 server7:/exp7 server8:/exp8</span><br></pre></td></tr></table></figure><p><img src="/articles/afd78e52/E:%5CBlog%5Csunhexo%5Csource_posts%5CCentOS7%E5%AE%89%E8%A3%85GlusterFS%E9%9B%86%E7%BE%A4%E6%95%99%E7%A8%8B%5C487774-20160824150956230-1177006347.png" alt="img"></p><h4 id="查看-volume-状态"><a href="#查看-volume-状态" class="headerlink" title="查看 volume 状态"></a>查看 volume 状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@swarm-manager ~]<span class="comment">#gluster volume info</span></span><br><span class="line"></span><br><span class="line">Volume Name: models</span><br><span class="line">Type: Replicate</span><br><span class="line">Volume ID: e539ff3b-2278-4f3f-a594-1f101eabbf1e</span><br><span class="line">Status: Created</span><br><span class="line">Number of Bricks: 1 x 3 = 3</span><br><span class="line">Transport-type: tcp</span><br><span class="line">Bricks:</span><br><span class="line">Brick1: swarm-manager:/opt/gluster/data</span><br><span class="line">Brick2: swarm-node-1:/opt/gluster/data</span><br><span class="line">Brick3: swarm-node-2:/opt/gluster/data</span><br><span class="line">Options Reconfigured:</span><br><span class="line">performance.readdir-ahead: on</span><br></pre></td></tr></table></figure><h4 id="启动-models"><a href="#启动-models" class="headerlink" title="启动 models"></a>启动 models</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@swarm-manager ~]#gluster volume start models</span><br><span class="line">volume start: models: success</span><br></pre></td></tr></table></figure><h2 id="gluster-性能调优"><a href="#gluster-性能调优" class="headerlink" title="gluster 性能调优"></a>gluster 性能调优</h2><p>开启 指定 volume 的配额： (models 为 volume 名称)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume quota models enable</span><br></pre></td></tr></table></figure><p>限制 models 中 / (既总目录) 最大使用 80GB 空间</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume quota models limit-usage / 80GB</span><br></pre></td></tr></table></figure><p>#设置 cache 4GB</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume set models performance.cache-size 4GB</span><br></pre></td></tr></table></figure><p>#开启 异步 ， 后台操作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume set models performance.flush-behind on</span><br></pre></td></tr></table></figure><p>#设置 io 线程 32</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume set models performance.io-thread-count 32</span><br></pre></td></tr></table></figure><p>#设置 回写 (写数据时间，先写入缓存内，再写入硬盘)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume set models performance.write-behind on</span><br></pre></td></tr></table></figure><h2 id="部署GlusterFS客户端"><a href="#部署GlusterFS客户端" class="headerlink" title="部署GlusterFS客户端"></a>部署GlusterFS客户端</h2><p>mount GlusterFS文件系统 (客户端必须加入 glusterfs hosts 否则报错。)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@node-94 ~]#yum install -y glusterfs glusterfs-fuse</span><br><span class="line">[root@node-94 ~]#mkdir -p /opt/gfsmnt</span><br><span class="line">[root@node-94 ~]#mount -t glusterfs swarm-manager:models /opt/gfsmnt/</span><br><span class="line"></span><br><span class="line">[root@node-94 ~]#df -h</span><br><span class="line">文件系统 容量 已用 可用 已用% 挂载点</span><br><span class="line">/dev/mapper/vg001-root 98G 1.2G 97G 2% /</span><br><span class="line">devtmpfs 32G 0 32G 0% /dev</span><br><span class="line">tmpfs 32G 0 32G 0% /dev/shm</span><br><span class="line">tmpfs 32G 130M 32G 1% /run</span><br><span class="line">tmpfs 32G 0 32G 0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/vg001-opt 441G 71G 370G 17% /opt</span><br><span class="line">/dev/sda2 497M 153M 344M 31% /boot</span><br><span class="line">tmpfs 6.3G 0 6.3G 0% /run/user/0</span><br><span class="line">swarm-manager:models 441G 18G 424G 4% /opt/gfsmnt</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>DHT 模式 客户端 创建一个 1G 的文件</p><p>[root@node-94 ~]#time dd if=/dev/zero of=hello bs=1000M count=1<br>记录了1+0 的读入<br>记录了1+0 的写出<br>1048576000字节(1.0 GB)已复制，9.1093 秒，115 MB/秒</p><p>real 0m9.120s<br>user 0m0.000s<br>sys 0m1.134s</p><p>AFR 模式 客户端 创建一个 1G 的文件</p><p>[root@node-94 ~]#time dd if=/dev/zero of=hello.txt bs=1024M count=1<br>录了1+0 的读入<br>记录了1+0 的写出<br>1073741824字节(1.1 GB)已复制，27.4566 秒，39.1 MB/秒</p><p>real 0m27.469s<br>user 0m0.000s<br>sys 0m1.065s</p><p>Striped 模式 客户端 创建一个 1G 的文件</p><p>[root@node-94 ~]#time dd if=/dev/zero of=hello bs=1000M count=1<br>记录了1+0 的读入<br>记录了1+0 的写出<br>1048576000字节(1.0 GB)已复制，9.10669 秒，115 MB/秒</p><p>real 0m9.119s<br>user 0m0.001s<br>sys 0m0.953s</p><p>条带复制卷模式 (Number of Bricks: 1 x 2 x 2 = 4) 客户端 创建一个 1G 的文件</p><p>[root@node-94 ~]#time dd if=/dev/zero of=hello bs=1000M count=1<br>记录了1+0 的读入<br>记录了1+0 的写出<br>1048576000字节(1.0 GB)已复制，17.965 秒，58.4 MB/秒</p><p>real 0m17.978s<br>user 0m0.000s<br>sys 0m0.970s</p><p>分布式复制模式 (Number of Bricks: 2 x 2 = 4) 客户端 创建一个 1G 的文件</p><p>[root@node-94 ~]#time dd if=/dev/zero of=haha bs=100M count=10<br>记录了10+0 的读入<br>记录了10+0 的写出<br>1048576000字节(1.0 GB)已复制，17.7697 秒，59.0 MB/秒</p><p>real 0m17.778s<br>user 0m0.001s<br>sys 0m0.886s</p><p>针对 分布式复制模式还做了如下测试：</p><p>4K随机写 测试:<br>安装 fio (yum -y install libaio-devel (否则运行fio 会报错engine libaio not loadable, 已安装需重新编译，否则一样报错))</p><p>[root@node-94 ~]#fio -ioengine=libaio -bs=4k -direct=1 -thread -rw=randwrite -size=10G -filename=1.txt -name=”EBS 4KB randwrite test” -iodepth=32 -runtime=60</p><p>write: io=352204KB, bw=5869.9KB/s, iops=1467, runt= 60002msec<br>WRITE: io=352204KB, aggrb=5869KB/s, minb=5869KB/s, maxb=5869KB/s, mint=60002msec, maxt=60002msec</p><p>4K随机读 测试：<br>fio -ioengine=libaio -bs=4k -direct=1 -thread -rw=randread -size=10G -filename=1.txt -name=”EBS 4KB randread test” -iodepth=8 -runtime=60</p><p>read: io=881524KB, bw=14692KB/s, iops=3672, runt= 60001msec<br>READ: io=881524KB, aggrb=14691KB/s, minb=14691KB/s, maxb=14691KB/s, mint=60001msec, maxt=60001msec</p><p>512K 顺序写 测试：<br>fio -ioengine=libaio -bs=512k -direct=1 -thread -rw=write -size=10G -filename=512.txt -name=”EBS 512KB seqwrite test” -iodepth=64 -runtime=60</p><p>write: io=3544.0MB, bw=60348KB/s, iops=117, runt= 60135msec<br>WRITE: io=3544.0MB, aggrb=60348KB/s, minb=60348KB/s, maxb=60348KB/s, mint=60135msec, maxt=60135msec</p><h2 id="其他的维护命令："><a href="#其他的维护命令：" class="headerlink" title="其他的维护命令："></a>其他的维护命令：</h2><p>\1. 查看GlusterFS中所有的volume:<br>[root@swarm-manager ~]#gluster volume list</p><p>\2. 删除GlusterFS磁盘：<br>[root@swarm-manager ~]#gluster volume stop models #停止名字为 models 的磁盘<br>[root@swarm-manager ~]#gluster volume delete models #删除名字为 models 的磁盘</p><p>注： 删除 磁盘 以后，必须删除 磁盘( /opt/gluster/data ) 中的 （ .glusterfs/ .trashcan/ ）目录。<br>否则创建新 volume 相同的 磁盘 会出现文件 不分布，或者 类型 错乱 的问题。</p><p>\3. 卸载某个节点GlusterFS磁盘<br>[root@swarm-manager ~]#gluster peer detach swarm-node-2</p><p>\4. 设置访问限制,按照每个volume 来限制<br>[root@swarm-manager ~]#gluster volume set models auth.allow 10.6.0.<em>,10.7.0.</em></p><p>\5. 添加GlusterFS节点：<br>[root@swarm-manager ~]#gluster peer probe swarm-node-3<br>[root@swarm-manager ~]#gluster volume add-brick models swarm-node-3:/opt/gluster/data<br>注：如果是复制卷或者条带卷，则每次添加的Brick数必须是replica或者stripe的整数倍</p><p>\6. 配置卷<br>[root@swarm-manager ~]# gluster volume set</p><p>\7. 缩容volume:</p><p>先将数据迁移到其它可用的Brick，迁移结束后才将该Brick移除：<br>[root@swarm-manager ~]#gluster volume remove-brick models swarm-node-2:/opt/gluster/data swarm-node-3:/opt/gluster/data start</p><p>在执行了start之后，可以使用status命令查看移除进度：<br>[root@swarm-manager ~]#gluster volume remove-brick models swarm-node-2:/opt/gluster/data swarm-node-3:/opt/gluster/data status</p><p>不进行数据迁移，直接删除该Brick：<br>[root@swarm-manager ~]#gluster volume remove-brick models swarm-node-2:/opt/gluster/data swarm-node-3:/opt/gluster/data commit<br>注意，如果是复制卷或者条带卷，则每次移除的Brick数必须是replica或者stripe的整数倍。</p><p>扩容：</p><p>gluster volume add-brick models swarm-node-2:/opt/gluster/data </p><p>\8. 修复命令:<br>[root@swarm-manager ~]#gluster volume replace-brick models swarm-node-2:/opt/gluster/data swarm-node-3:/opt/gluster/data commit -force</p><p>\9. 迁移volume:<br>[root@swarm-manager ~]#gluster volume replace-brick models swarm-node-2:/opt/gluster/data swarm-node-3:/opt/gluster/data start<br>pause 为暂停迁移<br>[root@swarm-manager ~]#gluster volume replace-brick models swarm-node-2:/opt/gluster/data swarm-node-3:/opt/gluster/data pause<br>abort 为终止迁移<br>[root@swarm-manager ~]#gluster volume replace-brick models swarm-node-2:/opt/gluster/data swarm-node-3:/opt/gluster/data abort<br>status 查看迁移状态<br>[root@swarm-manager ~]#gluster volume replace-brick models swarm-node-2:/opt/gluster/data swarm-node-3:/opt/gluster/data status<br>迁移结束后使用commit 来生效<br>[root@swarm-manager ~]#gluster volume replace-brick models swarm-node-2:/opt/gluster/data swarm-node-3:/opt/gluster/data commit</p><p>\10. 均衡volume:<br>[root@swarm-manager ~]#gluster volume models lay-outstart<br>[root@swarm-manager ~]#gluster volume models start<br>[root@swarm-manager ~]#gluster volume models startforce<br>[root@swarm-manager ~]#gluster volume models status<br>[root@swarm-manager ~]#gluster volume models stop</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;通过本文教程，帮助你搭建glusterfs集群共享存储。&lt;/p&gt;
&lt;h2 id=&quot;环境说明&quot;&gt;&lt;a href=&quot;#环境说明&quot; class=&quot;
      
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.netlify.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="GlusterFS" scheme="https://wandouduoduo.netlify.com/tags/GlusterFS/"/>
    
  </entry>
  
  <entry>
    <title>详解开源远程办公openvpn</title>
    <link href="https://wandouduoduo.netlify.com/articles/decac6ef.html"/>
    <id>https://wandouduoduo.netlify.com/articles/decac6ef.html</id>
    <published>2020-02-12T02:07:14.000Z</published>
    <updated>2020-04-19T11:21:07.152Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文利用OpenVPN搭建VPN服务，并利用pam_sqlite3插件实现用户认证；通过openvpn_web进行用户管理与日志系统。</p><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a><strong>环境</strong></h2><p>服务端： CentOS 7.6</p><p>客户端：Windows 7</p><p>OpenVPN: openvpn-2.4.7 (<a href="https://github.com/OpenVPN/openvpn" target="_blank" rel="noopener">https://github.com/OpenVPN/openvpn</a>)</p><p>easy-rsa：easy-rsa 3.0.6 (<a href="https://github.com/OpenVPN/easy-rsa" target="_blank" rel="noopener">https://github.com/OpenVPN/easy-rsa</a>)</p><p>OpenVPN GUI: openvpn gui (<a href="https://gitee.com/lang13002/openvpn-portable" target="_blank" rel="noopener">https://gitee.com/lang13002/openvpn-portable</a>)</p><h2 id="服务端安装"><a href="#服务端安装" class="headerlink" title="服务端安装"></a>服务端安装</h2><h4 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># yum install lz4-devel lzo-devel pam-devel openssl-devel systemd-devel sqlite-devel</span></span><br></pre></td></tr></table></figure><h4 id="安装openvpn"><a href="#安装openvpn" class="headerlink" title="安装openvpn"></a>安装openvpn</h4><p> 从github上下载openvpn源代码包并解压</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># wget https://github.com/OpenVPN/openvpn/archive/v2.4.7.tar.gz</span></span><br><span class="line"><span class="comment"># tar -xvf v2.4.7.tar.gz</span></span><br></pre></td></tr></table></figure><p>编译openvpn并安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cd openvpn-2.4.7</span></span><br><span class="line"><span class="comment"># autoreconf -i -v -f</span></span><br><span class="line"><span class="comment"># ./configure --prefix=/usr/local/openvpn --enable-lzo --enable-lz4 --enable-crypto --enable-server --enable-plugins --enable-port-share --enable-iproute2 --enable-pf --enable-plugin-auth-pam --enable-pam-dlopen --enable-systemd</span></span><br><span class="line"><span class="comment"># make &amp;&amp; make install</span></span><br></pre></td></tr></table></figure><p>参照sample/sample-config-files/server.conf文件生成配置文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /etc/openvpn/server/server.conf</span></span><br><span class="line">port 1194</span><br><span class="line">proto tcp-server</span><br><span class="line">;proto udp</span><br><span class="line">dev tun</span><br><span class="line">topology subnet</span><br><span class="line"></span><br><span class="line">ca /etc/openvpn/server/ca.crt</span><br><span class="line">cert /etc/openvpn/server/server.crt</span><br><span class="line">key /etc/openvpn/server/server.key</span><br><span class="line">dh /etc/openvpn/server/dh.pem</span><br><span class="line">tls-auth /etc/openvpn/server/ta.key 0</span><br><span class="line"></span><br><span class="line">user nobody</span><br><span class="line">group nobody</span><br><span class="line"></span><br><span class="line">server 10.8.0.0 255.255.255.0</span><br><span class="line">;ifconfig-pool-persist ipp.txt</span><br><span class="line">;push <span class="string">"redirect-gateway def1 bypass-dhcp"</span></span><br><span class="line">push <span class="string">"dhcp-option DNS 114.114.114.114"</span></span><br><span class="line">push <span class="string">"route 192.168.133.0 255.255.255.0"</span></span><br><span class="line">push <span class="string">"route-gateway 10.200.227.114"</span></span><br><span class="line"></span><br><span class="line">;client-to-client</span><br><span class="line"></span><br><span class="line">keepalive 10 120</span><br><span class="line">comp-lzo</span><br><span class="line">compress <span class="string">"lz4"</span></span><br><span class="line">persist-key</span><br><span class="line">persist-tun</span><br><span class="line">cipher AES-256-CBC</span><br><span class="line">status /var/<span class="built_in">log</span>/openvpn-status.log</span><br><span class="line"><span class="built_in">log</span>    /var/<span class="built_in">log</span>/openvpn.log</span><br><span class="line">verb 3</span><br></pre></td></tr></table></figure><p>配置系统服务</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cp distro/systemd/openvpn-server@.service /usr/lib/systemd/system/</span></span><br><span class="line"><span class="comment"># systemctl enable openvpn</span></span><br></pre></td></tr></table></figure><h4 id="生成证书"><a href="#生成证书" class="headerlink" title="生成证书"></a>生成证书</h4><p>下载easy-rsa3并解压</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># wget https://github.com/OpenVPN/easy-rsa/archive/v3.0.6.tar.gz</span><br><span class="line"># tar -xvf v3.0.6.tar.gz</span><br></pre></td></tr></table></figure><p>根据easy-rsa-3.0.6/easyrsa3/vars.example文件生成全局配置文件vars</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># cd easy-rsa-3.0.6/easyrsa3/</span><br><span class="line"># cp vars.samples vars</span><br></pre></td></tr></table></figure><p>修改vars文件，根据需要去掉注释，并修改对应值</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">set_var EASYRSA_REQ_COUNTRY     &quot;CN&quot;</span><br><span class="line">set_var EASYRSA_REQ_PROVINCE    &quot;HUBEI&quot;</span><br><span class="line">set_var EASYRSA_REQ_CITY        &quot;WUHAN&quot;</span><br><span class="line">set_var EASYRSA_REQ_ORG &quot;ZJ&quot;</span><br><span class="line">set_var EASYRSA_REQ_EMAIL       &quot;zj@test.com&quot;</span><br><span class="line">set_var EASYRSA_REQ_OU          &quot;ZJ&quot;</span><br><span class="line"></span><br><span class="line">set_var EASYRSA_KEY_SIZE        2048</span><br><span class="line"></span><br><span class="line">set_var EASYRSA_ALGO            rsa</span><br></pre></td></tr></table></figure><p>生成服务端证书</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># ./easyrsa init-pki    # 初始化，生成一系列文件与目录</span><br><span class="line"># ./easyrsa build-ca    # 生成根证书，记住ca密码</span><br><span class="line"># ./easyrsa build-server-full server nopass # 生成服务端证书，nopass参数生成一个无密码的证书</span><br><span class="line"># ./easyrsa gen-dh      # 生成Diffie-Hellman</span><br></pre></td></tr></table></figure><p>生成客户端证书</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># ./easy-rsa build-client-full client1 nopass</span><br><span class="line">注：可生成client1, client2, client3或对应姓名的客户端证书</span><br></pre></td></tr></table></figure><p>整理服务端证书</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># cp pki/ca.crt /etc/openvpn/server/</span><br><span class="line"># cp pki/private/server.key /etc/openvpn/server/</span><br><span class="line"># cp pki/issued/server.crt /etc/openvpn/server/</span><br><span class="line"># cp pki/dh.pem /etc/openvpn/server/</span><br></pre></td></tr></table></figure><h4 id="开启路由转发功能与防火墙"><a href="#开启路由转发功能与防火墙" class="headerlink" title="开启路由转发功能与防火墙"></a>开启路由转发功能与防火墙</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 路由转发</span><br><span class="line"># vim /etc/sysctl.conf</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line"></span><br><span class="line"># 临时启用</span><br><span class="line"># echo 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br><span class="line"></span><br><span class="line"># 防火墙</span><br><span class="line"># firewall-cmd --zone=public --add-service=openvpn</span><br></pre></td></tr></table></figure><p>下载pam_sqlite3并安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># git clone https://gitee.com/lang13002/pam_sqlite3.git</span><br><span class="line"># cd pam_sqlite3</span><br><span class="line"># make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>添加pam认证文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># vim /etc/pam.d/openvpn</span><br><span class="line">auth        required    pam_sqlite3.so db=/etc/openvpn/openvpn.db table=t_user user=username passwd=password expire=expire crypt=1</span><br><span class="line">account     required    pam_sqlite3.so db=/etc/openvpn/openvpn.db table=t_user user=username passwd=password expire=expire crypt=1</span><br></pre></td></tr></table></figure><p>创建sqlite3数据库文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># sqlite3 /etc/openvpn/openvpn.db</span><br><span class="line"></span><br><span class="line">sqlite&gt; create table t_user (</span><br><span class="line">     username text not null, </span><br><span class="line">     password text not null, </span><br><span class="line">     active int, </span><br><span class="line">     expire text</span><br><span class="line">);</span><br><span class="line">sqlite&gt; .quit</span><br></pre></td></tr></table></figure><p>在服务端配置添加认证插件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">verify-client-cert none</span><br><span class="line">username-as-common-name</span><br><span class="line">plugin /usr/local/openvpn/lib/openvpn/plugins/openvpn-plugin-auth-pam.so openvpn</span><br></pre></td></tr></table></figure><h2 id="客户端安装"><a href="#客户端安装" class="headerlink" title="客户端安装"></a>客户端安装</h2><h4 id="下载客户端程序："><a href="#下载客户端程序：" class="headerlink" title="下载客户端程序："></a>下载客户端程序：</h4><p> 从<a href="https://gitee.com/lang13002/openvpn-portable/repository/archive/v1.0下载程序，并安装网卡驱动；" target="_blank" rel="noopener">https://gitee.com/lang13002/openvpn-portable/repository/archive/v1.0下载程序，并安装网卡驱动；</a></p><h4 id="安装驱动："><a href="#安装驱动：" class="headerlink" title="安装驱动："></a>安装驱动：</h4><p>运行openvpn-portable/tap-windows.exe</p><h4 id="设置客户端证书"><a href="#设置客户端证书" class="headerlink" title="设置客户端证书"></a>设置客户端证书</h4><p>将上面生成的ca.crt, client1.crt, client1.key放到openvpn-portable的data/config下，并修改客户端配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">ca ca.crt</span><br><span class="line">cert client1.crt</span><br><span class="line">key client1.key</span><br><span class="line"></span><br><span class="line">remote-cert-tls server</span><br><span class="line">auth-user-pass</span><br><span class="line">auth-nocache</span><br><span class="line">注：当有多个客户端时，有多个文件(ca.crt, client1.crt, client1.key, client.ovpn)需要分发给客户，势必会很麻烦；可以将证书嵌入到客户端配置文件中； </span><br><span class="line">;ca ca.crt         // 将这行注释掉</span><br><span class="line">;cert client.crt   // 将这行注释掉</span><br><span class="line">;key client.key    // 将这行注释掉</span><br><span class="line"> &lt;ca&gt;</span><br><span class="line">-----BEGIN CERTIFICATE-----</span><br><span class="line">MIIDGDCCAgCgAwIBAgIJAI9Ld4PlKEiOMA0GCSqGSIb3DQEBCwUAMA0xCzAJBgNV</span><br><span class="line">....</span><br><span class="line">OCeTQvQ4WhyIvVgURV3ITcAKYFKUQ1sPbpjuZg==</span><br><span class="line">-----END CERTIFICATE---</span><br><span class="line">&lt;/ca&gt;</span><br><span class="line">&lt;cert&gt;</span><br><span class="line">-----BEGIN CERTIFICATE-----</span><br><span class="line">MIIDODCCAiCgAwIBAgIRAIZoEQ5PvHDs9xpTLMP3RqMwDQYJKoZIhvcNAQELBQAw</span><br><span class="line">......</span><br><span class="line">nCpzC3l8sVezxk2r</span><br><span class="line">-----END CERTIFICATE-----</span><br><span class="line">&lt;/cert&gt; &lt;key&gt;</span><br><span class="line">-----BEGIN PRIVATE KEY-----</span><br><span class="line">MIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQDw1iq3HBe1otCU</span><br><span class="line">......</span><br><span class="line">ullaNc6mu3N/wTPZoQhDOKAO</span><br><span class="line">-----END PRIVATE KEY-----&lt;/key&gt;</span><br></pre></td></tr></table></figure><h4 id="启动openvpn服务"><a href="#启动openvpn服务" class="headerlink" title="启动openvpn服务"></a>启动openvpn服务</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># systemctl start openvpn</span><br></pre></td></tr></table></figure><h4 id="启动openvpn-porable"><a href="#启动openvpn-porable" class="headerlink" title="启动openvpn-porable"></a>启动openvpn-porable</h4><p><img src="/articles/decac6ef/73636f45138fc37f6e606d0f0aa0656cfa1.jpg" alt="img"></p><h2 id="管理界面安装"><a href="#管理界面安装" class="headerlink" title="管理界面安装"></a>管理界面安装</h2><h4 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pip2 install peewee tornado</span></span><br></pre></td></tr></table></figure><h4 id="下载openvpn-web"><a href="#下载openvpn-web" class="headerlink" title="下载openvpn-web"></a>下载openvpn-web</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># git clone https://gitee.com/lang13002/openvpn_web.git</span></span><br></pre></td></tr></table></figure><h4 id="创建相应的数据库表"><a href="#创建相应的数据库表" class="headerlink" title="创建相应的数据库表"></a>创建相应的数据库表</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sqlite3 /etc/openvpn/openvpn.db</span></span><br><span class="line">sqlite&gt; .import openvpn_web/model/openvpn.sql</span><br></pre></td></tr></table></figure><h4 id="OpenVPN运行脚本写日志"><a href="#OpenVPN运行脚本写日志" class="headerlink" title="OpenVPN运行脚本写日志"></a>OpenVPN运行脚本写日志</h4><p> 服务端配置添加运行脚本   </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">script-security 2</span><br><span class="line">client-connect /etc/openvpn/server/connect.py</span><br><span class="line">client-disconnect /etc/openvpn/server/disconnect.py</span><br></pre></td></tr></table></figure><p>connect.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line"></span><br><span class="line">username = os.environ[<span class="string">'common_name'</span>]</span><br><span class="line">trusted_ip = os.environ[<span class="string">'trusted_ip'</span>]</span><br><span class="line">trusted_port = os.environ[<span class="string">'trusted_port'</span>]</span><br><span class="line">local = os.environ[<span class="string">'ifconfig_local'</span>]</span><br><span class="line">remote = os.environ[<span class="string">'ifconfig_pool_remote_ip'</span>]</span><br><span class="line">timeunix= os.environ[<span class="string">'time_unix'</span>]</span><br><span class="line"></span><br><span class="line">logintime = time.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>, time.localtime(time.time()))</span><br><span class="line"></span><br><span class="line">conn = sqlite3.connect(<span class="string">"/etc/openvpn/openvpn.db"</span>)</span><br><span class="line">cursor = conn.cursor()</span><br><span class="line">query = <span class="string">"insert into t_logs(username, timeunix, trusted_ip, trusted_port, local, remote, logintime) values('%s','%s', '%s', '%s', '%s', '%s', '%s')"</span> %  (username, timeunix, trusted_ip, trusted_port, local, remote, logintime)</span><br><span class="line">cursor.execute(query)</span><br><span class="line">conn.commit()</span><br><span class="line">conn.close()</span><br></pre></td></tr></table></figure><p>disconnect.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line"></span><br><span class="line">username = os.environ[<span class="string">'common_name'</span>]</span><br><span class="line">trusted_ip = os.environ[<span class="string">'trusted_ip'</span>]</span><br><span class="line">received = os.environ[<span class="string">'bytes_received'</span>]</span><br><span class="line">sent = os.environ[<span class="string">'bytes_sent'</span>]</span><br><span class="line"></span><br><span class="line">logouttime = time.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>, time.localtime(time.time()))</span><br><span class="line"></span><br><span class="line">conn = sqlite3.connect(<span class="string">"/etc/openvpn/openvpn.db"</span>)</span><br><span class="line">cursor = conn.cursor()</span><br><span class="line">query = <span class="string">"update t_logs set logouttime='%s', received='%s', sent= '%s' where username = '%s' and trusted_ip = '%s'"</span> %  (logouttime, received, sent, username, trusted_ip)</span><br><span class="line">cursor.execute(query)</span><br><span class="line">conn.commit()</span><br><span class="line">conn.close()</span><br></pre></td></tr></table></figure><h4 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># python myapp.py</span><br></pre></td></tr></table></figure><h4 id="管理界面"><a href="#管理界面" class="headerlink" title="管理界面"></a>管理界面</h4><p><img src="/articles/decac6ef/162533_61adb798_1097803.png" alt="img"></p><p><img src="/articles/decac6ef/162557_07c99033_1097803.png" alt="img"></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;本文利用OpenVPN搭建VPN服务，并利用pam_sqlite3插件实现用户认证；通过openvpn_web进行用户管理与日志系统。&lt;/p
      
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="openvpn" scheme="https://wandouduoduo.netlify.com/tags/openvpn/"/>
    
  </entry>
  
  <entry>
    <title>Hexo增加APlayer播放音乐</title>
    <link href="https://wandouduoduo.netlify.com/articles/4929566e.html"/>
    <id>https://wandouduoduo.netlify.com/articles/4929566e.html</id>
    <published>2020-01-15T09:38:10.000Z</published>
    <updated>2020-01-15T10:26:43.077Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>hexo搭建完静态博客后，有同学只看技术文档比较枯燥，会犯困。那么如果有音乐播放的功能，就可以一遍阅读文章，一边欣赏音乐了，岂不是一件很愉快的事。那么下面就以本站点为例，分享怎么在自己的hexo网站增加音乐播放功能。</p><a id="more"></a><h2 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h2><p>先上张效果图，如果有兴趣再接着往下看。</p><p><img src="/articles/4929566e/1.png" alt></p><h2 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h2><h4 id="播放器安装"><a href="#播放器安装" class="headerlink" title="播放器安装"></a>播放器安装</h4><p><a href="https://github.com/MoePlayer/APlayer" target="_blank" rel="noopener">APlayer</a>，下载github压缩包，解压后把dist文件夹复制到\themes\next\source目录中。</p><p><img src="/articles/4929566e/2.png" alt></p><h4 id="播放列表配置"><a href="#播放列表配置" class="headerlink" title="播放列表配置"></a>播放列表配置</h4><p>在dist目录里，新建music.js文件，并把如下代码粘贴进去。</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> ap = <span class="keyword">new</span> APlayer(&#123;</span><br><span class="line">    container: <span class="built_in">document</span>.getElementById(<span class="string">'aplayer'</span>),</span><br><span class="line">    fixed: <span class="literal">true</span>,</span><br><span class="line">    autoplay: <span class="literal">false</span>,</span><br><span class="line">    audio: [</span><br><span class="line">  &#123;</span><br><span class="line">        name: <span class="string">"还有多少个十年"</span>,</span><br><span class="line">        artist: <span class="string">'沈宁'</span>,</span><br><span class="line">        url: <span class="string">'http://m10.music.126.net/20200115174104/d1ca54236f9cb5d1b1e618b3063fca0f/ymusic/1266/9dd9/a0a5/ff5eb332cbd8f36891c9a8e0e68e47a1.mp3'</span>,</span><br><span class="line">        cover: <span class="string">'http://p2.music.126.net/W0iLDEeY8bjpYVcNT0Mr2g==/17787899114524329.jpg?param=130y130'</span>,</span><br><span class="line">      &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">        name: <span class="string">'我们的时光'</span>,</span><br><span class="line">        artist: <span class="string">'赵雷'</span>,</span><br><span class="line">        url: <span class="string">'http://m10.music.126.net/20200115175106/6b976e394b71ccde0f2dae06b6c48e75/ymusic/12ca/05c1/e5b7/c58c9f85a602e16983271f86f565f2e4.mp3'</span>,</span><br><span class="line">        cover: <span class="string">'http://p1.music.126.net/PJNV84mjt_mDXEkxtjzB4w==/18957779486268444.jpg?param=130y130'</span>,</span><br><span class="line">      &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">'麻雀'</span>,</span><br><span class="line">        artist: <span class="string">'李荣浩'</span>,</span><br><span class="line">        url: <span class="string">'http://m10.music.126.net/20200115175331/17567a992819334ab2fa2cd84ca03270/ymusic/555b/0f58/0609/b1e0b087cb826dde13b21cbaa504f963.mp3'</span>,</span><br><span class="line">        cover: <span class="string">'http://p2.music.126.net/TzlSVBiNtpRD2b7MT2Hi-w==/109951164527590793.jpg?param=130y130'</span>,</span><br><span class="line">      &#125;  </span><br><span class="line">    ]</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p><img src="/articles/4929566e/3.png" alt></p><h4 id="播放器引入"><a href="#播放器引入" class="headerlink" title="播放器引入"></a>播放器引入</h4><p>播放器和列表准备好后，需要在网站中引入后，才可以正常使用。</p><p>在\themes\next\layout_layout.swig文件中，<body>标签里新增如下代码：</body></p><p><img src="/articles/4929566e/4.png" alt></p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">  &lt;!-- 加入APlayer音乐播放器 --&gt;</span><br><span class="line">&lt;link rel=<span class="string">"stylesheet"</span> href=<span class="string">"/dist/APlayer.min.css"</span>&gt;</span><br><span class="line">&lt;div id=<span class="string">"aplayer"</span>&gt;<span class="xml"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line">&lt;script type=<span class="string">"text/javascript"</span> src=<span class="string">"/dist/APlayer.min.js"</span>&gt;<span class="xml"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line">&lt;script type=<span class="string">"text/javascript"</span> src=<span class="string">"/dist/music.js"</span>&gt;<span class="xml"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br></pre></td></tr></table></figure><p><img src="/articles/4929566e/5.png" alt></p><h4 id="部署网站"><a href="#部署网站" class="headerlink" title="部署网站"></a>部署网站</h4><p>播放器加入完成，网站需重新部署</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo cl &amp;&amp; hexo g &amp;&amp; gulp &amp;&amp; hexo d</span><br></pre></td></tr></table></figure><h2 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h2><p>是直接嵌入外链播放器即可，以网易云为例。具体步骤如下：</p><h4 id="生成外链播放器代码"><a href="#生成外链播放器代码" class="headerlink" title="生成外链播放器代码"></a>生成外链播放器代码</h4><p><img src="/articles/4929566e/6.png" alt></p><p><img src="/articles/4929566e/7.png" alt></p><h4 id="嵌入网站"><a href="#嵌入网站" class="headerlink" title="嵌入网站"></a>嵌入网站</h4><p>在themes\next\layout_macro\sidebar.swig文件中找到合适位置，把上面生成的外链播放器代码加入即可。</p><p><img src="/articles/4929566e/8.png" alt></p><h4 id="部署网站-1"><a href="#部署网站-1" class="headerlink" title="部署网站"></a>部署网站</h4><p>播放器加入完成，网站需重新部署</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo cl &amp;&amp; hexo g &amp;&amp; gulp &amp;&amp; hexo d</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>方法一比较自由和可定制化，可以根据自己喜好做各种配置。</p><p>方法二配置比较简单，但现在国内版权意识越来越强，很可能点击生成外链代码时，因为版权原因，生成不了。</p><p><img src="/articles/4929566e/9.png" alt></p><p>所以可以根据自己喜好选择用那种方法。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;hexo搭建完静态博客后，有同学只看技术文档比较枯燥，会犯困。那么如果有音乐播放的功能，就可以一遍阅读文章，一边欣赏音乐了，岂不是一件很愉快的事。那么下面就以本站点为例，分享怎么在自己的hexo网站增加音乐播放功能。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Hexo" scheme="https://wandouduoduo.netlify.com/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>Centos7安装Nginx整合Lua</title>
    <link href="https://wandouduoduo.netlify.com/articles/c745ae1a.html"/>
    <id>https://wandouduoduo.netlify.com/articles/c745ae1a.html</id>
    <published>2020-01-10T06:26:36.000Z</published>
    <updated>2020-01-10T08:02:38.128Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Lua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。现在通常把lua迁入nginx中，根据lua脚本规则，强化nginx的能力。本文介绍在centos7中安装nginx整合lua。</p><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p><strong>centos7</strong></p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h4 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld.service <span class="comment">#停止firewall</span></span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld.service <span class="comment">#禁止firewall开机启动</span></span><br></pre></td></tr></table></figure><h4 id="安装依赖环境"><a href="#安装依赖环境" class="headerlink" title="安装依赖环境"></a>安装依赖环境</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install yum-utils gcc zlib zlib-devel pcre-devel openssl openssl-devel wget</span><br></pre></td></tr></table></figure><h4 id="安装LuaJIT"><a href="#安装LuaJIT" class="headerlink" title="安装LuaJIT"></a>安装LuaJIT</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget http://luajit.org/download/LuaJIT-2.0.2.tar.gz</span><br><span class="line">tar -xvf LuaJIT-2.0.2.tar.gz</span><br><span class="line"><span class="built_in">cd</span> LuaJIT-2.0.2</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><h4 id="安装nginx"><a href="#安装nginx" class="headerlink" title="安装nginx"></a>安装nginx</h4><p><strong>下载ngx_devel_kit、lua-nginx-module、nginx</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/simpl/ngx_devel_kit/archive/v0.3.0.tar.gz</span><br><span class="line">wget https://github.com/openresty/lua-nginx-module/archive/v0.10.9rc7.tar.gz</span><br><span class="line">wget http://nginx.org/download/nginx-1.12.1.tar.gz </span><br><span class="line"><span class="comment">#注意下载后的压缩包没有文件名称，但是根据版本号能区分是哪个文件</span></span><br><span class="line">tar -xvf v0.3.0.tar.gz</span><br><span class="line">tar -xvf v0.10.9rc7.tar.gz</span><br><span class="line">tar -xvf nginx-1.12.1.tar.gz</span><br></pre></td></tr></table></figure><h4 id="编译Nginx"><a href="#编译Nginx" class="headerlink" title="编译Nginx"></a>编译Nginx</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> nginx-1.12.1</span><br><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/nginx --add-module=../ngx_devel_kit-0.3.0 --add-module=../lua-nginx-module-0.10.9rc7  --with-http_ssl_module  --with-http_stub_status_module  --with-http_gzip_static_module</span><br></pre></td></tr></table></figure><h4 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h4 id="启动nginx"><a href="#启动nginx" class="headerlink" title="启动nginx"></a>启动nginx</h4><p>启动时会nginx可能会报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./nginx: error while loading shared libraries: libluajit-5.1.so.2: cannot open shared object file:</span><br></pre></td></tr></table></figure><p>原因是：找不到libluajit-5.1.so.2这个文件</p><p><strong>解决办法</strong></p><p>找到 libluajit-5.1.so.2,libluajit-5.1.so.2.0.2这两个文件复制到 对应的lib下<br>64位是 /usr/lib64<br>32位是 /usr/lib</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find / -name libluajit-5.1.so.2</span><br></pre></td></tr></table></figure><p><img src="/articles/c745ae1a/1.png" alt></p><p>文件默认是安装在 /usr/local/lib/libluajit-5.1.so.2下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp /usr/<span class="built_in">local</span>/lib/libluajit-5.1.so.2 /usr/lib64/</span><br><span class="line">cp /usr/<span class="built_in">local</span>/lib/libluajit-5.1.so.2.0.2 /usr/lib64</span><br></pre></td></tr></table></figure><p><strong>然后启动</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/nginx/sbin/nginx</span><br></pre></td></tr></table></figure><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>在nginx安装目录下，修改nginx.conf文件</p><p>在Server代码块下添加如下代码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">location /hello&#123;</span><br><span class="line">        default_type <span class="string">'text/plain'</span>;</span><br><span class="line">        content_by_lua <span class="string">'ngx.say("hello,lua")'</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/articles/c745ae1a/2.png" alt></p><p><strong>配置生效</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/nginx/sbin/nginx -t</span><br><span class="line">/usr/<span class="built_in">local</span>/nginx/sbin/nginx -s reload</span><br></pre></td></tr></table></figure><p><strong>浏览器访问</strong> </p><p>访问地址： <a href="http://xxx.xxx.xxx/hello" target="_blank" rel="noopener">http://xxx.xxx.xxx/hello</a></p><p><img src="/articles/c745ae1a/3.png" alt></p><p>到此就成功了。</p><h2 id="添加服务"><a href="#添加服务" class="headerlink" title="添加服务"></a>添加服务</h2><p>这时nginx只能用绝对路径启动，测试和重载，非常不方便。那需要把nginx添加到linux的服务管理中。</p><p><strong>编写nginx.service文件</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=nginx</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=forking</span><br><span class="line">ExecStart=/usr/local/nginx/sbin/nginx</span><br><span class="line">ExecReload=/usr/local/nginx/sbin/nginx -s reload</span><br><span class="line">ExecStop=/usr/local/nginx/sbin/nginx -s quit</span><br><span class="line">PrivateTmp=true</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p><strong>添加</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp ./nginx.service /lib/systemd/system/</span><br></pre></td></tr></table></figure><p><strong>重新加载</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br></pre></td></tr></table></figure><p><strong>验证</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl start nginx.service</span><br><span class="line">systemctl status nginx.service</span><br><span class="line">systemctl <span class="built_in">enable</span> nginx.service</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;Lua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。现在通常把lua迁入nginx中，根据lua脚本规则，强化nginx的能力。本文介绍在centos7中安装nginx整合lua。&lt;/p&gt;
    
    </summary>
    
      <category term="Web服务" scheme="https://wandouduoduo.netlify.com/categories/Web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Nginx" scheme="https://wandouduoduo.netlify.com/categories/Web%E6%9C%8D%E5%8A%A1/Nginx/"/>
    
    
      <category term="Nginx" scheme="https://wandouduoduo.netlify.com/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>使用ELRepo第三方源为CentOS 6/7/8升级最新内核版本</title>
    <link href="https://wandouduoduo.netlify.com/articles/a6119320.html"/>
    <id>https://wandouduoduo.netlify.com/articles/a6119320.html</id>
    <published>2019-12-27T14:57:47.000Z</published>
    <updated>2019-12-29T08:36:34.865Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Linux实质上上特指内核的，不过我们现在通常所说的是Linux是各个公司在内核的基础上进行优化和封装了很多组件，并加入了软件包管理工具等发行版，如：ubuntu，redhat,  centos等等。linux内核一直有在维护并随着技术和硬件的不断更新也加入了很多功能，所以如果要研究新的技术，用到新内核的功能，可能旧的内核不能满足需求。这时候就需要升级内核，但升级内核属于高危操作，早期还会总是出问题，后来如CentOS或RHEL类的Linux发行版需要升级Linux内核的话可以使用<a href="http://elrepo.org/" target="_blank" rel="noopener">ELRepo</a>第三方源来很方便进行升级。但是也可能受限于系统本身的低版本会造成升级失败，所以就详细描述了内核的升级过程。</p><p><img src="/articles/a6119320/1.jpg" alt></p><a id="more"></a><h1 id="ELRepo源"><a href="#ELRepo源" class="headerlink" title="ELRepo源"></a>ELRepo源</h1><p><a href="https://www.elrepo.org/" target="_blank" rel="noopener">ELRepo</a> 仓库，该软件源包含文件系统驱动以及网络摄像头驱动程序等等（支持显卡、网卡、声音设备甚至<a href="https://linux.cn/article-8310-1.html" target="_blank" rel="noopener">新内核</a>），虽然 ELRepo 是第三方仓库，但它有一个活跃社区和良好技术支持，并且CentOS官网wiki也已将它列为是可靠的（<a href="https://wiki.centos.org/AdditionalResources/Repositories" target="_blank" rel="noopener">参见此处</a>）。所以可以放心使用。</p><p><strong>内核版本简写说明</strong></p><p><strong>kernel-lt</strong>（lt=long-term）长期有效</p><p><strong>kernel-ml</strong>（ml=mainline）主流版本</p><h1 id="查看当前内核版本"><a href="#查看当前内核版本" class="headerlink" title="查看当前内核版本"></a>查看当前内核版本</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uname -r</span><br></pre></td></tr></table></figure><p>目前Linux内核发布的最新稳定版可以从 <a href="https://www.kernel.org" target="_blank" rel="noopener">https://www.kernel.org</a> 进行查看。</p><p><img src="/articles/a6119320/1.png" alt></p><h1 id="升级内核"><a href="#升级内核" class="headerlink" title="升级内核"></a>升级内核</h1><h2 id="先更新nss"><a href="#先更新nss" class="headerlink" title="先更新nss"></a>先更新nss</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum update nss</span><br></pre></td></tr></table></figure><h2 id="自动从源中安装"><a href="#自动从源中安装" class="headerlink" title="自动从源中安装"></a>自动从源中安装</h2><h4 id="首先安装ELRepo源"><a href="#首先安装ELRepo源" class="headerlink" title="首先安装ELRepo源"></a>首先安装ELRepo源</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#centos6</span></span><br><span class="line">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span><br><span class="line">rpm -Uvh https://www.elrepo.org/elrepo-release-6-9.el6.elrepo.noarch.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment">#centos7</span></span><br><span class="line">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span><br><span class="line">rpm -Uvh https://www.elrepo.org/elrepo-release-7.0-4.el7.elrepo.noarch.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment">#centos8</span></span><br><span class="line">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span><br><span class="line">rpm -Uvh https://www.elrepo.org/elrepo-release-8.0-2.el8.elrepo.noarch.rpm</span><br></pre></td></tr></table></figure><h4 id="启用ELRepo源仓库"><a href="#启用ELRepo源仓库" class="headerlink" title="启用ELRepo源仓库"></a><strong>启用ELRepo源仓库</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum --disablerepo=<span class="string">"\*"</span> --enablerepo=<span class="string">"elrepo-kernel"</span> list available</span><br></pre></td></tr></table></figure><h4 id="安装新内核"><a href="#安装新内核" class="headerlink" title="安装新内核"></a><strong>安装新内核</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y --enablerepo=elrepo-kernel install kernel<span class="_">-lt</span> kernel<span class="_">-lt</span>-devel  kernel<span class="_">-lt</span>-doc  kernel<span class="_">-lt</span>-headers</span><br></pre></td></tr></table></figure><p>如果顺利不报错的话新内核就说明已经安装完成。</p><h2 id="手动下载安装"><a href="#手动下载安装" class="headerlink" title="手动下载安装"></a>手动下载安装</h2><h4 id="内核报错"><a href="#内核报错" class="headerlink" title="内核报错"></a>内核报错</h4><p>如安装内核有报错：No package kernel-lt available. 如下图</p><p><img src="/articles/a6119320/3.png" alt></p><p>新内核下载地址：<a href="https://elrepo.org/linux/kernel/el7/x86_64/RPMS/" target="_blank" rel="noopener">https://elrepo.org/linux/kernel/el7/x86_64/RPMS/</a></p><h4 id="下载安装内核"><a href="#下载安装内核" class="headerlink" title="下载安装内核"></a>下载安装内核</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://elrepo.org/linux/kernel/el6/x86_64/RPMS/kernel<span class="_">-lt</span>-4.4.207-1.el6.elrepo.x86_64.rpm</span><br><span class="line">rpm -ivh kernel<span class="_">-lt</span>-4.4.207-1.el6.elrepo.x86_64.rpm</span><br></pre></td></tr></table></figure><h4 id="更新kernel-lt-headers"><a href="#更新kernel-lt-headers" class="headerlink" title="更新kernel-lt-headers"></a>更新kernel-lt-headers</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://elrepo.org/linux/kernel/el6/x86_64/RPMS/kernel-lt-headers-4.4.207-1.el6.elrepo.x86_64.rpm</span><br><span class="line">rpm -ivh kernel-lt-headers-4.4.207-1.el6.elrepo.x86_64.rpm</span><br></pre></td></tr></table></figure><p> 安装kernel-lt-headers时有冲突报错</p><p><img src="/articles/a6119320/4.png" alt></p><p><strong>排除报错</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#移除</span></span><br><span class="line">yum remove kernel-headers</span><br><span class="line"><span class="comment">#再重新安装</span></span><br><span class="line">rpm -ivh kernel<span class="_">-lt</span>-headers-4.4.207-1.el6.elrepo.x86_64.rpm</span><br></pre></td></tr></table></figure><h4 id="更新kernel-lt-devel"><a href="#更新kernel-lt-devel" class="headerlink" title="更新kernel-lt-devel"></a>更新kernel-lt-devel</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://elrepo.org/linux/kernel/el6/x86_64/RPMS/kernel-lt-devel-4.4.207-1.el6.elrepo.x86_64.rpm</span><br><span class="line">rpm -ivh kernel-lt-devel-4.4.207-1.el6.elrepo.x86_64.rpm</span><br></pre></td></tr></table></figure><h4 id="更新kernel-lt-doc"><a href="#更新kernel-lt-doc" class="headerlink" title="更新kernel-lt-doc"></a>更新kernel-lt-doc</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://elrepo.org/linux/kernel/el6/x86_64/RPMS/kernel-lt-doc-4.4.207-1.el6.elrepo.noarch.rpm</span><br><span class="line">rpm -ivh kernel-lt-doc-4.4.207-1.el6.elrepo.noarch.rpm</span><br></pre></td></tr></table></figure><h1 id="修改grub配置"><a href="#修改grub配置" class="headerlink" title="修改grub配置"></a>修改grub配置</h1><p>这里因为系统差异原因，对centos7以上版本和centos6版本差异处理。</p><h4 id="centos7以上"><a href="#centos7以上" class="headerlink" title="centos7以上"></a>centos7以上</h4><h6 id="查看当前grub中内核版本列表"><a href="#查看当前grub中内核版本列表" class="headerlink" title="查看当前grub中内核版本列表"></a>查看当前grub中内核版本列表</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#centos7以上版本</span></span><br><span class="line">awk -F\<span class="string">' '</span><span class="variable">$1</span>==<span class="string">"menuentry "</span> &#123;<span class="built_in">print</span> i++ <span class="string">" : "</span> <span class="variable">$2</span>&#125;<span class="string">' /etc/grub2.cfg</span></span><br></pre></td></tr></table></figure><p>Centos7及以上版本会返回信息,可能如下：</p><p><img src="/articles/a6119320/5.png" alt></p><p>信息列表中：<strong>0</strong> 即为安装的新内核</p><h6 id="修改设置并生成新的grub配置文件"><a href="#修改设置并生成新的grub配置文件" class="headerlink" title="修改设置并生成新的grub配置文件"></a>修改设置并生成新的grub配置文件</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grub2-set-default 0</span><br><span class="line">grub2-mkconfig -o /boot/grub2/grub.cfg</span><br></pre></td></tr></table></figure><h4 id="Centos6"><a href="#Centos6" class="headerlink" title="Centos6"></a>Centos6</h4><h6 id="查看安装的内核版本"><a href="#查看安装的内核版本" class="headerlink" title="查看安装的内核版本"></a>查看安装的内核版本</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa | grep -i kernel</span><br></pre></td></tr></table></figure><p><img src="/articles/a6119320/6.png" alt></p><h6 id="编辑配置"><a href="#编辑配置" class="headerlink" title="编辑配置"></a>编辑配置</h6><p>更改/etc/grub.conf文件中default的值,设定为<strong>0</strong>如下图：</p><p><img src="/articles/a6119320/2.png" alt></p><h1 id="重新启动"><a href="#重新启动" class="headerlink" title="重新启动"></a>重新启动</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure><h1 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h1><p>查看内核版本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uname -r</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;Linux实质上上特指内核的，不过我们现在通常所说的是Linux是各个公司在内核的基础上进行优化和封装了很多组件，并加入了软件包管理工具等发行版，如：ubuntu，redhat,  centos等等。linux内核一直有在维护并随着技术和硬件的不断更新也加入了很多功能，所以如果要研究新的技术，用到新内核的功能，可能旧的内核不能满足需求。这时候就需要升级内核，但升级内核属于高危操作，早期还会总是出问题，后来如CentOS或RHEL类的Linux发行版需要升级Linux内核的话可以使用&lt;a href=&quot;http://elrepo.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ELRepo&lt;/a&gt;第三方源来很方便进行升级。但是也可能受限于系统本身的低版本会造成升级失败，所以就详细描述了内核的升级过程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/a6119320/1.jpg&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Linux" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/Linux/"/>
    
    
      <category term="Linux" scheme="https://wandouduoduo.netlify.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>运维职责和分类划分</title>
    <link href="https://wandouduoduo.netlify.com/articles/6aa3e89a.html"/>
    <id>https://wandouduoduo.netlify.com/articles/6aa3e89a.html</id>
    <published>2019-12-27T14:38:46.000Z</published>
    <updated>2019-12-29T08:37:39.091Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>有同学看到标题就会说5年以上的技术大咖都傻傻分不清楚，那能成的上大咖？这还真是的，有朋友在BAT等互联网大厂里工作多年，是做技术开发的，在业务上技术很牛的，但是有次聊天时问到这个问题，傻傻分不清楚运维具体是干什么的？有哪些分类？这很正常，孔子曰：术业有专攻，如是而已。还有一些新人小白想要进入这个行业，但是很懵懂，在刚刚接触，心里就打退堂鼓了，害怕自己学不会搞不定弄不懂。那这里就为大家揭开这一职业的朦胧面纱。</p><p><img src="/articles/6aa3e89a/1.jpg" alt></p><a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>何为运维？运维，从字面意思很好理解，运行维护。有可能你认为的运维是高大上，坐在高档写字楼里，敲敲电脑动动手指的，可能是风吹日晒走街串巷等等。</p><p><img src="/articles/6aa3e89a/3.jpg" alt></p><p><img src="/articles/6aa3e89a/2.jpg" alt></p><p>是的，这些都是运维，但是行业，分工以及内容都不同。总体来说大致可以分为两类：线上运维和线下运维。而互联网运维就属于线上运维，共享单车运维就是线下运维。这里我们聊得就是互联网运维。</p><h2 id="运维前景"><a href="#运维前景" class="headerlink" title="运维前景"></a>运维前景</h2><p>要说运维的前景还是很广阔的。可以这么说只要有互联网就会需要运维，试问下，现在的生活还能没有互联网吗？所以，就业前景还是可以的。就企业而言，运维属于技术职务，所以走的是P路线。什么是P路线呢？是互联网就个人职业规划的上升和晋级通道，P路线就是技术路线，M路线就是管理路线。分不同等级，逐级或跨级晋升，当然不能等级体现了你的能力高低。我们常常自嘲为“打杂的”，因为运维是技术支持部门，是为开发出产品后上线提供支持的，所以很多东西都需要懂。所以如果想要从事这个行业先有个心理准备。技术方面有两个维度：深度和广度。就运维而言，广度是第一要求，你不需要精，但是一定要知道。深度在根据自己的规划方向再深入研究。就广度来说，从网络，服务器，系统，环境，应用，监控，虚拟化，容器化，自动化，智能化等等，需要学的太多了。还有，有人说：“运维是吃青春饭的”，对也不对，对的是做技术的，年龄大了操作和思维等肯定不如年轻人，不对的是：看能力，能力比较牛，不可替代，无论年龄多大都有市场。就单纯的说运维晋升：初级，中级，高级，资深，架构师，CTO。少年，你做好准备了吗？</p><h2 id="运维分类"><a href="#运维分类" class="headerlink" title="运维分类"></a>运维分类</h2><p>有很多程序员都是宅男，单身，过年过节回家，亲戚朋友问到从事的职业被戏称为修电脑的。但是只要是从事技术的，哪怕是刚入行的小白，也能够了解清楚分类，工具等。一般程序员根据开发语言划分的，像：php，java, C++，Go等等，根据业务划分可分为：前端和后端。这些基本就可以涵盖所有了。而运维的分类是怎样的呢？问什么会让很多人傻傻分不清和懵懂呢？各自有哪些职责呢？按职责划分运维的分类大致可以分为应用运维，系统运维，运维研发，数据库运维和运维安全。如下图所示：</p><p><img src="/articles/6aa3e89a/sun.jpg" alt></p><p>那下面我们就逐个介绍下。</p><h2 id="应用运维"><a href="#应用运维" class="headerlink" title="应用运维"></a><strong>应用运维</strong></h2><p>应用运维也是大部分人所认知的运维，应用运维根据字面意思就可以知道是和应用维护的。主要负责线上服务的发布变更、服务健康状况监控、服务的容灾高可用和数据安全备份等工作。针对这些工作需要对服务进行巡检了解服务状况，服务出故障的应急处理和排查优化。下面详细的职责如下所述。</p><p><img src="/articles/6aa3e89a/timg.jpg" alt></p><p><strong>评审</strong></p><p>在产品研发阶段，参与产品设计评审，从运维的角度提出评审意见，使服务满足准入要求，尽快上线并预备高可用等方案。</p><p><strong>服务</strong></p><p>服务管理主要就是发布系统，制定线上业务的升级变更及回滚方案，并根据申请进行变更的实施。掌握所负责的服务及服务间的依赖关联关系中的各种资源。能够发现服务上的缺陷，及时通报并推进解决。制定服务的稳定性指标及准入标准方案，同时不断完善和优化程序和系统的功能、效率，提高运行质量，完善监控内容，提高报警准确度。在线上服务出现故障时，第一时间响应，对已知的故障能按流程进行通报并按预案执行，未知故障组织相关人员进行联合排障。</p><p><strong>资源</strong></p><p>对各个服务使用的服务器资产进行管理，梳理服务器资源实时状况、IDC数据中心分布情况、网络专线及带宽情况，能够合理使用服务器资源，根据不同服务的需求，分配不同配置的服务器，确保服务器资源的充分利用。</p><p><strong>巡检</strong></p><p>实时了解服务的运行状况，制定服务的例行排查点，并不断完善。并根据制定的服务排查点，对服务进行定期检查。对排查过程中发现的问题，及时进行追查处理，排除可能存在的隐患和痛点</p><p><strong>监控</strong></p><p>确定服务存活状态正常，对服务的各项性能、系统的指标阈值或临界点安排合理，以及对出现该异常后的处理制定预案。建立和更新和维护服务预案文档，并根据日常故障情况不断补充完善，提高预案完备性。周期性进行预案演练，确保预案的可行性。</p><p><strong>备份</strong></p><p>制定业务数据的备份方案，按策略对数据进行备份和冗余工作。保证数据备份的可用性，完整性和安全性，定期开展数据恢复性测试。</p><h2 id="系统运维"><a href="#系统运维" class="headerlink" title="系统运维"></a><strong>系统运维</strong></h2><p>系统运维主要和系统及底层网络等打交道，如：IDC机房、网络拓扑、CDN加速和基础服务的建设等；对所有服务器的资产进行管理，服务器的调研选型、交付上架和后期维护等。详细的工作职责如下：</p><p><img src="/articles/6aa3e89a/4.jpg" alt></p><p><strong>IDC机房</strong></p><p>根据业务申请需求，预估未来数据中心的发展规模，从骨干网络的分布，数据中心建筑可靠性，以及Internet的接入、网络中的攻击防御、扩容、空间预留、外接专线、现场支撑等方面。</p><p><strong>网络</strong></p><p>设计及规划生产网络架构，这里面包括：数据中心网络架构、传输网架构、CDN网络架构等，以及网络调优等日常运维工作。</p><p><strong>基础服务</strong></p><p>根据网络规模和业务需求，构建负载均衡集群，完成网络与业务服务器的衔接，提供高性能、高可用的负载调度能力，以及统一的网络层防御能力；通过集群化部署，保证公网访问服务的高性能与高可用。有些服务需要借助于第三方的，对第三方进行测试选型和调度控制，监控等等，保障系统稳定、高效运行。</p><p><strong>服务器</strong></p><p>服务器的测试和选型，包含服务器整机、部件的基础性测试和业务压力测试，降低整机功率，规划服务器上架位置，在保证温湿度的情况下，提升部署密度，降低成本；服务器硬件故障的诊断排查和定位，服务器温湿度转速等硬件监控等；</p><p><strong>操作系统</strong></p><p>所有平台的操作系统选型、定制和内核优化，以及漏洞补丁的更新和内部版本升级；建立统一的软件包管理和分发中心库，以及现在用的很多的maven依赖包仓库和Docker容器仓库；</p><p><strong>资产管理</strong></p><p>记录和管理所有基础物理信息，包括IDC数据中心、网络信息、机架机柜位置、服务器型号信息，售后信息等等各种资源信息，制定有效合理的流程，确保信息的准确性；</p><h2 id="运维开发"><a href="#运维开发" class="headerlink" title="运维开发"></a><strong>运维开发</strong></h2><p>运维平台设计,开发和实施部署，如：用户管理，资产管理、监控系统、发布平台、权限管理系统等等。提供各种接口，封装更高层的自动化运维系统。详细的工作职责如下所述。</p><p><img src="/articles/6aa3e89a/5.jpg" alt></p><p><strong>发布平台</strong></p><p>记录关联关系，协助运维人员对日常运维标准化，流程化进而自动化，包括服务器的管理如：重启、改名、初始化、域名管理、流量切换和故障预案实施等。</p><p><strong>监控系统</strong></p><p>监控系统的调研选型，对服务器和各种网络设备的资源性能指标、业务性能指标的收集、告警、存储、分析、展示和数据分析等工作，保证公司服务器资源的合理化调配，持续提高告警的及时性、准确性和有效性，对监控进行聚合，进而实现智能化报警监控。</p><p><strong>自动化平台</strong></p><p>自动化系统的开发，自动化部署系统所需要的各种数据和信息。结合云计算，区块链等技术，研发和提供PaaS相关高可用平台，提高服务的部署有效性和稳定性，提高资源利用率。</p><h2 id="数据库运维"><a href="#数据库运维" class="headerlink" title="数据库运维"></a><strong>数据库运维</strong></h2><p>数据库运维需要对库、表、索引和SQL等制定规范，对数据库进行变更、监控、备份、高可用设计等工作。详细的工作职责如下所述。</p><p><img src="/articles/6aa3e89a/6.jpg" alt></p><p><strong>评审</strong></p><p>在产品研发阶段，参与设计方案评审，从DBA的角度提出数据存储、库表设计，索引设计等方案、SQL开发标准，使服务满足数据库的高可用、高性能要求。</p><p><strong>容量</strong></p><p>掌握所负责服务数据库的容量上限，清楚地了解瓶颈点，当服务将触及容量阈值时，及时优化、分拆或者扩容等</p><p><strong>备份与灾备</strong></p><p>制定数据备份与灾备策略方案，定期对数据进行恢复性测试，保证数据备份的有效性，可用性和完整性。</p><p><strong>监控</strong></p><p>对数据库存活和各项性能指标监控，及时了解数据库的运行状态。</p><p><strong>安全</strong></p><p>建立数据库账号和权限控制体系，有效降低误操作和数据泄露的风险；加强离线备份数据的管理，降低数据泄露的风险。</p><p><strong>性能优化</strong></p><p>对数据库风险点有备用或切换方案，降低故障对数据库的影响；对数据库性能进行优化，包括存储方案改进、硬件资源优化、文件系统优化、库表优化、SQL优化等。</p><p><strong>自动化</strong></p><p>开发数据库自动化平台，包括数据库部署、自动扩容、分库分表、权限管理、备份恢复、SQL审核和上线、故障处理等。</p><h2 id="运维安全"><a href="#运维安全" class="headerlink" title="运维安全"></a><strong>运维安全</strong></h2><p>运维安全负责各方面的安全加固工作，进行安全扫描、渗透测试，进行安全工具和系统研发以及安全事件应急处理。详细的工作职责如下所述。</p><p><img src="/articles/6aa3e89a/7.jpg" alt></p><p><strong>安全文档</strong></p><p>根据公司内部的具体流程，制定切实可行且行之有效的安全方案和制度。</p><p><strong>安全培训</strong></p><p>定期向员工提供具有安全培训和考核，在公司内建立安全负责人制度。</p><p><strong>风险评估</strong></p><p>通过黑白盒测试和检查机制，对网络、服务器、业务、用户数据等方面的风险评估。</p><p><strong>安全</strong></p><p>根据风险评估报告，加固薄弱环节，包括设计安全防线、部署安全设备、更新补丁、防御病毒、源代码自动扫描和业务产品安全咨询等等。通过加密、匿名化、混淆数据，乃至定期删除等技术手段和流程来降低可能泄露数据的风险。</p><p><strong>安全合规</strong></p><p>为了满足合规性要求例如金融牌照，支付牌照等，安全团队承担着对外安全合规的接口人角色。</p><p><strong>应急响应</strong></p><p>建立安全报警系统，通过安全中心收集第三方发现的安全问题，评估影响面，组织各部门对已经发现的安全问题进行修复和事后造成安全的追查。</p><p>运维工作的目标和期望是：希望所有的工作都自动化起来，减少人的重复工作，降低知识传递的成本，使我们的业务能够更高效、更安全运行，使产品运行的更加稳定。Good  Luck!!!</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;有同学看到标题就会说5年以上的技术大咖都傻傻分不清楚，那能成的上大咖？这还真是的，有朋友在BAT等互联网大厂里工作多年，是做技术开发的，在业务上技术很牛的，但是有次聊天时问到这个问题，傻傻分不清楚运维具体是干什么的？有哪些分类？这很正常，孔子曰：术业有专攻，如是而已。还有一些新人小白想要进入这个行业，但是很懵懂，在刚刚接触，心里就打退堂鼓了，害怕自己学不会搞不定弄不懂。那这里就为大家揭开这一职业的朦胧面纱。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/6aa3e89a/1.jpg&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="心得体会" scheme="https://wandouduoduo.netlify.com/categories/%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/"/>
    
    
      <category term="Experiences" scheme="https://wandouduoduo.netlify.com/tags/Experiences/"/>
    
  </entry>
  
  <entry>
    <title>Hexo博客导流到微信公众号</title>
    <link href="https://wandouduoduo.netlify.com/articles/36a9dafd.html"/>
    <id>https://wandouduoduo.netlify.com/articles/36a9dafd.html</id>
    <published>2019-12-25T06:05:19.000Z</published>
    <updated>2019-12-26T03:34:41.212Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>随着互联网的高速发展，我们身边的一切都发生了翻天覆地的变化，互联网真真正正改变了我们的生活方式。足不出户买东西，点点手机叫外卖，一部手机走天下等等。古有文人墨客怀才不遇，积愤难平。但现在互联网放大了每个人的能力，知识变现，粉丝导流，人气带货等等已很常见。这时很多技术博主或站长，就想技术文档笔记积累的人气导流到微信公众号。本文就是讲解Hexo博客导流到微信公众号的流程。一句话概括：就是Hexo 整合 OpenWrite 平台的 readmore 插件,实现博客的每一篇文章自动增加阅读更多效果,关注公众号后方可解锁全站文章,从而实现博客流量导流到微信公众号粉丝目的。</p><p>有些同学，会有如下疑问：</p><ul><li>为什么要讲Hexo博客，而不是其他如简书，博客园等？</li><li>导流后效果是怎样的呢？</li><li>配置会不会很麻烦呢？</li><li>需要用到哪些工具呢？</li><li>具体流程是怎样的呢？</li></ul><p>针对这些问题，下面就一一解答。</p><a id="more"></a><h2 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h2><p>为什么要讲Hexo博客，而不是其他如简书，博客园等，或者自己建站呢？归根结底，还是因为Money问题。Hexo是github的静态pages博客，搭建好后不需要域名和服务器空间（这些虽然不贵，但是都是要钱的), 并且所有博客内的源码自己可控的。而且国内的云服务商都有静态pages功能，如码云和腾讯云等。重要的是需求就是：做个笔记，记录工作中遇到的技术，对自己做个总结，后面忘记时可以快速查询回忆起来。需求简单，源码可控等造成了hexo静态博客用处很广。</p><h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p><img src="/articles/36a9dafd/1.png" alt></p><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>hexo配置导流很简单的，主要用到工具就是<a href="https://openwrite.cn/" target="_blank" rel="noopener">OpenWrite</a>。</p><h4 id="注册"><a href="#注册" class="headerlink" title="注册"></a>注册</h4><p>web页面填写邮箱和密码注册openwrite。</p><p><img src="/articles/36a9dafd/2.png" alt></p><p><img src="/articles/36a9dafd/3.png" alt></p><h4 id="导流公众号设定"><a href="#导流公众号设定" class="headerlink" title="导流公众号设定"></a>导流公众号设定</h4><p>增长工具–&gt;添加–&gt;填写信息–&gt;保存</p><p><img src="/articles/36a9dafd/4.png" alt></p><p><img src="/articles/36a9dafd/5.png" alt></p><p>注意：保存好后，需要再次到增长工具–&gt;博客导流公众号–&gt;使用</p><p><img src="/articles/36a9dafd/6.png" alt></p><p>然后会展示使用指南</p><p><img src="/articles/36a9dafd/7.png" alt></p><h4 id="Hexo配置"><a href="#Hexo配置" class="headerlink" title="Hexo配置"></a>Hexo配置</h4><p>在hexo <code>_config.yml</code> 配置文件中,添加配置 <code>readmore</code> 插件相关信息</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># readmore</span></span><br><span class="line"><span class="attr">plugins:</span></span><br><span class="line"><span class="attr">  readmore:</span></span><br><span class="line"><span class="attr">    blogId:</span> <span class="number">19128</span><span class="bullet">-1577246103864</span><span class="bullet">-519</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">豌豆多多追梦记</span></span><br><span class="line"><span class="attr">    qrcode:</span> <span class="attr">https://wandouduoduo.github.io/about/index/gongzhonghao.jpg</span></span><br><span class="line"><span class="attr">    keyword:</span> <span class="string">vip</span></span><br></pre></td></tr></table></figure><p>其中,配置参数含义如下:</p><ul><li><code>blogId</code> : [必选]OpenWrite 后台申请的博客唯一标识,例如:119128-1577246103864-519</li><li><code>name</code> : [必选]OpenWrite 后台申请的博客名称,例如:豌豆多多追梦记</li><li><code>qrcode</code> : [必选]OpenWrite 后台申请的微信公众号二维码图片地址。</li><li><code>keyword</code> : [必选]OpenWrite 后台申请的微信公众号后台回复关键字,例如:vip</li></ul><p>注意: <strong>一定要替换成自己的在使用指南中显示的相关配置</strong>!</p><h4 id="Hexo安装组件"><a href="#Hexo安装组件" class="headerlink" title="Hexo安装组件"></a>Hexo安装组件</h4><p>开通readmore功能，原本需要手动更改主题的配置文件，但现在有牛人进行了封装。有兴趣可以看下</p><p><a href="https://github.com/snowdreams1006/hexo-plugin-readmore" target="_blank" rel="noopener">hexo-plugin-readmore</a>。所以我们现在只需要安装即可</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-plugin-readmore --save</span><br><span class="line">或</span><br><span class="line">cnpm install hexo-plugin-readmore --save</span><br></pre></td></tr></table></figure><h4 id="构建发布"><a href="#构建发布" class="headerlink" title="构建发布"></a>构建发布</h4><p>插件安装完成后，保存配置，构建发布即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g &amp;&amp; hexo d</span><br></pre></td></tr></table></figure><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>打开hexo博客，随便打开一篇文档，查看是否有效果。Good   Luck!!!</p><p><img src="/articles/36a9dafd/8.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;随着互联网的高速发展，我们身边的一切都发生了翻天覆地的变化，互联网真真正正改变了我们的生活方式。足不出户买东西，点点手机叫外卖，一部手机走天下等等。古有文人墨客怀才不遇，积愤难平。但现在互联网放大了每个人的能力，知识变现，粉丝导流，人气带货等等已很常见。这时很多技术博主或站长，就想技术文档笔记积累的人气导流到微信公众号。本文就是讲解Hexo博客导流到微信公众号的流程。一句话概括：就是Hexo 整合 OpenWrite 平台的 readmore 插件,实现博客的每一篇文章自动增加阅读更多效果,关注公众号后方可解锁全站文章,从而实现博客流量导流到微信公众号粉丝目的。&lt;/p&gt;
&lt;p&gt;有些同学，会有如下疑问：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;为什么要讲Hexo博客，而不是其他如简书，博客园等？&lt;/li&gt;
&lt;li&gt;导流后效果是怎样的呢？&lt;/li&gt;
&lt;li&gt;配置会不会很麻烦呢？&lt;/li&gt;
&lt;li&gt;需要用到哪些工具呢？&lt;/li&gt;
&lt;li&gt;具体流程是怎样的呢？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;针对这些问题，下面就一一解答。&lt;/p&gt;
    
    </summary>
    
      <category term="心得体会" scheme="https://wandouduoduo.netlify.com/categories/%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/"/>
    
      <category term="使用技巧" scheme="https://wandouduoduo.netlify.com/categories/%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Hexo" scheme="https://wandouduoduo.netlify.com/categories/%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/Hexo/"/>
    
    
      <category term="Hexo" scheme="https://wandouduoduo.netlify.com/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch分片副本机制</title>
    <link href="https://wandouduoduo.netlify.com/articles/688d9226.html"/>
    <id>https://wandouduoduo.netlify.com/articles/688d9226.html</id>
    <published>2019-12-23T06:46:15.000Z</published>
    <updated>2019-12-26T03:34:41.207Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>日常运维工作中，保证系统服务的稳定是第一优先级的。做好高可用方案是关键。在用Elasticsearch作为存储的服务中，保证Elasticsearch数据的高可用，数据的安全性和一致性至关重要。本文就针对这一问题详细介绍了Elasticsearch的分片和副本机制。</p><a id="more"></a><h2 id="分片和副本机制"><a href="#分片和副本机制" class="headerlink" title="分片和副本机制"></a>分片和副本机制</h2><ol><li><p>index(索引) 包含多个 shard(分片)，创建 index 时可以在settings中设置分片数，不设置时默认是5个。</p></li><li><p>每个 shard 都是一个最小工作单元，承载部分数据；每个 shard 都是一个 lucene 实例，并且具有完整的建立索引和处理能力。</p></li><li><p>增减节点时，shard 会自动在 nodes 中负载均衡。</p></li><li><p>primary shard（主分片） 和 replica shard（副本分片），每个 document 肯定只存在于某一个 primary shard 以及对应的 replica shard 中，不可能存在于多个 primary shard 。</p><p><img src="/articles/688d9226/1.png" alt></p></li><li><p>replica shard 是 primary shard 的副本，负责容错，以及承担读请求负载。</p></li><li><p>primary shard 的数量在创建索引的时候就固定了，不可更改；replica shard 的数量可以随时修改。</p></li><li><p>primary shard 的默认数量是5，replica 默认是1，默认有10个 shard，5个 primary shard ，5个 replica shard 。</p></li><li><p>primary shard 不能和自己的 replica shard 放在同一个节点上，否则节点宕机，primary shard 和副本都丢失，容错机制将失效；但是可以和其他 primary shard 的 replica shard 放在同一个节点上。</p><p><img src="/articles/688d9226/2.png" alt></p></li></ol><h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><p>Shards分片个数:  3</p><p>Replica副本个数：3</p><h4 id="单节点环境下"><a href="#单节点环境下" class="headerlink" title="单节点环境下"></a>单节点环境下</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">PUT /myindex</span><br><span class="line">&#123;</span><br><span class="line">    &quot;settings&quot;: &#123;</span><br><span class="line">        &quot;number_of_shards&quot;: 3,</span><br><span class="line">        &quot;number_of_replica&quot;: 1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"># 查看集群健康状态 --- 将返回yellow，说明集群状态不健康</span><br><span class="line">GET _cat/health</span><br></pre></td></tr></table></figure><p>此时，因为是单节点环境，3个 primary shard 只能分配到这个仅有的 node 上，另外3个 replica shard 是无法分配的（一个 shard 的副本 replica，两个是不能在同一个节点），集群可以正常工作；但出现宕机，数据全部丢失，而且集群不可用，无法接受任何请求。</p><h4 id="两个节点环境下"><a href="#两个节点环境下" class="headerlink" title="两个节点环境下"></a>两个节点环境下</h4><p>将3个 primary shard 分配到一个 node 上，另外3个 replica shard 分配到另一个节点上；<br>primary shard 和 replica shard 保持同步；<br>primary shard 和 replica shard 都可以处理客户端的读请求。</p><p><img src="/articles/688d9226/3.png" alt></p><h4 id="三个节点环境下"><a href="#三个节点环境下" class="headerlink" title="三个节点环境下"></a>三个节点环境下</h4><p>将3个 primary shard 分别分配到一个 node 上，另外3个 replica shard 也交叉分配到另一个节点上；</p><p><img src="/articles/688d9226/1.png" alt></p><p>这样3个节点都可以负载均衡增大访问量，同时如果一台服务器宕机后，数据也不会丢失，还可以对外正常提供服务。保证了服务的高可用和数据的安全。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>建议:  primary shard的个数和集群节点数一致，replica shard 数可以根据业务需求量决定，需求量大可以设定多个replica shard，来增加读取操作。但是至少每个primary shard设置1个replica shard，来保证高可用和数据的安全性。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;日常运维工作中，保证系统服务的稳定是第一优先级的。做好高可用方案是关键。在用Elasticsearch作为存储的服务中，保证Elasticsearch数据的高可用，数据的安全性和一致性至关重要。本文就针对这一问题详细介绍了Elasticsearch的分片和副本机制。&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.netlify.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://wandouduoduo.netlify.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="https://wandouduoduo.netlify.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Nginx之正反代理详解</title>
    <link href="https://wandouduoduo.netlify.com/articles/c5ecc6c0.html"/>
    <id>https://wandouduoduo.netlify.com/articles/c5ecc6c0.html</id>
    <published>2019-12-19T11:14:45.000Z</published>
    <updated>2019-12-26T03:34:41.226Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在日常运维工作中，常常会用到反向代理，为了更安全同时为了负载均衡，分担压力。</p><p>那么，有小伙伴就会有疑问：</p><ul><li>什么是反向代理？</li><li>负载均衡又是怎么实现的？</li><li>有反向代理那有正向代理吗？</li><li>正向代理的应用场景是怎样的？</li><li>反向代理和正向代理怎么配置实现呢？</li></ul><p>带着这些疑问，就给大家详细解释下nginx的正反向代理。</p><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>Nginx（Nginx是一款自由的、开源的、高性能的HTTP服务器。功能优势等等这里就不再赘述了。度娘那里有很多信息。）</p><h2 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h2><p>说到代理，首先我们要明确一个概念，所谓代理就是一个代表、一个渠道；</p><p>此时就设计到两个角色，一个是被代理角色，一个是目标角色，被代理角色通过这个代理访问目标角色完成一些任务的过程称为代理操作过程；如同生活中的专卖店~客人到adidas专卖店买了一双鞋，这个专卖店就是代理，被代理角色就是adidas厂家，目标角色就是用户。</p><h2 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h2><p>我们在运维的日常工作中经常用到负载均衡，所以接触反向代理比较多，那么反向代理是怎样的呢？。例如人气比较高的网站，如淘宝，京东等等。每天访问人数的人很多，数以万计，此时单台服务器远远不能承载所有人的访问请求，这时作为资深运维人员就需要对web服务进行分布式部署；何为分布式部署呢？就是通过部署多台服务器组成web集群共同来处理访问请求，解决单台服务器不能承载的问题；分布式部署的web服务可以横行扩展。而实现web分布式部署通常要用到反向代理。apache或nginx都可以。本文以nginx为例，用nginx的反向代理实现的。国内公司通过把nginx和其他的组件进行封装，根据场景或侧重点不同，便于构建安装，就有了：Tengine或OpenResty等。有兴趣的朋友可以度娘搜索学习。那么反向代理具体是通过什么样的方式实现的分布式的集群操作呢，我们先看一个示意图：</p><p><img src="/articles/c5ecc6c0/2.png" alt></p><p>通过上述的图解大家就可以看清楚了，多个客户端给服务器发送的请求，nginx服务器接收到之后，按照一定的规则分发给了后端的web服务器进行处理了。此时请求的来源也就是客户端是明确的，但是请求后具体由哪台服务器进行处理响应并不明确了，web服务（nginx）扮演的就是一个反向代理角色。</p><p>反向代理，主要用于服务器集群分布式部署负载均衡共同承载请求压力或安全需求等的情况下使用，反向代理可以隐藏了响应服务器的信息，能够过滤网络攻击，保证安全。</p><h2 id="正向代理"><a href="#正向代理" class="headerlink" title="正向代理"></a>正向代理</h2><p>阴阳两仪生万物，有阴就有阳，有反就有正。说完反向代理了，我们再来看看正向代理。正向代理可能在日常工作中用的不是很多，但是，相信大家经常听到：翻墙这个词，何为翻墙呢？翻墙是因为大陆对网络中攻击等等进行了屏蔽和过滤，相当于防火墙的墙一样，允许的我们才可以访问，屏蔽的我们就不能访问。这是我们做技术的如果需要在国外查询技术文档等就需要翻墙，通常我们需要购买vpn来实现，vpn的功能就是用的正向代理。那么vpn是怎么实现的呢？我们如果需要访问国外的某些网站，此时你会发现位于国外的某网站我们通过浏览器是没有办法访问的，被屏蔽过滤掉了。vpn的方式就是找一个可以正常访问国外网站的代理服务器，我们将请求发送给代理服务器，然后代理服务器去访问国外的网站，然后将访问到的数据传递给我们！</p><p>上述描述的代理模式称为正向代理，正向代理的特点是：客户端非常明确要访问的服务器地址；服务器只清楚请求来自哪个代理服务器，但是不清楚来自哪个具体的客户端；正向代理模式屏蔽或者隐藏了真实客户端信息。如下图</p><p><img src="/articles/c5ecc6c0/1.png" alt></p><h2 id="正反向代理共同使用"><a href="#正反向代理共同使用" class="headerlink" title="正反向代理共同使用"></a>正反向代理共同使用</h2><p>日常在实际项目操作中，正向代理和反向代理会搭配使用。正向代理代理客户端的请求去访问目标服务器，而目标服务器是又使用反向代理服务器，反向代理多台真实的业务处理服务器，进行负载均衡。具体的拓扑图如下：</p><p><img src="/articles/c5ecc6c0/2.jpg" alt></p><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p>我们知道了代理服务器，也一直说负载均衡，何为负载均衡呢？简单的说：web服务（nginx）作为反向代理服务器，依据一定的规则对请求进行分发，把请求平均让后端业务服务器进行响应，已达到分担压力的作用。负载就是客户端对业务发送的请求，分发到不同的服务器处理的规则，就是一种均衡规则。将服务器接收到的请求按照规则分发的过程，就是负载均衡。</p><p>负载均衡，有硬件负载均衡和软件负载均衡两种，硬件负载均衡也称为硬负载，如F5负载均衡，但是相对造价昂贵成本较高，但是数据的稳定性安全性等等有非常好的保障，如国有企业三大运营商这样的公司才会选择硬负载进行操作；通常公司都会考虑到成本问题，会选择使用软件负载均衡，软件负载均衡是利用现有的技术结合主机硬件实现的一种消息队列分发机制。软件负载均衡肯定和硬负载没发比较的，但是成本较低，稳定性和安全性在架构优化后在可接受范围，广为使用。</p><p>nginx的负载均衡规则如下：</p><ul><li><strong>weight轮询（默认</strong>）：接收到的请求按照顺序逐一分配到不同的后端服务器，即使在使用过程中，某一台后端服务器宕机，nginx会自动将该服务器剔除出队列，请求受理情况不会受到任何影响。 这种方式下，可以给不同的后端服务器设置一个权重值（weight），用于调整不同的服务器上请求的分配率；权重数据越大，被分配到请求的几率越大；该权重值，主要是针对实际工作环境中不同的后端服务器硬件配置进行调整的。</li><li><strong>ip_hash</strong>：每个请求按照发起客户端的ip的hash结果进行匹配，这样的算法下一个固定ip地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题。</li><li><strong>fair</strong>：智能调整调度算法，动态的根据后端服务器的请求处理到响应的时间进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高，响应时间长处理效率低的服务器分配到的请求少；结合了前两者的优点的一种调度算法。但是需要注意的是nginx默认不支持fair算法，如果要使用这种调度算法，请安装upstream_fair模块</li><li><strong>url_hash</strong>：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在nginx作为静态服务器的情况下提高缓存效率。同样要注意nginx默认不支持这种调度算法，要使用的话需要安装nginx的hash软件包</li></ul><h2 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h2><p>了解了正反向代理和负载均衡，那么要怎么实现呢？如何去配置。</p><h4 id="正向代理配置"><a href="#正向代理配置" class="headerlink" title="正向代理配置"></a><strong>正向代理配置</strong></h4><p>现在我登录上代理服务器上, 打开/etc/nginx/conf.d/default.conf<br>添加<code>resolver</code>和<code>proxy_pass</code>,设置如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  localhost nginx.tangll.cn;</span><br><span class="line"></span><br><span class="line">    resolver 8.8.8.8;</span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://$http_host$request_uri;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    error_page   500 502 503 504  /50x.html;</span><br><span class="line">    location = /50x.html &#123;</span><br><span class="line">        root   /usr/share/nginx/html;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>resolver</code>为DNS解析,这里填写的IP为Google提供的免费DNS服务器的IP地址。<br><code>proxy_pass</code>配置代理转发。<br>至此便是配置了代理服务器，所有访问请求全部都通过代理服务器转发,<code>$http_host</code>就是我们要访问的主机名,<code>$request_uri</code>就是我们后面所加的参数。<br>简单的说至此就是相当于配置好了我们请求了代理服务器,代理服务器再去请求我们所请求的地址。</p><p>然后，只需要在本机系统或浏览器配置代理即可访问。</p><h6 id="windows配置"><a href="#windows配置" class="headerlink" title="windows配置"></a><strong>windows配置</strong></h6><p><img src="/articles/c5ecc6c0/3.png" alt></p><h6 id="Linux系统"><a href="#Linux系统" class="headerlink" title="Linux系统"></a><strong>Linux系统</strong></h6><p><strong>使用yum 的设置代理的方法</strong></p><p>如果只需要使用yum来更新包的，只需进行yum配置即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vim /etc/yum.conf </span></span><br><span class="line">proxy=http://192.168.99.99:80</span><br><span class="line"><span class="comment">#proxy=ftp://192.168.99.99:80</span></span><br><span class="line"><span class="comment">#proxy_username=username                 #####代理的用户名</span></span><br><span class="line"><span class="comment">#proxy_password=password                  #####代理的密码</span></span><br><span class="line"><span class="comment">#然后直接用yum安装即可</span></span><br></pre></td></tr></table></figure><p><strong>wget设置代理的方法</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vim /etc/wgetrc</span></span><br><span class="line">http_proxy=192.168.99.99:80</span><br><span class="line">http_proxy=192.168.99.99:443</span><br></pre></td></tr></table></figure><p><strong>curl访问代理设置的方法</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#如果访问HTTP网站，可以直接这样的方式: curl --proxy proxy_server:80 http://www.taobao.com/</span></span><br><span class="line"><span class="comment">#如果访问HTTPS网站，例如https://www.alipay.com，那么可以使用nginx的HTTPS转发的server：</span></span><br><span class="line">curl --proxy proxy_server:443 http://www.alipay.com</span><br><span class="line"></span><br><span class="line">[root@localhost ~]<span class="comment"># curl -I --proxy 192.168.99.99:80 www.baidu.com    ###显示http访问的状态码</span></span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">备注：上边有介绍，详见上边内容。</span><br></pre></td></tr></table></figure><p><strong>使用设置全局代理的方法</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vim /etc/profile</span></span><br><span class="line">http_proxy = http://192.168.99.99:80</span><br><span class="line">http_proxy = http://192.168.99.99:443</span><br><span class="line">ftp_proxy = http://192.168.99.99:80/</span><br><span class="line"><span class="built_in">export</span> http_proxy</span><br><span class="line"><span class="built_in">export</span> ftp_proxy</span><br></pre></td></tr></table></figure><h4 id="反向代理配置"><a href="#反向代理配置" class="headerlink" title="反向代理配置"></a>反向代理配置</h4><p>反向代理的演示更为简单一些。<br>首先在/etc/nginx/conf.d/下新建一个default.conf:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  localhost nginx.tangll.cn;</span><br><span class="line">    location / &#123;</span><br><span class="line">        root   /usr/share/nginx/html;</span><br><span class="line">        index  index.html index.htm;</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">    #设置代理</span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://127.0.0.1:8080;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    error_page   500 502 503 504 404  /50x.html;</span><br><span class="line">    location = /50x.html &#123;</span><br><span class="line">        root   /usr/share/nginx/html;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>代理服务器站在客户端那边就是正向代理，代理服务器站在原始服务器那边就是反向代理, Nginx通过<code>proxy_pass</code>可以设置代理服务。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;在日常运维工作中，常常会用到反向代理，为了更安全同时为了负载均衡，分担压力。&lt;/p&gt;
&lt;p&gt;那么，有小伙伴就会有疑问：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;什么是反向代理？&lt;/li&gt;
&lt;li&gt;负载均衡又是怎么实现的？&lt;/li&gt;
&lt;li&gt;有反向代理那有正向代理吗？&lt;/li&gt;
&lt;li&gt;正向代理的应用场景是怎样的？&lt;/li&gt;
&lt;li&gt;反向代理和正向代理怎么配置实现呢？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;带着这些疑问，就给大家详细解释下nginx的正反向代理。&lt;/p&gt;
    
    </summary>
    
      <category term="Web服务" scheme="https://wandouduoduo.netlify.com/categories/Web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Nginx" scheme="https://wandouduoduo.netlify.com/categories/Web%E6%9C%8D%E5%8A%A1/Nginx/"/>
    
    
      <category term="Nginx" scheme="https://wandouduoduo.netlify.com/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>zookeeper集群脑裂探讨</title>
    <link href="https://wandouduoduo.netlify.com/articles/f714eb8e.html"/>
    <id>https://wandouduoduo.netlify.com/articles/f714eb8e.html</id>
    <published>2019-12-19T08:57:10.000Z</published>
    <updated>2019-12-26T03:34:41.315Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是脑裂"><a href="#什么是脑裂" class="headerlink" title="什么是脑裂"></a>什么是脑裂</h2><p>脑裂(split-brain)就是“大脑分裂”，也就是本来一个“大脑”被拆分了两个或多个“大脑”，我们都知道，如果一个人有多个大脑，并且相互独立的话，那么会导致人体“手舞足蹈”，“不听使唤”。</p><p>脑裂通常会出现在集群环境中，比如ElasticSearch、Zookeeper集群，而这些集群环境有一个统一的特点，就是它们有一个大脑，比如ElasticSearch集群中有Master节点，Zookeeper集群中有Leader节点。</p><p>本篇文章着重来给大家讲一下Zookeeper中的脑裂问题，以及是如果解决脑裂问题的。</p><a id="more"></a><h2 id="集群脑裂场景"><a href="#集群脑裂场景" class="headerlink" title="集群脑裂场景"></a>集群脑裂场景</h2><hr><p>对于一个集群，想要提高这个集群的可用性，通常会采用多机房部署，比如现在有一个由6台zkServer所组成的一个集群，部署在了两个机房：</p><p><img src="/articles/f714eb8e/2.png" alt="img"></p><p>正常情况下，此集群只会有一个Leader，那么如果机房之间的网络断了之后，两个机房内的zkServer还是可以相互通信的，如果<strong>不考虑过半机制</strong>，那么就会出现每个机房内部都将选出一个Leader。<img src="/articles/f714eb8e/1.png" alt="img"></p><p>这就相当于原本一个集群，被分成了两个集群，出现了两个“大脑”，这就是脑裂。</p><p>对于这种情况，我们也可以看出来，原本应该是统一的一个集群对外提供服务的，现在变成了两个集群同时对外提供服务，如果过了一会，断了的网络突然联通了，那么此时就会出现问题了，两个集群刚刚都对外提供服务了，数据该怎么合并，数据冲突怎么解决等等问题。</p><p>刚刚在说明脑裂场景时，有一个前提条件就是没有考虑过半机制，所以实际上Zookeeper集群中是不会出现脑裂问题的，而不会出现的原因就跟过半机制有关。</p><h2 id="过半机制"><a href="#过半机制" class="headerlink" title="过半机制"></a>过半机制</h2><p>在领导者选举的过程中，如果某台zkServer获得了超过半数的选票，则此zkServer就可以成为Leader了。</p><p>过半机制的源码实现其实非常简单：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">QuorumMaj</span> <span class="keyword">implements</span> <span class="title">QuorumVerifier</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(QuorumMaj.class);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span> half;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// n表示集群中zkServer的个数（准确的说是参与者的个数，参与者不包括观察者节点）</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">QuorumMaj</span><span class="params">(<span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.half = n/<span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 验证是否符合过半机制</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">containsQuorum</span><span class="params">(Set&lt;Long&gt; set)</span></span>&#123;</span><br><span class="line">        <span class="comment">// half是在构造方法里赋值的</span></span><br><span class="line">        <span class="comment">// set.size()表示某台zkServer获得的票数</span></span><br><span class="line">        <span class="keyword">return</span> (set.size() &gt; half);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>大家仔细看一下上面方法中的注释，核心代码就是下面两行：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">this.half = n/2;return (set.size() &gt; half);</span><br></pre></td></tr></table></figure><p>举个简单的例子：如果现在集群中有5台zkServer，那么half=5/2=2，那么也就是说，领导者选举的过程中至少要有三台zkServer投了同一个zkServer，才会符合过半机制，才能选出来一个Leader。</p><p>那么有一个问题我们想一下，<strong>选举的过程中为什么一定要有一个过半机制验证？</strong>因为这样不需要等待所有zkServer都投了同一个zkServer就可以选举出来一个Leader了，这样比较快，所以叫快速领导者选举算法呗。</p><p>那么再来想一个问题，<strong>过半机制中为什么是大于，而不是大于等于呢？</strong></p><p>这就是更脑裂问题有关系了，比如回到上文出现脑裂问题的场景：<img src="/articles/f714eb8e/3.png" alt="img"></p><p>当机房中间的网络断掉之后，机房1内的三台服务器会进行领导者选举，但是此时过半机制的条件是set.size() &gt; 3，也就是说至少要4台zkServer才能选出来一个Leader，所以对于机房1来说它不能选出一个Leader，同样机房2也不能选出一个Leader，这种情况下整个集群当机房间的网络断掉后，整个集群将没有Leader。没有Leader对外就不能提供服务。</p><p>而如果过半机制的条件是set.size() &gt;= 3，那么机房1和机房2都会选出一个Leader，这样就出现了脑裂。所以我们就知道了，为什么过半机制中是<strong>大于</strong>，而不是<strong>大于等于</strong>。就是为了防止脑裂。</p><p>如果假设我们现在只有5台机器，也部署在两个机房：<img src="/articles/f714eb8e/4.png" alt="img"></p><p>此时过半机制的条件是set.size() &gt; 2，也就是至少要3台服务器才能选出一个Leader，此时机房件的网络断开了，对于机房1来说是没有影响的，Leader依然还是Leader，对于机房2来说是选不出来Leader的，此时整个集群中只有一个Leader。</p><p>所以，我们可以总结得出，有了过半机制，对于一个Zookeeper集群，要么没有Leader，要没只有1个Leader，这样就避免了脑裂问题。</p><h2 id="奇偶节点数探讨"><a href="#奇偶节点数探讨" class="headerlink" title="奇偶节点数探讨"></a>奇偶节点数探讨</h2><p>命题：A,B两个机房5个节点和6个节点zookeeper节点比较。</p><p>5个节点：A机房3个，B机房2个。如果网络出现中断，根据过半机制原则, 大于2个节点就可以选举出来leader。那么结果就是A机房3个节点大于2，就可以正常选举出来Leader。B节点不大于2，不能选举出Leader。这时集群还是可以正常对外提供服务，只是节点少两个而已。当网络恢复后，B机房节点再加入到集群，集群恢复。</p><p>6个节点：A机房3个，B机房3个。如果网络出现中断，根据过半机制原则, 大于3个节点才可以选举出来leader。那么结果就是A机房3个节点不大于3，B节点也不大于3，两个机房都不能选举出Leader。而没有Leader集群就不能对外提供服务，造成整个集群不可用。违背了高可用的初衷。并且还多用一台服务器，还有搭建和维护成本。而且和5个节点冗余是一样的。</p><p>可能有同学会说那A机房4个，B节点2个不就可以了。是的，这样是可以，但是偶数是存在3，3分布的这种情况。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>综上所述，为了保证zookeeper集群高可用，防止脑裂。建议用奇数个zk节点，当然是大于2的奇数。奇数个zk节点有两个好处：1，奇数个节点可用节省一个节点的资源（服务器和部署及维护成本）。2，如为偶数个节点，因为过半机制的设定，有可能出现没有leader，造成整个集群不可以。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是脑裂&quot;&gt;&lt;a href=&quot;#什么是脑裂&quot; class=&quot;headerlink&quot; title=&quot;什么是脑裂&quot;&gt;&lt;/a&gt;什么是脑裂&lt;/h2&gt;&lt;p&gt;脑裂(split-brain)就是“大脑分裂”，也就是本来一个“大脑”被拆分了两个或多个“大脑”，我们都知道，如果一个人有多个大脑，并且相互独立的话，那么会导致人体“手舞足蹈”，“不听使唤”。&lt;/p&gt;
&lt;p&gt;脑裂通常会出现在集群环境中，比如ElasticSearch、Zookeeper集群，而这些集群环境有一个统一的特点，就是它们有一个大脑，比如ElasticSearch集群中有Master节点，Zookeeper集群中有Leader节点。&lt;/p&gt;
&lt;p&gt;本篇文章着重来给大家讲一下Zookeeper中的脑裂问题，以及是如果解决脑裂问题的。&lt;/p&gt;
    
    </summary>
    
      <category term="自动化" scheme="https://wandouduoduo.netlify.com/categories/%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
      <category term="Zookeeper" scheme="https://wandouduoduo.netlify.com/categories/%E8%87%AA%E5%8A%A8%E5%8C%96/Zookeeper/"/>
    
    
      <category term="Zookeeper" scheme="https://wandouduoduo.netlify.com/tags/Zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>Tomcat最强优化</title>
    <link href="https://wandouduoduo.netlify.com/articles/a315956e.html"/>
    <id>https://wandouduoduo.netlify.com/articles/a315956e.html</id>
    <published>2019-12-19T06:54:38.000Z</published>
    <updated>2019-12-26T03:34:41.252Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文不在于给出最佳配置，而是带领开发者，能够从实际情况出发，通过不断的调节tomcat和jvm参数，去发现吞吐量，平均响应时间和错误率等信息的变化，同时根据服务器的cpu和内存等信息，结合接口的业务逻辑，最好是测试使用率最高，并发最大，或者是最重要的接口(比如下单支付接口)，设置最优的tomcat和jvm配置参数。通过Tomcat性能优化可以提高网站的并发能力。Tomcat服务器在JavaEE项目中使用率非常高，所以在生产环境对Tomcat的优化也变得非常重要了。</p><a id="more"></a><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>对于Tomcat的优化，主要是从2个方面入手：</p><p>一是<strong>Tomcat自身的配置</strong>，另一个是<strong>Tomcat所运行的jvm虚拟机的调优</strong>。</p><h2 id="硬件资源"><a href="#硬件资源" class="headerlink" title="硬件资源"></a>硬件资源</h2><p>服务器所能提供CPU、内存、硬盘的性能对处理能力有决定性影响。硬件我们不说了，这个方面是钱越多越好是吧。</p><h2 id="Tomcat配置优化"><a href="#Tomcat配置优化" class="headerlink" title="Tomcat配置优化"></a>Tomcat配置优化</h2><h4 id="管理界面"><a href="#管理界面" class="headerlink" title="管理界面"></a>管理界面</h4><p>Linux环境安装运行Tomcat8，具体的安装步骤省略 (官网下载，解压即可)。</p><p><a href="https://tomcat.apache.org/download-80.cgi" target="_blank" rel="noopener">Tomcat官网</a></p><p>如果需要登录系统，必须配置tomcat用户，在安装完Tomcat后，进行如下操作</p><p>在 <strong>/conf/tomcat-users.xml</strong>  文件中的 <tomcat-users> 标签里面添加如下内容</tomcat-users></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 修改配置文件，配置tomcat的管理用户 --&gt;</span><br><span class="line">&lt;role rolename=&quot;manager&quot;/&gt;</span><br><span class="line">&lt;role rolename=&quot;manager-gui&quot;/&gt;</span><br><span class="line">&lt;role rolename=&quot;admin&quot;/&gt;</span><br><span class="line">&lt;role rolename=&quot;admin-gui&quot;/&gt;</span><br><span class="line">&lt;user username=&quot;tomcat&quot; password=&quot;tomcat&quot; roles=&quot;admin-gui,admin,manager-gui,manager&quot;/&gt;</span><br></pre></td></tr></table></figure><p>如果是tomcat7，配置了tomcat用户就可以登录系统了，但是tomcat8中不行，还需要修改另一个配置文件，否则访问不了，提示403，打开 <code>webapps/manager/META-INF/context.xml</code>文件</p><p>启动Tomcat。(下图为默认配置启动)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/startup.sh</span><br></pre></td></tr></table></figure><p><img src="/articles/a315956e/1.png" alt></p><p>打开浏览器进行访问<a href="http://10.93.165.61:8080/" target="_blank" rel="noopener">http://10.93.165.61:8080/</a>,  点击“Server Status”，输入用户名/密码进行登陆tomcat/tomcat</p><p><img src="/articles/a315956e/2.png" alt></p><p>登录之后可以看到服务器状态等信息，主要包括服务器信息，JVM，ajp和http信息</p><p><img src="/articles/a315956e/3.png" alt></p><h4 id="AJP连接"><a href="#AJP连接" class="headerlink" title="AJP连接"></a>AJP连接</h4><p>在服务状态页面中可以看到，默认状态下会启用AJP服务，并且占用8009端口。</p><p><img src="/articles/a315956e/4.png" alt></p><p><strong>什么是AJP</strong></p><p>AJP（Apache JServer Protocol）<br>AJPv13协议是面向包的。WEB服务器和Servlet容器通过TCP连接来交互；为了节省SOCKET创建的昂贵代价，WEB服务器会尝试维护一个永久TCP连接到servlet容器，并且在多个请求和响应周期过程会重用连接。</p><p><img src="/articles/a315956e/5.png" alt></p><p>我们一般是使用Nginx+Tomcat的架构，所以用不着AJP协议，把AJP连接器禁用。</p><p>修改conf下的server.xml文件，将AJP服务禁用掉即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 禁用AJP连接 --&gt;</span><br><span class="line">&lt;!-- &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; --&gt;</span><br></pre></td></tr></table></figure><p>重启tomcat，查看效果。可以看到AJP服务已经不存在了。</p><p><img src="/articles/a315956e/6.png" alt></p><h4 id="执行器（线程池）"><a href="#执行器（线程池）" class="headerlink" title="执行器（线程池）"></a>执行器（线程池）</h4><p>在tomcat中每一个用户请求都是一个线程，所以可以使用线程池提高性能。</p><p>修改server.xml文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--将注释打开--&gt;</span><br><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;500&quot; minSpareThreads=&quot;50&quot; prestartminSpareThreads=&quot;true&quot; maxQueueSize=&quot;100&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--</span><br><span class="line">参数说明：</span><br><span class="line">maxThreads：最大并发数，默认设置 200，一般建议在 500 ~ 1000，根据硬件设施和业务来判断</span><br><span class="line">minSpareThreads：Tomcat 初始化时创建的线程数，默认设置 25</span><br><span class="line">prestartminSpareThreads： 在 Tomcat 初始化的时候就初始化 minSpareThreads 的参数值，如果不等于 true，minSpareThreads 的值就没啥效果了</span><br><span class="line">maxQueueSize，最大的等待队列数，超过则拒绝请求</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--在Connector中设置executor属性指向上面的执行器--&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure><p>保存退出，重启tomcat，查看效果。</p><p><img src="/articles/a315956e/7.png" alt></p><p>在页面中显示最大线程数为-1，这个是正常的，仅仅是显示的问题，实际使用的是指定的值。如果配置了一个Executor，则该属性的任何值将被正确记录，但是它将被显示为-1</p><h4 id="运行模式"><a href="#运行模式" class="headerlink" title="运行模式"></a>运行模式</h4><p>tomcat的运行模式有3种：</p><p><strong>bio</strong><br>性能非常低下，没有经过任何优化处理和支持。</p><p><strong>nio</strong><br>nio(new I/O)，是Java SE 1.4及后续版本提供的一种新的I/O操作方式(即java.nio包及其子包)。Java nio是一个基于缓冲区、并能提供非阻塞I/O操作的Java API，因此nio也被看成是non-blocking I/O的缩写。它拥有比传统I/O操作(bio)更好的并发运行性能。Tomcat8默认使用nio运行模式。</p><p><strong>apr</strong><br>安装起来最困难，但是从操作系统级别来解决异步的IO问题，大幅度的提高性能。</p><p>对于每种协议，Tomcat都提供了对应的I/O方式的实现，而且Tomcat官方还提供了在每种协议下每种I/O实现方案的差异， HTTP协议下的处理方式如下表，详情可查看<a href="https://tomcat.apache.org/tomcat-8.5-doc/config/http.html" target="_blank" rel="noopener">Tomcat官网说明</a></p><p><img src="/articles/a315956e/8.png" alt><br>推荐使用nio，在tomcat8中有最新的nio2，速度更快，建议使用nio2</p><p>设置nio2：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot;  port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11Nio2Protocol&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure><p>可以看到已经设置为nio2了。</p><p>部署测试用的web项目<br>为了方便测试性能，我们将部署一个java web项目，这个项目本身和本博客没有什么关系，仅仅用于测试。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">注意：这里在测试时，我们使用一个新的tomcat，进行测试，后面再对其进行优化调整，再测试。</span><br></pre></td></tr></table></figure><h2 id="查看服务器信息"><a href="#查看服务器信息" class="headerlink" title="查看服务器信息"></a>查看服务器信息</h2><p>说明一下我的测试服务器配置，不同的服务器配置对Tomcat的性能会有所影响。</p><p><img src="/articles/a315956e/9.png" alt></p><p>CentOS7服务器环境信息查看命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">查看Linux版本：cat /etc/centos-release</span><br><span class="line"></span><br><span class="line">查看CPU个数</span><br><span class="line">查看逻辑cpu个数：cat /proc/cpuinfo | grep “processor” | wc -l</span><br><span class="line">查看物理cpu个数：cat /proc/cpuinfo | grep “physical id” | sort | uniq | wc -l</span><br><span class="line">查看每个物理cpu的核数cores：cat /proc/cpuinfo | grep “cpu cores”</span><br><span class="line">如果所有物理cpu的cores个数加起来小于逻辑cpu的个数，则该cpu使用了超线程技术。查看每个物理cpu中逻辑cpu的个数：cat /proc/cpuinfo | grep “siblings”</span><br><span class="line"></span><br><span class="line">查看内存使用情况</span><br><span class="line">查看内存占用情况：free -m</span><br><span class="line"></span><br><span class="line">参数说明</span><br><span class="line">Mem：内存的使用情况总览表。</span><br><span class="line">total：机器总的物理内存 单位为：M</span><br><span class="line">used：用掉的内存。</span><br><span class="line">free：空闲的物理内存。</span><br></pre></td></tr></table></figure><h2 id="部署web应用"><a href="#部署web应用" class="headerlink" title="部署web应用"></a>部署web应用</h2><p>上传war包到linux服务器，然后进行部署</p><p>我的web应用的名字叫tomcat-optimization，主要是提供了一个查询用户列表的接口，该接口会去阿里云数据库查询用户列表，没有任务业务逻辑的处理。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除tomcat的/webapps/ROOT目录的所有文件</span></span><br><span class="line"><span class="built_in">cd</span> /webapps/ROOT</span><br><span class="line">rm -rf *</span><br><span class="line"></span><br><span class="line"><span class="comment"># 上传war包到tomcat的/webapps/ROOT，然后解压</span></span><br><span class="line">jar -xvf tomcat-optimization.war</span><br><span class="line">rm -rf tomcat-optimization.war</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入tomcat的/bin目录重启tomcat</span></span><br><span class="line"><span class="built_in">cd</span> /bin</span><br><span class="line">./shutdown.sh</span><br><span class="line">./startup.sh</span><br></pre></td></tr></table></figure><p>访问接口地址： <a href="http://10.93.165.61:8080/user/listUser" target="_blank" rel="noopener">http://10.93.165.61:8080/user/listUser</a></p><h2 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h2><p>Apache JMeter是Apache组织开发的基于Java的压力测试工具。 我们借助于此工具进行测试，将测试出tomcat的吞吐量等信息。</p><p><a href="http://jmeter.apache.org/download_jmeter.cgi" target="_blank" rel="noopener">官网下载地址</a></p><p><img src="/articles/a315956e/10.png" alt></p><p>注意：这里需要先安装好jdk8及其以上版本的环境。</p><p>直接将下载好的zip压缩包进行解压, 进入bin目录，找到jmeter.bat文件，双机打开即可启动。</p><p><img src="/articles/a315956e/11.png" alt></p><p>启动后，JMeter主页面如下</p><p><img src="/articles/a315956e/12.png" alt></p><p>修改语言<br>默认的主题是黑色风格的主题并且语言是英语，这样不太方便使用，所以需要修改下语言。</p><p>设置语言为简体中文。</p><p><img src="/articles/a315956e/13.png" alt></p><p>创建接口的测试用例<br>测试接口之前需要调整Windows环境配置，不然会报如下错误</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JMeter java.net.BindException: Address already in use: connect</span><br></pre></td></tr></table></figure><p>出现原因：<br>TCP/IP连接数不够或TIME_WAIT中存在很多链接，导致吞吐量低。</p><p>解决方案：<br>从问题的原因分析，有两种解决方案，一是增加预留给TCP/IP服务的临时端口的数量，二是加快被占用端口的释放速度。</p><p>解决办法：<br>1、打开注册表：regedit<br>2、HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\ Services\TCPIP\Parameters<br>3、新建 DWORD值，name：TCPTimedWaitDelay，value：30（十进制） –&gt; 设置为30秒，默认是240秒<br>4、新建 DWORD值，name：MaxUserPort，value：65534（十进制） –&gt; 设置最大连接数65534<br>5、重启系统</p><p>第一步：设置测试计划的名称</p><p>第二步：添加线程组，使用线程模拟用户的并发</p><p><img src="/articles/a315956e/14.png" alt></p><p><img src="/articles/a315956e/15.png" alt></p><p>1000个线程，每个线程循环10次，也就是tomcat会接收到10000个请求。</p><p>第三步：添加http请求</p><p><img src="/articles/a315956e/16.png" alt></p><p>设置http请求</p><p><img src="/articles/a315956e/17.png" alt></p><p>第四步：添加请求监控</p><p><img src="/articles/a315956e/18.png" alt></p><p>启动与进行接口测试</p><p>查看测试报告<br>在聚合报告中，重点看吞吐量。</p><p><img src="/articles/a315956e/19.png" alt></p><p>调整Tomcat参数进行优化<br>通过上面测试可以看出，tomcat在不做任何调整时，吞吐量为697次/秒。这个吞吐量跟接口的业务逻辑关系很大，如果业务逻辑复杂，需要比较长时间计算的，可能吞吐量只有几十次/秒，我这里测试的时候没有添加任务业务逻辑，才会出现吞吐量为697次/秒的情况。这里的吞吐量最好是经过多次测试取平均值，因为单次测试具有一定的随机性</p><p>禁用AJP连接<br>修改conf下的server.xml文件，将AJP服务禁用掉即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; --&gt;</span><br></pre></td></tr></table></figure><p><img src="/articles/a315956e/20.png" alt></p><p>这里经过9次测试，测试结果如下704 730 736 728 730 727 714 708 735 平均是723</p><p>可以看到，禁用AJP服务后，吞吐量会有所提升。</p><p>当然了，测试不一定准确，需要多测试几次才能看出是否有提升。</p><p>设置线程池<br>通过设置线程池，调整线程池相关的参数进行测试tomcat的性能。有关线程池更多更详细的配置参考Tomcat官网提供的配置详解</p><p>最大线程数为150，初始为4</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;150&quot; minSpareThreads=&quot;4&quot; prestartminSpareThreads=&quot;true&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--在Connector中设置executor属性指向上面的执行器--&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure><p><img src="/articles/a315956e/21.png" alt></p><p>经过9次测试，测试结果如下705 725 702 729 733 738 735 728 平均是724</p><p><strong>最大线程数为500，初始为50</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;500&quot; minSpareThreads=&quot;50&quot; prestartminSpareThreads=&quot;true&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--在Connector中设置executor属性指向上面的执行器--&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure><p>测试结果：733 724 718 728 734 721 720 723 平均725。吞吐量为725次/秒，性能有所提升。</p><p><strong>最大线程数为1000，初始为200</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;1000&quot; minSpareThreads=&quot;200&quot; prestartminSpareThreads=&quot;true&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--在Connector中设置executor属性指向上面的执行器--&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure><p>吞吐量为732，性能有所提升。测试结果 737 729 730 738 735 726 725 740 平均732</p><p><strong>最大线程数为5000，初始为1000</strong><br>是否是线程数最多，速度越快呢？ 我们来测试下。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;5000&quot; minSpareThreads=&quot;1000&quot; prestartminSpareThreads=&quot;true&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--在Connector中设置executor属性指向上面的执行器--&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure><p>测试结果 727 733 728 725 738 729 737 735 739 平均732</p><p>可以看到，虽然最大线程已经设置到5000，但是实际测试效果并不理想，并且平均的响应时间也边长了，所以单纯靠提升线程数量是不能一直得到性能提升的。</p><p><strong>设置最大等待队列数</strong><br>默认情况下，请求发送到tomcat，如果tomcat正忙，那么该请求会一直等待。这样虽然可以保证每个请求都能请求到，但是请求时间就会边长。</p><p>有些时候，我们也不一定要求请求一定等待，可以设置最大等待队列大小，如果超过就不等待了。这样虽然有些请求是失败的，但是请求时间会虽短。典型的应用：12306。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--最大等待数为100--&gt;</span><br><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;500&quot; minSpareThreads=&quot;100&quot; prestartminSpareThreads=&quot;true&quot; maxQueueSize=&quot;100&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--在Connector中设置executor属性指向上面的执行器--&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure><p><img src="/articles/a315956e/22.png" alt></p><p>测试结果：</p><ul><li><p>平均响应时间：0.438秒，响应时间明显缩短</p></li><li><p>错误率：43.07%，错误率超过40%，也可以理解，最大线程为500，测试的并发为1000</p></li><li><p>吞吐量：1359次/秒，吞吐量明显提升</p><p>结论：响应时间、吞吐量这2个指标需要找到平衡才能达到更好的性能。</p></li></ul><p><strong>设置nio2的运行模式</strong><br>将最大线程设置为500进行测试：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;500&quot; minSpareThreads=&quot;100&quot; prestartminSpareThreads=&quot;true&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 设置nio2 --&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11Nio2Protocol&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure><p>从测试结果可以看到，平均响应时间有缩短，吞吐量有提升，可以得出结论：nio2的性能要高于nio。</p><p>参数说明与最佳实践<br>具体参数参考官网说明</p><p>执行器参数说明(加粗是重点)<br><img src="/articles/a315956e/23.png" alt><br>执行器最佳实践<br>此最佳配置仅供参考</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;800&quot; minSpareThreads=&quot;100&quot; maxQueueSize=&quot;100&quot;                                 prestartminSpareThreads=&quot;true&quot;/&gt;</span><br></pre></td></tr></table></figure><p>连接器参数说明<br>可以看到除了这几个基本配置外并无特殊功能，所以我们需要对 Connector 进行扩展。</p><p>其中Connector 支持参数属性可以参考Tomcat官方网站，本文就只介绍些常用的。</p><p>通用属性(加粗是重点)<br><img src="/articles/a315956e/24.png" alt></p><p><img src="/articles/a315956e/25.png" alt></p><p><img src="/articles/a315956e/26.png" alt></p><p><strong>标准实现(加粗是重点)</strong><br>除了上面列出的常见的连接器属性，标准的HTTP连接器（BIO，NIO和APR/native）都支持以下属性。</p><p><img src="/articles/a315956e/27.png" alt></p><p><img src="/articles/a315956e/28.png" alt></p><p><img src="/articles/a315956e/29.png" alt></p><p><img src="/articles/a315956e/30.png" alt></p><p><strong>连接器最佳实践</strong><br>此最佳配置仅供参考</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot;                             protocol=&quot;org.apache.coyote.http11.Http11Nio2Protocol&quot; </span><br><span class="line">           connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; </span><br><span class="line">           enableLookups=&quot;false&quot; maxPostSize=&quot;10485760&quot; URIEncoding=&quot;UTF-8&quot;                     acceptCount=&quot;100&quot; acceptorThreadCount=&quot;2&quot; disableUploadTimeout=&quot;true&quot;                    maxConnections=&quot;10000&quot; SSLEnabled=&quot;false&quot;/&gt;</span><br></pre></td></tr></table></figure><p><strong>调整JVM参数进行优化</strong><br>接下来，通过设置jvm参数进行优化，为了测试一致性，依然将最大线程数设置为500，启用nio2运行模式</p><p><strong>设置并行垃圾回收器</strong><br>在/bin/catalina.sh文件第一行添加如下参数，gc日志输出到/logs/gc.log</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#年轻代、老年代均使用并行收集器，初始堆内存64M，最大堆内存512M</span><br><span class="line">JAVA_OPTS=&quot;-XX:+UseParallelGC -XX:+UseParallelOldGC -Xms64m -Xmx512m -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -Xloggc:../logs/gc.log&quot;</span><br></pre></td></tr></table></figure><p>测试结果与默认的JVM参数结果接近。</p><p>查看gc日志文件<br>将gc.log文件上传到gceasy.io查看gc中是否存在问题。上传文件后需要等待一段时间，需要耐心等待。</p><p>问题一：<strong>系统所消耗的时间大于用户时间</strong></p><p>如果在报告中显示System Time greater than User Time，系统所消耗的时间大于用户时间，这反应出的服务器的性能存在瓶颈，调度CPU等资源所消耗的时间要长一些。</p><p>问题二：<strong>线程暂停时间有点长</strong></p><p>可以关键指标中可以看出，吞吐量表现不错，但是gc时，线程的暂停时间稍有点长。</p><p>问题三：<strong>GC总次数过多</strong></p><p><img src="/articles/a315956e/31.png" alt></p><p>通过GC的统计可以看出：</p><p>年轻代的gc有100次，次数有点多，说明年轻代设置的大小不合适，需要调整<br>FullGC有7次，说明堆内存的大小不合适，需要调整</p><p>问题四：<strong>年轻代内存不足导致GC</strong></p><p><img src="/articles/a315956e/32.png" alt></p><p>从GC原因的可以看出，年轻代大小设置不合理，导致了多次GC。</p><p>调整年轻代大小<br>调整jvm配置参数</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-XX:+UseParallelGC -XX:+UseParallelOldGC -Xms128m -Xmx1024m -XX:NewSize=64m -XX:MaxNewSize=256m -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -Xloggc:../logs/gc.log&quot;</span><br></pre></td></tr></table></figure><p>将初始堆大小设置为128m，最大为1024m，初始年轻代大小64m，年轻代最大256m</p><p>从测试结果来看，吞吐量以及响应时间均有提升。</p><p>查看gc日志</p><p><img src="/articles/a315956e/33.png" alt></p><p>可以看到GC次数要明显减少，说明调整是有效的。</p><p><img src="/articles/a315956e/34.png" alt></p><p>GC次数有所减少</p><p><img src="/articles/a315956e/35.png" alt></p><p>设置G1垃圾回收器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#设置了最大停顿时间100毫秒，初始堆内存128m，最大堆内存1024m</span><br><span class="line">JAVA_OPTS=&quot;-XX:+UseG1GC -XX:MaxGCPauseMillis=100 -Xms128m -Xmx1024m -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -Xloggc:../logs/gc.log&quot;</span><br></pre></td></tr></table></figure><p>测试结果: 可以看到，吞吐量有所提升，评价响应时间也有所缩短。</p><p>JVM配置最佳实践<br>此最佳配置仅供参考</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-Dfile.encoding=UTF-8-server -Xms1024m -Xmx2048m -XX:NewSize=512m -XX:MaxNewSize=1024m -XX:PermSize=256m -XX:MaxPermSize=256m -XX:MaxTenuringThreshold=10-XX:NewRatio=2 -XX:+DisableExplicitGC&quot;</span><br></pre></td></tr></table></figure><p>参数说明：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">file.encoding 默认文件编码</span><br><span class="line">-Xmx1024m 设置JVM最大可用内存为1024MB</span><br><span class="line">-Xms1024m 设置JVM最小内存为1024m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。</span><br><span class="line">-XX:NewSize 设置年轻代大小</span><br><span class="line">-XX:MaxNewSize 设置最大的年轻代大小</span><br><span class="line">-XX:PermSize 设置永久代大小</span><br><span class="line">-XX:MaxPermSize 设置最大永久代大小</span><br><span class="line">-XX:NewRatio=4 设置年轻代（包括Eden和两个Survivor区）与终身代的比值（除去永久代）。设置为4，则年轻代与终身代所占比值为1：4，年轻代占整个堆栈的1/5</span><br><span class="line">-XX:MaxTenuringThreshold=0 设置垃圾最大年龄，默认为：15。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。</span><br><span class="line">-XX:+DisableExplicitGC 这个将会忽略手动调用GC的代码使得System.gc()的调用就会变成一个空调用，完全不会触发任何GC。</span><br></pre></td></tr></table></figure><p>总结<br>通过上述的测试，可以总结出，对tomcat性能优化就是需要不断的进行调整参数，然后测试结果，可能会调优也可能会调差，这时就需要借助于gc的可视化工具来看gc的情况。再帮我我们做出决策应该调整哪些参数。</p><p>再次重申本博客的目的不在于给出最佳配置，而是带领开发者，能够从实际情况出发，通过不断的调节tomcat和jvm参数，去发现吞吐量，平均响应时间和错误率等信息的变化，同时根据服务器的cpu和内存等信息，结合接口的业务逻辑，最好是测试使用率最高，并发最大，或者是最重要的接口(比如下单支付接口)，设置最优的tomcat和jvm配置参数。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;本文不在于给出最佳配置，而是带领开发者，能够从实际情况出发，通过不断的调节tomcat和jvm参数，去发现吞吐量，平均响应时间和错误率等信息的变化，同时根据服务器的cpu和内存等信息，结合接口的业务逻辑，最好是测试使用率最高，并发最大，或者是最重要的接口(比如下单支付接口)，设置最优的tomcat和jvm配置参数。通过Tomcat性能优化可以提高网站的并发能力。Tomcat服务器在JavaEE项目中使用率非常高，所以在生产环境对Tomcat的优化也变得非常重要了。&lt;/p&gt;
    
    </summary>
    
      <category term="容器化" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Tomcat" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/Tomcat/"/>
    
    
      <category term="Tomcat" scheme="https://wandouduoduo.netlify.com/tags/Tomcat/"/>
    
  </entry>
  
  <entry>
    <title>Tomcat高并发和安全配置</title>
    <link href="https://wandouduoduo.netlify.com/articles/d5611253.html"/>
    <id>https://wandouduoduo.netlify.com/articles/d5611253.html</id>
    <published>2019-12-19T03:43:17.000Z</published>
    <updated>2019-12-26T03:34:41.314Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>现在Tomcat容器在企业中的应用还占据很高比例，如何对Tomcat优化配置，让其实现高并发的同时，安全也能兼顾呢。本篇就详细介绍Tomcat高并发和安全配置。</p><a id="more"></a><h2 id="变量配置"><a href="#变量配置" class="headerlink" title="变量配置"></a>变量配置</h2><p>设置 Tomcat 相关变量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim bin/catalina.sh</span><br></pre></td></tr></table></figure><p>在配置文件的可编辑内容最上面（98 行开始），加上如下内容（具体参数根据你服务器情况自行修改）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">JAVA_HOME=/usr/program/jdk1.8.0_72</span><br><span class="line">CATALINA_HOME=/usr/program/tomcat8</span><br><span class="line">CATALINA_OPTS=&quot;-server -Xms528m -Xmx528m -XX:PermSize=256m -XX:MaxPermSize=358m&quot;</span><br><span class="line">CATALINA_PID=$CATALINA_HOME/catalina.pid</span><br></pre></td></tr></table></figure><p>如果使用 shutdown.sh 还无法停止 tomcat，可以修改其配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim bin/shutdown.sh</span><br><span class="line">把最尾巴这一行：exec &quot;$PRGDIR&quot;/&quot;$EXECUTABLE&quot; stop &quot;$@&quot;</span><br><span class="line">改为：exec &quot;$PRGDIR&quot;/&quot;$EXECUTABLE&quot; stop 10 -force</span><br></pre></td></tr></table></figure><h2 id="JVM-优化"><a href="#JVM-优化" class="headerlink" title="JVM 优化"></a>JVM 优化</h2><p>Java 的内存模型分为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Young，年轻代（易被 GC）。Young 区被划分为三部分，Eden 区和两个大小严格相同的 Survivor 区，其中 Survivor 区间中，某一时刻只有其中一个是被使用的，另外一个留做垃圾收集时复制对象用，在 Young 区间变满的时候，minor GC 就会将存活的对象移到空闲的Survivor 区间中，根据 JVM 的策略，在经过几次垃圾收集后，任然存活于 Survivor 的对象将被移动到 Tenured 区间。</span><br><span class="line"></span><br><span class="line">Tenured，终身代。Tenured 区主要保存生命周期长的对象，一般是一些老的对象，当一些对象在 Young 复制转移一定的次数以后，对象就会被转移到 Tenured 区，一般如果系统中用了 application 级别的缓存，缓存中的对象往往会被转移到这一区间。</span><br><span class="line"></span><br><span class="line">Perm，永久代。主要保存 class,method,filed 对象，这部门的空间一般不会溢出，除非一次性加载了很多的类，不过在涉及到热部署的应用服务器的时候，有时候会遇到 java.lang.OutOfMemoryError : PermGen space 的错误，造成这个错误的很大原因就有可能是每次都重新部署，但是重新部署后，类的 class 没有被卸载掉，这样就造成了大量的 class 对象保存在了 perm 中，这种情况下，一般重新启动应用服务器可以解决问题。</span><br></pre></td></tr></table></figure><p>Linux 修改 bin/catalina.sh 文件，把下面信息添加到文件第一行。Windows 和 Linux 有点不一样的地方在于，在 Linux 下，下面的的参数值是被引号包围的，而 Windows 不需要引号包围。</p><p>如果服务器只运行一个 Tomcat<br>机子内存如果是 8G，一般 PermSize 配置是主要保证系统能稳定起来就行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-Dfile.encoding=UTF-8 -server -Xms6144m -Xmx6144m -XX:NewSize=1024m -XX:MaxNewSize=2048m -XX:PermSize=512m -XX:MaxPermSize=512m -XX:MaxTenuringThreshold=10 -XX:NewRatio=2 -XX:+DisableExplicitGC&quot;</span><br></pre></td></tr></table></figure><p>机子内存如果是 16G，一般 PermSize 配置是主要保证系统能稳定起来就行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-Dfile.encoding=UTF-8 -server -Xms13312m -Xmx13312m -XX:NewSize=3072m -XX:MaxNewSize=4096m -XX:PermSize=512m -XX:MaxPermSize=512m -XX:MaxTenuringThreshold=10 -XX:NewRatio=2 -XX:+DisableExplicitGC&quot;</span><br></pre></td></tr></table></figure><p>机子内存如果是 32G，一般 PermSize 配置是主要保证系统能稳定起来就行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-Dfile.encoding=UTF-8 -server -Xms29696m -Xmx29696m -XX:NewSize=6144m -XX:MaxNewSize=9216m -XX:PermSize=1024m -XX:MaxPermSize=1024m -XX:MaxTenuringThreshold=10 -XX:NewRatio=2 -XX:+DisableExplicitGC&quot;</span><br></pre></td></tr></table></figure><p>如果是开发机</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-Xms550m -Xmx1250m -XX:PermSize=550m -XX:MaxPermSize=1250m</span><br></pre></td></tr></table></figure><p>参数说明：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">-Dfile.encoding：默认文件编码</span><br><span class="line">-server：表示这是应用于服务器的配置，JVM 内部会有特殊处理的</span><br><span class="line">-Xmx1024m：设置JVM最大可用内存为1024MB</span><br><span class="line">-Xms1024m：设置JVM最小内存为1024m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。</span><br><span class="line">-XX:NewSize：设置年轻代大小</span><br><span class="line">-XX:MaxNewSize：设置最大的年轻代大小</span><br><span class="line">-XX:PermSize：设置永久代大小</span><br><span class="line">-XX:MaxPermSize：设置最大永久代大小</span><br><span class="line">-XX:NewRatio=4：设置年轻代（包括 Eden 和两个 Survivor 区）与终身代的比值（除去永久代）。设置为 4，则年轻代与终身代所占比值为 1：4，年轻代占整个堆栈的 1/5</span><br><span class="line">-XX:MaxTenuringThreshold=10：设置垃圾最大年龄，默认为：15。如果设置为 0 的话，则年轻代对象不经过 Survivor 区，直接进入年老代。对于年老代比较多的应用，可以提高效率。                             如果将此值设置为一个较大值，则年轻代对象会在 Survivor 区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。</span><br><span class="line">-XX:+DisableExplicitGC：这个将会忽略手动调用 GC 的代码使得 System.gc() 的调用就会变成一个空调用，完全不会触发任何 GC</span><br></pre></td></tr></table></figure><h2 id="禁用8005端口"><a href="#禁用8005端口" class="headerlink" title="禁用8005端口"></a>禁用8005端口</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim conf/server.xml</span><br><span class="line"></span><br><span class="line"><span class="comment"># telnet localhost 8005 然后输入 SHUTDOWN 就可以关闭 Tomcat，为了安全我们要禁用该功能。</span></span><br><span class="line"><span class="comment"># 禁用该端口，要说明的是： shutdown端口是Tomcat中shutdown.sh脚本执行时给操作系统发送停止信号的端口，禁用后，执行shutdown.sh并不能停掉tomcat。那有同学就问，那我要怎么停，并且问什么要禁掉呢？停可以直接停止进程。禁掉是为了安全，同时在日常自动化运维中，为了自动批量控制业务状态，都会直接控制业务进程，所以就可以禁掉。</span></span><br><span class="line"></span><br><span class="line">默认值:</span><br><span class="line">&lt;Server port=<span class="string">"8005"</span> shutdown=<span class="string">"SHUTDOWN"</span>&gt;</span><br><span class="line">修改为:</span><br><span class="line">&lt;Server port=<span class="string">"-1"</span> shutdown=<span class="string">"SHUTDOWN"</span>&gt;</span><br></pre></td></tr></table></figure><h2 id="关闭自动部署"><a href="#关闭自动部署" class="headerlink" title="关闭自动部署"></a>关闭自动部署</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">默认值:</span><br><span class="line">&lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot;</span><br><span class="line">     unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;</span><br><span class="line">修改为:</span><br><span class="line">&lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot;</span><br><span class="line">     unpackWARs=&quot;false&quot; autoDeploy=&quot;false&quot; reloadable=&quot;false&quot;&gt;</span><br><span class="line">     </span><br><span class="line"># 在tomcat8版本中配置 reloadable=&quot;false&quot; 选项启动时会包如下警告可忽略：</span><br><span class="line">警告 [main] org.apache.tomcat.util.digester.SetPropertiesRule.begin [SetPropertiesRule]Server/Service/Engine/Host&#125; Setting property &apos;reloadable&apos; to &apos;false&apos; did not find a matching property.</span><br></pre></td></tr></table></figure><h2 id="线程池限制"><a href="#线程池限制" class="headerlink" title="线程池限制"></a>线程池限制</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">默认为注释:</span><br><span class="line">&lt;!--</span><br><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">maxThreads=&quot;150&quot; minSpareThreads=&quot;4&quot;/&gt;</span><br><span class="line">--&gt;</span><br><span class="line">修改为:</span><br><span class="line">&lt;Executor</span><br><span class="line">   name=&quot;tomcatThreadPool&quot;</span><br><span class="line">   namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">   maxThreads=&quot;500&quot;</span><br><span class="line">   minSpareThreads=&quot;100&quot; </span><br><span class="line">   maxIdleTime=&quot;60000&quot;</span><br><span class="line">  prestartminSpareThreads = &quot;true&quot;</span><br><span class="line">  maxQueueSize = &quot;100&quot;</span><br><span class="line">/&gt;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">参数解释：</span><br><span class="line"></span><br><span class="line">maxThreads：最大并发数，默认设置 200，一般建议在 500 ~ 800，根据硬件设施和业务来判断</span><br><span class="line">minSpareThreads：Tomcat 初始化时创建的线程数，默认设置 25</span><br><span class="line">maxIdleTime：如果当前线程大于初始化线程，那空闲线程存活的时间，单位毫秒，默认60000=60秒=1分钟。</span><br><span class="line">prestartminSpareThreads：在 Tomcat 初始化的时候就初始化 minSpareThreads 的参数值，如果不等于 true，minSpareThreads 的值就没啥效果了</span><br><span class="line">maxQueueSize：最大的等待队列数，超过则拒绝请求</span><br></pre></td></tr></table></figure><h2 id="连接器配置"><a href="#连接器配置" class="headerlink" title="连接器配置"></a>连接器配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">默认值：</span><br><span class="line">&lt;Connector </span><br><span class="line">   port=&quot;8080&quot; </span><br><span class="line">   protocol=&quot;HTTP/1.1&quot; </span><br><span class="line">   connectionTimeout=&quot;20000&quot; </span><br><span class="line">   redirectPort=&quot;8443&quot; </span><br><span class="line">/&gt;</span><br><span class="line">修改为：</span><br><span class="line">&lt;Connector </span><br><span class="line">  executor=&quot;tomcatThreadPool&quot;</span><br><span class="line">  port=&quot;8080&quot; </span><br><span class="line">  protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot; </span><br><span class="line">  connectionTimeout=&quot;40000&quot; </span><br><span class="line">  maxConnections=&quot;10000&quot; </span><br><span class="line">  redirectPort=&quot;8443&quot; </span><br><span class="line">  enableLookups=&quot;false&quot; </span><br><span class="line">  acceptCount=&quot;100&quot; </span><br><span class="line">  maxPostSize=&quot;10485760&quot; </span><br><span class="line">  compression=&quot;on&quot; </span><br><span class="line">  disableUploadTimeout=&quot;true&quot; </span><br><span class="line">  compressionMinSize=&quot;2048&quot; </span><br><span class="line">  acceptorThreadCount=&quot;2&quot; </span><br><span class="line">compressableMimeType=&quot;text/html,text/xml,text/plain,text/css,text/javascript,application/javascript&quot; </span><br><span class="line">  maxHttpHeaderSize=&quot;8192&quot;</span><br><span class="line">  processorCache=&quot;20000&quot;</span><br><span class="line">  tcpNoDelay=&quot;true&quot;</span><br><span class="line">  connectionLinger=&quot;5&quot;</span><br><span class="line">  server=&quot;Server Version 11.0&quot;</span><br><span class="line">  URIEncoding=&quot;utf-8&quot;</span><br><span class="line">/&gt;</span><br><span class="line"></span><br><span class="line">用此项配置 protocol=&quot;org.apache.coyote.http11.Http11Nio2Protocol&quot;启动时会有警告可忽略</span><br><span class="line">警告 [main] org.apache.tomcat.util.net.Nio2Endpoint.bind The NIO2 connector requires an exclusive executor to operate properly on shutdown</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">参数解释：</span><br><span class="line"></span><br><span class="line">protocol：Tomcat 8 设置 nio2 更好：org.apache.coyote.http11.Http11Nio2Protocol（如果这个用不了，就用下面那个），Tomcat 6、7 设置 nio 更好：org.apache.coyote.http11.Http11NioProtocol</span><br><span class="line">enableLookups：禁用DNS查询</span><br><span class="line">acceptCount：指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理，默认设置 100</span><br><span class="line">maxPostSize：以 FORM URL 参数方式的 POST 提交方式，限制提交最大的大小，默认是 2097152(2兆)，它使用的单位是字节。10485760 为 10M。如果要禁用限制，则可以设置为 -1。</span><br><span class="line">maxPostSize：设置由容器解析的URL参数的最大长度，-1(小于0)为禁用这个属性，默认为2097152(2M) 请注意， FailedRequestFilter 过滤器可以用来拒绝达到了极限值的请求。</span><br><span class="line">acceptorThreadCount，用于接收连接的线程的数量，默认值是1。一般这个指需要改动的时候是因为该服务器是一个多核CPU，如果是多核 CPU 一般配置为 2.</span><br><span class="line">acceptorThreadCount：用于接受连接的线程数量。增加这个值在多CPU的机器上,尽管你永远不会真正需要超过2。 也有很多非维持连接,您可能希望增加这个值。默认值是1。</span><br><span class="line">connectionTimeout：Connector接受一个连接后等待的时间(milliseconds)，默认值是60000。</span><br><span class="line">maxConnections：这个值表示最多可以有多少个socket连接到tomcat上</span><br><span class="line">maxHttpHeaderSize：http请求头信息的最大程度，超过此长度的部分不予处理。一般8K。</span><br><span class="line">compression：是否启用GZIP压缩 on为启用（文本数据压缩） off为不启用， force 压缩所有数据</span><br><span class="line">disableUploadTimeout：这个标志允许servlet容器使用一个不同的,通常长在数据上传连接超时。 如果不指定,这个属性被设置为true,表示禁用该时间超时。</span><br><span class="line">compressionMinSize：当超过最小数据大小才进行压缩</span><br><span class="line">compressableMimeType：配置想压缩的数据类型</span><br><span class="line">URIEncoding：网站一般采用UTF-8作为默认编码。</span><br><span class="line">processorCache：协议处理器缓存的处理器对象来提高性能。 该设置决定多少这些对象的缓存。-1意味着无限的,默认是200。 如果不使用Servlet 3.0异步处理,默认是使用一样的maxThreads设置。                 如果使用Servlet 3.0异步处理,默认是使用大maxThreads和预期的并发请求的最大数量(同步和异步)。</span><br><span class="line">tcpNoDelay：如果设置为true,TCP_NO_DELAY选项将被设置在服务器套接字,而在大多数情况下提高性能。这是默认设置为true。</span><br><span class="line">connectionLinger：秒数在这个连接器将持续使用的套接字时关闭。默认值是 -1,禁用socket 延迟时间。</span><br><span class="line">server：隐藏Tomcat版本信息，首先隐藏HTTP头中的版本信息</span><br></pre></td></tr></table></figure><p><strong>建议：压缩会增加Tomcat负担，最好采用Nginx + Tomcat 或者 Apache + Tomcat 方式，压缩交由Nginx/Apache 去做。</strong><br><strong>Tomcat 的压缩是在客户端请求服务器对应资源后，从服务器端将资源文件压缩，再输出到客户端，由客户端的浏览器负责解压缩并浏览。相对于普通的 浏览过程 HTML、CSS、Javascript和Text，它可以节省40% 左右的流量。更为重要的是，它可以对动态生成的，包括CGI、PHP、JSP、ASP、Servlet,SHTML等输出的网页也能进行压缩，压缩效率也很高。</strong></p><h2 id="禁用-AJP"><a href="#禁用-AJP" class="headerlink" title="禁用 AJP"></a>禁用 AJP</h2><p><strong>前提：如果你服务器没有使用 Apache或不用ajp</strong></p><p>AJP是为 Tomcat 与 HTTP 服务器之间通信而定制的协议，能提供较高的通信速度和效率。如果tomcat前端放的是apache的时候，会使用到AJP这个连接器。 默认是开启的。如果不使用apache，注释该连接器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">把下面这一行注释掉，默认 Tomcat 是开启的。</span><br><span class="line">&lt;!-- &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; --&gt;</span><br></pre></td></tr></table></figure><h2 id="隐藏或修改版本号"><a href="#隐藏或修改版本号" class="headerlink" title="隐藏或修改版本号"></a>隐藏或修改版本号</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/tomcat/lib/</span><br><span class="line">unzip catalina.jar</span><br><span class="line"><span class="built_in">cd</span> org/apache/catalina/util</span><br><span class="line">vim ServerInfo.properties</span><br><span class="line"></span><br><span class="line">server.info=Apache Tomcat/8.5.16</span><br><span class="line">server.number=8.5.16.0</span><br><span class="line">server.built=Jun 21 2017 17:01:09 UTC</span><br><span class="line"><span class="comment"># 将以上去掉或修改版本号即可。</span></span><br></pre></td></tr></table></figure><h2 id="管理页面安全"><a href="#管理页面安全" class="headerlink" title="管理页面安全"></a>管理页面安全</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rm -rf /usr/<span class="built_in">local</span>/apache-tomcat-8.5.16/webapps/*</span><br><span class="line">rm -rf /usr/<span class="built_in">local</span>/apache-tomcat-8.5.16/conf/tomcat-users.xml</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;现在Tomcat容器在企业中的应用还占据很高比例，如何对Tomcat优化配置，让其实现高并发的同时，安全也能兼顾呢。本篇就详细介绍Tomcat高并发和安全配置。&lt;/p&gt;
    
    </summary>
    
      <category term="容器化" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Tomcat" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/Tomcat/"/>
    
    
      <category term="Tomcat" scheme="https://wandouduoduo.netlify.com/tags/Tomcat/"/>
    
  </entry>
  
  <entry>
    <title>Tomcat优化之APR模式</title>
    <link href="https://wandouduoduo.netlify.com/articles/98d7cf0b.html"/>
    <id>https://wandouduoduo.netlify.com/articles/98d7cf0b.html</id>
    <published>2019-12-18T09:22:37.000Z</published>
    <updated>2019-12-18T13:57:15.961Z</updated>
    
    <content type="html"><![CDATA[<h2 id="APR模式介绍"><a href="#APR模式介绍" class="headerlink" title="APR模式介绍"></a>APR模式介绍</h2><p>Tomcat可以使用APR来提供超强的可伸缩性和性能，更好地集成本地服务器技术。APR(Apache Portable Runtime)是一个高可移植库，它是Apache HTTP Server2.x的核心。</p><p>APR有很多用途，包括访问高级IO功能(例如sendfile,epoll和OpenSSL)，OS级别功能(随机数生成，系统状态等等)，本地进程管理(共享内存，NT管道和UNIXsockets)。这些功能可以使Tomcat作为一个通常的前台WEB服务器，能更好地和其它本地web技术集成，总体上让Java更有效率作为一个高性能web服务器平台而不是简单作为后台容器。</p><p>在产品环境中，特别是直接使用Tomcat做WEB服务器的时候，应该使用Tomcat Native来提高其性能。就是如何  在Tomcat中使用JNI的方式来读取文件以及进行网络传输。这个东西可以大大提升Tomcat对静态文件的处理性能，同时如果你使用了HTTPS方式  传输的话，也可以提升SSL的处理性能。</p><a id="more"></a><h2 id="APR模式配置"><a href="#APR模式配置" class="headerlink" title="APR模式配置"></a>APR模式配置</h2><h4 id="获取APR组件依赖包"><a href="#获取APR组件依赖包" class="headerlink" title="获取APR组件依赖包"></a>获取APR组件依赖包</h4><p>首先需要下载APR的三个依赖包 <a href="http://apr.apache.org/download.cgi" target="_blank" rel="noopener">官方下载地址</a> </p><p><img src="/articles/98d7cf0b/1.png" alt></p><p>然后把包上传到服务器。</p><h4 id="编译安装各个组件"><a href="#编译安装各个组件" class="headerlink" title="编译安装各个组件"></a>编译安装各个组件</h4><h6 id="安装相关环境包"><a href="#安装相关环境包" class="headerlink" title="安装相关环境包"></a>安装相关环境包</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install cmake gcc expat-devel</span><br></pre></td></tr></table></figure><h6 id="安装apr"><a href="#安装apr" class="headerlink" title="安装apr"></a>安装apr</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf apr-1.7.0.tar.gz</span><br><span class="line">cd apr-1.7.0</span><br><span class="line">./configure --prefix=/usr/local/apr</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h6 id="安装apr-iconv"><a href="#安装apr-iconv" class="headerlink" title="安装apr-iconv"></a>安装apr-iconv</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf apr-iconv-1.2.2.tar.gz</span><br><span class="line"><span class="built_in">cd</span> apr-iconv-1.2.2</span><br><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/apr-iconv --with-apr=/usr/<span class="built_in">local</span>/apr</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h6 id="安装apr-util"><a href="#安装apr-util" class="headerlink" title="安装apr-util"></a>安装apr-util</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf apr-util-1.6.1.tar.gz</span><br><span class="line"><span class="built_in">cd</span> apr-util-1.6.1</span><br><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/apr-util --with-apr=/usr/<span class="built_in">local</span>/apr --with-apr-iconv=/usr/<span class="built_in">local</span>/apr-iconv/bin/apriconv</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h6 id="安装Tomcat-native"><a href="#安装Tomcat-native" class="headerlink" title="安装Tomcat-native"></a>安装Tomcat-native</h6><p>两种方式获取安装包：1，<a href="http://tomcat.apache.org/download-native.cgi" target="_blank" rel="noopener">从官方网站下载</a>；2，Tomcat中就包含该安装包，目录在: tomcat_home/bin/下。本教程采用第二种。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd tomcat_home/bin</span><br><span class="line">tar -zxvf tomcat-native.tar.gz</span><br><span class="line">cd tomcat-native-1.2.23-src/native/</span><br><span class="line">./configure  --with-apr=/usr/local/apr </span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>如有报错，openssl版本过低，需要大于1.0.2版本的，如下图</p><p><img src="/articles/98d7cf0b/2.png" alt></p><p>在<a href="https://www.openssl.org/source/" target="_blank" rel="noopener">openssl官方网站</a>下载。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget https://www.openssl.org/<span class="built_in">source</span>/openssl-1.0.2t.tar.gz</span><br><span class="line">tar xzvf openssl-1.0.2t.tar.gz</span><br><span class="line"><span class="built_in">cd</span> openssl-1.0.2t</span><br><span class="line">./config --prefix=/usr/<span class="built_in">local</span>/openssl  –fPIC <span class="comment">#加上-fPIC参数,否则编译native的时候会报错</span></span><br><span class="line">./config -t</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><p>安装成功openssl后再次编译还是报错，说明没找到，可以添加绝对路径编译</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./configure  --with-apr=/usr/<span class="built_in">local</span>/apr --with-ssl=/usr/<span class="built_in">local</span>/openssl</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h6 id="设置环境变量"><a href="#设置环境变量" class="headerlink" title="设置环境变量"></a>设置环境变量</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/<span class="built_in">local</span>/apr/lib <span class="comment">##添加apr path</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure><h4 id="修改tomcat配置文件"><a href="#修改tomcat配置文件" class="headerlink" title="修改tomcat配置文件"></a>修改tomcat配置文件</h4><h6 id="修改protocol值"><a href="#修改protocol值" class="headerlink" title="修改protocol值"></a>修改protocol值</h6><p>Tomcat默认是HTTP/1.1，如果运行apr模式需要把protocol值修改成apr模式：<strong>org.apache.coyote.http11.Http11AprProtocol</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim server.xml</span></span><br><span class="line"></span><br><span class="line">&lt;Connector port=<span class="string">"8080"</span> protocol=<span class="string">"org.apache.coyote.http11.Http11AprProtocol"</span></span><br></pre></td></tr></table></figure><h6 id="修改SSLEngine"><a href="#修改SSLEngine" class="headerlink" title="修改SSLEngine"></a>修改SSLEngine</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim server.xml</span></span><br><span class="line"></span><br><span class="line">&lt;Listener className=<span class="string">"org.apache.catalina.core.AprLifecycleListener"</span> SSLEngine=<span class="string">"off"</span> /&gt;</span><br></pre></td></tr></table></figure><h2 id="启动tomcat验证"><a href="#启动tomcat验证" class="headerlink" title="启动tomcat验证"></a>启动tomcat验证</h2><p><img src="/articles/98d7cf0b/3.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;APR模式介绍&quot;&gt;&lt;a href=&quot;#APR模式介绍&quot; class=&quot;headerlink&quot; title=&quot;APR模式介绍&quot;&gt;&lt;/a&gt;APR模式介绍&lt;/h2&gt;&lt;p&gt;Tomcat可以使用APR来提供超强的可伸缩性和性能，更好地集成本地服务器技术。APR(Apache Portable Runtime)是一个高可移植库，它是Apache HTTP Server2.x的核心。&lt;/p&gt;
&lt;p&gt;APR有很多用途，包括访问高级IO功能(例如sendfile,epoll和OpenSSL)，OS级别功能(随机数生成，系统状态等等)，本地进程管理(共享内存，NT管道和UNIXsockets)。这些功能可以使Tomcat作为一个通常的前台WEB服务器，能更好地和其它本地web技术集成，总体上让Java更有效率作为一个高性能web服务器平台而不是简单作为后台容器。&lt;/p&gt;
&lt;p&gt;在产品环境中，特别是直接使用Tomcat做WEB服务器的时候，应该使用Tomcat Native来提高其性能。就是如何  在Tomcat中使用JNI的方式来读取文件以及进行网络传输。这个东西可以大大提升Tomcat对静态文件的处理性能，同时如果你使用了HTTPS方式  传输的话，也可以提升SSL的处理性能。&lt;/p&gt;
    
    </summary>
    
      <category term="容器化" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Tomcat" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/Tomcat/"/>
    
    
      <category term="Tomcat" scheme="https://wandouduoduo.netlify.com/tags/Tomcat/"/>
    
  </entry>
  
  <entry>
    <title>shell中的多进程并发</title>
    <link href="https://wandouduoduo.netlify.com/articles/d7c52fa4.html"/>
    <id>https://wandouduoduo.netlify.com/articles/d7c52fa4.html</id>
    <published>2019-12-10T08:23:40.000Z</published>
    <updated>2019-12-10T09:18:52.522Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>日常工作中编写shell脚本处理事务，很多时候需要一次性处理很多，需要用到循环，但是循环体内还是线性的，还是要一个个处理，这样并不会节省很多时间，只是节省了人工一次次输入的繁琐。但是对于提高处理能力，没有实质性的提高。这就需要考虑并发。但Shell中并没有真正意义的多线程，要实现多线程可以启动多个后端进程，最大程度利用cpu性能。即：多进程并发，本篇教程由浅入深详细介绍了shell中的多进程并发。</p><a id="more"></a><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>所谓的多进程只不过是将多个任务放到后台执行而已，很多人都用到过，所以现在讲的主要是控制，而不是实现。</p><h4 id="实验一"><a href="#实验一" class="headerlink" title="实验一"></a>实验一</h4><p>先看一个小shell：</p><p><img src="/articles/d7c52fa4/1.jpg" alt></p><p>看执行结果：</p><p><img src="/articles/d7c52fa4/2.jpg" alt></p><p>很明显是8s，这种不占处理器却有很耗时的进程，我们可以通过一种后台运行的方式<br>来达到节约时间的目的。</p><h4 id="实验二"><a href="#实验二" class="headerlink" title="实验二"></a>实验二</h4><p>如下为改进：</p><p><img src="/articles/d7c52fa4/3.jpg" alt="img"></p><p>用“{}”将主执行程序变为一个块，用&amp;放入后台，四次执行全部放入后台后，我们需要用一个wait指令，等待所有后台进程执行结束，不然 系统是不会等待的，直接继续执行后续指令，知道整个程序结束。<br>看结果：</p><p><img src="/articles/d7c52fa4/4.jpg" alt="img"> </p><p>可以看到，时间已经大大缩短了！</p><h4 id="实验三"><a href="#实验三" class="headerlink" title="实验三"></a>实验三</h4><p>以上实验虽然达到了多线程并发的目的，但有一个缺陷，不能控制运行在后台的进程数。为了控制进程，我们引入了管道 和文件操作符。</p><p>无名管道： 就是我们经常使用的 例如： cat text | grep “abc”   那个“|”就是管道，只不过是无名的，可以直接作为两个进程的数据通道<br>有名管道： mkfilo  可以创建一个管道文件 ，例如： mkfifo　fifo_file</p><p>管道有一个特点，如果管道中没有数据，那么取管道数据的操作就会停滞，直到管道内进入数据，然后读出后才会终止这一操作，同理，写入管道的操作，如果没有读取操作，这一个动作也会停滞。</p><p><img src="/articles/d7c52fa4/5.jpg" alt="img"> </p><p>当我们试图用echo想管道文件中写入数据时，由于没有任何进程在对它做读取操作，所以它会一直停留在那里等待读取操作，此时我们在另一终端上用cat指令做读取操作</p><p><img src="/articles/d7c52fa4/6.jpg" alt="img"> </p><p>你会发现读取操作一旦执行，写入操作就可以顺利完成了，同理，先做读取操作也是一样的：<br><img src="/articles/d7c52fa4/7.jpg" alt="img"> </p><p>由于没有管道内没有数据，所以读取操作一直滞留在那里等待写入的数据<br><img src="/articles/d7c52fa4/8.jpg" alt></p><p>一旦有了写入的数据，读取操作立刻顺利完成</p><p>以上实验，看以看到，仅仅一个管道文件似乎很难实现 我们的目的（控制后台线程数),  所以 接下来介绍 文件操作符，这里只做简单的介绍，如果不熟悉的可以自行查阅资料。<br>系统运行起始，就相应设备自动绑定到了 三个文件操作符   分别为 0  1  2 对应 stdin ，stdout， stderr 。<br>在 /proc/self/fd 中 可以看到 这三个三个对应文件</p><p><img src="/articles/d7c52fa4/9.jpg" alt="img"> </p><p>输出到这三个文件的内容都会显示出来。只是因为显示器作为最常用的输出设备而被绑定。</p><p>我们可以exec 指令自行定义、绑定文件操作符，文件操作符一般从3–（n-1）都可以随便使用<br>此处的n 为 ulimit -n 的定义值得<br><img src="/articles/d7c52fa4/10.jpg" alt="img"> </p><p>可以看到 我的 n值为1024 ，所以文件操作符只能使用 0-1023，可自行定义的 就只能是 3-1023 了。</p><p>直接上代码，然后根据代码分析每行代码的含义：<br><img src="/articles/d7c52fa4/11.jpg" alt="img"> </p><p><strong>代码解释</strong></p><p>第3行：  接受信号 2 （ctrl +C）做的操作。exec 1000&gt;&amp;-和exec 1000&lt;&amp;- 是关闭fd1000的意思，我们生成做绑                定时 可以用 exec 1000&lt;&gt;testfifo 来实现，但关闭时必须分开来写，&gt; 读的绑定，&lt; 标识写的绑定  &lt;&gt; 则                标识 对文件描述符 1000的所有操作等同于对管道文件testfifo的操作。</p><p>第5-7行：分别为 创建管道文件，文件操作符绑定，删除管道文件<br>　　　　  可能会有疑问，为什么不能直接使用管道文件呢？　<br>　　　　  事实上，这并非多此一举，刚才已经说明了管道文件的一个重要特性了，那就是读写必须同时存在<br>　　　　  缺少某一种操作，另一种操作就是滞留，而绑定文件操作符　正好解决了这个问题。</p><p>第9-12 行： 对文件操作符进行写入操作。通过一个for循环写入10个空行，这个10就是我们要定义的后台线程数                     量。<br>                     为什么写入空行而不是10个字符呢 ？<br>                     这是因为，管道文件的读取 是以行为单位的。<br><img src="/articles/d7c52fa4/12.jpg" alt="img"><br>                      当我们试图用 read 读取管道中的一个字符时，结果是不成功的，而刚才我们已经证实使用cat是可以                      读取的。</p><p>第17-24行：这里假定我们有100个任务，我们要实现的时 ，保证后台只有10个进程在同步运行 。read -u1000 的                     作用是：读取一次管道中的一行，在这儿就是读取一个空行。减少操作附中的一个空行之后，执行一                     次任务（当然是放到后台执行），需要注意的是，这个任务在后台执行结束以后会向文件操作符中写                    入一个空行，这就是重点所在，如果我们不在某种情况某种时刻向操作符中写入空行，那么结果就                    是：在后台放入10个任务之后，由于操作符中没有可读取的空行，导致  read -u1000 这儿 始终停顿。</p><p>后边的 就不用解释了。</p><p>贴下执行结果：<br><img src="/articles/d7c52fa4/13.jpg" alt="img"> </p><p>每次的停顿中都能看到  只有10个进程在运行<br>一共耗时50s  一共100个任务，每次10个 ，每个5s 正好50s。上边的结果图之所以这么有规律，这是因为我们所执行的100个任务耗时都是相同的。</p><p>比如，系统将第一批10个任务放入后台的过程所消耗的时间 几乎可以忽略不计，也就是说这10个任务几乎可以任务是同时运行，当然也就可以认为是同时结束了，而按照刚才的分析，一个任务结束时就会向文件描述符写入空行，既然是同时结束的，那么肯定是同时写入的空行，所以下一批任务又几乎同时运行，如此循环下去的。实际应用时，肯定不是这个样子的，比如，第一个放到后台执行的任务，是最耗时间的，那他肯定就会是最后一个执行完毕。所以，实际上来说，只要有一个任务完成，那么下一个任务就可以被放到后台并发执行了。  </p><h2 id="范例"><a href="#范例" class="headerlink" title="范例"></a>范例</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">trap</span> <span class="string">"exec 1000&gt;&amp;-;exec 1000&lt;&amp;-;exit 0"</span> 2</span><br><span class="line"></span><br><span class="line">mkfifo testfifo</span><br><span class="line"><span class="built_in">exec</span> 1000&lt;&gt;testfifo</span><br><span class="line">rm -fr testfifo</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>((n=1;n&lt;=10;n++))</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> &gt;&amp;1000</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">start=`date <span class="string">"+%s"</span>`</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>((i=1;i&lt;=100;i++))</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">read</span> -u1000</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"success <span class="variable">$i</span>"</span>;</span><br><span class="line">        sleep 5</span><br><span class="line"></span><br><span class="line">        <span class="built_in">echo</span> &gt;&amp;1000</span><br><span class="line">    &#125;&amp;</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">wait</span></span><br><span class="line"></span><br><span class="line">end=`date <span class="string">"+%s"</span>`</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Time: `expr <span class="variable">$end</span> - <span class="variable">$start</span>`"</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">exec</span> 1000&gt;&amp;-</span><br><span class="line"><span class="built_in">exec</span> 1000&lt;&amp;-</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;日常工作中编写shell脚本处理事务，很多时候需要一次性处理很多，需要用到循环，但是循环体内还是线性的，还是要一个个处理，这样并不会节省很多时间，只是节省了人工一次次输入的繁琐。但是对于提高处理能力，没有实质性的提高。这就需要考虑并发。但Shell中并没有真正意义的多线程，要实现多线程可以启动多个后端进程，最大程度利用cpu性能。即：多进程并发，本篇教程由浅入深详细介绍了shell中的多进程并发。&lt;/p&gt;
    
    </summary>
    
      <category term="编程积累" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/"/>
    
      <category term="Shell" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/Shell/"/>
    
    
      <category term="Shell" scheme="https://wandouduoduo.netlify.com/tags/Shell/"/>
    
  </entry>
  
  <entry>
    <title>Python多进程和多线程效率最优选</title>
    <link href="https://wandouduoduo.netlify.com/articles/4efb4de8.html"/>
    <id>https://wandouduoduo.netlify.com/articles/4efb4de8.html</id>
    <published>2019-11-29T08:51:15.000Z</published>
    <updated>2019-11-29T10:50:01.362Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>通过实例实验，比较用多线程和多进程耗时情况，并进行总结归纳，选择效率最高的方法。</p><a id="more"></a><h2 id="多线程和多进程测试"><a href="#多线程和多进程测试" class="headerlink" title="多线程和多进程测试"></a>多线程和多进程测试</h2><h4 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h4><ul><li>python3.6</li><li>threading和multiprocessing</li><li>四核+三星250G-850-SSD</li></ul><p>自从用多进程和多线程进行编程,一致没搞懂到底谁更快。网上很多都说python多进程更快，因为GIL(全局解释器锁)。但是我在写代码的时候，测试时间却是多线程更快，所以这到底是怎么回事？最近再做分词工作，原来的代码速度太慢，想提速，所以来探求一下有效方法(文末有代码和效果图)</p><p>这里先来一张程序的结果图，说明线程和进程谁更快</p><p><img src="/articles/4efb4de8/1.png" alt></p><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">并行是指两个或者多个事件在同一时刻发生。并发是指两个或多个事件在同一时间间隔内发生</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">线程是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一个程序的执行实例就是一个进程。</span><br></pre></td></tr></table></figure><h4 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h4><p>而python里面的多线程显然得拿到GIL,执行code，最后释放GIL。所以由于GIL，多线程的时候拿不到，实际上，它是并发实现，即多个事件，在同一时间间隔内发生。</p><p>但进程有独立GIL，所以可以并行实现。因此，针对多核CPU，理论上采用多进程更能有效利用资源。</p><h4 id="现实问题"><a href="#现实问题" class="headerlink" title="现实问题"></a>现实问题</h4><p>在网上的教程里面，经常能见到python多线程的身影。比如网络爬虫的教程、端口扫描的教程。</p><p>这里拿端口扫描来说，大家可以用多进程实现下面的脚本，会发现python多进程更快。那么不就是和我们分析相悖了吗？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys,threading</span><br><span class="line"><span class="keyword">from</span> socket <span class="keyword">import</span> *</span><br><span class="line"> </span><br><span class="line">host = <span class="string">"127.0.0.1"</span> <span class="keyword">if</span> len(sys.argv)==<span class="number">1</span> <span class="keyword">else</span> sys.argv[<span class="number">1</span>]</span><br><span class="line">portList = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">1000</span>)]</span><br><span class="line">scanList = []</span><br><span class="line">lock = threading.Lock()</span><br><span class="line">print(<span class="string">'Please waiting... From '</span>,host)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scanPort</span><span class="params">(port)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        tcp = socket(AF_INET,SOCK_STREAM)</span><br><span class="line">        tcp.connect((host,port))</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> lock.acquire():</span><br><span class="line">            print(<span class="string">'[+]port'</span>,port,<span class="string">'open'</span>)</span><br><span class="line">            lock.release()</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        tcp.close()</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> portList:</span><br><span class="line">    t = threading.Thread(target=scanPort,args=(p,))</span><br><span class="line">    scanList.append(t)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(portList)):</span><br><span class="line">    scanList[i].start()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(portList)):</span><br><span class="line">    scanList[i].join()</span><br></pre></td></tr></table></figure><h4 id="谁更快"><a href="#谁更快" class="headerlink" title="谁更快"></a>谁更快</h4><p>因为python锁的问题，线程进行锁竞争、切换线程，会消耗资源。所以，大胆猜测一下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在CPU密集型任务下，多进程更快，或者说效果更好；而IO密集型，多线程能有效提高效率。</span><br></pre></td></tr></table></figure><p>大家看一下下面的代码:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"> </span><br><span class="line">max_process = <span class="number">4</span></span><br><span class="line">max_thread = max_process</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(n,n2)</span>:</span></span><br><span class="line">    <span class="comment">#cpu密集型</span></span><br><span class="line">    <span class="keyword">for</span>  i <span class="keyword">in</span> range(<span class="number">0</span>,n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,(int)(n*n*n*n2)):</span><br><span class="line">            t = i*j</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">thread_main</span><span class="params">(n2)</span>:</span></span><br><span class="line">    thread_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,max_thread):</span><br><span class="line">        t = threading.Thread(target=fun,args=(<span class="number">50</span>,n2))</span><br><span class="line">        thread_list.append(t)</span><br><span class="line"> </span><br><span class="line">    start = time.time()</span><br><span class="line">    print(<span class="string">' [+] much thread start'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> thread_list:</span><br><span class="line">        i.start()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> thread_list:</span><br><span class="line">        i.join()</span><br><span class="line">    print(<span class="string">' [-] much thread use '</span>,time.time()-start,<span class="string">'s'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_main</span><span class="params">(n2)</span>:</span></span><br><span class="line">    p = multiprocessing.Pool(max_process)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,max_process):</span><br><span class="line">        p.apply_async(func = fun,args=(<span class="number">50</span>,n2))</span><br><span class="line">    start = time.time()</span><br><span class="line">    print(<span class="string">' [+] much process start'</span>)</span><br><span class="line">    p.close()<span class="comment">#关闭进程池</span></span><br><span class="line">    p.join()<span class="comment">#等待所有子进程完毕</span></span><br><span class="line">    print(<span class="string">' [-] much process use '</span>,time.time()-start,<span class="string">'s'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">"[++]When n=50,n2=0.1:"</span>)</span><br><span class="line">    thread_main(<span class="number">0.1</span>)</span><br><span class="line">    process_main(<span class="number">0.1</span>)</span><br><span class="line">    print(<span class="string">"[++]When n=50,n2=1:"</span>)</span><br><span class="line">    thread_main(<span class="number">1</span>)</span><br><span class="line">    process_main(<span class="number">1</span>)</span><br><span class="line">    print(<span class="string">"[++]When n=50,n2=10:"</span>)</span><br><span class="line">    thread_main(<span class="number">10</span>)</span><br><span class="line">    process_main(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>结果如下：</p><p><img src="/articles/4efb4de8/2.png" alt></p><p>可以看出来，当对cpu使用率越来越高的时候（代码循环越多的时候），差距越来越大。</p><p><strong>验证我们猜想(在CPU密集型任务下，多进程更快，或者说效果更好；而IO密集型，多线程能有效提高效率。</strong></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>CPU密集型代码(如：各种循环处理、计数等等)，适合用多进程<br>IO密集型代码(如：文件处理、网络爬虫等)，适合用多线程</p><h2 id="判断方法"><a href="#判断方法" class="headerlink" title="判断方法"></a>判断方法</h2><p>1，直接看CPU占用率或硬盘IO读写速度<br>2，大致上归纳：计算较多为CPU密集型；时间等待较多(如网络爬虫)为IO密集型。</p><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>对于IO密集型任务：</p><p>单进程单线程直接执行用时：10.0333秒<br>多线程执行用时：4.0156秒<br>多进程执行用时：5.0182秒<br>说明多线程适合IO密集型任务。</p><p>对于计算密集型任务</p><p>单进程单线程直接执行用时：10.0273秒<br>多线程执行用时：13.247秒<br>多进程执行用时：6.8377秒</p><p><strong>说明多进程适合计算密集型任务</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义全局变量Queue</span></span><br><span class="line">g_queue = multiprocessing.Queue()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_queue</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"init g_queue start"</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> g_queue.empty():</span><br><span class="line">        g_queue.get()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">for</span> _index <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        g_queue.put(_index)</span><br><span class="line">    print(<span class="string">"init g_queue end"</span>)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个IO密集型任务：利用time.sleep()</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">task_io</span><span class="params">(task_id)</span>:</span></span><br><span class="line">    print(<span class="string">"IOTask[%s] start"</span> % task_id)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> g_queue.empty():</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data = g_queue.get(block=<span class="literal">True</span>, timeout=<span class="number">1</span>)</span><br><span class="line">            print(<span class="string">"IOTask[%s] get data: %s"</span> % (task_id, data))</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> excep:</span><br><span class="line">            print(<span class="string">"IOTask[%s] error: %s"</span> % (task_id, str(excep)))</span><br><span class="line">    print(<span class="string">"IOTask[%s] end"</span> % task_id)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">g_search_list = list(range(<span class="number">10000</span>))</span><br><span class="line"><span class="comment"># 定义一个计算密集型任务：利用一些复杂加减乘除、列表查找等</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">task_cpu</span><span class="params">(task_id)</span>:</span></span><br><span class="line">    print(<span class="string">"CPUTask[%s] start"</span> % task_id)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> g_queue.empty():</span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">            count += pow(<span class="number">3</span>*<span class="number">2</span>, <span class="number">3</span>*<span class="number">2</span>) <span class="keyword">if</span> i <span class="keyword">in</span> g_search_list <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data = g_queue.get(block=<span class="literal">True</span>, timeout=<span class="number">1</span>)</span><br><span class="line">            print(<span class="string">"CPUTask[%s] get data: %s"</span> % (task_id, data))</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> excep:</span><br><span class="line">            print(<span class="string">"CPUTask[%s] error: %s"</span> % (task_id, str(excep)))</span><br><span class="line">    print(<span class="string">"CPUTask[%s] end"</span> % task_id)</span><br><span class="line">    <span class="keyword">return</span> task_id</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">"cpu count:"</span>, multiprocessing.cpu_count(), <span class="string">"\n"</span>)</span><br><span class="line">    print(<span class="string">u"========== 直接执行IO密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    task_io(<span class="number">0</span>)</span><br><span class="line">    print(<span class="string">u"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 多线程执行IO密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    thread_list = [threading.Thread(target=task_io, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        <span class="keyword">if</span> t.is_alive():</span><br><span class="line">            t.join()</span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 多进程执行IO密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    process_list = [multiprocessing.Process(target=task_io, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(multiprocessing.cpu_count())]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        p.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        <span class="keyword">if</span> p.is_alive():</span><br><span class="line">            p.join()</span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 直接执行CPU密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    task_cpu(<span class="number">0</span>)</span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 多线程执行CPU密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    thread_list = [threading.Thread(target=task_cpu, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        <span class="keyword">if</span> t.is_alive():</span><br><span class="line">            t.join()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 多进程执行cpu密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    process_list = [multiprocessing.Process(target=task_cpu, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(multiprocessing.cpu_count())]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        p.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        <span class="keyword">if</span> p.is_alive():</span><br><span class="line">            p.join()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;通过实例实验，比较用多线程和多进程耗时情况，并进行总结归纳，选择效率最高的方法。&lt;/p&gt;
    
    </summary>
    
      <category term="编程积累" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/"/>
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/Python/"/>
    
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Multiprocessing基础</title>
    <link href="https://wandouduoduo.netlify.com/articles/9a80786c.html"/>
    <id>https://wandouduoduo.netlify.com/articles/9a80786c.html</id>
    <published>2019-11-29T07:40:05.000Z</published>
    <updated>2019-11-29T10:50:01.360Z</updated>
    
    <content type="html"><![CDATA[<p>multiprocessing是Python的标准模块，它既可以用来编写多进程，也可以用来编写多线程。如果是多线程的话，用multiprocessing.dummy即可，用法与multiprocessing基本相同，这里主要介绍多进程的用法，欢迎纠错。</p><h2 id="Multiprocessing介绍"><a href="#Multiprocessing介绍" class="headerlink" title="Multiprocessing介绍"></a>Multiprocessing介绍</h2><h5 id="为什么要使用python多进程？"><a href="#为什么要使用python多进程？" class="headerlink" title="为什么要使用python多进程？"></a>为什么要使用python<strong>多进程</strong>？</h5><p>因为python使用全局解释器锁(GIL)，他会将进程中的线程序列化，也就是多核cpu实际上并不能达到并行提高速度的目的，而使用多进程则是不受限的，所以实际应用中都是推荐多进程的。<br>如果每个子进程执行需要消耗的时间非常短（执行+1操作等），这不必使用多进程，因为进程的启动关闭也会耗费资源。<br>当然使用多进程往往是用来处理CPU密集型（科学计算）的需求，如果是IO密集型（文件读取，爬虫等）则可以使用多线程去处理。</p><a id="more"></a><h2 id="multiprocessing常用组件及功能"><a href="#multiprocessing常用组件及功能" class="headerlink" title="multiprocessing常用组件及功能"></a>multiprocessing常用组件及功能</h2><p>创建管理进程模块：</p><ul><li>Process (用于创建进程模块）</li><li>Pool（用于创建管理进程池）</li><li>Queue（用于进程通信，资源共享）</li><li>Value，Array（用于进程通信，资源共享）</li><li>Pipe（用于管道通信）</li><li>Manager（用于资源共享）</li></ul><p>同步子进程模块：</p><ul><li>Condition</li><li>Event</li><li>Lock</li><li>RLock</li><li>Semaphore</li></ul><h2 id="Multiprocessing进程管理模块"><a href="#Multiprocessing进程管理模块" class="headerlink" title="Multiprocessing进程管理模块"></a>Multiprocessing进程管理模块</h2><p>说明：由于篇幅有限，模块具体用法结束请参考每个模块的具体链接。</p><h5 id="Process模块"><a href="#Process模块" class="headerlink" title="Process模块"></a>Process模块</h5><p>Process模块用来创建子进程，是Multiprocessing核心模块，使用方式与Threading类似，可以实现多进程的创建，启动，关闭等操作。</p><h5 id="Pool模块"><a href="#Pool模块" class="headerlink" title="Pool模块"></a>Pool模块</h5><p>Pool模块是用来创建管理进程池的，当子进程非常多且需要控制子进程数量时可以使用此模块。</p><h5 id="Queue模块"><a href="#Queue模块" class="headerlink" title="Queue模块"></a>Queue模块</h5><p>Queue模块用来控制进程安全，与线程中的Queue用法一样。</p><h5 id="Pipe模块"><a href="#Pipe模块" class="headerlink" title="Pipe模块"></a>Pipe模块</h5><p>Pipe模块用来管道操作。</p><h5 id="Manager模块"><a href="#Manager模块" class="headerlink" title="Manager模块"></a>Manager模块</h5><p>Manager模块常与Pool模块一起使用，作用是共享资源。</p><h4 id="Multiprocessing同步进程模块"><a href="#Multiprocessing同步进程模块" class="headerlink" title="Multiprocessing同步进程模块"></a>Multiprocessing同步进程模块</h4><h5 id="Lock模块"><a href="#Lock模块" class="headerlink" title="Lock模块"></a>Lock模块</h5><p>作用：当多个进程需要访问共享资源的时候，Lock可以用来避免访问的冲突。</p><p>具体场景：所有的任务在打印的时候都会向同一个标准输出(stdout)输出。这样输出的字符会混合在一起，无法阅读。使用Lock同步，在一个任务输出完成之后，再允许另一个任务输出，可以避免多个任务同时向终端输出。</p><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process, Lock  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">l</span><span class="params">(lock, num)</span>:</span>      </span><br><span class="line">lock.acquire()      </span><br><span class="line"><span class="keyword">print</span> <span class="string">"Hello Num: %s"</span> % (num)      </span><br><span class="line">lock.release()  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:      </span><br><span class="line">lock = Lock()  <span class="comment">#这个一定要定义为全局    </span></span><br><span class="line"><span class="keyword">for</span> num <span class="keyword">in</span> range(<span class="number">20</span>):          </span><br><span class="line">Process(target=l, args=(lock, num)).start()  <span class="comment">#这个类似多线程中的threading，但是进程太多了，控制不了。</span></span><br></pre></td></tr></table></figure><h5 id="Semaphore模块"><a href="#Semaphore模块" class="headerlink" title="Semaphore模块"></a>Semaphore模块</h5><p>作用：用来控制对共享资源的访问数量，例如池的最大连接数。</p><h5 id="Event模块"><a href="#Event模块" class="headerlink" title="Event模块"></a>Event模块</h5><p>作用：用来实现进程间同步通信。</p><h2 id="Multiprocessing-dummy多线程"><a href="#Multiprocessing-dummy多线程" class="headerlink" title="Multiprocessing.dummy多线程"></a>Multiprocessing.dummy多线程</h2><p>Multiprocessing.dummy用法与Multiprocessing用法基本相同，只不过是用来创建多线程。</p><h2 id="使用Multiprocessing疑问"><a href="#使用Multiprocessing疑问" class="headerlink" title="使用Multiprocessing疑问"></a>使用Multiprocessing疑问</h2><ul><li><em>启动多进程的代码一定要放在</em> if <strong>name</strong>==”<strong>main</strong>“: <em>后面吗？</em></li></ul><p>　　解答：windows系统下，想要启动一个子进程，必须加上<em>if *</em>name<strong>==”</strong>main*<em>“:</em>，linux则不需要。</p><ul><li><em>父进程中的全局变量能被子进程共享吗？</em></li></ul><p>　　解答：不行，因为每个进程享有独立的内存数据，如果想要共享资源，可以使用Manage类，或者Queue等模块。</p><ul><li><em>子进程能结束其他子进程或父进程吗？如果能，怎么通过子进程去结束所有进程?</em></li></ul><p>　　解答：此需求可以稍作修改：所有的子进程都是为了完成一件事情，而当某个子进程完成该事情后，父进程就该结束所有子进程，请问该怎么做？此时结束所有子进程的操作可以交给父进程去做，因为子进程想要结束另外的子进程比较难实现。<br>　　那么问题就又变成了父进程什么时候该结束所有进程？<br>　　其中一个思路是<em>获取每个子进程的返回值</em>，一旦有返回True（结束的标记），则立马结束所有进程；<br>　　另外一种思路是<em>使用共享资源</em>，父进程可以一直去判断这个公共资源，一旦子进程将它改变，则结束所有子进程。（推荐使用前者，因为多进程中不推荐使用资源共享）</p><ul><li><em>子进程中还能再创建子进程吗？</em></li></ul><p>解答：可以，子进程可以再创建进程，线程中也可以创建进程。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;multiprocessing是Python的标准模块，它既可以用来编写多进程，也可以用来编写多线程。如果是多线程的话，用multiprocessing.dummy即可，用法与multiprocessing基本相同，这里主要介绍多进程的用法，欢迎纠错。&lt;/p&gt;
&lt;h2 id=&quot;Multiprocessing介绍&quot;&gt;&lt;a href=&quot;#Multiprocessing介绍&quot; class=&quot;headerlink&quot; title=&quot;Multiprocessing介绍&quot;&gt;&lt;/a&gt;Multiprocessing介绍&lt;/h2&gt;&lt;h5 id=&quot;为什么要使用python多进程？&quot;&gt;&lt;a href=&quot;#为什么要使用python多进程？&quot; class=&quot;headerlink&quot; title=&quot;为什么要使用python多进程？&quot;&gt;&lt;/a&gt;为什么要使用python&lt;strong&gt;多进程&lt;/strong&gt;？&lt;/h5&gt;&lt;p&gt;因为python使用全局解释器锁(GIL)，他会将进程中的线程序列化，也就是多核cpu实际上并不能达到并行提高速度的目的，而使用多进程则是不受限的，所以实际应用中都是推荐多进程的。&lt;br&gt;如果每个子进程执行需要消耗的时间非常短（执行+1操作等），这不必使用多进程，因为进程的启动关闭也会耗费资源。&lt;br&gt;当然使用多进程往往是用来处理CPU密集型（科学计算）的需求，如果是IO密集型（文件读取，爬虫等）则可以使用多线程去处理。&lt;/p&gt;
    
    </summary>
    
      <category term="编程积累" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/"/>
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/Python/"/>
    
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python之多进程详解</title>
    <link href="https://wandouduoduo.netlify.com/articles/a5c1f14c.html"/>
    <id>https://wandouduoduo.netlify.com/articles/a5c1f14c.html</id>
    <published>2019-11-29T07:34:06.000Z</published>
    <updated>2019-11-29T10:50:01.364Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>Python中的multiprocess提供了Process类，实现进程相关的功能。但是它基于fork机制，因此不被windows平台支持。想要在windows中运行，必须使用 if <strong>name</strong> == ‘<strong>main</strong>: 的方式)。并且多进程就是开启多个进程，每个进程之间是不会互相通信互相干扰的，适用于密集计算。</p><a id="more"></a><h2 id="案例一-基础用法"><a href="#案例一-基础用法" class="headerlink" title="案例一 基础用法"></a>案例一 基础用法</h2><p>多进程的使用方法和多线程使用方法基本一样，所以如果你会多线程用法多进程也就懂了，有一点要注意，定义多进程，然后传递参数的时候，如果是有一个参数就是用args=（i，）一定要加上逗号，如果有两个或者以上的参数就不用这样。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">import multiprocessing</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line">def fun(i):</span><br><span class="line">    print sys.path</span><br><span class="line">    print sys.version_info</span><br><span class="line">    print sys.platform</span><br><span class="line">    print sys.long_info</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    m = multiprocessing.Process(target=fun,args=(1,))</span><br><span class="line">    m.start()</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[&apos;E:\\python27\\python study&apos;, &apos;E:\\python27&apos;, &apos;C:\\windows\\SYSTEM32\\python27.zip&apos;, &apos;F:\\Python27\\DLLs&apos;, &apos;F:\\Python27\\lib&apos;, &apos;F:\\Python27\\lib\\plat-win&apos;, &apos;F:\\Python27\\lib\\lib-tk&apos;, &apos;F:\\Python27&apos;, &apos;F:\\Python27\\lib\\site-packages&apos;, &apos;F:\\Python27\\lib\\site-packages\\certifi-2017.7.27.1-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\idna-2.6-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\pypiwin32-219-py2.7-win-amd64.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\future-0.16.0-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\dis3-0.1.1-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\macholib-1.8-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\pefile-2017.9.3-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\altgraph-0.14-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\beautifulsoup4-4.6.0-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\chardet-3.0.4-py2.7.egg&apos;]</span><br><span class="line">sys.version_info(major=2, minor=7, micro=14, releaselevel=&apos;final&apos;, serial=0)</span><br><span class="line">win32</span><br><span class="line">sys.long_info(bits_per_digit=30, sizeof_digit=4)</span><br></pre></td></tr></table></figure><h2 id="案例二-数据通信"><a href="#案例二-数据通信" class="headerlink" title="案例二 数据通信"></a>案例二 数据通信</h2><p>ipc：就是进程间的通信模式，常用的一半是socke，rpc，pipe和消息队列等。</p><p>multiprocessing提供了threading包中没有的IPC(比如Pipe和Queue)，效率上更高。应优先考虑Pipe和Queue，避免使用Lock/Event/Semaphore/Condition等同步方式 (因为它们占据的不是用户进程的资源)。</p><h4 id="使用Array共享数据"><a href="#使用Array共享数据" class="headerlink" title="使用Array共享数据"></a>使用Array共享数据</h4><p>对于Array数组类，括号内的“i”表示它内部的元素全部是int类型，而不是指字符“i”，数组内的元素可以预先指定，也可以只指定数组的长度。Array类在实例化的时候必须指定数组的数据类型和数组的大小，类似temp = Array(‘i’, 5)。对于数据类型有下面的对应关系：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&apos;c&apos;: ctypes.c_char, &apos;u&apos;: ctypes.c_wchar,</span><br><span class="line">&apos;b&apos;: ctypes.c_byte, &apos;B&apos;: ctypes.c_ubyte,</span><br><span class="line">&apos;h&apos;: ctypes.c_short, &apos;H&apos;: ctypes.c_ushort,</span><br><span class="line">&apos;i&apos;: ctypes.c_int, &apos;I&apos;: ctypes.c_uint,</span><br><span class="line">&apos;l&apos;: ctypes.c_long, &apos;L&apos;: ctypes.c_ulong,</span><br><span class="line">&apos;f&apos;: ctypes.c_float, &apos;d&apos;: ctypes.c_double</span><br></pre></td></tr></table></figure><p>代码实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Process</span><br><span class="line">from multiprocessing import Array</span><br><span class="line"></span><br><span class="line">def func(i,temp):</span><br><span class="line">    temp[0] += 100</span><br><span class="line">    print(&quot;进程%s &quot; % i, &apos; 修改数组第一个元素后-----&gt;&apos;, temp[0])</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    temp = Array(&apos;i&apos;, [1, 2, 3, 4])</span><br><span class="line">    for i in range(10):</span><br><span class="line">        p = Process(target=func, args=(i, temp))</span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">进程2   修改数组第一个元素后-----&gt; 101</span><br><span class="line">进程4   修改数组第一个元素后-----&gt; 201</span><br><span class="line">进程5   修改数组第一个元素后-----&gt; 301</span><br><span class="line">进程3   修改数组第一个元素后-----&gt; 401</span><br><span class="line">进程1   修改数组第一个元素后-----&gt; 501</span><br><span class="line">进程6   修改数组第一个元素后-----&gt; 601</span><br><span class="line">进程9   修改数组第一个元素后-----&gt; 701</span><br><span class="line">进程8   修改数组第一个元素后-----&gt; 801</span><br><span class="line">进程0   修改数组第一个元素后-----&gt; 901</span><br><span class="line">进程7   修改数组第一个元素后-----&gt; 1001</span><br></pre></td></tr></table></figure><h4 id="使用Manager共享数据"><a href="#使用Manager共享数据" class="headerlink" title="使用Manager共享数据"></a>使用Manager共享数据</h4><p>通过Manager类也可以实现进程间数据的共享，主要用于线程池之间通信，Manager()返回的manager对象提供一个服务进程，使得其他进程可以通过代理的方式操作Python对象。manager对象支持 list, dict, Namespace, Lock, RLock, Semaphore, BoundedSemaphore, Condition, Event, Barrier, Queue, Value ,Array等多种格式。</p><p>代码实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Process</span><br><span class="line">from multiprocessing import Manager</span><br><span class="line"></span><br><span class="line">def func(i, dic):</span><br><span class="line">    dic[&quot;num&quot;] = 100+i</span><br><span class="line">    print(dic.items())</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    dic = Manager().dict()</span><br><span class="line">    for i in range(10):</span><br><span class="line">        p = Process(target=func, args=(i, dic))</span><br><span class="line">        p.start()</span><br><span class="line">        p.join()</span><br></pre></td></tr></table></figure><h4 id="使用queues的Queue类共享数据"><a href="#使用queues的Queue类共享数据" class="headerlink" title="使用queues的Queue类共享数据"></a>使用queues的Queue类共享数据</h4><p>multiprocessing是一个包，它内部有一个queues模块，提供了一个Queue队列类，可以实现进程间的数据共享，如下例所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import multiprocessing</span><br><span class="line">from multiprocessing import Process</span><br><span class="line">from multiprocessing import queues</span><br><span class="line"></span><br><span class="line">def func(i, q):</span><br><span class="line">    ret = q.get()</span><br><span class="line">    print(&quot;进程%s从队列里获取了一个%s，然后又向队列里放入了一个%s&quot; % (i, ret, i))</span><br><span class="line">    q.put(i)</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    lis = queues.Queue(20, ctx=multiprocessing)</span><br><span class="line">    lis.put(0)</span><br><span class="line">    for i in range(10):</span><br><span class="line">        p = Process(target=func, args=(i, lis,))</span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">进程1从队列里获取了一个0，然后又向队列里放入了一个1</span><br><span class="line">进程4从队列里获取了一个1，然后又向队列里放入了一个4</span><br><span class="line">进程2从队列里获取了一个4，然后又向队列里放入了一个2</span><br><span class="line">进程6从队列里获取了一个2，然后又向队列里放入了一个6</span><br><span class="line">进程0从队列里获取了一个6，然后又向队列里放入了一个0</span><br><span class="line">进程5从队列里获取了一个0，然后又向队列里放入了一个5</span><br><span class="line">进程9从队列里获取了一个5，然后又向队列里放入了一个9</span><br><span class="line">进程7从队列里获取了一个9，然后又向队列里放入了一个7</span><br><span class="line">进程3从队列里获取了一个7，然后又向队列里放入了一个3</span><br><span class="line">进程8从队列里获取了一个3，然后又向队列里放入了一个8</span><br></pre></td></tr></table></figure><p>例如来跑多进程对一批IP列表进行运算，运算后的结果都存到Queue队列里面，这个就必须使用multiprocessing提供的Queue来实现</p><p>关于queue和Queue，在Python库中非常频繁的出现，很容易就搞混淆了。甚至是multiprocessing自己还有一个Queue类(大写的Q)和的Manager类中提供的Queue方法，一样能实现消息队列queues.Queue的功能，导入方式是from multiprocessing import Queue，前者Queue用于多个进程间通信，和queues.Queue()差不多，后者Manager().queue用于进程池之间通信。</p><h4 id="使用pipe实现进程间通信"><a href="#使用pipe实现进程间通信" class="headerlink" title="使用pipe实现进程间通信"></a>使用pipe实现进程间通信</h4><p>pipe只能适用于两个进程间通信，queue则没这个限制，他有两个方法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">receive_pi = Pipe()</span><br><span class="line"># 定义变量，用来获取数据</span><br><span class="line">send_pi = Pipe()</span><br><span class="line"># 用来发送数据</span><br></pre></td></tr></table></figure><p>具体例子如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pipe,Process</span><br><span class="line">import time</span><br><span class="line">def produce(pipe):</span><br><span class="line">    pipe.send(&apos;666&apos;)</span><br><span class="line">    time.sleep(1)</span><br><span class="line">def consumer(pipe):</span><br><span class="line">    print(pipe.recv())</span><br><span class="line">    # 有些类似socket的recv方法</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    send_pi,recv_pi = Pipe()</span><br><span class="line">    my_pro = Process(target=produce,args=(send_pi,))</span><br><span class="line">    my_con = Process(target=consumer,args=(recv_pi,))</span><br><span class="line">    my_pro.start()</span><br><span class="line">    my_con.start()</span><br><span class="line">    my_pro.join()</span><br><span class="line">    my_con.join()</span><br></pre></td></tr></table></figure><p>pipe相当于queue的一个子集，只能服务两个进程，pipe的性能高于queue。</p><h2 id="案例三-进程锁"><a href="#案例三-进程锁" class="headerlink" title="案例三 进程锁"></a>案例三 进程锁</h2><p>一般来说每个进程使用单独的空间，不必加进程锁的，但是如果你需要先实现进程数据共享，<strong>使用案例二中的代码</strong>，又害怕造成数据抢夺和脏数据的问题。就可以设置进程锁，与threading类似，在multiprocessing里也有同名的锁类RLock，Lock，Event，Condition和 Semaphore，连用法都是一样样的。</p><p><strong>如果有多个进程要上锁，使用multiprocessing.Manager().BoundedSemaphore(1)</strong></p><p>代码实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Process</span><br><span class="line">from multiprocessing import Array</span><br><span class="line">from multiprocessing import RLock, Lock, Event, Condition, Semaphore</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">def func(i,lis,lc):</span><br><span class="line">    lc.acquire()</span><br><span class="line">    lis[0] = lis[0] - 1</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    print(&apos;say hi&apos;, lis[0])</span><br><span class="line">    lc.release()</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    array = Array(&apos;i&apos;, 1)</span><br><span class="line">    array[0] = 10</span><br><span class="line">    lock = RLock()</span><br><span class="line">    for i in range(10):</span><br><span class="line">        p = Process(target=func, args=(i, array, lock))</span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">say hi 9</span><br><span class="line">say hi 8</span><br><span class="line">say hi 7</span><br><span class="line">say hi 6</span><br><span class="line">say hi 5</span><br><span class="line">say hi 4</span><br><span class="line">say hi 3</span><br><span class="line">say hi 2</span><br><span class="line">say hi 1</span><br><span class="line">say hi 0</span><br></pre></td></tr></table></figure><h2 id="案例四-进程池"><a href="#案例四-进程池" class="headerlink" title="案例四 进程池"></a>案例四 进程池</h2><p>from multiprocessing import Pool导入就行，非常容易使用的。进程池内部维护了一个进程序列，需要时就去进程池中拿取一个进程，如果进程池序列中没有可供使用的进程，那么程序就会等待，直到进程池中有可用进程为止。</p><ol><li>apply() 同步执行（串行）</li><li>apply_async() 异步执行（并行）</li><li>terminate() 立刻关闭进程池</li><li>join() 主进程等待所有子进程执行完毕。必须在close或terminate()之后。</li><li>close() 等待所有进程结束后，才关闭进程池。</li></ol><p>代码实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">import time</span><br><span class="line">def func(args):</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    print(&quot;正在执行进程 &quot;, args)</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    p = Pool(5)     # 创建一个包含5个进程的进程池</span><br><span class="line">    for i in range(30):</span><br><span class="line">        # 有30个任务</span><br><span class="line">        p.apply_async(func=func, args=(i,))</span><br><span class="line">        # 异步执行，并发。这里不用target，要用func</span><br><span class="line">    p.close()           # 等子进程执行完毕后关闭进程池</span><br><span class="line">    # time.sleep(2)</span><br><span class="line">    # p.terminate()     # 立刻关闭进程池</span><br><span class="line">    p.join()</span><br></pre></td></tr></table></figure><p>from multiprocessing.dummy import Pool as ThreadPool 是多线程进程池，绑定一个cpu核心。from multiprocessing import Pool多进程，运行于多个cpu核心。multiprocessing 是多进程模块， 而multiprocessing.dummy是以相同API实现的多线程模块。<br>没有绕过GIL情况下，多线程一定受GIL限制。</p><p>代码实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing.dummy import Pool as tp</span><br><span class="line">def fun(i):</span><br><span class="line">    print i+i+i+i</span><br><span class="line"></span><br><span class="line">list_i=[range(100)]</span><br><span class="line"></span><br><span class="line">px = tp(processes=8)</span><br><span class="line"># 开启8个线程池</span><br><span class="line">px.map(fun,list_i)</span><br><span class="line">px.close()</span><br><span class="line">px.join()</span><br></pre></td></tr></table></figure><p>使用dummy方法可以不用<strong>name</strong>=’<strong>main</strong>‘，并且用法很简单，开启线程池用法一样，需要注意的是导入的参数，要在一个列表中导入。比如你有一批数据要放进这个线程池，就直接把这批数据放在一个列表中。</p><h2 id="案例五-爬虫进程池"><a href="#案例五-爬虫进程池" class="headerlink" title="案例五 爬虫进程池"></a>案例五 爬虫进程池</h2><p>案例来自<a href="https://morvanzhou.github.io/tutorials/data-manipulation/scraping/4-01-distributed-scraping/" target="_blank" rel="noopener">莫凡</a></p><h4 id="什么是分布式爬虫"><a href="#什么是分布式爬虫" class="headerlink" title="什么是分布式爬虫"></a>什么是分布式爬虫</h4><p>分布式爬虫主要是为了非常有效率的抓取网页, 我们的程序一般是单线程跑的, 指令也是一条条处理的, 每执行完一条指令才能跳到下一条. 那么在爬虫的世界里, 这里存在着一个问题.</p><p>如果你已经顺利地执行过了前几节的爬虫代码, 你会发现, 有时候代码运行的时间大部分都花在了下载网页上. 有时候不到一秒能下载好一张网页的 HTML, 有时候却要几十秒. 而且非要等到 HTML 下载好了以后, 才能执行网页分析等步骤. 这非常浪费时间.</p><p>如果我们能合理利用计算资源, 在下载一部分网页的时候就已经开始分析另一部分网页了. 这将会大大节省整个程序的运行时间. 又或者, 我们能同时下载多个网页, 同时分析多个网页, 这样就有种事倍功半的效用. 分布式爬虫的体系有很多种, 处理优化的问题也是多样的. 这里有一篇博客可以当做扩展阅读, 来了解当今比较流行的分布式爬虫框架.</p><h4 id="我们的分布式爬虫"><a href="#我们的分布式爬虫" class="headerlink" title="我们的分布式爬虫"></a>我们的分布式爬虫</h4><p>而今天我们想搭建的这一个爬虫, 就是同时下载, 同时分析的这一种类型的分布式爬虫. 虽然算不上特别优化的框架, 但是概念理解起来比较容易. 我有尝试过徒手写高级一点的分布式爬虫, 但是写起来非常麻烦. 我琢磨了一下, 打算给大家介绍的这种分布式爬虫代码也较好写, 而且效率比普通爬虫快了3.5倍. 我也特地画了张图给大家解释一下要搭建的分布式爬虫.</p><p><img src="/articles/a5c1f14c/1.png" alt="img"></p><p>主要来说, 我们最开始有一个网页, 比如说是莫烦Python的首页, 然后首页中有很多 url, 我们使用多进程 (Python多进程教程) 同时开始下载这些 url, 得到这些 url 的 HTML 以后, 同时开始解析 (比如 BeautifulSoup) 网页内容. 在网页中寻找这个网站还没有爬过的链接. 最终爬完整个 莫烦 Python 网站所有页面.</p><p>有了这种思路, 我们就可以开始写代码了. 你可以在我的 Github 一次性观看全部代码.</p><p>首先 import 全部要用的模块, 并规定一个主页. 注意, 我用这份代码测试我内网的网站(速度不受外网影响) 所以使用的 base_url 是 “<a href="http://127.0.0.1:4000/”" target="_blank" rel="noopener">http://127.0.0.1:4000/”</a>, 如果你要爬 莫烦Python, 你的 base_url 要是 “<a href="https://morvanzhou.github.io/”" target="_blank" rel="noopener">https://morvanzhou.github.io/”</a> (下载速度会受外网影响).</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import multiprocessing as mp</span><br><span class="line">import time</span><br><span class="line">from urllib.request import urlopen, urljoin</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line"># base_url = &quot;http://127.0.0.1:4000/&quot;</span><br><span class="line">base_url = &apos;https://morvanzhou.github.io/&apos;</span><br></pre></td></tr></table></figure><p>我们定义两个功能, 一个是用来爬取网页的(crawl), 一个是解析网页的(parse). 有了前几节内容的铺垫, 你应该能一言看懂下面的代码. crawl() 用 urlopen 来打开网页, 我用的内网测试, 所以为了体现下载网页的延迟, 添加了一个 time.sleep(0.1) 的下载延迟. 返回原始的 HTML 页面, parse() 就是在这个 HTML 页面中找到需要的信息, 我们用 BeautifulSoup 找 (BeautifulSoup 教程). 返回找到的信息.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def crawl(url):</span><br><span class="line">    response = urlopen(url)</span><br><span class="line">    # time.sleep(0.1)             # slightly delay for downloading</span><br><span class="line">    return response.read().decode()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def parse(html):</span><br><span class="line">    soup = BeautifulSoup(html, &apos;lxml&apos;)</span><br><span class="line">    urls = soup.find_all(&apos;a&apos;, &#123;&quot;href&quot;: re.compile(&apos;^/.+?/$&apos;)&#125;)</span><br><span class="line">    title = soup.find(&apos;h1&apos;).get_text().strip()</span><br><span class="line">    page_urls = set([urljoin(base_url, url[&apos;href&apos;]) for url in urls])   # 去重</span><br><span class="line">    url = soup.find(&apos;meta&apos;, &#123;&apos;property&apos;: &quot;og:url&quot;&#125;)[&apos;content&apos;]</span><br><span class="line">    return title, page_urls, url</span><br></pre></td></tr></table></figure><p>网页中爬取中, 肯定会爬到重复的网址, 为了去除掉这些重复, 我们使用 python 的 set 功能. 定义两个 set, 用来搜集爬过的网页和没爬过的.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">unseen = set([base_url,])</span><br><span class="line">seen = set()</span><br></pre></td></tr></table></figure><h4 id="测试普通爬法"><a href="#测试普通爬法" class="headerlink" title="测试普通爬法"></a>测试普通爬法</h4><p>为了对比效果, 我们将在下面对比普通的爬虫和这种分布式的效果. 如果是普通爬虫, 我简化了一下接下来的代码, 将一些不影响的代码去除掉了, 如果你想看全部的代码, 请来到我的 Github. 我们用循环一个个 crawl unseen 里面的 url, 爬出来的 HTML 放到 parse 里面去分析得到结果. 接着就是更新 seen 和 unseen 这两个集合了.</p><p>特别注意: 任何网站都是有一个服务器压力的, 如果你爬的过于频繁, 特别是使用多进程爬取或异步爬取, 一次性提交请求给服务器太多次, 这将可能会使得服务器瘫痪, 你可能再也看不到莫烦 Python 了. 所以为了安全起见, 我限制了爬取数量(restricted_crawl=True). 因为我测试使用的是内网 “<a href="http://127.0.0.1:4000/”" target="_blank" rel="noopener">http://127.0.0.1:4000/”</a> 所以不会有这种压力. 你在以后的爬网页中, 会经常遇到这样的爬取次数的限制 (甚至被封号). 我以前爬 github 时就被限制成一小时只能爬60页.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># DON&apos;T OVER CRAWL THE WEBSITE OR YOU MAY NEVER VISIT AGAIN</span><br><span class="line">if base_url != &quot;http://127.0.0.1:4000/&quot;:</span><br><span class="line">    restricted_crawl = True</span><br><span class="line">else:</span><br><span class="line">    restricted_crawl = False</span><br><span class="line"></span><br><span class="line">while len(unseen) != 0:                 # still get some url to visit</span><br><span class="line">    if restricted_crawl and len(seen) &gt;= 20:</span><br><span class="line">        break</span><br><span class="line">    htmls = [crawl(url) for url in unseen]</span><br><span class="line">    results = [parse(html) for html in htmls]</span><br><span class="line"></span><br><span class="line">    seen.update(unseen)         # seen the crawled</span><br><span class="line">    unseen.clear()              # nothing unseen</span><br><span class="line"></span><br><span class="line">    for title, page_urls, url in results:</span><br><span class="line">        unseen.update(page_urls - seen)     # get new url to crawl</span><br></pre></td></tr></table></figure><p>使用这种单线程的方法, 在我的内网上面爬, 爬完整个 莫烦Python, 一共消耗 52.3秒. 接着我们把它改成多进程分布式.</p><h4 id="测试分布式爬法"><a href="#测试分布式爬法" class="headerlink" title="测试分布式爬法"></a>测试分布式爬法</h4><p>还是上一个 while 循环, 首先我们创建一个进程池(Pool). 不太懂进程池的朋友看过来. 然后我们修改得到 htmls 和 results 的两句代码. 其他都不变, 只将这两个功能给并行了. 我在这里写的都是简化代码, 你可以在这里 看到完整代码.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">pool = mp.Pool(4)</span><br><span class="line">while len(unseen) != 0:</span><br><span class="line">    # htmls = [crawl(url) for url in unseen]</span><br><span class="line">    # ---&gt;</span><br><span class="line">    crawl_jobs = [pool.apply_async(crawl, args=(url,)) for url in unseen]</span><br><span class="line">    htmls = [j.get() for j in crawl_jobs]</span><br><span class="line"></span><br><span class="line">    # results = [parse(html) for html in htmls]</span><br><span class="line">    # ---&gt;</span><br><span class="line">    parse_jobs = [pool.apply_async(parse, args=(html,)) for html in htmls]</span><br><span class="line">    results = [j.get() for j in parse_jobs]</span><br></pre></td></tr></table></figure><p>还是在内网测试, 只用了 16.3秒!! 这可比上面的单线程爬虫快了3.5倍. 而且我还不是在外网测试的. 如果在外网, 爬取一张网页的时间更长, 使用多进程会更加有效率, 节省的时间更多.</p><h2 id="各模块作用"><a href="#各模块作用" class="headerlink" title="各模块作用"></a>各模块作用</h2><h4 id="Process介绍"><a href="#Process介绍" class="headerlink" title="Process介绍"></a>Process介绍</h4><p>构造方法:</p><ol><li>Process([group [, target [, name [, args [, kwargs]]]]])</li><li>group: 线程组，目前还没有实现，库引用中提示必须是None；</li><li>target: 要执行的方法；</li><li>name: 进程名；</li><li>args/kwargs: 要传入方法的参数。</li></ol><p>实例方法:</p><ol><li>is_alive()：返回进程是否在运行。</li><li>join([timeout])：阻塞当前上下文环境的进程程，直到调用此方法的进程终止或到达指定的3. timeout（可选参数）。</li><li>start()：进程准备就绪，等待CPU调度。</li><li>run()：strat()调用run方法，如果实例进程时未制定传入target，这star执行t默认run()方法。</li><li>terminate()：不管任务是否完成，立即停止工作进程。</li></ol><p>属性：</p><ol><li>authkey</li><li>daemon：和线程的setDeamon功能一样（将父进程设置为守护进程，当父进程结束时，子进程也结束）。</li><li>exitcode(进程在运行时为None、如果为–N，表示被信号N结束）。</li><li>name：进程名字。</li><li>pid：进程号。</li></ol><h4 id="Pool介绍"><a href="#Pool介绍" class="headerlink" title="Pool介绍"></a>Pool介绍</h4><p>Multiprocessing.Pool可以提供指定数量的进程供用户调用，当有新的请求提交到pool中时，如果池还没有满，那么就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到规定最大值，那么该请求就会等待，直到池中有进程结束，才会创建新的进程来执行它。在共享资源时，只能使用Multiprocessing.Manager类，而不能使用Queue或者Array。Pool类用于需要执行的目标很多，而手动限制进程数量又太繁琐时，如果目标少且不用控制进程数量则可以用Process类。</p><p>构造方法：</p><ol><li>Pool([processes[, initializer[, initargs[, maxtasksperchild[, context]]]]])</li><li>processes ：使用的工作进程的数量，如果processes是None那么使用 os.cpu_count()返回的数量。</li><li>initializer： 如果initializer是None，那么每一个工作进程在开始的时候会调用initializer(*initargs)。</li><li>maxtasksperchild：工作进程退出之前可以完成的任务数，完成后用一个新的工作进程来替代原进程，来让闲置的资源被释放。maxtasksperchild默认是None，意味着只要Pool存在工作进程就会一直存活。</li><li>context: 用在制定工作进程启动时的上下文，一般使用 multiprocessing.Pool() 或者一个context对象的Pool()方法来创建一个池，两种方法都适当的设置了context。</li></ol><p>实例方法：</p><ol><li>apply_async(func[, args[, kwds[, callback]]]) 它是非阻塞。</li><li>apply(func[, args[, kwds]])是阻塞的</li><li>close() 关闭pool，使其不在接受新的任务。</li><li>terminate() 关闭pool，结束工作进程，不在处理未完成的任务。</li><li>join() 主进程阻塞，等待子进程的退出， join方法要在close或terminate之后使用。</li></ol><p>Pool使用方法</p><p>Pool+map函数</p><p>说明：此写法缺点在于只能通过map向函数传递一个参数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">def test(i):</span><br><span class="line">    print i</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    lists=[1,2,3]</span><br><span class="line">    pool=Pool(processes=2) #定义最大的进程数</span><br><span class="line">    pool.map(test,lists)        #p必须是一个可迭代变量。</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure><p>异步进程池（非阻塞）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">def test(i):</span><br><span class="line">    print i</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    pool = Pool(processes=10)</span><br><span class="line">    for i  in xrange(500):</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        For循环中执行步骤：</span><br><span class="line">        （1）循环遍历，将500个子进程添加到进程池（相对父进程会阻塞）</span><br><span class="line">        （2）每次执行10个子进程，等一个子进程执行完后，立马启动新的子进程。（相对父进程不阻塞）</span><br><span class="line"></span><br><span class="line">        apply_async为异步进程池写法。</span><br><span class="line">        异步指的是启动子进程的过程，与父进程本身的执行（print）是异步的，而For循环中往进程池添加子进程的过程，与父进程本身的执行却是同步的。</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        pool.apply_async(test, args=(i,)) #维持执行的进程总数为10，当一个进程执行完后启动一个新进程.       </span><br><span class="line">    print “test”</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure><p>执行顺序：For循环内执行了2个步骤，第一步：将500个对象放入进程池（阻塞）。第二步：同时执行10个子进程（非阻塞），有结束的就立即添加，维持10个子进程运行。（apply_async方法的会在执行完for循环的添加步骤后，直接执行后面的print语句，而apply方法会等所有进程池中的子进程运行完以后再执行后面的print语句）</p><p>注意：调用join之前，先调用close或者terminate方法，否则会出错。执行完close后不会有新的进程加入到pool,join函数等待所有子进程结束。</p><p>同步进程池（阻塞）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">def test(p):</span><br><span class="line">       print p</span><br><span class="line">       time.sleep(3)</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    pool = Pool(processes=10)</span><br><span class="line">    for i  in xrange(500):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    实际测试发现，for循环内部执行步骤：</span><br><span class="line">    （1）遍历500个可迭代对象，往进程池放一个子进程</span><br><span class="line">    （2）执行这个子进程，等子进程执行完毕，再往进程池放一个子进程，再执行。（同时只执行一个子进程）</span><br><span class="line">    for循环执行完毕，再执行print函数。</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">        pool.apply(test, args=(i,))   #维持执行的进程总数为10，当一个进程执行完后启动一个新进程.</span><br><span class="line">    print “test”</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure><p>说明：for循环内执行的步骤顺序，往进程池中添加一个子进程，执行子进程，等待执行完毕再添加一个子进程…..等500个子进程都执行完了，再执行print “test”。（从结果来看，并没有多进程并发）</p><h4 id="子进程返回值"><a href="#子进程返回值" class="headerlink" title="子进程返回值"></a>子进程返回值</h4><p>在实际使用多进程的时候，可能需要获取到子进程运行的返回值。如果只是用来存储，则可以将返回值保存到一个数据结构中；如果需要判断此返回值，从而决定是否继续执行所有子进程，则会相对比较复杂。另外在Multiprocessing中，可以利用Process与Pool创建子进程，这两种用法在获取子进程返回值上的写法上也不相同。这篇中，我们直接上代码，分析多进程中获取子进程返回值的不同用法，以及优缺点。</p><p>初级用法（Pool）</p><p>目的：存储子进程返回值</p><p>说明：如果只是单纯的存储子进程返回值，则可以使用Pool的apply_async异步进程池；当然也可以使用Process，用法与threading中的相同，这里只介绍前者。</p><p>实例：当进程池中所有子进程执行完毕后，输出每个子进程的返回值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">def test(p):     </span><br><span class="line">    return p</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    pool = Pool(processes=10)</span><br><span class="line">    result=[]</span><br><span class="line">    for i  in xrange(50000):</span><br><span class="line">       &apos;&apos;&apos;</span><br><span class="line">       for循环执行流程：</span><br><span class="line">       （1）添加子进程到pool，并将这个对象（子进程）添加到result这个列表中。（此时子进程并没有运行）</span><br><span class="line">       （2）执行子进程（同时执行10个）</span><br><span class="line">       &apos;&apos;&apos;</span><br><span class="line">       result.append(pool.apply_async(test, args=(i,)))#维持执行的进程总数为10，当一个进程执行完后添加新进程.       </span><br><span class="line">    pool.join()</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    遍历result列表，取出子进程对象，访问get()方法，获取返回值。（此时所有子进程已执行完毕）</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    for i in result:</span><br><span class="line">        print i.get()</span><br></pre></td></tr></table></figure><p>错误写法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for i  in xrange(50000):</span><br><span class="line">   t=pool.apply_async(test, args=(i,)))</span><br><span class="line">   print t.get()</span><br></pre></td></tr></table></figure><p>说明：这样会造成阻塞，因为get()方法只能等子进程运行完毕后才能调用成功，否则会一直阻塞等待。如果写在for循环内容，相当于变成了同步，执行效率将会非常低。</p><p>高级用法（Pool）<br>目的：父进程实时获取子进程返回值，以此为标记结束所有进程。</p><p>实例（一）<br>执行子进程的过程中，不断获取返回值并校验，如果返回值为True则结果所有进程。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">import Queue</span><br><span class="line">import time</span><br><span class="line">def test(p):</span><br><span class="line">    time.sleep(0.001)</span><br><span class="line">    if p==10000:</span><br><span class="line">        return True</span><br><span class="line">    else:</span><br><span class="line">        return False</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    pool = Pool(processes=10)</span><br><span class="line">    q=Queue.Queue()</span><br><span class="line">    for i  in xrange(50000):</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        将子进程对象存入队列中。</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        q.put(pool.apply_async(test, args=(i,)))#维持执行的进程总数为10，当一个进程执行完后添加新进程.       </span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    因为这里使用的为pool.apply_async异步方法，因此子进程执行的过程中，父进程会执行while，获取返回值并校验。</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    while 1:</span><br><span class="line">        if q.get().get():</span><br><span class="line">            pool.terminate() #结束进程池中的所有子进程。</span><br><span class="line">            break</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure><p>说明：总共要执行50000个子进程（并发数量为10），当其中一个子进程返回True时，结束进程池。因为使用了apply_async为异步进程，因此在执行完for循环的添加子进程操作后（只是添加并没有执行完所有的子进程），可以直接执行while代码，实时判断子进程返回值是否有True，有的话结束所有进程。</p><p>优点：不必等到所有子进程结束再结束程序，只要得到想要的结果就可以提前结束，节省资源。</p><p>不足：当需要执行的子进程非常大时，不适用，因为for循环在添加子进程时，要花费很长的时间，虽然是异步，但是也需要等待for循环添加子进程操作结束才能执行while代码，因此会比较慢。</p><p>实例（二）</p><p>多线程+多进程，添加执行子进程的过程中，不断获取返回值并校验，如果返回值为True则结果所有进程。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">import Queue</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">def test(p):</span><br><span class="line">    time.sleep(0.001)</span><br><span class="line">    if p==10000:</span><br><span class="line">        return True</span><br><span class="line">    else:</span><br><span class="line">        return False</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    result=Queue.Queue() #队列</span><br><span class="line">    pool = Pool()</span><br><span class="line">    def pool_th():</span><br><span class="line">        for i  in xrange(50000000): ##这里需要创建执行的子进程非常多</span><br><span class="line">            try:</span><br><span class="line">                result.put(pool.apply_async(test, args=(i,)))</span><br><span class="line">            except:</span><br><span class="line">                break</span><br><span class="line">    def result_th():</span><br><span class="line">        while 1:</span><br><span class="line">            a=result.get().get() #获取子进程返回值</span><br><span class="line">            if a:</span><br><span class="line">                pool.terminate() #结束所有子进程</span><br><span class="line">                break</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    利用多线程，同时运行Pool函数创建执行子进程，以及运行获取子进程返回值函数。</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    t1=threading.Thread(target=pool_th)</span><br><span class="line">    t2=threading.Thread(target=result_th)</span><br><span class="line">    t1.start()</span><br><span class="line">    t2.start()</span><br><span class="line">    t1.join()</span><br><span class="line">    t2.join()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure><p>执行流程：利用多线程，创建一个执行pool_th函数线程，一个执行result_th函数线程，pool_th函数用来添加进程池，开启进程执行功能函数并将子进程对象存入队列，而result_th()函数用来不停地从队列中取子进程对象，调用get（）方法获取返回值。等发现其中存在子进程的返回值为True时，结束所有进程，最后结束线程。</p><p>优点：弥补了实例（一）的不足，即使for循环的子进程数量很多，也能提高性能，因为for循环与判断子进程返回值同时进行。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;Python中的multiprocess提供了Process类，实现进程相关的功能。但是它基于fork机制，因此不被windows平台支持。想要在windows中运行，必须使用 if &lt;strong&gt;name&lt;/strong&gt; == ‘&lt;strong&gt;main&lt;/strong&gt;: 的方式)。并且多进程就是开启多个进程，每个进程之间是不会互相通信互相干扰的，适用于密集计算。&lt;/p&gt;
    
    </summary>
    
      <category term="编程积累" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/"/>
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/Python/"/>
    
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python之多线程详解</title>
    <link href="https://wandouduoduo.netlify.com/articles/e0b461d5.html"/>
    <id>https://wandouduoduo.netlify.com/articles/e0b461d5.html</id>
    <published>2019-11-29T07:28:51.000Z</published>
    <updated>2019-11-29T10:50:01.363Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>线程是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务，多线程就是在一个进程中的多个线程，如果使用多线程默认开启一个主线程，按照程序需求自动开启多个线程(也可以自己定义线程数)。</p><a id="more"></a><h2 id="多线程知识点"><a href="#多线程知识点" class="headerlink" title="多线程知识点"></a>多线程知识点</h2><ol><li>Python 在设计之初就考虑到要在解释器的主循环中，同时只有一个线程在执行，即在任意时刻，只有一个线程在解释器中运行。对Python 虚拟机的访问由全局解释器锁（GIL）来控制，正是这个锁能保证同一时刻只有一个线程在运行。</li><li>多线程共享主进程的资源，所以可能还会改变其中的变量，这个时候就要加上线程锁，每次执行完一个线程在执行下一个线程。</li><li>因为每次只能有一个线程运行，多线程怎么实现的呢？Python解释器中一个线程做完了任务然后做IO(文件读写)操作的时候，这个线程就退出，然后下一个线程开始运行，循环之。</li><li>当你读完上面三点你就知道多线程如何运行起来，并且知道多线程常用在那些需要等待然后执行的应用程序上(比如爬虫读取到数据，然后保存的时候下一个线程开始启动)也就是说多线程适用于IO密集型的任务量（文件存储，网络通信）。</li><li>注意一点，定义多线程，然后传递参数的时候，如果是有一个参数就是用args=（i，）一定要加上逗号，如果有两个或者以上的参数就不用这样。</li></ol><h2 id="代码实例"><a href="#代码实例" class="headerlink" title="代码实例"></a>代码实例</h2><h4 id="案例一-多线程核心用法"><a href="#案例一-多线程核心用法" class="headerlink" title="案例一 多线程核心用法"></a>案例一 多线程核心用法</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line"></span><br><span class="line">def loop():</span><br><span class="line">    #定义一个要循环的函数，当然后面肯定会定义好几个函数</span><br><span class="line">    print &apos;thread %s is running...&apos; % threading.current_thread().name</span><br><span class="line">    #threading.current_thread().name就是当前线程的名字  在声明线程的时候可以自定义子线程的名字</span><br><span class="line">    n = 0</span><br><span class="line">    while n &lt; 10:</span><br><span class="line">        n = n + 1</span><br><span class="line">        print &apos;%s &gt;&gt;&gt; %s&apos; % (threading.current_thread().name, n)</span><br><span class="line">        #输出当前线程名字  和循环的参数n</span><br><span class="line">    print &apos;thread %s ended.&apos; % threading.current_thread().name</span><br><span class="line">print &apos;thread %s is running...&apos; % threading.current_thread().name</span><br><span class="line"></span><br><span class="line">#下面的一部分就是threading的核心用法</span><br><span class="line">#包括target name args 之类的 一般我只用targer=你定义的函数名</span><br><span class="line">t = threading.Thread(target=loop, name=&apos;线程名:&apos;)</span><br><span class="line"># 在这里就申明了这个线程的名字</span><br><span class="line">t.start()</span><br><span class="line">#开始</span><br><span class="line">t.join()</span><br><span class="line">#关于join的相关信息我会在后面的代码详说</span><br><span class="line">print &apos;thread %s ended.&apos; % threading.current_thread().name</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">thread MainThread is running...</span><br><span class="line">thread 线程名: is running...</span><br><span class="line">线程名: &gt;&gt;&gt; 1</span><br><span class="line">线程名: &gt;&gt;&gt; 2</span><br><span class="line">线程名: &gt;&gt;&gt; 3</span><br><span class="line">线程名: &gt;&gt;&gt; 4</span><br><span class="line">线程名: &gt;&gt;&gt; 5</span><br><span class="line">线程名: &gt;&gt;&gt; 6</span><br><span class="line">线程名: &gt;&gt;&gt; 7</span><br><span class="line">线程名: &gt;&gt;&gt; 8</span><br><span class="line">线程名: &gt;&gt;&gt; 9</span><br><span class="line">线程名: &gt;&gt;&gt; 10</span><br><span class="line">thread 线程名: ended.</span><br><span class="line">thread MainThread ended.</span><br></pre></td></tr></table></figure><h4 id="案例二-线程锁"><a href="#案例二-线程锁" class="headerlink" title="案例二 线程锁"></a>案例二 线程锁</h4><p>前面有说到过，多线程是共享内存的，所以其中的变量如果发生了改变的话就会改变后边的变量，导致异常，这个时候可以加上线程锁。线程锁的概念就是主要这个线程运行完后再运行下一个线程。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line"></span><br><span class="line">def loop():</span><br><span class="line">    l.acquire()</span><br><span class="line">    # 这里相当于把线程加了锁，目前只允许这一个线程运行</span><br><span class="line">    print &apos;thread %s is running...&apos; % threading.current_thread().name</span><br><span class="line">    #threading.current_thread().name就是当前线程的名字  在声明线程的时候可以自定义子线程的名字</span><br><span class="line">    n = 0</span><br><span class="line">    while n &lt; 10:</span><br><span class="line">        n = n + 1</span><br><span class="line">        print &apos;%s &gt;&gt;&gt; %s&apos; % (threading.current_thread().name, n)</span><br><span class="line">        #输出当前线程名字  和循环的参数n</span><br><span class="line">    print &apos;thread %s ended.&apos; % threading.current_thread().name</span><br><span class="line">    l.release()</span><br><span class="line">    # 这里是把线程锁解开，可以再运行写一个线程</span><br><span class="line">print &apos;thread %s is running...&apos; % threading.current_thread().name</span><br><span class="line"></span><br><span class="line">#下面的一部分就是threading的核心用法</span><br><span class="line">#包括target name args 之类的 一般我只用targer=你定义的函数名</span><br><span class="line">t = threading.Thread(target=loop, name=&apos;线程名:&apos;)</span><br><span class="line">l = threading.Lock()</span><br><span class="line"># 这里申明一个线程锁</span><br><span class="line">t.start()</span><br><span class="line">#开始</span><br><span class="line">t.join()</span><br><span class="line">#关于join的相关信息我会在后面的代码详说</span><br><span class="line">print &apos;thread %s ended.&apos; % threading.current_thread().name</span><br></pre></td></tr></table></figure><p>使用线程锁后，程序按照一个一个有序执行。其中lock还有Rlock的方法，RLock允许在同一线程中被多次acquire。而Lock却不允许这种情况。否则会出现死循环，程序不知道解哪一把锁。注意：如果使用RLock，那么acquire和release必须成对出现，即调用了n次acquire，必须调用n次的release才能真正释放所占用的锁</p><h4 id="案例三-join-方法的使用"><a href="#案例三-join-方法的使用" class="headerlink" title="案例三 join()方法的使用"></a>案例三 join()方法的使用</h4><p>在多线程中，每个线程自顾执行自己的任务，当最后一个线程运行完毕后再退出，所以这个时候如果你要打印信息的话，会看到打印出来的信息错乱无章，有的时候希望主线程能够等子线程执行完毕后在继续执行，就是用join()方法。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line">t00 = time.time()</span><br><span class="line"># 获取当前时间戳</span><br><span class="line">def cs1():</span><br><span class="line">    time0 = time.time()</span><br><span class="line">    for x in range(9):</span><br><span class="line">        print x + time.time()-time0</span><br><span class="line">        # 计算用了多少时间</span><br><span class="line">        print threading.current_thread().name</span><br><span class="line">        # 打印这个线程名字</span><br><span class="line"></span><br><span class="line">def cs2():</span><br><span class="line">    for x1 in range(6,9):</span><br><span class="line">        print x1</span><br><span class="line">        print threading.current_thread().name</span><br><span class="line"></span><br><span class="line">threads=[]</span><br><span class="line"># 定义一个空的列表</span><br><span class="line">t1 = threading.Thread(target=cs1)</span><br><span class="line">t2 = threading.Thread(target=cs2)</span><br><span class="line">threads.append(t1)</span><br><span class="line">threads.append(t2)</span><br><span class="line"># 把这两个线程的任务加载到这个列表中</span><br><span class="line">for x in threads:</span><br><span class="line">    x.start()</span><br><span class="line">    # 然后执行，这个案例很常用，就是有多个函数要多线程执行的时候用到</span><br><span class="line">    # 如果一个程序有多个函数，但是你只想其中的某一个或者某两个函数多线程，用法一样加入空的列表即可</span><br><span class="line">    x.join()</span><br><span class="line">    #线程堵塞 先运行第一个在运行第二个</span><br><span class="line">#x.join()</span><br><span class="line">#注意你的join放在这里是没有意义的，和不加join一样。线程不堵塞  但是会出现不匀称的表现  并且会修改不同线程中的变量</span><br><span class="line">print &apos;use time.&#123;&#125;&apos;.format(time.time()-t00)</span><br></pre></td></tr></table></figure><p>关于setDaemon()的概念就是：主线程A中，创建了子线程B，并且在主线程A中调用了B.setDaemon(),这个的意思是，把主线程A设置为守护线程，这时候，要是主线程A执行结束了，就不管子线程B是否完成,一并和主线程A退出.这就是setDaemon方法的含义，这基本和join是相反的。此外，还有个要特别注意的：必须在start() 方法调用之前设置，如果不设置为守护线程，程序会被无限挂起。</p><h4 id="案例四-线程锁之信号Semaphore"><a href="#案例四-线程锁之信号Semaphore" class="headerlink" title="案例四 线程锁之信号Semaphore"></a>案例四 线程锁之信号Semaphore</h4><p>类名：BoundedSemaphore。这种锁允许一定数量的线程同时更改数据，它不是互斥锁。比如地铁安检，排队人很多，工作人员只允许一定数量的人进入安检区，其它的人继续排队。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">import threading</span><br><span class="line"></span><br><span class="line">def run(n, se):</span><br><span class="line">    se.acquire()</span><br><span class="line">    print(&quot;run the thread: %s&quot; % n)</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    se.release()</span><br><span class="line"></span><br><span class="line"># 设置允许5个线程同时运行</span><br><span class="line">semaphore = threading.BoundedSemaphore(5)</span><br><span class="line">for i in range(20):</span><br><span class="line">    t = threading.Thread(target=run, args=(i,semaphore))</span><br><span class="line">    t.start()</span><br></pre></td></tr></table></figure><p>运行后，可以看到5个一批的线程被放行。</p><h4 id="案例五-线程锁之事件Event"><a href="#案例五-线程锁之事件Event" class="headerlink" title="案例五 线程锁之事件Event"></a>案例五 线程锁之事件Event</h4><p>事件线程锁的运行机制：<br>全局定义了一个Flag，如果Flag的值为False，那么当程序执行wait()方法时就会阻塞，如果Flag值为True，线程不再阻塞。这种锁，类似交通红绿灯（默认是红灯），它属于在红灯的时候一次性阻挡所有线程，在绿灯的时候，一次性放行所有排队中的线程。<br>事件主要提供了四个方法set()、wait()、clear()和is_set()。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">调用clear()方法会将事件的Flag设置为False。</span><br><span class="line">调用set()方法会将Flag设置为True。</span><br><span class="line">调用wait()方法将等待“红绿灯”信号。</span><br><span class="line">is_set():判断当前是否&quot;绿灯放行&quot;状态</span><br></pre></td></tr></table></figure><p>下面是一个模拟红绿灯，然后汽车通行的例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">#利用Event类模拟红绿灯</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">event = threading.Event()</span><br><span class="line"># 定义一个事件的对象</span><br><span class="line">def lighter():</span><br><span class="line">    green_time = 5       </span><br><span class="line">    # 绿灯时间</span><br><span class="line">    red_time = 5         </span><br><span class="line">    # 红灯时间</span><br><span class="line">    event.set()          </span><br><span class="line">    # 初始设为绿灯</span><br><span class="line">    while True:</span><br><span class="line">        print(&quot;\33[32;0m 绿灯亮...\033[0m&quot;)</span><br><span class="line">        time.sleep(green_time)</span><br><span class="line">        event.clear()</span><br><span class="line">        print(&quot;\33[31;0m 红灯亮...\033[0m&quot;)</span><br><span class="line">        time.sleep(red_time)</span><br><span class="line">        event.set()</span><br><span class="line"></span><br><span class="line">def run(name):</span><br><span class="line">    while True:</span><br><span class="line">        if event.is_set():      </span><br><span class="line">        # 判断当前是否&quot;放行&quot;状态</span><br><span class="line">            print(&quot;一辆[%s] 呼啸开过...&quot; % name)</span><br><span class="line">            time.sleep(1)</span><br><span class="line">        else:</span><br><span class="line">            print(&quot;一辆[%s]开来，看到红灯，无奈的停下了...&quot; % name)</span><br><span class="line">            event.wait()</span><br><span class="line">            print(&quot;[%s] 看到绿灯亮了，瞬间飞起.....&quot; % name)</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    light = threading.Thread(target=lighter,)</span><br><span class="line">    light.start()</span><br><span class="line">        for name in [&apos;奔驰&apos;, &apos;宝马&apos;, &apos;奥迪&apos;]:</span><br><span class="line">        car = threading.Thread(target=run, args=(name,))</span><br><span class="line">        car.start()</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">绿灯亮...</span><br><span class="line">一辆[奔驰] 呼啸开过...</span><br><span class="line">一辆[宝马] 呼啸开过...</span><br><span class="line">一辆[奥迪] 呼啸开过...</span><br><span class="line">一辆[奥迪] 呼啸开过...</span><br><span class="line">......</span><br><span class="line"> 红灯亮...</span><br><span class="line">一辆[宝马]开来，看到红灯，无奈的停下了...</span><br><span class="line">一辆[奥迪]开来，看到红灯，无奈的停下了...</span><br><span class="line">一辆[奔驰]开来，看到红灯，无奈的停下了...</span><br><span class="line">绿灯亮...</span><br><span class="line">[奥迪] 看到绿灯亮了，瞬间飞起.....</span><br><span class="line">一辆[奥迪] 呼啸开过...</span><br><span class="line">[奔驰] 看到绿灯亮了，瞬间飞起.....</span><br><span class="line">一辆[奔驰] 呼啸开过...</span><br><span class="line">[宝马] 看到绿灯亮了，瞬间飞起.....</span><br><span class="line">一辆[宝马] 呼啸开过...</span><br><span class="line">一辆[奥迪] 呼啸开过...</span><br><span class="line">......</span><br></pre></td></tr></table></figure><h4 id="案例六-线程锁之条件Condition"><a href="#案例六-线程锁之条件Condition" class="headerlink" title="案例六 线程锁之条件Condition"></a>案例六 线程锁之条件Condition</h4><p>Condition称作条件锁，依然是通过acquire()/release()加锁解锁。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wait([timeout])方法将使线程进入Condition的等待池等待通知，并释放锁。使用前线程必须已获得锁定，否则将抛出异常。</span><br><span class="line">notify()方法将从等待池挑选一个线程并通知，收到通知的线程将自动调用acquire()尝试获得锁定（进入锁定池），其他线程仍然在等待池中。调用这个方法不会释放锁定。使用前线程必须已获得锁定，否则将抛出异常。</span><br><span class="line">notifyAll()方法将通知等待池中所有的线程，这些线程都将进入锁定池尝试获得锁定。调用这个方法不会释放锁定。使用前线程必须已获得锁定，否则将抛出异常。</span><br></pre></td></tr></table></figure><p>实际案例</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">num = 0</span><br><span class="line">con = threading.Condition()</span><br><span class="line">class Foo(threading.Thread):</span><br><span class="line"></span><br><span class="line">    def __init__(self, name, action):</span><br><span class="line">        super(Foo, self).__init__()</span><br><span class="line">        self.name = name</span><br><span class="line">        self.action = action</span><br><span class="line"></span><br><span class="line">    def run(self):</span><br><span class="line">        global num</span><br><span class="line">        con.acquire()</span><br><span class="line">        print(&quot;%s开始执行...&quot; % self.name)</span><br><span class="line">        while True:</span><br><span class="line">            if self.action == &quot;add&quot;:</span><br><span class="line">                num += 1</span><br><span class="line">            elif self.action == &apos;reduce&apos;:</span><br><span class="line">                num -= 1</span><br><span class="line">            else:</span><br><span class="line">                exit(1)</span><br><span class="line">            print(&quot;num当前为：&quot;, num)</span><br><span class="line">            time.sleep(1)</span><br><span class="line">            if num == 5 or num == 0:</span><br><span class="line">                print(&quot;暂停执行%s！&quot; % self.name)</span><br><span class="line">                con.notify()</span><br><span class="line">                con.wait()</span><br><span class="line">                print(&quot;%s开始执行...&quot; % self.name)</span><br><span class="line">        con.release()</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    a = Foo(&quot;线程A&quot;, &apos;add&apos;)</span><br><span class="line">    b = Foo(&quot;线程B&quot;, &apos;reduce&apos;)</span><br><span class="line">    a.start()</span><br><span class="line">    b.start()</span><br></pre></td></tr></table></figure><p>如果不强制停止，程序会一直执行下去，并循环下面的结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">线程A开始执行...</span><br><span class="line">num当前为： 1</span><br><span class="line">num当前为： 2</span><br><span class="line">num当前为： 3</span><br><span class="line">num当前为： 4</span><br><span class="line">num当前为： 5</span><br><span class="line">暂停执行线程A！</span><br><span class="line">线程B开始执行...</span><br><span class="line">num当前为： 4</span><br><span class="line">num当前为： 3</span><br><span class="line">num当前为： 2</span><br><span class="line">num当前为： 1</span><br><span class="line">num当前为： 0</span><br><span class="line">暂停执行线程B！</span><br><span class="line">线程A开始执行...</span><br><span class="line">num当前为： 1</span><br><span class="line">num当前为： 2</span><br><span class="line">num当前为： 3</span><br><span class="line">num当前为： 4</span><br><span class="line">num当前为： 5</span><br><span class="line">暂停执行线程A！</span><br><span class="line">线程B开始执行...</span><br></pre></td></tr></table></figure><h4 id="案例-七定时器"><a href="#案例-七定时器" class="headerlink" title="案例 七定时器"></a>案例 七定时器</h4><p>定时器Timer类是threading模块中的一个小工具，用于指定n秒后执行某操作。一个简单但很实用的东西。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from threading import Timer</span><br><span class="line">def hello():</span><br><span class="line">    print(&quot;hello, world&quot;)</span><br><span class="line">t = Timer(1, hello)</span><br><span class="line"># 表示1秒后执行hello函数</span><br><span class="line">t.start()</span><br></pre></td></tr></table></figure><h4 id="案例八-通过with语句使用线程锁"><a href="#案例八-通过with语句使用线程锁" class="headerlink" title="案例八 通过with语句使用线程锁"></a>案例八 通过with语句使用线程锁</h4><p>类似于上下文管理器，所有的线程锁都有一个加锁和释放锁的动作，非常类似文件的打开和关闭。在加锁后，如果线程执行过程中出现异常或者错误，没有正常的释放锁，那么其他的线程会造到致命性的影响。通过with上下文管理器，可以确保锁被正常释放。其格式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">with some_lock:</span><br><span class="line">    # 执行任务...</span><br></pre></td></tr></table></figure><p>这相当于：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">some_lock.acquire()</span><br><span class="line">try:</span><br><span class="line">    # 执行任务..</span><br><span class="line">finally:</span><br><span class="line">    some_lock.release()</span><br></pre></td></tr></table></figure><h2 id="threading-的常用属性"><a href="#threading-的常用属性" class="headerlink" title="threading 的常用属性"></a>threading 的常用属性</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">current_thread()    返回当前线程</span><br><span class="line">active_count()    返回当前活跃的线程数，1个主线程+n个子线程</span><br><span class="line">get_ident()    返回当前线程</span><br><span class="line">enumerater()    返回当前活动 Thread 对象列表</span><br><span class="line">main_thread()    返回主 Thread 对象</span><br><span class="line">settrace(func)    为所有线程设置一个 trace 函数</span><br><span class="line">setprofile(func)    为所有线程设置一个 profile 函数</span><br><span class="line">stack_size([size])    返回新创建线程栈大小；或为后续创建的线程设定栈大小为 size</span><br><span class="line">TIMEOUT_MAX    Lock.acquire(), RLock.acquire(), Condition.wait() 允许的最大超时时间</span><br></pre></td></tr></table></figure><h2 id="线程池-threadingpool"><a href="#线程池-threadingpool" class="headerlink" title="线程池 threadingpool"></a>线程池 threadingpool</h2><p>在使用多线程处理任务时也不是线程越多越好。因为在切换线程的时候，需要切换上下文环境，线程很多的时候，依然会造成CPU的大量开销。为解决这个问题，线程池的概念被提出来了。</p><p>预先创建好一个数量较为优化的线程组，在需要的时候立刻能够使用，就形成了线程池。在Python中，没有内置的较好的线程池模块，需要自己实现或使用第三方模块。<br>需要注意的是，线程池的整体构造需要自己精心设计，比如某个函数定义存在多少个线程，某个函数定义什么时候运行这个线程，某个函数定义去获取线程获取任务，某个线程设置线程守护(线程锁之类的)，等等…<br>在网上找了几个案例，供大家学习参考。</p><p>下面是一个简单的线程池：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import queue</span><br><span class="line">import time</span><br><span class="line">import threading</span><br><span class="line">class MyThreadPool:</span><br><span class="line">    def __init__(self, maxsize=5):</span><br><span class="line">        self.maxsize = maxsize</span><br><span class="line">        self._pool = queue.Queue(maxsize)   # 使用queue队列，创建一个线程池</span><br><span class="line">        for _ in range(maxsize):</span><br><span class="line">            self._pool.put(threading.Thread)</span><br><span class="line">    def get_thread(self):</span><br><span class="line">        return self._pool.get()</span><br><span class="line"></span><br><span class="line">    def add_thread(self):</span><br><span class="line">        self._pool.put(threading.Thread)</span><br><span class="line"></span><br><span class="line">def run(i, pool):</span><br><span class="line">    print(&apos;执行任务&apos;, i)</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    pool.add_thread()   # 执行完毕后，再向线程池中添加一个线程类</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    pool = MyThreadPool(5)  # 设定线程池中最多只能有5个线程类</span><br><span class="line">    for i in range(20):</span><br><span class="line">        t = pool.get_thread()   # 每个t都是一个线程类</span><br><span class="line">        obj = t(target=run, args=(i, pool)) # 这里的obj才是正真的线程对象</span><br><span class="line">        obj.start()</span><br><span class="line">    print(&quot;活动的子线程数： &quot;, threading.active_count()-1)</span><br></pre></td></tr></table></figure><p>分析一下上面的代码：</p><ol><li>实例化一个MyThreadPool的对象，在其内部建立了一个最多包含5个元素的阻塞队列，并一次性将5个Thread类型添加进去。</li><li>循环100次，每次从pool中获取一个thread类，利用该类，传递参数，实例化线程对象。</li><li>在run()方法中，每当任务完成后，又为pool添加一个thread类，保持队列中始终有5个thread类。</li><li>一定要分清楚，代码里各个变量表示的内容。t表示的是一个线程类，也就是threading.Thread，而obj才是正真的线程对象。</li></ol><p>上面的例子是把线程类当做元素添加到队列内，从而实现的线程池。这种方法比较糙，每个线程使用后就被抛弃，并且一开始就将线程开到满，因此性能较差。下面是一个相对好一点的例子，在这个例子中，队列里存放的不再是线程类，而是任务，线程池也不是一开始就直接开辟所有线程，而是根据需要，逐步建立，直至池满。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">一个基于thread和queue的线程池，以任务为队列元素，动态创建线程，重复利用线程，</span><br><span class="line">通过close和terminate方法关闭线程池。</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">import queue</span><br><span class="line">import threading</span><br><span class="line">import contextlib</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"># 创建空对象,用于停止线程</span><br><span class="line">StopEvent = object()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def callback(status, result):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    根据需要进行的回调函数，默认不执行。</span><br><span class="line">    :param status: action函数的执行状态</span><br><span class="line">    :param result: action函数的返回值</span><br><span class="line">    :return:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def action(thread_name, arg):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    真实的任务定义在这个函数里</span><br><span class="line">    :param thread_name: 执行该方法的线程名</span><br><span class="line">    :param arg: 该函数需要的参数</span><br><span class="line">    :return:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 模拟该函数执行了0.1秒</span><br><span class="line">    time.sleep(0.1)</span><br><span class="line">    print(&quot;第%s个任务调用了线程 %s，并打印了这条信息！&quot; % (arg+1, thread_name))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class ThreadPool:</span><br><span class="line"></span><br><span class="line">    def __init__(self, max_num, max_task_num=None):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        初始化线程池</span><br><span class="line">        :param max_num: 线程池最大线程数量</span><br><span class="line">        :param max_task_num: 任务队列长度</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 如果提供了最大任务数的参数，则将队列的最大元素个数设置为这个值。</span><br><span class="line">        if max_task_num:</span><br><span class="line">            self.q = queue.Queue(max_task_num)</span><br><span class="line">        # 默认队列可接受无限多个的任务</span><br><span class="line">        else:</span><br><span class="line">            self.q = queue.Queue()</span><br><span class="line">        # 设置线程池最多可实例化的线程数</span><br><span class="line">        self.max_num = max_num</span><br><span class="line">        # 任务取消标识</span><br><span class="line">        self.cancel = False</span><br><span class="line">        # 任务中断标识</span><br><span class="line">        self.terminal = False</span><br><span class="line">        # 已实例化的线程列表</span><br><span class="line">        self.generate_list = []</span><br><span class="line">        # 处于空闲状态的线程列表</span><br><span class="line">        self.free_list = []</span><br><span class="line"></span><br><span class="line">    def put(self, func, args, callback=None):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        往任务队列里放入一个任务</span><br><span class="line">        :param func: 任务函数</span><br><span class="line">        :param args: 任务函数所需参数</span><br><span class="line">        :param callback: 任务执行失败或成功后执行的回调函数，回调函数有两个参数</span><br><span class="line">        1、任务函数执行状态；2、任务函数返回值（默认为None，即：不执行回调函数）</span><br><span class="line">        :return: 如果线程池已经终止，则返回True否则None</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 先判断标识，看看任务是否取消了</span><br><span class="line">        if self.cancel:</span><br><span class="line">            return</span><br><span class="line">        # 如果没有空闲的线程，并且已创建的线程的数量小于预定义的最大线程数，则创建新线程。</span><br><span class="line">        if len(self.free_list) == 0 and len(self.generate_list) &lt; self.max_num:</span><br><span class="line">            self.generate_thread()</span><br><span class="line">        # 构造任务参数元组，分别是调用的函数，该函数的参数，回调函数。</span><br><span class="line">        w = (func, args, callback,)</span><br><span class="line">        # 将任务放入队列</span><br><span class="line">        self.q.put(w)</span><br><span class="line"></span><br><span class="line">    def generate_thread(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        创建一个线程</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 每个线程都执行call方法</span><br><span class="line">        t = threading.Thread(target=self.call)</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line">    def call(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        循环去获取任务函数并执行任务函数。在正常情况下，每个线程都保存生存状态，  直到获取线程终止的flag。</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 获取当前线程的名字</span><br><span class="line">        current_thread = threading.currentThread().getName()</span><br><span class="line">        # 将当前线程的名字加入已实例化的线程列表中</span><br><span class="line">        self.generate_list.append(current_thread)</span><br><span class="line">        # 从任务队列中获取一个任务</span><br><span class="line">        event = self.q.get()</span><br><span class="line">        # 让获取的任务不是终止线程的标识对象时</span><br><span class="line">        while event != StopEvent:</span><br><span class="line">            # 解析任务中封装的三个参数</span><br><span class="line">            func, arguments, callback = event</span><br><span class="line">            # 抓取异常，防止线程因为异常退出</span><br><span class="line">            try:</span><br><span class="line">                # 正常执行任务函数</span><br><span class="line">                result = func(current_thread, *arguments)</span><br><span class="line">                success = True</span><br><span class="line">            except Exception as e:</span><br><span class="line">                # 当任务执行过程中弹出异常</span><br><span class="line">                result = None</span><br><span class="line">                success = False</span><br><span class="line">            # 如果有指定的回调函数</span><br><span class="line">            if callback is not None:</span><br><span class="line">                # 执行回调函数，并抓取异常</span><br><span class="line">                try:</span><br><span class="line">                    callback(success, result)</span><br><span class="line">                except Exception as e:</span><br><span class="line">                    pass</span><br><span class="line">            # 当某个线程正常执行完一个任务时，先执行worker_state方法</span><br><span class="line">            with self.worker_state(self.free_list, current_thread):</span><br><span class="line">                # 如果强制关闭线程的flag开启，则传入一个StopEvent元素</span><br><span class="line">                if self.terminal:</span><br><span class="line">                    event = StopEvent</span><br><span class="line">                # 否则获取一个正常的任务，并回调worker_state方法的yield语句</span><br><span class="line">                else:</span><br><span class="line">                    # 从这里开始又是一个正常的任务循环</span><br><span class="line">                    event = self.q.get()</span><br><span class="line">        else:</span><br><span class="line">            # 一旦发现任务是个终止线程的标识元素，将线程从已创建线程列表中删除</span><br><span class="line">            self.generate_list.remove(current_thread)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def close(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        执行完所有的任务后，让所有线程都停止的方法</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 设置flag</span><br><span class="line">        self.cancel = True</span><br><span class="line">        # 计算已创建线程列表中线程的个数，</span><br><span class="line">        # 然后往任务队列里推送相同数量的终止线程的标识元素</span><br><span class="line">        full_size = len(self.generate_list)</span><br><span class="line">        while full_size:</span><br><span class="line">            self.q.put(StopEvent)</span><br><span class="line">            full_size -= 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def terminate(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        在任务执行过程中，终止线程，提前退出。</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.terminal = True</span><br><span class="line">        # 强制性的停止线程</span><br><span class="line">        while self.generate_list:</span><br><span class="line">            self.q.put(StopEvent)</span><br><span class="line"></span><br><span class="line"># 该装饰器用于上下文管理</span><br><span class="line">    @contextlib.contextmanager</span><br><span class="line">    def worker_state(self, state_list, worker_thread):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        用于记录空闲的线程，或从空闲列表中取出线程处理任务</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 将当前线程，添加到空闲线程列表中</span><br><span class="line">        state_list.append(worker_thread)</span><br><span class="line">        # 捕获异常</span><br><span class="line">        try:</span><br><span class="line">            # 在此等待</span><br><span class="line">            yield</span><br><span class="line">        finally:</span><br><span class="line">            # 将线程从空闲列表中移除</span><br><span class="line">            state_list.remove(worker_thread)</span><br><span class="line"></span><br><span class="line"># 调用方式</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    # 创建一个最多包含5个线程的线程池</span><br><span class="line">    pool = ThreadPool(5)</span><br><span class="line">    # 创建100个任务，让线程池进行处理</span><br><span class="line">    for i in range(100):</span><br><span class="line">        pool.put(action, (i,), callback)</span><br><span class="line">    # 等待一定时间，让线程执行任务</span><br><span class="line">    time.sleep(3)</span><br><span class="line">    print(&quot;-&quot; * 50)</span><br><span class="line">    print(&quot;\033[32;0m任务停止之前线程池中有%s个线程，空闲的线程有%s个！\033[0m&quot;</span><br><span class="line">          % (len(pool.generate_list), len(pool.free_list)))</span><br><span class="line">    # 正常关闭线程池</span><br><span class="line">    pool.close()</span><br><span class="line">    print(&quot;任务执行完毕，正常退出！&quot;)</span><br><span class="line">    # 强制关闭线程池</span><br><span class="line">    # pool.terminate()</span><br><span class="line">    # print(&quot;强制停止任务！&quot;)</span><br></pre></td></tr></table></figure><p>关于线程池其实涉及到工程设计，需要自己很熟练的运行面向对象程序设计。</p><h2 id="生产者和消费者模式"><a href="#生产者和消费者模式" class="headerlink" title="生产者和消费者模式"></a>生产者和消费者模式</h2><p>生产者就是生成任务，消费者就是解决处理任务。比如在一个程序中，代码是按照重上往下执行，有的时候做等待的时间完全可以用来做任务处理或者做别的事情，为了节省时间，可以借助多线程的功能（自顾自完成自己线程任务）加上Queue队列特性（管道模式。里面存储数据，然后提供给线程处理）完成生产者和消费者模式。关于Queue的用法参考我之前的文章。</p><h4 id="案例一"><a href="#案例一" class="headerlink" title="案例一"></a>案例一</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">import Queue</span><br><span class="line">import time</span><br><span class="line">import threading</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line">q = Queue.Queue(10)</span><br><span class="line">def get(i):</span><br><span class="line">    # 这个函数用来生产任务，接受参数i，也可以不传入参数</span><br><span class="line">    while 1:</span><br><span class="line">        time.sleep(2)</span><br><span class="line">        # 这里可以做一些动作，比如过去网站的网址之类的</span><br><span class="line">        q.put(i)</span><br><span class="line">        # 然后把得到的数据放在消息队列中</span><br><span class="line">def fun(o):</span><br><span class="line">    # 这个函数用来处理任务，必须要接受参数</span><br><span class="line">    q.get(o)</span><br><span class="line">    # 得到获取接受来的参数</span><br><span class="line">    print o*10</span><br><span class="line">    # 然后对获取的参数作处理，我这里仅仅打印数据乘以10</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for i in range(100):</span><br><span class="line">    # 生产任务启动，有100个任务量要产生</span><br><span class="line">    t1 = threading.Thread(target=get, args=(i,))</span><br><span class="line">    t1.start()</span><br><span class="line">for o in range(100):</span><br><span class="line">    # 处理任务启动</span><br><span class="line">    t = threading.Thread(target=fun, args=(o,))</span><br><span class="line">    t.start()</span><br></pre></td></tr></table></figure><p>上面这个代码主要是针对骨架进行拆分解说，一般的生产者消费者模式都是这种构架，下面用一个更加清晰的案例来帮助理解。</p><h4 id="案例二"><a href="#案例二" class="headerlink" title="案例二"></a>案例二</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line">import time</span><br><span class="line">import queue</span><br><span class="line">import threading</span><br><span class="line"></span><br><span class="line">q = queue.Queue(10)     # 生成一个队列，用来保存“包子”，最大数量为10</span><br><span class="line"></span><br><span class="line">def productor(i):</span><br><span class="line">    # 厨师不停地每2秒做一个包子</span><br><span class="line">    while True:</span><br><span class="line">        q.put(&quot;厨师 %s 做的包子！&quot; % i)</span><br><span class="line">        time.sleep(2)</span><br><span class="line"></span><br><span class="line">def consumer(j):</span><br><span class="line">    # 顾客不停地每秒吃一个包子</span><br><span class="line">    while True:</span><br><span class="line">        print(&quot;顾客 %s 吃了一个 %s&quot;%(j,q.get()))</span><br><span class="line">        time.sleep(1)</span><br><span class="line"></span><br><span class="line"># 实例化了3个生产者（厨师）</span><br><span class="line">for i in range(3):</span><br><span class="line">    t = threading.Thread(target=productor, args=(i,))</span><br><span class="line">    t.start()</span><br><span class="line"># 实例化了10个消费者（顾客）</span><br><span class="line">for j in range(10):</span><br><span class="line">    v = threading.Thread(target=consumer, args=(j,))</span><br><span class="line">    v.start()</span><br></pre></td></tr></table></figure><h4 id="案例三"><a href="#案例三" class="headerlink" title="案例三"></a>案例三</h4><p>使用生产者消费者模式实现代理IP扫描并且同步扫描代理IP是否可用，如果不适用生产者消费者模式的话，首先要获取代理IP，然后把获取到的IP放在一个列表，然后在扫描列表的IP，扫描过程为—-&gt;获取IP—-&gt;IP保存—-&gt;IP存活扫描。过程是单向的，也就是说没办法同步一边获取IP然后马上验证。</p><p>下面的代码是用生产者消费者模式实现代理IP的获取与存活扫描。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"># @Time    : 2018/5/3 0003 10:52</span><br><span class="line"># @Author  : Sun</span><br><span class="line"># @Blog    : wandouduoduo</span><br><span class="line"># @File    : 生产者消费者.py</span><br><span class="line"># @Software: PyCharm</span><br><span class="line">import sys</span><br><span class="line">import Queue</span><br><span class="line">import time</span><br><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import threading</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line">q = Queue.Queue(10)</span><br><span class="line">headers=&#123;&apos;User-Agent&apos;:&apos;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36&apos;&#125;</span><br><span class="line">def get_ip(page):</span><br><span class="line">    url1=&apos;http://www.66ip.cn/mo.php?sxb=&amp;tqsl=30&amp;port=&amp;export=&amp;ktip=&amp;sxa=&amp;submit=%CC%E1++%C8%A1&amp;textarea=&apos;</span><br><span class="line">    url2=&apos;http://www.xicidaili.com/nn/%s&apos;</span><br><span class="line">    for i in range(1,page):</span><br><span class="line">        url1_1=url1+str(i)</span><br><span class="line">        url2_2=url2+str(i)</span><br><span class="line">        try:</span><br><span class="line">            r = requests.get(url=url1_1,headers=headers,timeout=5)</span><br><span class="line">            #time.sleep(20)</span><br><span class="line">            rr = re.findall(&apos;        (.*?)&lt;br /&gt;&apos;,r.content)</span><br><span class="line">            for x in rr:</span><br><span class="line">                q.put(x)</span><br><span class="line">            time.sleep(20)</span><br><span class="line">        except Exception,e:</span><br><span class="line">            print e</span><br><span class="line">        try:</span><br><span class="line">            time.sleep(30)</span><br><span class="line">            r = requests.get(url=url2_2,headers=headers,timeout=5)</span><br><span class="line">            rr = re.findall(&apos;/&gt;&lt;/td&gt;(.*?)&lt;a href&apos;,r.content,re.S)</span><br><span class="line">            for x in rr:</span><br><span class="line">                x1 = x.replace(&apos;\n&apos;,&apos;&apos;).replace(&apos;&lt;td&gt;&apos;,&apos;&apos;).replace(&quot;&lt;/td&gt;&quot;,&apos;:&apos;).replace(&apos;      &apos;,&apos;&apos;).replace(&apos;:  &apos;,&apos;&apos;)</span><br><span class="line">                print x1</span><br><span class="line">                q.put(x1)</span><br><span class="line">            time.sleep(20)</span><br><span class="line">        except Exception,e:</span><br><span class="line">            print e</span><br><span class="line">def scan_ip():</span><br><span class="line">    while 1:</span><br><span class="line">        proxies=&#123;&#125;</span><br><span class="line">        ip = q.get()</span><br><span class="line">        proxies[&apos;http&apos;] = str(ip)</span><br><span class="line">        try:</span><br><span class="line">            req2 = requests.get(url=&apos;http://blog.csdn.net/lzy98&apos;, proxies=proxies, headers=headers, timeout=5)</span><br><span class="line">            if &apos;One puls&apos; in req2.content:</span><br><span class="line">                print str(proxies[&apos;http&apos;]) + unicode(&apos;该代理可正常访问网页...&apos;,&apos;utf-8&apos;)</span><br><span class="line">            else:</span><br><span class="line">                print unicode(&apos;  该代理无法访问网页,继续验证下一代理...&apos;, &apos;utf-8&apos;)</span><br><span class="line">        except :</span><br><span class="line">            print str(proxies[&apos;http&apos;])+unicode(&apos;  无法连接到代理服务器&apos;,&apos;utf-8&apos;)</span><br><span class="line"></span><br><span class="line">for i in range(2):</span><br><span class="line">    # 这里是要开2个任务量，就是2个线程</span><br><span class="line">    t = threading.Thread(target=get_ip,args=(10,))</span><br><span class="line">    # 传入的参数是10，回归到get_ip函数，发现传入的参数就是要扫描提供代理网站的页数</span><br><span class="line">    t.start()</span><br><span class="line"></span><br><span class="line">t1 = threading.Thread(target=scan_ip)</span><br><span class="line">t1.start()</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">177.132.249.127:20183无法连接到代理服务器</span><br><span class="line">39.104.82.143:8080无法连接到代理服务器</span><br><span class="line">123.231.203.139:8080无法连接到代理服务器</span><br><span class="line">180.250.43.66:8080该代理可正常访问网页...</span><br><span class="line">189.127.238.65:8080无法连接到代理服务器</span><br><span class="line">107.178.3.105:8181该代理可正常访问网页...</span><br><span class="line">95.31.80.67:53281该代理可正常访问网页...</span><br><span class="line">79.174.160.167:8080无法连接到代理服务器</span><br><span class="line">223.242.94.36:31588无法连接到代理服务器</span><br><span class="line">该代理无法访问网页,继续验证下一代理...</span><br><span class="line">5.188.155.243:8080无法连接到代理服务器</span><br><span class="line">180.183.17.151:8080该代理可正常访问网页...</span><br><span class="line">113.90.247.99:8118该代理可正常访问网页...</span><br><span class="line">180.119.65.184:3128无法连接到代理服务器</span><br></pre></td></tr></table></figure><h2 id="Python3中的线程池方法"><a href="#Python3中的线程池方法" class="headerlink" title="Python3中的线程池方法"></a>Python3中的线程池方法</h2><p>虽然在2版本中并没有线程池，但是在3版本中有相关线程池的使用方法。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from concurrent.futures import ThreadPoolExecutor</span><br><span class="line">executor = ThreadPoolExecutor(3)</span><br><span class="line"># 实例化线程池对象，开启3个线程</span><br><span class="line">def fun(a,b):</span><br><span class="line">    print (a,b)</span><br><span class="line">    returl a**b</span><br><span class="line"># 定义一个函数</span><br><span class="line">executor.submit(fun,2,5) # y运行结果：2,5</span><br><span class="line"># 这是调用与开启线程</span><br><span class="line">result=executor.submit(fun,5,2)</span><br><span class="line">print result # 运行结果: 25</span><br><span class="line"># 如果要有很多参数传入进行运算</span><br><span class="line">executor.map(fun,[1,2,3,4],[2,3,5,6])</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;线程是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务，多线程就是在一个进程中的多个线程，如果使用多线程默认开启一个主线程，按照程序需求自动开启多个线程(也可以自己定义线程数)。&lt;/p&gt;
    
    </summary>
    
      <category term="编程积累" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/"/>
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/Python/"/>
    
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>glusterfs常用命令</title>
    <link href="https://wandouduoduo.netlify.com/articles/4f1d1494.html"/>
    <id>https://wandouduoduo.netlify.com/articles/4f1d1494.html</id>
    <published>2019-11-26T08:03:27.000Z</published>
    <updated>2019-11-26T09:20:44.545Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>glusterfs作为分布式存储，优点和安装这里就不再赘述了，看博客中教程。本文主要是介绍glusterfs常用命令和案例。</p><a id="more"></a><h2 id="命令详解"><a href="#命令详解" class="headerlink" title="命令详解"></a>命令详解</h2><h4 id="服务器节点"><a href="#服务器节点" class="headerlink" title="服务器节点"></a>服务器节点</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看所有节点信息，显示时不包括本节点</span></span><br><span class="line">gluster peer status </span><br><span class="line"><span class="comment">#添加节点</span></span><br><span class="line">gluster peer probe NODE-NAME </span><br><span class="line"><span class="comment">#移除节点，需要提前将该节点上的brick移除</span></span><br><span class="line">gluster peer detach NODE-NAME</span><br></pre></td></tr></table></figure><h4 id="glusterd服务"><a href="#glusterd服务" class="headerlink" title="glusterd服务"></a>glusterd服务</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#启动glusterd服务</span></span><br><span class="line">/etc/init.d/glusterd start </span><br><span class="line"><span class="comment">#关闭glusterd服务</span></span><br><span class="line">/etc/init.d/glusterd stop </span><br><span class="line"><span class="comment">#查看glusterd服务</span></span><br><span class="line">/etc/init.d/glusterd status</span><br></pre></td></tr></table></figure><h4 id="卷管理"><a href="#卷管理" class="headerlink" title="卷管理"></a>卷管理</h4><h5 id="创建卷"><a href="#创建卷" class="headerlink" title="创建卷"></a>创建卷</h5><p><strong>复制卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法： gluster volume create NEW-VOLNAME [replica COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK</span><br><span class="line"></span><br><span class="line">示例1：gluster volume create <span class="built_in">test</span>-volume replica 2 transport tcp server1:/exp1/brick server2:/exp2/brick</span><br></pre></td></tr></table></figure><p><strong>条带卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法：gluster volume create NEW-VOLNAME [stripe COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK...</span><br><span class="line"></span><br><span class="line">示例：gluster volume create <span class="built_in">test</span>-volume stripe 2 transport tcp server1:/exp1/brick server2:/exp2/brick</span><br></pre></td></tr></table></figure><p><strong>分布式卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">语法： gluster volume create NEW-VOLNAME [transport tcp | rdma | tcp, rdma] NEW-BRICK</span><br><span class="line"></span><br><span class="line">示例1：gluster volume create <span class="built_in">test</span>-volume server1:/exp1/brick server2:/exp2/brick</span><br><span class="line">示例2：gluster volume create <span class="built_in">test</span>-volume transport rdma server1:/exp1/brick server2:/exp2/brick server3:/exp3/brick server4:/exp4/brick</span><br></pre></td></tr></table></figure><p><strong>分布式复制卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">语法： gluster volume create NEW-VOLNAME [replica COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK...</span><br><span class="line">示例： gluster volume create <span class="built_in">test</span>-volume replica 2 transport tcp server1:/exp1/brick server2:/exp2/brick server3:/exp3/brick server4:/exp4/brick</span><br></pre></td></tr></table></figure><p> <strong>分布式条带卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法：gluster volume create NEW-VOLNAME [stripe COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK...</span><br><span class="line"></span><br><span class="line">示例：gluster volume create <span class="built_in">test</span>-volume stripe 2 transport tcp server1:/exp1/brick server2:/exp2/brick server3:/exp3/brick server4:/exp4/brick</span><br></pre></td></tr></table></figure><p><strong>条带复制卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法：gluster volume create NEW-VOLNAME [stripe COUNT] [replica COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK...</span><br><span class="line"></span><br><span class="line">示例：gluster volume create <span class="built_in">test</span>-volume stripe 2 replica 2 transport tcp server1:/exp1/brick server2:/exp2/brick server3:/exp3/brick server4:/exp4/brick</span><br></pre></td></tr></table></figure><h5 id="启动卷"><a href="#启动卷" class="headerlink" title="启动卷"></a>启动卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume start <span class="built_in">test</span>-volume</span><br></pre></td></tr></table></figure><h5 id="停止卷"><a href="#停止卷" class="headerlink" title="停止卷"></a>停止卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume stop <span class="built_in">test</span>-volume</span><br></pre></td></tr></table></figure><p> <strong>删除卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先停止卷后才能删除</span></span><br><span class="line">gluster volume delete <span class="built_in">test</span>-volume</span><br></pre></td></tr></table></figure><h5 id="查看卷"><a href="#查看卷" class="headerlink" title="查看卷"></a>查看卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#列出集群中的所有卷</span></span><br><span class="line">gluster volume list </span><br><span class="line"><span class="comment">#查看集群中的卷信息</span></span><br><span class="line">gluster volume info [all] </span><br><span class="line"><span class="comment">#查看集群中的卷状态</span></span><br><span class="line">gluster volume status [all] </span><br><span class="line"></span><br><span class="line">gluster volume status [detail| clients | mem | inode | fd]</span><br></pre></td></tr></table></figure><h5 id="配置卷"><a href="#配置卷" class="headerlink" title="配置卷"></a>配置卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume <span class="built_in">set</span> &lt;VOLNAME&gt; &lt;OPTION&gt; &lt;PARAMETER&gt;</span><br></pre></td></tr></table></figure><h5 id="扩展卷"><a href="#扩展卷" class="headerlink" title="扩展卷"></a>扩展卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gluster volume add-brick &lt;VOLNAME&gt; &lt;NEW-BRICK&gt;</span><br><span class="line"><span class="comment">#注意，如果是复制卷或者条带卷，则每次添加的Brick数必须是replica或者stripe的整数倍。</span></span><br></pre></td></tr></table></figure><h5 id="收缩卷"><a href="#收缩卷" class="headerlink" title="收缩卷"></a>收缩卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先将数据迁移到其它可用的Brick，迁移结束后才将该Brick移除：</span></span><br><span class="line">gluster volume remove-brick start</span><br><span class="line"><span class="comment">#在执行了start之后，可以使用status命令查看移除进度：</span></span><br><span class="line">gluster volume remove-brick status</span><br><span class="line"><span class="comment">#不进行数据迁移，直接删除该Brick：</span></span><br><span class="line">gluster volume remove-brick commit</span><br><span class="line"><span class="comment">#注意，如果是复制卷或者条带卷，则每次移除的Brick数必须是replica或者stripe的整数倍。</span></span><br></pre></td></tr></table></figure><h5 id="迁移卷"><a href="#迁移卷" class="headerlink" title="迁移卷"></a>迁移卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用start命令开始进行迁移：</span></span><br><span class="line">gluster volume replace-brick start</span><br><span class="line"><span class="comment">#在数据迁移过程中，可以使用pause命令暂停迁移：</span></span><br><span class="line">gluster volume replace-brick pause</span><br><span class="line"><span class="comment">#在数据迁移过程中，可以使用abort命令终止迁移：</span></span><br><span class="line">gluster volume replace-brick abort</span><br><span class="line"><span class="comment">#在数据迁移过程中，可以使用status命令查看迁移进度：</span></span><br><span class="line">gluster volume replace-brick status</span><br><span class="line"><span class="comment">#在数据迁移结束后，执行commit命令来进行Brick替换：</span></span><br><span class="line">gluster volume replace-brick commit</span><br></pre></td></tr></table></figure><h5 id="重新均衡卷"><a href="#重新均衡卷" class="headerlink" title="重新均衡卷"></a>重新均衡卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#不迁移数据：</span></span><br><span class="line">gluster volume rebalance lay-outstart</span><br><span class="line">gluster volume rebalance start</span><br><span class="line">gluster volume rebalance startforce</span><br><span class="line">gluster volume rebalance status</span><br><span class="line">gluster volume rebalance stop</span><br></pre></td></tr></table></figure><h4 id="Brick管理"><a href="#Brick管理" class="headerlink" title="Brick管理"></a>Brick管理</h4><h5 id="添加Brick"><a href="#添加Brick" class="headerlink" title="添加Brick"></a>添加Brick</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume add-brick <span class="built_in">test</span>-volume 192.168.1.&#123;151,152&#125;:/mnt/brick2</span><br></pre></td></tr></table></figure><h5 id="删除Brick"><a href="#删除Brick" class="headerlink" title="删除Brick"></a>删除Brick</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#若是副本卷，则移除的Bricks数是replica的整数倍</span></span><br><span class="line">gluster volume remove-brick <span class="built_in">test</span>-volume 192.168.1.&#123;151,152&#125;:/mnt/brick2 start</span><br><span class="line"><span class="comment">#在执行开始移除之后，可以使用status命令进行移除状态查看。</span></span><br><span class="line">gluster volume remove-brick <span class="built_in">test</span>-volume 192.168.1.&#123;151,152&#125;:/mnt/brick2 status</span><br><span class="line"><span class="comment">#使用commit命令执行Brick移除，则不会进行数据迁移而直接删除Brick，符合不需要数据迁移的用户需求。</span></span><br><span class="line">gluster volume remove-brick <span class="built_in">test</span>-volume 192.168.1.&#123;151,152&#125;:/mnt/brick2 commit</span><br></pre></td></tr></table></figure><h5 id="替换Brick"><a href="#替换Brick" class="headerlink" title="替换Brick"></a>替换Brick</h5><p>任务：把192.168.1.151:/mnt/brick0 替换为192.168.1.151:/mnt/brick2</p><p><strong>开始替换</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">gluster volume replace-brick <span class="built_in">test</span>-volume 192.168.1.:/mnt/brick0 ..152:/mnt/brick2 start</span><br><span class="line">异常信息：volume replace-brick: failed: /data/share2 or a prefix of it is already part of a volume</span><br><span class="line"></span><br><span class="line"><span class="comment">#说明 /mnt/brick2 曾经是一个Brick。具体解决方法</span></span><br><span class="line">rm -rf /mnt/brick2/.glusterfs</span><br><span class="line"></span><br><span class="line">setfattr -x trusted.glusterfs.volume-id /mnt/brick2</span><br><span class="line">setfattr -x trusted.gfid /mnt/brick2</span><br><span class="line"></span><br><span class="line"><span class="comment">#如上，执行replcace-brick卷替换启动命令，使用start启动命令后，开始将原始Brick的数据迁移到即将需要替换的Brick上。</span></span><br></pre></td></tr></table></figure><p><strong>查看是否替换完</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume replace-brick <span class="built_in">test</span>-volume 192.168.1.151:/mnt/brick0 ..152:/mnt/brick2 status</span><br></pre></td></tr></table></figure><p><strong>在数据迁移的过程中，可以执行abort命令终止Brick替换。</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume replace-brick <span class="built_in">test</span>-volume 192.168.1.151:/mnt/brick0 ..152:/mnt/brick2 abort</span><br></pre></td></tr></table></figure><p><strong>在数据迁移结束之后，执行commit命令结束任务，则进行Brick替换。使用volume info命令可以查看到Brick已经被替换</strong>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gluster volume replace-brick <span class="built_in">test</span>-volume 192.168.1.151:/mnt/brick0 .152:/mnt/brick2 commit</span><br><span class="line"><span class="comment">#此时我们再往 /sf/data/vs/gfs/rep2上添加数据的话，数据会同步到 192.168.1.152:/mnt/brick0和192.168.1.152:/mnt/brick2上。而不会同步到192.168.1.151:/mnt/brick0 上。</span></span><br></pre></td></tr></table></figure><h4 id="文件系统扩展属性"><a href="#文件系统扩展属性" class="headerlink" title="文件系统扩展属性"></a>文件系统扩展属性</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获取文件扩展属性</span></span><br><span class="line">getfattr -d -m . -e hex filename</span><br><span class="line">getfattr -d -m <span class="string">"trusted.afr.*"</span> -e hex filename</span><br></pre></td></tr></table></figure><h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><h4 id="增加节点"><a href="#增加节点" class="headerlink" title="增加节点"></a>增加节点</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#hosts文件中添加对应服务器解析</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"ip   gs3"</span> &gt;&gt;/etc/hosts</span><br><span class="line"><span class="comment">#查看节点信息</span></span><br><span class="line">gluster peer status</span><br><span class="line"><span class="comment">#添加节点</span></span><br><span class="line">gluster peer probe gs3</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据卷添加新的brick</span></span><br><span class="line">gluster volume add-brick 卷名 replica 添加后的副本个数 brick所在的IP:brick所在的地址 force</span><br><span class="line">最后的force是因为，gluster集群推荐不要和系统公用磁盘，如果公用就需添加。</span><br><span class="line"></span><br><span class="line">例如：</span><br><span class="line">mkdir -p /brick/gv0</span><br><span class="line">gluster volume add-brick gv0 replica 2 gs2:/brick/gv0  force</span><br></pre></td></tr></table></figure><h4 id="删除节点"><a href="#删除节点" class="headerlink" title="删除节点"></a>删除节点</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看节点信息</span></span><br><span class="line">gluster peer status</span><br><span class="line"><span class="comment"># 删除操作,注意删除节点必须先删除brick</span></span><br><span class="line">gluster peer detach gs3</span><br></pre></td></tr></table></figure><p><img src="/articles/4f1d1494/1.png" alt></p><p>上面报错，是因为没有删除brick导致。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#数据卷移除旧的brick</span></span><br><span class="line">gluster volume remove-brick 卷名 replica 移除后的副本个数 brick所在的IP:brick所在的地址</span><br><span class="line"></span><br><span class="line">例如：移除gs3上的static卷</span><br><span class="line">gluster volume remove-brick static gs3:/data/volume/brick/static</span><br></pre></td></tr></table></figure><p><img src="/articles/4f1d1494/2.png" alt></p><p>执行移除报错，是因为先删除副本。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gluster volume remove-brick gv0 replica 2  gs3:/brick/gv0 force</span><br><span class="line"><span class="comment">#注意副本数为删除后还剩的个数</span></span><br><span class="line"><span class="comment">#然后再移除节点</span></span><br><span class="line">gluster peer detach gs3</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;glusterfs作为分布式存储，优点和安装这里就不再赘述了，看博客中教程。本文主要是介绍glusterfs常用命令和案例。&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.netlify.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="GlusterFS" scheme="https://wandouduoduo.netlify.com/tags/GlusterFS/"/>
    
  </entry>
  
  <entry>
    <title>GlusterFS分布式存储集群之使用</title>
    <link href="https://wandouduoduo.netlify.com/articles/35de9bb2.html"/>
    <id>https://wandouduoduo.netlify.com/articles/35de9bb2.html</id>
    <published>2019-11-05T03:56:15.000Z</published>
    <updated>2019-11-05T06:32:39.546Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Glusterfs逻辑卷创建与使用"><a href="#Glusterfs逻辑卷创建与使用" class="headerlink" title="Glusterfs逻辑卷创建与使用"></a>Glusterfs逻辑卷创建与使用</h1><p>volume是brick的组合，并且大部分glusterfs文件系统的操作都在volume上。</p><p>glusterfs支持4种基本卷，并可以根据需求对4种基本卷进行组合形成多种扩展卷（得益于glusterfs的模块化堆栈架构设计）。</p><p>以下主要展示各类型逻辑卷的功能性，未对性能做测试验证。</p><a id="more"></a><h2 id="分布式卷"><a href="#分布式卷" class="headerlink" title="分布式卷"></a>分布式卷</h2><p>分布式卷（Distributed Glusterfs Volume，又称DHT），glusterfs创建volume不指定卷类型时，默认即分布式卷，特点如下：</p><ol><li>根据hash算法，将多个文件分布到卷中的多个brick server上，类似（不是）raid0，但文件无分片；</li><li>方便扩展空间，但无冗余保护；</li><li>由于使用本地文件系统进行存储（brick server 的本地文件系统），存取效率不高；</li><li>受限于本地文件系统对单文件容量的限制，支持超大型文件系统有问题。</li></ol><p><img src="/articles/35de9bb2/1.png" alt="img"></p><h4 id="创建存储目录（optional）"><a href="#创建存储目录（optional）" class="headerlink" title="创建存储目录（optional）"></a>创建存储目录（optional）</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在brick server节点创建存储目录，即brick所在；</span></span><br><span class="line"><span class="comment"># 以glusterfs01节点为例，注意各brick server挂载磁盘的目录名的不同</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># mkdir -p /brick1/dis_volume</span></span><br></pre></td></tr></table></figure><h4 id="创建分布式卷"><a href="#创建分布式卷" class="headerlink" title="创建分布式卷"></a>创建分布式卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [transport [tcp | rdma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 演示分布式卷的创建，两个server节点即可，创建名为”distributed-volume”的逻辑卷</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create distributed-volume glusterfs01:/brick1/dis_volume glusterfs02:/brick2/dis_volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/2.png" alt="img"></p><h4 id="卷信息-状态"><a href="#卷信息-状态" class="headerlink" title="卷信息/状态"></a>卷信息/状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令”gluster volume list”可列出已创建的卷；</span></span><br><span class="line"><span class="comment"># 命令”gluster volume info”可不指定具体的卷，即列出所有卷信息；</span></span><br><span class="line"><span class="comment"># info中给出除卷名外，还有卷类型，状态，brick组成等信息；</span></span><br><span class="line"><span class="comment"># 其中状态为“Created”，需要通过命令启动后才可被挂载使用，在创建成功后的提示信息中有提到”please start the volume to access data”</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info distributed-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/3.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看卷状态；</span></span><br><span class="line"><span class="comment"># 展示卷中每个brick的状态，以及每个brick服务的监听端口</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume status distributed-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/4.png" alt="img"></p><h4 id="启动卷"><a href="#启动卷" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start distributed-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/5.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 再次查看卷信息，状态变为"Started"</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info distributed-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/6.png" alt="img"></p><h4 id="client挂载"><a href="#client挂载" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在客户端创建挂载目录</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/distributed</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 挂载时，可使用任意1台已加入可信存储池并已创建对应卷类型的server节点；</span></span><br><span class="line"><span class="comment"># brick以”SERVER:EXPORT”的形式标识</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:distributed-volume /mnt/distributed/</span></span><br></pre></td></tr></table></figure><h4 id="查看挂载情况"><a href="#查看挂载情况" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过“df -Th”命令可查看被挂载的volume，被挂载的文件系统，已经挂载卷的容量是2个brick容量之和</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/7.png" alt="img"></p><h4 id="查看brick的监听端口"><a href="#查看brick的监听端口" class="headerlink" title="查看brick的监听端口"></a>查看brick的监听端口</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># server节点上每启动1个brick，即启动1个brick服务，具备相应的服务监听端口，起始端口号是tcp49152</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># netstat -tunlp | grep gluster</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/8.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 另外，client连接的即brick服务的监听端口</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># netstat -nt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/9.png" alt="img"></p><h4 id="存储测试"><a href="#存储测试" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/distributed/</span></span><br><span class="line">[root@glusterfs-client distributed]<span class="comment"># touch distributed&#123;1..4&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/dis_volume/</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/10.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/dis_volume/</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/11.png" alt="img"></p><p><strong>结论：分布式卷将多个文件分布存储在多个brick server，但并无副本。</strong> </p><h2 id="条带卷（Deprecated）"><a href="#条带卷（Deprecated）" class="headerlink" title="条带卷（Deprecated）"></a>条带卷（Deprecated）</h2><p>条带卷（Striped Glusterfs Volume），特点如下：</p><ol><li>每个文件被分片成等同于brick数量的chunks，然后以round robin的方式将每个chunk存储到1个brick，相当于raid0；</li><li>单一超大容量文件可被分片，不受brick server本地文件系统的限制；</li><li>文件分片后，并发粒度是chunks，分布式读写性能较高，但分片随机读写可能会导致硬盘iops较高；</li><li>无冗余，1个server节点故障会导致所有数据丢失。</li></ol><p><img src="/articles/35de9bb2/12.png" alt="img"></p><h4 id="创建条带卷"><a href="#创建条带卷" class="headerlink" title="创建条带卷"></a>创建条带卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [stripe COUNT] [transport [tcp | dma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”strsipe-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的条带数量，数量需要与后续使用brick server数量对等；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create stripe-volume stripe 3 transport tcp glusterfs01:/brick1/str_volume glusterfs02:/brick2/str_volume glusterfs03:/brick3/str_volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/13.png" alt="img"></p><h4 id="启动卷-1"><a href="#启动卷-1" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start stripe-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/14.png" alt="img"></p><h4 id="client挂载-1"><a href="#client挂载-1" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/stripe</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:stripe-volume /mnt/stripe/</span></span><br></pre></td></tr></table></figure><h4 id="查看挂载情况-1"><a href="#查看挂载情况-1" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是3个brick容量之和</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/15.png" alt="img"></p><h4 id="存储测试-1"><a href="#存储测试-1" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/stripe/</span></span><br><span class="line">[root@glusterfs-client stripe]<span class="comment"># touch stripe&#123;1..6&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向strip1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client stripe]<span class="comment"># echo "this is stripe1.txt" &gt;&gt; strip1.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/str_volume/</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># cat /brick1/str_volume/strip1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/16.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/str_volume/</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># cat /brick2/str_volume/strip1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/17.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs03节点</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># tree /brick3/str_volume/</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># cat /brick3/str_volume/strip1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/18.png" alt="img"></p><p><strong>结论：条带卷将1个文件分片存储在多个brick server，但并无副本。</strong></p><h2 id="复制卷"><a href="#复制卷" class="headerlink" title="复制卷"></a>复制卷</h2><p>复制卷（Replicated Glusterfs Volume，又称AFR（Auto File Replication）），特点如下：</p><ol><li>每个文件同步复制镜像到多个brick，相当于文件级raid1；</li><li>副本数量通常设置为2或3，设置的副本数量需要是brick数量（至少为2）的倍数（如2台brick server，可设置副本数为2/4/6/…；如3台brick server，可设置副本数为3/6/9/…；依次类推），且每个brick的容量相等；</li><li>读性能提升，写性能下降，因为<strong>glusterfs的复制是同步事务操作，即写文件时，先把这个文件锁住，然后同时写两个或多个副本，写完后解锁，操作结束</strong>（ceph采用异步写副本，即写到一个主OSD便返回，这个OSD再通过内部网络异步写到其余OSD）；</li><li>通常与分布式卷或条带卷组合使用，解决前两者的冗余问题；</li><li>提升数据可靠性，但磁盘利用率低；</li><li>副本数设置为2时，可能会有脑裂（Split-brain）的风险（风险提示，但可配置），主要因在两个副本不一致时，无法仲裁以哪个副本为准，解决方案是加入仲裁或者设置3副本。</li></ol><p><img src="/articles/35de9bb2/19.png" alt="img"></p><h4 id="创建复制卷"><a href="#创建复制卷" class="headerlink" title="创建复制卷"></a>创建复制卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [replica COUNT] [transport [tcp | rdma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”replica-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的副本数量，数量需要与后续使用brick server数量对等；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式；</span></span><br><span class="line"><span class="comment"># 副本数为2时，有脑裂风险提示，提示采用3副本或仲裁机制，验证环境略过即可</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create replica-volume replica 2 transport tcp glusterfs01:/brick1/repl_volume glusterfs02:/brick2/repl_volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/20.png" alt="img"></p><h4 id="启动卷-2"><a href="#启动卷-2" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start replica-volume</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info replica-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/21.png" alt="img"></p><h4 id="client挂载-2"><a href="#client挂载-2" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/replica</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:replica-volume /mnt/replica/</span></span><br></pre></td></tr></table></figure><h4 id="查看挂载情况-2"><a href="#查看挂载情况-2" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是1个brick的容量</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/22.png" alt="img"></p><h4 id="存储测试-2"><a href="#存储测试-2" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/replica/</span></span><br><span class="line">[root@glusterfs-client replica]<span class="comment"># touch replica&#123;1..4&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向replica1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client replica]<span class="comment"># echo "this is replica1.txt" &gt;&gt; replica1.txt</span></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/repl_volume/</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># cat /brick1/repl_volume/replica1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/23.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/repl_volume/</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># cat /brick2/repl_volume/replica1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/24.png" alt="img"></p><p><strong>结论：复制卷将1个文件同步镜像到多个brick server，数据有冗余备份。</strong></p><h4 id="AFR恢复原理"><a href="#AFR恢复原理" class="headerlink" title="AFR恢复原理"></a>AFR恢复原理</h4><p>数据恢复只针对复制卷，AFR数据修复主要涉及三个方面：ENTRY，META，DATA。</p><p>记录描述副本状态的称之为<strong>ChangeLog</strong>，记录在每个副本文件扩展属性里，读入内存后以矩阵形式判断是否需要修复以及要以哪个副本为Source进行修复；初始值以及正常值为0（注：ENTRY和META,DATA分布对应着一个数值）。</p><p>以冗余度为2，即含有2个副本A和B的DATA修复为例，write的步骤分解为：</p><ol><li>下发Write操作；</li><li>加锁Lock；</li><li>向A，B副本的ChangeLog分别加1，记录到各副本的扩展属性中；</li><li>对A，B副本进行写操作；</li><li>若副本写成功则ChangeLog减1，若该副本写失败则ChangLog值不变，记录到各个副本的扩展属性中；</li><li>解锁UnLock；</li><li>向上层返回，只要有一个副本写成功就返回成功。 </li></ol><p>上述操作在AFR中是完整的一个transaction动作，根据两个副本记录的ChangeLog的数值确定了副本的几种状态：</p><ol><li>WISE：智慧的，即该副本的ChangeLog中对应的值是0，而另一副本对应的数值大于0；</li><li>INNOCENT：无辜的，即两副本的ChangeLog对应的值都是0；</li><li>FOOL：愚蠢的，即该副本的ChangeLog对应的值大于是0，而另一副本对应的数值是0；</li><li>IGNORANT，忽略的，即该副本的ChangeLog丢失。</li></ol><p>恢复分以下场景：</p><ol><li><p>1个节点changelog状态为WISE，其余节点为FOOL或其他非WISE状态，以WISE节点去恢复其他节点；</p></li><li><p>所有节点是IGNORANT状态，手动触发heal，通过命令以UID最小的文件作为source，去恢复大小为0的其他文件；</p></li><li><p>多个状态是WISE时，即出现脑裂状态，脑裂的文件通常读不出来，报”Input/Output error”，可查看日志/var/log/glusterfs/glustershd.log。</p><p>脑裂原理及解决方案：[<a href="https://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/]" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/]</a>(<a href="https://docs.gluster.org/en/latest/Administrator" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator</a> Guide/Split brain and ways to deal with it/)</p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过命令查看副本文件的扩展属性：getfattr -m . -d -e hex [filename]</span></span><br><span class="line"><span class="comment"># “trusted.afr.xxx”部分即扩展属性，值是24bit，分3部分，依次标识DATA ，META， ENTRY 3者的changelog</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># getfattr -m . -d -e hex /brick1/repl_volume/replica1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/25.png" alt="img"></p><h2 id="分布式复制卷"><a href="#分布式复制卷" class="headerlink" title="分布式复制卷"></a>分布式复制卷</h2><p>分布式复制卷（Distributed Replicated Glusterfs Volume），是分布式卷与复制卷的组合，兼具两者的功能，特点如下：</p><ol><li>若干brick组成1个复制卷，另外若干brick组成其他复制卷；单个文件在复制卷内数据保持副本，不同文件在不同复制卷之间进行哈希分布；即分布式卷跨复制卷集（replicated sets ）；</li><li>brick server数量是副本数量的倍数，且&gt;=2倍，即最少需要4台brick server，同时组建复制卷集的brick容量相等。</li></ol><p><img src="/articles/35de9bb2/26.png" alt="img"></p><h4 id="创建分布式复制卷"><a href="#创建分布式复制卷" class="headerlink" title="创建分布式复制卷"></a>创建分布式复制卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [replica COUNT] [transport [tcp | rdma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”distributed-replica-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的副本数量，brick server数量是副本数量的倍数，且&gt;=2倍；</span></span><br><span class="line"><span class="comment"># 不需要指出分布式卷类型，只要副本数量与brick server数量不等且符合倍数关系，即是分布式复制卷；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式；</span></span><br><span class="line"><span class="comment"># 副本数为2时，有脑裂风险提示，提示采用3副本或仲裁机制，验证环境略过即可</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create distributed-replica-volume replica 2 transport tcp \</span></span><br><span class="line"> glusterfs01:/brick1/dis_repl_volume \</span><br><span class="line"> glusterfs02:/brick2/dis_repl_volume \</span><br><span class="line"> glusterfs03:/brick3/dis_repl_volume \</span><br><span class="line"> glusterfs04:/brick4/dis_repl_volume</span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/27.png" alt="img"></p><h4 id="启动卷-3"><a href="#启动卷-3" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 卷类型：分布式复制卷</span></span><br><span class="line"><span class="comment"># “Number of Bricks”：2副本，2个副本集（replicated sets ），4个brick server</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start distributed-replica-volume</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info distributed-replica-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/28.png" alt="img"></p><h4 id="client挂载-3"><a href="#client挂载-3" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/distributed-replica</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:distributed-replica-volume /mnt/distributed-replica/</span></span><br></pre></td></tr></table></figure><h4 id="查看挂载情况-3"><a href="#查看挂载情况-3" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是2个副本集（replicated sets ）容量之和</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/29.png" alt="img"></p><h4 id="存储测试-3"><a href="#存储测试-3" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/distributed-replica/</span></span><br><span class="line">[root@glusterfs-client distributed-replica]<span class="comment"># touch distributed-replica&#123;1..6&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向distributed-replica1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client distributed-replica]<span class="comment"># echo "this is distributed-replica1.txt" &gt;&gt; distributed-replica1.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/dis_repl_volume/</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/30.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/dis_repl_volume/</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/31.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs03节点</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># tree /brick3/dis_repl_volume/</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># cat /brick3/dis_repl_volume/distributed-replica1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/32.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs04节点</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># tree /brick4/dis_repl_volume/</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># cat /brick4/dis_repl_volume/distributed-replica1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/33.png" alt="img"></p><p><strong>结论：分布式复制卷将数据文件分布在多个复制集（replicated sets ）中，每个复制集中数据有镜像冗余。</strong></p><h2 id="分布式条带卷（Deprecated）"><a href="#分布式条带卷（Deprecated）" class="headerlink" title="分布式条带卷（Deprecated）"></a>分布式条带卷（Deprecated）</h2><p>分布式条带卷（Distributed Striped Glusterfs Volume），是分布式卷与条带卷的组合，兼具两者的功能，特点如下：</p><ol><li>若干brick组成1个条带卷，另外若干brick组成其他条带卷；单个文件在条带卷内数据以条带的形式存储，不同文件在不同条带卷之间进行哈希分布；即分布式卷跨条带卷；</li><li>brick server数量是条带数的倍数，且&gt;=2倍，即最少需要4台brick server。</li></ol><p><img src="/articles/35de9bb2/34.png" alt="img"></p><h4 id="创建分布式条带卷"><a href="#创建分布式条带卷" class="headerlink" title="创建分布式条带卷"></a>创建分布式条带卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [stripe COUNT] [transport [tcp | rdma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”distributed-stripe-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的条带数，brick server数量是条带数量的倍数，且&gt;=2倍；</span></span><br><span class="line"><span class="comment"># 不需要指出分布式卷类型，只要条带数量与brick server数量不等且符合倍数关系，即是分布式复制卷；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式；</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create distributed-stripe-volume stripe 2 transport tcp \</span></span><br><span class="line"> glusterfs01:/brick1/dis_str_volume \</span><br><span class="line"> glusterfs02:/brick2/dis_str_volume \</span><br><span class="line"> glusterfs03:/brick3/dis_str_volume \</span><br><span class="line"> glusterfs04:/brick4/dis_str_volume</span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/35.png" alt="img"></p><h4 id="启动卷-4"><a href="#启动卷-4" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 卷类型：分布式条带卷</span></span><br><span class="line"><span class="comment"># “Number of Bricks”：2分布集，2条带集（replicated sets ），4个brick server</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start distributed-stripe-volume</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info distributed-stripe-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/36.png" alt="img"></p><h4 id="client挂载-4"><a href="#client挂载-4" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/distributed-stripe</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:distributed-stripe-volume /mnt/distributed-stripe/</span></span><br></pre></td></tr></table></figure><h4 id="查看挂载情况-4"><a href="#查看挂载情况-4" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是4个brick容量之和</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/37.png" alt="img"></p><h4 id="存储测试-4"><a href="#存储测试-4" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/distributed-stripe/</span></span><br><span class="line">[root@glusterfs-client distributed-stripe]<span class="comment"># touch distributed-stripe&#123;1..6&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向distributed-stripe1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client distributed-stripe]<span class="comment"># echo "this is distributed-stripe1.txt" &gt;&gt; distributed-stripe1.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/dis_str_volume/</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/38.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/dis_str_volume/</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/39.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs03节点</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># tree /brick3/dis_str_volume/</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># cat /brick3/dis_str_volume/distributed-stripe1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/40.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs04节点</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># tree /brick4/dis_str_volume/</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># cat /brick4/dis_str_volume/distributed-stripe1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/41.png" alt="img"></p><p><strong>结论：分布式条带卷将数据文件分布在多个条带集中，每个条带集中数据再以条带的形式存储在对应条带集中的全部brick上，数据无冗余备份。</strong></p><h2 id="条带镜像卷（Deprecated）"><a href="#条带镜像卷（Deprecated）" class="headerlink" title="条带镜像卷（Deprecated）"></a>条带镜像卷（Deprecated）</h2><p>条带复制卷（STRIPE REPLICA Volume），是条带与复制卷的组合，兼具两者的功能，特点如下：</p><ol><li>若干brick组成1个复制卷，另外若干brick组成其他复制卷；单个文件以条带的形式存储在2个或多个复制集（replicated sets ），复制集内文件分片以副本的形式保存；相当于文件级raid01；</li><li>brick server数量是副本数的倍数，且&gt;=2倍，即最少需要4台brick server。</li></ol><p><img src="/articles/35de9bb2/42.png" alt="img"></p><h2 id="分布式条带镜像卷（Deprecated）"><a href="#分布式条带镜像卷（Deprecated）" class="headerlink" title="分布式条带镜像卷（Deprecated）"></a>分布式条带镜像卷（Deprecated）</h2><p>分布式条带复制卷（DISTRIBUTE STRIPE REPLICA VOLUME），是分布式卷，条带与复制卷的组合，兼具三者的功能，特点如下：</p><ol><li>多个文件哈希分布到到多个条带集中，单个文件在条带集中以条带的形式存储在2个或多个复制集（replicated sets ），复制集内文件分片以副本的形式保存；</li><li>brick server数量是副本数的倍数，且&gt;=2倍，即最少需要4台brick server。</li></ol><p><img src="/articles/35de9bb2/43.png" alt="img"></p><h2 id="纠删卷"><a href="#纠删卷" class="headerlink" title="纠删卷"></a>纠删卷</h2><p>纠删卷（Dispersed Volumes）是v3.6版本后发布的一种volume特点如下：</p><ol><li>基于纠删码（erasure codes， EC）实现，类似于raid5/6（取决于redundancy等级）；</li><li>通过配置redundancy（冗余）级别提高可靠性，在保证较高的可靠性同时，可以提升物理存储空间的利用率；</li><li>文件被分割成大小相同的chunk(块)，每个chunk又被分割成fragment，冗余信息的fragment随之生成，且同一个fragment只会保存一个brick上；</li><li>redundancy均匀分布存储在所有的brick，逻辑卷的有效空间是<usable size> = <brick size> * (#bricks - redundancy)；</brick></usable></li><li>在数据恢复时，只要(#bricks - redundancy)个fragment（数据或冗余信息）可用，就能正常恢复数据；</li><li>卷中所有brick容量需要相同，否则最小的brick满容量时，数据无法写入；</li><li>实际部署时，redundancy &lt; #bricks / 2 (or equivalently, redundancy * 2 &lt; #bricks)，即brick至少是3个；redundancy设置为0时，DispersedVolume等同于分布式卷；若redundancy设置为brick/2时，DispersedVolume等同于复制卷。</li></ol><h4 id="创建纠删卷"><a href="#创建纠删卷" class="headerlink" title="创建纠删卷"></a>创建纠删卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create [disperse [&lt;count&gt;]] [redundancy &lt;count&gt;] [transport tcp | rdma | tcp,rdma]</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”disperse-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的brick server数量；</span></span><br><span class="line"><span class="comment"># 冗余等级”redundancy”需要根据使用brick server数量(“disperse conunt”)，并结合期望的冗余度数综合考量；</span></span><br><span class="line"><span class="comment"># 也可不设置冗余等级”redundancy”，系统会根据brick server数量(“disperse conunt”)自动计算最优值，确认即可；如disperse conunt=3，则redundancy=1（无“warning message”）；disperse conunt=6，则redundancy=2（有“warning message”）；但disperse conunt=4，则无最优值，此时使用默认redundancy=1（有“warning message”）；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式，默认即tcp；</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create disperse-volume disperse 3 transport tcp \</span></span><br><span class="line"> glusterfs01:/brick1/disperse_volume \</span><br><span class="line"> glusterfs02:/brick2/disperse_volume \</span><br><span class="line"> glusterfs03:/brick3/disperse_volume</span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/44.png" alt="img"></p><h4 id="启动卷-5"><a href="#启动卷-5" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 卷类型：disperse卷</span></span><br><span class="line"><span class="comment"># “Number of Bricks”：rudundancy=1，3个brick server</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start disperse-volume</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info disperse-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/45.png" alt="img"></p><h4 id="client挂载-5"><a href="#client挂载-5" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/disperse</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:disperse-volume /mnt/disperse/</span></span><br></pre></td></tr></table></figure><h4 id="查看挂载情况-5"><a href="#查看挂载情况-5" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是2个brick容量之和，&lt;usable size&gt; = &lt;brick size&gt; * (#bricks - redundancy)</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/46.png" alt="img"></p><h4 id="存储测试-5"><a href="#存储测试-5" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/disperse/</span></span><br><span class="line">[root@glusterfs-client disperse]<span class="comment"># touch disperse&#123;1..4&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向distributed-replica1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client disperse]<span class="comment"># echo "this is disperse1.txt" &gt;&gt; disperse1.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/disperse_volume/</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># cat /brick1/disperse_volume/disperse1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/47.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/disperse_volume/</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># cat /brick2/disperse_volume/disperse1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/48.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs03节点</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># tree /brick3/disperse_volume/</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># cat /brick3/disperse_volume/disperse1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/49.png" alt="img"></p><p><strong>结论：纠删卷将数据文件（含冗余信息）分布在多个brick中，数据有冗余。</strong></p><h2 id="分布式纠删卷"><a href="#分布式纠删卷" class="headerlink" title="分布式纠删卷"></a>分布式纠删卷</h2><p>分布式纠删卷（Distributed Dispersed Volumes）等效于分布式复制卷，但使用的是纠删子卷，而非复制子卷。</p><h1 id="Glusterfs管理"><a href="#Glusterfs管理" class="headerlink" title="Glusterfs管理"></a>Glusterfs管理</h1><h2 id="均衡卷"><a href="#均衡卷" class="headerlink" title="均衡卷"></a>均衡卷</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不迁移数据</span></span><br><span class="line">gluster volume VOLNAME rebalance [fix-layout start | start | startforce | status | stop]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修复卷（只针对复制卷）</span></span><br><span class="line">gluster volume heal REPLICATE-VOLNAME/DISPERSE-VOLNAME       <span class="comment">#只修复有问题的文件  </span></span><br><span class="line">gluster volume heal REPLICATE-VOLNAME/DISPERSE-VOLNAME full    <span class="comment">#修复所有文件  </span></span><br><span class="line">gluster volume heal REPLICATE-VOLNAME/DISPERSE-VOLNAME info    <span class="comment">#查看自愈详情  </span></span><br><span class="line">gluster volume heal REPLICATE-VOLNAME/DISPERSE-VOLNAME info healed|heal-failed|split-brain</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置卷</span></span><br><span class="line">gluster volume <span class="built_in">set</span> options</span><br></pre></td></tr></table></figure><h2 id="删除卷"><a href="#删除卷" class="headerlink" title="删除卷"></a>删除卷</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除卷操作，必须先停用卷；</span></span><br><span class="line"><span class="comment"># 最后可清空brick server节点对应目录下的内容</span></span><br><span class="line">gluster volume stop distributed-volume</span><br><span class="line">gluster volume delete distributed-volume</span><br><span class="line">rm -f /brick1/dis_volume</span><br></pre></td></tr></table></figure><h2 id="brick管理"><a href="#brick管理" class="headerlink" title="brick管理"></a>brick管理</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加brick</span></span><br><span class="line">gluster volume add-brick VOLNAME NEW-BRICK</span><br><span class="line"></span><br><span class="line"><span class="comment"># 移除brick</span></span><br><span class="line">gluster volume remove-brick VOLNAME BRICK [start | status | commit]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换brick</span></span><br><span class="line">gluster volume replace-brick VOLNAME BRICKNEW-BRICK [start | pause | sbortstatus | commit]</span><br></pre></td></tr></table></figure><h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p>相关日志，在/var/log/glusterfs/目录下，可根据需要查看；</p><p>如/var/log/glusterfs/brick/下是各brick创建的日志；</p><p>如/var/log/glusterfs/cmd_history.log是命令执行记录日志；</p><p>如/var/log/glusterfs/glusterd.log是glusterd守护进程日志。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Glusterfs逻辑卷创建与使用&quot;&gt;&lt;a href=&quot;#Glusterfs逻辑卷创建与使用&quot; class=&quot;headerlink&quot; title=&quot;Glusterfs逻辑卷创建与使用&quot;&gt;&lt;/a&gt;Glusterfs逻辑卷创建与使用&lt;/h1&gt;&lt;p&gt;volume是brick的组合，并且大部分glusterfs文件系统的操作都在volume上。&lt;/p&gt;
&lt;p&gt;glusterfs支持4种基本卷，并可以根据需求对4种基本卷进行组合形成多种扩展卷（得益于glusterfs的模块化堆栈架构设计）。&lt;/p&gt;
&lt;p&gt;以下主要展示各类型逻辑卷的功能性，未对性能做测试验证。&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.netlify.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="GlusterFS" scheme="https://wandouduoduo.netlify.com/tags/GlusterFS/"/>
    
  </entry>
  
</feed>
