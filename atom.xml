<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>豌豆多多</title>
  
  <subtitle>Senior O &amp; M Architect</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://wandouduoduo.netlify.com/"/>
  <updated>2020-06-23T06:27:58.136Z</updated>
  <id>https://wandouduoduo.netlify.com/</id>
  
  <author>
    <name>WanDouDuoDuo</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Centos7.x安装opensips并实现通话成功</title>
    <link href="https://wandouduoduo.netlify.com/articles/a63421f.html"/>
    <id>https://wandouduoduo.netlify.com/articles/a63421f.html</id>
    <published>2020-06-23T02:51:42.000Z</published>
    <updated>2020-06-23T06:27:58.136Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>先是使用<code>opensips</code>官方的<code>docker</code>尝试，好不容易装好了，软电话（<code>sipphone</code>）上注册不成功，主要是我<code>docker</code>又是装在<code>VirtualBox</code>的虚拟机里的，网络结构致使调试困难，直接新开一个虚拟机，很顺利的就安装成功并且实现局域网终端之间通话。</p><a id="more"></a><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h4 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install mysql mysql-server mysql-devel gcc gcc-c++ ncurses-devel flex bison -y</span><br></pre></td></tr></table></figure><p>机器上已经又<code>mysql</code>正常运行的话就跳过<code>mysql</code>相关的安装了。<br>注意在安装<code>mysql-server</code>的时候可能会出现找不到包，提示使用<code>mariadb-server</code>替代，那就老实使用<code>yum install mariadb-server mariadb</code>安装吧。</p><h4 id="mysql-设置密码并打开远程访问权限"><a href="#mysql-设置密码并打开远程访问权限" class="headerlink" title="mysql 设置密码并打开远程访问权限"></a>mysql 设置密码并打开远程访问权限</h4><p>装好的<code>mysql</code>启动默认是没有密码的，进入<code>mysql</code>后进去运行下面的代码。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 设置密码</span><br><span class="line"><span class="built_in">set</span> password <span class="keyword">for</span> <span class="string">'root'</span>@<span class="string">'localhost'</span> =password(<span class="string">'123456'</span>);</span><br><span class="line">// 设置远程访问及全表权限</span><br><span class="line">grant all privileges on *.* to root@<span class="string">'%'</span>identified by <span class="string">'123456'</span>;</span><br><span class="line">// 更新权限</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure><p>这里的设置根据需要来就好了。</p><h4 id="开启防火墙5060端口"><a href="#开启防火墙5060端口" class="headerlink" title="开启防火墙5060端口"></a>开启防火墙5060端口</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">firewall-cmd --zone=public --add-port=5060/udp --permanent</span><br><span class="line">firewall-cmd --reload</span><br></pre></td></tr></table></figure><h2 id="安装opensips"><a href="#安装opensips" class="headerlink" title="安装opensips"></a>安装opensips</h2><h4 id="下载源码并选择模块"><a href="#下载源码并选择模块" class="headerlink" title="下载源码并选择模块"></a>下载源码并选择模块</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src </span><br><span class="line">git <span class="built_in">clone</span> https://github.com/OpenSIPS/opensips.git -b 2.4 opensips-2.4</span><br><span class="line"><span class="built_in">cd</span> opensips-2.4</span><br><span class="line">make all</span><br><span class="line"><span class="comment"># 如果这里报错，停止，装好依赖再make all</span></span><br><span class="line">make menuconfig</span><br></pre></td></tr></table></figure><p><img src="/articles/a63421f/1.png" alt></p><p>进入这个菜单后，根据需要使用这个工具（左右键进入返回，空格键选中，回车键确定），但有个必须的是进入<code>Configure Compile Options</code>，选中<code>db_mysql</code>保存，返回主菜单选择<code>Compile And Install OpenSIPS</code>编译安装即可。完成后会回到这个界面，保存退出。</p><h4 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置文件目录</span></span><br><span class="line">ls /usr/<span class="built_in">local</span>/etc/opensips/</span><br><span class="line"></span><br><span class="line">opensips.cfg  opensipsctlrc  osipsconsolerc  scenario_callcenter.xml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行程序目录</span></span><br><span class="line">ls /usr/<span class="built_in">local</span>/sbin</span><br><span class="line"></span><br><span class="line">opensips  opensipsctl  opensipsdbctl  opensipsunix  osipsconfig  osipsconsole</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改配置</span></span><br><span class="line">vim opensipsctlrc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改后的配置</span></span><br><span class="line"><span class="comment"># $Id$</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># The OpenSIPS configuration file for the control tools.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Here you can set variables used in the opensipsctl and opensipsdbctl setup</span></span><br><span class="line"><span class="comment"># scripts. Per default all variables here are commented out, the control tools</span></span><br><span class="line"><span class="comment"># will use their internal default values.</span></span><br><span class="line"><span class="comment">## your SIP domain</span></span><br><span class="line">SIP_DOMAIN=192.168.0.191</span><br><span class="line"><span class="comment">## chrooted directory</span></span><br><span class="line"><span class="comment"># $CHROOT_DIR="/path/to/chrooted/directory"</span></span><br><span class="line"><span class="comment">## database type: MYSQL, PGSQL, ORACLE, DB_BERKELEY, DBTEXT, or SQLITE</span></span><br><span class="line"><span class="comment">## by default none is loaded</span></span><br><span class="line"><span class="comment"># If you want to setup a database with opensipsdbctl, you must at least specify</span></span><br><span class="line"><span class="comment"># this parameter.</span></span><br><span class="line">DBENGINE=MYSQL</span><br><span class="line"><span class="comment">## database port (PostgreSQL=5432 default; MYSQL=3306 default)</span></span><br><span class="line">DBPORT=3306</span><br><span class="line"><span class="comment">## database host</span></span><br><span class="line">DBHOST=localhost</span><br><span class="line"><span class="comment">## database name (for ORACLE this is TNS name)</span></span><br><span class="line">DBNAME=opensips</span><br><span class="line"><span class="comment"># database path used by dbtext, db_berkeley, or sqlite</span></span><br><span class="line">DB_PATH=<span class="string">"/usr/local/etc/opensips/dbtext"</span></span><br><span class="line"><span class="comment">## database read/write user</span></span><br><span class="line">DBRWUSER=opensips</span><br><span class="line"><span class="comment">## password for database read/write user</span></span><br><span class="line">DBRWPW=<span class="string">"opensipsrw"</span></span><br><span class="line"><span class="comment">## engine type for the MySQL/MariaDB tabels (default InnoDB)</span></span><br><span class="line">MYSQL_ENGINE=<span class="string">"MyISAM"</span></span><br><span class="line"><span class="comment">## database super user (for ORACLE this is 'scheme-creator' user)</span></span><br><span class="line">DBROOTUSER=<span class="string">"root"</span></span><br></pre></td></tr></table></figure><p>这里主要是<code>mysql</code>连接信息，保证能正常连接即可。还有一个<code>SIP_DOMAIN</code>能连接到本服务的域名或者<code>IP地址</code>即可。</p><p><strong>修改opensips.cfg</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim opensips.cfg</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改配置项</span></span><br><span class="line">listen=udp:192.168.0.191:5060 <span class="comment"># CUSTOMIZE ME</span></span><br></pre></td></tr></table></figure><p>这里如果你不确定该怎么填的话，运行下面的命令看一下，一般是本机<code>IP</code>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip route get 8.8.8.8 | head -n +1 | tr -s <span class="string">" "</span> | cut -d <span class="string">" "</span> -f 7</span><br></pre></td></tr></table></figure><h4 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/sbin</span><br><span class="line"></span><br><span class="line">opensipsdbctl create</span><br><span class="line">……</span><br><span class="line">INFO: creating database opensips ...</span><br><span class="line">INFO: Using table engine MyISAM.</span><br><span class="line">INFO: Core OpenSIPS tables successfully created.</span><br><span class="line">Install presence related tables? (Y/n): y</span><br><span class="line">INFO: creating presence tables into opensips ...</span><br><span class="line">INFO: Presence tables successfully created.</span><br><span class="line">Install tables <span class="keyword">for</span> </span><br><span class="line">    b2b</span><br><span class="line">    cachedb_sql</span><br><span class="line">    call_center</span><br><span class="line">    carrierroute</span><br><span class="line">    cpl</span><br><span class="line">    domainpolicy</span><br><span class="line">    emergency</span><br><span class="line">    fraud_detection</span><br><span class="line">    freeswitch_scripting</span><br><span class="line">    imc</span><br><span class="line">    registrant</span><br><span class="line">    siptrace</span><br><span class="line">    userblacklist</span><br><span class="line">? (Y/n): y</span><br><span class="line">INFO: creating extra tables into opensips ...</span><br><span class="line">INFO: Extra tables successfully created.</span><br></pre></td></tr></table></figure><p>之后就是根据提示傻瓜操作创建数据库就好了，如果前面的<code>mysql</code>环境没装好，数据库连接有问题，这里就会报错，如果提示类似下面的编码问题，输入<code>latin1</code>即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WARNING: Your current default mysql characters <span class="built_in">set</span> cannot be used to create DB. Please choice another one from the following list:</span><br></pre></td></tr></table></figure><p>这一步完成之后，会在数据库新建一个<code>opensips</code>（名字是在上面的配置文件里设置的）的数据库。</p><h4 id="启动opensips"><a href="#启动opensips" class="headerlink" title="启动opensips"></a>启动opensips</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">[root@localhost sbin]<span class="comment"># opensipsctl start</span></span><br><span class="line">INFO: Starting OpenSIPS : </span><br><span class="line">INFO: started (pid: 26051)</span><br><span class="line"><span class="comment"># 查看opensips进程</span></span><br><span class="line">[root@localhost sbin]<span class="comment"># ps -aux | grep opensips</span></span><br><span class="line">root      3504  0.0  0.4  70536  4420 ?        S    3月07   0:00 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3505  3.1  0.1  70776  1368 ?        S    3月07  12:35 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3506  0.1  0.0  70536   476 ?        S    3月07   0:29 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3507  0.0  0.0  70536   688 ?        S    3月07   0:08 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3508  0.0  0.2  70536  2396 ?        S    3月07   0:03 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3509  0.0  0.1  70536  1424 ?        S    3月07   0:01 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3510  0.0  0.1  70536  1912 ?        S    3月07   0:01 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3511  0.0  0.2  70536  2392 ?        S    3月07   0:01 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3512  0.0  0.1  70536  1164 ?        S    3月07   0:01 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line"><span class="comment"># 注册用户格式 opensipsctl 用户名 密码</span></span><br><span class="line">[root@localhost sbin]<span class="comment"># opensipsctl add 1001 1001</span></span><br><span class="line">new user <span class="string">'1001'</span> added</span><br><span class="line">[root@localhost sbin]<span class="comment"># opensipsctl add 1002 1002</span></span><br><span class="line">new user <span class="string">'1002'</span> added</span><br></pre></td></tr></table></figure><p>到这里就成功的启动了服务并添加了两个用户（1001，1002），下面我们来在局域网测试一下。</p><h4 id="测试通话"><a href="#测试通话" class="headerlink" title="测试通话"></a>测试通话</h4><p>在同一个局域网的手机上装上支持<code>sip</code>的软电话应用市场搜<code>sip phone</code>应该能找到不少，电脑端也有。<br>配置一般是这样的</p><p><img src="/articles/a63421f/2.png" alt></p><p>拨打电话成功</p><p><img src="/articles/a63421f/3.png" alt></p><p>配置好两个终端直接拨号就行了，号码就是1001，1002，经测试视频通话也是默认就支持的，很6哦。至此，借助<code>opensips</code>实现<code>sip</code>通话已经完成，只是实现最基本的功能，<code>opensips</code>还有很多好用的功能供大家来挖掘。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;先是使用&lt;code&gt;opensips&lt;/code&gt;官方的&lt;code&gt;docker&lt;/code&gt;尝试，好不容易装好了，软电话（&lt;code&gt;sipphone&lt;/code&gt;）上注册不成功，主要是我&lt;code&gt;docker&lt;/code&gt;又是装在&lt;code&gt;VirtualBox&lt;/code&gt;的虚拟机里的，网络结构致使调试困难，直接新开一个虚拟机，很顺利的就安装成功并且实现局域网终端之间通话。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Opensips" scheme="https://wandouduoduo.netlify.com/tags/Opensips/"/>
    
  </entry>
  
  <entry>
    <title>kubernetes1.18安装Dashboard</title>
    <link href="https://wandouduoduo.netlify.com/articles/674d1146.html"/>
    <id>https://wandouduoduo.netlify.com/articles/674d1146.html</id>
    <published>2020-06-22T04:06:34.000Z</published>
    <updated>2020-06-22T07:31:26.740Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>k8s的集群搭建已经完成，那么页面怎么管理呢？本文详细介绍k8s-dashboard页面管理。</p><a id="more"></a><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h4 id="下载yaml文件"><a href="#下载yaml文件" class="headerlink" title="下载yaml文件"></a>下载yaml文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/kubernetes/dashboard/v2.0.0/aio/deploy/recommended.yaml</span><br></pre></td></tr></table></figure><h4 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h4><p>修改kubernetes-dashboard的service类型为NodePort类型，使用nodeport方式访问Dashboard 。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[root@k8s-master</span> <span class="string">dashboard]#</span> <span class="string">vim</span> <span class="string">recommended.yaml</span> </span><br><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Service</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  type:</span> <span class="string">NodePort</span> <span class="comment"># 新增</span></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"><span class="attr">    - port:</span> <span class="number">443</span></span><br><span class="line"><span class="attr">      targetPort:</span> <span class="number">8443</span></span><br><span class="line"><span class="attr">      nodePort:</span> <span class="number">30443</span> <span class="comment"># 新增</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">kubernetes-dashboard</span></span><br></pre></td></tr></table></figure><h4 id="安装Dashboard"><a href="#安装Dashboard" class="headerlink" title="安装Dashboard"></a>安装Dashboard</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master dashboard]# kubectl create -f recommended.yaml </span><br><span class="line">namespace/kubernetes-dashboard created</span><br><span class="line">serviceaccount/kubernetes-dashboard created</span><br><span class="line">service/kubernetes-dashboard created</span><br><span class="line">secret/kubernetes-dashboard-certs created</span><br><span class="line">secret/kubernetes-dashboard-csrf created</span><br><span class="line">secret/kubernetes-dashboard-key-holder created</span><br><span class="line">configmap/kubernetes-dashboard-settings created</span><br><span class="line">role.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kubernetes-dashboard created</span><br><span class="line">deployment.apps/kubernetes-dashboard created</span><br><span class="line">service/dashboard-metrics-scraper created</span><br><span class="line">deployment.apps/dashboard-metrics-scraper created</span><br></pre></td></tr></table></figure><h4 id="确认状态"><a href="#确认状态" class="headerlink" title="确认状态"></a>确认状态</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master dashboard]# kubectl get pod,svc -n kubernetes-dashboard</span><br><span class="line">NAME                                            READY   STATUS    RESTARTS   AGE</span><br><span class="line">pod/dashboard-metrics-scraper-c79c65bb7-bpnbq   1/1     Running   0          2m52s</span><br><span class="line">pod/kubernetes-dashboard-56484d4c5-cthdm        1/1     Running   0          2m52s</span><br><span class="line"> </span><br><span class="line">NAME                                TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">service/dashboard-metrics-scraper   ClusterIP   10.105.74.63   &lt;none&gt;        8000/TCP        2m52s</span><br><span class="line">service/kubernetes-dashboard        NodePort    10.98.84.244   &lt;none&gt;        443:30444/TCP   2m52s</span><br></pre></td></tr></table></figure><h4 id="创建管理员用户yaml"><a href="#创建管理员用户yaml" class="headerlink" title="创建管理员用户yaml"></a>创建管理员用户yaml</h4><p>默认Dashboard为最小RBAC权限，添加集群管理员权限以便从Dashboard操作集群资源</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">[root@k8s-master</span> <span class="string">dashboard]#</span> <span class="string">vim</span> <span class="string">adminuser.yaml</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">admin-user</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">admin-user</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">rbac.authorization.k8s.io</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">cluster-admin</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">- kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">admin-user</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kubernetes-dashboard</span></span><br></pre></td></tr></table></figure><h4 id="创建管理员权限"><a href="#创建管理员权限" class="headerlink" title="创建管理员权限"></a>创建管理员权限</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master dashboard]<span class="comment"># kubectl create -f adminuser.yaml</span></span><br><span class="line">serviceaccount/admin-user created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/admin-user created</span><br><span class="line"></span><br><span class="line"><span class="comment"># 补充</span></span><br><span class="line"><span class="comment"># 如有报错，可以先删掉再重新创建</span></span><br><span class="line">kubectl delete -f ***.yaml</span><br></pre></td></tr></table></figure><h2 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h2><h4 id="浏览器访问https-IP-30443"><a href="#浏览器访问https-IP-30443" class="headerlink" title="浏览器访问https://IP:30443"></a>浏览器访问<a href="https://ip:30001/" target="_blank" rel="noopener">https://IP:304</a>43</h4><p><img src="/articles/674d1146/1.png" alt></p><h4 id="查看token"><a href="#查看token" class="headerlink" title="查看token"></a>查看token</h4><p>获取token，用于登录Dashboard UI</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master dashboard]<span class="comment"># kubectl -n kubernetes-dashboard describe secret $(kubectl -n kubernetes-dashboard get secret | grep admin-user | awk '&#123;print $1&#125;')</span></span><br><span class="line">Name:         admin-user-token-k4gdg</span><br><span class="line">Namespace:    kubernetes-dashboard</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubernetes.io/service-account.name: admin-user</span><br><span class="line">              kubernetes.io/service-account.uid: d116f560-15a2-45ca-930f-40f4fc12ce44</span><br><span class="line"> </span><br><span class="line">Type:  kubernetes.io/service-account-token</span><br><span class="line"> </span><br><span class="line">Data</span><br><span class="line">====</span><br><span class="line">ca.crt:     1025 bytes</span><br><span class="line">namespace:  20 bytes</span><br><span class="line">token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IlNEa2dTVGZhM09xd0MyNWtqaGFoZEc5R0NuYnVsZ0FfVlJQODNaQUFhZjgifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLWs0Z2RnIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiJkMTE2ZjU2MC0xNWEyLTQ1Y2EtOTMwZi00MGY0ZmMxMmNlNDQiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.qn98x11n4rPUGkDBU6ceImElgeVbM-b2SeXeeiUEm0rj41_vWXzlpd-r1Z1leuRHuveYnLpquR3QhMlFdjxLAIVAQ83KnDNhHyXYY08ZFeoGqGqlOWIAI-OCS9_IhClIskmmqYwA0kQ5AkHWbEsCKEMiYL-dZH7ECPziV0icFfBIYa6zK8-RLUBHR56rvzgjcap1WeTPdu84vr1jl8a4ZLMrzdwW_WmC4rsesA67DH6cQLgoKZRejGf6Sp4h7izO3DEwcGCUrNbg8biDRoqJwzusKoM7IJbC_C14Omg1kGrozFrMufHs8n7ujjpyuLeUyGjseX9eazlnyNkAwY0XIw</span><br></pre></td></tr></table></figure><h4 id="登录"><a href="#登录" class="headerlink" title="登录"></a>登录</h4><p>输入第二部获取到的token值，点击登录按钮</p><p><img src="/articles/674d1146/2.png" alt></p><p>Dashboard 概况画面如下</p><p><img src="/articles/674d1146/3.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;k8s的集群搭建已经完成，那么页面怎么管理呢？本文详细介绍k8s-dashboard页面管理。&lt;/p&gt;
    
    </summary>
    
      <category term="容器化" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Docker" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/Docker/"/>
    
    
      <category term="K8s" scheme="https://wandouduoduo.netlify.com/tags/K8s/"/>
    
  </entry>
  
  <entry>
    <title>centos7使用kubeadm安装kubernetes集群</title>
    <link href="https://wandouduoduo.netlify.com/articles/87f87b20.html"/>
    <id>https://wandouduoduo.netlify.com/articles/87f87b20.html</id>
    <published>2020-06-22T02:25:57.000Z</published>
    <updated>2020-06-22T07:31:05.136Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>Kubernetes是Google 2014年创建管理的，是Google 10多年大规模容器管理技术Borg的开源版本。它是容器集群管理系统，是一个开源的平台，可以实现容器集群的自动化部署、自动扩缩容、维护等功能。本文详细介绍了集群的搭建。</p><a id="more"></a><h2 id="规划"><a href="#规划" class="headerlink" title="规划"></a>规划</h2><p>一台master结点，两台node结点</p><table><thead><tr><th align="center">主机名</th><th align="center">IP</th><th align="center">OS</th><th align="center">配置</th></tr></thead><tbody><tr><td align="center">k8s-master</td><td align="center">192.168.6.201</td><td align="center">CentOS 7</td><td align="center">2 CPUs， 2G</td></tr><tr><td align="center">k8s-node1</td><td align="center">192.168.6.202</td><td align="center">CentOS 7</td><td align="center">2 CPUs， 2G</td></tr><tr><td align="center">k8s-node2</td><td align="center">192.168.6.203</td><td align="center">CentOS 7</td><td align="center">2 CPUs， 2G</td></tr></tbody></table><p>组件功能：</p><p><img src="/articles/87f87b20/1.png" alt></p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h4 id="设置主机名"><a href="#设置主机名" class="headerlink" title="设置主机名"></a>设置主机名</h4><p>192.168.6.201上执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置master节点主机名</span></span><br><span class="line">hostnamectl <span class="built_in">set</span>-hostname --static k8s-master</span><br></pre></td></tr></table></figure><p>192.168.6.202上执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置node1节点主机名</span></span><br><span class="line">hostnamectl <span class="built_in">set</span>-hostname --static k8s-node1</span><br></pre></td></tr></table></figure><p>192.168.6.203上执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置node2节点主机名</span></span><br><span class="line">hostnamectl <span class="built_in">set</span>-hostname --static k8s-node2</span><br></pre></td></tr></table></figure><h4 id="安装docker-ce"><a href="#安装docker-ce" class="headerlink" title="安装docker-ce"></a>安装docker-ce</h4><p>所有节点上（k8s-master, k8s-node1, k8s-node2）安装docker-ce：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装必要软件包</span></span><br><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 设置docker镜像源</span></span><br><span class="line">yum-config-manager --add-repo \</span><br><span class="line">  http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 安装docker-ce</span></span><br><span class="line">yum update -y &amp;&amp; yum install -y \</span><br><span class="line">  containerd.io-1.2.13 \</span><br><span class="line">  docker-ce-19.03.8 \</span><br><span class="line">  docker-ce-cli-19.03.8</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 启动docker，并设置开机自启</span></span><br><span class="line">systemctl <span class="built_in">enable</span> docker &amp;&amp; systemctl start docker</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 配置docker镜像加速</span></span><br><span class="line">cat &lt;&lt;EOF &gt;  /etc/docker/daemon.json</span><br><span class="line">&#123;</span><br><span class="line">  <span class="string">"exec-opts"</span>: [<span class="string">"native.cgroupdriver=systemd"</span>],</span><br><span class="line">  <span class="string">"registry-mirrors"</span>: [ <span class="string">"https://gcr.azk8s.cn"</span>, <span class="string">"https://docker.mirrors.ustc.edu.cn"</span>, <span class="string">"http://hub-mirror.c.163.com"</span>, <span class="string">"https://registry.docker-cn.com"</span>]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 重启docker</span></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><h4 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h4><p>所有节点上（k8s-master, k8s-node1, k8s-node2）做如下准备工作</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭firewalld</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 关闭SELinux</span></span><br><span class="line">setenforce 0</span><br><span class="line">sed -i <span class="string">'s/^SELINUX=enforcing$/SELINUX=disabled/'</span> /etc/selinux/config</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 关闭swap</span></span><br><span class="line">swapoff -a</span><br><span class="line">sed -i <span class="string">"s/\/dev\/mapper\/centos-swap/# \/dev\/mapper\/centos-swap/"</span> /etc/fstab</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 设置iptables</span></span><br><span class="line">cat &lt;&lt;EOF &gt;  /etc/sysctl.d/k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line">sysctl --system</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 载入br_netfilter模块</span></span><br><span class="line">modprobe br_netfilter</span><br></pre></td></tr></table></figure><h4 id="安装kubelet-kubeadm-kubectl"><a href="#安装kubelet-kubeadm-kubectl" class="headerlink" title="安装kubelet kubeadm kubectl"></a>安装kubelet kubeadm kubectl</h4><p>所有节点上（k8s-master, k8s-node1, k8s-node2）安装kubelet kubeadm kubectl：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置kubernetes镜像源</span></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 安装kubelet kubeadm kubectl</span></span><br><span class="line">yum install -y kubelet kubeadm kubectl –disableexcludes=kubernetes</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 启动kubelet kubeadm kubectl，并设置开机自启</span></span><br><span class="line">systemctl <span class="built_in">enable</span> kubelet &amp;&amp; systemctl start kubelet</span><br></pre></td></tr></table></figure><h4 id="下载镜像"><a href="#下载镜像" class="headerlink" title="下载镜像"></a>下载镜像</h4><p>k8s-master节点上执行如下命令获取下载镜像所需列表</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取所需镜像列表</span></span><br><span class="line">[root@k8s-master ~]<span class="comment"># kubeadm config images list</span></span><br><span class="line">W0523 16:59:15.466625   24669 configset.go:202] WARNING: kubeadm cannot validate component configs <span class="keyword">for</span> API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]</span><br><span class="line">k8s.gcr.io/kube-apiserver:v1.18.3</span><br><span class="line">k8s.gcr.io/kube-controller-manager:v1.18.3</span><br><span class="line">k8s.gcr.io/kube-scheduler:v1.18.3</span><br><span class="line">k8s.gcr.io/kube-proxy:v1.18.3</span><br><span class="line">k8s.gcr.io/pause:3.2</span><br><span class="line">k8s.gcr.io/etcd:3.4.3-0</span><br><span class="line">k8s.gcr.io/coredns:1.6.7</span><br></pre></td></tr></table></figure><p>由于国内无法访问k8s.gcr.io镜像仓库，先从daocloud.io镜像仓库下载所需镜像，然后修改镜像标签</p><p>所有节点上（k8s-master, k8s-node1, k8s-node2）下载安装kubernetes集群所需镜像</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载镜像</span></span><br><span class="line">docker pull daocloud.io/daocloud/kube-apiserver:v1.18.3</span><br><span class="line">docker pull daocloud.io/daocloud/kube-controller-manager:v1.18.3</span><br><span class="line">docker pull daocloud.io/daocloud/kube-scheduler:v1.18.3</span><br><span class="line">docker pull daocloud.io/daocloud/kube-proxy:v1.18.3</span><br><span class="line">docker pull daocloud.io/daocloud/pause:3.2</span><br><span class="line">docker pull daocloud.io/daocloud/etcd:3.4.3-0</span><br><span class="line">docker pull daocloud.io/daocloud/coredns:1.6.7</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 给镜像打tag</span></span><br><span class="line">docker tag daocloud.io/daocloud/kube-apiserver:v1.18.3 k8s.gcr.io/kube-apiserver:v1.18.3</span><br><span class="line">docker tag daocloud.io/daocloud/kube-controller-manager:v1.18.3 k8s.gcr.io/kube-controller-manager:v1.18.3</span><br><span class="line">docker tag daocloud.io/daocloud/kube-scheduler:v1.18.3 k8s.gcr.io/kube-scheduler:v1.18.3</span><br><span class="line">docker tag daocloud.io/daocloud/kube-proxy:v1.18.3 k8s.gcr.io/kube-proxy:v1.18.3</span><br><span class="line">docker tag daocloud.io/daocloud/pause:3.2 k8s.gcr.io/pause:3.2</span><br><span class="line">docker tag daocloud.io/daocloud/etcd:3.4.3-0 k8s.gcr.io/etcd:3.4.3-0</span><br><span class="line">docker tag daocloud.io/daocloud/coredns:1.6.7 k8s.gcr.io/coredns:1.6.7</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 清理原镜像</span></span><br><span class="line">docker rmi daocloud.io/daocloud/kube-apiserver:v1.18.3</span><br><span class="line">docker rmi daocloud.io/daocloud/kube-controller-manager:v1.18.3</span><br><span class="line">docker rmi daocloud.io/daocloud/kube-scheduler:v1.18.3</span><br><span class="line">docker rmi daocloud.io/daocloud/kube-proxy:v1.18.3</span><br><span class="line">docker rmi daocloud.io/daocloud/pause:3.2</span><br><span class="line">docker rmi daocloud.io/daocloud/etcd:3.4.3-0</span><br><span class="line">docker rmi daocloud.io/daocloud/coredns:1.6.7</span><br></pre></td></tr></table></figure><p>为了简化上述拉取镜像操作，特意写了个批量脚本:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">vim sun-k8s.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">ImageLists=`kubeadm config images list 2&gt;/dev/null`</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$&#123;ImageLists[@]&#125;</span>;<span class="keyword">do</span></span><br><span class="line">imagename=`<span class="built_in">echo</span> <span class="variable">$i</span>|awk -F\/ <span class="string">'&#123;print $2&#125;'</span>`</span><br><span class="line">srcimage=<span class="string">"daocloud.io/daocloud/<span class="variable">$&#123;imagename&#125;</span>"</span></span><br><span class="line">docker pull <span class="variable">$&#123;srcimage&#125;</span></span><br><span class="line">docker tag <span class="variable">$&#123;srcimage&#125;</span> k8s.gcr.io/<span class="variable">$&#123;imagename&#125;</span></span><br><span class="line">docker rmi <span class="variable">$&#123;srcimage&#125;</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h4 id="初始化master节点"><a href="#初始化master节点" class="headerlink" title="初始化master节点"></a>初始化master节点</h4><p>在k8s-master节点上执行初始化操作</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化master</span></span><br><span class="line">kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address 192.168.92.201</span><br></pre></td></tr></table></figure><p>日志如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化master</span></span><br><span class="line">[root@k8s-master ~]<span class="comment"># kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address 192.168.92.201</span></span><br><span class="line">W0523 16:21:59.515265   10688 version.go:102] could not fetch a Kubernetes version from the internet: unable to get URL <span class="string">"https://dl.k8s.io/release/stable-1.txt"</span>: Get https://dl.k8s.io/release/stable-1.txt: net/http: request canceled <span class="keyword">while</span> waiting <span class="keyword">for</span> connection (Client.Timeout exceeded <span class="keyword">while</span> awaiting headers)</span><br><span class="line">W0523 16:21:59.515315   10688 version.go:103] falling back to the <span class="built_in">local</span> client version: v1.18.3</span><br><span class="line">W0523 16:21:59.515387   10688 configset.go:202] WARNING: kubeadm cannot validate component configs <span class="keyword">for</span> API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]</span><br><span class="line">[init] Using Kubernetes version: v1.18.3</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">error execution phase preflight: [preflight] Some fatal errors occurred:</span><br><span class="line">        [ERROR Swap]: running with swap on is not supported. Please <span class="built_in">disable</span> swap</span><br><span class="line">[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`</span><br><span class="line">To see the stack trace of this error execute with --v=5 or higher</span><br><span class="line">[root@k8s-master ~]<span class="comment"># swapoff -a    </span></span><br><span class="line">[root@k8s-master ~]<span class="comment"># kubeadm init --pod-network-cidr=10.244.0.0/16 --apiserver-advertise-address 192.168.92.201</span></span><br><span class="line">W0523 16:22:26.828070   10824 configset.go:202] WARNING: kubeadm cannot validate component configs <span class="keyword">for</span> API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]</span><br><span class="line">[init] Using Kubernetes version: v1.18.3</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Pulling images required <span class="keyword">for</span> setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action <span class="keyword">in</span> beforehand using <span class="string">'kubeadm config images pull'</span></span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file <span class="string">"/var/lib/kubelet/kubeadm-flags.env"</span></span><br><span class="line">[kubelet-start] Writing kubelet configuration to file <span class="string">"/var/lib/kubelet/config.yaml"</span></span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[certs] Using certificateDir folder <span class="string">"/etc/kubernetes/pki"</span></span><br><span class="line">[certs] Generating <span class="string">"ca"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"apiserver"</span> certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed <span class="keyword">for</span> DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.92.201]</span><br><span class="line">[certs] Generating <span class="string">"apiserver-kubelet-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"front-proxy-ca"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"front-proxy-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"etcd/ca"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"etcd/server"</span> certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed <span class="keyword">for</span> DNS names [k8s-master localhost] and IPs [192.168.92.201 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating <span class="string">"etcd/peer"</span> certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed <span class="keyword">for</span> DNS names [k8s-master localhost] and IPs [192.168.92.201 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating <span class="string">"etcd/healthcheck-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"apiserver-etcd-client"</span> certificate and key</span><br><span class="line">[certs] Generating <span class="string">"sa"</span> key and public key</span><br><span class="line">[kubeconfig] Using kubeconfig folder <span class="string">"/etc/kubernetes"</span></span><br><span class="line">[kubeconfig] Writing <span class="string">"admin.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"kubelet.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"controller-manager.conf"</span> kubeconfig file</span><br><span class="line">[kubeconfig] Writing <span class="string">"scheduler.conf"</span> kubeconfig file</span><br><span class="line">[control-plane] Using manifest folder <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-apiserver"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-controller-manager"</span></span><br><span class="line">W0523 16:22:29.441917   10824 manifests.go:225] the default kube-apiserver authorization-mode is <span class="string">"Node,RBAC"</span>; using <span class="string">"Node,RBAC"</span></span><br><span class="line">[control-plane] Creating static Pod manifest <span class="keyword">for</span> <span class="string">"kube-scheduler"</span></span><br><span class="line">W0523 16:22:29.442422   10824 manifests.go:225] the default kube-apiserver authorization-mode is <span class="string">"Node,RBAC"</span>; using <span class="string">"Node,RBAC"</span></span><br><span class="line">[etcd] Creating static Pod manifest <span class="keyword">for</span> <span class="built_in">local</span> etcd <span class="keyword">in</span> <span class="string">"/etc/kubernetes/manifests"</span></span><br><span class="line">[<span class="built_in">wait</span>-control-plane] Waiting <span class="keyword">for</span> the kubelet to boot up the control plane as static Pods from directory <span class="string">"/etc/kubernetes/manifests"</span>. This can take up to 4m0s</span><br><span class="line">[apiclient] All control plane components are healthy after 15.006156 seconds</span><br><span class="line">[upload-config] Storing the configuration used <span class="keyword">in</span> ConfigMap <span class="string">"kubeadm-config"</span> <span class="keyword">in</span> the <span class="string">"kube-system"</span> Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap <span class="string">"kubelet-config-1.18"</span> <span class="keyword">in</span> namespace kube-system with the configuration <span class="keyword">for</span> the kubelets <span class="keyword">in</span> the cluster</span><br><span class="line">[upload-certs] Skipping phase. Please see --upload-certs</span><br><span class="line">[mark-control-plane] Marking the node k8s-master as control-plane by adding the label <span class="string">"node-role.kubernetes.io/master=''"</span></span><br><span class="line">[mark-control-plane] Marking the node k8s-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[bootstrap-token] Using token: 19jjaa.6q8jc5u15ykqqoyf</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs <span class="keyword">in</span> order <span class="keyword">for</span> nodes to get long term certificate credentials</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow certificate rotation <span class="keyword">for</span> all node client certificates <span class="keyword">in</span> the cluster</span><br><span class="line">[bootstrap-token] Creating the <span class="string">"cluster-info"</span> ConfigMap <span class="keyword">in</span> the <span class="string">"kube-public"</span> namespace</span><br><span class="line">[kubelet-finalize] Updating <span class="string">"/etc/kubernetes/kubelet.conf"</span> to point to a rotatable kubelet client certificate and key</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"> </span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"> </span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"> </span><br><span class="line">  mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"> </span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">"kubectl apply -f [podnetwork].yaml"</span> with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"> </span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"> </span><br><span class="line">kubeadm join 192.168.92.201:6443 --token 19jjaa.6q8jc5u15ykqqoyf \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:36f3a6a07d7007712a6c103fd276716716bbe420101374186ddf01fb4dc24f2b </span><br><span class="line">[root@k8s-master ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure><p>在k8s-master节点上按照提示执行如下命令:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><h4 id="安装网络插件"><a href="#安装网络插件" class="headerlink" title="安装网络插件"></a>安装网络插件</h4><p>这里选择安装flannel网络插件，也可以安装其他网络插件。master节点上安装flannel网络插件:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载kube-flannel.yaml</span></span><br><span class="line">wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 安装flannel插件</span></span><br><span class="line">kubectl apply -f kube-flannel.yml</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 确认pod状态，直到所有pod变为running</span></span><br><span class="line">kubectl get pod --all-namespaces</span><br></pre></td></tr></table></figure><p>pod状态确认结果如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master ~]# kubectl get pod --all-namespaces</span><br><span class="line">NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system   coredns-66bff467f8-d47nh             1/1     Running   0          11m</span><br><span class="line">kube-system   coredns-66bff467f8-xh6rc             1/1     Running   0          11m</span><br><span class="line">kube-system   etcd-k8s-master                      1/1     Running   0          12m</span><br><span class="line">kube-system   kube-apiserver-k8s-master            1/1     Running   0          12m</span><br><span class="line">kube-system   kube-controller-manager-k8s-master   1/1     Running   0          12m</span><br><span class="line">kube-system   kube-flannel-ds-amd64-sb6vm          1/1     Running   0          2m17s</span><br><span class="line">kube-system   kube-proxy-lxhjf                     1/1     Running   0          11m</span><br><span class="line">kube-system   kube-scheduler-k8s-master            1/1     Running   0          12m</span><br><span class="line">[root@k8s-master ~]#</span><br></pre></td></tr></table></figure><h4 id="加入node节点"><a href="#加入node节点" class="headerlink" title="加入node节点"></a>加入node节点</h4><p>master初始化成功时，屏幕会输出加入节点的命令如下所示:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加入节点</span></span><br><span class="line"><span class="comment"># Then you can join any number of worker nodes by running the following on each as root:</span></span><br><span class="line"> </span><br><span class="line">kubeadm join 192.168.92.201:6443 --token 19jjaa.6q8jc5u15ykqqoyf \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:36f3a6a07d7007712a6c103fd276716716bbe420101374186ddf01fb4dc24f2b</span><br></pre></td></tr></table></figure><p>两台node节点上都执行加入节点命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node1 ~]<span class="comment"># kubeadm join 192.168.92.201:6443 --token 19jjaa.6q8jc5u15ykqqoyf \</span></span><br><span class="line">&gt;     --discovery-token-ca-cert-hash sha256:36f3a6a07d7007712a6c103fd276716716bbe420101374186ddf01fb4dc24f2b </span><br><span class="line">W0523 16:37:35.582972   11590 join.go:346] [preflight] WARNING: JoinControlPane.controlPlane settings will be ignored when control-plane flag is not <span class="built_in">set</span>.</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">[preflight] Reading configuration from the cluster...</span><br><span class="line">[preflight] FYI: You can look at this config file with <span class="string">'kubectl -n kube-system get cm kubeadm-config -oyaml'</span></span><br><span class="line">[kubelet-start] Downloading configuration <span class="keyword">for</span> the kubelet from the <span class="string">"kubelet-config-1.18"</span> ConfigMap <span class="keyword">in</span> the kube-system namespace</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file <span class="string">"/var/lib/kubelet/config.yaml"</span></span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file <span class="string">"/var/lib/kubelet/kubeadm-flags.env"</span></span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[kubelet-start] Waiting <span class="keyword">for</span> the kubelet to perform the TLS Bootstrap...</span><br><span class="line"> </span><br><span class="line">This node has joined the cluster:</span><br><span class="line">* Certificate signing request was sent to apiserver and a response was received.</span><br><span class="line">* The Kubelet was informed of the new secure connection details.</span><br><span class="line"> </span><br><span class="line">Run <span class="string">'kubectl get nodes'</span> on the control-plane to see this node join the cluster.</span><br><span class="line"> </span><br><span class="line">[root@k8s-node1 ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure><h4 id="确认集群状态"><a href="#确认集群状态" class="headerlink" title="确认集群状态"></a>确认集群状态</h4><p>kubernetes集群安装完成，确认集群状态：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 确认node状态</span></span><br><span class="line">[root@k8s-master ~]<span class="comment"># kubectl get nodes</span></span><br><span class="line">NAME         STATUS   ROLES    AGE     VERSION</span><br><span class="line">k8s-master   Ready    master   21m     v1.18.3</span><br><span class="line">k8s-node1    Ready    &lt;none&gt;   6m19s   v1.18.3</span><br><span class="line">k8s-node2    Ready    &lt;none&gt;   6m14s   v1.18.3</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 确认pod状态</span></span><br><span class="line">[root@k8s-master ~]<span class="comment"># kubectl get pod --all-namespaces -o wide</span></span><br><span class="line">NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE     IP               NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">kube-system   coredns-66bff467f8-d47nh             1/1     Running   0          21m     10.244.0.2       k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   coredns-66bff467f8-xh6rc             1/1     Running   0          21m     10.244.0.3       k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   etcd-k8s-master                      1/1     Running   0          21m     192.168.92.201   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-apiserver-k8s-master            1/1     Running   0          21m     192.168.92.201   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-controller-manager-k8s-master   1/1     Running   0          21m     192.168.92.201   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-47tnz          1/1     Running   0          23s     192.168.92.201   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-74smd          1/1     Running   0          23s     192.168.92.202   k8s-node1    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-flannel-ds-amd64-srstj          1/1     Running   0          23s     192.168.92.203   k8s-node2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-2j7m8                     1/1     Running   0          6m22s   192.168.92.203   k8s-node2    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-lxhjf                     1/1     Running   0          21m     192.168.92.201   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-proxy-zwxhp                     1/1     Running   0          6m27s   192.168.92.202   k8s-node1    &lt;none&gt;           &lt;none&gt;</span><br><span class="line">kube-system   kube-scheduler-k8s-master            1/1     Running   0          21m     192.168.92.201   k8s-master   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure><p>至此，k8s集群已搭建完成，enjoy  it。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;Kubernetes是Google 2014年创建管理的，是Google 10多年大规模容器管理技术Borg的开源版本。它是容器集群管理系统，是一个开源的平台，可以实现容器集群的自动化部署、自动扩缩容、维护等功能。本文详细介绍了集群的搭建。&lt;/p&gt;
    
    </summary>
    
      <category term="容器化" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/"/>
    
      <category term="Docker" scheme="https://wandouduoduo.netlify.com/categories/%E5%AE%B9%E5%99%A8%E5%8C%96/Docker/"/>
    
    
      <category term="K8s" scheme="https://wandouduoduo.netlify.com/tags/K8s/"/>
    
  </entry>
  
  <entry>
    <title>如何让es保留固定天数的数据</title>
    <link href="https://wandouduoduo.netlify.com/articles/8e6c2d39.html"/>
    <id>https://wandouduoduo.netlify.com/articles/8e6c2d39.html</id>
    <published>2020-06-17T02:45:07.000Z</published>
    <updated>2020-06-20T02:45:30.603Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>elk为常见的日志分析平台，在很多公司都用使用，但是日志数据是一个不断海量增加的东西，如果没有太大的存储来存储这些日志历史数据，就会需要删除时间过长的历史数据，以保证数据量可控。</p><a id="more"></a><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>elk中elasticsearch为搜索引擎，也是数据的储存单元。要想实现只保留固定时间的数据，这里以7天为例，要想每个索引的数据都只保留最近7天的数据，大于7天的则删除，有两种方法：</p><ol><li><p>看你的索引是怎么样的，如果你的索引名称中有时间，比如logstash-2019-01-02 这样，就是每天都会生成一个新的索引，这样的话可以使用官方的Curator 工具</p></li><li><p>如果你的索引中不带时间，比如，如果是根据应用或者服务名来命名的，那么注意，Curator是无法实现删除索中的某一段数据的！！这里需要特别注意，网上很多说可以实现的，那是因为他们的索引如上面1 所说，是根据时间日期来生成的。但实际上，很多索引都不是这样的，按正常的思维，更容易用服务名或应用名作为索引，以此来区分日志所属应用，方便日志的分析对应指定的应用。这种时候需要使用elasticsearch的api：delete_by_query来进行删除指定数据。这种方法也是通用的，更推荐用这种方法。</p></li></ol><h2 id="使用API"><a href="#使用API" class="headerlink" title="使用API"></a>使用API</h2><p>删除指定的数据，需要使用到delete_by_query接口，这里需要科普一下，在elk中，每一条日志数据就是一个doc文档，如下：每条数据都会有一个_index,_type,_id 分别就是索引，类型，id。</p><p><img src="/articles/8e6c2d39/1.png" alt></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">delete_by_query的接口格式如下：</span><br><span class="line">请求方式为：post  </span><br><span class="line">url为： http://elasticsearch-host:9200/&#123;index&#125;/_delete_by_query?conflicts=proceed</span><br><span class="line">需要传参数，通过参数执行选择的数据，传参格式为json。</span><br></pre></td></tr></table></figure><p>下面以删除所有索引，超过7天的历史数据为例，用python写成的脚本如下，可以直接拿去用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"> </span><br><span class="line">es_host = <span class="string">'127.0.0。1'</span> <span class="comment"># Elasticsearch访问地址</span></span><br><span class="line"> </span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'Content-Type'</span>: <span class="string">'application/json'</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 这里url中，用*匹配所有的索引，也可以写成logstash-* 匹配所有以logstash-开头的索引等等。</span></span><br><span class="line">url = <span class="string">'http://&#123;&#125;:9200/*/_delete_by_query?conflicts=proceed'</span>.format(es_host)</span><br><span class="line"> </span><br><span class="line">data = &#123;</span><br><span class="line">    <span class="string">"query"</span>: &#123;</span><br><span class="line">        <span class="string">"range"</span>: &#123;</span><br><span class="line">            <span class="string">"@timestamp"</span>: &#123;    <span class="comment"># 这里我根据默认的时间来作为查询的时间字段，也可以是自定义的</span></span><br><span class="line">                <span class="string">"lt"</span>: <span class="string">"now-7d"</span>,    <span class="comment"># 这里是7天，时间可自定义</span></span><br><span class="line">                <span class="string">"format"</span>: <span class="string">"epoch_millis"</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">response = requests.post(url, headers=headers, data=json.dumps(data))</span><br><span class="line">print(response.json())</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 删除后，需要执行forcemerge操作，手动释放磁盘空间</span></span><br><span class="line">url2 =<span class="string">'http://&#123;&#125;:9200/_forcemerge?only_expunge_deletes=true&amp;max_num_segments=1'</span>.format(es_host)</span><br><span class="line">response = requests.post(url2)</span><br><span class="line"> </span><br><span class="line">print(response.json())</span><br></pre></td></tr></table></figure><p>以上，就是一个完整的删除索引的历史数据的一个脚本，然后只需要将此脚本添加到crontab中，每天定时执行以此就可以实现只保留固定时间的数据了。</p><h2 id="Es-Curator"><a href="#Es-Curator" class="headerlink" title="Es Curator"></a>Es Curator</h2><h4 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h4><p>curator 是一个官方的，可以管理elasticsearch索引的工具，可以实现创建，删除，段合并等等操作。</p><h4 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h4><p><a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/index.html" target="_blank" rel="noopener">官方文档</a></p><h4 id="版本"><a href="#版本" class="headerlink" title="版本"></a>版本</h4><p><img src="/articles/8e6c2d39/2.png" alt></p><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>安装非常简单，直接通过pip安装即可。 其他安装方案，详见官方文档：<a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/installation.html" target="_blank" rel="noopener">安装</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install elasticsearch-curator</span><br></pre></td></tr></table></figure><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><p> 安装后，便可以在命令行中直接使用，使用–help查看一下使用方法</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">curator --<span class="built_in">help</span></span><br><span class="line">Usage: curator [OPTIONS] ACTION_FILE</span><br><span class="line"> </span><br><span class="line">  Curator <span class="keyword">for</span> Elasticsearch indices.</span><br><span class="line"> </span><br><span class="line">  See http://elastic.co/guide/en/elasticsearch/client/curator/current</span><br><span class="line"> </span><br><span class="line">Options:</span><br><span class="line">  --config PATH  Path to configuration file. Default: ~/.curator/curator.yml</span><br><span class="line">  --dry-run      Do not perform any changes.</span><br><span class="line">  --version      Show the version and <span class="built_in">exit</span>.</span><br><span class="line">  --<span class="built_in">help</span>         Show this message and <span class="built_in">exit</span>.</span><br></pre></td></tr></table></figure><p>看到使用需要定义两个文件，一个配置文件 curator,.yml 和 操作文件 action.yml</p><p>配置文件 curator.yml 示例如下： 详细的配置文件配置方法，详见官方文档： <a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/configfile.html" target="_blank" rel="noopener">配置文件curator.yml</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">client:</span><br><span class="line">  hosts:</span><br><span class="line">    - 127.0.0.1</span><br><span class="line">  port: 9200</span><br><span class="line">  url_prefix:</span><br><span class="line">  use_ssl: False</span><br><span class="line">  certificate:</span><br><span class="line">  client_cert:</span><br><span class="line">  client_key:</span><br><span class="line">  ssl_no_validate: False</span><br><span class="line">  <span class="comment"># 下面用户名密码修改为自己es的用户密码</span></span><br><span class="line">  http_auth: elastic:123456</span><br><span class="line">  timeout:</span><br><span class="line">  master_only: True</span><br><span class="line"> </span><br><span class="line">logging:</span><br><span class="line">  loglevel: INFO</span><br><span class="line">  logfile:</span><br><span class="line">  logformat: default</span><br><span class="line">  blacklist: [<span class="string">'elasticsearch'</span>, <span class="string">'urllib3'</span>]</span><br></pre></td></tr></table></figure><p>然后就是action.yml 文件，定义需要执行的操作，我们这里需要删除索引中时间过长的历史数据，详细的操作文件action.yml配置的字段和用法，详见官方文档： </p><p><a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/actions.html" target="_blank" rel="noopener">action操作类型定义</a></p><p><a href="https://www.elastic.co/guide/en/elasticsearch/client/curator/current/filters.html" target="_blank" rel="noopener">filters过滤器定义</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">actions:</span><br><span class="line">  1:</span><br><span class="line">    action: delete_indices    <span class="comment"># 这里执行操作类型为删除索引</span></span><br><span class="line">    description: <span class="string">"delete index expire date"</span></span><br><span class="line">    options:</span><br><span class="line">      ignore_empty_list: True</span><br><span class="line">      timeout_override:</span><br><span class="line">      continue_if_exception: False</span><br><span class="line">      disable_action: False</span><br><span class="line">    filters:</span><br><span class="line">    - filtertype: pattern</span><br><span class="line">      kind: prefix    <span class="comment"># 这里是指匹配前缀为 “yaobili-” 的索引，还可以支持正则匹配等，详见官方文档</span></span><br><span class="line">      value: logstash-</span><br><span class="line">    <span class="comment"># 这里匹配时间</span></span><br><span class="line">    - filtertype: age</span><br><span class="line">      <span class="built_in">source</span>: name    <span class="comment"># 这里不单可以根据name来匹配，还可以根据字段等，详见官方文档</span></span><br><span class="line">      direction: older</span><br><span class="line">    <span class="comment"># 这里定义的是days，还有weeks，months等，总时间为unit * unit_count</span></span><br><span class="line">      unit: days</span><br><span class="line">      unit_count: 7</span><br><span class="line">      timestring: <span class="string">'%Y.%m.%d'</span>    <span class="comment"># 这里是跟在logstash-后面的时间的格式</span></span><br></pre></td></tr></table></figure><p>ok，定义了两个文件后，则可以直接使用命令行进行执行：指定两个文件的路径即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">curator --config curator.yml action.yml </span><br><span class="line">输出日志：</span><br><span class="line">2020-06-17 13:53:39,840 INFO      Preparing Action ID: 1, <span class="string">"delete_indices"</span></span><br><span class="line">2020-06-17 13:53:39,840 INFO      Creating client object and testing connection</span><br><span class="line">2020-06-17 13:53:39,842 INFO      Instantiating client object</span><br><span class="line">2020-06-17 13:53:39,843 INFO      Testing client connectivity</span><br><span class="line">2020-06-17 13:53:39,847 INFO      Successfully created Elasticsearch client object with provided settings</span><br><span class="line">2020-06-17 13:53:39,849 INFO      Connecting only to <span class="built_in">local</span> master node...</span><br><span class="line">2020-06-17 13:53:39,858 INFO      Trying Action ID: 1, <span class="string">"delete_indices"</span>: delete index expire date</span><br><span class="line">2020-06-17 13:53:39,991 INFO      Skipping action <span class="string">"delete_indices"</span> due to empty list: &lt;class <span class="string">'curator.exceptions.NoIndices'</span>&gt;</span><br><span class="line">2020-06-17 13:53:39,992 INFO      Action ID: 1, <span class="string">"delete_indices"</span> completed.</span><br><span class="line">2020-06-17 13:53:39,992 INFO      Job completed.</span><br></pre></td></tr></table></figure><p>最后，将此命令添加到crontab中即可。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;elk为常见的日志分析平台，在很多公司都用使用，但是日志数据是一个不断海量增加的东西，如果没有太大的存储来存储这些日志历史数据，就会需要删除时间过长的历史数据，以保证数据量可控。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Elk" scheme="https://wandouduoduo.netlify.com/tags/Elk/"/>
    
  </entry>
  
  <entry>
    <title>lvs的三次实践</title>
    <link href="https://wandouduoduo.netlify.com/articles/eb3c6886.html"/>
    <id>https://wandouduoduo.netlify.com/articles/eb3c6886.html</id>
    <published>2020-06-11T11:31:15.000Z</published>
    <updated>2020-06-11T12:08:05.913Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文详细介绍了lvs的三次实践。</p><a id="more"></a><h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><h4 id="NAT模式"><a href="#NAT模式" class="headerlink" title="NAT模式"></a><strong>NAT模式</strong></h4><p><strong>实验环境</strong></p><p>三台服务器，一台作为 director，两台作为 real server。</p><p>director 有一个外网网卡(172.16.254.200) 和一个内网ip(192.168.0.8)，两个 real server 上只有内网 ip (192.168.0.18) 和 (192.168.0.28)，并且需要把两个 real server 的内网网关设置为 director 的内网 ip(192.168.0.8)。</p><p><strong>安装和配置</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#两个 real server 上都安装 nginx 服务</span></span><br><span class="line">yum install -y nginx</span><br><span class="line"></span><br><span class="line"><span class="comment">#Director 上安装 ipvsadm</span></span><br><span class="line">yum install -y ipvsadm</span><br></pre></td></tr></table></figure><p>Director 上编辑 nat 实现脚本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /usr/local/sbin/lvs_nat.sh</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑写入如下内容：</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"><span class="comment"># director服务器上开启路由转发功能:</span></span><br><span class="line"><span class="built_in">echo</span> 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br><span class="line"><span class="comment"># 关闭 icmp 的重定向</span></span><br><span class="line"><span class="built_in">echo</span> 0 &gt; /proc/sys/net/ipv4/conf/all/send_redirects</span><br><span class="line"><span class="built_in">echo</span> 0 &gt; /proc/sys/net/ipv4/conf/default/send_redirects</span><br><span class="line"><span class="built_in">echo</span> 0 &gt; /proc/sys/net/ipv4/conf/eth0/send_redirects</span><br><span class="line"><span class="built_in">echo</span> 0 &gt; /proc/sys/net/ipv4/conf/eth1/send_redirects</span><br><span class="line"></span><br><span class="line"><span class="comment"># director设置 nat 防火墙</span></span><br><span class="line">iptables -t nat -F</span><br><span class="line">iptables -t nat -X</span><br><span class="line">iptables -t nat -A POSTROUTING -s 192.168.0.0/24 -j MASQUERADE</span><br><span class="line"></span><br><span class="line"><span class="comment"># director设置 ipvsadm</span></span><br><span class="line">IPVSADM=<span class="string">'/sbin/ipvsadm'</span></span><br><span class="line"><span class="variable">$IPVSADM</span> -C</span><br><span class="line"><span class="variable">$IPVSADM</span> -A -t 172.16.254.200:80 -s wrr</span><br><span class="line"><span class="variable">$IPVSADM</span> -a -t 172.16.254.200:80 -r 192.168.0.18:80 -m -w 1</span><br><span class="line"><span class="variable">$IPVSADM</span> -a -t 172.16.254.200:80 -r 192.168.0.28:80 -m -w 1</span><br></pre></td></tr></table></figure><p>保存后，在 Director 上直接运行这个脚本就可以完成 lvs/nat 的配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/bin/bash   /usr/<span class="built_in">local</span>/sbin/lvs_nat.sh</span><br></pre></td></tr></table></figure><p>查看ipvsadm设置的规则</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipvsadm -ln</span><br></pre></td></tr></table></figure><p><strong>测试LVS的效果</strong></p><p>通过浏览器测试2台机器上的web内容 <a href="http://172.16.254.200" target="_blank" rel="noopener">http://172.16.254.200</a> 。</p><p>为了区分开，我们可以把 nginx 的默认页修改一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#在 RS1 上执行</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"rs1rs1"</span> &gt;/usr/share/nginx/html/index.html</span><br><span class="line"></span><br><span class="line"><span class="comment">#在 RS2 上执行</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"rs2rs2"</span> &gt;/usr/share/nginx/html/index.html</span><br></pre></td></tr></table></figure><p><em>注意，切记一定要在两台 RS 上设置网关的 IP 为 director 的内网 IP。</em></p><h4 id="DR模式"><a href="#DR模式" class="headerlink" title="DR模式"></a><strong>DR模式</strong></h4><p><strong>实验环境</strong></p><p>三台机器：</p><ul><li>Director节点：  (eth0 192.168.0.8  vip eth0:0 192.168.0.38)</li><li>Real server1： (eth0 192.168.0.18 vip lo:0 192.168.0.38)</li><li>Real server2： (eth0 192.168.0.28 vip lo:0 192.168.0.38)</li></ul><p><strong>安装</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#两个 real server 上都安装 nginx 服务</span></span><br><span class="line">yum install -y nginx</span><br><span class="line"></span><br><span class="line"><span class="comment">#Director 上安装 ipvsadm</span></span><br><span class="line">yum install -y ipvsadm</span><br></pre></td></tr></table></figure><p><strong>Director 上配置脚本</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">vim /usr/<span class="built_in">local</span>/sbin/lvs_dr.sh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">echo</span> 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br><span class="line">ipv=/sbin/ipvsadm</span><br><span class="line">vip=192.168.0.38</span><br><span class="line">rs1=192.168.0.18</span><br><span class="line">rs2=192.168.0.28</span><br><span class="line"></span><br><span class="line">ifconfig eth0:0 down</span><br><span class="line">ifconfig eth0:0 <span class="variable">$vip</span> broadcast <span class="variable">$vip</span> netmask 255.255.255.255 up</span><br><span class="line">route add -host <span class="variable">$vip</span> dev eth0:0</span><br><span class="line"><span class="variable">$ipv</span> -C</span><br><span class="line"><span class="variable">$ipv</span> -A -t <span class="variable">$vip</span>:80 -s wrr</span><br><span class="line"><span class="variable">$ipv</span> -a -t <span class="variable">$vip</span>:80 -r <span class="variable">$rs1</span>:80 -g -w 3</span><br><span class="line"><span class="variable">$ipv</span> -a -t <span class="variable">$vip</span>:80 -r <span class="variable">$rs2</span>:80 -g -w 1</span><br></pre></td></tr></table></figure><p>执行脚本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash /usr/<span class="built_in">local</span>/sbin/lvs_dr.sh</span><br></pre></td></tr></table></figure><p><strong>在2台 rs 上配置脚本：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vim /usr/<span class="built_in">local</span>/sbin/lvs_dr_rs.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">vip=192.168.0.38</span><br><span class="line">ifconfig lo:0 <span class="variable">$vip</span> broadcast <span class="variable">$vip</span> netmask 255.255.255.255 up</span><br><span class="line">route add -host <span class="variable">$vip</span> lo:0</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"1"</span> &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"2"</span> &gt;/proc/sys/net/ipv4/conf/lo/arp_announce</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"1"</span> &gt;/proc/sys/net/ipv4/conf/all/arp_ignore</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"2"</span> &gt;/proc/sys/net/ipv4/conf/all/arp_announce</span><br></pre></td></tr></table></figure><p>rs 上分别执行脚本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash /usr/<span class="built_in">local</span>/sbin/lvs_dr_rs.sh</span><br></pre></td></tr></table></figure><p><strong>实验测试</strong></p><p>测试方式同上，浏览器访问 <a href="http://192.168.0.38" target="_blank" rel="noopener">http://192.168.0.38</a></p><p><em>注意：在 DR 模式下，2台 rs 节点的 gateway 不需要设置成 dir 节点的 IP 。</em></p><h4 id="LVS结合keepalive"><a href="#LVS结合keepalive" class="headerlink" title="LVS结合keepalive"></a><strong>LVS结合keepalive</strong></h4><p>LVS可以实现负载均衡，但是不能够进行健康检查，比如一个rs出现故障，LVS 仍然会把请求转发给故障的rs服务器，这样就会导致请求的无效性。keepalive 软件可以进行健康检查，而且能同时实现 LVS 的高可用性，解决 LVS 单点故障的问题，其实 keepalive 就是为 LVS 而生的。</p><p><strong>实验环境</strong></p><p>4台节点</p><ul><li><p>Keepalived1 + lvs1(Director1)：192.168.0.48</p></li><li><p>Keepalived2 + lvs2(Director2)：192.168.0.58</p></li><li><p>Real server1：192.168.0.18</p></li><li><p>Real server2：192.168.0.28</p></li><li><p>IP: 192.168.0.38</p></li></ul><p><strong>安装系统软件</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Lvs + keepalived的2个节点安装</span></span><br><span class="line">yum install ipvsadm keepalived -y</span><br><span class="line"></span><br><span class="line"><span class="comment">#Real server + nginx服务的2个节点安装</span></span><br><span class="line">yum install epel-release -y</span><br><span class="line">yum install nginx -y</span><br></pre></td></tr></table></figure><p><strong>设置配置脚本</strong></p><p>Real server节点2台配置脚本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vim /usr/<span class="built_in">local</span>/sbin/lvs_dr_rs.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line">vip=192.168.0.38</span><br><span class="line">ifconfig lo:0 <span class="variable">$vip</span> broadcast <span class="variable">$vip</span> netmask 255.255.255.255 up</span><br><span class="line">route add -host <span class="variable">$vip</span> lo:0</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"1"</span> &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"2"</span> &gt;/proc/sys/net/ipv4/conf/lo/arp_announce</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"1"</span> &gt;/proc/sys/net/ipv4/conf/all/arp_ignore</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"2"</span> &gt;/proc/sys/net/ipv4/conf/all/arp_announce</span><br></pre></td></tr></table></figure><p>2个节点rs 上分别执行脚本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash /usr/<span class="built_in">local</span>/sbin/lvs_dr_rs.sh</span><br></pre></td></tr></table></figure><p>keepalived节点配置(2节点)：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#主节点( MASTER )配置文件</span></span><br><span class="line"></span><br><span class="line">vim /etc/keepalived/keepalived.conf</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface eth0</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 100</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        192.168.0.38</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_server 192.168.0.38 80 &#123;</span><br><span class="line">    delay_loop 6</span><br><span class="line">    lb_algo rr</span><br><span class="line">    lb_kind DR</span><br><span class="line">    persistence_timeout 0</span><br><span class="line">    protocol TCP</span><br><span class="line"></span><br><span class="line">    real_server 192.168.0.18 80 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        TCP_CHECK &#123;</span><br><span class="line">            connect_timeout 10</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">            connect_port 80</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    real_server 192.168.0.28 80 &#123;</span><br><span class="line">        weight 1</span><br><span class="line">        TCP_CHECK &#123;</span><br><span class="line">            connect_timeout 10</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">            connect_port 80</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从节点( BACKUP )配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#拷贝主节点的配置文件keepalived.conf，然后修改如下内容：</span><br><span class="line"></span><br><span class="line">state MASTER -&gt; state BACKUP</span><br><span class="line">priority 100 -&gt; priority 90</span><br></pre></td></tr></table></figure><p>keepalived的2个节点执行如下命令，开启转发功能：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure><p><strong>启动keepalive</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;strong&gt;先主后从分别启动keepalive&lt;/strong&gt;</span><br><span class="line"></span><br><span class="line">service keepalived start</span><br></pre></td></tr></table></figure><h2 id="验证结果"><a href="#验证结果" class="headerlink" title="验证结果"></a>验证结果</h2><p>实验1</p><p>手动关闭192.168.0.18节点的nginx，service nginx stop 在客户端上去测试访问 <a href="http://192.168.0.38" target="_blank" rel="noopener">http://192.168.0.38</a> 结果正常，不会出现访问18节点，一直访问的是28节点的内容。</p><p>实验2</p><p>手动重新开启 192.168.0.18 节点的nginx， service nginx start 在客户端上去测试访问 <a href="http://192.168.0.38" target="_blank" rel="noopener">http://192.168.0.38</a> 结果正常，按照 rr 调度算法访问18节点和28节点。</p><p>实验3</p><p>测试 keepalived 的HA特性，首先在master上执行命令 ip addr ，可以看到38的vip在master节点上的；这时如果在master上执行 service keepalived stop 命令，这时vip已经不再master上，在slave节点上执行 ip addr 命令可以看到 vip 已经正确漂到slave节点，这时客户端去访问 <a href="http://192.168.0.38" target="_blank" rel="noopener">http://192.168.0.38</a> 访问依然正常，验证了 keepalived的HA特性。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;本文详细介绍了lvs的三次实践。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Lvs" scheme="https://wandouduoduo.netlify.com/tags/Lvs/"/>
    
  </entry>
  
  <entry>
    <title>详解lvs安装部署</title>
    <link href="https://wandouduoduo.netlify.com/articles/2fd6b41.html"/>
    <id>https://wandouduoduo.netlify.com/articles/2fd6b41.html</id>
    <published>2020-06-11T08:44:46.000Z</published>
    <updated>2020-06-11T12:08:05.915Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>负载均衡器分为硬件和软件。硬件如F5等，但是像F5这些设备费用高昂，不是每个公司都有财力用的。而软件业界用的最多的就是lvs，haproxy和nginx，而负载能力最强的就是lvs。本文详细介绍了lvs的安装部署。</p><p><img src="/articles/2fd6b41/1.jpeg" alt="img"></p><p>在实际应用中，在 Web 服务器集群之前总会有一台负载均衡服务器，负载均衡设备的任务就是作为 Web 服务器流量的入口，挑选最合适的一台 Web 服务器，将客户端的请求转发给它处理，实现客户端到真实服务端的透明转发。</p><p>最近几年很火的「云计算」以及分布式架构，本质上也是将后端服务器作为计算资源、存储资源，由某台管理服务器封装成一个服务对外提供，客户端不需要关心真正提供服务的是哪台机器，在它看来，就好像它面对的是一台拥有近乎无限能力的服务器，而本质上，真正提供服务的，是后端的集群。</p><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>环境如下:centos6.5<br>Lvs主调度器：192.168.65.128 vip:192.168.65.200<br>真实服务器：192.168.65.150 vip:192.168.65.200<br>真实服务器：192.168.65.151 vip:192.168.65.200<br>特别注意的是:虚拟地址由keepalived提供</p><h2 id="优劣势分析"><a href="#优劣势分析" class="headerlink" title="优劣势分析"></a>优劣势分析</h2><p>LVS、Nginx、HAProxy 是目前使用最广泛的三种软件负载均衡软件。</p><p>一般对负载均衡的使用是随着网站规模的提升根据不同的阶段来使用不同的技术。具体的应用需求还得具体分析，如果是中小型的 Web 应用，比如日 PV 小于1000万，用 Nginx 就完全可以了；如果机器不少，可以用 DNS 轮询，LVS 所耗费的机器还是比较多的；大型网站或重要的服务，且服务器比较多时，可以考虑用 LVS。</p><p>目前关于网站架构一般比较合理流行的架构方案：Web 前端采用 Nginx/HAProxy+Keepalived 作负载均衡器；后端采用 MySQ L数据库一主多从和读写分离，采用 LVS+Keepalived 的架构。</p><h4 id="LVS"><a href="#LVS" class="headerlink" title="LVS"></a><strong>LVS</strong></h4><p>LVS 是 Linux Virtual Server 的简称，也就是 Linux 虚拟服务器。现在 LVS 已经是 Linux 标准内核的一部分，从 Linux2.4 内核以后，已经完全内置了 LVS 的各个功能模块，无需给内核打任何补丁，可以直接使用 LVS 提供的各种功能。</p><p>LVS 自从1998年开始，发展到现在已经是一个比较成熟的技术项目了。</p><p><strong>LVS 的体系结构</strong></p><p><img src="/articles/2fd6b41/2.jpeg" alt="img"></p><p>LVS 架设的服务器集群系统有三个部分组成：</p><ol><li>最前端的负载均衡层，用 Load Balancer 表示</li><li>中间的服务器集群层，用 Server Array 表示</li><li>最底端的数据共享存储层，用 Shared Storage 表示</li></ol><p><strong>LVS 负载均衡机制</strong></p><p>LVS 是四层负载均衡，也就是说建立在 OSI 模型的第四层——传输层之上，传输层上有我们熟悉的 TCP/UDP，LVS 支持 TCP/UDP 的负载均衡。因为 LVS 是四层负载均衡，因此它相对于其它高层负载均衡的解决办法，比如 DNS 域名轮流解析、应用层负载的调度、客户端的调度等，它的效率是非常高的。</p><p>所谓四层负载均衡 ，也就是主要通过报文中的目标地址和端口。七层负载均衡 ，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容。</p><p><img src="/articles/2fd6b41/3.jpeg" alt="img"></p><p>LVS 的转发主要通过修改 IP 地址（NAT 模式，分为源地址修改 SNAT 和目标地址修改 DNAT）、修改目标 MAC（DR 模式）来实现。</p><p><strong>NAT 模式：网络地址转换</strong></p><p>NAT（Network Address Translation）是一种外网和内网地址映射的技术。</p><p>NAT 模式下，网络数据报的进出都要经过 LVS 的处理。LVS 需要作为 RS（真实服务器）的网关。</p><p>当包到达 LVS 时，LVS 做目标地址转换（DNAT），将目标 IP 改为 RS 的 IP。RS 接收到包以后，仿佛是客户端直接发给它的一样。RS 处理完，返回响应时，源 IP 是 RS IP，目标 IP 是客户端的 IP。这时 RS 的包通过网关（LVS）中转，LVS 会做源地址转换（SNAT），将包的源地址改为 VIP，这样，这个包对客户端看起来就仿佛是 LVS 直接返回给它的。</p><p><img src="/articles/2fd6b41/4.jpeg" alt="img"></p><p><strong>DR 模式：直接路由</strong></p><p>DR 模式下需要 LVS 和 RS 集群绑定同一个 VIP（RS 通过将 VIP 绑定在 loopback 实现），但与 NAT 的不同点在于：请求由 LVS 接受，由真实提供服务的服务器（RealServer，RS）直接返回给用户，返回的时候不经过 LVS。</p><p>详细来看，一个请求过来时，LVS 只需要将网络帧的 MAC 地址修改为某一台 RS 的 MAC，该包就会被转发到相应的 RS 处理，注意此时的源 IP 和目标 IP 都没变，LVS 只是做了一下移花接木。RS 收到 LVS 转发来的包时，链路层发现 MAC 是自己的，到上面的网络层，发现 IP 也是自己的，于是这个包被合法地接受，RS 感知不到前面有 LVS 的存在。而当 RS 返回响应时，只要直接向源 IP（即用户的 IP）返回即可，不再经过 LVS。</p><p><img src="/articles/2fd6b41/5.jpeg" alt="img"></p><p>DR 负载均衡模式数据分发过程中不修改 IP 地址，只修改 mac 地址，由于实际处理请求的真实物理 IP 地址和数据请求目的 IP 地址一致，所以不需要通过负载均衡服务器进行地址转换，可将响应数据包直接返回给用户浏览器，避免负载均衡服务器网卡带宽成为瓶颈。因此，DR 模式具有较好的性能，也是目前大型网站使用最广泛的一种负载均衡手段。</p><p><strong>LVS 的优点</strong></p><ul><li>抗负载能力强、是工作在传输层上仅作分发之用，没有流量的产生，这个特点也决定了它在负载均衡软件里的性能最强的，对内存和 cpu 资源消耗比较低。</li><li>配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率。</li><li>工作稳定，因为其本身抗负载能力很强，自身有完整的双机热备方案，如 LVS+Keepalived。</li><li>无流量，LVS 只分发请求，而流量并不从它本身出去，这点保证了均衡器 IO 的性能不会受到大流量的影响。</li><li>应用范围比较广，因为 LVS 工作在传输层，所以它几乎可以对所有应用做负载均衡，包括 http、数据库、在线聊天室等等。</li></ul><p><strong>LVS 的缺点</strong></p><ul><li>软件本身不支持正则表达式处理，不能做动静分离；而现在许多网站在这方面都有较强的需求，这个是 Nginx、HAProxy+Keepalived 的优势所在。</li><li>如果是网站应用比较庞大的话，LVS/DR+Keepalived 实施起来就比较复杂了，相对而言，Nginx/HAProxy+Keepalived就简单多了。</li></ul><h4 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a><strong>Nginx</strong></h4><p>Nginx 是一个强大的 Web 服务器软件，用于处理高并发的 HTTP 请求和作为反向代理服务器做负载均衡。具有高性能、轻量级、内存消耗少，强大的负载均衡能力等优势。</p><p><img src="/articles/2fd6b41/6.jpeg" alt="img"></p><p><strong>Nignx 的架构设计</strong></p><p>相对于传统基于进程或线程的模型（Apache就采用这种模型）在处理并发连接时会为每一个连接建立一个单独的进程或线程，且在网络或者输入/输出操作时阻塞。这将导致内存和 CPU 的大量消耗，因为新起一个单独的进程或线程需要准备新的运行时环境，包括堆和栈内存的分配，以及新的执行上下文，当然，这些也会导致多余的 CPU 开销。最终，会由于过多的上下文切换而导致服务器性能变差。</p><p>反过来，Nginx 的架构设计是采用模块化的、基于事件驱动、异步、单线程且非阻塞。</p><p>Nginx 大量使用多路复用和事件通知，Nginx 启动以后，会在系统中以 daemon 的方式在后台运行，其中包括一个 master 进程，n(n&gt;=1) 个 worker 进程。所有的进程都是单线程（即只有一个主线程）的，且进程间通信主要使用共享内存的方式。</p><p>其中，master 进程用于接收来自外界的信号，并给 worker 进程发送信号，同时监控 worker 进程的工作状态。worker 进程则是外部请求真正的处理者，每个 worker 请求相互独立且平等的竞争来自客户端的请求。请求只能在一个 worker 进程中被处理，且一个 worker 进程只有一个主线程，所以同时只能处理一个请求。（原理同 Netty 很像）</p><p><img src="/articles/2fd6b41/7.jpeg" alt="img"></p><p><strong>Nginx 负载均衡</strong></p><p>Nginx 负载均衡主要是对七层网络通信模型中的第七层应用层上的 http、https 进行支持。</p><p>Nginx 是以反向代理的方式进行负载均衡的。反向代理（Reverse Proxy）方式是指以代理服务器来接受 Internet 上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 Internet 上请求连接的客户端，此时代理服务器对外就表现为一个服务器。</p><p>Nginx 实现负载均衡的分配策略有很多，Nginx 的 upstream 目前支持以下几种方式：</p><ul><li>轮询（默认）：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器 down 掉，能自动剔除。</li><li>weight：指定轮询几率，weight 和访问比率成正比，用于后端服务器性能不均的情况。</li><li>ip_hash：每个请求按访问 ip 的 hash 结果分配，这样每个访客固定访问一个后端服务器，可以解决 session 的问题。</li><li>fair（第三方）：按后端服务器的响应时间来分配请求，响应时间短的优先分配。</li><li>url_hash（第三方）：按访问 url 的 hash 结果来分配请求，使每个 url 定向到同一个后端服务器，后端服务器为缓存时比较有效。</li></ul><p><strong>Nginx 的优点</strong></p><ul><li>跨平台：Nginx 可以在大多数 Unix like OS编译运行，而且也有 Windows 的移植版本</li><li>配置异常简单：非常容易上手。配置风格跟程序开发一样，神一般的配置</li><li>非阻塞、高并发连接：官方测试能够支撑5万并发连接，在实际生产环境中跑到2～3万并发连接数</li><li>事件驱动：通信机制采用 epoll 模型，支持更大的并发连接</li><li>Master/Worker 结构：一个 master 进程，生成一个或多个 worker 进程</li><li>内存消耗小：处理大并发的请求内存消耗非常小。在3万并发连接下，开启的10个 Nginx 进程才消耗150M 内存（15M*10=150M）</li><li>内置的健康检查功能：如果 Nginx 代理的后端的某台 Web 服务器宕机了，不会影响前端访问</li><li>节省带宽：支持 GZIP 压缩，可以添加浏览器本地缓存的 Header 头</li><li>稳定性高：用于反向代理，宕机的概率微乎其微</li></ul><p><strong>Nginx 的缺点</strong></p><ul><li>Nginx 仅能支 持http、https 和 Email 协议，这样就在适用范围上面小些，这个是它的缺点</li><li>对后端服务器的健康检查，只支持通过端口来检测，不支持通过 ur l来检测。不支持 Session 的直接保持，但能通过 ip_hash 来解决</li></ul><h4 id="HAProxy"><a href="#HAProxy" class="headerlink" title="HAProxy"></a><strong>HAProxy</strong></h4><p>HAProxy 的优点能够补充 Nginx 的一些缺点，比如支持 Session 的保持，Cookie 的引导；同时支持通过获取指定的 url 来检测后端服务器的状态。</p><p>HAProxy 跟 LVS 类似，本身就只是一款负载均衡软件；单纯从效率上来讲 HAProxy 会比 Nginx 有更出色的负载均衡速度，在并发处理上也是优于 Nginx 的。</p><p>HAProxy 支持 TCP 协议的负载均衡转发，可以对 MySQL 读进行负载均衡，对后端的 MySQL 节点进行检测和负载均衡，大家可以用 LVS+Keepalived 对 MySQL 主从做负载均衡。</p><p>HAProxy 负载均衡策略非常多：Round-robin（轮循）、Weight-round-robin（带权轮循）、source（原地址保持）、RI（请求URL）、rdp-cookie（根据cookie）。</p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><h4 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h4><p>修改系统内核文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sysctl.conf 修改默认值0为1，开启内核路由转发模式</span><br><span class="line"></span><br><span class="line">net.ipv4.ip_forward = 1</span><br></pre></td></tr></table></figure><h4 id="源码安装"><a href="#源码安装" class="headerlink" title="源码安装"></a><strong>源码安装</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum install ipvsadm*</span><br><span class="line">wget http://www.linuxvirtualserver.org/software/kernel-2.6/ipvsadm-1.26.tar.gz</span><br><span class="line">tar -zxvf ipvsadm-1.26.tar.gz</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#添加虚拟IP地址，wrr表示给予权重的轮询。rr表示轮询</span></span><br><span class="line">ipvsadm -A -t 192.168.65.200:80 -s wrr</span><br><span class="line"><span class="comment">#制定后台和轮询的IP地址分别是150和151这两台机器 -g表示路由模式，-w表示权重</span></span><br><span class="line">ipvsadm -a -t 192.168.65.200:80 -r 192.168.65.150:80 -g -w 5</span><br><span class="line">ipvsadm -a -t 192.168.65.200:80 -r 192.168.65.151:80 -g -w 5</span><br><span class="line">service ipvsadm save</span><br><span class="line"></span><br><span class="line"><span class="comment">#编辑lvs的配置文件</span></span><br><span class="line">vim /etc/sysconfig/ipvsadm</span><br><span class="line">-A -t 192.168.65.200:80 -s wrr</span><br><span class="line">-a -t 192.168.65.200:80 -r 192.168.65.150:80 -g -w 5</span><br><span class="line">-a -t 192.168.65.200:80 -r 192.168.65.151:80 -g -w 5</span><br><span class="line"></span><br><span class="line"><span class="comment">#开机启动脚本 </span></span><br><span class="line">vim/etc/init.d/ipvsadm</span><br><span class="line"></span><br><span class="line"> <span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Startup script handle the initialisation of LVS</span></span><br><span class="line"><span class="comment"># chkconfig: - 28 72</span></span><br><span class="line"><span class="comment"># description: Initialise the Linux Virtual Server</span></span><br><span class="line"><span class="comment"># config: /etc/sysconfig/ipvsadm</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">### BEGIN INIT INFO</span></span><br><span class="line"><span class="comment"># Provides: ipvsadm</span></span><br><span class="line"><span class="comment"># Required-Start: $local_fs $network $named</span></span><br><span class="line"><span class="comment"># Required-Stop: $local_fs $remote_fs $network</span></span><br><span class="line"><span class="comment"># Short-Description: Initialise the Linux Virtual Server</span></span><br><span class="line"><span class="comment"># Description: The Linux Virtual Server is a highly scalable and highly</span></span><br><span class="line"><span class="comment">#   available server built on a cluster of real servers, with the load</span></span><br><span class="line"><span class="comment">#   balancer running on Linux.</span></span><br><span class="line"><span class="comment">### END INIT INFO</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Source function library</span></span><br><span class="line">. /etc/rc.d/init.d/<span class="built_in">functions</span></span><br><span class="line"></span><br><span class="line">IPVSADM=ipvsadm</span><br><span class="line">IPVSADMRESTORE=<span class="variable">$&#123;IPVSADM&#125;</span>-restore</span><br><span class="line">IPVSADMSAVE=<span class="variable">$&#123;IPVSADM&#125;</span>-save</span><br><span class="line"><span class="comment"># Saved IPVS data</span></span><br><span class="line">IPVSADM_DATA=/etc/sysconfig/<span class="variable">$IPVSADM</span></span><br><span class="line"><span class="comment"># Configuration</span></span><br><span class="line">IPVSADM_CONFIG=/etc/sysconfig/<span class="variable">$&#123;IPVSADM&#125;</span>-config</span><br><span class="line">IPVS=ip_vs</span><br><span class="line">PROC_IPVS=/proc/net/<span class="variable">$IPVS</span></span><br><span class="line">VAR_SUBSYS_IPVSADM=/var/lock/subsys/<span class="variable">$IPVSADM</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -x /sbin/<span class="variable">$IPVSADM</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> -n $<span class="string">"<span class="variable">$&#123;IPVSADM&#125;</span>: /sbin/<span class="variable">$IPVSADM</span> does not exist."</span>; warning; <span class="built_in">echo</span></span><br><span class="line">    <span class="built_in">exit</span> 5</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Old or new modutils</span></span><br><span class="line">/sbin/modprobe --version 2&gt;&amp;1 | grep -q module-init-tools \</span><br><span class="line">    &amp;&amp; NEW_MODUTILS=1 \</span><br><span class="line">    || NEW_MODUTILS=0</span><br><span class="line"></span><br><span class="line"><span class="comment"># Default IPVSADM configuration:</span></span><br><span class="line">IPVS_MODULES_UNLOAD=<span class="string">"yes"</span></span><br><span class="line">IPVS_SAVE_ON_STOP=<span class="string">"no"</span></span><br><span class="line">IPVS_SAVE_ON_RESTART=<span class="string">"no"</span></span><br><span class="line">IPVS_STATUS_NUMERIC=<span class="string">"yes"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Load IPVSADM configuration.</span></span><br><span class="line">[ -f <span class="string">"<span class="variable">$IPVSADM_CONFIG</span>"</span> ] &amp;&amp; . <span class="string">"<span class="variable">$IPVSADM_CONFIG</span>"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">rmmod_r</span></span>() &#123;</span><br><span class="line">    <span class="comment"># Unload module with all referring modules.</span></span><br><span class="line">    <span class="comment"># At first all referring modules will be unloaded, then the module itself.</span></span><br><span class="line">    <span class="built_in">local</span> mod=<span class="variable">$1</span></span><br><span class="line">    <span class="built_in">local</span> ret=0</span><br><span class="line">    <span class="built_in">local</span> ref=</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Get referring modules.</span></span><br><span class="line">    <span class="comment"># New modutils have another output format.</span></span><br><span class="line">    [ <span class="variable">$NEW_MODUTILS</span> = 1 ] \</span><br><span class="line">        &amp;&amp; ref=$(lsmod | awk <span class="string">"/^<span class="variable">$&#123;mod&#125;</span>[[:space:]]/ &#123; print \$4; &#125;"</span> | tr <span class="string">','</span> <span class="string">' '</span>) \</span><br><span class="line">        || ref=$(lsmod | grep ^<span class="variable">$&#123;mod&#125;</span> | cut -d <span class="string">"["</span> -s -f 2 | cut -d <span class="string">"]"</span> -s -f 1)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># recursive call for all referring modules</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="variable">$ref</span>; <span class="keyword">do</span></span><br><span class="line">        rmmod_r <span class="variable">$i</span></span><br><span class="line">        <span class="built_in">let</span> ret+=$?;</span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Unload module.</span></span><br><span class="line">    <span class="comment"># The extra test is for 2.6: The module might have autocleaned,</span></span><br><span class="line">    <span class="comment"># after all referring modules are unloaded.</span></span><br><span class="line">    <span class="keyword">if</span> grep -q <span class="string">"^<span class="variable">$&#123;mod&#125;</span>"</span> /proc/modules ; <span class="keyword">then</span></span><br><span class="line">        modprobe -r <span class="variable">$mod</span> &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">        res=$?</span><br><span class="line">        [ <span class="variable">$res</span> -eq 0 ] || <span class="built_in">echo</span> -n <span class="string">" <span class="variable">$mod</span>"</span></span><br><span class="line">        <span class="built_in">let</span> ret+=<span class="variable">$res</span>;</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> <span class="variable">$ret</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">start</span></span>() &#123;</span><br><span class="line">    <span class="comment"># Do not start if there is no config file.</span></span><br><span class="line">    [ ! -f <span class="string">"<span class="variable">$IPVSADM_DATA</span>"</span> ] &amp;&amp; <span class="built_in">return</span> 6</span><br><span class="line"></span><br><span class="line">    <span class="comment"># check if ipvs module load is deactivated</span></span><br><span class="line">    <span class="keyword">if</span> grep -qIsE <span class="string">"^install[[:space:]]+<span class="variable">$&#123;IPVS&#125;</span>[[:space:]]+/bin/(true|false)"</span> /etc/modprobe.conf /etc/modprobe.d/* ; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> $<span class="string">"<span class="variable">$&#123;IPVSADM&#125;</span>: <span class="variable">$&#123;IPVS&#125;</span> is disabled."</span></span><br><span class="line">        <span class="built_in">return</span> 150</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># If we don't clear these first, we might be adding to pre-existing rules.</span></span><br><span class="line">    action $<span class="string">"<span class="variable">$&#123;IPVSADM&#125;</span>: Clearing the current IPVS table:"</span> <span class="variable">$IPVSADM</span> -C</span><br><span class="line"></span><br><span class="line">    <span class="built_in">echo</span> -n $<span class="string">"<span class="variable">$&#123;IPVSADM&#125;</span>: Applying IPVS configuration: "</span></span><br><span class="line">    <span class="variable">$IPVSADMRESTORE</span> &lt; <span class="variable">$&#123;IPVSADM_DATA&#125;</span></span><br><span class="line">    <span class="keyword">if</span> [ $? -eq 0 ];<span class="keyword">then</span> success; <span class="built_in">echo</span>; <span class="keyword">else</span> failure; <span class="built_in">echo</span>; <span class="built_in">return</span> 1;<span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    touch <span class="variable">$VAR_SUBSYS_IPVSADM</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">stop</span></span>() &#123;</span><br><span class="line">    <span class="comment"># Do not stop if ipvs module is not loaded.</span></span><br><span class="line">    [ ! -e <span class="string">"<span class="variable">$PROC_IPVS</span>"</span> ] &amp;&amp; <span class="built_in">return</span> 0</span><br><span class="line"></span><br><span class="line">    action $<span class="string">"<span class="variable">$&#123;IPVSADM&#125;</span>: Clearing the current IPVS table:"</span> <span class="variable">$IPVSADM</span> -C</span><br><span class="line"></span><br><span class="line">    ret=0</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> [ <span class="string">"x<span class="variable">$IPVS_MODULES_UNLOAD</span>"</span> = <span class="string">"xyes"</span> ]; <span class="keyword">then</span></span><br><span class="line">        action $<span class="string">"<span class="variable">$&#123;IPVSADM&#125;</span>: Unloading modules:"</span> rmmod_r <span class="variable">$IPVS</span></span><br><span class="line">        [ $? -ne 0 ] &amp;&amp; ret=1</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    rm -f <span class="variable">$VAR_SUBSYS_IPVSADM</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> <span class="variable">$ret</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">status</span></span>() &#123;</span><br><span class="line">    <span class="comment"># Do not print status if lockfile is missing and ipvs modules are not</span></span><br><span class="line">    <span class="comment"># loaded.</span></span><br><span class="line">    <span class="keyword">if</span> [ ! -f <span class="string">"<span class="variable">$VAR_SUBSYS_IPVSADM</span>"</span> -a ! -e <span class="string">"<span class="variable">$PROC_IPVS</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> $<span class="string">"<span class="variable">$&#123;IPVSADM&#125;</span>: IPVS is not running."</span></span><br><span class="line">        <span class="built_in">return</span> 3</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Do show status if ipvs module is not loaded.</span></span><br><span class="line">    <span class="keyword">if</span> [ ! -e <span class="string">"<span class="variable">$PROC_IPVS</span>"</span> ];<span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> $<span class="string">"<span class="variable">$&#123;IPVSADM&#125;</span>: IPVS module is not loaded."</span></span><br><span class="line">        <span class="built_in">return</span> 3</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    NUM=<span class="string">""</span></span><br><span class="line">    [ <span class="string">"x<span class="variable">$IPVS_STATUS_NUMERIC</span>"</span> = <span class="string">"xyes"</span> ] &amp;&amp; NUM=<span class="string">"-n"</span></span><br><span class="line"></span><br><span class="line">    <span class="variable">$IPVSADM</span> -L <span class="variable">$NUM</span> &amp;&amp; <span class="built_in">echo</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">save</span></span>() &#123;</span><br><span class="line">    <span class="comment"># Check if module is loaded</span></span><br><span class="line">    [ ! -e <span class="string">"<span class="variable">$PROC_IPVS</span>"</span> ] &amp;&amp; <span class="built_in">return</span> 0</span><br><span class="line"></span><br><span class="line">    <span class="built_in">echo</span> -n $<span class="string">"<span class="variable">$&#123;IPVSADM&#125;</span>: Saving IPVS table to <span class="variable">$&#123;IPVSADM_DATA&#125;</span>: "</span></span><br><span class="line">    <span class="variable">$IPVSADMSAVE</span> -n &gt; <span class="variable">$&#123;IPVSADM_DATA&#125;</span> 2&gt;/dev/null</span><br><span class="line">    <span class="keyword">if</span> [ $? -eq 0 ];<span class="keyword">then</span> success; <span class="built_in">echo</span>; <span class="keyword">else</span> failure; <span class="built_in">echo</span>; <span class="built_in">return</span> 1;<span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">return</span> 0</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">restart</span></span>() &#123;</span><br><span class="line">    [ <span class="string">"x<span class="variable">$IPVS_SAVE_ON_RESTART</span>"</span> = <span class="string">"xyes"</span> ] &amp;&amp; save</span><br><span class="line">    stop</span><br><span class="line">    start</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># See how we were called.</span></span><br><span class="line"><span class="keyword">case</span> <span class="string">"<span class="variable">$1</span>"</span> <span class="keyword">in</span></span><br><span class="line">    start)</span><br><span class="line">        [ -f <span class="string">"<span class="variable">$VAR_SUBSYS_IPVSADM</span>"</span> ] &amp;&amp; <span class="built_in">exit</span> 0</span><br><span class="line"></span><br><span class="line">        <span class="comment"># If we have no configuration, save the current one</span></span><br><span class="line">        [ -f <span class="variable">$&#123;IPVSADM_DATA&#125;</span> ] || save</span><br><span class="line">        start</span><br><span class="line">        RETVAL=$?</span><br><span class="line">        ;;</span><br><span class="line">    stop)</span><br><span class="line">        [ <span class="string">"x<span class="variable">$IPVS_SAVE_ON_STOP</span>"</span> = <span class="string">"xyes"</span> ] &amp;&amp; save</span><br><span class="line">        stop</span><br><span class="line">        RETVAL=$?</span><br><span class="line">        ;;</span><br><span class="line">    restart|force-reload)</span><br><span class="line">        restart</span><br><span class="line">        RETVAL=$?</span><br><span class="line">        ;;</span><br><span class="line">    reload)</span><br><span class="line">        <span class="comment"># Start will flush everything, so it counts as a reload</span></span><br><span class="line">        start</span><br><span class="line">        RETVAL=$?</span><br><span class="line">        ;;</span><br><span class="line">    status)</span><br><span class="line">        status</span><br><span class="line">        RETVAL=$?</span><br><span class="line">        ;;</span><br><span class="line">    save)</span><br><span class="line">        save</span><br><span class="line">        RETVAL=$?</span><br><span class="line">        ;;</span><br><span class="line">    *)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Usage: <span class="variable">$0</span> &#123;start|stop|restart|force-reload|reload|status|save&#125;"</span></span><br><span class="line">        RETVAL=2</span><br><span class="line"><span class="keyword">esac</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">exit</span> <span class="variable">$RETVA</span></span><br></pre></td></tr></table></figure><p><strong>配置real server服务器</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">service iptables stop</span><br><span class="line">iptables -F</span><br><span class="line">vim /etc/sysctl.conf 在文件的末尾添加如下内容</span><br><span class="line">net.ipv4.conf.lo.arp_ignore = 1</span><br><span class="line">net.ipv4.conf.all.arp_ignore = 1</span><br><span class="line">net.ipv4.conf.lo.arp_announce = 2</span><br><span class="line">net.ipv4.conf.all.arp_announce = 2</span><br><span class="line">立即生效配置，禁止arp相应的请求</span><br><span class="line">sysctl -p</span><br><span class="line"></span><br><span class="line">设置虚拟网卡，添加如下内容</span><br><span class="line">vim /etc/sysconfig/network-scripts/ifcfg-lo:0</span><br><span class="line">DEVICE=lo:0</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">IPADDR=192.168.65.200</span><br><span class="line">NETMASK=255.255.255.255</span><br><span class="line">ONBOOT=yes</span><br><span class="line"></span><br><span class="line">添加路由: route add -host 192.168.65.200 dev lo:0</span><br><span class="line"></span><br><span class="line">在lvs调度器查看</span><br><span class="line">ipvsadm -Ln</span><br></pre></td></tr></table></figure><p><img src="/articles/2fd6b41/1.png" alt></p><p>查看你当前ipvsadm的轮询时间，为了使实验有比较好的效果，设置时间为1秒，可以查看转换效果<br>查看当前的的轮询时间<br>ipvsadm -L –timeout<br>设置时间为1秒<br>ipvsadm –set 1 1 1</p><p>在浏览器查看并且过一秒刷新页面地址变化则说明lvs轮询成功<br><img src="/articles/2fd6b41/2.png" alt></p><p>刷新页面之后。可以目前的当前链接的后端服务器轮询</p><p>ipvsadm -Lcn</p><p><img src="/articles/2fd6b41/3.png" alt></p><h2 id="ipvsadm命令"><a href="#ipvsadm命令" class="headerlink" title="ipvsadm命令"></a>ipvsadm命令</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">ipvsadm是LVS在应用层的管理命令，我们可以通过这个命令去管理LVS的配置。在笔者使用的fedora14系统中，已经集成了LVS相关模块，但是ipvsadm命令仍然需要使用yum单独安装。</span><br><span class="line"> </span><br><span class="line">参数：</span><br><span class="line"></span><br><span class="line">-A --add-service      在内核的虚拟服务器表中添加一条新的虚拟服务器记录。也就是增加一台新的虚拟服务器。 </span><br><span class="line">-E --edit-service     编辑内核虚拟服务器表中的一条虚拟服务器记录。 </span><br><span class="line">-D --delete-service   删除内核虚拟服务器表中的一条虚拟服务器记录。 </span><br><span class="line">-C --clear           清除内核虚拟服务器表中的所有记录。 </span><br><span class="line">-R --restore         恢复虚拟服务器规则 </span><br><span class="line">-S --save            保存虚拟服务器规则，输出为-R 选项可读的格式 </span><br><span class="line">-a --add-server      在内核虚拟服务器表的一条记录里添加一条新的真实服务器记录。也就是在一个虚拟服务器中增加一台新的真实服务器 </span><br><span class="line">-e --edit-server     编辑一条虚拟服务器记录中的某条真实服务器记录 </span><br><span class="line">-d --delete-server   删除一条虚拟服务器记录中的某条真实服务器记录 </span><br><span class="line">-L|-l --list         显示内核虚拟服务器表 </span><br><span class="line">-Z --zero            虚拟服务表计数器清零（清空当前的连接数量等） </span><br><span class="line">--<span class="built_in">set</span> tcp tcpfin udp 设置连接超时值 </span><br><span class="line">--start-daemon       启动同步守护进程。他后面可以是master 或backup，用来说明LVS Router 是aster 或是backup。在这个功能上也可以采用keepalived 的VRRP 功能。 </span><br><span class="line">--stop-daemon        停止同步守护进程 </span><br><span class="line">-h --<span class="built_in">help</span>            显示帮助信息 </span><br><span class="line"></span><br><span class="line">其他的选项: </span><br><span class="line"></span><br><span class="line">-t --tcp-service service-address     说明虚拟服务器提供的是tcp 的服务[vip:port] or [real-server-ip:port] </span><br><span class="line">-u --udp-service service-address     说明虚拟服务器提供的是udp 的服务[vip:port] or [real-server-ip:port] </span><br><span class="line">-f --fwmark-service fwmark           说明是经过iptables 标记过的服务类型。 </span><br><span class="line">-s --scheduler scheduler             使用的调度算法，有这样几个选项rr|wrr|lc|wlc|lblc|lblcr|dh|sh|sed|nq,默认的调度算法是： wlc. </span><br><span class="line">-p --persistent [timeout]            持久稳固的服务。这个选项的意思是来自同一个客户的多次请求，将被同一台真实的服务器处理。timeout 的默认值为300 秒。 </span><br><span class="line">-M --netmask                         指定客户地址的子网掩码</span><br><span class="line">-r --real-server server-address      真实的服务器[Real-Server:port] </span><br><span class="line">-g --gatewaying                      指定LVS 的工作模式为直接路由模式（也是LVS 默认的模式） </span><br><span class="line">-i --ipip                            指定LVS 的工作模式为隧道模式 </span><br><span class="line">-m --masquerading                    指定LVS 的工作模式为NAT 模式 </span><br><span class="line">-w --weight weight                   真实服务器的权值 </span><br><span class="line">--mcast-interface interface          指定组播的同步接口 </span><br><span class="line">-c --connection                      显示LVS目前的连接 如：ipvsadm -L -c </span><br><span class="line">   --timeout                         显示tcp tcpfin udp 的timeout 值 如：ipvsadm -L --timeout </span><br><span class="line">   --daemon                          显示同步守护进程状态 </span><br><span class="line">   --stats                           显示统计信息 </span><br><span class="line">   --rate                            显示速率信息 </span><br><span class="line">   --sort                            对虚拟服务器和真实服务器排序输出 </span><br><span class="line">   --numeric -n                      输出IP 地址和端口的数字形式 </span><br><span class="line">-6：                                 如果fwmark用的是ipv6地址需要指定此选项。  </span><br><span class="line"></span><br><span class="line">例1：</span><br><span class="line">ipvsadm -A -t 192.168.10.10:80 -s rr -p 600 <span class="comment">#添加地址为192.168.10.10:80的虚拟服务，指定调度算法为轮转</span></span><br><span class="line">ipvsadm -a -t 192.168.10.10:80 -r 192.168.10.1:80 -g <span class="comment">#添加真实服务器，指定传输模式为DR</span></span><br><span class="line">ipvsadm -a -t 192.168.10.10:80 -r 192.168.10.2:80 -m <span class="comment">#添加真实服务器，指定传输模式为NAT</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#以下表示在内核的虚拟服务器列表中又添加了一条192.168.60.188的虚拟服务器，此虚拟服务器的服务端口为21，即FTP服务。使用的调度策略为wlc，即加权最少链接算法。</span></span><br><span class="line">ipvsadm -A -t 192.168.10.188:21 -s wlc </span><br><span class="line"></span><br><span class="line"><span class="comment">#规则导出导入</span></span><br><span class="line">ipvsadm-save &gt; ipvs.txt  (其中ipvs.txt保存的是你的配置) </span><br><span class="line">ipvsadm-restore &lt; ipvs.txt  (将配置导入)</span><br><span class="line"></span><br><span class="line"><span class="comment">#规则恢复</span></span><br><span class="line">ipvsadm -R &lt; /root/xxx.rule</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看规则</span></span><br><span class="line">ipvsadm -Ln </span><br><span class="line">TCP  192.168.11.100:80 wrr</span><br><span class="line">  -&gt; 192.168.11.12:80             Route   3      0          0</span><br><span class="line">  -&gt; 192.168.11.13:80             Route   3      0          0</span><br><span class="line"></span><br><span class="line">ipvsadm -d -t 192.168.11.100:80 -r 192.168.11.12:80   <span class="comment">#删除一条真实服务器记录</span></span><br></pre></td></tr></table></figure><h2 id="排错"><a href="#排错" class="headerlink" title="排错"></a>排错</h2><p>报错：collect2: ld returned 1 exit status<br>make: * [ipvsadm] Error 1<br>yum install install kernel-headers popt-static</p><p>报错：unexpected argument 192.168.65.130:80<br>使用上面ipvsad的脚本，添加/etc/sysconfig/ipvsadm<br>里面的规则，重启ipvsadm服务</p><p>报错：<br>eloading ipvsadm configuration (via systemctl): Failed to issue method call: Job type reload is not applicable for unit ipvsadm.service.<br>解决办法<br>添加：/sys/fs/cgroup/systemd/system.slice/ipvsadm.service</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;负载均衡器分为硬件和软件。硬件如F5等，但是像F5这些设备费用高昂，不是每个公司都有财力用的。而软件业界用的最多的就是lvs，haproxy和nginx，而负载能力最强的就是lvs。本文详细介绍了lvs的安装部署。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/2fd6b41/1.jpeg&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;p&gt;在实际应用中，在 Web 服务器集群之前总会有一台负载均衡服务器，负载均衡设备的任务就是作为 Web 服务器流量的入口，挑选最合适的一台 Web 服务器，将客户端的请求转发给它处理，实现客户端到真实服务端的透明转发。&lt;/p&gt;
&lt;p&gt;最近几年很火的「云计算」以及分布式架构，本质上也是将后端服务器作为计算资源、存储资源，由某台管理服务器封装成一个服务对外提供，客户端不需要关心真正提供服务的是哪台机器，在它看来，就好像它面对的是一台拥有近乎无限能力的服务器，而本质上，真正提供服务的，是后端的集群。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Lvs" scheme="https://wandouduoduo.netlify.com/tags/Lvs/"/>
    
  </entry>
  
  <entry>
    <title>详解负载均衡器lvs</title>
    <link href="https://wandouduoduo.netlify.com/articles/d0d5843b.html"/>
    <id>https://wandouduoduo.netlify.com/articles/d0d5843b.html</id>
    <published>2020-06-11T03:59:11.000Z</published>
    <updated>2020-06-11T12:08:05.917Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><pre><code>LVS（Linux Virtual Server）即Linux虚拟服务器，是由章文嵩博士主导的开源负载均衡项目，目前LVS已经被集成到Linux内核模块中。该项目在Linux内核中实现了基于IP的数据请求负载均衡调度方案，其体系结构如图1所示，终端互联网用户从外部访问公司的外部负载均衡服务器，终端用户的Web请求会发送给LVS调度器，调度器根据自己预设的算法决定将该请求发送给后端的某台Web服务器，比如，轮询算法可以将外部的请求平均分发给后端的所有服务器，终端用户访问LVS调度器虽然会被转发到后端真实的服务器，但如果真实服务器连接的是相同的存储，提供的服务也是相同的服务，最终用户不管是访问哪台真实服务器，得到的服务内容都是一样的，整个集群对用户而言都是透明的。最后根据LVS工作模式的不同，真实服务器会选择不同的方式将用户需要的数据发送到终端用户，LVS工作模式分为NAT模式、TUN模式、以及DR模式。</code></pre><p><img src="/articles/d0d5843b/1.png" alt></p><p>本文详细讲解了lvs的三种模式和十种算法。让你有个清晰的认识。</p><a id="more"></a><h2 id="三种模式"><a href="#三种模式" class="headerlink" title="三种模式"></a>三种模式</h2><h4 id="基于NAT"><a href="#基于NAT" class="headerlink" title="基于NAT"></a>基于NAT</h4><pre><code>NAT（Network Address Translation）即网络地址转换，其作用是通过数据报头的修改，使得位于企业内部的私有IP地址可以访问外网，以及外部用用户可以访问位于公司内部的私有IP主机。VS/NAT工作模式拓扑结构如图2所示，LVS负载调度器可以使用两块网卡配置不同的IP地址，eth0设置为私钥IP与内部网络通过交换设备相互连接，eth1设备为外网IP与外部网络联通。</code></pre><p> 第一步，用户通过互联网DNS服务器解析到公司负载均衡设备上面的外网地址，相对于真实服务器而言，LVS外网IP又称VIP（Virtual IP Address），用户通过访问VIP，即可连接后端的真实服务器（Real Server），而这一切对用户而言都是透明的，用户以为自己访问的就是真实服务器，但他并不知道自己访问的VIP仅仅是一个调度器，也不清楚后端的真实服务器到底在哪里、有多少真实服务器。</p><p>第二步，用户将请求发送至124.126.147.168，此时LVS将根据预设的算法选择后端的一台真实服务器（192.168.0.1~192.168.0.3），将数据请求包转发给真实服务器，并且在转发之前LVS会修改数据包中的目标地址以及目标端口，目标地址与目标端口将被修改为选出的真实服务器IP地址以及相应的端口。</p><p>第三步，真实的服务器将响应数据包返回给LVS调度器，调度器在得到响应的数据包后会将源地址和源端口修改为VIP及调度器相应的端口，修改完成后，由调度器将响应数据包发送回终端用户，另外，由于LVS调度器有一个连接Hash表，该表中会记录连接请求及转发信息，当同一个连接的下一个数据包发送给调度器时，从该Hash表中可以直接找到之前的连接记录，并根据记录信息选出相同的真实服务器及端口信息。</p><p><img src="/articles/d0d5843b/2.png" alt></p><p>NAT（Network Address Translation）是一种外网和内网地址映射的技术。</p><p>NAT 模式下，网络数据报的进出都要经过 LVS 的处理。LVS 需要作为 RS（真实服务器）的网关。</p><p>当包到达 LVS 时，LVS 做目标地址转换（DNAT），将目标 IP 改为 RS 的 IP。RS 接收到包以后，仿佛是客户端直接发给它的一样。RS 处理完，返回响应时，源 IP 是 RS IP，目标 IP 是客户端的 IP。这时 RS 的包通过网关（LVS）中转，LVS 会做源地址转换（SNAT），将包的源地址改为 VIP，这样，这个包对客户端看起来就仿佛是 LVS 直接返回给它的。</p><p><img src="/articles/d0d5843b/1.jpeg" alt></p><h4 id="基于TUN"><a href="#基于TUN" class="headerlink" title="基于TUN"></a>基于TUN</h4><pre><code>在LVS（NAT）模式的集群环境中，由于所有的数据请求及响应的数据包都需要经过LVS调度器转发，如果后端服务器的数量大于10台，则调度器就会成为整个集群环境的瓶颈。我们知道，数据请求包往往远小于响应数据包的大小。因为响应数据包中包含有客户需要的具体数据，所以LVS（TUN）的思路就是将请求与响应数据分离，让调度器仅处理数据请求，而让真实服务器响应数据包直接返回给客户端。VS/TUN工作模式拓扑结构如图3所示。其中，IP隧道（IP tunning）是一种数据包封装技术，它可以将原始数据包封装并添加新的包头（内容包括新的源地址及端口、目标地址及端口），从而实现将一个目标为调度器的VIP地址的数据包封装，通过隧道转发给后端的真实服务器（Real Server），通过将客户端发往调度器的原始数据包封装，并在其基础上添加新的数据包头（修改目标地址为调度器选择出来的真实服务器的IP地址及对应端口），LVS（TUN）模式要求真实服务器可以直接与外部网络连接，真实服务器在收到请求数据包后直接给客户端主机响应数据。</code></pre><p><img src="/articles/d0d5843b/3.png" alt></p><p><strong>VS/TUN模式的工作原理</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(1)IP隧道技术又称为IP封装技术，它可以将带有源和目标IP地址的数据报文使用新的源和目标IP进行第二次封装，这样这个报文就可以发送到一个指定的目标主机上；</span><br><span class="line">(2)VS/TUN模式下，调度器和后端服务器组之间使用IP隧道技术。当客户端发送的请求(CIP--&gt;VIP)被director接收后，director修改该报文，加上IP隧道两端的IP地址作为新的源和目标地址，并将请求转发给后端被选中的一个目标；</span><br><span class="line">(3)当后端服务器接收到报文后，首先解封报文得到原有的CIP--&gt;VIP，该后端服务器发现自身的tun接口上配置了VIP，因此接受该数据包。</span><br><span class="line">(4)当请求处理完成后，结果将不会重新交给director，而是直接返回给客户端；在后端服务器返回给客户端数据包时，由于使用的是普通网卡接口，根据一般的路由条目，源IP地址将是该网卡接口上的地址，例如是RIP。因此，要让响应数据包的源IP为VIP，必须添加一条特殊的路由条目，明确指定该路由的源地址是VIP。</span><br></pre></td></tr></table></figure><p><strong>采用VS/TUN模式时的基本属性和要求</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(1)Real  Server的RIP和director的DIP不用处于同一物理网络中，且RIP必须可以和公网通信。也就是说集群节点可以跨互联网实现。</span><br><span class="line">(2)real server的 tun接口上需要配置VIP地址，以便接收director转发过来的数据包，以及作为响应报文的源IP。</span><br><span class="line">(3)director给realserver时需要借助隧道，隧道外层的IP头部的源IP是DIP，目标IP是RIP。而realsever响应给客户端的IP头部是根据隧道内层的IP头分析得到的，源IP是VIP，目标IP是CIP。这样客户端就无法区分这个VIP到底是director的还是服务器组中的。</span><br><span class="line">(4)需要添加一条特殊的路由条目，使得后端服务器返回响应给客户端时的源IP为VIP。</span><br><span class="line">(5)director只处理入站请求，响应请求由realserver完成。</span><br><span class="line"></span><br><span class="line">一般来说，VS/TUN模式会用来负载调度缓存服务器组，这些缓存服务器一般放置在不同网络环境，可以就近返回数据给客户端。在请求对象不能在Cache服务器本地命中的情况下，Cache服务器要向源服务器发请求，将结果取回，最后将结果返回给客户。</span><br></pre></td></tr></table></figure><h4 id="基于DR"><a href="#基于DR" class="headerlink" title="基于DR"></a>基于DR</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在LVS（TUN）模式下，由于需要在LVS调度器与真实服务器之间创建隧道连接，这同样会增加服务器的负担。与LVS（TUN）类似，DR模式也叫直接路由模式，其体系结构如图4所示，该模式中LVS依然仅承担数据的入站请求以及根据算法选出合理的真实服务器，最终由后端真实服务器负责将响应数据包发送返回给客户端。与隧道模式不同的是，直接路由模式（DR模式）要求调度器与后端服务器必须在同一个局域网内，VIP地址需要在调度器与后端所有的服务器间共享，因为最终的真实服务器给客户端回应数据包时需要设置源IP为VIP地址，目标IP为客户端IP，这样客户端访问的是调度器的VIP地址，回应的源地址也依然是该VIP地址（真实服务器上的VIP），客户端是感觉不到后端服务器存在的。由于多台计算机都设置了同样一个VIP地址，所以在直接路由模式中要求调度器的VIP地址是对外可见的，客户端需要将请求数据包发送到调度器主机，而所有的真实服务器的VIP地址必须配置在Non-ARP的网络设备上，也就是该网络设备并不会向外广播自己的MAC及对应的IP地址，真实服务器的VIP对外界是不可见的，但真实服务器却可以接受目标地址VIP的网络请求，并在回应数据包时将源地址设置为该VIP地址。调度器根据算法在选出真实服务器后，在不修改数据报文的情况下，将数据帧的MAC地址修改为选出的真实服务器的MAC地址，通过交换机将该数据帧发给真实服务器。整个过程中，真实服务器的VIP不需要对外界可见。</span><br></pre></td></tr></table></figure><p><img src="/articles/d0d5843b/4.png" alt></p><p>DR 模式下需要 LVS 和 RS 集群绑定同一个 VIP（RS 通过将 VIP 绑定在 loopback 实现），但与 NAT 的不同点在于：请求由 LVS 接受，由真实提供服务的服务器（RealServer，RS）直接返回给用户，返回的时候不经过 LVS。</p><p>详细来看，一个请求过来时，LVS 只需要将网络帧的 MAC 地址修改为某一台 RS 的 MAC，该包就会被转发到相应的 RS 处理，注意此时的源 IP 和目标 IP 都没变，LVS 只是做了一下移花接木。RS 收到 LVS 转发来的包时，链路层发现 MAC 是自己的，到上面的网络层，发现 IP 也是自己的，于是这个包被合法地接受，RS 感知不到前面有 LVS 的存在。而当 RS 返回响应时，只要直接向源 IP（即用户的 IP）返回即可，不再经过 LVS。</p><p><img src="/articles/d0d5843b/2.jpeg" alt></p><p>DR 负载均衡模式数据分发过程中不修改 IP 地址，只修改 mac 地址，由于实际处理请求的真实物理 IP 地址和数据请求目的 IP 地址一致，所以不需要通过负载均衡服务器进行地址转换，可将响应数据包直接返回给用户浏览器，避免负载均衡服务器网卡带宽成为瓶颈。因此，DR 模式具有较好的性能，也是目前大型网站使用最广泛的一种负载均衡手段。</p><h2 id="十种调度算法"><a href="#十种调度算法" class="headerlink" title="十种调度算法"></a>十种调度算法</h2><pre><code>根据前面的介绍，我们了解了LVS的三种工作模式，但不管实际环境中采用的是哪种模式，调度算法进行调度的策略与算法都是LVS的核心技术。LVS的调度方法分为两种，一种是静态方法，一种是动态方法：静态方法：仅根据算法本身实现调度；实现起点公平，不管服务器当前处理多少请求，分配的数量一致动态方法：根据算法及后端RS当前的负载状况实现调度；不管以前分了多少，只看分配的结果是不是公平</code></pre><h4 id="静态调度算法（4种）"><a href="#静态调度算法（4种）" class="headerlink" title="静态调度算法（4种）"></a>静态调度算法（4种）</h4><p><em>1)rr  ( round robin 轮叫,轮询)</em>  </p><p>说明：轮询调度算法的原理是每一次把来自用户的请求轮流分配给内部中的服务器，从1开始，直到N(内部服务器个数)，然后重新开始循环。算法的优点是其简洁性，它无需记录当前所有连接的状态，所以它是一种无状态调度。缺点：是不考虑每台服务器的处理能力。</p><p><em>(2)wrr  (weight round robin  加权轮询:以权重之间的比例实现在各主机之间进行调度)</em>  </p><p>说明：由于每台服务器的配置、安装的业务应用等不同，其处理能力会不一样。所以，我们根据服务器的不同处理能力，给每个服务器分配不同的权值，使其能够接受相应权值数的服务请求。</p><p><em>(3)sh  (source hashing  源地址hash实现会话绑定session affinity)</em>  </p><p>说明：简单的说就是有将同一客户端的请求发给同一个real server,源地址散列调度算法正好与目标地址散列调度算法相反，它根据请求的源IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的并且没有超负荷，将请求发送到该服务器，否则返回空。它采用的散列函数与目标地址散列调 度算法的相同。它的算法流程与目标地址散列调度算法的基本相似，除了将请求的目标IP地址换成请求的源IP地址。</p><p><em>(4)dh  (destination hashing  目标地址hash)</em>  </p><p>说明：将同样的请求发送给同一个server,一般用于缓存服务器，简单的说，LB集群后面又加了一层，在LB与realserver之间加了一层缓存服 务器，当一个客户端请求一个页面时,LB发给cache1,当第二个客户端请求同样的页面时，LB还是发给cache1,这就是我们所说的，将同样的请求 发给同一个server,来提高缓存的命中率。目标地址散列调度算法也是针对目标IP地址的负载均衡，它是一种静态映射算法，通过一个散列（Hash）函 数将一个目标IP地址映射到一台服务器。目标地址散列调度算法先根据请求的目标IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。</p><h4 id="动态调度算法（6种）"><a href="#动态调度算法（6种）" class="headerlink" title="动态调度算法（6种）"></a>动态调度算法（6种）</h4><p><em>(1)lc  (leash-connection 最少连接)</em> </p><p>说明：最少连接调度算法是把新的连接请求分配到当前连接数最小的服务器，最小连接调度是一种动态调度短算法，它通过服务器当前所活跃的连接数来估计服务器 的负载均衡，调度器需要记录各个服务器已建立连接的数目，当一个请求被调度到某台服务器，其连接数加1，当连接中止或超时，其连接数减一，在系统实现时， 我们也引入当服务器的权值为0时，表示该服务器不可用而不被调度。此算法忽略了服务器的性能问题，有的服务器性能好，有的服务器性能差，通过加权重来区分 性能，所以有了下面算法wlc。</p><p>简单算法：active*256+inactive (谁的小，挑谁)</p><p><em>(2)wlc  (加权最少连接 )</em> </p><p>说明:加权最小连接调度算法是最小连接调度的超集，各个服务器用相应的权值表示其处理性能。服务器的缺省权值为1，系统管理员可以动态地设置服务器的权限，加权 最小连接调度在调度新连接时尽可能使服务器的已建立连接数和其权值成比例。由于服务器的性能不同，我们给性能相对好的服务器，加大权重，即会接收到更多的 请求。</p><p>简单算法：（active*256+inactive）/weight（谁的小，挑谁）</p><p><em>(3)sed (最少期望延迟)</em> </p><p>说明：不考虑非活动连接，谁的权重大，我们优先选择权重大的服务器来接收请求，但会出现问题，就是权重比较大的服务器会很忙，但权重相对较小的服务器很闲，甚至会接收不到请求，所以便有了下面的算法nq。</p><p>基于wlc算法，简单算法：（active+1)*256/weight （谁的小选谁）</p><p><em>(4)nq (never queue 永不排队)</em>  </p><p>说明：在上面我们说明了，由于某台服务器的权重较小，比较空闲，甚至接收不到请求，而权重大的服务器会很忙，所此算法是sed改进，就是说不管你的权重多 大都会被分配到请求。简单说，无需队列，如果有台real server的连接数为0就直接分配过去，不需要在进行sed运算。</p><p><em>(5)LBLC  (基于局部性的最少连接)</em>  </p><p>说明：基于局部性的最少连接算法是针对请求报文的目标IP地址的负载均衡调度，主要用于Cache集群系统，因为Cache集群中客户请求报文的目标IP 地址是变化的，这里假设任何后端服务器都可以处理任何请求，算法的设计目标在服务器的负载基本平衡的情况下，将相同的目标IP地址的请求调度到同一个台服 务器，来提高服务器的访问局部性和主存Cache命中率，从而调整整个集群系统的处理能力。</p><p><em>(6)LBLCR  (基于局部性的带复制功能的最少连接)</em>   </p><p>说明：基于局部性的带复制功能的最少连接调度算法也是针对目标IP地址的负载均衡，该算法根据请求的目标IP地址找出该目标IP地 址对应的服务器组，按“最小连接”原则从服务器组中选出一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载，则按“最小连接”原则从这个 集群中选出一台服务器，将该服务器加入到服务器组中，将请求发送到该服务器。同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除， 以降低复制的程度。</p><p>总结: 在实际lvs环境中，比较常用的算法有:wlc，rr，wrr这三种，一般性能相近的server常用rr，而根据应用比如连接情况，一般用wlc</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;LVS（Linux Virtual Server）即Linux虚拟服务器，是由章文嵩博士主导的开源负载均衡项目，目前LVS已经被集成到Linux内核模块中。该项目在Linux内核中实现了基于IP的数据请求负载均衡调度方案，其体系结构如图1所示，终端互联网用户从外部访问公司的外部负载均衡服务器，终端用户的Web请求会发送给LVS调度器，调度器根据自己预设的算法决定将该请求发送给后端的某台Web服务器，比如，轮询算法可以将外部的请求平均分发给后端的所有服务器，终端用户访问LVS调度器虽然会被转发到后端真实的服务器，但如果真实服务器连接的是相同的存储，提供的服务也是相同的服务，最终用户不管是访问哪台真实服务器，得到的服务内容都是一样的，整个集群对用户而言都是透明的。最后根据LVS工作模式的不同，真实服务器会选择不同的方式将用户需要的数据发送到终端用户，LVS工作模式分为NAT模式、TUN模式、以及DR模式。&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;img src=&quot;/articles/d0d5843b/1.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;本文详细讲解了lvs的三种模式和十种算法。让你有个清晰的认识。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Lvs" scheme="https://wandouduoduo.netlify.com/tags/Lvs/"/>
    
  </entry>
  
  <entry>
    <title>分布式定时任务调度系统Saturn安装部署</title>
    <link href="https://wandouduoduo.netlify.com/articles/8fc06fb2.html"/>
    <id>https://wandouduoduo.netlify.com/articles/8fc06fb2.html</id>
    <published>2020-06-10T11:18:15.000Z</published>
    <updated>2020-06-11T08:50:31.846Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Saturn (定时任务调度系统)是唯品会自主研发的分布式的定时任务的调度平台，目标是取代传统的Linux Cron/Spring Batch Job/Quartz的方式，做到全域统一配置，统一监控，任务高可用以及分片。目前该平台己平稳运行1年，承载着唯品会核心系统的全部定时任务的调度，监控，配置，经受住了生产环境的各种考验。 开源版本系唯品会生产使用的saturn核心，去除了唯品会的认证，监控，告警系统等依赖，可独立部署安装使用。</p><a id="more"></a><h2 id="系统特性"><a href="#系统特性" class="headerlink" title="系统特性"></a>系统特性</h2><h4 id="任务负荷，动态均衡"><a href="#任务负荷，动态均衡" class="headerlink" title="任务负荷，动态均衡"></a>任务负荷，动态均衡</h4><p><img src="/articles/8fc06fb2/1.png" alt></p><p>Saturn 给每个任务的每个分片一个负荷值，即权重。比如任务 A 每个分片的权重都是 30，任务 B每个分片的权重都是 10，在进行资源调度的时候，Saturn 可以根据分配给不同机器的总负荷值，来做一个均衡。比如说机器 1 的负荷值是 60，机器 2 的负荷值也是 60，虽然机器 1 只负责了两个任务分片，机器 2 却负责了四个任务分片，通过任务负荷来达到资源均衡的效果。</p><h4 id="优先列表"><a href="#优先列表" class="headerlink" title="优先列表"></a>优先列表</h4><p>资源自动分配时存在一个问题，若任务非常重要如唯品会的双订单任务，或者订单处理的问题非常重要，这时机器应该如何处理？</p><p><img src="/articles/8fc06fb2/2.png" alt></p><p>对此唯品会引入了优先列表概念，开发和运维人员可以给某些任务分配一些优先运行的机器列表，当优先机器任务存在的时候，只会在这些机器运行，只有当这些机器全部不在了，任务才会被迁移到其他的机器上运行，满足订单部门提出的场景化需求。</p><h4 id="本地模式"><a href="#本地模式" class="headerlink" title="本地模式"></a>本地模式</h4><p><img src="/articles/8fc06fb2/3.png" alt></p><p>有些情况下，任务的分配是不可预知的，比如唯品会在商品售卖前，会全量扫描在售商品图片，这个任务要进行大量的图片处理，这时通常就不会让这个任务跟其他任务共享资源。另外 Saturn 支持容器化，可以在高峰期自动扩展到 150 个节点去执行某个任务，然后在低谷期自动缩回到 20 个节点，这就是 Saturn 本地模式的一种场景。</p><h2 id="探索与演进"><a href="#探索与演进" class="headerlink" title="探索与演进"></a>探索与演进</h2><p>唯品会任务调度系统也经过了长期的探索， 2012 年之前采用 Crond 服务，2014 年开始使用Quartz、 Spring Batch 和各团队的个性化方案，但会遇到任务没法监控，任务出问题了不知道和成本高昂等情况，因此唯品会在 2016 年开始实行全部定时任务，并统一到 Saturn 平台。</p><p>目前 Saturn 产生的价值是：有 66 个业务应用系统在使用，包括订单、支付、库存、用户、财务等售卖相关的核心系统，每天有 350 个执行节点执行任务，每天执行任务 2000 万多次，相当于网站的全部的流量。这表明 Saturn 并不是一个纸上谈兵的产品，它已经承受住了唯品会大规模使用场景的考验。</p><h2 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h2><h4 id="术语定义"><a href="#术语定义" class="headerlink" title="术语定义"></a><strong>术语定义</strong></h4><p><img src="/articles/8fc06fb2/4.png" alt></p><h4 id="系统逻辑架构"><a href="#系统逻辑架构" class="headerlink" title="系统逻辑架构"></a>系统逻辑架构</h4><p><img src="/articles/8fc06fb2/5.png" alt></p><p><strong>执行结点</strong><br>负责作业的触发（定时），作业执行，结果上报，日志上报，告警上报，监控日志写入等功能。可独立运行在业务服务器，也可与业务代码运行在同一个JVM。 使用java开发，提供jar包和可运行的工程两种方式供业务方使用，是业务作业接入saturn最主要的组件。</p><p><strong>控制台</strong><br>负责作业的统一配置，包括作业添加、删除，作业属性配置，作业状态查看，执行日志查看，执行结点监控等功能。 控制台单独部署，提供WEB应用给全域共用，业务接入方根据申请的权限控制对应的业务作业。</p><p><strong>作业分片调度器</strong><br>Saturn的”大脑“，其基本功能是将作业分片指派到执行结点。通过调整分配算法和分配策略，可以将作业合理地安排到合适的执行结点，从而实现HA，负载均衡，动态扩容，作业隔离，资源隔离等治理功能。 作业分片调度器为后台程序，单独部署；它是公共资源，所有域共用同一套作业分片调度器。接入作业后，会自动接受作业分片调度器的调度。</p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><h3 id="控制台console部署"><a href="#控制台console部署" class="headerlink" title="控制台console部署"></a>控制台console部署</h3><h4 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a><strong>准备工作</strong></h4><p>1,  安装zookeeper(&gt;=3.4.6)jdk(&gt;=1.7)并启动zookeeper</p><p>2,  下载console包<a href="https://github.com/vipshop/Saturn/releases（建议下载源码包，自行编译，console项目是基于maven+springboot开发，可以直接打成jar包运行）" target="_blank" rel="noopener">https://github.com/vipshop/Saturn/releases（建议下载源码包，自行编译，console项目是基于maven+springboot开发，可以直接打成jar包运行）</a></p><h4 id="console部署"><a href="#console部署" class="headerlink" title="console部署"></a>console部署</h4><p>1,  准备域配置json文件</p><p>域配置json文件用于定义saturn系统中的组织名，namespace，以及ZK的连接串，格式如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    <span class="attr">"nameAndNamespace"</span>:<span class="string">"/name/namespace"</span>,</span><br><span class="line"></span><br><span class="line">   <span class="attr">"zkAddressList"</span>:<span class="string">"ip:port,ip:port,..."</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>把它保存在某个路径，比如/apps/saturn/config/regcenter.json</p><p>2,  配置环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export   REG_CENTER_JSON_PATH=/apps/saturn/config/regcenter.json</span><br></pre></td></tr></table></figure><p>3 启动saturn console</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java -DSATURN_CONSOLE_LOG=/apps –jar  saturn-console-master-SNAPSHOT.jar &amp;</span><br></pre></td></tr></table></figure><p> 注意，如果是在生产环境启动console，建议增加一些JVM启动参数：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#for jdk1.7:</span></span><br><span class="line">-Xmx2G -Xms2G -XX:PermSize=256m-XX:MaxPermSize=512m -XX:+UseConcMarkSweepGC -XX:+UseCMSInitiatingOccupancyOnly-XX:CMSInitiatingOccupancyFraction=75 -XX:+ExplicitGCInvokesConcurrent-Xloggc:<span class="variable">$&#123;HOME&#125;</span>/gc_zk.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps-XX:ErrorFile=<span class="variable">$&#123;HOME&#125;</span>/hs_err_%p.log -XX:+HeapDumpOnOutOfMemoryError-XX:HeapDumpPath=<span class="variable">$&#123;HOME&#125;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#for jdk1.8:</span></span><br><span class="line">-Xmx2G -Xms2G -MetaspaceSize=256m-MaxMetaspaceSize=512m -XX:+UseConcMarkSweepGC-XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction=75-XX:+ExplicitGCInvokesConcurrent -Xloggc:<span class="variable">$&#123;HOME&#125;</span>/gc_zk.log -XX:+PrintGCDetails-XX:+PrintGCDateStamps -XX:ErrorFile=<span class="variable">$&#123;HOME&#125;</span>/hs_err_%p.log-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=<span class="variable">$&#123;HOME&#125;</span></span><br></pre></td></tr></table></figure><h3 id="executor部署"><a href="#executor部署" class="headerlink" title="executor部署"></a>executor部署</h3><h4 id="准备工作-1"><a href="#准备工作-1" class="headerlink" title="准备工作"></a>准备工作</h4><p>1，安装jdk(&gt;=1.7)</p><p>2，下载executor包<a href="https://github.com/vipshop/Saturn/releases（建议下载源码包，自行编译）" target="_blank" rel="noopener">https://github.com/vipshop/Saturn/releases（建议下载源码包，自行编译）</a></p><h4 id="executor部署-1"><a href="#executor部署-1" class="headerlink" title="executor部署"></a>executor部署</h4><p>1，配置zookeeper链接地址环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export VIP_SATURN_ZK_CONNECTION=zkip:2181</span><br></pre></td></tr></table></figure><p>2，启动executor</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">chmod a+x bin/saturn-executor.sh</span><br><span class="line"></span><br><span class="line">bin/saturn-executor.sh start -n saturn-it.vip.com -e executor_001 -env dev</span><br><span class="line"></span><br><span class="line"><span class="comment">#-n：本executor所属的域名，即namespace</span></span><br><span class="line"><span class="comment">#-e: 本executor的唯一ID</span></span><br><span class="line"><span class="comment">#-env: 运行模式，可取值为dev/product， dev模式下-Xmx为512m，product模式下-Xmx为2G</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#exeucutor启动之后，日志默认保存在/apps/logs/saturn/&#123;namespace&#125;/&#123;executorname&#125;-&#123;ip&#125;/目录下； 可以通过启动参数修改日志保存路径，具体参数为：</span></span><br><span class="line"></span><br><span class="line">bin/saturn-executor.sh start -nsaturn-it.vip.com -e executor_001 -Dsaturn.log.dir=/apps/logs/otherdir</span><br></pre></td></tr></table></figure><h4 id="部署java作业"><a href="#部署java作业" class="headerlink" title="部署java作业"></a>部署java作业</h4><p>saturn executor启动时会扫描 saturn目录的同级目录下的app目录并加载这个目录下（含子目录)所有的jar包定义的类(关于这个原理，请参考Saturn架构文档 )，因此可以把开发好的jar包及其依赖包一起放在 app目录，目录结构如下：</p><p><img src="/articles/8fc06fb2/6.png" alt></p><p>可以通过 -d 参数来重新定义executor寻找作业实现类的路径，比如</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/saturn-executor.sh start -n saturn-it.vip.com -e executor_001 -d /apps/<span class="built_in">jobs</span></span><br></pre></td></tr></table></figure><p>以上面的命令启动后，exeucutor会从/apps/jobs中寻找作业实现类。</p><h3 id="Saturn-java-开发指引"><a href="#Saturn-java-开发指引" class="headerlink" title="Saturn java 开发指引"></a>Saturn java 开发指引</h3><p><a href="https://github.com/vipshop/Saturn/wiki/saturn%E5%BC%80%E5%8F%91%E6%8C%87%E5%BC%95%E4%B9%8Bjava" target="_blank" rel="noopener">https://github.com/vipshop/Saturn/wiki/saturn%E5%BC%80%E5%8F%91%E6%8C%87%E5%BC%95%E4%B9%8Bjava</a></p><h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><h4 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h4><p>A   192.168.5.24    虚拟机  zookeeper（路径：/home/qq/zookeeper）</p><p>A   192.168.5.24    虚拟机  console</p><p>A   192.168.5.24    虚拟机  executor_001</p><p>B   172.17.30.35    物理机  executor_002</p><p>目录结构：</p><p>A  </p><p><img src="/articles/8fc06fb2/7.png" alt></p><p>B</p><p><img src="/articles/8fc06fb2/8.png" alt></p><h4 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h4><p>A在/etc/profile文件末尾增加如下配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">REG_CENTER_JSON_PATH=/home/qq/saturn/regcenter.json</span><br><span class="line"></span><br><span class="line">VIP_SATURN_ZK_CONNECTION=192.168.5.24:2181</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> REG_CENTER_JSON_PATH VIP_SATURN_ZK_CONNECTION</span><br></pre></td></tr></table></figure><p>B在/etc/profile文件末尾增加如下配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">REG_CENTER_JSON_PATH=/home/qzn/regcenter.json</span><br><span class="line"></span><br><span class="line">VIP_SATURN_ZK_CONNECTION=192.168.5.24:2181</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> REG_CENTER_JSON_PATHVIP_SATURN_ZK_CONNECTION</span><br></pre></td></tr></table></figure><p>A、 B分别在对应的目录下创建regcenter.json文件，并写入如下内容：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">   <span class="attr">"nameAndNamespace"</span>:<span class="string">"/demo/saturn-it.vip.com"</span>,</span><br><span class="line"></span><br><span class="line">   <span class="attr">"zkAddressList"</span>:<span class="string">"192.168.5.24:2181"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="启动console"><a href="#启动console" class="headerlink" title="启动console"></a>启动console</h4><p>首先在A机器启动zookeeper注册中心:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/qq/zookeeper/bin</span><br><span class="line"></span><br><span class="line">./zkServer.sh start &amp;</span><br><span class="line"></span><br><span class="line">日志查看：tail -f zookeeper.out</span><br></pre></td></tr></table></figure><p>然后在A机器启动console控制台:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/qq/saturn/</span><br><span class="line"></span><br><span class="line">java -jarsaturn-console-master-SNAPSHOT.jar &amp;</span><br><span class="line"></span><br><span class="line">日志查看：tail -f  SATURN_CONSOLE_LOG_IS_UNDEFINED/saturn.console</span><br></pre></td></tr></table></figure><p> 启动后可直接在浏览器中访问：<a href="http://192.168.5.24:9088/" target="_blank" rel="noopener">http://192.168.5.24:9088/</a></p><p><img src="/articles/8fc06fb2/9.png" alt></p><h4 id="启动executor-001（带有job）"><a href="#启动executor-001（带有job）" class="headerlink" title="启动executor_001（带有job）"></a>启动executor_001（带有job）</h4><p>首先将demo打成jar放到对应目录下（executor会自动扫描此目录下的相关job），如图：</p><p><img src="/articles/8fc06fb2/10.png" alt></p><p>然后启动executor_001:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span>/home/qq/saturn/saturn-executor-master-SNAPSHOT/saturn/</span><br><span class="line"></span><br><span class="line">bin/saturn-executor.sh start -n saturn-it.vip.com -e executor_001 -env dev</span><br><span class="line"></span><br><span class="line">日志查看: </span><br><span class="line">tail -f /apps/logs/saturn/saturn-it.vip.com/executor_001-192.168.5.24/saturn-executor-log.log(executor日志)</span><br></pre></td></tr></table></figure><p>启动后查看控制台，已经有一个executor</p><h4 id="启动executor-002（带有job）"><a href="#启动executor-002（带有job）" class="headerlink" title="启动executor_002（带有job）"></a>启动executor_002（带有job）</h4><p>与上一步类似</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /home/qzn/saturn-executor-master-SNAPSHOT/saturn/</span><br><span class="line"></span><br><span class="line">bin/saturn-executor.sh start -n saturn-it.vip.com -e executor_002 -env dev</span><br></pre></td></tr></table></figure><h4 id="执行job"><a href="#执行job" class="headerlink" title="执行job"></a>执行job</h4><p><img src="/articles/8fc06fb2/11.png" alt></p><p>任务启动后，只有一个executor会运行job</p><p>关闭当前运行的executor，任务会在另一个executor运行 bin/saturn-executor.sh stop</p><p> 禁用job后，job可以停止运行</p><p><strong>Job并行执行**</strong></p><p> 修改job设置并启用</p><p> <img src="/articles/8fc06fb2/12.png" alt></p><p>每个executor执行一个分片</p><p>当停止一个executor时，job在另一个executor上会一次执行两个分片任务</p><p><strong>优先executor执行</strong></p><p>设置优先executor为executor_002，则job只会在002上执行</p><p><img src="/articles/8fc06fb2/13.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;Saturn (定时任务调度系统)是唯品会自主研发的分布式的定时任务的调度平台，目标是取代传统的Linux Cron/Spring Batch Job/Quartz的方式，做到全域统一配置，统一监控，任务高可用以及分片。目前该平台己平稳运行1年，承载着唯品会核心系统的全部定时任务的调度，监控，配置，经受住了生产环境的各种考验。 开源版本系唯品会生产使用的saturn核心，去除了唯品会的认证，监控，告警系统等依赖，可独立部署安装使用。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Saturn" scheme="https://wandouduoduo.netlify.com/tags/Saturn/"/>
    
  </entry>
  
  <entry>
    <title>详解统一配置中心平台：Apollo服务搭建</title>
    <link href="https://wandouduoduo.netlify.com/articles/10484a0.html"/>
    <id>https://wandouduoduo.netlify.com/articles/10484a0.html</id>
    <published>2020-05-19T07:06:21.000Z</published>
    <updated>2020-06-11T08:50:50.367Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。本文就详细讲解了Apollo这一统一配置中心的搭建过程。</p><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/ctripcorp/apollo" target="_blank" rel="noopener">官方地址</a></p><p><a href="https://github.com/ctripcorp/apollo/wiki/Apollo%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E4%BB%8B%E7%BB%8D" target="_blank" rel="noopener">官方详细文档</a></p><p><a href="https://github.com/ctripcorp/apollo/wiki/Quick-Start" target="_blank" rel="noopener">快速部署文档</a></p><p><a href="https://github.com/ctripcorp/apollo/wiki/分布式部署指南" target="_blank" rel="noopener">生产分布式部署指南</a></p><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>系统版本：CentOS7.X</p><p>环境组件：JDK1.8，Mysql5.7</p><p>说明：本次部署是在单台上部署测试环境，这里只做研究测试，尽量不要用在生产环境。因为生产环境通常为保证服务的稳定性，需要考虑高可用和高负载等方案。</p><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><h4 id="下载安装包"><a href="#下载安装包" class="headerlink" title="下载安装包"></a>下载安装包</h4><p><a href="https://github.com/ctripcorp/apollo/releases" target="_blank" rel="noopener">官方稳定包下载</a></p><p>依赖的jar包如下:</p><p>apollo-adminservice-1.6.1-github.zip</p><p>apollo-configservice-1.6.1-github.zip</p><p>apollo-portal-1.6.1-github.zip  </p><h4 id="创建ApolloPortalDB"><a href="#创建ApolloPortalDB" class="headerlink" title="创建ApolloPortalDB"></a>创建ApolloPortalDB</h4><p>通过各种MySQL客户端导入<a href="https://github.com/nobodyiam/apollo-build-scripts/blob/master/sql/apolloportaldb.sql" target="_blank" rel="noopener">sql/apolloportaldb.sql</a>即可</p><p>导入成功后，可以通过执行以下sql语句来验证</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select `Id`, `AppId`, `Name` from ApolloPortalDB.App;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">Id</th><th align="center">AppId</th><th align="center">Name</th></tr></thead><tbody><tr><td align="center">1</td><td align="center">SampleApp</td><td align="center">Sample App</td></tr></tbody></table><h4 id="创建ApolloConfigDB"><a href="#创建ApolloConfigDB" class="headerlink" title="创建ApolloConfigDB"></a>创建ApolloConfigDB</h4><p>通过各种MySQL客户端导入<a href="https://github.com/nobodyiam/apollo-build-scripts/blob/master/sql/apolloconfigdb.sql" target="_blank" rel="noopener">sql/apolloconfigdb.sql</a>即可<br>导入成功后，可以通过执行以下sql语句来验证</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select `NamespaceId`, `Key`, `Value`, `Comment` from ApolloConfigDB.Item;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">NamespaceId</th><th align="center">Key</th><th align="center">Value</th><th align="center">Comment</th></tr></thead><tbody><tr><td align="center">1</td><td align="center">timeout</td><td align="center">100</td><td align="center">sample timeout配置</td></tr></tbody></table><h4 id="修改数据库配置文件"><a href="#修改数据库配置文件" class="headerlink" title="修改数据库配置文件"></a>修改数据库配置文件</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建应用目录</span></span><br><span class="line">mkdir -p /usr/<span class="built_in">local</span>/&#123;apollo-adminservice,apollo-configservice,apollo-portal&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 解压安装包</span></span><br><span class="line">unzip apollo-adminservice-1.6.1-github.zip -d /usr/<span class="built_in">local</span>/apollo-adminservice/</span><br><span class="line">unzip apollo-configservice-1.6.1-github.zip -d /usr/<span class="built_in">local</span>/apollo-configservice/</span><br><span class="line">unzip apollo-portal-1.6.1-github.zip -d /usr/<span class="built_in">local</span>/apollo-portal/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vim /usr/<span class="built_in">local</span>/apollo-configservice/config/application-github.properties</span><br><span class="line"></span><br><span class="line"><span class="comment"># DataSource</span></span><br><span class="line">spring.datasource.url = jdbc:mysql://localhost:3306/ApolloPortalDB?characterEncoding=utf8</span><br><span class="line">spring.datasource.username = root</span><br><span class="line">spring.datasource.password = 123456</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vim /usr/<span class="built_in">local</span>/apollo-portal/config/application-github.properties</span><br><span class="line"></span><br><span class="line"><span class="comment"># DataSource</span></span><br><span class="line">spring.datasource.url = jdbc:mysql://localhost:3306/ApolloConfigDB?characterEncoding=utf8</span><br><span class="line">spring.datasource.username = root</span><br><span class="line">spring.datasource.password = 123456</span><br><span class="line"><span class="comment">#apollo.eureka.server.enabled=true</span></span><br><span class="line"><span class="comment">#apollo.eureka.client.enabled=true</span></span><br></pre></td></tr></table></figure><h4 id="启动apollo服务"><a href="#启动apollo服务" class="headerlink" title="启动apollo服务"></a>启动apollo服务</h4><p>启动顺序</p><p>configservice –&gt;   adminservice  –&gt;  portal</p><p>一切顺利的话: 通过访问  http://部署服务器地址:端口/8070,  就能看到配置登录页</p><p><img src="/articles/10484a0/1.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;Apollo（阿波罗）是携程框架部门研发的分布式配置中心，能够集中化管理应用不同环境、不同集群的配置，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。本文就详细讲解了Apollo这一统一配置中心的搭建过程。&lt;/p&gt;
&lt;h2 id=&quot;参考&quot;&gt;&lt;a href=&quot;#参考&quot; class=&quot;headerlink&quot; title=&quot;参考&quot;&gt;&lt;/a&gt;参考&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/ctripcorp/apollo&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官方地址&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/ctripcorp/apollo/wiki/Apollo%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E4%BB%8B%E7%BB%8D&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;官方详细文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/ctripcorp/apollo/wiki/Quick-Start&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;快速部署文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/ctripcorp/apollo/wiki/分布式部署指南&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;生产分布式部署指南&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Apollo" scheme="https://wandouduoduo.netlify.com/tags/Apollo/"/>
    
  </entry>
  
  <entry>
    <title>详解统一配置中心平台：服务选型</title>
    <link href="https://wandouduoduo.netlify.com/articles/7b60ea15.html"/>
    <id>https://wandouduoduo.netlify.com/articles/7b60ea15.html</id>
    <published>2020-05-11T06:39:16.000Z</published>
    <updated>2020-05-19T07:00:17.008Z</updated>
    
    <content type="html"><![CDATA[<h2 id="为什么需配置中心"><a href="#为什么需配置中心" class="headerlink" title="为什么需配置中心"></a>为什么需配置中心</h2><h4 id="配置实时生效"><a href="#配置实时生效" class="headerlink" title="配置实时生效"></a>配置实时生效</h4><p>传统的静态配置方式要想修改某个配置只能修改之后重新发布应用。如要实现动态性，可以选择使用数据库，通过定时轮询访问数据库来感知配置的变化。但是轮询频率低，感知配置变化的延时就长，轮询频率高，感知配置变化的延时就短，但又比较损耗性能，所以需要在实时性和性能之间做折中。而配置中心专门针对这个业务场景，兼顾实时性和一致性来管理动态配置。</p><h4 id="配置管理流程"><a href="#配置管理流程" class="headerlink" title="配置管理流程"></a>配置管理流程</h4><p>配置的权限管控、灰度发布、版本管理、格式检验和安全配置等一系列的配置管理相关的特性也是配置中心不可获取的一部分。</p><h4 id="运维需求"><a href="#运维需求" class="headerlink" title="运维需求"></a>运维需求</h4><p>随着程序功能的日益复杂，程序的配置日益增多：各种功能的开关、参数的配置、服务器的地址等等。对程序配置的期望值也越来越高：配置修改后实时生效，分环境、分集群管理配置，代码安全、审核机制等等。在这样的大环境下，传统的通过配置文件、数据库等方式已经越来越无法满足开发人员对配置管理的需求。所以，配置中心应运而生。</p><h2 id="开源配置中心比较"><a href="#开源配置中心比较" class="headerlink" title="开源配置中心比较"></a>开源配置中心比较</h2><p>目前市面上用的比较多的配置中心有：（按开源时间排序）</p><h4 id="Disconf"><a href="#Disconf" class="headerlink" title="Disconf"></a>Disconf</h4><p>2014年7月百度开源的配置管理中心，同样具备配置的管理能力，不过目前已经不维护了，最近的一次提交是两年前了。</p><h4 id="Spring-Cloud-Config"><a href="#Spring-Cloud-Config" class="headerlink" title="Spring Cloud Config"></a>Spring Cloud Config</h4><p>2014年9月开源，Spring Cloud 生态组件，可以和Spring Cloud体系无缝整合。</p><h4 id="Apollo"><a href="#Apollo" class="headerlink" title="Apollo"></a>Apollo</h4><p>2016年5月，携程开源的配置管理中心，具备规范的权限、流程治理等特性。</p><h4 id="Nacos"><a href="#Nacos" class="headerlink" title="Nacos"></a>Nacos</h4><p>2018年6月，阿里开源的配置中心，也可以做DNS和RPC的服务发现。</p><h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="https://springcloud.cc/spring-cloud-config.html" target="_blank" rel="noopener">Spring Cloud Config</a></p><p><a href="https://github.com/ctripcorp/apollo" target="_blank" rel="noopener">Apollo</a></p><p><a href="https://nacos.io/" target="_blank" rel="noopener">Nacos</a></p><a id="more"></a><h2 id="产品概念特点比较"><a href="#产品概念特点比较" class="headerlink" title="产品概念特点比较"></a>产品概念特点比较</h2><p>由于Disconf不再维护，下面对比一下Spring Cloud Config、Apollo和Nacos。</p><h4 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h4><p>应用是客户端系统的基本单位，Spring Cloud Config 将应用名称和对应Git中的文件名称关联起来了，这样可以起到多个应用配置相互隔离的作用。Apollo的配置都是在某个应用下面的（除了公共配置），也起到了多个应用配置相互隔离的作用。Nacos的应用概念比较弱，只有一个用于区分配置的额外属性，不过可以使用 Group 来做应用字段，可以起到隔离作用。</p><h4 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h4><p>不同的环境可以搭建不同的集群，这样可以起到物理隔离的作用，Spring Cloud Config、Apollo、Nacos都支持多个集群。</p><h4 id="Label-Profile-amp-环境-amp-命名空间"><a href="#Label-Profile-amp-环境-amp-命名空间" class="headerlink" title="Label Profile &amp; 环境 &amp; 命名空间"></a>Label Profile &amp; 环境 &amp; 命名空间</h4><p>Spring Cloud Config可以使用Label和Profile来做逻辑隔离，Label指远程仓库的分支，Profile类似Maven Profile可以区分环境，比如{application}-{profile}.properties。</p><p>Nacos的命名空间和Apollo的环境一样，是一个逻辑概念，可以作为环境逻辑隔离。Apollo中的命名空间指配置的名称，具体的配置项指配置文件中的一个Property。</p><h4 id="配置管理功能的对比"><a href="#配置管理功能的对比" class="headerlink" title="配置管理功能的对比"></a>配置管理功能的对比</h4><p>作为配置中心，配置的整个管理流程应该具备流程化能力。</p><h4 id="灰度发布"><a href="#灰度发布" class="headerlink" title="灰度发布"></a>灰度发布</h4><p>配置的灰度发布是配置中心比较重要的功能，当配置的变更影响比较大的时候，需要先在部分应用实例中验证配置的变更是否符合预期，然后再推送到所有应用实例。</p><p>Spring Cloud Config支持通过/bus/refresh端点的destination参数来指定要更新配置的机器，不过整个流程不够自动化和体系化。</p><p>Apollo可以直接在控制台上点灰度发布指定发布机器的IP，接着再全量发布，做得比较体系化。<br>Nacos目前发布到0.9版本，还不支持灰度发布。</p><h4 id="权限管理"><a href="#权限管理" class="headerlink" title="权限管理"></a>权限管理</h4><p>配置的变更和代码变更都是对应用运行逻辑的改变，重要的配置变更常常会带来核弹的效果，对于配置变更的权限管控和审计能力同样是配置中心重要的功能。</p><p>Spring Cloud Config依赖Git的权限管理能力，开源的GitHub权限控制可以分为Admin、Write和Read权限，权限管理比较完善。</p><p>Apollo通过项目的维度来对配置进行权限管理，一个项目的owner可以授权给其他用户配置的修改发布权限。</p><p>Nacos目前看还不具备权限管理能力。</p><h4 id="版本管理-amp-回滚"><a href="#版本管理-amp-回滚" class="headerlink" title="版本管理&amp;回滚"></a>版本管理&amp;回滚</h4><p>当配置变更不符合预期的时候，需要根据配置的发布版本进行回滚。Spring Cloud Config、Apollo和Nacos都具备配置的版本管理和回滚能力，可以在控制台上查看配置的变更情况或进行回滚操作。Spring Cloud Config通过Git来做版本管理，更方便些。</p><h4 id="配置格式校验"><a href="#配置格式校验" class="headerlink" title="配置格式校验"></a>配置格式校验</h4><p>应用的配置数据存储在配置中心一般都会以一种配置格式存储，比如Properties、Json、Yaml等，如果配置格式错误，会导致客户端解析配置失败引起生产故障，配置中心对配置的格式校验能够有效防止人为错误操作的发生，是配置中心核心功能中的刚需。<br>Spring Cloud Config使用Git，目前还不支持格式检验，格式的正确性依赖研发人员自己。<br>Apollo和Nacos都会对配置格式的正确性进行检验，可以有效防止人为错误。</p><h4 id="监听查询"><a href="#监听查询" class="headerlink" title="监听查询"></a>监听查询</h4><p>当排查问题或者进行统计的时候，需要知道一个配置被哪些应用实例使用到，以及一个实例使用到了哪些配置。<br>Spring Cloud Config使用Spring Cloud Bus推送配置变更，Spring Cloud Bus兼容 RabbitMQ、Kafka等，支持查询订阅Topic和Consumer的订阅关系。<br>Apollo可以通过灰度实例列表查看监听配置的实例列表，但实例监听的配置(Apollo称为命名空间)目前还没有展示出来。</p><p>Nacos可以查看监听配置的实例，也可以查看实例监听的配置情况。</p><p>基本上，这三个产品都具备监听查询能力，在我们自己的使用过程中，Nacos使用起来相对简单，易用性相对更好些。</p><h4 id="多环境"><a href="#多环境" class="headerlink" title="多环境"></a>多环境</h4><p>在实际生产中，配置中心常常需要涉及多环境或者多集群，业务在开发的时候可以将开发环境和生产环境分开，或者根据不同的业务线存在多个生产环境。如果各个环境之间的相互影响比较小（开发环境影响到生产环境稳定性），配置中心可以通过逻辑隔离的方式支持多环境。</p><p>Spring Cloud Config支持Profile的方式隔离多个环境，通过在Git上配置多个Profile的配置文件，客户端启动时指定Profile就可以访问对应的配置文件。</p><p>Apollo也支持多环境，在控制台创建配置的时候就要指定配置所在的环境，客户端在启动的时候指定JVM参数ENV来访问对应环境的配置文件。</p><p>Nacos通过命名空间来支持多环境，每个命名空间的配置相互隔离，客户端指定想要访问的命名空间就可以达到逻辑隔离的作用。</p><h4 id="多集群"><a href="#多集群" class="headerlink" title="多集群"></a>多集群</h4><p>当对稳定性要求比较高，不允许各个环境相互影响的时候，需要将多个环境通过多集群的方式进行物理隔离。</p><p>Spring Cloud Config可以通过搭建多套Config Server，Git使用同一个Git的多个仓库，来实现物理隔离。</p><p>Apollo可以搭建多套集群，Apollo的控制台和数据更新推送服务分开部署，控制台部署一套就可以管控多个集群。</p><p>Nacos控制台和后端配置服务是部署在一起的，可以通过不同的域名切换来支持多集群。</p><h4 id="配置实时推送的对比"><a href="#配置实时推送的对比" class="headerlink" title="配置实时推送的对比"></a>配置实时推送的对比</h4><p>当配置变更的时候，配置中心需要将配置实时推送到应用客户端。</p><p>Nacos和Apollo配置推送都是基于HTTP长轮询，客户端和配置中心建立HTTP长联接，当配置变更的的时候，配置中心把配置推送到客户端。</p><p><img src="/articles/7b60ea15/2.png" alt></p><p>Spring Cloud Config原生不支持配置的实时推送，需要依赖Git的WebHook、Spring Cloud Bus和客户端/bus/refresh端点:</p><ul><li>基于Git的WebHook，配置变更触发server端refresh</li><li>Server端接收到请求并发送给Spring Cloud Bus</li><li>Spring Cloud Bus接到消息并通知给客户端</li><li>客户端接收到通知，请求Server端获取最新配置</li></ul><p><img src="/articles/7b60ea15/3.png" alt></p><p>整体比较下来，Nacos和Apollo在配置实时推送链路上是比较简单高效的，Spring Cloud Config的配置推送引入Spring Cloud Bus，链路较长，比较复杂。</p><h2 id="产品功能特点比较"><a href="#产品功能特点比较" class="headerlink" title="产品功能特点比较"></a>产品功能特点比较</h2><p>根据下面的图，就可以直观了解各个产品功能</p><p><img src="/articles/7b60ea15/1.jpeg" alt></p><h2 id="架构比较"><a href="#架构比较" class="headerlink" title="架构比较"></a>架构比较</h2><p>目前很多公司内部微服务架构基础设施建设中，技术选型以Spring Cloud技术为主，也被大家俗称作“全家桶”。</p><p>因其具备微服务架构体系中所需的各个服务组件，比如服务注册发现(如Spring Cloud Eureka、Zookeeper、Consul)、API网关路由服务(Spring Cloud Zuul)，客户端负载均衡(Spring Cloud Ribbon，Zuul默认集成了Ribbon)、服务容错保护(Spring Cloud Hystrix)，消息总线 (Spring Cloud Bus)、分布式配置中心(Spring Cloud Config)、消息驱动的微服务(Spring Cloud Stream)、分布式链路跟踪服务(Spring Cloud Sleuth)。</p><h4 id="Spring-Cloud-Config配置中心介绍-amp-架构"><a href="#Spring-Cloud-Config配置中心介绍-amp-架构" class="headerlink" title="Spring Cloud Config配置中心介绍&amp;架构"></a><strong>Spring Cloud Config配置中心介绍&amp;架构</strong></h4><p>在微服务架构体系中配置中心是比较重要的组件之一，Spring Cloud官方自身提供了Spring Cloud Config分布式配置中心，由它来提供集中化的外部配置支持，它分为客户端和服务端两个部分。其中服务端称作配置中心，是一个独立的微服务应用，用来连接仓库(如Git、Svn)并未客户端提供获取配置的接口；而客户端是各微服务应用，通过指定配置中心地址从远端获取配置内容，启动时加载配置信息到应用上下文中。因Spring Cloud Config实现的配置中心默认采用了Git来存储配置信息，所以版本控制管理也是基于Git仓库本身的特性来支持的 。<br>对该组件调研后，主要采用基于消息总线的架构方式，架构图如下所示：<br><img src="/articles/7b60ea15/4.png" alt></p><p>基于消息总线的配置中心架构中需要依赖外部的MQ组件，如Rabbit、Kafka 实现远程环境事件变更通知，客户端实时配置变更可以基于Git Hook功能实现。<br><strong>Self scheduleing refresher</strong></p><blockquote><p><strong>Self scheduleing refresher</strong> 是一个定时任务，默认5分钟执行一次，执行时会判断本地的Git仓库版本与远程Git仓库版本如果不一致，则会从配置中心获取最新配置进行加载，保障了配置最终一致性。</p></blockquote><p>经过实际使用你会发现Spring Cloud Config这个配置中心并不是非常好用，如果是小规模的项目可以使用问题不大，但它并不适用于中大型的企业级的配置管理。</p><h4 id="Apollo总体架构设计"><a href="#Apollo总体架构设计" class="headerlink" title="Apollo总体架构设计"></a>Apollo总体架构设计</h4><p><img src="/articles/7b60ea15/5.png" alt></p><p><strong>各组件作用说明</strong></p><p><img src="/articles/7b60ea15/6.png" alt></p><p><strong>Apollo HA高可用设计</strong></p><p><img src="/articles/7b60ea15/7.png" alt></p><h4 id="Apollo客户端架构"><a href="#Apollo客户端架构" class="headerlink" title="Apollo客户端架构"></a>Apollo客户端架构</h4><p><img src="/articles/7b60ea15/8.png" alt></p><p><strong>客户端架构原理</strong></p><ol><li>推拉结合方式<br>客户端与配置中心保持一个长连接，配置实时推送<br>定时拉配置(默认5分钟)</li><li>本地缓存<br>配置缓存在内存<br>本地缓存一份配置文件</li><li>应用程序<br>通过Apollo客户端获取最新配置<br>订阅配置更新通知</li></ol><h4 id="Apollo核心概念"><a href="#Apollo核心概念" class="headerlink" title="Apollo核心概念"></a>Apollo核心概念</h4><p>application (应用)</p><blockquote><p>每个应用都需要有唯一的身份标识 – appId</p></blockquote><p>environment (环境)</p><blockquote><p>Apollo客户端通过不同环境获取对应配置</p></blockquote><p>cluster (集群)</p><blockquote><p>一个应用下不同实例的分组，不同的cluster，可以有不同的配置。<br> 比如北京机房和天津机房可以有不一样的kafka或zk地址配置。</p></blockquote><p>namespace (命名空间)</p><blockquote><p>一个应用下不同配置的分组，不同的namespace的类似于不同的文件。<br> 如：数据库配置，RPC配置等。支持继承公共组件的配置。<br> <strong>配置分类</strong><br> 私有类型（private）：只能被所属应用获取<br> 公共类型（public）：必须全局唯一。使用场景：部门/小组级别共享配置，中间件客户端配置。<br> 关联类型（继承类型）：私有继承公有配置并覆盖；定制公共组件配置场景。<br> <strong>配置项(Item)</strong><br> 默认和公共配置使用properties格式；私有配置支持properties/json/xml/yaml/yml格式。<br> 定位方式：app+cluster+namespace+item_key</p></blockquote><p>权限管理</p><blockquote><p>系统管理员拥有所有的权限<br> 创建者可以代为创建项目，责任人默认是项目管理员，一般创建者=责任人<br> 项目管理员可创建集群，Namespace，管理项目和Namespace权限<br> 编辑权限只能编辑不能发布<br> 发布权限只能发布不能编辑<br> 普通用户可以搜索查看所有项目配置，但没有相关操作权限</p></blockquote><h4 id="Nacos架构"><a href="#Nacos架构" class="headerlink" title="Nacos架构"></a>Nacos架构</h4><p><img src="/articles/7b60ea15/2.jpeg" alt></p><h2 id="部署结构-amp-高可用的对比"><a href="#部署结构-amp-高可用的对比" class="headerlink" title="部署结构 &amp; 高可用的对比"></a>部署结构 &amp; 高可用的对比</h2><h4 id="Spring-Cloud-Config-1"><a href="#Spring-Cloud-Config-1" class="headerlink" title="Spring Cloud Config"></a>Spring Cloud Config</h4><p>Spring Cloud Config包含config-server、Git和Spring Cloud Bus三大组件：</p><ul><li>config-server提供给客户端获取配置;</li><li>Git用于存储和修改配置;</li><li>Spring Cloud Bus通知客户端配置变更;</li></ul><p>本地测试模式下，Spring Cloud Bus和config-server需要部署一个节点，Git使用GitHub就可以。</p><p>Git服务如果使用GitHub就不用考虑高可用问题，如果考虑到安全性要自建Git私有仓库，整体的成本比较高。Web服务可以部署多节点支持高可用，由于Git有数据的一致性问题，可以通过以下的方式来支持高可用：</p><ul><li>Git+Keepalived冷备模式，当主Git挂了可以马上切到备Git;</li><li>Git多节点部署，存储使用网络文件系统或者通过DRBD实现多个Git节点的数据同步;</li></ul><h4 id="Apollo-1"><a href="#Apollo-1" class="headerlink" title="Apollo"></a>Apollo</h4><p>Apollo分为MySQL，Config Service，Admin Service，Portal四个模块：</p><ul><li>MySQL存储Apollo元数据和用户配置数据;</li><li>Config Service提供配置的读取、推送等功能，客户端请求都是落到Config Service上;</li><li>Admin Service提供配置的修改、发布等功能，Portal操作的服务就是Admin Service;</li><li>Portal提供给用户配置管理界面;</li></ul><p>本地测试Config Service，Admin Service，Portal三个模块可以合并一起部署，MySQL单独安装并创建需要的表结构。在生产环境使用Apollo，Portal可以两个节点单独部署，稳定性要求没那么高的话，Config Service和Admin Service可以部署在一起，数据库支持主备容灾。</p><h4 id="Nacos-1"><a href="#Nacos-1" class="headerlink" title="Nacos"></a>Nacos</h4><p>Nacos部署需要Nacos Service和MySQL：</p><ul><li>Nacos对外提供服务，支持配置管理和服务发现;</li><li>MySQL提供Nacos的数据持久化存储;</li></ul><p>单机模式下，Nacos可以使用嵌入式数据库部署一个节点，就能启动。</p><h4 id="整体来看"><a href="#整体来看" class="headerlink" title="整体来看"></a>整体来看</h4><p>Nacos的部署结构比较简单，运维成本较低。Apollo部署组件较多，运维成本比Nacos高。Spring Cloud Config生产高可用的成本最高。</p><h4 id="多语言支持的对比"><a href="#多语言支持的对比" class="headerlink" title="多语言支持的对比"></a>多语言支持的对比</h4><p>一个公司的各个系统可能语言不尽相同，现在使用的比较多的比如C++，Java，PHP，Python，Nodejs，还有Go等。引入配置中心之后，配置中心要想让多语言的系统都能享受到动态配置的能力，需要支持多语言生态。</p><h4 id="多语言支持"><a href="#多语言支持" class="headerlink" title="多语言支持"></a>多语言支持</h4><p>Spring Cloud服务于Java生态，一开始只是针对Java微服务应用，对于非Java应用的微服务调用，可以使用Sidecar提供了HTTP API，但动态配置方面还不能很好的支持。</p><p>Apollo已经支持了多种语言，并且提供了open API。其他不支持的语言，Apollo的接入成本相对较低。</p><p><a href="http://mp.weixin.qq.com/s?__biz=MzI3ODcxMzQzMw==&mid=2247488083&idx=1&sn=75cbbb39c04510953e9d7b0eb8e43147&chksm=eb539765dc241e73849c188fd51761aeb09b2ea9b1f3919313659476bf5a92a764bd42828b73&scene=21#wechat_redirect" target="_blank" rel="noopener">Nacos</a>支持主流的语言，例如Java、Go、Python、Nodejs、PHP等，也提供了open API。</p><h4 id="迁移支持"><a href="#迁移支持" class="headerlink" title="迁移支持"></a>迁移支持</h4><p>国内主流的互联网公司仍是以Java为主，除了原生Java SDK，在对整个Java生态，比如Spring Boot和Spring Cloud的支持上，三个产品都是支持的。</p><p>Spring Cloud Config原生就支持Spring Boot和Spring Cloud，Nacos通过Spring Cloud for Alibaba支持Spring Boot和Spring Cloud生态，符合Spring生态中的标准实现方式，可以无缝从Spring Cloud Conig迁移到Nacos。</p><p>Apollo支持Spring Boot和Spring Cloud项目，但是实现方式不同于标准，无法做无缝迁移，从Spring Cloud迁移到Apollo，存在代码改造和兼容性成本。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>总的来说，Apollo和Nacos相对于Spring Cloud Config的生态支持更广，在配置管理流程上做的更好。Apollo相对于Nacos在配置管理做的更加全面。Nacos使用起来相对比较简洁，在对性能要求比较高的大规模场景更适合。此外，Nacos除了提供配置中心的功能，还提供了动态服务发现、服务共享与管理的功能，降低了服务化改造过程中的难度。但Nacos开源不久，还有一定的局限性，如权限管理，灰度等等。所以下篇文章详细介绍apollo的搭建过程。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;为什么需配置中心&quot;&gt;&lt;a href=&quot;#为什么需配置中心&quot; class=&quot;headerlink&quot; title=&quot;为什么需配置中心&quot;&gt;&lt;/a&gt;为什么需配置中心&lt;/h2&gt;&lt;h4 id=&quot;配置实时生效&quot;&gt;&lt;a href=&quot;#配置实时生效&quot; class=&quot;headerlink&quot; title=&quot;配置实时生效&quot;&gt;&lt;/a&gt;配置实时生效&lt;/h4&gt;&lt;p&gt;传统的静态配置方式要想修改某个配置只能修改之后重新发布应用。如要实现动态性，可以选择使用数据库，通过定时轮询访问数据库来感知配置的变化。但是轮询频率低，感知配置变化的延时就长，轮询频率高，感知配置变化的延时就短，但又比较损耗性能，所以需要在实时性和性能之间做折中。而配置中心专门针对这个业务场景，兼顾实时性和一致性来管理动态配置。&lt;/p&gt;
&lt;h4 id=&quot;配置管理流程&quot;&gt;&lt;a href=&quot;#配置管理流程&quot; class=&quot;headerlink&quot; title=&quot;配置管理流程&quot;&gt;&lt;/a&gt;配置管理流程&lt;/h4&gt;&lt;p&gt;配置的权限管控、灰度发布、版本管理、格式检验和安全配置等一系列的配置管理相关的特性也是配置中心不可获取的一部分。&lt;/p&gt;
&lt;h4 id=&quot;运维需求&quot;&gt;&lt;a href=&quot;#运维需求&quot; class=&quot;headerlink&quot; title=&quot;运维需求&quot;&gt;&lt;/a&gt;运维需求&lt;/h4&gt;&lt;p&gt;随着程序功能的日益复杂，程序的配置日益增多：各种功能的开关、参数的配置、服务器的地址等等。对程序配置的期望值也越来越高：配置修改后实时生效，分环境、分集群管理配置，代码安全、审核机制等等。在这样的大环境下，传统的通过配置文件、数据库等方式已经越来越无法满足开发人员对配置管理的需求。所以，配置中心应运而生。&lt;/p&gt;
&lt;h2 id=&quot;开源配置中心比较&quot;&gt;&lt;a href=&quot;#开源配置中心比较&quot; class=&quot;headerlink&quot; title=&quot;开源配置中心比较&quot;&gt;&lt;/a&gt;开源配置中心比较&lt;/h2&gt;&lt;p&gt;目前市面上用的比较多的配置中心有：（按开源时间排序）&lt;/p&gt;
&lt;h4 id=&quot;Disconf&quot;&gt;&lt;a href=&quot;#Disconf&quot; class=&quot;headerlink&quot; title=&quot;Disconf&quot;&gt;&lt;/a&gt;Disconf&lt;/h4&gt;&lt;p&gt;2014年7月百度开源的配置管理中心，同样具备配置的管理能力，不过目前已经不维护了，最近的一次提交是两年前了。&lt;/p&gt;
&lt;h4 id=&quot;Spring-Cloud-Config&quot;&gt;&lt;a href=&quot;#Spring-Cloud-Config&quot; class=&quot;headerlink&quot; title=&quot;Spring Cloud Config&quot;&gt;&lt;/a&gt;Spring Cloud Config&lt;/h4&gt;&lt;p&gt;2014年9月开源，Spring Cloud 生态组件，可以和Spring Cloud体系无缝整合。&lt;/p&gt;
&lt;h4 id=&quot;Apollo&quot;&gt;&lt;a href=&quot;#Apollo&quot; class=&quot;headerlink&quot; title=&quot;Apollo&quot;&gt;&lt;/a&gt;Apollo&lt;/h4&gt;&lt;p&gt;2016年5月，携程开源的配置管理中心，具备规范的权限、流程治理等特性。&lt;/p&gt;
&lt;h4 id=&quot;Nacos&quot;&gt;&lt;a href=&quot;#Nacos&quot; class=&quot;headerlink&quot; title=&quot;Nacos&quot;&gt;&lt;/a&gt;Nacos&lt;/h4&gt;&lt;p&gt;2018年6月，阿里开源的配置中心，也可以做DNS和RPC的服务发现。&lt;/p&gt;
&lt;h2 id=&quot;参考文档&quot;&gt;&lt;a href=&quot;#参考文档&quot; class=&quot;headerlink&quot; title=&quot;参考文档&quot;&gt;&lt;/a&gt;参考文档&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;https://springcloud.cc/spring-cloud-config.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Spring Cloud Config&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/ctripcorp/apollo&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Apollo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://nacos.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Nacos&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Apollo" scheme="https://wandouduoduo.netlify.com/tags/Apollo/"/>
    
  </entry>
  
  <entry>
    <title>CentOS7安装GlusterFS集群教程</title>
    <link href="https://wandouduoduo.netlify.com/articles/afd78e52.html"/>
    <id>https://wandouduoduo.netlify.com/articles/afd78e52.html</id>
    <published>2020-04-16T11:12:47.000Z</published>
    <updated>2020-04-19T11:34:47.333Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>通过本文教程，帮助你搭建glusterfs集群共享存储。</p><h2 id="环境说明"><a href="#环境说明" class="headerlink" title="环境说明"></a>环境说明</h2><p>3台机器安装 GlusterFS 组成一个集群。<br>使用 docker volume plugin GlusterFS</p><p>服务器：<br>10.6.0.140<br>10.6.0.192<br>10.6.0.196</p><p>配置 hosts</p><p>10.6.0.140 swarm-manager<br>10.6.0.192 swarm-node-1<br>10.6.0.196 swarm-node-2</p><p>client:<br>10.6.0.94 node-94</p><a id="more"></a><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>CentOS 安装 glusterfs 非常的简单</p><h4 id="安装glusterfs"><a href="#安装glusterfs" class="headerlink" title="安装glusterfs"></a>安装glusterfs</h4><p>在三个节点都执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install centos-release-gluster</span><br><span class="line">yum install -y glusterfs glusterfs-server glusterfs-fuse glusterfs-rdma</span><br></pre></td></tr></table></figure><h4 id="配置-GlusterFS-集群"><a href="#配置-GlusterFS-集群" class="headerlink" title="配置 GlusterFS 集群"></a>配置 GlusterFS 集群</h4><p>启动 glusterFS</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl start glusterd.service</span><br><span class="line">systemctl enable glusterd.service</span><br></pre></td></tr></table></figure><p>在 swarm-manager 节点上配置，将 节点 加入到 集群中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@swarm-manager ~]#gluster peer probe swarm-manager</span><br><span class="line">peer probe: success. Probe on localhost not needed</span><br><span class="line"></span><br><span class="line">[root@swarm-manager ~]#gluster peer probe swarm-node-1</span><br><span class="line">peer probe: success.</span><br><span class="line"></span><br><span class="line">[root@swarm-manager ~]#gluster peer probe swarm-node-2</span><br><span class="line">peer probe: success.</span><br></pre></td></tr></table></figure><h4 id="查看集群状态"><a href="#查看集群状态" class="headerlink" title="查看集群状态"></a><strong>查看集群状态</strong></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@swarm-manager ~]#gluster peer status</span><br><span class="line">Number of Peers: 2</span><br><span class="line"></span><br><span class="line">Hostname: swarm-node-1</span><br><span class="line">Uuid: 41573e8b-eb00-4802-84f0-f923a2c7be79</span><br><span class="line">State: Peer in Cluster (Connected)</span><br><span class="line"></span><br><span class="line">Hostname: swarm-node-2</span><br><span class="line">Uuid: da068e0b-eada-4a50-94ff-623f630986d7</span><br><span class="line">State: Peer in Cluster (Connected)</span><br></pre></td></tr></table></figure><h4 id="创建数据存储目录"><a href="#创建数据存储目录" class="headerlink" title="创建数据存储目录"></a>创建数据存储目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@swarm-manager ~]#mkdir -p /opt/gluster/data</span><br><span class="line">[root@swarm-node-1 ~]# mkdir -p /opt/gluster/data</span><br><span class="line">[root@swarm-node-2 ~]# mkdir -p /opt/gluster/data</span><br></pre></td></tr></table></figure><h4 id="查看volume-状态"><a href="#查看volume-状态" class="headerlink" title="查看volume 状态"></a>查看volume 状态</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@swarm-manager ~]#gluster volume info</span><br><span class="line">No volumes present</span><br></pre></td></tr></table></figure><h4 id="创建GlusterFS磁盘："><a href="#创建GlusterFS磁盘：" class="headerlink" title="创建GlusterFS磁盘："></a>创建GlusterFS磁盘：</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@swarm-manager ~]<span class="comment">#gluster volume create models replica 3 swarm-manager:/opt/gluster/data swarm-node-1:/opt/gluster/data swarm-node-2:/opt/gluster/data force</span></span><br><span class="line">volume create: models: success: please start the volume to access data</span><br></pre></td></tr></table></figure><h2 id="volume-模式说明"><a href="#volume-模式说明" class="headerlink" title="volume 模式说明"></a>volume 模式说明</h2><p>一、 <strong>默认模式</strong>，既DHT, 也叫 分布卷: 将文件已hash算法随机分布到 一台服务器节点中存储。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume create test-volume server1:/exp1 server2:/exp2</span><br></pre></td></tr></table></figure><p><img src="/articles/afd78e52/487774-20160824150913058-603139078.png" alt="img"></p><p>二、 <strong>复制模式</strong>，既AFR, 创建volume 时带 replica x 数量: 将文件复制到 replica x 个节点中。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume create test-volume replica 2 transport tcp server1:/exp1 server2:/exp2</span><br></pre></td></tr></table></figure><p><img src="/articles/afd78e52/487774-20160824150919026-1102278746.png" alt="img"></p><p>三、 <strong>条带模式</strong>，既Striped, 创建volume 时带 stripe x 数量： 将文件切割成数据块，分别存储到 stripe x 个节点中 ( 类似raid 0 )。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume create test-volume stripe 2 transport tcp server1:/exp1 server2:/exp2</span><br></pre></td></tr></table></figure><p><img src="/articles/afd78e52/487774-20160824150925136-1728170659.png" alt="img"></p><p>四、 <strong>分布式条带模式（组合型）</strong>，最少需要4台服务器才能创建。 创建volume 时 stripe 2 server = 4 个节点： 是DHT 与 Striped 的组合型。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume create test-volume stripe 2 transport tcp server1:/exp1 server2:/exp2 server3:/exp3 server4:/exp4</span><br></pre></td></tr></table></figure><p><img src="/articles/afd78e52/487774-20160824150931995-642839940.png" alt="img"></p><p>五、 <strong>分布式复制模式（组合型）</strong>, 最少需要4台服务器才能创建。 创建volume 时 replica 2 server = 4 个节点：是DHT 与 AFR 的组合型。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume create test-volume replica 2 transport tcp server1:/exp1 server2:/exp2　server3:/exp3 server4:/exp4</span><br></pre></td></tr></table></figure><p><img src="/articles/afd78e52/487774-20160824150939886-840830039.png" alt="img"></p><p>六、 <strong>条带复制卷模式（组合型）</strong>, 最少需要4台服务器才能创建。 创建volume 时 stripe 2 replica 2 server = 4 个节点： 是 Striped 与 AFR 的组合型。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume create test-volume stripe 2 replica 2 transport tcp server1:/exp1 server2:/exp2 server3:/exp3 server4:/exp4</span><br></pre></td></tr></table></figure><p><img src="/articles/afd78e52/487774-20160824150948276-1699673130.png" alt="img"></p><p>七、 三种模式混合, 至少需要8台 服务器才能创建。 stripe 2 replica 2 , 每4个节点 组成一个 组。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume create test-volume stripe 2 replica 2 transport tcp server1:/exp1 server2:/exp2 server3:/exp3 server4:/exp4 server5:/exp5 server6:/exp6 server7:/exp7 server8:/exp8</span><br></pre></td></tr></table></figure><p><img src="/articles/afd78e52/E:%5CBlog%5Csunhexo%5Csource_posts%5CCentOS7%E5%AE%89%E8%A3%85GlusterFS%E9%9B%86%E7%BE%A4%E6%95%99%E7%A8%8B%5C487774-20160824150956230-1177006347.png" alt="img"></p><h4 id="查看-volume-状态"><a href="#查看-volume-状态" class="headerlink" title="查看 volume 状态"></a>查看 volume 状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@swarm-manager ~]<span class="comment">#gluster volume info</span></span><br><span class="line"></span><br><span class="line">Volume Name: models</span><br><span class="line">Type: Replicate</span><br><span class="line">Volume ID: e539ff3b-2278-4f3f-a594-1f101eabbf1e</span><br><span class="line">Status: Created</span><br><span class="line">Number of Bricks: 1 x 3 = 3</span><br><span class="line">Transport-type: tcp</span><br><span class="line">Bricks:</span><br><span class="line">Brick1: swarm-manager:/opt/gluster/data</span><br><span class="line">Brick2: swarm-node-1:/opt/gluster/data</span><br><span class="line">Brick3: swarm-node-2:/opt/gluster/data</span><br><span class="line">Options Reconfigured:</span><br><span class="line">performance.readdir-ahead: on</span><br></pre></td></tr></table></figure><h4 id="启动-models"><a href="#启动-models" class="headerlink" title="启动 models"></a>启动 models</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@swarm-manager ~]#gluster volume start models</span><br><span class="line">volume start: models: success</span><br></pre></td></tr></table></figure><h2 id="gluster-性能调优"><a href="#gluster-性能调优" class="headerlink" title="gluster 性能调优"></a>gluster 性能调优</h2><p>开启 指定 volume 的配额： (models 为 volume 名称)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume quota models enable</span><br></pre></td></tr></table></figure><p>限制 models 中 / (既总目录) 最大使用 80GB 空间</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume quota models limit-usage / 80GB</span><br></pre></td></tr></table></figure><p>#设置 cache 4GB</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume set models performance.cache-size 4GB</span><br></pre></td></tr></table></figure><p>#开启 异步 ， 后台操作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume set models performance.flush-behind on</span><br></pre></td></tr></table></figure><p>#设置 io 线程 32</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume set models performance.io-thread-count 32</span><br></pre></td></tr></table></figure><p>#设置 回写 (写数据时间，先写入缓存内，再写入硬盘)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume set models performance.write-behind on</span><br></pre></td></tr></table></figure><h2 id="部署GlusterFS客户端"><a href="#部署GlusterFS客户端" class="headerlink" title="部署GlusterFS客户端"></a>部署GlusterFS客户端</h2><p>mount GlusterFS文件系统 (客户端必须加入 glusterfs hosts 否则报错。)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@node-94 ~]#yum install -y glusterfs glusterfs-fuse</span><br><span class="line">[root@node-94 ~]#mkdir -p /opt/gfsmnt</span><br><span class="line">[root@node-94 ~]#mount -t glusterfs swarm-manager:models /opt/gfsmnt/</span><br><span class="line"></span><br><span class="line">[root@node-94 ~]#df -h</span><br><span class="line">文件系统 容量 已用 可用 已用% 挂载点</span><br><span class="line">/dev/mapper/vg001-root 98G 1.2G 97G 2% /</span><br><span class="line">devtmpfs 32G 0 32G 0% /dev</span><br><span class="line">tmpfs 32G 0 32G 0% /dev/shm</span><br><span class="line">tmpfs 32G 130M 32G 1% /run</span><br><span class="line">tmpfs 32G 0 32G 0% /sys/fs/cgroup</span><br><span class="line">/dev/mapper/vg001-opt 441G 71G 370G 17% /opt</span><br><span class="line">/dev/sda2 497M 153M 344M 31% /boot</span><br><span class="line">tmpfs 6.3G 0 6.3G 0% /run/user/0</span><br><span class="line">swarm-manager:models 441G 18G 424G 4% /opt/gfsmnt</span><br></pre></td></tr></table></figure><h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><p>DHT 模式 客户端 创建一个 1G 的文件</p><p>[root@node-94 ~]#time dd if=/dev/zero of=hello bs=1000M count=1<br>记录了1+0 的读入<br>记录了1+0 的写出<br>1048576000字节(1.0 GB)已复制，9.1093 秒，115 MB/秒</p><p>real 0m9.120s<br>user 0m0.000s<br>sys 0m1.134s</p><p>AFR 模式 客户端 创建一个 1G 的文件</p><p>[root@node-94 ~]#time dd if=/dev/zero of=hello.txt bs=1024M count=1<br>录了1+0 的读入<br>记录了1+0 的写出<br>1073741824字节(1.1 GB)已复制，27.4566 秒，39.1 MB/秒</p><p>real 0m27.469s<br>user 0m0.000s<br>sys 0m1.065s</p><p>Striped 模式 客户端 创建一个 1G 的文件</p><p>[root@node-94 ~]#time dd if=/dev/zero of=hello bs=1000M count=1<br>记录了1+0 的读入<br>记录了1+0 的写出<br>1048576000字节(1.0 GB)已复制，9.10669 秒，115 MB/秒</p><p>real 0m9.119s<br>user 0m0.001s<br>sys 0m0.953s</p><p>条带复制卷模式 (Number of Bricks: 1 x 2 x 2 = 4) 客户端 创建一个 1G 的文件</p><p>[root@node-94 ~]#time dd if=/dev/zero of=hello bs=1000M count=1<br>记录了1+0 的读入<br>记录了1+0 的写出<br>1048576000字节(1.0 GB)已复制，17.965 秒，58.4 MB/秒</p><p>real 0m17.978s<br>user 0m0.000s<br>sys 0m0.970s</p><p>分布式复制模式 (Number of Bricks: 2 x 2 = 4) 客户端 创建一个 1G 的文件</p><p>[root@node-94 ~]#time dd if=/dev/zero of=haha bs=100M count=10<br>记录了10+0 的读入<br>记录了10+0 的写出<br>1048576000字节(1.0 GB)已复制，17.7697 秒，59.0 MB/秒</p><p>real 0m17.778s<br>user 0m0.001s<br>sys 0m0.886s</p><p>针对 分布式复制模式还做了如下测试：</p><p>4K随机写 测试:<br>安装 fio (yum -y install libaio-devel (否则运行fio 会报错engine libaio not loadable, 已安装需重新编译，否则一样报错))</p><p>[root@node-94 ~]#fio -ioengine=libaio -bs=4k -direct=1 -thread -rw=randwrite -size=10G -filename=1.txt -name=”EBS 4KB randwrite test” -iodepth=32 -runtime=60</p><p>write: io=352204KB, bw=5869.9KB/s, iops=1467, runt= 60002msec<br>WRITE: io=352204KB, aggrb=5869KB/s, minb=5869KB/s, maxb=5869KB/s, mint=60002msec, maxt=60002msec</p><p>4K随机读 测试：<br>fio -ioengine=libaio -bs=4k -direct=1 -thread -rw=randread -size=10G -filename=1.txt -name=”EBS 4KB randread test” -iodepth=8 -runtime=60</p><p>read: io=881524KB, bw=14692KB/s, iops=3672, runt= 60001msec<br>READ: io=881524KB, aggrb=14691KB/s, minb=14691KB/s, maxb=14691KB/s, mint=60001msec, maxt=60001msec</p><p>512K 顺序写 测试：<br>fio -ioengine=libaio -bs=512k -direct=1 -thread -rw=write -size=10G -filename=512.txt -name=”EBS 512KB seqwrite test” -iodepth=64 -runtime=60</p><p>write: io=3544.0MB, bw=60348KB/s, iops=117, runt= 60135msec<br>WRITE: io=3544.0MB, aggrb=60348KB/s, minb=60348KB/s, maxb=60348KB/s, mint=60135msec, maxt=60135msec</p><h2 id="其他的维护命令："><a href="#其他的维护命令：" class="headerlink" title="其他的维护命令："></a>其他的维护命令：</h2><p>\1. 查看GlusterFS中所有的volume:<br>[root@swarm-manager ~]#gluster volume list</p><p>\2. 删除GlusterFS磁盘：<br>[root@swarm-manager ~]#gluster volume stop models #停止名字为 models 的磁盘<br>[root@swarm-manager ~]#gluster volume delete models #删除名字为 models 的磁盘</p><p>注： 删除 磁盘 以后，必须删除 磁盘( /opt/gluster/data ) 中的 （ .glusterfs/ .trashcan/ ）目录。<br>否则创建新 volume 相同的 磁盘 会出现文件 不分布，或者 类型 错乱 的问题。</p><p>\3. 卸载某个节点GlusterFS磁盘<br>[root@swarm-manager ~]#gluster peer detach swarm-node-2</p><p>\4. 设置访问限制,按照每个volume 来限制<br>[root@swarm-manager ~]#gluster volume set models auth.allow 10.6.0.<em>,10.7.0.</em></p><p>\5. 添加GlusterFS节点：<br>[root@swarm-manager ~]#gluster peer probe swarm-node-3<br>[root@swarm-manager ~]#gluster volume add-brick models swarm-node-3:/opt/gluster/data<br>注：如果是复制卷或者条带卷，则每次添加的Brick数必须是replica或者stripe的整数倍</p><p>\6. 配置卷<br>[root@swarm-manager ~]# gluster volume set</p><p>\7. 缩容volume:</p><p>先将数据迁移到其它可用的Brick，迁移结束后才将该Brick移除：<br>[root@swarm-manager ~]#gluster volume remove-brick models swarm-node-2:/opt/gluster/data swarm-node-3:/opt/gluster/data start</p><p>在执行了start之后，可以使用status命令查看移除进度：<br>[root@swarm-manager ~]#gluster volume remove-brick models swarm-node-2:/opt/gluster/data swarm-node-3:/opt/gluster/data status</p><p>不进行数据迁移，直接删除该Brick：<br>[root@swarm-manager ~]#gluster volume remove-brick models swarm-node-2:/opt/gluster/data swarm-node-3:/opt/gluster/data commit<br>注意，如果是复制卷或者条带卷，则每次移除的Brick数必须是replica或者stripe的整数倍。</p><p>扩容：</p><p>gluster volume add-brick models swarm-node-2:/opt/gluster/data </p><p>\8. 修复命令:<br>[root@swarm-manager ~]#gluster volume replace-brick models swarm-node-2:/opt/gluster/data swarm-node-3:/opt/gluster/data commit -force</p><p>\9. 迁移volume:<br>[root@swarm-manager ~]#gluster volume replace-brick models swarm-node-2:/opt/gluster/data swarm-node-3:/opt/gluster/data start<br>pause 为暂停迁移<br>[root@swarm-manager ~]#gluster volume replace-brick models swarm-node-2:/opt/gluster/data swarm-node-3:/opt/gluster/data pause<br>abort 为终止迁移<br>[root@swarm-manager ~]#gluster volume replace-brick models swarm-node-2:/opt/gluster/data swarm-node-3:/opt/gluster/data abort<br>status 查看迁移状态<br>[root@swarm-manager ~]#gluster volume replace-brick models swarm-node-2:/opt/gluster/data swarm-node-3:/opt/gluster/data status<br>迁移结束后使用commit 来生效<br>[root@swarm-manager ~]#gluster volume replace-brick models swarm-node-2:/opt/gluster/data swarm-node-3:/opt/gluster/data commit</p><p>\10. 均衡volume:<br>[root@swarm-manager ~]#gluster volume models lay-outstart<br>[root@swarm-manager ~]#gluster volume models start<br>[root@swarm-manager ~]#gluster volume models startforce<br>[root@swarm-manager ~]#gluster volume models status<br>[root@swarm-manager ~]#gluster volume models stop</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;通过本文教程，帮助你搭建glusterfs集群共享存储。&lt;/p&gt;
&lt;h2 id=&quot;环境说明&quot;&gt;&lt;a href=&quot;#环境说明&quot; class=&quot;headerlink&quot; title=&quot;环境说明&quot;&gt;&lt;/a&gt;环境说明&lt;/h2&gt;&lt;p&gt;3台机器安装 GlusterFS 组成一个集群。&lt;br&gt;使用 docker volume plugin GlusterFS&lt;/p&gt;
&lt;p&gt;服务器：&lt;br&gt;10.6.0.140&lt;br&gt;10.6.0.192&lt;br&gt;10.6.0.196&lt;/p&gt;
&lt;p&gt;配置 hosts&lt;/p&gt;
&lt;p&gt;10.6.0.140 swarm-manager&lt;br&gt;10.6.0.192 swarm-node-1&lt;br&gt;10.6.0.196 swarm-node-2&lt;/p&gt;
&lt;p&gt;client:&lt;br&gt;10.6.0.94 node-94&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.netlify.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="GlusterFS" scheme="https://wandouduoduo.netlify.com/tags/GlusterFS/"/>
    
  </entry>
  
  <entry>
    <title>Centos7搭建神器openvpn</title>
    <link href="https://wandouduoduo.netlify.com/articles/decac6ef.html"/>
    <id>https://wandouduoduo.netlify.com/articles/decac6ef.html</id>
    <published>2020-02-12T02:07:14.000Z</published>
    <updated>2020-05-14T10:49:38.268Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>OpenVPN是一个开源的应用程序，它允许您通过公共互联网创建一个安全的专用网络。OpenVPN实现一个虚拟专用网（VPN）来创建一个安全连接。OpenVPN使用OpenSSL库提供加密，它提供了几种身份验证机制，如基于证书的、预共享密钥和用户名/密码身份验证。本文详细介绍了OpenVPN搭建过程，并利用pam_sqlite3插件实现用户认证；通过openvpn_web进行用户管理与日志系统。</p><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a><strong>环境</strong></h2><p>服务端：CentOS7.x</p><p>客户端：Windows10</p><a id="more"></a><h2 id="服务端安装"><a href="#服务端安装" class="headerlink" title="服务端安装"></a>服务端安装</h2><h4 id="安装openvpn"><a href="#安装openvpn" class="headerlink" title="安装openvpn"></a>安装openvpn</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#临时关闭selinux</span></span><br><span class="line">setenforce 0</span><br><span class="line"><span class="comment">#配置文件永久关闭 修改/etc/selinux/config 文件</span></span><br><span class="line">SELINUX=disabled</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加epel yum源</span></span><br><span class="line">wget -O /etc/yum.repos.d/epel-7.repo http://mirrors.aliyun.com/repo/epel-7.repo</span><br><span class="line"></span><br><span class="line"><span class="comment">#yum安装包</span></span><br><span class="line">yum install openvpn -y</span><br></pre></td></tr></table></figure><h4 id="配置EasyRSA"><a href="#配置EasyRSA" class="headerlink" title="配置EasyRSA"></a><strong>配置EasyRSA</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#下载EasyRSA 3.0.7</span></span><br><span class="line"><span class="built_in">cd</span> /opt/</span><br><span class="line">wget https://github.com/OpenVPN/easy-rsa/releases/download/v3.0.7/EasyRSA-3.0.7.tgz</span><br><span class="line">tar xf EasyRSA-3.0.7.tgz</span><br><span class="line">cp -r easyRSA-3.0.7/ /etc/openvpn/easy-rsa3</span><br><span class="line">cp /etc/openvpn/easy-rsa3/vars.example /etc/openvpn/easy-rsa3/vars</span><br></pre></td></tr></table></figure><h4 id="创建相关证书和秘钥"><a href="#创建相关证书和秘钥" class="headerlink" title="创建相关证书和秘钥"></a><strong>创建相关证书和秘钥</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/openvpn/easy-rsa3/</span><br><span class="line"></span><br><span class="line"><span class="comment">#初始化目录</span></span><br><span class="line">./easyrsa init-pki</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建根证书</span></span><br><span class="line"><span class="comment">#nopass 参数表示不加密；也可以不加此参数，那就需要输入密码短语</span></span><br><span class="line">./easyrsa build-ca nopass</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建服务端秘钥</span></span><br><span class="line">./easyrsa gen-req server nopass</span><br></pre></td></tr></table></figure><p><img src="/articles/decac6ef/1.png" alt></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#给服务端证书签名，这里要输入yes才能完成</span></span><br><span class="line">./easyrsa sign-req server server</span><br><span class="line"></span><br><span class="line"><span class="comment">##创建客户端秘钥</span></span><br><span class="line">./easyrsa gen-req client nopass</span><br></pre></td></tr></table></figure><p><img src="/articles/decac6ef/2.png" alt></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#给客户端证书签名，这里要输入yes才能完成</span></span><br><span class="line">./easyrsa sign-req client client</span><br></pre></td></tr></table></figure><p><img src="/articles/decac6ef/3.png" alt></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#创建Diffie-Hellman</span></span><br><span class="line">./easyrsa gen-dh</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建TLS认证密钥</span></span><br><span class="line">openvpn --genkey --secret /etc/openvpn/ta.key</span><br></pre></td></tr></table></figure><p><img src="/articles/decac6ef/4.png" alt></p><h4 id="拷贝证书到目录"><a href="#拷贝证书到目录" class="headerlink" title="拷贝证书到目录"></a><strong>拷贝证书到目录</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#目录自定义，配置文件中要用到</span></span><br><span class="line">/etc/openvpn/easy-rsa3/pki/</span><br><span class="line">cp ca.crt dh.pem /etc/openvpn/</span><br><span class="line">cp private/server.key issued/server.crt /etc/openvpn/server/</span><br><span class="line">cp private/client.key issued/client.crt /etc/openvpn/client/</span><br></pre></td></tr></table></figure><h4 id="编辑配置文件"><a href="#编辑配置文件" class="headerlink" title="编辑配置文件"></a><strong>编辑配置文件</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /etc/openvpn/</span><br><span class="line"></span><br><span class="line">cp /usr/share/doc/openvpn-2.4.8/sample/sample-config-files/server.conf ./</span><br><span class="line"></span><br><span class="line">vim server.conf</span><br><span class="line"></span><br><span class="line"><span class="comment">#监听本机ip地址</span></span><br><span class="line"><span class="built_in">local</span> 0.0.0.0</span><br><span class="line"><span class="comment">#监控本机端口号</span></span><br><span class="line">port 1194</span><br><span class="line"><span class="comment">#指定采用的传输协议，可以选择tcp或udp</span></span><br><span class="line">proto tcp</span><br><span class="line"><span class="comment">#指定创建的通信隧道类型，可选tun或tap</span></span><br><span class="line">dev tun</span><br><span class="line"><span class="comment">#指定CA证书的文件路径</span></span><br><span class="line">ca /etc/openvpn/ca.crt</span><br><span class="line"><span class="comment">#指定服务器端的证书文件路径</span></span><br><span class="line">cert /etc/openvpn/server/server.crt</span><br><span class="line"><span class="comment">#指定服务器端的私钥文件路径</span></span><br><span class="line">key /etc/openvpn/server/server.key</span><br><span class="line"><span class="comment">#指定迪菲赫尔曼参数的文件路径</span></span><br><span class="line">dh /etc/openvpn/dh.pem</span><br><span class="line"><span class="comment">#指定虚拟局域网占用的IP地址段和子网掩码，此处配置的服务器自身占用.1的ip地址</span></span><br><span class="line">server 10.8.0.0 255.255.255.0</span><br><span class="line"><span class="comment">#服务器自动给客户端分配IP后，客户端下次连接时，仍然采用上次的IP地址(第一次分配的IP保存在ipp.txt中，下一次分配其中保存的IP)。</span></span><br><span class="line">ifconfig-pool-persist ipp.txt</span><br><span class="line"><span class="comment">#自动推送客户端上的网关及DHCP</span></span><br><span class="line">push <span class="string">"redirect-gateway def1 bypass-dhcp"</span></span><br><span class="line"><span class="comment">#OpenVPN的DHCP功能为客户端提供指定的 DNS、WINS 等</span></span><br><span class="line">push <span class="string">"dhcp-option DNS 114.114.114.114"</span></span><br><span class="line"><span class="comment">#允许客户端与客户端相连接，默认情况下客户端只能与服务器相连接</span></span><br><span class="line">client-to-client</span><br><span class="line"><span class="comment">#每10秒ping一次，连接超时时间设为120秒</span></span><br><span class="line">keepalive 10 120</span><br><span class="line"><span class="comment">#开启TLS-auth，使用ta.key防御攻击。服务器端的第二个参数值为0，客户端的为1。</span></span><br><span class="line">tls-auth /etc/openvpn/ta.key 0</span><br><span class="line"><span class="comment">#加密认证算法</span></span><br><span class="line">cipher AES-256-CBC</span><br><span class="line"><span class="comment">#使用lzo压缩的通讯,服务端和客户端都必须配置</span></span><br><span class="line">comp-lzo</span><br><span class="line"><span class="comment">#最大连接用户</span></span><br><span class="line">max-clients 100 </span><br><span class="line"><span class="comment">#定义运行的用户和组</span></span><br><span class="line">user openvpn</span><br><span class="line">group openvpn</span><br><span class="line"><span class="comment">#重启时仍保留一些状态</span></span><br><span class="line">persist-key</span><br><span class="line">persist-tun</span><br><span class="line"><span class="comment">#输出短日志,每分钟刷新一次,以显示当前的客户端</span></span><br><span class="line">status /var/<span class="built_in">log</span>/openvpn-status.log</span><br><span class="line"><span class="comment">#日志保存路径</span></span><br><span class="line"><span class="built_in">log</span>         /var/<span class="built_in">log</span>/openvpn.log</span><br><span class="line"><span class="built_in">log</span>-append  /var/<span class="built_in">log</span>/openvpn.log</span><br><span class="line"><span class="comment">#指定日志文件的记录详细级别，可选0-9，等级越高日志内容越详细</span></span><br><span class="line">verb 4</span><br><span class="line"><span class="comment">#相同信息的数量，如果连续出现 20 条相同的信息，将不记录到日志中</span></span><br><span class="line">mute 20</span><br></pre></td></tr></table></figure><h4 id="配置系统转发和开放端口，云服务器记得安全组要开放对应端口"><a href="#配置系统转发和开放端口，云服务器记得安全组要开放对应端口" class="headerlink" title="配置系统转发和开放端口，云服务器记得安全组要开放对应端口"></a><strong>配置系统转发和开放端口，云服务器记得安全组要开放对应端口</strong></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">修改文件目录权限</span></span><br><span class="line">chown root.openvpn /etc/openvpn/* -R</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">/etc/sysctl.conf 配置文件中添加</span></span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">生效</span></span><br><span class="line">sysctl -p </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">iptables</span></span><br><span class="line">iptables -t nat -A POSTROUTING -s 10.8.0.0/24 -o eth0 -j MASQUERADE</span><br><span class="line">iptables -I INPUT -p tcp --dport 1194 -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">保存规则并重启</span></span><br><span class="line">service iptables save</span><br><span class="line">systemctl restart iptables</span><br></pre></td></tr></table></figure><h4 id="启动openvpn服务"><a href="#启动openvpn服务" class="headerlink" title="启动openvpn服务"></a><strong>启动openvpn服务</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#启动openvpn服务</span></span><br><span class="line">systemctl start openvpn@server</span><br><span class="line"></span><br><span class="line"><span class="comment">#确认服务进程是否存在</span></span><br><span class="line">netstat -nap|grep openvpn</span><br><span class="line">ps -ef|grep openvpn</span><br></pre></td></tr></table></figure><p><img src="/articles/decac6ef/5.png" alt></p><h2 id="win10客户端连接测试"><a href="#win10客户端连接测试" class="headerlink" title="win10客户端连接测试"></a><strong>win10客户端连接测试</strong></h2><h4 id="下载客户端"><a href="#下载客户端" class="headerlink" title="下载客户端:"></a><strong>下载客户端:</strong></h4><p> <a href="https://ossjc-1252545319.cos.ap-shanghai.myqcloud.com/other/Software/openvpn/openvpn-install-2.4.8-I602-Win10.exe" target="_blank" rel="noopener">openvpn-install-2.4.8-I602-Win10.exe</a></p><h4 id="证书配置"><a href="#证书配置" class="headerlink" title="证书配置"></a><strong>证书配置</strong></h4><p>把ca.crt、client.crt、client.key、ta.key 4个文件放到软件安装目录下\OpenVPN\config</p><h4 id="编辑配置文件-1"><a href="#编辑配置文件-1" class="headerlink" title="编辑配置文件"></a>编辑配置文件</h4><p>新建文件client.ovpn,把下面的参数粘贴到里面</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#客户端配置文件</span></span><br><span class="line">client</span><br><span class="line">dev tun</span><br><span class="line">proto tcp</span><br><span class="line">remote 你的服务器ip/域名 1194</span><br><span class="line">resolv-retry infinite</span><br><span class="line">nobind</span><br><span class="line">persist-key</span><br><span class="line">persist-tun</span><br><span class="line">ca ca.crt</span><br><span class="line">cert client.crt</span><br><span class="line">key client.key</span><br><span class="line">ns-cert-type server</span><br><span class="line">tls-auth ta.key 1</span><br><span class="line">cipher AES-256-CBC</span><br><span class="line">auth-nocache</span><br><span class="line">verb 4</span><br><span class="line">comp-lzo</span><br></pre></td></tr></table></figure><h4 id="启动OpenVPN-GUI软件"><a href="#启动OpenVPN-GUI软件" class="headerlink" title="启动OpenVPN GUI软件"></a><strong>启动OpenVPN GUI软件</strong></h4><p><img src="/articles/decac6ef/6.png" alt></p><p><img src="/articles/decac6ef/7.png" alt></p><h4 id="连通性和上网测试"><a href="#连通性和上网测试" class="headerlink" title="连通性和上网测试"></a><strong>连通性和上网测试</strong></h4><p><img src="/articles/decac6ef/8.png" alt></p><p><img src="/articles/decac6ef/9.png" alt></p><h2 id="密码认证"><a href="#密码认证" class="headerlink" title="密码认证"></a>密码认证</h2><p><strong>基于证书的认证方式已经完成了，但是有些老铁想要用用户名和密码来认证，那要怎么做呢？下面介绍基于用户密码的认证方式</strong></p><p><strong>在证书认证的基础上修改openvpn配置</strong></p><h4 id="修改服务端-server-conf配置文件"><a href="#修改服务端-server-conf配置文件" class="headerlink" title="修改服务端 server.conf配置文件"></a><strong>修改服务端 server.conf配置文件</strong></h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">添加几个参数</span></span><br><span class="line"><span class="meta">#</span><span class="bash">客户端不进行证书认证，如果不加将实现证书和用户密码双重认证</span></span><br><span class="line">client-cert-not-required</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">用户和密码验证脚本</span></span><br><span class="line">auth-user-pass-verify /etc/openvpn/checkpsw.sh via-env</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">使用用户名密码登录认证</span></span><br><span class="line">username-as-common-name</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">脚本安全级别</span></span><br><span class="line">script-security 3</span><br></pre></td></tr></table></figure><h4 id="创建脚本和用户密码文件"><a href="#创建脚本和用户密码文件" class="headerlink" title="创建脚本和用户密码文件"></a><strong>创建脚本和用户密码文件</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#脚本</span></span><br><span class="line">vim /etc/openvpn/checkpsw.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">###########################################################</span></span><br><span class="line"><span class="comment"># checkpsw.sh (C) 2004 Mathias Sundman &lt;mathias@openvpn.se&gt;</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># This script will authenticate OpenVPN users against</span></span><br><span class="line"><span class="comment"># a plain text file. The passfile should simply contain</span></span><br><span class="line"><span class="comment"># one row per user with the username first followed by</span></span><br><span class="line"><span class="comment"># one or more space(s) or tab(s) and then the password.</span></span><br><span class="line"></span><br><span class="line">PASSFILE=<span class="string">"/etc/openvpn/psw-file"</span></span><br><span class="line">LOG_FILE=<span class="string">"/var/log/openvpn-password.log"</span></span><br><span class="line">TIME_STAMP=`date <span class="string">"+%Y-%m-%d %T"</span>`</span><br><span class="line"></span><br><span class="line"><span class="comment">###########################################################</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ ! -r <span class="string">"<span class="variable">$&#123;PASSFILE&#125;</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"<span class="variable">$&#123;TIME_STAMP&#125;</span>: Could not open password file \"<span class="variable">$&#123;PASSFILE&#125;</span>\" for reading."</span> &gt;&gt;  <span class="variable">$&#123;LOG_FILE&#125;</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">CORRECT_PASSWORD=`awk <span class="string">'!/^;/&amp;&amp;!/^#/&amp;&amp;$1=="'</span><span class="variable">$&#123;username&#125;</span><span class="string">'"&#123;print $2;exit&#125;'</span> <span class="variable">$&#123;PASSFILE&#125;</span>`</span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$&#123;CORRECT_PASSWORD&#125;</span>"</span> = <span class="string">""</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"<span class="variable">$&#123;TIME_STAMP&#125;</span>: User does not exist: username=\"<span class="variable">$&#123;username&#125;</span>\", password=\"<span class="variable">$&#123;password&#125;</span>\"."</span> &gt;&gt; <span class="variable">$&#123;LOG_FILE&#125;</span></span><br><span class="line">    <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="string">"<span class="variable">$&#123;password&#125;</span>"</span> = <span class="string">"<span class="variable">$&#123;CORRECT_PASSWORD&#125;</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"<span class="variable">$&#123;TIME_STAMP&#125;</span>: Successful authentication: username=\"<span class="variable">$&#123;username&#125;</span>\"."</span> &gt;&gt; <span class="variable">$&#123;LOG_FILE&#125;</span></span><br><span class="line">    <span class="built_in">exit</span> 0</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$&#123;TIME_STAMP&#125;</span>: Incorrect password: username=\"<span class="variable">$&#123;username&#125;</span>\", password=\"<span class="variable">$&#123;password&#125;</span>\"."</span> &gt;&gt; <span class="variable">$&#123;LOG_FILE&#125;</span></span><br><span class="line"><span class="built_in">exit</span> 1</span><br><span class="line"></span><br><span class="line"><span class="comment">#增加执行权限</span></span><br><span class="line">chmod +x /etc/openvpn/checkpsw.sh</span><br><span class="line"></span><br><span class="line"><span class="comment">#用户密码文件，格式：一行对应一个用户</span></span><br><span class="line">vim psw-file</span><br><span class="line">wandou  123456</span><br><span class="line">duoduo  456789</span><br><span class="line"></span><br><span class="line"><span class="comment">#修改权限</span></span><br><span class="line">chmod 777 psw-file</span><br><span class="line">chown root.openvpn /etc/openvpn/* -R</span><br><span class="line"></span><br><span class="line"><span class="comment">#重启openvpn服务</span></span><br><span class="line">systemctl restart openvpn@server</span><br></pre></td></tr></table></figure><h4 id="win10-客户端配置文件修改"><a href="#win10-客户端配置文件修改" class="headerlink" title="win10 客户端配置文件修改"></a><strong>win10 客户端配置文件修改</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#注释掉</span></span><br><span class="line">;cert client.crt</span><br><span class="line">;key client.key</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加上</span></span><br><span class="line">auth-user-pass</span><br></pre></td></tr></table></figure><p><img src="/articles/decac6ef/10.png" alt></p><h2 id="管理界面安装-lt-待验证-gt"><a href="#管理界面安装-lt-待验证-gt" class="headerlink" title="管理界面安装&lt;待验证&gt;"></a>管理界面安装&lt;待验证&gt;</h2><h4 id="下载pam-sqlite3并安装"><a href="#下载pam-sqlite3并安装" class="headerlink" title="下载pam_sqlite3并安装"></a>下载pam_sqlite3并安装</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git clone https://gitee.com/lang13002/pam_sqlite3.git</span><br><span class="line">cd pam_sqlite3</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h4 id="添加pam认证文件"><a href="#添加pam认证文件" class="headerlink" title="添加pam认证文件"></a>添加pam认证文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> vim /etc/pam.d/openvpn</span></span><br><span class="line"></span><br><span class="line">auth        required    pam_sqlite3.so db=/etc/openvpn/openvpn.db table=t_user user=username passwd=password expire=expire crypt=1</span><br><span class="line">account     required    pam_sqlite3.so db=/etc/openvpn/openvpn.db table=t_user user=username passwd=password expire=expire crypt=1</span><br></pre></td></tr></table></figure><h4 id="创建sqlite3数据库文件"><a href="#创建sqlite3数据库文件" class="headerlink" title="创建sqlite3数据库文件"></a>创建sqlite3数据库文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> sqlite3 /etc/openvpn/openvpn.db</span></span><br><span class="line"></span><br><span class="line"><span class="meta">sqlite&gt;</span><span class="bash"> create table t_user (</span></span><br><span class="line">     username text not null, </span><br><span class="line">     password text not null, </span><br><span class="line">     active int, </span><br><span class="line">     expire text</span><br><span class="line">);</span><br><span class="line"><span class="meta">sqlite&gt;</span><span class="bash"> .quit</span></span><br></pre></td></tr></table></figure><h4 id="在服务端配置添加认证插件"><a href="#在服务端配置添加认证插件" class="headerlink" title="在服务端配置添加认证插件"></a>在服务端配置添加认证插件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">verify-client-cert none</span><br><span class="line">username-as-common-name</span><br><span class="line">plugin /usr/local/openvpn/lib/openvpn/plugins/openvpn-plugin-auth-pam.so openvpn</span><br></pre></td></tr></table></figure><h4 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip2 install peewee tornado</span><br></pre></td></tr></table></figure><h4 id="下载openvpn-web"><a href="#下载openvpn-web" class="headerlink" title="下载openvpn-web"></a>下载openvpn-web</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://gitee.com/lang13002/openvpn_web.git</span><br></pre></td></tr></table></figure><h4 id="创建相应的数据库表"><a href="#创建相应的数据库表" class="headerlink" title="创建相应的数据库表"></a>创建相应的数据库表</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sqlite3 /etc/openvpn/openvpn.db</span></span><br><span class="line">sqlite&gt; .import openvpn_web/model/openvpn.sql</span><br></pre></td></tr></table></figure><h4 id="OpenVPN运行脚本写日志"><a href="#OpenVPN运行脚本写日志" class="headerlink" title="OpenVPN运行脚本写日志"></a>OpenVPN运行脚本写日志</h4><p> 服务端配置添加运行脚本   </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">script-security 2</span><br><span class="line">client-connect /etc/openvpn/server/connect.py</span><br><span class="line">client-disconnect /etc/openvpn/server/disconnect.py</span><br></pre></td></tr></table></figure><p>connect.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line"></span><br><span class="line">username = os.environ[<span class="string">'common_name'</span>]</span><br><span class="line">trusted_ip = os.environ[<span class="string">'trusted_ip'</span>]</span><br><span class="line">trusted_port = os.environ[<span class="string">'trusted_port'</span>]</span><br><span class="line">local = os.environ[<span class="string">'ifconfig_local'</span>]</span><br><span class="line">remote = os.environ[<span class="string">'ifconfig_pool_remote_ip'</span>]</span><br><span class="line">timeunix= os.environ[<span class="string">'time_unix'</span>]</span><br><span class="line"></span><br><span class="line">logintime = time.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>, time.localtime(time.time()))</span><br><span class="line"></span><br><span class="line">conn = sqlite3.connect(<span class="string">"/etc/openvpn/openvpn.db"</span>)</span><br><span class="line">cursor = conn.cursor()</span><br><span class="line">query = <span class="string">"insert into t_logs(username, timeunix, trusted_ip, trusted_port, local, remote, logintime) values('%s','%s', '%s', '%s', '%s', '%s', '%s')"</span> %  (username, timeunix, trusted_ip, trusted_port, local, remote, logintime)</span><br><span class="line">cursor.execute(query)</span><br><span class="line">conn.commit()</span><br><span class="line">conn.close()</span><br></pre></td></tr></table></figure><p>disconnect.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line"></span><br><span class="line">username = os.environ[<span class="string">'common_name'</span>]</span><br><span class="line">trusted_ip = os.environ[<span class="string">'trusted_ip'</span>]</span><br><span class="line">received = os.environ[<span class="string">'bytes_received'</span>]</span><br><span class="line">sent = os.environ[<span class="string">'bytes_sent'</span>]</span><br><span class="line"></span><br><span class="line">logouttime = time.strftime(<span class="string">"%Y-%m-%d %H:%M:%S"</span>, time.localtime(time.time()))</span><br><span class="line"></span><br><span class="line">conn = sqlite3.connect(<span class="string">"/etc/openvpn/openvpn.db"</span>)</span><br><span class="line">cursor = conn.cursor()</span><br><span class="line">query = <span class="string">"update t_logs set logouttime='%s', received='%s', sent= '%s' where username = '%s' and trusted_ip = '%s'"</span> %  (logouttime, received, sent, username, trusted_ip)</span><br><span class="line">cursor.execute(query)</span><br><span class="line">conn.commit()</span><br><span class="line">conn.close()</span><br></pre></td></tr></table></figure><h4 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python myapp.py</span><br></pre></td></tr></table></figure><h4 id="管理界面"><a href="#管理界面" class="headerlink" title="管理界面"></a>管理界面</h4><p><img src="/articles/decac6ef/162533_61adb798_1097803.png" alt="img"></p><p><img src="/articles/decac6ef/162557_07c99033_1097803.png" alt="img"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;OpenVPN是一个开源的应用程序，它允许您通过公共互联网创建一个安全的专用网络。OpenVPN实现一个虚拟专用网（VPN）来创建一个安全连接。OpenVPN使用OpenSSL库提供加密，它提供了几种身份验证机制，如基于证书的、预共享密钥和用户名/密码身份验证。本文详细介绍了OpenVPN搭建过程，并利用pam_sqlite3插件实现用户认证；通过openvpn_web进行用户管理与日志系统。&lt;/p&gt;
&lt;h2 id=&quot;环境&quot;&gt;&lt;a href=&quot;#环境&quot; class=&quot;headerlink&quot; title=&quot;环境&quot;&gt;&lt;/a&gt;&lt;strong&gt;环境&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;服务端：CentOS7.x&lt;/p&gt;
&lt;p&gt;客户端：Windows10&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Openvpn" scheme="https://wandouduoduo.netlify.com/tags/Openvpn/"/>
    
  </entry>
  
  <entry>
    <title>Hexo增加APlayer播放音乐</title>
    <link href="https://wandouduoduo.netlify.com/articles/4929566e.html"/>
    <id>https://wandouduoduo.netlify.com/articles/4929566e.html</id>
    <published>2020-01-15T09:38:10.000Z</published>
    <updated>2020-01-15T10:26:43.077Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>hexo搭建完静态博客后，有同学只看技术文档比较枯燥，会犯困。那么如果有音乐播放的功能，就可以一遍阅读文章，一边欣赏音乐了，岂不是一件很愉快的事。那么下面就以本站点为例，分享怎么在自己的hexo网站增加音乐播放功能。</p><a id="more"></a><h2 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a>效果图</h2><p>先上张效果图，如果有兴趣再接着往下看。</p><p><img src="/articles/4929566e/1.png" alt></p><h2 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h2><h4 id="播放器安装"><a href="#播放器安装" class="headerlink" title="播放器安装"></a>播放器安装</h4><p><a href="https://github.com/MoePlayer/APlayer" target="_blank" rel="noopener">APlayer</a>，下载github压缩包，解压后把dist文件夹复制到\themes\next\source目录中。</p><p><img src="/articles/4929566e/2.png" alt></p><h4 id="播放列表配置"><a href="#播放列表配置" class="headerlink" title="播放列表配置"></a>播放列表配置</h4><p>在dist目录里，新建music.js文件，并把如下代码粘贴进去。</p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> ap = <span class="keyword">new</span> APlayer(&#123;</span><br><span class="line">    container: <span class="built_in">document</span>.getElementById(<span class="string">'aplayer'</span>),</span><br><span class="line">    fixed: <span class="literal">true</span>,</span><br><span class="line">    autoplay: <span class="literal">false</span>,</span><br><span class="line">    audio: [</span><br><span class="line">  &#123;</span><br><span class="line">        name: <span class="string">"还有多少个十年"</span>,</span><br><span class="line">        artist: <span class="string">'沈宁'</span>,</span><br><span class="line">        url: <span class="string">'http://m10.music.126.net/20200115174104/d1ca54236f9cb5d1b1e618b3063fca0f/ymusic/1266/9dd9/a0a5/ff5eb332cbd8f36891c9a8e0e68e47a1.mp3'</span>,</span><br><span class="line">        cover: <span class="string">'http://p2.music.126.net/W0iLDEeY8bjpYVcNT0Mr2g==/17787899114524329.jpg?param=130y130'</span>,</span><br><span class="line">      &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">        name: <span class="string">'我们的时光'</span>,</span><br><span class="line">        artist: <span class="string">'赵雷'</span>,</span><br><span class="line">        url: <span class="string">'http://m10.music.126.net/20200115175106/6b976e394b71ccde0f2dae06b6c48e75/ymusic/12ca/05c1/e5b7/c58c9f85a602e16983271f86f565f2e4.mp3'</span>,</span><br><span class="line">        cover: <span class="string">'http://p1.music.126.net/PJNV84mjt_mDXEkxtjzB4w==/18957779486268444.jpg?param=130y130'</span>,</span><br><span class="line">      &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">        name: <span class="string">'麻雀'</span>,</span><br><span class="line">        artist: <span class="string">'李荣浩'</span>,</span><br><span class="line">        url: <span class="string">'http://m10.music.126.net/20200115175331/17567a992819334ab2fa2cd84ca03270/ymusic/555b/0f58/0609/b1e0b087cb826dde13b21cbaa504f963.mp3'</span>,</span><br><span class="line">        cover: <span class="string">'http://p2.music.126.net/TzlSVBiNtpRD2b7MT2Hi-w==/109951164527590793.jpg?param=130y130'</span>,</span><br><span class="line">      &#125;  </span><br><span class="line">    ]</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p><img src="/articles/4929566e/3.png" alt></p><h4 id="播放器引入"><a href="#播放器引入" class="headerlink" title="播放器引入"></a>播放器引入</h4><p>播放器和列表准备好后，需要在网站中引入后，才可以正常使用。</p><p>在\themes\next\layout_layout.swig文件中，<body>标签里新增如下代码：</body></p><p><img src="/articles/4929566e/4.png" alt></p><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">  &lt;!-- 加入APlayer音乐播放器 --&gt;</span><br><span class="line">&lt;link rel=<span class="string">"stylesheet"</span> href=<span class="string">"/dist/APlayer.min.css"</span>&gt;</span><br><span class="line">&lt;div id=<span class="string">"aplayer"</span>&gt;<span class="xml"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span></span><br><span class="line">&lt;script type=<span class="string">"text/javascript"</span> src=<span class="string">"/dist/APlayer.min.js"</span>&gt;<span class="xml"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br><span class="line">&lt;script type=<span class="string">"text/javascript"</span> src=<span class="string">"/dist/music.js"</span>&gt;<span class="xml"><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span></span><br></pre></td></tr></table></figure><p><img src="/articles/4929566e/5.png" alt></p><h4 id="部署网站"><a href="#部署网站" class="headerlink" title="部署网站"></a>部署网站</h4><p>播放器加入完成，网站需重新部署</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo cl &amp;&amp; hexo g &amp;&amp; gulp &amp;&amp; hexo d</span><br></pre></td></tr></table></figure><h2 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h2><p>是直接嵌入外链播放器即可，以网易云为例。具体步骤如下：</p><h4 id="生成外链播放器代码"><a href="#生成外链播放器代码" class="headerlink" title="生成外链播放器代码"></a>生成外链播放器代码</h4><p><img src="/articles/4929566e/6.png" alt></p><p><img src="/articles/4929566e/7.png" alt></p><h4 id="嵌入网站"><a href="#嵌入网站" class="headerlink" title="嵌入网站"></a>嵌入网站</h4><p>在themes\next\layout_macro\sidebar.swig文件中找到合适位置，把上面生成的外链播放器代码加入即可。</p><p><img src="/articles/4929566e/8.png" alt></p><h4 id="部署网站-1"><a href="#部署网站-1" class="headerlink" title="部署网站"></a>部署网站</h4><p>播放器加入完成，网站需重新部署</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo cl &amp;&amp; hexo g &amp;&amp; gulp &amp;&amp; hexo d</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>方法一比较自由和可定制化，可以根据自己喜好做各种配置。</p><p>方法二配置比较简单，但现在国内版权意识越来越强，很可能点击生成外链代码时，因为版权原因，生成不了。</p><p><img src="/articles/4929566e/9.png" alt></p><p>所以可以根据自己喜好选择用那种方法。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;hexo搭建完静态博客后，有同学只看技术文档比较枯燥，会犯困。那么如果有音乐播放的功能，就可以一遍阅读文章，一边欣赏音乐了，岂不是一件很愉快的事。那么下面就以本站点为例，分享怎么在自己的hexo网站增加音乐播放功能。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Hexo" scheme="https://wandouduoduo.netlify.com/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>Centos7安装Nginx整合Lua</title>
    <link href="https://wandouduoduo.netlify.com/articles/c745ae1a.html"/>
    <id>https://wandouduoduo.netlify.com/articles/c745ae1a.html</id>
    <published>2020-01-10T06:26:36.000Z</published>
    <updated>2020-01-10T08:02:38.128Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Lua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。现在通常把lua迁入nginx中，根据lua脚本规则，强化nginx的能力。本文介绍在centos7中安装nginx整合lua。</p><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p><strong>centos7</strong></p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h4 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld.service <span class="comment">#停止firewall</span></span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld.service <span class="comment">#禁止firewall开机启动</span></span><br></pre></td></tr></table></figure><h4 id="安装依赖环境"><a href="#安装依赖环境" class="headerlink" title="安装依赖环境"></a>安装依赖环境</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install yum-utils gcc zlib zlib-devel pcre-devel openssl openssl-devel wget</span><br></pre></td></tr></table></figure><h4 id="安装LuaJIT"><a href="#安装LuaJIT" class="headerlink" title="安装LuaJIT"></a>安装LuaJIT</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget http://luajit.org/download/LuaJIT-2.0.2.tar.gz</span><br><span class="line">tar -xvf LuaJIT-2.0.2.tar.gz</span><br><span class="line"><span class="built_in">cd</span> LuaJIT-2.0.2</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><h4 id="安装nginx"><a href="#安装nginx" class="headerlink" title="安装nginx"></a>安装nginx</h4><p><strong>下载ngx_devel_kit、lua-nginx-module、nginx</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/simpl/ngx_devel_kit/archive/v0.3.0.tar.gz</span><br><span class="line">wget https://github.com/openresty/lua-nginx-module/archive/v0.10.9rc7.tar.gz</span><br><span class="line">wget http://nginx.org/download/nginx-1.12.1.tar.gz </span><br><span class="line"><span class="comment">#注意下载后的压缩包没有文件名称，但是根据版本号能区分是哪个文件</span></span><br><span class="line">tar -xvf v0.3.0.tar.gz</span><br><span class="line">tar -xvf v0.10.9rc7.tar.gz</span><br><span class="line">tar -xvf nginx-1.12.1.tar.gz</span><br></pre></td></tr></table></figure><h4 id="编译Nginx"><a href="#编译Nginx" class="headerlink" title="编译Nginx"></a>编译Nginx</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> nginx-1.12.1</span><br><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/nginx --add-module=../ngx_devel_kit-0.3.0 --add-module=../lua-nginx-module-0.10.9rc7  --with-http_ssl_module  --with-http_stub_status_module  --with-http_gzip_static_module</span><br></pre></td></tr></table></figure><h4 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h4 id="启动nginx"><a href="#启动nginx" class="headerlink" title="启动nginx"></a>启动nginx</h4><p>启动时会nginx可能会报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./nginx: error while loading shared libraries: libluajit-5.1.so.2: cannot open shared object file:</span><br></pre></td></tr></table></figure><p>原因是：找不到libluajit-5.1.so.2这个文件</p><p><strong>解决办法</strong></p><p>找到 libluajit-5.1.so.2,libluajit-5.1.so.2.0.2这两个文件复制到 对应的lib下<br>64位是 /usr/lib64<br>32位是 /usr/lib</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">find / -name libluajit-5.1.so.2</span><br></pre></td></tr></table></figure><p><img src="/articles/c745ae1a/1.png" alt></p><p>文件默认是安装在 /usr/local/lib/libluajit-5.1.so.2下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp /usr/<span class="built_in">local</span>/lib/libluajit-5.1.so.2 /usr/lib64/</span><br><span class="line">cp /usr/<span class="built_in">local</span>/lib/libluajit-5.1.so.2.0.2 /usr/lib64</span><br></pre></td></tr></table></figure><p><strong>然后启动</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/nginx/sbin/nginx</span><br></pre></td></tr></table></figure><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>在nginx安装目录下，修改nginx.conf文件</p><p>在Server代码块下添加如下代码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">location /hello&#123;</span><br><span class="line">        default_type <span class="string">'text/plain'</span>;</span><br><span class="line">        content_by_lua <span class="string">'ngx.say("hello,lua")'</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="/articles/c745ae1a/2.png" alt></p><p><strong>配置生效</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/nginx/sbin/nginx -t</span><br><span class="line">/usr/<span class="built_in">local</span>/nginx/sbin/nginx -s reload</span><br></pre></td></tr></table></figure><p><strong>浏览器访问</strong> </p><p>访问地址： <a href="http://xxx.xxx.xxx/hello" target="_blank" rel="noopener">http://xxx.xxx.xxx/hello</a></p><p><img src="/articles/c745ae1a/3.png" alt></p><p>到此就成功了。</p><h2 id="添加服务"><a href="#添加服务" class="headerlink" title="添加服务"></a>添加服务</h2><p>这时nginx只能用绝对路径启动，测试和重载，非常不方便。那需要把nginx添加到linux的服务管理中。</p><p><strong>编写nginx.service文件</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=nginx</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=forking</span><br><span class="line">ExecStart=/usr/local/nginx/sbin/nginx</span><br><span class="line">ExecReload=/usr/local/nginx/sbin/nginx -s reload</span><br><span class="line">ExecStop=/usr/local/nginx/sbin/nginx -s quit</span><br><span class="line">PrivateTmp=true</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure><p><strong>添加</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp ./nginx.service /lib/systemd/system/</span><br></pre></td></tr></table></figure><p><strong>重新加载</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br></pre></td></tr></table></figure><p><strong>验证</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl start nginx.service</span><br><span class="line">systemctl status nginx.service</span><br><span class="line">systemctl <span class="built_in">enable</span> nginx.service</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;Lua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。现在通常把lua迁入nginx中，根据lua脚本规则，强化nginx的能力。本文介绍在centos7中安装nginx整合lua。&lt;/p&gt;
    
    </summary>
    
      <category term="Web服务" scheme="https://wandouduoduo.netlify.com/categories/Web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Nginx" scheme="https://wandouduoduo.netlify.com/categories/Web%E6%9C%8D%E5%8A%A1/Nginx/"/>
    
    
      <category term="Nginx" scheme="https://wandouduoduo.netlify.com/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>使用ELRepo第三方源为CentOS 6/7/8升级最新内核版本</title>
    <link href="https://wandouduoduo.netlify.com/articles/a6119320.html"/>
    <id>https://wandouduoduo.netlify.com/articles/a6119320.html</id>
    <published>2019-12-27T14:57:47.000Z</published>
    <updated>2019-12-29T08:36:34.865Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Linux实质上上特指内核的，不过我们现在通常所说的是Linux是各个公司在内核的基础上进行优化和封装了很多组件，并加入了软件包管理工具等发行版，如：ubuntu，redhat,  centos等等。linux内核一直有在维护并随着技术和硬件的不断更新也加入了很多功能，所以如果要研究新的技术，用到新内核的功能，可能旧的内核不能满足需求。这时候就需要升级内核，但升级内核属于高危操作，早期还会总是出问题，后来如CentOS或RHEL类的Linux发行版需要升级Linux内核的话可以使用<a href="http://elrepo.org/" target="_blank" rel="noopener">ELRepo</a>第三方源来很方便进行升级。但是也可能受限于系统本身的低版本会造成升级失败，所以就详细描述了内核的升级过程。</p><p><img src="/articles/a6119320/1.jpg" alt></p><a id="more"></a><h1 id="ELRepo源"><a href="#ELRepo源" class="headerlink" title="ELRepo源"></a>ELRepo源</h1><p><a href="https://www.elrepo.org/" target="_blank" rel="noopener">ELRepo</a> 仓库，该软件源包含文件系统驱动以及网络摄像头驱动程序等等（支持显卡、网卡、声音设备甚至<a href="https://linux.cn/article-8310-1.html" target="_blank" rel="noopener">新内核</a>），虽然 ELRepo 是第三方仓库，但它有一个活跃社区和良好技术支持，并且CentOS官网wiki也已将它列为是可靠的（<a href="https://wiki.centos.org/AdditionalResources/Repositories" target="_blank" rel="noopener">参见此处</a>）。所以可以放心使用。</p><p><strong>内核版本简写说明</strong></p><p><strong>kernel-lt</strong>（lt=long-term）长期有效</p><p><strong>kernel-ml</strong>（ml=mainline）主流版本</p><h1 id="查看当前内核版本"><a href="#查看当前内核版本" class="headerlink" title="查看当前内核版本"></a>查看当前内核版本</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uname -r</span><br></pre></td></tr></table></figure><p>目前Linux内核发布的最新稳定版可以从 <a href="https://www.kernel.org" target="_blank" rel="noopener">https://www.kernel.org</a> 进行查看。</p><p><img src="/articles/a6119320/1.png" alt></p><h1 id="升级内核"><a href="#升级内核" class="headerlink" title="升级内核"></a>升级内核</h1><h2 id="先更新nss"><a href="#先更新nss" class="headerlink" title="先更新nss"></a>先更新nss</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum update nss</span><br></pre></td></tr></table></figure><h2 id="自动从源中安装"><a href="#自动从源中安装" class="headerlink" title="自动从源中安装"></a>自动从源中安装</h2><h4 id="首先安装ELRepo源"><a href="#首先安装ELRepo源" class="headerlink" title="首先安装ELRepo源"></a>首先安装ELRepo源</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#centos6</span></span><br><span class="line">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span><br><span class="line">rpm -Uvh https://www.elrepo.org/elrepo-release-6-9.el6.elrepo.noarch.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment">#centos7</span></span><br><span class="line">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span><br><span class="line">rpm -Uvh https://www.elrepo.org/elrepo-release-7.0-4.el7.elrepo.noarch.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment">#centos8</span></span><br><span class="line">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span><br><span class="line">rpm -Uvh https://www.elrepo.org/elrepo-release-8.0-2.el8.elrepo.noarch.rpm</span><br></pre></td></tr></table></figure><h4 id="启用ELRepo源仓库"><a href="#启用ELRepo源仓库" class="headerlink" title="启用ELRepo源仓库"></a><strong>启用ELRepo源仓库</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum --disablerepo=<span class="string">"\*"</span> --enablerepo=<span class="string">"elrepo-kernel"</span> list available</span><br></pre></td></tr></table></figure><h4 id="安装新内核"><a href="#安装新内核" class="headerlink" title="安装新内核"></a><strong>安装新内核</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y --enablerepo=elrepo-kernel install kernel<span class="_">-lt</span> kernel<span class="_">-lt</span>-devel  kernel<span class="_">-lt</span>-doc  kernel<span class="_">-lt</span>-headers</span><br></pre></td></tr></table></figure><p>如果顺利不报错的话新内核就说明已经安装完成。</p><h2 id="手动下载安装"><a href="#手动下载安装" class="headerlink" title="手动下载安装"></a>手动下载安装</h2><h4 id="内核报错"><a href="#内核报错" class="headerlink" title="内核报错"></a>内核报错</h4><p>如安装内核有报错：No package kernel-lt available. 如下图</p><p><img src="/articles/a6119320/3.png" alt></p><p>新内核下载地址：<a href="https://elrepo.org/linux/kernel/el7/x86_64/RPMS/" target="_blank" rel="noopener">https://elrepo.org/linux/kernel/el7/x86_64/RPMS/</a></p><h4 id="下载安装内核"><a href="#下载安装内核" class="headerlink" title="下载安装内核"></a>下载安装内核</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://elrepo.org/linux/kernel/el6/x86_64/RPMS/kernel<span class="_">-lt</span>-4.4.207-1.el6.elrepo.x86_64.rpm</span><br><span class="line">rpm -ivh kernel<span class="_">-lt</span>-4.4.207-1.el6.elrepo.x86_64.rpm</span><br></pre></td></tr></table></figure><h4 id="更新kernel-lt-headers"><a href="#更新kernel-lt-headers" class="headerlink" title="更新kernel-lt-headers"></a>更新kernel-lt-headers</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://elrepo.org/linux/kernel/el6/x86_64/RPMS/kernel-lt-headers-4.4.207-1.el6.elrepo.x86_64.rpm</span><br><span class="line">rpm -ivh kernel-lt-headers-4.4.207-1.el6.elrepo.x86_64.rpm</span><br></pre></td></tr></table></figure><p> 安装kernel-lt-headers时有冲突报错</p><p><img src="/articles/a6119320/4.png" alt></p><p><strong>排除报错</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#移除</span></span><br><span class="line">yum remove kernel-headers</span><br><span class="line"><span class="comment">#再重新安装</span></span><br><span class="line">rpm -ivh kernel<span class="_">-lt</span>-headers-4.4.207-1.el6.elrepo.x86_64.rpm</span><br></pre></td></tr></table></figure><h4 id="更新kernel-lt-devel"><a href="#更新kernel-lt-devel" class="headerlink" title="更新kernel-lt-devel"></a>更新kernel-lt-devel</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://elrepo.org/linux/kernel/el6/x86_64/RPMS/kernel-lt-devel-4.4.207-1.el6.elrepo.x86_64.rpm</span><br><span class="line">rpm -ivh kernel-lt-devel-4.4.207-1.el6.elrepo.x86_64.rpm</span><br></pre></td></tr></table></figure><h4 id="更新kernel-lt-doc"><a href="#更新kernel-lt-doc" class="headerlink" title="更新kernel-lt-doc"></a>更新kernel-lt-doc</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://elrepo.org/linux/kernel/el6/x86_64/RPMS/kernel-lt-doc-4.4.207-1.el6.elrepo.noarch.rpm</span><br><span class="line">rpm -ivh kernel-lt-doc-4.4.207-1.el6.elrepo.noarch.rpm</span><br></pre></td></tr></table></figure><h1 id="修改grub配置"><a href="#修改grub配置" class="headerlink" title="修改grub配置"></a>修改grub配置</h1><p>这里因为系统差异原因，对centos7以上版本和centos6版本差异处理。</p><h4 id="centos7以上"><a href="#centos7以上" class="headerlink" title="centos7以上"></a>centos7以上</h4><h6 id="查看当前grub中内核版本列表"><a href="#查看当前grub中内核版本列表" class="headerlink" title="查看当前grub中内核版本列表"></a>查看当前grub中内核版本列表</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#centos7以上版本</span></span><br><span class="line">awk -F\<span class="string">' '</span><span class="variable">$1</span>==<span class="string">"menuentry "</span> &#123;<span class="built_in">print</span> i++ <span class="string">" : "</span> <span class="variable">$2</span>&#125;<span class="string">' /etc/grub2.cfg</span></span><br></pre></td></tr></table></figure><p>Centos7及以上版本会返回信息,可能如下：</p><p><img src="/articles/a6119320/5.png" alt></p><p>信息列表中：<strong>0</strong> 即为安装的新内核</p><h6 id="修改设置并生成新的grub配置文件"><a href="#修改设置并生成新的grub配置文件" class="headerlink" title="修改设置并生成新的grub配置文件"></a>修改设置并生成新的grub配置文件</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grub2-set-default 0</span><br><span class="line">grub2-mkconfig -o /boot/grub2/grub.cfg</span><br></pre></td></tr></table></figure><h4 id="Centos6"><a href="#Centos6" class="headerlink" title="Centos6"></a>Centos6</h4><h6 id="查看安装的内核版本"><a href="#查看安装的内核版本" class="headerlink" title="查看安装的内核版本"></a>查看安装的内核版本</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa | grep -i kernel</span><br></pre></td></tr></table></figure><p><img src="/articles/a6119320/6.png" alt></p><h6 id="编辑配置"><a href="#编辑配置" class="headerlink" title="编辑配置"></a>编辑配置</h6><p>更改/etc/grub.conf文件中default的值,设定为<strong>0</strong>如下图：</p><p><img src="/articles/a6119320/2.png" alt></p><h1 id="重新启动"><a href="#重新启动" class="headerlink" title="重新启动"></a>重新启动</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure><h1 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h1><p>查看内核版本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">uname -r</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;Linux实质上上特指内核的，不过我们现在通常所说的是Linux是各个公司在内核的基础上进行优化和封装了很多组件，并加入了软件包管理工具等发行版，如：ubuntu，redhat,  centos等等。linux内核一直有在维护并随着技术和硬件的不断更新也加入了很多功能，所以如果要研究新的技术，用到新内核的功能，可能旧的内核不能满足需求。这时候就需要升级内核，但升级内核属于高危操作，早期还会总是出问题，后来如CentOS或RHEL类的Linux发行版需要升级Linux内核的话可以使用&lt;a href=&quot;http://elrepo.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ELRepo&lt;/a&gt;第三方源来很方便进行升级。但是也可能受限于系统本身的低版本会造成升级失败，所以就详细描述了内核的升级过程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/a6119320/1.jpg&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Linux" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/Linux/"/>
    
    
      <category term="Linux" scheme="https://wandouduoduo.netlify.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>运维职责和分类划分</title>
    <link href="https://wandouduoduo.netlify.com/articles/6aa3e89a.html"/>
    <id>https://wandouduoduo.netlify.com/articles/6aa3e89a.html</id>
    <published>2019-12-27T14:38:46.000Z</published>
    <updated>2019-12-29T08:37:39.091Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>有同学看到标题就会说5年以上的技术大咖都傻傻分不清楚，那能成的上大咖？这还真是的，有朋友在BAT等互联网大厂里工作多年，是做技术开发的，在业务上技术很牛的，但是有次聊天时问到这个问题，傻傻分不清楚运维具体是干什么的？有哪些分类？这很正常，孔子曰：术业有专攻，如是而已。还有一些新人小白想要进入这个行业，但是很懵懂，在刚刚接触，心里就打退堂鼓了，害怕自己学不会搞不定弄不懂。那这里就为大家揭开这一职业的朦胧面纱。</p><p><img src="/articles/6aa3e89a/1.jpg" alt></p><a id="more"></a><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>何为运维？运维，从字面意思很好理解，运行维护。有可能你认为的运维是高大上，坐在高档写字楼里，敲敲电脑动动手指的，可能是风吹日晒走街串巷等等。</p><p><img src="/articles/6aa3e89a/3.jpg" alt></p><p><img src="/articles/6aa3e89a/2.jpg" alt></p><p>是的，这些都是运维，但是行业，分工以及内容都不同。总体来说大致可以分为两类：线上运维和线下运维。而互联网运维就属于线上运维，共享单车运维就是线下运维。这里我们聊得就是互联网运维。</p><h2 id="运维前景"><a href="#运维前景" class="headerlink" title="运维前景"></a>运维前景</h2><p>要说运维的前景还是很广阔的。可以这么说只要有互联网就会需要运维，试问下，现在的生活还能没有互联网吗？所以，就业前景还是可以的。就企业而言，运维属于技术职务，所以走的是P路线。什么是P路线呢？是互联网就个人职业规划的上升和晋级通道，P路线就是技术路线，M路线就是管理路线。分不同等级，逐级或跨级晋升，当然不能等级体现了你的能力高低。我们常常自嘲为“打杂的”，因为运维是技术支持部门，是为开发出产品后上线提供支持的，所以很多东西都需要懂。所以如果想要从事这个行业先有个心理准备。技术方面有两个维度：深度和广度。就运维而言，广度是第一要求，你不需要精，但是一定要知道。深度在根据自己的规划方向再深入研究。就广度来说，从网络，服务器，系统，环境，应用，监控，虚拟化，容器化，自动化，智能化等等，需要学的太多了。还有，有人说：“运维是吃青春饭的”，对也不对，对的是做技术的，年龄大了操作和思维等肯定不如年轻人，不对的是：看能力，能力比较牛，不可替代，无论年龄多大都有市场。就单纯的说运维晋升：初级，中级，高级，资深，架构师，CTO。少年，你做好准备了吗？</p><h2 id="运维分类"><a href="#运维分类" class="headerlink" title="运维分类"></a>运维分类</h2><p>有很多程序员都是宅男，单身，过年过节回家，亲戚朋友问到从事的职业被戏称为修电脑的。但是只要是从事技术的，哪怕是刚入行的小白，也能够了解清楚分类，工具等。一般程序员根据开发语言划分的，像：php，java, C++，Go等等，根据业务划分可分为：前端和后端。这些基本就可以涵盖所有了。而运维的分类是怎样的呢？问什么会让很多人傻傻分不清和懵懂呢？各自有哪些职责呢？按职责划分运维的分类大致可以分为应用运维，系统运维，运维研发，数据库运维和运维安全。如下图所示：</p><p><img src="/articles/6aa3e89a/sun.jpg" alt></p><p>那下面我们就逐个介绍下。</p><h2 id="应用运维"><a href="#应用运维" class="headerlink" title="应用运维"></a><strong>应用运维</strong></h2><p>应用运维也是大部分人所认知的运维，应用运维根据字面意思就可以知道是和应用维护的。主要负责线上服务的发布变更、服务健康状况监控、服务的容灾高可用和数据安全备份等工作。针对这些工作需要对服务进行巡检了解服务状况，服务出故障的应急处理和排查优化。下面详细的职责如下所述。</p><p><img src="/articles/6aa3e89a/timg.jpg" alt></p><p><strong>评审</strong></p><p>在产品研发阶段，参与产品设计评审，从运维的角度提出评审意见，使服务满足准入要求，尽快上线并预备高可用等方案。</p><p><strong>服务</strong></p><p>服务管理主要就是发布系统，制定线上业务的升级变更及回滚方案，并根据申请进行变更的实施。掌握所负责的服务及服务间的依赖关联关系中的各种资源。能够发现服务上的缺陷，及时通报并推进解决。制定服务的稳定性指标及准入标准方案，同时不断完善和优化程序和系统的功能、效率，提高运行质量，完善监控内容，提高报警准确度。在线上服务出现故障时，第一时间响应，对已知的故障能按流程进行通报并按预案执行，未知故障组织相关人员进行联合排障。</p><p><strong>资源</strong></p><p>对各个服务使用的服务器资产进行管理，梳理服务器资源实时状况、IDC数据中心分布情况、网络专线及带宽情况，能够合理使用服务器资源，根据不同服务的需求，分配不同配置的服务器，确保服务器资源的充分利用。</p><p><strong>巡检</strong></p><p>实时了解服务的运行状况，制定服务的例行排查点，并不断完善。并根据制定的服务排查点，对服务进行定期检查。对排查过程中发现的问题，及时进行追查处理，排除可能存在的隐患和痛点</p><p><strong>监控</strong></p><p>确定服务存活状态正常，对服务的各项性能、系统的指标阈值或临界点安排合理，以及对出现该异常后的处理制定预案。建立和更新和维护服务预案文档，并根据日常故障情况不断补充完善，提高预案完备性。周期性进行预案演练，确保预案的可行性。</p><p><strong>备份</strong></p><p>制定业务数据的备份方案，按策略对数据进行备份和冗余工作。保证数据备份的可用性，完整性和安全性，定期开展数据恢复性测试。</p><h2 id="系统运维"><a href="#系统运维" class="headerlink" title="系统运维"></a><strong>系统运维</strong></h2><p>系统运维主要和系统及底层网络等打交道，如：IDC机房、网络拓扑、CDN加速和基础服务的建设等；对所有服务器的资产进行管理，服务器的调研选型、交付上架和后期维护等。详细的工作职责如下：</p><p><img src="/articles/6aa3e89a/4.jpg" alt></p><p><strong>IDC机房</strong></p><p>根据业务申请需求，预估未来数据中心的发展规模，从骨干网络的分布，数据中心建筑可靠性，以及Internet的接入、网络中的攻击防御、扩容、空间预留、外接专线、现场支撑等方面。</p><p><strong>网络</strong></p><p>设计及规划生产网络架构，这里面包括：数据中心网络架构、传输网架构、CDN网络架构等，以及网络调优等日常运维工作。</p><p><strong>基础服务</strong></p><p>根据网络规模和业务需求，构建负载均衡集群，完成网络与业务服务器的衔接，提供高性能、高可用的负载调度能力，以及统一的网络层防御能力；通过集群化部署，保证公网访问服务的高性能与高可用。有些服务需要借助于第三方的，对第三方进行测试选型和调度控制，监控等等，保障系统稳定、高效运行。</p><p><strong>服务器</strong></p><p>服务器的测试和选型，包含服务器整机、部件的基础性测试和业务压力测试，降低整机功率，规划服务器上架位置，在保证温湿度的情况下，提升部署密度，降低成本；服务器硬件故障的诊断排查和定位，服务器温湿度转速等硬件监控等；</p><p><strong>操作系统</strong></p><p>所有平台的操作系统选型、定制和内核优化，以及漏洞补丁的更新和内部版本升级；建立统一的软件包管理和分发中心库，以及现在用的很多的maven依赖包仓库和Docker容器仓库；</p><p><strong>资产管理</strong></p><p>记录和管理所有基础物理信息，包括IDC数据中心、网络信息、机架机柜位置、服务器型号信息，售后信息等等各种资源信息，制定有效合理的流程，确保信息的准确性；</p><h2 id="运维开发"><a href="#运维开发" class="headerlink" title="运维开发"></a><strong>运维开发</strong></h2><p>运维平台设计,开发和实施部署，如：用户管理，资产管理、监控系统、发布平台、权限管理系统等等。提供各种接口，封装更高层的自动化运维系统。详细的工作职责如下所述。</p><p><img src="/articles/6aa3e89a/5.jpg" alt></p><p><strong>发布平台</strong></p><p>记录关联关系，协助运维人员对日常运维标准化，流程化进而自动化，包括服务器的管理如：重启、改名、初始化、域名管理、流量切换和故障预案实施等。</p><p><strong>监控系统</strong></p><p>监控系统的调研选型，对服务器和各种网络设备的资源性能指标、业务性能指标的收集、告警、存储、分析、展示和数据分析等工作，保证公司服务器资源的合理化调配，持续提高告警的及时性、准确性和有效性，对监控进行聚合，进而实现智能化报警监控。</p><p><strong>自动化平台</strong></p><p>自动化系统的开发，自动化部署系统所需要的各种数据和信息。结合云计算，区块链等技术，研发和提供PaaS相关高可用平台，提高服务的部署有效性和稳定性，提高资源利用率。</p><h2 id="数据库运维"><a href="#数据库运维" class="headerlink" title="数据库运维"></a><strong>数据库运维</strong></h2><p>数据库运维需要对库、表、索引和SQL等制定规范，对数据库进行变更、监控、备份、高可用设计等工作。详细的工作职责如下所述。</p><p><img src="/articles/6aa3e89a/6.jpg" alt></p><p><strong>评审</strong></p><p>在产品研发阶段，参与设计方案评审，从DBA的角度提出数据存储、库表设计，索引设计等方案、SQL开发标准，使服务满足数据库的高可用、高性能要求。</p><p><strong>容量</strong></p><p>掌握所负责服务数据库的容量上限，清楚地了解瓶颈点，当服务将触及容量阈值时，及时优化、分拆或者扩容等</p><p><strong>备份与灾备</strong></p><p>制定数据备份与灾备策略方案，定期对数据进行恢复性测试，保证数据备份的有效性，可用性和完整性。</p><p><strong>监控</strong></p><p>对数据库存活和各项性能指标监控，及时了解数据库的运行状态。</p><p><strong>安全</strong></p><p>建立数据库账号和权限控制体系，有效降低误操作和数据泄露的风险；加强离线备份数据的管理，降低数据泄露的风险。</p><p><strong>性能优化</strong></p><p>对数据库风险点有备用或切换方案，降低故障对数据库的影响；对数据库性能进行优化，包括存储方案改进、硬件资源优化、文件系统优化、库表优化、SQL优化等。</p><p><strong>自动化</strong></p><p>开发数据库自动化平台，包括数据库部署、自动扩容、分库分表、权限管理、备份恢复、SQL审核和上线、故障处理等。</p><h2 id="运维安全"><a href="#运维安全" class="headerlink" title="运维安全"></a><strong>运维安全</strong></h2><p>运维安全负责各方面的安全加固工作，进行安全扫描、渗透测试，进行安全工具和系统研发以及安全事件应急处理。详细的工作职责如下所述。</p><p><img src="/articles/6aa3e89a/7.jpg" alt></p><p><strong>安全文档</strong></p><p>根据公司内部的具体流程，制定切实可行且行之有效的安全方案和制度。</p><p><strong>安全培训</strong></p><p>定期向员工提供具有安全培训和考核，在公司内建立安全负责人制度。</p><p><strong>风险评估</strong></p><p>通过黑白盒测试和检查机制，对网络、服务器、业务、用户数据等方面的风险评估。</p><p><strong>安全</strong></p><p>根据风险评估报告，加固薄弱环节，包括设计安全防线、部署安全设备、更新补丁、防御病毒、源代码自动扫描和业务产品安全咨询等等。通过加密、匿名化、混淆数据，乃至定期删除等技术手段和流程来降低可能泄露数据的风险。</p><p><strong>安全合规</strong></p><p>为了满足合规性要求例如金融牌照，支付牌照等，安全团队承担着对外安全合规的接口人角色。</p><p><strong>应急响应</strong></p><p>建立安全报警系统，通过安全中心收集第三方发现的安全问题，评估影响面，组织各部门对已经发现的安全问题进行修复和事后造成安全的追查。</p><p>运维工作的目标和期望是：希望所有的工作都自动化起来，减少人的重复工作，降低知识传递的成本，使我们的业务能够更高效、更安全运行，使产品运行的更加稳定。Good  Luck!!!</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;有同学看到标题就会说5年以上的技术大咖都傻傻分不清楚，那能成的上大咖？这还真是的，有朋友在BAT等互联网大厂里工作多年，是做技术开发的，在业务上技术很牛的，但是有次聊天时问到这个问题，傻傻分不清楚运维具体是干什么的？有哪些分类？这很正常，孔子曰：术业有专攻，如是而已。还有一些新人小白想要进入这个行业，但是很懵懂，在刚刚接触，心里就打退堂鼓了，害怕自己学不会搞不定弄不懂。那这里就为大家揭开这一职业的朦胧面纱。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/6aa3e89a/1.jpg&quot; alt&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="心得体会" scheme="https://wandouduoduo.netlify.com/categories/%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/"/>
    
    
      <category term="Experiences" scheme="https://wandouduoduo.netlify.com/tags/Experiences/"/>
    
  </entry>
  
  <entry>
    <title>Hexo博客导流到微信公众号</title>
    <link href="https://wandouduoduo.netlify.com/articles/36a9dafd.html"/>
    <id>https://wandouduoduo.netlify.com/articles/36a9dafd.html</id>
    <published>2019-12-25T06:05:19.000Z</published>
    <updated>2019-12-26T03:34:41.212Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>随着互联网的高速发展，我们身边的一切都发生了翻天覆地的变化，互联网真真正正改变了我们的生活方式。足不出户买东西，点点手机叫外卖，一部手机走天下等等。古有文人墨客怀才不遇，积愤难平。但现在互联网放大了每个人的能力，知识变现，粉丝导流，人气带货等等已很常见。这时很多技术博主或站长，就想技术文档笔记积累的人气导流到微信公众号。本文就是讲解Hexo博客导流到微信公众号的流程。一句话概括：就是Hexo 整合 OpenWrite 平台的 readmore 插件,实现博客的每一篇文章自动增加阅读更多效果,关注公众号后方可解锁全站文章,从而实现博客流量导流到微信公众号粉丝目的。</p><p>有些同学，会有如下疑问：</p><ul><li>为什么要讲Hexo博客，而不是其他如简书，博客园等？</li><li>导流后效果是怎样的呢？</li><li>配置会不会很麻烦呢？</li><li>需要用到哪些工具呢？</li><li>具体流程是怎样的呢？</li></ul><p>针对这些问题，下面就一一解答。</p><a id="more"></a><h2 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h2><p>为什么要讲Hexo博客，而不是其他如简书，博客园等，或者自己建站呢？归根结底，还是因为Money问题。Hexo是github的静态pages博客，搭建好后不需要域名和服务器空间（这些虽然不贵，但是都是要钱的), 并且所有博客内的源码自己可控的。而且国内的云服务商都有静态pages功能，如码云和腾讯云等。重要的是需求就是：做个笔记，记录工作中遇到的技术，对自己做个总结，后面忘记时可以快速查询回忆起来。需求简单，源码可控等造成了hexo静态博客用处很广。</p><h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p><img src="/articles/36a9dafd/1.png" alt></p><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>hexo配置导流很简单的，主要用到工具就是<a href="https://openwrite.cn/" target="_blank" rel="noopener">OpenWrite</a>。</p><h4 id="注册"><a href="#注册" class="headerlink" title="注册"></a>注册</h4><p>web页面填写邮箱和密码注册openwrite。</p><p><img src="/articles/36a9dafd/2.png" alt></p><p><img src="/articles/36a9dafd/3.png" alt></p><h4 id="导流公众号设定"><a href="#导流公众号设定" class="headerlink" title="导流公众号设定"></a>导流公众号设定</h4><p>增长工具–&gt;添加–&gt;填写信息–&gt;保存</p><p><img src="/articles/36a9dafd/4.png" alt></p><p><img src="/articles/36a9dafd/5.png" alt></p><p>注意：保存好后，需要再次到增长工具–&gt;博客导流公众号–&gt;使用</p><p><img src="/articles/36a9dafd/6.png" alt></p><p>然后会展示使用指南</p><p><img src="/articles/36a9dafd/7.png" alt></p><h4 id="Hexo配置"><a href="#Hexo配置" class="headerlink" title="Hexo配置"></a>Hexo配置</h4><p>在hexo <code>_config.yml</code> 配置文件中,添加配置 <code>readmore</code> 插件相关信息</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># readmore</span></span><br><span class="line"><span class="attr">plugins:</span></span><br><span class="line"><span class="attr">  readmore:</span></span><br><span class="line"><span class="attr">    blogId:</span> <span class="number">19128</span><span class="bullet">-1577246103864</span><span class="bullet">-519</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">豌豆多多追梦记</span></span><br><span class="line"><span class="attr">    qrcode:</span> <span class="attr">https://wandouduoduo.github.io/about/index/gongzhonghao.jpg</span></span><br><span class="line"><span class="attr">    keyword:</span> <span class="string">vip</span></span><br></pre></td></tr></table></figure><p>其中,配置参数含义如下:</p><ul><li><code>blogId</code> : [必选]OpenWrite 后台申请的博客唯一标识,例如:119128-1577246103864-519</li><li><code>name</code> : [必选]OpenWrite 后台申请的博客名称,例如:豌豆多多追梦记</li><li><code>qrcode</code> : [必选]OpenWrite 后台申请的微信公众号二维码图片地址。</li><li><code>keyword</code> : [必选]OpenWrite 后台申请的微信公众号后台回复关键字,例如:vip</li></ul><p>注意: <strong>一定要替换成自己的在使用指南中显示的相关配置</strong>!</p><h4 id="Hexo安装组件"><a href="#Hexo安装组件" class="headerlink" title="Hexo安装组件"></a>Hexo安装组件</h4><p>开通readmore功能，原本需要手动更改主题的配置文件，但现在有牛人进行了封装。有兴趣可以看下</p><p><a href="https://github.com/snowdreams1006/hexo-plugin-readmore" target="_blank" rel="noopener">hexo-plugin-readmore</a>。所以我们现在只需要安装即可</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-plugin-readmore --save</span><br><span class="line">或</span><br><span class="line">cnpm install hexo-plugin-readmore --save</span><br></pre></td></tr></table></figure><h4 id="构建发布"><a href="#构建发布" class="headerlink" title="构建发布"></a>构建发布</h4><p>插件安装完成后，保存配置，构建发布即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g &amp;&amp; hexo d</span><br></pre></td></tr></table></figure><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>打开hexo博客，随便打开一篇文档，查看是否有效果。Good   Luck!!!</p><p><img src="/articles/36a9dafd/8.png" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;随着互联网的高速发展，我们身边的一切都发生了翻天覆地的变化，互联网真真正正改变了我们的生活方式。足不出户买东西，点点手机叫外卖，一部手机走天下等等。古有文人墨客怀才不遇，积愤难平。但现在互联网放大了每个人的能力，知识变现，粉丝导流，人气带货等等已很常见。这时很多技术博主或站长，就想技术文档笔记积累的人气导流到微信公众号。本文就是讲解Hexo博客导流到微信公众号的流程。一句话概括：就是Hexo 整合 OpenWrite 平台的 readmore 插件,实现博客的每一篇文章自动增加阅读更多效果,关注公众号后方可解锁全站文章,从而实现博客流量导流到微信公众号粉丝目的。&lt;/p&gt;
&lt;p&gt;有些同学，会有如下疑问：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;为什么要讲Hexo博客，而不是其他如简书，博客园等？&lt;/li&gt;
&lt;li&gt;导流后效果是怎样的呢？&lt;/li&gt;
&lt;li&gt;配置会不会很麻烦呢？&lt;/li&gt;
&lt;li&gt;需要用到哪些工具呢？&lt;/li&gt;
&lt;li&gt;具体流程是怎样的呢？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;针对这些问题，下面就一一解答。&lt;/p&gt;
    
    </summary>
    
      <category term="心得体会" scheme="https://wandouduoduo.netlify.com/categories/%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/"/>
    
      <category term="使用技巧" scheme="https://wandouduoduo.netlify.com/categories/%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/"/>
    
      <category term="Hexo" scheme="https://wandouduoduo.netlify.com/categories/%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7/Hexo/"/>
    
    
      <category term="Hexo" scheme="https://wandouduoduo.netlify.com/tags/Hexo/"/>
    
  </entry>
  
  <entry>
    <title>Elasticsearch分片副本机制</title>
    <link href="https://wandouduoduo.netlify.com/articles/688d9226.html"/>
    <id>https://wandouduoduo.netlify.com/articles/688d9226.html</id>
    <published>2019-12-23T06:46:15.000Z</published>
    <updated>2019-12-26T03:34:41.207Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>日常运维工作中，保证系统服务的稳定是第一优先级的。做好高可用方案是关键。在用Elasticsearch作为存储的服务中，保证Elasticsearch数据的高可用，数据的安全性和一致性至关重要。本文就针对这一问题详细介绍了Elasticsearch的分片和副本机制。</p><a id="more"></a><h2 id="分片和副本机制"><a href="#分片和副本机制" class="headerlink" title="分片和副本机制"></a>分片和副本机制</h2><ol><li><p>index(索引) 包含多个 shard(分片)，创建 index 时可以在settings中设置分片数，不设置时默认是5个。</p></li><li><p>每个 shard 都是一个最小工作单元，承载部分数据；每个 shard 都是一个 lucene 实例，并且具有完整的建立索引和处理能力。</p></li><li><p>增减节点时，shard 会自动在 nodes 中负载均衡。</p></li><li><p>primary shard（主分片） 和 replica shard（副本分片），每个 document 肯定只存在于某一个 primary shard 以及对应的 replica shard 中，不可能存在于多个 primary shard 。</p><p><img src="/articles/688d9226/1.png" alt></p></li><li><p>replica shard 是 primary shard 的副本，负责容错，以及承担读请求负载。</p></li><li><p>primary shard 的数量在创建索引的时候就固定了，不可更改；replica shard 的数量可以随时修改。</p></li><li><p>primary shard 的默认数量是5，replica 默认是1，默认有10个 shard，5个 primary shard ，5个 replica shard 。</p></li><li><p>primary shard 不能和自己的 replica shard 放在同一个节点上，否则节点宕机，primary shard 和副本都丢失，容错机制将失效；但是可以和其他 primary shard 的 replica shard 放在同一个节点上。</p><p><img src="/articles/688d9226/2.png" alt></p></li></ol><h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><p>Shards分片个数:  3</p><p>Replica副本个数：3</p><h4 id="单节点环境下"><a href="#单节点环境下" class="headerlink" title="单节点环境下"></a>单节点环境下</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">PUT /myindex</span><br><span class="line">&#123;</span><br><span class="line">    &quot;settings&quot;: &#123;</span><br><span class="line">        &quot;number_of_shards&quot;: 3,</span><br><span class="line">        &quot;number_of_replica&quot;: 1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"># 查看集群健康状态 --- 将返回yellow，说明集群状态不健康</span><br><span class="line">GET _cat/health</span><br></pre></td></tr></table></figure><p>此时，因为是单节点环境，3个 primary shard 只能分配到这个仅有的 node 上，另外3个 replica shard 是无法分配的（一个 shard 的副本 replica，两个是不能在同一个节点），集群可以正常工作；但出现宕机，数据全部丢失，而且集群不可用，无法接受任何请求。</p><h4 id="两个节点环境下"><a href="#两个节点环境下" class="headerlink" title="两个节点环境下"></a>两个节点环境下</h4><p>将3个 primary shard 分配到一个 node 上，另外3个 replica shard 分配到另一个节点上；<br>primary shard 和 replica shard 保持同步；<br>primary shard 和 replica shard 都可以处理客户端的读请求。</p><p><img src="/articles/688d9226/3.png" alt></p><h4 id="三个节点环境下"><a href="#三个节点环境下" class="headerlink" title="三个节点环境下"></a>三个节点环境下</h4><p>将3个 primary shard 分别分配到一个 node 上，另外3个 replica shard 也交叉分配到另一个节点上；</p><p><img src="/articles/688d9226/1.png" alt></p><p>这样3个节点都可以负载均衡增大访问量，同时如果一台服务器宕机后，数据也不会丢失，还可以对外正常提供服务。保证了服务的高可用和数据的安全。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>建议:  primary shard的个数和集群节点数一致，replica shard 数可以根据业务需求量决定，需求量大可以设定多个replica shard，来增加读取操作。但是至少每个primary shard设置1个replica shard，来保证高可用和数据的安全性。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;日常运维工作中，保证系统服务的稳定是第一优先级的。做好高可用方案是关键。在用Elasticsearch作为存储的服务中，保证Elasticsearch数据的高可用，数据的安全性和一致性至关重要。本文就针对这一问题详细介绍了Elasticsearch的分片和副本机制。&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.netlify.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="Elasticsearch" scheme="https://wandouduoduo.netlify.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/Elasticsearch/"/>
    
    
      <category term="Elasticsearch" scheme="https://wandouduoduo.netlify.com/tags/Elasticsearch/"/>
    
  </entry>
  
  <entry>
    <title>Nginx之正反代理详解</title>
    <link href="https://wandouduoduo.netlify.com/articles/c5ecc6c0.html"/>
    <id>https://wandouduoduo.netlify.com/articles/c5ecc6c0.html</id>
    <published>2019-12-19T11:14:45.000Z</published>
    <updated>2019-12-26T03:34:41.226Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在日常运维工作中，常常会用到反向代理，为了更安全同时为了负载均衡，分担压力。</p><p>那么，有小伙伴就会有疑问：</p><ul><li>什么是反向代理？</li><li>负载均衡又是怎么实现的？</li><li>有反向代理那有正向代理吗？</li><li>正向代理的应用场景是怎样的？</li><li>反向代理和正向代理怎么配置实现呢？</li></ul><p>带着这些疑问，就给大家详细解释下nginx的正反向代理。</p><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>Nginx（Nginx是一款自由的、开源的、高性能的HTTP服务器。功能优势等等这里就不再赘述了。度娘那里有很多信息。）</p><h2 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h2><p>说到代理，首先我们要明确一个概念，所谓代理就是一个代表、一个渠道；</p><p>此时就设计到两个角色，一个是被代理角色，一个是目标角色，被代理角色通过这个代理访问目标角色完成一些任务的过程称为代理操作过程；如同生活中的专卖店~客人到adidas专卖店买了一双鞋，这个专卖店就是代理，被代理角色就是adidas厂家，目标角色就是用户。</p><h2 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h2><p>我们在运维的日常工作中经常用到负载均衡，所以接触反向代理比较多，那么反向代理是怎样的呢？。例如人气比较高的网站，如淘宝，京东等等。每天访问人数的人很多，数以万计，此时单台服务器远远不能承载所有人的访问请求，这时作为资深运维人员就需要对web服务进行分布式部署；何为分布式部署呢？就是通过部署多台服务器组成web集群共同来处理访问请求，解决单台服务器不能承载的问题；分布式部署的web服务可以横行扩展。而实现web分布式部署通常要用到反向代理。apache或nginx都可以。本文以nginx为例，用nginx的反向代理实现的。国内公司通过把nginx和其他的组件进行封装，根据场景或侧重点不同，便于构建安装，就有了：Tengine或OpenResty等。有兴趣的朋友可以度娘搜索学习。那么反向代理具体是通过什么样的方式实现的分布式的集群操作呢，我们先看一个示意图：</p><p><img src="/articles/c5ecc6c0/2.png" alt></p><p>通过上述的图解大家就可以看清楚了，多个客户端给服务器发送的请求，nginx服务器接收到之后，按照一定的规则分发给了后端的web服务器进行处理了。此时请求的来源也就是客户端是明确的，但是请求后具体由哪台服务器进行处理响应并不明确了，web服务（nginx）扮演的就是一个反向代理角色。</p><p>反向代理，主要用于服务器集群分布式部署负载均衡共同承载请求压力或安全需求等的情况下使用，反向代理可以隐藏了响应服务器的信息，能够过滤网络攻击，保证安全。</p><h2 id="正向代理"><a href="#正向代理" class="headerlink" title="正向代理"></a>正向代理</h2><p>阴阳两仪生万物，有阴就有阳，有反就有正。说完反向代理了，我们再来看看正向代理。正向代理可能在日常工作中用的不是很多，但是，相信大家经常听到：翻墙这个词，何为翻墙呢？翻墙是因为大陆对网络中攻击等等进行了屏蔽和过滤，相当于防火墙的墙一样，允许的我们才可以访问，屏蔽的我们就不能访问。这是我们做技术的如果需要在国外查询技术文档等就需要翻墙，通常我们需要购买vpn来实现，vpn的功能就是用的正向代理。那么vpn是怎么实现的呢？我们如果需要访问国外的某些网站，此时你会发现位于国外的某网站我们通过浏览器是没有办法访问的，被屏蔽过滤掉了。vpn的方式就是找一个可以正常访问国外网站的代理服务器，我们将请求发送给代理服务器，然后代理服务器去访问国外的网站，然后将访问到的数据传递给我们！</p><p>上述描述的代理模式称为正向代理，正向代理的特点是：客户端非常明确要访问的服务器地址；服务器只清楚请求来自哪个代理服务器，但是不清楚来自哪个具体的客户端；正向代理模式屏蔽或者隐藏了真实客户端信息。如下图</p><p><img src="/articles/c5ecc6c0/1.png" alt></p><h2 id="正反向代理共同使用"><a href="#正反向代理共同使用" class="headerlink" title="正反向代理共同使用"></a>正反向代理共同使用</h2><p>日常在实际项目操作中，正向代理和反向代理会搭配使用。正向代理代理客户端的请求去访问目标服务器，而目标服务器是又使用反向代理服务器，反向代理多台真实的业务处理服务器，进行负载均衡。具体的拓扑图如下：</p><p><img src="/articles/c5ecc6c0/2.jpg" alt></p><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p>我们知道了代理服务器，也一直说负载均衡，何为负载均衡呢？简单的说：web服务（nginx）作为反向代理服务器，依据一定的规则对请求进行分发，把请求平均让后端业务服务器进行响应，已达到分担压力的作用。负载就是客户端对业务发送的请求，分发到不同的服务器处理的规则，就是一种均衡规则。将服务器接收到的请求按照规则分发的过程，就是负载均衡。</p><p>负载均衡，有硬件负载均衡和软件负载均衡两种，硬件负载均衡也称为硬负载，如F5负载均衡，但是相对造价昂贵成本较高，但是数据的稳定性安全性等等有非常好的保障，如国有企业三大运营商这样的公司才会选择硬负载进行操作；通常公司都会考虑到成本问题，会选择使用软件负载均衡，软件负载均衡是利用现有的技术结合主机硬件实现的一种消息队列分发机制。软件负载均衡肯定和硬负载没发比较的，但是成本较低，稳定性和安全性在架构优化后在可接受范围，广为使用。</p><p>nginx的负载均衡规则如下：</p><ul><li><strong>weight轮询（默认</strong>）：接收到的请求按照顺序逐一分配到不同的后端服务器，即使在使用过程中，某一台后端服务器宕机，nginx会自动将该服务器剔除出队列，请求受理情况不会受到任何影响。 这种方式下，可以给不同的后端服务器设置一个权重值（weight），用于调整不同的服务器上请求的分配率；权重数据越大，被分配到请求的几率越大；该权重值，主要是针对实际工作环境中不同的后端服务器硬件配置进行调整的。</li><li><strong>ip_hash</strong>：每个请求按照发起客户端的ip的hash结果进行匹配，这样的算法下一个固定ip地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题。</li><li><strong>fair</strong>：智能调整调度算法，动态的根据后端服务器的请求处理到响应的时间进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高，响应时间长处理效率低的服务器分配到的请求少；结合了前两者的优点的一种调度算法。但是需要注意的是nginx默认不支持fair算法，如果要使用这种调度算法，请安装upstream_fair模块</li><li><strong>url_hash</strong>：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在nginx作为静态服务器的情况下提高缓存效率。同样要注意nginx默认不支持这种调度算法，要使用的话需要安装nginx的hash软件包</li></ul><h2 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h2><p>了解了正反向代理和负载均衡，那么要怎么实现呢？如何去配置。</p><h4 id="正向代理配置"><a href="#正向代理配置" class="headerlink" title="正向代理配置"></a><strong>正向代理配置</strong></h4><p>现在我登录上代理服务器上, 打开/etc/nginx/conf.d/default.conf<br>添加<code>resolver</code>和<code>proxy_pass</code>,设置如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  localhost nginx.tangll.cn;</span><br><span class="line"></span><br><span class="line">    resolver 8.8.8.8;</span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://$http_host$request_uri;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    error_page   500 502 503 504  /50x.html;</span><br><span class="line">    location = /50x.html &#123;</span><br><span class="line">        root   /usr/share/nginx/html;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>resolver</code>为DNS解析,这里填写的IP为Google提供的免费DNS服务器的IP地址。<br><code>proxy_pass</code>配置代理转发。<br>至此便是配置了代理服务器，所有访问请求全部都通过代理服务器转发,<code>$http_host</code>就是我们要访问的主机名,<code>$request_uri</code>就是我们后面所加的参数。<br>简单的说至此就是相当于配置好了我们请求了代理服务器,代理服务器再去请求我们所请求的地址。</p><p>然后，只需要在本机系统或浏览器配置代理即可访问。</p><h6 id="windows配置"><a href="#windows配置" class="headerlink" title="windows配置"></a><strong>windows配置</strong></h6><p><img src="/articles/c5ecc6c0/3.png" alt></p><h6 id="Linux系统"><a href="#Linux系统" class="headerlink" title="Linux系统"></a><strong>Linux系统</strong></h6><p><strong>使用yum 的设置代理的方法</strong></p><p>如果只需要使用yum来更新包的，只需进行yum配置即可。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vim /etc/yum.conf </span></span><br><span class="line">proxy=http://192.168.99.99:80</span><br><span class="line"><span class="comment">#proxy=ftp://192.168.99.99:80</span></span><br><span class="line"><span class="comment">#proxy_username=username                 #####代理的用户名</span></span><br><span class="line"><span class="comment">#proxy_password=password                  #####代理的密码</span></span><br><span class="line"><span class="comment">#然后直接用yum安装即可</span></span><br></pre></td></tr></table></figure><p><strong>wget设置代理的方法</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vim /etc/wgetrc</span></span><br><span class="line">http_proxy=192.168.99.99:80</span><br><span class="line">http_proxy=192.168.99.99:443</span><br></pre></td></tr></table></figure><p><strong>curl访问代理设置的方法</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#如果访问HTTP网站，可以直接这样的方式: curl --proxy proxy_server:80 http://www.taobao.com/</span></span><br><span class="line"><span class="comment">#如果访问HTTPS网站，例如https://www.alipay.com，那么可以使用nginx的HTTPS转发的server：</span></span><br><span class="line">curl --proxy proxy_server:443 http://www.alipay.com</span><br><span class="line"></span><br><span class="line">[root@localhost ~]<span class="comment"># curl -I --proxy 192.168.99.99:80 www.baidu.com    ###显示http访问的状态码</span></span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">备注：上边有介绍，详见上边内容。</span><br></pre></td></tr></table></figure><p><strong>使用设置全局代理的方法</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vim /etc/profile</span></span><br><span class="line">http_proxy = http://192.168.99.99:80</span><br><span class="line">http_proxy = http://192.168.99.99:443</span><br><span class="line">ftp_proxy = http://192.168.99.99:80/</span><br><span class="line"><span class="built_in">export</span> http_proxy</span><br><span class="line"><span class="built_in">export</span> ftp_proxy</span><br></pre></td></tr></table></figure><h4 id="反向代理配置"><a href="#反向代理配置" class="headerlink" title="反向代理配置"></a>反向代理配置</h4><p>反向代理的演示更为简单一些。<br>首先在/etc/nginx/conf.d/下新建一个default.conf:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  localhost nginx.tangll.cn;</span><br><span class="line">    location / &#123;</span><br><span class="line">        root   /usr/share/nginx/html;</span><br><span class="line">        index  index.html index.htm;</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">    #设置代理</span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://127.0.0.1:8080;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    error_page   500 502 503 504 404  /50x.html;</span><br><span class="line">    location = /50x.html &#123;</span><br><span class="line">        root   /usr/share/nginx/html;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>代理服务器站在客户端那边就是正向代理，代理服务器站在原始服务器那边就是反向代理, Nginx通过<code>proxy_pass</code>可以设置代理服务。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;在日常运维工作中，常常会用到反向代理，为了更安全同时为了负载均衡，分担压力。&lt;/p&gt;
&lt;p&gt;那么，有小伙伴就会有疑问：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;什么是反向代理？&lt;/li&gt;
&lt;li&gt;负载均衡又是怎么实现的？&lt;/li&gt;
&lt;li&gt;有反向代理那有正向代理吗？&lt;/li&gt;
&lt;li&gt;正向代理的应用场景是怎样的？&lt;/li&gt;
&lt;li&gt;反向代理和正向代理怎么配置实现呢？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;带着这些疑问，就给大家详细解释下nginx的正反向代理。&lt;/p&gt;
    
    </summary>
    
      <category term="Web服务" scheme="https://wandouduoduo.netlify.com/categories/Web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Nginx" scheme="https://wandouduoduo.netlify.com/categories/Web%E6%9C%8D%E5%8A%A1/Nginx/"/>
    
    
      <category term="Nginx" scheme="https://wandouduoduo.netlify.com/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>zookeeper集群脑裂探讨</title>
    <link href="https://wandouduoduo.netlify.com/articles/f714eb8e.html"/>
    <id>https://wandouduoduo.netlify.com/articles/f714eb8e.html</id>
    <published>2019-12-19T08:57:10.000Z</published>
    <updated>2019-12-26T03:34:41.315Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是脑裂"><a href="#什么是脑裂" class="headerlink" title="什么是脑裂"></a>什么是脑裂</h2><p>脑裂(split-brain)就是“大脑分裂”，也就是本来一个“大脑”被拆分了两个或多个“大脑”，我们都知道，如果一个人有多个大脑，并且相互独立的话，那么会导致人体“手舞足蹈”，“不听使唤”。</p><p>脑裂通常会出现在集群环境中，比如ElasticSearch、Zookeeper集群，而这些集群环境有一个统一的特点，就是它们有一个大脑，比如ElasticSearch集群中有Master节点，Zookeeper集群中有Leader节点。</p><p>本篇文章着重来给大家讲一下Zookeeper中的脑裂问题，以及是如果解决脑裂问题的。</p><a id="more"></a><h2 id="集群脑裂场景"><a href="#集群脑裂场景" class="headerlink" title="集群脑裂场景"></a>集群脑裂场景</h2><hr><p>对于一个集群，想要提高这个集群的可用性，通常会采用多机房部署，比如现在有一个由6台zkServer所组成的一个集群，部署在了两个机房：</p><p><img src="/articles/f714eb8e/2.png" alt="img"></p><p>正常情况下，此集群只会有一个Leader，那么如果机房之间的网络断了之后，两个机房内的zkServer还是可以相互通信的，如果<strong>不考虑过半机制</strong>，那么就会出现每个机房内部都将选出一个Leader。<img src="/articles/f714eb8e/1.png" alt="img"></p><p>这就相当于原本一个集群，被分成了两个集群，出现了两个“大脑”，这就是脑裂。</p><p>对于这种情况，我们也可以看出来，原本应该是统一的一个集群对外提供服务的，现在变成了两个集群同时对外提供服务，如果过了一会，断了的网络突然联通了，那么此时就会出现问题了，两个集群刚刚都对外提供服务了，数据该怎么合并，数据冲突怎么解决等等问题。</p><p>刚刚在说明脑裂场景时，有一个前提条件就是没有考虑过半机制，所以实际上Zookeeper集群中是不会出现脑裂问题的，而不会出现的原因就跟过半机制有关。</p><h2 id="过半机制"><a href="#过半机制" class="headerlink" title="过半机制"></a>过半机制</h2><p>在领导者选举的过程中，如果某台zkServer获得了超过半数的选票，则此zkServer就可以成为Leader了。</p><p>过半机制的源码实现其实非常简单：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">QuorumMaj</span> <span class="keyword">implements</span> <span class="title">QuorumVerifier</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(QuorumMaj.class);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span> half;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// n表示集群中zkServer的个数（准确的说是参与者的个数，参与者不包括观察者节点）</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">QuorumMaj</span><span class="params">(<span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.half = n/<span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 验证是否符合过半机制</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">containsQuorum</span><span class="params">(Set&lt;Long&gt; set)</span></span>&#123;</span><br><span class="line">        <span class="comment">// half是在构造方法里赋值的</span></span><br><span class="line">        <span class="comment">// set.size()表示某台zkServer获得的票数</span></span><br><span class="line">        <span class="keyword">return</span> (set.size() &gt; half);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>大家仔细看一下上面方法中的注释，核心代码就是下面两行：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">this.half = n/2;return (set.size() &gt; half);</span><br></pre></td></tr></table></figure><p>举个简单的例子：如果现在集群中有5台zkServer，那么half=5/2=2，那么也就是说，领导者选举的过程中至少要有三台zkServer投了同一个zkServer，才会符合过半机制，才能选出来一个Leader。</p><p>那么有一个问题我们想一下，<strong>选举的过程中为什么一定要有一个过半机制验证？</strong>因为这样不需要等待所有zkServer都投了同一个zkServer就可以选举出来一个Leader了，这样比较快，所以叫快速领导者选举算法呗。</p><p>那么再来想一个问题，<strong>过半机制中为什么是大于，而不是大于等于呢？</strong></p><p>这就是更脑裂问题有关系了，比如回到上文出现脑裂问题的场景：<img src="/articles/f714eb8e/3.png" alt="img"></p><p>当机房中间的网络断掉之后，机房1内的三台服务器会进行领导者选举，但是此时过半机制的条件是set.size() &gt; 3，也就是说至少要4台zkServer才能选出来一个Leader，所以对于机房1来说它不能选出一个Leader，同样机房2也不能选出一个Leader，这种情况下整个集群当机房间的网络断掉后，整个集群将没有Leader。没有Leader对外就不能提供服务。</p><p>而如果过半机制的条件是set.size() &gt;= 3，那么机房1和机房2都会选出一个Leader，这样就出现了脑裂。所以我们就知道了，为什么过半机制中是<strong>大于</strong>，而不是<strong>大于等于</strong>。就是为了防止脑裂。</p><p>如果假设我们现在只有5台机器，也部署在两个机房：<img src="/articles/f714eb8e/4.png" alt="img"></p><p>此时过半机制的条件是set.size() &gt; 2，也就是至少要3台服务器才能选出一个Leader，此时机房件的网络断开了，对于机房1来说是没有影响的，Leader依然还是Leader，对于机房2来说是选不出来Leader的，此时整个集群中只有一个Leader。</p><p>所以，我们可以总结得出，有了过半机制，对于一个Zookeeper集群，要么没有Leader，要没只有1个Leader，这样就避免了脑裂问题。</p><h2 id="奇偶节点数探讨"><a href="#奇偶节点数探讨" class="headerlink" title="奇偶节点数探讨"></a>奇偶节点数探讨</h2><p>命题：A,B两个机房5个节点和6个节点zookeeper节点比较。</p><p>5个节点：A机房3个，B机房2个。如果网络出现中断，根据过半机制原则, 大于2个节点就可以选举出来leader。那么结果就是A机房3个节点大于2，就可以正常选举出来Leader。B节点不大于2，不能选举出Leader。这时集群还是可以正常对外提供服务，只是节点少两个而已。当网络恢复后，B机房节点再加入到集群，集群恢复。</p><p>6个节点：A机房3个，B机房3个。如果网络出现中断，根据过半机制原则, 大于3个节点才可以选举出来leader。那么结果就是A机房3个节点不大于3，B节点也不大于3，两个机房都不能选举出Leader。而没有Leader集群就不能对外提供服务，造成整个集群不可用。违背了高可用的初衷。并且还多用一台服务器，还有搭建和维护成本。而且和5个节点冗余是一样的。</p><p>可能有同学会说那A机房4个，B节点2个不就可以了。是的，这样是可以，但是偶数是存在3，3分布的这种情况。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>综上所述，为了保证zookeeper集群高可用，防止脑裂。建议用奇数个zk节点，当然是大于2的奇数。奇数个zk节点有两个好处：1，奇数个节点可用节省一个节点的资源（服务器和部署及维护成本）。2，如为偶数个节点，因为过半机制的设定，有可能出现没有leader，造成整个集群不可以。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是脑裂&quot;&gt;&lt;a href=&quot;#什么是脑裂&quot; class=&quot;headerlink&quot; title=&quot;什么是脑裂&quot;&gt;&lt;/a&gt;什么是脑裂&lt;/h2&gt;&lt;p&gt;脑裂(split-brain)就是“大脑分裂”，也就是本来一个“大脑”被拆分了两个或多个“大脑”，我们都知道，如果一个人有多个大脑，并且相互独立的话，那么会导致人体“手舞足蹈”，“不听使唤”。&lt;/p&gt;
&lt;p&gt;脑裂通常会出现在集群环境中，比如ElasticSearch、Zookeeper集群，而这些集群环境有一个统一的特点，就是它们有一个大脑，比如ElasticSearch集群中有Master节点，Zookeeper集群中有Leader节点。&lt;/p&gt;
&lt;p&gt;本篇文章着重来给大家讲一下Zookeeper中的脑裂问题，以及是如果解决脑裂问题的。&lt;/p&gt;
    
    </summary>
    
      <category term="自动化" scheme="https://wandouduoduo.netlify.com/categories/%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
      <category term="Zookeeper" scheme="https://wandouduoduo.netlify.com/categories/%E8%87%AA%E5%8A%A8%E5%8C%96/Zookeeper/"/>
    
    
      <category term="Zookeeper" scheme="https://wandouduoduo.netlify.com/tags/Zookeeper/"/>
    
  </entry>
  
</feed>
