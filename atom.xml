<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>运维随笔</title>
  
  <subtitle>SRE &amp; Devops &amp; Architect</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://wandouduoduo.github.io/"/>
  <updated>2022-01-21T11:12:59.337Z</updated>
  <id>https://wandouduoduo.github.io/</id>
  
  <author>
    <name>豌豆多多</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Linux系统中信号篇</title>
    <link href="https://wandouduoduo.github.io/articles/8a41de2a.html"/>
    <id>https://wandouduoduo.github.io/articles/8a41de2a.html</id>
    <published>2022-01-21T10:48:45.000Z</published>
    <updated>2022-01-21T11:12:59.337Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>Linux 的命令行里面有用来停止正在运行的进程的所有所需工具。这里将为您讲述细节。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8a41de2a/1.jpg" alt></p><p><strong>想像一下</strong>：你打开了一个程序（可能来自于你的桌面菜单或者命令行），然后开始使用这个程序，没想到程序会锁死、停止运行、或者意外死机。你尝试再次运行该程序，但是它反馈说原来的进程没有完全关闭。</p><p><strong>你该怎么办</strong>？你要结束进程。但该如何做？不管你信与不信，最好的解决方法大都在命令行里。值得庆幸的是， Linux 有供用户杀死错误的进程的每个必要的工具，然而，你在执行杀死进程的命令之前，你首先需要知道进程是什么。该如何处理这一类的任务。一旦你能够掌握这种工具，它实际是十分简单的……</p><p>我来概述的步骤是每个 Linux 发行版都能用的，不论是桌面版还是服务器版。我将限定只使用命令行，请打开你的终端开始输入命令吧。</p><a id="more"></a><h2 id="定位进程"><a href="#定位进程" class="headerlink" title="定位进程"></a>定位进程</h2><p>杀死一个没有响应的进程的第一个步骤是定位这个进程。我用来定位进程的命令有两个：top 和 ps 命令。top 是每个系统管理员都知道的工具，用 top 命令，你能够知道到所有当前正在运行的进程有哪些。在命令行里，输入 top 命令能够就看到你正在运行的程序进程（图1）</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8a41de2a/2.jpg" alt></p><p>从显示的列表中你能够看到相当重要的信息，举个例子，Chrome 浏览器反映迟钝，依据我们的 top 命令显示，我们能够辨别的有四个 Chrome 浏览器的进程在运行，进程的 pid 号分别是 3827、3919、10764 和 11679。这个信息是重要的，可以用一个特殊的方法来结束进程。</p><p>尽管 top 命令很是方便，但也不是得到你所要信息最有效的方法。 你知道你要杀死的 Chrome 进程是那个，并且你也不想看 top 命令所显示的实时信息。 鉴于此，你能够使用 ps 命令然后用 grep 命令来过滤出输出结果。这个 ps 命令能够显示出当前进程列表的快照，然后用 grep 命令输出匹配的样式。我们通过 grep 命令过滤 ps 命令的输出的理由很简单：如果你只输入 ps 命令，你将会得到当前所有进程的列表快照，而我们需要的是列出 Chrome 浏览器进程相关的。所以这个命令是这个样子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ps aux | grep chrome</span><br><span class="line"></span><br><span class="line">这里 aux 选项如下所示：</span><br><span class="line"></span><br><span class="line">a = 显示所有用户的进程</span><br><span class="line">u = 显示进程的用户和拥有者</span><br><span class="line">x = 也显示不依附于终端的进程</span><br></pre></td></tr></table></figure><p>当你搜索图形化程序的信息时，这个 x 参数是很重要的。</p><p>当你输入以上命令的时候，你将会得到比图 2 更多的信息，而且它有时用起来比 top 命令更有效。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8a41de2a/3.jpg" alt></p><h2 id="结束进程"><a href="#结束进程" class="headerlink" title="结束进程"></a>结束进程</h2><p>现在我们开始结束进程的任务。我们有两种可以帮我们杀死错误的进程的信息。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">进程的名字</span><br><span class="line">进程的 ID （PID）</span><br></pre></td></tr></table></figure><p>你用哪一个将会决定终端命令如何使用，通常有两个命令来结束进程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">kill</span> - 通过进程 ID 来结束进程</span><br><span class="line">killall - 通过进程名字来结束进程</span><br></pre></td></tr></table></figure><p>有两个不同的信号能够发送给这两个结束进程的命令。你发送的信号决定着你想要从结束进程命令中得到的结果。举个例子，你可以发送 HUP（挂起）信号给结束进程的命令，命令实际上将会重启这个进程。当你需要立即重启一个进程（比如就守护进程来说），这是一个明智的选择。你通过输入 kill -l 可以得到所有信号的列表，你将会发现大量的信号。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8a41de2a/4.jpg" alt></p><p>最经常使用的结束进程的信号是：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8a41de2a/5.png" alt="1642762726720"><br>好的是，你能用信号值来代替信号名字。所以你没有必要来记住所有各种各样的信号名字。</p><p>所以，让我们现在用 kill 命令来杀死 Chrome 浏览器的进程。这个命令的结构是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">kill</span> SIGNAL PID</span><br></pre></td></tr></table></figure><p>这里 SIGNAL 是要发送的信号，PID 是被杀死的进程的 ID。我们已经知道，来自我们的 ps 命令显示我们想要结束的进程 ID 号是 3827、3919、10764 和 11679。所以要发送结束进程信号，我们输入以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">kill</span> -9 3827</span><br><span class="line"><span class="built_in">kill</span> -9 3919</span><br><span class="line"><span class="built_in">kill</span> -9 10764</span><br><span class="line"><span class="built_in">kill</span> -9 11679</span><br></pre></td></tr></table></figure><p>一旦我们输入了以上命令，Chrome 浏览器的所有进程将会成功被杀死。</p><p>我们有更简单的方法！如果我们已经知道我们想要杀死的那个进程的名字，我们能够利用 killall 命令发送同样的信号，像这样：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">killall -9 chrome</span><br></pre></td></tr></table></figure><p>附带说明的是，上边这个命令可能不能捕捉到所有正在运行的 Chrome 进程。如果，运行了上边这个命令之后，你输入 ps aux | grep chrome 命令过滤一下，看到剩下正在运行的 Chrome 进程有那些，最好的办法还是回到 kIll 命令通过进程 ID 来发送信号值 9 来结束这个进程。</p><h2 id="结束进程很容易"><a href="#结束进程很容易" class="headerlink" title="结束进程很容易"></a>结束进程很容易</h2><p>正如你看到的，杀死错误的进程并没有你原本想的那样有挑战性。当我让一个顽固的进程结束的时候，我趋向于用 killall命令来作为有效的方法来终止，然而，当我让一个真正的活跃的进程结束的时候，kill命令是一个好的方法。</p><h2 id="精髓补充"><a href="#精髓补充" class="headerlink" title="精髓补充"></a>精髓补充</h2><p>根据上面的kill停止，大家基本上了解了信号的概念，那么这些信号是怎么产生的呢？每个信号有有什么用呢？这里详细和大家聊聊。</p><p>linux中信号，编号为1 ~ 31的信号为传统UNIX支持的信号，是<strong>不可靠信号(非实时的)</strong>，编号为32 ~ 63的信号是后来扩充的，称做<strong>可靠信号(实时信号)</strong>。</p><p>不可靠信号和可靠信号的<strong>区别</strong>在于<strong>前者不支持排队，可能会造成信号丢失，而后者不会</strong>。</p><p>下面我们对编号小于SIGRTMIN的信号进行讨论。 </p><p>1) <strong>SIGHUP</strong>   该信号在用户终端连接(正常或非正常)结束时发出, 通常是在终端的控制进程结束时, 通知同一session内的各个作业, 这时它们与控制终端不再关联。 当登录Linux时，系统会分配给登录用户一个终端(Session)。在这个终端运行的所有程序，包括前台进程组和后台进程组，一般都属于这个Session。当用户退出Linux登录时，前台进程组和后台有对终端输出的进程将会收到SIGHUP信号。这个信号的默认操作为终止进程，因此前台进程组和后台有终端输出的进程就会中止。不过可以捕获这个信号，比如wget能捕获SIGHUP信号，并忽略它，这样就算退出了Linux登录，wget也能继续下载。 此外，对于与终端脱离关系的守护进程，这个信号用于通知它重新读取配置文件。 </p><p>2) <strong>SIGINT</strong>    程序终止(interrupt)信号, 在用户键入INTR字符(通常是Ctrl-C)时发出，用于通知前台进程组终止进程。 </p><p>3) <strong>SIGQUIT</strong> 和SIGINT类似, 但由QUIT字符(通常是Ctrl-)来控制. 进程在因收到SIGQUIT退出时会产生core文件, 在这个意义上类似于一个程序错误信号。 </p><p>4) <strong>SIGILL</strong> 执行了非法指令. 通常是因为可执行文件本身出现错误, 或者试图执行数据段. 堆栈溢出时也有可能产生这个信号。 </p><p>5) <strong>SIGTRAP</strong> 由断点指令或其它trap指令产生. 由debugger使用。 </p><p>6) <strong>SIGABRT</strong> 调用abort函数生成的信号。 </p><p>7) <strong>SIGBUS</strong> 非法地址, 包括内存地址对齐(alignment)出错。比如访问一个四个字长的整数, 但其地址不是4的倍数。它与SIGSEGV的区别在于后者是由于对合法存储地址的非法访问触发的(如访问不属于自己存储空间或只读存储空间)。 </p><p>8) <strong>SIGFPE</strong> 在发生致命的算术运算错误时发出. 不仅包括浮点运算错误, 还包括溢出及除数为0等其它所有的算术的错误。 </p><p>9) <strong>SIGKILL</strong> 用来立即结束程序的运行. 本信号不能被阻塞、处理和忽略。如果管理员发现某个进程终止不了，可尝试发送这个信号。 </p><p>10) <strong>SIGUSR1</strong> 留给用户使用 </p><p>11) <strong>SIGSEGV</strong> 试图访问未分配给自己的内存, 或试图往没有写权限的内存地址写数据. </p><p>12) <strong>SIGUSR2</strong> 留给用户使用 </p><p>13) <strong>SIGPIPE</strong> 管道破裂。这个信号通常在进程间通信产生，比如采用FIFO(管道)通信的两个进程，读管道没打开或者意外终止就往管道写，写进程会收到SIGPIPE信号。此外用Socket通信的两个进程，写进程在写Socket的时候，读进程已经终止。 </p><p>14) <strong>SIGALRM</strong> 时钟定时信号, 计算的是实际的时间或时钟时间. alarm函数使用该信号. </p><p>15) <strong>SIGTERM</strong> 程序结束(terminate)信号, 与SIGKILL不同的是该信号可以被阻塞和处理。通常用来要求程序自己正常退出，shell命令kill缺省产生这个信号。如果进程终止不了，我们才会尝试SIGKILL。 </p><p>17) <strong>SIGCHLD</strong> 子进程结束时, 父进程会收到这个信号。 如果父进程没有处理这个信号，也没有等待(wait)子进程，子进程虽然终止，但是还会在内核进程表中占有表项，这时的子进程称为僵尸进程。这种情况我们应该避免(父进程或者忽略SIGCHILD信号，或者捕捉它，或者wait它派生的子进程，或者父进程先终止，这时子进程的终止自动由init进程来接管)。 </p><p>18) <strong>SIGCONT</strong> 让一个停止(stopped)的进程继续执行. 本信号不能被阻塞. 可以用一个handler来让程序在由stopped状态变为继续执行时完成特定的工作. 例如, 重新显示提示符 </p><p>19) <strong>SIGSTOP</strong> 停止(stopped)进程的执行. 注意它和terminate以及interrupt的区别:该进程还未结束, 只是暂停执行. 本信号不能被阻塞, 处理或忽略. </p><p>20) <strong>SIGTSTP</strong> 停止进程的运行, 但该信号可以被处理和忽略. 用户键入SUSP字符时(通常是Ctrl-Z)发出这个信号 </p><p>21) <strong>SIGTTIN</strong> 当后台作业要从用户终端读数据时, 该作业中的所有进程会收到SIGTTIN信号. 缺省时这些进程会停止执行. </p><p>22) <strong>SIGTTOU</strong> 类似于SIGTTIN, 但在写终端(或修改终端模式)时收到. </p><p>23) <strong>SIGURG</strong> 有”紧急”数据或out-of-band数据到达socket时产生. </p><p>24) <strong>SIGXCPU</strong> 超过CPU时间资源限制. 这个限制可以由getrlimit/setrlimit来读取/改变。 </p><p>25) <strong>SIGXFSZ</strong> 当进程企图扩大文件以至于超过文件大小资源限制。 </p><p>26) <strong>SIGVTALRM</strong> 虚拟时钟信号. 类似于SIGALRM, 但是计算的是该进程占用的CPU时间. </p><p>27) <strong>SIGPROF</strong> 类似于SIGALRM/SIGVTALRM, 但包括该进程用的CPU时间以及系统调用的时间. </p><p>28) <strong>SIGWINCH</strong> 窗口大小改变时发出. </p><p>29) <strong>SIGIO</strong> 文件描述符准备就绪, 可以开始进行输入/输出操作. </p><p>30) <strong>SIGPWR</strong> Power failure </p><p>31) <strong>SIGSYS</strong> 非法的系统调用。 </p><p>在以上列出的信号中</p><p>程序不可捕获、阻塞或忽略的信号有：SIGKILL,SIGSTOP </p><p>不能恢复至默认动作的信号有：SIGILL,SIGTRAP </p><p>默认会导致进程流产的信号有：SIGABRT,SIGBUS,SIGFPE,SIGILL,SIGIOT,SIGQUIT,SIGSEGV,SIGTRAP,SIGXCPU,SIGXFSZ </p><p>默认会导致进程退出的信号有：SIGALRM,SIGHUP,SIGINT,SIGKILL,SIGPIPE,SIGPOLL,SIGPROF,SIGSYS,SIGTERM,SIGUSR1,SIGUSR2,SIGVTALRM 默认会导致进程停止的信号有：SIGSTOP,SIGTSTP,SIGTTIN,SIGTTOU </p><p>默认进程忽略的信号有：SIGCHLD,SIGPWR,SIGURG,SIGWINCH </p><p>此外，SIGIO在SVR4是退出，在4.3BSD中是忽略；SIGCONT在进程挂起时是继续，否则是忽略，不能被阻塞</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Linux 的命令行里面有用来停止正在运行的进程的所有所需工具。这里将为您讲述细节。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8a41de2a/1.jpg&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;想像一下&lt;/strong&gt;：你打开了一个程序（可能来自于你的桌面菜单或者命令行），然后开始使用这个程序，没想到程序会锁死、停止运行、或者意外死机。你尝试再次运行该程序，但是它反馈说原来的进程没有完全关闭。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;你该怎么办&lt;/strong&gt;？你要结束进程。但该如何做？不管你信与不信，最好的解决方法大都在命令行里。值得庆幸的是， Linux 有供用户杀死错误的进程的每个必要的工具，然而，你在执行杀死进程的命令之前，你首先需要知道进程是什么。该如何处理这一类的任务。一旦你能够掌握这种工具，它实际是十分简单的……&lt;/p&gt;
&lt;p&gt;我来概述的步骤是每个 Linux 发行版都能用的，不论是桌面版还是服务器版。我将限定只使用命令行，请打开你的终端开始输入命令吧。&lt;/p&gt;
    
    </summary>
    
      <category term="操作系统" scheme="https://wandouduoduo.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="Linux" scheme="https://wandouduoduo.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux/"/>
    
    
      <category term="Linux" scheme="https://wandouduoduo.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Linux禁止普通用户su至root的解决方法</title>
    <link href="https://wandouduoduo.github.io/articles/952bb64d.html"/>
    <id>https://wandouduoduo.github.io/articles/952bb64d.html</id>
    <published>2021-08-31T09:38:53.000Z</published>
    <updated>2021-08-31T09:47:40.189Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>很多朋友不清楚linux如何禁止普通用户su到root，这里需要修改两个配置文件，具体详细配置大家通过本文了解下吧</p><a id="more"></a><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>为禁止普通用户su至root，需要分别修改/etc/pam.d/su和/etc/login.defs两个配置文件。</p><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>(1)<strong>去除</strong>/etc/pam.d/su文件中如下行的注释：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#auth      required    pam_wheel.so use_uid</span></span><br></pre></td></tr></table></figure><p>(2)在／etc/login.defs文件中加入如下配置项：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SU_WHEEL_ONLY  yes</span><br></pre></td></tr></table></figure><p>经过上述配置后，普通用户将被禁止su至root，如果希望指定普通用户su至root，可以执行如下命令将该用户添加至wheel组中：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">usermod -G wheel username</span><br></pre></td></tr></table></figure><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@titan ~]<span class="comment"># id apple</span></span><br><span class="line">uid=1001(apple) gid=1001(fruit) 组=1001(fruit),10(wheel)</span><br><span class="line">[root@titan ~]<span class="comment"># id banana</span></span><br><span class="line">uid=1002(banana) gid=1001(fruit) 组=1001(fruit)</span><br></pre></td></tr></table></figure><p>验证apple</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[apple@titan ~]$ su - root</span><br><span class="line">[root@titan ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure><p>验证banana</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[banana@titan ~]$ su - root</span><br><span class="line">su: 拒绝权限</span><br><span class="line">[banana@titan ~]$</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>以上所述是站长给大家介绍的Linux禁止普通用户su至root的解决方法，希望对大家有所帮助，如果大家有任何疑问请给我留言，站长会及时回复大家的。</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;很多朋友不清楚linux如何禁止普通用户su到root，这里需要修改两个配置文件，具体详细配置大家通过本文了解下吧&lt;/p&gt;
    
    </summary>
    
      <category term="操作系统" scheme="https://wandouduoduo.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="Linux" scheme="https://wandouduoduo.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux/"/>
    
    
      <category term="Linux" scheme="https://wandouduoduo.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Linux文件系统卸载小技巧解决大问题</title>
    <link href="https://wandouduoduo.github.io/articles/fe844df6.html"/>
    <id>https://wandouduoduo.github.io/articles/fe844df6.html</id>
    <published>2021-07-12T07:27:57.000Z</published>
    <updated>2021-08-31T09:47:40.187Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>现在系统功能越来越丰富，那么响应的开发资源需要的越来越多，文件存储也越来越必要。无论是你用nfs、glusterfs等等，都需要在linux服务器中设置挂载点并执行挂载后才可使用，但如果fs文件系统有调整，那么可能就需要卸载umount,重新挂载，但是你真的可以顺顺利利的卸载吗？不见得，因为可能有应用在占用该磁盘或者系统在fstab中写入了磁盘自动挂载，本文就详细给你介绍个小技巧，帮你解决该烦恼。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/fe844df6/1.png" alt="1626075503955"></p><a id="more"></a><h2 id="场景一：磁盘正有程序占用"><a href="#场景一：磁盘正有程序占用" class="headerlink" title="场景一：磁盘正有程序占用"></a>场景一：磁盘正有程序占用</h2><p>但出现这种情况时，可以根据提示用lsof 或fuser来判断有哪些进程正在占用该磁盘，停掉改进程，重新挂载后再重新启动进程应用即可。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/fe844df6/2.png" alt></p><p>可以根据图上看到，找到了进程16011占用了该文件系统，并可以准确看到该进程是哪些应用，并占用了哪些文件等信息。</p><p><strong>科普</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fuser -m -v /mnt</span><br></pre></td></tr></table></figure><p>可以查看到当前占用/mnt目录的进程号，然后用kill杀死它。</p><p>也可以直接杀死这个进程</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fuser -m -k /mnt</span><br></pre></td></tr></table></figure><p>如果你不是很明确是否要杀死所有霸占设备的程序，你还可以加一个 -i 参数，这样每杀死一个程序前，都会询问,加参数-i </p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fuser -m -v -i -k /mnt</span><br></pre></td></tr></table></figure><p>-m :  表明指定的路径是一个挂载点显示所有使用指定文件系统的进程。后面可以跟挂载点或dev设备</p><p>-v :    给出详细的输出。可以给出了占用磁盘程序的详细信息，如进程号等。</p><h2 id="场景二：内核占用"><a href="#场景二：内核占用" class="headerlink" title="场景二：内核占用"></a>场景二：内核占用</h2><p>应用程序占用可以根据场景一操作拿到进程id，你就可以对它为所欲为了。但是场景一图中有一个隐藏的信息，可能有同学已经发现</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/fe844df6/3.png" alt></p><p>PID:  kernel这个是内核占用着该磁盘，要怎么去杀掉呢。这又是怎么造成的呢？</p><p>出现这种情况是因为在linux系统fstab中添加的文件磁盘，那么在系统启动时，内核自动挂载该磁盘，所有就是内核进程。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/fe844df6/4.png" alt></p><p>那有办法解决吗？答案是肯定的，要不就不会有本教程了。</p><p><strong>方法一</strong></p><p>既然内核占有，那么先把fstab中fs挂载点删掉，并重启服务器，那么重启时内核重新加载，就不会再占用了。</p><p>但是对于生产环境，业务应用在线上跑，有没有不用重启，还能解决挂载问题的呢？</p><p><strong>方法二</strong></p><p>lazy umount法，使用如下命令和参数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">umount -l /mnt</span><br></pre></td></tr></table></figure><p>–l ：并不是马上umount，而是在该目录空闲后再umount。</p><p><strong>请注意，该方法并不是完全安全的，它主要完成如下操作：</strong></p><p>1，立即从目录结构中实现卸载，即新进程将无法通过/media/disk访问,该磁盘。</p><p>2，正在访问该文件系统的程序不受影响。即正在操作/media/disk的进程不会被打断，且仍可以读写磁盘中的所有文件。如果所有进程对/media/disk的操作都执行完，那么才真正地umount。</p><p>由此可知，lazy umount并没有真正实现umount，仅用于特殊需要的情况。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>被应用程序占用，找到进程号，停掉应用解除占用就可卸载。如果是内核占用，可以重启或用lazy  umount来解决。但都有优劣点，需要自行把握。</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;现在系统功能越来越丰富，那么响应的开发资源需要的越来越多，文件存储也越来越必要。无论是你用nfs、glusterfs等等，都需要在linux服务器中设置挂载点并执行挂载后才可使用，但如果fs文件系统有调整，那么可能就需要卸载umount,重新挂载，但是你真的可以顺顺利利的卸载吗？不见得，因为可能有应用在占用该磁盘或者系统在fstab中写入了磁盘自动挂载，本文就详细给你介绍个小技巧，帮你解决该烦恼。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/fe844df6/1.png&quot; alt=&quot;1626075503955&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="操作系统" scheme="https://wandouduoduo.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
      <category term="Linux" scheme="https://wandouduoduo.github.io/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/Linux/"/>
    
    
      <category term="Linux" scheme="https://wandouduoduo.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>详解TcpDump神器</title>
    <link href="https://wandouduoduo.github.io/articles/b667fec3.html"/>
    <id>https://wandouduoduo.github.io/articles/b667fec3.html</id>
    <published>2021-07-02T03:24:31.000Z</published>
    <updated>2021-08-31T09:47:40.191Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>今天要给大家介绍的一个类Unix下的一个网络数据采集分析工具 – Tcpdump，也就是我们常说的抓包工具。与它功能类似的工具有 wireshark。不同的是wireshark有图形化界面，而tcpdump 则只有命令行。</p><p>作为一个运维，经常和服务器打交道，但服务器追求性能很少安装图形界面，因此直接跳过wireshark，直接给大家介绍这个tcpdump神器。</p><p>这篇文章借助于很多帮助文档，终于把tcpdump的用法全部研究了个遍。毫不夸张的说，应该可以算是中文里把 tcpdump 讲得最清楚明白，并且最全的文章了。所以<strong>本文值得你收藏分享，就怕你错过了，就再也找不到像这样把 tcpdump 讲得直白而且特全的文章了</strong>。</p><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>操作系统：CentOS 7.2   </p><p>tcpdump版本：v4.5.1 </p><h2 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h2><p><strong>tcpdump核心参数图解</strong></p><p>大家都知道，网络上的流量、数据包非常的多，因此要想抓到我们所需要的数据包，就需要我们定义一个精准的过滤器，把这些目标数据包，从巨大的数据包网络中抓取出来。</p><p>所以学习抓包工具，其实就是学习如何定义过滤器的过程。</p><p>而在 tcpdump 的世界里，过滤器的实现，都是通过一个又一个的参数组合起来，一个参数不够精准，那就再加一个，直到我们能过滤掉无用的数据包，只留下我们感兴趣的数据包。</p><p>tcpdump 的参数非常的多，初学者在没有掌握 tcpdump 时，会对这个命令的众多参数产生很多的疑惑。</p><p>就比如下面这个命令，我们要通过 host 参数指定 host ip 进行过滤</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump host 192.168.10.100</span><br></pre></td></tr></table></figure><p>主程序 + 参数名+ 参数值 这样的组合才是我们正常认知里面命令行该有的样子。</p><p>可 tcpdump 却不走寻常路，我们居然还可以在 host 前再加一个限定词，来缩小过滤的范围？</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump src host 192.168.10.100</span><br></pre></td></tr></table></figure><p>从字面上理解，确实很容易理解，但是这不符合编写命令行程序的正常逻辑，导致我们会有所疑虑：</p><p>除 src ，dst  还有其它可以的限定词？src，host 应该如何理解它们，叫参数名？不合适，因为 src 明显不合适。如果你在网上看到有关 tcpdump 的博客、教程，无一不是给你一个参数组合，告诉你这是实现了怎样的一个过滤器？这样的教学方式，很容易让你依赖别人的文章来使用 tcpdump，而不能将 tcpdump 这样神器消化，并达到灵活应用，灵活搭配过滤器的效果。</p><p>上面加了 src 本身就颠覆了我们的认知，你可知道在 src 之前还可以加更多的条件，比如 tcp, udp, icmp 等词，在你之前的基础上再过滤一层。如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump tcp src host 192.168.10.100</span><br></pre></td></tr></table></figure><p>这种参数的不确定性，让大多数人对 tcpdump 的学习始终无法得其精髓。</p><p>因此，在学习 tcpdump 之前，我觉得有必要要先让你知道：<strong>tcpdump 的参数是如何组成的？这非常重要。</strong></p><p>为此画了一张图，方便你直观的理解 tcpdump 的各种参数：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/b667fec3/1.png" alt="img"></p><ol><li>option 可选参数：将在后边一一解释，对应本文 <strong>第四章：可选参数解析</strong></li><li>proto 类过滤器：根据协议进行过滤，可识别的关键词有：upd, udp, icmp, ip, ip6, arp, rarp,ether,wlan, fddi, tr, decnet等</li><li>type 类过滤器：可识别的关键词有：host, net, port, portrange等，这些词后边需要再接参数。</li><li>direction 类过滤器：根据数据流向进行过滤，可识别的关键字有：src, dst，同时你可以使用逻辑运算符进行组合，比如 src or dst</li></ol><p>proto、type、direction 这三类过滤器的内容比较简单，也最常用，因此我将其放在最前面，也就是 <strong>第三章：常规过滤规则</strong>一起介绍。</p><p>而 option 可选的参数非常多，有的甚至也不经常用到，因此我将其放到后面一点，也就是 <strong>第四章：可选参数解析</strong></p><p>当你看完前面六章，你对 tcpdump 的认识会上了一个台阶，至少能够满足你 80% 的使用需求。</p><p><strong>你一定会问了，还有 20% 呢？</strong></p><p>其实 tcpdump 还有一些过滤关键词，它不符合以上四种过滤规则，可能需要你单独记忆。关于这部分我会在 <strong>第六章：特殊过滤规则</strong> 里进行介绍。</p><h2 id="第二章"><a href="#第二章" class="headerlink" title="第二章"></a>第二章</h2><p><strong>理解 tcpdump 的输出</strong></p><p><strong>2.1 输出内容结构</strong></p><p>tcpdump 输出的内容虽然多，却很规律。</p><p>这里以我随便抓取的一个 tcp 包为例来看一下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">21:26:49.013621 IP 172.20.20.1.15605 &gt; 172.20.20.2.5920: Flags [P.], seq 49:97, ack 106048, win 4723, length 48</span><br></pre></td></tr></table></figure><p>从上面的输出来看，可以总结出：</p><ol><li>第一列：时分秒毫秒 21:26:49.013621</li><li>第二列：网络协议 IP</li><li>第三列：发送方的ip地址+端口号，其中172.20.20.1是 ip，而15605 是端口号</li><li>第四列：箭头 &gt;， 表示数据流向</li><li>第五列：接收方的ip地址+端口号，其中 172.20.20.2 是 ip，而5920 是端口号</li><li>第六列：冒号</li><li>第七列：数据包内容，包括Flags 标识符，seq 号，ack 号，win 窗口，数据长度 length，其中 [P.] 表示 PUSH 标志位为 1，更多标识符见下面</li></ol><p><strong>2.2 Flags 标识符</strong></p><p>使用 tcpdump 抓包后，会遇到的 TCP 报文 Flags，有以下几种：</p><ul><li>[S] : SYN（开始连接）</li><li>[P] : PSH（推送数据）</li><li>[F] : FIN （结束连接）</li><li>[R] : RST（重置连接）</li><li>[.] : 没有 Flag，由于除了 SYN 包外所有的数据包都有ACK，所以一般这个标志也可表示 ACK</li></ul><h2 id="第三章"><a href="#第三章" class="headerlink" title="第三章"></a>第三章</h2><p><strong>常规过滤规则</strong></p><p><strong>3.1 基于IP地址过滤：host</strong></p><p>使用 host 就可以指定 host ip 进行过滤</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump host 192.168.10.100</span><br></pre></td></tr></table></figure><p>数据包的 ip 可以再细分为源ip和目标ip两种</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据源ip进行过滤</span></span><br><span class="line">$ tcpdump -i eth2 src 192.168.10.100</span><br><span class="line"><span class="comment"># 根据目标ip进行过滤</span></span><br><span class="line">$ tcpdump -i eth2 dst 192.168.10.200</span><br></pre></td></tr></table></figure><p><strong>3.2 基于网段进行过滤：net</strong></p><p>若你的ip范围是一个网段，可以直接这样指定</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump net 192.168.10.0/24</span><br></pre></td></tr></table></figure><p>网段同样可以再细分为源网段和目标网段</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据源网段进行过滤</span></span><br><span class="line">$ tcpdump src net 192.168</span><br><span class="line"><span class="comment"># 根据目标网段进行过滤</span></span><br><span class="line">$ tcpdump dst net 192.168</span><br></pre></td></tr></table></figure><p><strong>3.3 基于端口进行过滤：port</strong></p><p>使用 port 就可以指定特定端口进行过滤</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump port 8088</span><br></pre></td></tr></table></figure><p>端口同样可以再细分为源端口，目标端口</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据源端口进行过滤</span></span><br><span class="line">$ tcpdump src port 8088</span><br><span class="line"><span class="comment"># 根据目标端口进行过滤</span></span><br><span class="line">$ tcpdump dst port 8088</span><br></pre></td></tr></table></figure><p>如果你想要同时指定两个端口你可以这样写</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump port 80 or port 8088</span><br></pre></td></tr></table></figure><p>但也可以简写成这样</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump port 80 or 8088</span><br></pre></td></tr></table></figure><p>如果你的想抓取的不再是一两个端口，而是一个范围，一个一个指定就非常麻烦了，此时你可以这样指定一个端口段。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump portrange 8000-8080</span><br><span class="line">$ tcpdump src portrange 8000-8080</span><br><span class="line">$ tcpdump dst portrange 8000-8080</span><br></pre></td></tr></table></figure><p>对于一些常见协议的默认端口，我们还可以直接使用协议名，而不用具体的端口号。如http=80，https = 443 等</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump tcp port http</span><br></pre></td></tr></table></figure><p><strong>3.4 基于协议进行过滤：proto</strong></p><p>常见的网络协议有：tcp, udp, icmp, http, ip,ipv6 等</p><p>若你只想查看 icmp 的包，可以直接这样写</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump icmp</span><br><span class="line"></span><br><span class="line"><span class="comment">#protocol可选值：ip, ip6, arp, rarp, atalk, aarp, decnet, sca, lat, mopdl, moprc, iso, stp, ipx, or netbeui</span></span><br></pre></td></tr></table></figure><p><strong>3.5 基本IP协议的版本进行过滤</strong></p><p>当你想查看 tcp 的包，你也许会这样写</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump tcp</span><br></pre></td></tr></table></figure><p>这样写也没问题，就是不够精准，为什么这么说呢？</p><p>ip 根据版本的不同，可以再细分为 IPv4 和 IPv6 两种，如果你只指定了 tcp，这两种其实都会包含在内。</p><p>那有什么办法，能够将 IPv4 和 IPv6 区分开来呢？</p><p>很简单，如果是 IPv4 的 tcp 包 ，就这样写（友情提示：数字 6 表示的是 tcp 在ip报文中的编号。）</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump <span class="string">'ip proto tcp'</span></span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">$ tcpdump ip proto 6</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">$ tcpdump <span class="string">'ip protochain tcp'</span></span><br><span class="line"><span class="comment"># or </span></span><br><span class="line">$ tcpdump ip protochain 6</span><br></pre></td></tr></table></figure><p>而如果是 IPv6 的 tcp 包 ，就这样写</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump <span class="string">'ip6 proto tcp'</span></span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">$ tcpdump ip6 proto 6</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">$ tcpdump <span class="string">'ip6 protochain tcp'</span></span><br><span class="line"><span class="comment"># or </span></span><br><span class="line">$ tcpdump ip6 protochain 6</span><br></pre></td></tr></table></figure><p>关于上面这几个命令示例，有两点需要注意：</p><p>跟在 proto 和 protochain 后面的如果是 tcp, udp, icmp ，那么过滤器需要用引号包含，这是因为 tcp,udp, icmp 是 tcpdump 的关键字。跟在ip 和 ip6 关键字后面的 proto 和 protochain 是两个新面孔，看起来用法类似，它们是否等价，又有什么区别呢？关于第二点，网络上没有找到很具体的答案，我只能通过 man tcpdump 的提示， 给出自己的个人猜测，但不保证正确。</p><p>proto 后面跟的 <protocol> 的关键词是固定的，只能是 ip, ip6, arp, rarp, atalk, aarp, decnet, sca, lat, mopdl, moprc, iso, stp, ipx, or netbeui 这里面的其中一个。</protocol></p><p>而 protochain 后面跟的 protocol 要求就没有那么严格，它可以是任意词，只要 tcpdump 的 IP 报文头部里的 protocol 字段为 <protocol> 就能匹配上。</protocol></p><p>理论上来讲，下面两种写法效果是一样的</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump <span class="string">'ip &amp;&amp; tcp'</span>$ tcpdump <span class="string">'ip proto tcp'</span></span><br></pre></td></tr></table></figure><p>同样的，这两种写法也是一样的</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump <span class="string">'ip6 &amp;&amp; tcp'</span>$ tcpdump <span class="string">'ip6 proto tcp'</span></span><br></pre></td></tr></table></figure><h2 id="第四章"><a href="#第四章" class="headerlink" title="第四章"></a>第四章</h2><p><strong>可选参数解析</strong></p><p><strong>4.1 设置不解析域名提升速度</strong></p><ul><li>-n：不把ip转化成域名，直接显示 ip，避免执行 DNS lookups 的过程，速度会快很多</li><li>-nn：不把协议和端口号转化成名字，速度也会快很多。</li><li>-N：不打印出host 的域名部分.。比如,，如果设置了此选现，tcpdump 将会打印’nic’ 而不是 ‘nic.ddn.mil’</li></ul><p>​    </p><p><strong>4.2 过滤结果输出到文件</strong></p><p>使用 tcpdump 工具抓到包后，往往需要再借助其他的工具进行分析，比如常见的 wireshark 。</p><p>而要使用wireshark ，我们得将 tcpdump 抓到的包数据生成到文件中，最后再使用 wireshark 打开它即可。</p><p>使用 -w 参数后接一个以 .pcap 后缀命令的文件名，就可以将 tcpdump 抓到的数据保存到文件中。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump icmp -w icmp.pcap</span><br></pre></td></tr></table></figure><p><strong>4.3 从文件中读取包数据</strong></p><p>使用 -w 是写入数据到文件，而使用 -r 是从文件中读取数据。</p><p>读取后，我们照样可以使用上述的过滤器语法进行过滤分析。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump icmp -r all.pcap</span><br></pre></td></tr></table></figure><p><strong>4.4 控制详细内容的输出</strong></p><ul><li>-v：产生详细的输出. 比如包的TTL，id标识，数据包长度，以及IP包的一些选项。同时它还会打开一些附加的包完整性检测，比如对IP或ICMP包头部的校验和。</li><li>-vv：产生比-v更详细的输出. 比如NFS回应包中的附加域将会被打印, SMB数据包也会被完全解码。（摘自网络，目前我还未使用过）</li><li>-vvv：产生比-vv更详细的输出。比如 telent 时所使用的SB, SE 选项将会被打印, 如果telnet同时使用的是图形界面，其相应的图形选项将会以16进制的方式打印出来（摘自网络，目前我还未使用过）</li></ul><p><strong>4.5 控制时间的显示</strong></p><ul><li>-t：在每行的输出中不输出时间</li><li>-tt：在每行的输出中会输出时间戳</li><li>-ttt：输出每两行打印的时间间隔(以毫秒为单位)-tttt：在每行打印的时间戳之前添加日期的打印（此种选项，输出的时间最直观）</li></ul><p><strong>4.6 显示数据包的头部</strong></p><ul><li>-x：以16进制的形式打印每个包的头部数据（但不包括数据链路层的头部）</li><li>-xx：以16进制的形式打印每个包的头部数据（包括数据链路层的头部）</li><li>-X：以16进制和 ASCII码形式打印出每个包的数据(但不包括连接层的头部)，这在分析一些新协议的数据包很方便。</li><li>-XX：以16进制和 ASCII码形式打印出每个包的数据(包括连接层的头部)，这在分析一些新协议的数据包很方便。</li></ul><p><strong>4.7 过滤指定网卡的数据包</strong></p><p>-i：指定要过滤的网卡接口，如果要查看所有网卡，可以 -i any</p><p><strong>4.8 过滤特定流向的数据包</strong></p><p>-Q：选择是入方向还是出方向的数据包，可选项有：in, out, inout，也可以使用 –direction=[direction] 这种写法<strong>4.9 其他常用的一些参数</strong></p><ul><li>-A：以ASCII码方式显示每一个数据包(不显示链路层头部信息). 在抓取包含网页数据的数据包时, 可方便查看数据</li><li>-l : 基于行的输出，便于你保存查看，或者交给其它工具分析</li><li>-q : 简洁地打印输出。即打印很少的协议相关信息, 从而输出行都比较简短.</li><li>-c : 捕获 count 个包 tcpdump 就退出</li><li>-s : tcpdump 默认只会截取前 96 字节的内容，要想截取所有的报文内容，可以使用 -s number， number 就是你要截取的报文字节数，如果是 0 的话，表示截取报文全部内容。</li><li>-S : 使用绝对序列号，而不是相对序列号</li><li>-C：file-size，tcpdump 在把原始数据包直接保存到文件中之前, 检查此文件大小是否超过file-size. 如果超过了, 将关闭此文件,另创一个文件继续用于原始数据包的记录. 新创建的文件名与-w 选项指定的文件名一致, 但文件名后多了一个数字.该数字会从1开始随着新创建文件的增多而增加. file-size的单位是百万字节(nt: 这里指1,000,000个字节,并非1,048,576个字节, 后者是以1024字节为1k, 1024k字节为1M计算所得, 即1M=1024 ＊ 1024 ＝ 1,048,576)</li><li>-F：使用file 文件作为过滤条件表达式的输入, 此时命令行上的输入将被忽略.</li></ul><p><strong>4.10 对输出内容进行控制的参数</strong></p><ul><li>-D : 显示所有可用网络接口的列表</li><li>-e : 每行的打印输出中将包括数据包的数据链路层头部信息</li><li>-E : 揭秘IPSEC数据</li><li>-L ：列出指定网络接口所支持的数据链路层的类型后退出</li><li>-Z：后接用户名，在抓包时会受到权限的限制。如果以root用户启动tcpdump，tcpdump将会有超级用户权限。</li><li>-d：打印出易读的包匹配码</li><li>-dd：以C语言的形式打印出包匹配码.</li><li>-ddd：以十进制数的形式打印出包匹配码</li></ul><h2 id="第五章"><a href="#第五章" class="headerlink" title="第五章"></a>第五章</h2><p><strong>过滤规则组合</strong></p><p>有编程基础的同学，对于下面三个逻辑运算符应该不陌生了吧</p><ul><li>and：所有的条件都需要满足，也可以表示为 &amp;&amp;</li><li>or：只要有一个条件满足就可以，也可以表示为 ||</li><li>not：取反，也可以使用 !举个例子，我想需要抓一个来自10.5.2.3，发往任意主机的3389端口的包</li></ul><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump src 10.5.2.3 and dst port 3389</span><br></pre></td></tr></table></figure><p>当你在使用多个过滤器进行组合时，有可能需要用到括号，而括号在 shell 中是特殊符号，因为你需要使用引号将其包含。例子如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump <span class="string">'src 10.0.2.4 and (dst port 3389 or 22)'</span></span><br></pre></td></tr></table></figure><p>而在单个过滤器里，常常会判断一条件是否成立，这时候，就要使用下面两个符号</p><ul><li>=：判断二者相等</li><li>==：判断二者相等</li><li>!=：判断二者不相等</li></ul><p>当你使用这两个符号时，tcpdump 还提供了一些关键字的接口来方便我们进行判断，比如</p><ul><li>if：表示网卡接口名</li><li>proc：表示进程名</li><li>pid：表示进程 id</li><li>svc：表示 service class</li><li>dir：表示方向，in 和 out</li><li>eproc：表示 effective process name</li><li>epid：表示 effective process ID</li></ul><p>比如我现在要过滤来自进程名为 nc 发出的流经 en0 网卡的数据包，或者不流经 en0 的入方向数据包，可以这样子写</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump <span class="string">"( if=en0 and proc =nc ) || (if != en0 and dir=in)"</span></span><br></pre></td></tr></table></figure><h2 id="第六章"><a href="#第六章" class="headerlink" title="第六章"></a>第六章</h2><p><strong>特殊过滤规则</strong></p><p><strong>6.1 根据 tcpflags 进行过滤</strong></p><p>通过上一篇文章，我们知道了 tcp 的首部有一个标志位。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/b667fec3/2.png" alt="img"></p><p>TCP 报文首部</p><p>tcpdump 支持我们根据数据包的标志位进行过滤</p><p>proto [ expr:size ]</p><ul><li>proto：可以是熟知的协议之一（如ip，arp，tcp，udp，icmp，ipv6）</li><li>expr：可以是数值，也可以是一个表达式，表示与指定的协议头开始处的字节偏移量。</li><li>size：是可选的，表示从字节偏移量开始取的字节数量。</li></ul><p>接下来，我将举几个例子，让人明白它的写法，不过在那之前，有几个点需要你明白，这在后面的例子中会用到：</p><p><strong>1、</strong>tcpflags 可以理解为是一个别名常量，相当于 13，它代表着与指定的协议头开头相关的字节偏移量，也就是标志位，所以 tcp[tcpflags] 等价于 tcp[13] ，对应下图中的报文位置。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/b667fec3/3.png" alt="img"></p><p><strong>2、</strong>tcp-fin, tcp-syn, tcp-rst, tcp-push, tcp-ack, tcp-urg 这些同样可以理解为别名常量，分别代表 1，2，4，8，16，32，64。这些数字是如何计算出来的呢？</p><p>以 tcp-syn 为例，你可以参照下面这张图，计算出来的值 是就是 2</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/b667fec3/4.png" alt="img"></p><p>由于数字不好记忆，所以一般使用这样的“别名常量”表示。</p><p>因此当下面这个表达式成立时，就代表这个包是一个 syn 包。</p><p>tcp[tcpflags] == tcp-syn</p><p>要抓取特定数据包，方法有很多种。</p><p>下面以最常见的 syn包为例，演示一下如何用 tcpdump 抓取到 syn 包，而其他的类型的包也是同样的道理。</p><p>据我总结，主要有三种写法：</p><p>1、第一种写法：使用数字表示偏移量</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -i eth0 <span class="string">"tcp[13] &amp; 2 != 0"</span></span><br></pre></td></tr></table></figure><p>2、第二种写法：使用别名常量表示偏移量</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -i eth0 <span class="string">"tcp[tcpflags] &amp; tcp-syn != 0"</span></span><br></pre></td></tr></table></figure><p>3、第三种写法：使用混合写法</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -i eth0 <span class="string">"tcp[tcpflags] &amp; 2 != 0"</span><span class="comment"># or$ tcpdump -i eth0 "tcp[13] &amp; tcp-syn != 0"</span></span><br></pre></td></tr></table></figure><p>如果我想同时捕获多种类型的包呢，比如 syn + ack 包</p><p>1、第一种写法</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -i eth0 <span class="string">'tcp[13] == 2 or tcp[13] == 16'</span></span><br></pre></td></tr></table></figure><p>2、第二种写法</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -i eth0 <span class="string">'tcp[tcpflags] == tcp-syn or tcp[tcpflags] == tcp-ack'</span></span><br></pre></td></tr></table></figure><p>3、第三种写法</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -i eth0 <span class="string">"tcp[tcpflags] &amp; (tcp-syn|tcp-ack) != 0"</span></span><br></pre></td></tr></table></figure><p>4、第四种写法：注意这里是 单个等号，而不是像上面一样两个等号，18（syn+ack） = 2（syn） + 16（ack）</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -i eth0 <span class="string">'tcp[13] = 18'</span><span class="comment"># or$ tcpdump -i eth0 'tcp[tcpflags] = 18'</span></span><br></pre></td></tr></table></figure><p>tcp 中有 类似 tcp-syn 的别名常量，其他协议也是有的，比如 icmp 协议，可以使用的别名常量有</p><p>icmp-echoreply, icmp-unreach, icmp-sourcequench, icmp-redirect, icmp-echo, icmp-routeradvert,icmp-routersolicit, icmp-timx-ceed, icmp-paramprob, icmp-tstamp, icmp-tstampreply,icmp-ireq, icmp-ireqreply, icmp-maskreq, icmp-maskreply</p><p><strong>5.2 基于包大小进行过滤</strong></p><p>若你想查看指定大小的数据包，也是可以的</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump less 32 $ tcpdump greater 64 $ tcpdump &lt;= 128</span><br></pre></td></tr></table></figure><p><strong>5.3 根据 mac 地址进行过滤</strong></p><p>例子如下，其中 ehost 是记录在 /etc/ethers 里的 name</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump ether host [ehost]$ tcpdump ether dst [ehost]$ tcpdump ether src [ehost]</span><br></pre></td></tr></table></figure><p><strong>5.4 过滤通过指定网关的数据包</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump gateway [host]</span><br></pre></td></tr></table></figure><p><strong>5.5 过滤广播/多播数据包</strong></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump ether broadcast$ tcpdump ether multicast$ tcpdump ip broadcast$ tcpdump ip multicast$ tcpdump ip6 multicast</span><br></pre></td></tr></table></figure><h2 id="第七章"><a href="#第七章" class="headerlink" title="第七章"></a>第七章</h2><p><strong>如何抓取到更精准的包？</strong></p><p>先给你抛出一个问题：如果我只想抓取 HTTP 的 POST 请求该如何写呢？</p><p>如果只学习了上面的内容，恐怕你还是无法写法满足这个抓取需求的过滤器。</p><p>在学习之前，我先给出答案，然后再剖析一下，这个过滤器是如何生效的，居然能让我们对包内的内容进行判断。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -s 0 -A -vv <span class="string">'tcp[((tcp[12:1] &amp; 0xf0) &gt;&gt; 2):4]'</span></span><br></pre></td></tr></table></figure><p>命令里的可选参数，在前面的内容里已经详细讲过了。这里不再细讲。</p><p>本节的重点是引号里的内容，看起来很复杂的样子。</p><p>将它逐一分解，我们只要先理解了下面几种用法，就能明白</p><ul><li>tcp[n]：表示 tcp 报文里 第 n 个字节</li><li>tcp[n:c]：表示 tcp 报文里从第n个字节开始取 c 个字节，tcp[12:1] 表示从报文的第12个字节（因为有第0个字节，所以这里的12其实表示的是13）开始算起取一个字节，也就是 8 个bit。查看 tcp 的报文首部结构，可以得知这 8 个bit 其实就是下图中的红框圈起来的位置，而在这里我们只要前面 4个bit，也就是实际数据在整个报文首部中的偏移量。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/b667fec3/5.png" alt="img"></p><ul><li><p>&amp;：是位运算里的 and 操作符，比如 0011 &amp; 0010 = 0010</p></li><li><p>&gt;&gt;：是位运算里的右移操作，比如 0111 &gt;&gt; 2 = 0011</p></li><li><p>0xf0：是 10 进制的 240 的 16 进制表示，但对于位操作来说，10进制和16进制都将毫无意义，我们需要的是二进制，将其转换成二进制后是：11110000，这个数有什么特点呢？前面个 4bit 全部是 1，后面4个bit全部是0，往后看你就知道这个特点有什么用了。</p></li></ul><p>分解完后，再慢慢合并起来看</p><p>1、tcp[12:1] &amp; 0xf0 其实并不直观，但是我们将它换一种写法，就好看多了，假设 tcp 报文中的 第12 个字节是这样组成的 10110000，那么这个表达式就可以变成 10110110 &amp;&amp; 11110000 = 10110000，得到了 10110000 后，再进入下一步。</p><p>2、tcp[12:1] &amp; 0xf0) &gt;&gt; 2 ：如果你不理解 tcp 报文首部里的数据偏移，请先点击这个前往我的上一篇文章，搞懂数据偏移的意义，否则我保证你这里会绝对会听懵了。</p><p>tcp[12:1] &amp; 0xf0) &gt;&gt; 2 这个表达式实际是 (tcp[12:1] &amp; 0xf0) &gt;&gt; 4 ) &lt;&lt; 2 的简写形式。所以要搞懂 tcp[12:1] &amp; 0xf0) &gt;&gt; 2 只要理解了(tcp[12:1] &amp; 0xf0) &gt;&gt; 4 ) &lt;&lt; 2 就行了 。</p><p>从上一步我们算出了 tcp[12:1] &amp; 0xf0 的值其实是一个字节，也就是 8 个bit，但是你再回去看下上面的 tcp 报文首部结构图，表示数据偏移量的只有 4个bit，也就是说 上面得到的值 10110000，前面 4 位（1011）才是正确的偏移量，那么为了得到 1011，只需要将 10110000 右移4位即可，也就是 tcp[12:1] &amp; 0xf0) &gt;&gt; 4，至此我们是不是已经得出了实际数据的正确位置呢，很遗憾还没有，前一篇文章里我们讲到 Data Offset 的单位是 4个字节，因为要将 1011 乘以 4才可以，除以4在位运算中相当于左移2位，也就是 &lt;&lt;2，与前面的 &gt;&gt;4 结合起来一起算的话，最终的运算可以简化为 &gt;&gt;2</p><p>至此，我们终于得出了实际数据开始的位置是 tcp[12:1] &amp; 0xf0) &gt;&gt; 2 （单位是字节）。</p><p>找到了数据的起点后，可别忘了我们的目的是从数据中打到 HTTP 请求的方法，是 GET 呢 还是 POST ，或者是其他的？</p><p>有了上面的经验，我们自然懂得使用 tcp[((tcp[12:1] &amp; 0xf0) &gt;&gt; 2):4] 从数据开始的位置再取出四个字节，然后将结果与 GET （注意 GET最后还有个空格）的 16进制写法（也就是 0x47455420）进行比对。</p><p>0x47 –&gt; 71 –&gt; G0x45 –&gt; 69 –&gt; E0x54 –&gt; 84 –&gt; T0x20 –&gt; 32 –&gt; 空格</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/b667fec3/6.png" alt="img"></p><p>如果相等，则该表达式为True，tcpdump 认为这就是我们所需要抓的数据包，将其输出到我们的终端屏幕上。</p><h2 id="第八章"><a href="#第八章" class="headerlink" title="第八章"></a>第八章</h2><p><strong>抓包实战应用例子</strong></p><p><strong>以下例子摘自：<a href="https://fuckcloudnative.io/posts/tcpdump-examples/" rel="noopener" target="_blank">https://fuckcloudnative.io/posts/tcpdump-examples/</a></strong></p><p><strong>8.1 提取 HTTP 的 User-Agent</strong></p><p>从 HTTP 请求头中提取 HTTP 用户代理：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -nn -A -s1500 -l | grep <span class="string">"User-Agent:"</span></span><br></pre></td></tr></table></figure><p>通过 egrep 可以同时提取用户代理和主机名（或其他头文件）：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -nn -A -s1500 -l | egrep -i <span class="string">'User-Agent:|Host:'</span></span><br></pre></td></tr></table></figure><p><strong>8.2 抓取 HTTP GET 和 POST 请求</strong></p><p>抓取 HTTP GET 请求包：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -s 0 -A -vv <span class="string">'tcp[((tcp[12:1] &amp; 0xf0) &gt;&gt; 2):4] = 0x47455420'</span><span class="comment"># or$ tcpdump -vvAls0 | grep 'GET'</span></span><br></pre></td></tr></table></figure><p>可以抓取 HTTP POST 请求包：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -s 0 -A -vv <span class="string">'tcp[((tcp[12:1] &amp; 0xf0) &gt;&gt; 2):4] = 0x504f5354'</span><span class="comment"># or $ tcpdump -vvAls0 | grep 'POST'</span></span><br></pre></td></tr></table></figure><p>注意：该方法不能保证抓取到 HTTP POST 有效数据流量，因为一个 POST 请求会被分割为多个 TCP 数据包。</p><p><strong>8.3 找出发包数最多的 IP</strong></p><p>找出一段时间内发包最多的 IP，或者从一堆报文中找出发包最多的 IP，可以使用下面的命令：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -nnn -t -c 200 | cut -f 1,2,3,4 -d <span class="string">'.'</span> | sort | uniq -c | sort -nr | head -n 20</span><br></pre></td></tr></table></figure><ul><li><strong>cut -f 1,2,3,4 -d ‘.’</strong> : 以 . 为分隔符，打印出每行的前四列。即 IP 地址。</li><li><strong>sort | uniq -c</strong> : 排序并计数</li><li><strong>sort -nr</strong> : 按照数值大小逆向排序</li></ul><p><strong>8.4 抓取 DNS 请求和响应</strong></p><p>DNS 的默认端口是 53，因此可以通过端口进行过滤</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -i any -s0 port 53</span><br></pre></td></tr></table></figure><p><strong>8.5 切割 pcap 文件</strong></p><p>当抓取大量数据并写入文件时，可以自动切割为多个大小相同的文件。例如，下面的命令表示每 3600 秒创建一个新文件 capture-(hour).pcap，每个文件大小不超过 200*1000000 字节：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -w /tmp/capture-%H.pcap -G 3600 -C 200</span><br></pre></td></tr></table></figure><p>这些文件的命名为 capture-{1-24}.pcap，24 小时之后，之前的文件就会被覆盖。</p><p><strong>8.6 提取 HTTP POST 请求中的密码</strong></p><p>从 HTTP POST 请求中提取密码和主机名：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -s 0 -A -n -l | egrep -i <span class="string">"POST /|pwd=|passwd=|password=|Host:"</span></span><br></pre></td></tr></table></figure><p><strong>8.7 提取 HTTP 请求的 URL</strong></p><p>提取 HTTP 请求的主机名和路径：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump -s 0 -v -n -l | egrep -i <span class="string">"POST /|GET /|Host:"</span></span><br></pre></td></tr></table></figure><p><strong>8.8 抓取 HTTP 有效数据包</strong></p><p>抓取 80 端口的 HTTP 有效数据包，排除 TCP 连接建立过程的数据包（SYN / FIN / ACK）：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tcpdump <span class="string">'tcp port 80 and (((ip[2:2] - ((ip[0]&amp;0xf)&lt;&lt;2)) - ((tcp[12]&amp;0xf0)&gt;&gt;2)) != 0)'</span></span><br></pre></td></tr></table></figure><p><strong>8.9 结合 Wireshark 进行分析</strong></p><p>通常 Wireshark（或 tshark）比 tcpdump 更容易分析应用层协议。一般的做法是在远程服务器上先使用 tcpdump 抓取数据并写入文件，然后再将文件拷贝到本地工作站上用 Wireshark 分析。</p><p>还有一种更高效的方法，可以通过 ssh 连接将抓取到的数据实时发送给 Wireshark 进行分析。以 MacOS 系统为例，可以通过 brew cask install wireshark 来安装，然后通过下面的命令来分析：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh root@remotesystem <span class="string">'tcpdump -s0 -c 1000 -nn -w - not port 22'</span> | /Applications/Wireshark.app/Contents/MacOS/Wireshark -k -i -</span><br></pre></td></tr></table></figure><p>例如，如果想分析 DNS 协议，可以使用下面的命令：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh root@remotesystem <span class="string">'tcpdump -s0 -c 1000 -nn -w - port 53'</span> | /Applications/Wireshark.app/Contents/MacOS/Wireshark -k -i -</span><br></pre></td></tr></table></figure><p>抓取到的数据：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/b667fec3/7.png" alt="img"></p><p>-c 选项用来限制抓取数据的大小。如果不限制大小，就只能通过 ctrl-c 来停止抓取，这样一来不仅关闭了 tcpdump，也关闭了 wireshark。</p><p>到这里，我已经将我所知道的 tcpdump 的用法全部说了一遍，如果你有认真地看完本文，相信会有不小的收获，掌握一个上手的抓包工具，对于以后我们学习网络、分析网络协议、以及定位网络问题，会很有帮助，而 tcpdump 是我推荐的一个抓包工具。</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天要给大家介绍的一个类Unix下的一个网络数据采集分析工具 – Tcpdump，也就是我们常说的抓包工具。与它功能类似的工具有 wireshark。不同的是wireshark有图形化界面，而tcpdump 则只有命令行。&lt;/p&gt;
&lt;p&gt;作为一个运维，经常和服务器打交道，但服务器追求性能很少安装图形界面，因此直接跳过wireshark，直接给大家介绍这个tcpdump神器。&lt;/p&gt;
&lt;p&gt;这篇文章借助于很多帮助文档，终于把tcpdump的用法全部研究了个遍。毫不夸张的说，应该可以算是中文里把 tcpdump 讲得最清楚明白，并且最全的文章了。所以&lt;strong&gt;本文值得你收藏分享，就怕你错过了，就再也找不到像这样把 tcpdump 讲得直白而且特全的文章了&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
      <category term="网络技术" scheme="https://wandouduoduo.github.io/categories/%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Tcpdump" scheme="https://wandouduoduo.github.io/tags/Tcpdump/"/>
    
  </entry>
  
  <entry>
    <title>生产mysql数据库集群优化&lt;二&gt;--proxysql安装及优化</title>
    <link href="https://wandouduoduo.github.io/articles/8307f670.html"/>
    <id>https://wandouduoduo.github.io/articles/8307f670.html</id>
    <published>2021-06-23T06:26:18.000Z</published>
    <updated>2021-06-23T06:51:09.961Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>前面文章对数据库中间层进行了选型，那么要怎么安装，怎么验证，怎么优化，又有哪些坑可以避免呢？本文就详细介绍下。</p><a id="more"></a><h2 id="ProxySQL-安装-两种方式"><a href="#ProxySQL-安装-两种方式" class="headerlink" title="ProxySQL 安装 (两种方式)"></a><strong>ProxySQL 安装 (两种方式)</strong></h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">1) 采用yum方式安装</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># vim /etc/yum.repos.d/proxysql.repo</span></span><br><span class="line">[proxysql_repo]</span><br><span class="line">name= ProxySQL YUM repository</span><br><span class="line">baseurl=http://repo.proxysql.com/ProxySQL/proxysql-1.4.x/centos/\<span class="variable">$releasever</span></span><br><span class="line">gpgcheck=1</span><br><span class="line">gpgkey=http://repo.proxysql.com/ProxySQL/repo_pub_key</span><br><span class="line"> </span><br><span class="line">执行安装</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># yum clean all</span></span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># yum makecache</span></span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># yum -y install proxysql</span></span><br><span class="line">  </span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># proxysql --version</span></span><br><span class="line">ProxySQL version 1.4.13-15-g69d4207, codename Truls</span><br><span class="line">  </span><br><span class="line">启动ProxySQL</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># chkconfig proxysql on</span></span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># systemctl start proxysql      </span></span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># systemctl status proxysql</span></span><br><span class="line"> </span><br><span class="line">启动后会监听两个端口，</span><br><span class="line">默认为6032和6033。6032端口是ProxySQL的管理端口，6033是ProxySQL对外提供服务的端口 (即连接到转发后端的真正数据库的转发端口)。</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># netstat -tunlp</span></span><br><span class="line">Active Internet connections (only servers)</span><br><span class="line">Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name  </span><br><span class="line">tcp        0      0 0.0.0.0:6032            0.0.0.0:*               LISTEN      23940/proxysql    </span><br><span class="line">tcp        0      0 0.0.0.0:6033            0.0.0.0:*               LISTEN      23940/proxysql</span><br><span class="line"> </span><br><span class="line">2）采用rpm包方式安装</span><br><span class="line">proxysql的rpm包下载地址: https://pan.baidu.com/s/1S1_b5DKVCpZSOUNmtCXrrg</span><br><span class="line">提取密码: 5t1c</span><br><span class="line">  </span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># wget https://github.com/sysown/proxysql/releases/download/v1.4.8/proxysql-1.4.8-1-centos7.x86_64.rpm</span></span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># rpm -ivh proxysql-1.4.8-1-centos7.x86_64.rpm --force</span></span><br><span class="line"> </span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># /etc/init.d/proxysql start</span></span><br><span class="line">Starting ProxySQL: DONE!</span><br><span class="line"> </span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># ss -lntup|grep proxy</span></span><br><span class="line">tcp    LISTEN     0      128       *:6032                  *:*                   users:((<span class="string">"proxysql"</span>,pid=2943,fd=24))</span><br><span class="line">tcp    LISTEN     0      128       *:6033                  *:*                   users:((<span class="string">"proxysql"</span>,pid=2943,fd=22))</span><br><span class="line">tcp    LISTEN     0      128       *:6033                  *:*                   users:((<span class="string">"proxysql"</span>,pid=2943,fd=21))</span><br><span class="line">tcp    LISTEN     0      128       *:6033                  *:*                   users:((<span class="string">"proxysql"</span>,pid=2943,fd=20))</span><br><span class="line">tcp    LISTEN     0      128       *:6033                  *:*                   users:((<span class="string">"proxysql"</span>,pid=2943,fd=19))</span><br><span class="line"> </span><br><span class="line">如上可以看出转发端口6033是启动了四个线程</span><br><span class="line"> </span><br><span class="line">==============================================================</span><br><span class="line">以上两种方式采用任何一种都可以顺利安装proxysql插件。</span><br><span class="line"> </span><br><span class="line">另外，记得在proxysql服务器上安装mysql客户端，用于在本机连接到ProxySQL的管理接口</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># vim /etc/yum.repos.d/mariadb.repo</span></span><br><span class="line">[mariadb]</span><br><span class="line">name = MariaDB</span><br><span class="line">baseurl = http://yum.mariadb.org/10.3.5/centos6-amd64</span><br><span class="line">gpgkey=https://yum.mariadb.org/RPM-GPG-KEY-MariaDB</span><br><span class="line">gpgcheck=1</span><br><span class="line">   </span><br><span class="line">安装mysql-clinet客户端</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># yum install -y MariaDB-client</span></span><br><span class="line">  </span><br><span class="line">--------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">如果遇到报错：</span><br><span class="line">Error: MariaDB-compat conflicts with 1:mariadb-libs-5.5.60-1.el7_5.x86_64</span><br><span class="line"> You could try using --skip-broken to work around the problem</span><br><span class="line"> You could try running: rpm -Va --nofiles --nodigest</span><br><span class="line">   </span><br><span class="line">解决办法：</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># rpm -qa|grep mariadb*</span></span><br><span class="line">mariadb-libs-5.5.56-2.el7.x86_64</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># rpm -e mariadb-libs-5.5.56-2.el7.x86_64 --nodeps</span></span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># yum install -y MariaDB-client</span></span><br></pre></td></tr></table></figure><h2 id="ProxySQL配置"><a href="#ProxySQL配置" class="headerlink" title="ProxySQL配置"></a><strong>ProxySQL配置</strong></h2><p>ProxySQL有配置文件/etc/proxysql.cnf和配置数据库文件/var/lib/proxysql/proxysql.db。<strong>这里需要特别注意：如果存在如果存在”proxysql.db”文件(在/var/lib/proxysql目录下)，则ProxySQL服务只有在第一次启动时才会去读取proxysql.cnf文件并解析；后面启动会就不会读取proxysql.cnf文件了！如果想要让proxysql.cnf文件里的配置在重启proxysql服务后生效(即想要让proxysql重启时读取并解析proxysql.cnf配置文件)，则需要先删除/var/lib/proxysql/proxysql.db数据库文件，然后再重启proxysql服务。这样就相当于初始化启动proxysql服务了，会再次生产一个纯净的proxysql.db数据库文件(如果之前配置了proxysql相关路由规则等，则就会被抹掉)。</strong> 官方推荐用admin interface方式！(即在proxysql本机使用mysql客户端连接管理端口)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br></pre></td><td class="code"><pre><span class="line">[root@mysql-proxy ~]<span class="comment"># egrep -v "^#|^$" /etc/proxysql.cnf</span></span><br><span class="line">datadir=<span class="string">"/var/lib/proxysql"</span>                                   <span class="comment">#数据目录</span></span><br><span class="line">admin_variables=</span><br><span class="line">&#123;</span><br><span class="line">        admin_credentials=<span class="string">"admin:admin"</span>                       <span class="comment">#连接管理端的用户名与密码</span></span><br><span class="line">        mysql_ifaces=<span class="string">"0.0.0.0:6032"</span>                           <span class="comment">#管理端口，用来连接proxysql的管理数据库</span></span><br><span class="line">&#125;</span><br><span class="line">mysql_variables=</span><br><span class="line">&#123;</span><br><span class="line">        threads=4                                             <span class="comment">#指定转发端口开启的线程数量</span></span><br><span class="line">        max_connections=2048</span><br><span class="line">        default_query_delay=0</span><br><span class="line">        default_query_timeout=36000000</span><br><span class="line">        have_compress=<span class="literal">true</span></span><br><span class="line">        poll_timeout=2000</span><br><span class="line">        interfaces=<span class="string">"0.0.0.0:6033"</span>                             <span class="comment">#指定转发端口，用于连接后端mysql数据库的，相当于代理作用</span></span><br><span class="line">        default_schema=<span class="string">"information_schema"</span></span><br><span class="line">        stacksize=1048576</span><br><span class="line">        server_version=<span class="string">"5.5.30"</span>                               <span class="comment">#指定后端mysql的版本</span></span><br><span class="line">        connect_timeout_server=3000</span><br><span class="line">        monitor_username=<span class="string">"monitor"</span></span><br><span class="line">        monitor_password=<span class="string">"monitor"</span></span><br><span class="line">        monitor_history=600000</span><br><span class="line">        monitor_connect_interval=60000</span><br><span class="line">        monitor_ping_interval=10000</span><br><span class="line">        monitor_read_only_interval=1500</span><br><span class="line">        monitor_read_only_timeout=500</span><br><span class="line">        ping_interval_server_msec=120000</span><br><span class="line">        ping_timeout_server=500</span><br><span class="line">        commands_stats=<span class="literal">true</span></span><br><span class="line">        sessions_sort=<span class="literal">true</span></span><br><span class="line">        connect_retries_on_failure=10</span><br><span class="line">&#125;</span><br><span class="line">mysql_servers =</span><br><span class="line">(</span><br><span class="line">)</span><br><span class="line">mysql_users:</span><br><span class="line">(</span><br><span class="line">)</span><br><span class="line">mysql_query_rules:</span><br><span class="line">(</span><br><span class="line">)</span><br><span class="line">scheduler=</span><br><span class="line">(</span><br><span class="line">)</span><br><span class="line">mysql_replication_hostgroups=</span><br><span class="line">(</span><br><span class="line">)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">proxysql的数据目录</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># ll /var/lib/proxysql/</span></span><br><span class="line">total 1014052</span><br><span class="line">-rw------- 1 root root     122880 Jan 25 14:33 proxysql.db</span><br><span class="line">-rw------- 1 root root 1023288179 Jan 28 12:30 proxysql.log</span><br><span class="line">-rw-r--r-- 1 root root          6 Jan 25 14:20 proxysql.pid</span><br><span class="line">-rw------- 1 root root    1736704 Jan 28 12:29 proxysql_stats.db</span><br><span class="line"> </span><br><span class="line">查看main库（默认登陆后即在此库）的global_variables表信息</span><br><span class="line">MySQL [(none)]&gt; show databases;</span><br><span class="line">+-----+---------------+-------------------------------------+</span><br><span class="line">| seq | name          | file                                |</span><br><span class="line">+-----+---------------+-------------------------------------+</span><br><span class="line">| 0   | main          |                                     |</span><br><span class="line">| 2   | disk          | /var/lib/proxysql/proxysql.db       |</span><br><span class="line">| 3   | stats         |                                     |</span><br><span class="line">| 4   | monitor       |                                     |</span><br><span class="line">| 5   | stats_history | /var/lib/proxysql/proxysql_stats.db |</span><br><span class="line">+-----+---------------+-------------------------------------+</span><br><span class="line">5 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.000 sec)</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; use main;</span><br><span class="line">Reading table information <span class="keyword">for</span> completion of table and column names</span><br><span class="line">You can turn off this feature to get a quicker startup with -A</span><br><span class="line"> </span><br><span class="line">Database changed</span><br><span class="line">MySQL [main]&gt; show tables;</span><br><span class="line">+--------------------------------------------+</span><br><span class="line">| tables                                     |</span><br><span class="line">+--------------------------------------------+</span><br><span class="line">| global_variables                           |</span><br><span class="line">| mysql_collations                           |</span><br><span class="line">| mysql_group_replication_hostgroups         |</span><br><span class="line">| mysql_query_rules                          |</span><br><span class="line">| mysql_query_rules_fast_routing             |</span><br><span class="line">| mysql_replication_hostgroups               |</span><br><span class="line">| mysql_servers                              |</span><br><span class="line">| mysql_users                                |</span><br><span class="line">| proxysql_servers                           |</span><br><span class="line">| runtime_checksums_values                   |</span><br><span class="line">| runtime_global_variables                   |</span><br><span class="line">| runtime_mysql_group_replication_hostgroups |</span><br><span class="line">| runtime_mysql_query_rules                  |</span><br><span class="line">| runtime_mysql_query_rules_fast_routing     |</span><br><span class="line">| runtime_mysql_replication_hostgroups       |</span><br><span class="line">| runtime_mysql_servers                      |</span><br><span class="line">| runtime_mysql_users                        |</span><br><span class="line">| runtime_proxysql_servers                   |</span><br><span class="line">| runtime_scheduler                          |</span><br><span class="line">| scheduler                                  |</span><br><span class="line">+--------------------------------------------+</span><br><span class="line">20 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.000 sec)</span><br><span class="line"> </span><br><span class="line">MySQL [main]&gt; select * from global_variables;</span><br><span class="line">+-----------------------------------------------------+---------------------------+</span><br><span class="line">| variable_name                                       | variable_value            |</span><br><span class="line">+-----------------------------------------------------+---------------------------+</span><br><span class="line">| mysql-shun_on_failures                              | 5                         |</span><br><span class="line">| mysql-shun_recovery_time_sec                        | 10                        |</span><br><span class="line">| mysql-query_retries_on_failure                      | 1                         |</span><br><span class="line">| mysql-connect_retries_delay                         | 1                         |</span><br><span class="line">| mysql-connection_delay_multiplex_ms                 | 0                         |</span><br><span class="line">| mysql-connection_max_age_ms                         | 0                         |</span><br><span class="line">| mysql-connect_timeout_server_max                    | 10000                     |</span><br><span class="line">| mysql-eventslog_filename                            |                           |</span><br><span class="line">| mysql-eventslog_filesize                            | 104857600                 |</span><br><span class="line">| mysql-default_charset                               | utf8                      |</span><br><span class="line">| mysql-free_connections_pct                          | 10                        |</span><br><span class="line">| mysql-session_idle_ms                               | 1000                      |</span><br><span class="line">| mysql-client_found_rows                             | <span class="literal">true</span>                      |</span><br><span class="line">| mysql-monitor_enabled                               | <span class="literal">true</span>                      |</span><br><span class="line">| mysql-monitor_connect_timeout                       | 600                       |</span><br><span class="line">| mysql-monitor_ping_max_failures                     | 3                         |</span><br><span class="line">| mysql-monitor_ping_timeout                          | 1000                      |</span><br><span class="line">| mysql-monitor_read_only_max_timeout_count           | 3                         |</span><br><span class="line">| mysql-monitor_replication_lag_interval              | 10000                     |</span><br><span class="line">| mysql-monitor_replication_lag_timeout               | 1000                      |</span><br><span class="line">| mysql-monitor_groupreplication_healthcheck_interval | 5000                      |</span><br><span class="line">| mysql-monitor_groupreplication_healthcheck_timeout  | 800                       |</span><br><span class="line">| mysql-monitor_replication_lag_use_percona_heartbeat |                           |</span><br><span class="line">| mysql-monitor_query_interval                        | 60000                     |</span><br><span class="line">| mysql-monitor_query_timeout                         | 100                       |</span><br><span class="line">| mysql-monitor_slave_lag_when_null                   | 60                        |</span><br><span class="line">| mysql-monitor_wait_timeout                          | <span class="literal">true</span>                      |</span><br><span class="line">| mysql-monitor_writer_is_also_reader                 | <span class="literal">true</span>                      |</span><br><span class="line">| mysql-max_allowed_packet                            | 4194304                   |</span><br><span class="line">| mysql-throttle_connections_per_sec_to_hostgroup     | 1000000                   |</span><br><span class="line">| mysql-max_transaction_time                          | 14400000                  |</span><br><span class="line">| mysql-multiplexing                                  | <span class="literal">true</span>                      |</span><br><span class="line">| mysql-forward_autocommit                            | <span class="literal">false</span>                     |</span><br><span class="line">| mysql-enforce_autocommit_on_reads                   | <span class="literal">false</span>                     |</span><br><span class="line">| mysql-autocommit_false_not_reusable                 | <span class="literal">false</span>                     |</span><br><span class="line">| mysql-autocommit_false_is_transaction               | <span class="literal">false</span>                     |</span><br><span class="line">| mysql-verbose_query_error                           | <span class="literal">false</span>                     |</span><br><span class="line">| mysql-hostgroup_manager_verbose                     | 1                         |</span><br><span class="line">| mysql-threshold_query_length                        | 524288                    |</span><br><span class="line">| mysql-threshold_resultset_size                      | 4194304                   |</span><br><span class="line">| mysql-query_digests_max_digest_length               | 2048                      |</span><br><span class="line">| mysql-query_digests_max_query_length                | 65000                     |</span><br><span class="line">| mysql-wait_timeout                                  | 28800000                  |</span><br><span class="line">| mysql-throttle_max_bytes_per_second_to_client       | 2147483647                |</span><br><span class="line">| mysql-throttle_ratio_server_to_client               | 0                         |</span><br><span class="line">| mysql-max_stmts_per_connection                      | 20                        |</span><br><span class="line">| mysql-max_stmts_cache                               | 10000                     |</span><br><span class="line">| mysql-mirror_max_concurrency                        | 16                        |</span><br><span class="line">| mysql-mirror_max_queue_length                       | 32000                     |</span><br><span class="line">| mysql-default_max_latency_ms                        | 1000                      |</span><br><span class="line">| mysql-query_processor_iterations                    | 0                         |</span><br><span class="line">| mysql-query_processor_regex                         | 1                         |</span><br><span class="line">| mysql-long_query_time                               | 1000                      |</span><br><span class="line">| mysql-query_cache_size_MB                           | 256                       |</span><br><span class="line">| mysql-poll_timeout_on_failure                       | 100                       |</span><br><span class="line">| mysql-server_capabilities                           | 45578                     |</span><br><span class="line">| mysql-session_idle_show_processlist                 | <span class="literal">true</span>                      |</span><br><span class="line">| mysql-query_digests                                 | <span class="literal">true</span>                      |</span><br><span class="line">| mysql-query_digests_lowercase                       | <span class="literal">false</span>                     |</span><br><span class="line">| mysql-servers_stats                                 | <span class="literal">true</span>                      |</span><br><span class="line">| mysql-default_reconnect                             | <span class="literal">true</span>                      |</span><br><span class="line">| mysql-ssl_p2s_ca                                    |                           |</span><br><span class="line">| mysql-ssl_p2s_cert                                  |                           |</span><br><span class="line">| mysql-ssl_p2s_key                                   |                           |</span><br><span class="line">| mysql-ssl_p2s_cipher                                |                           |</span><br><span class="line">| mysql-init_connect                                  |                           |</span><br><span class="line">| mysql-default_sql_mode                              |                           |</span><br><span class="line">| mysql-default_time_zone                             | SYSTEM                    |</span><br><span class="line">| mysql-connpoll_reset_queue_length                   | 50                        |</span><br><span class="line">| mysql-stats_time_backend_query                      | <span class="literal">false</span>                     |</span><br><span class="line">| mysql-stats_time_query_processor                    | <span class="literal">false</span>                     |</span><br><span class="line">| mysql-threads                                       | 4                         |</span><br><span class="line">| mysql-max_connections                               | 2048                      |</span><br><span class="line">| mysql-default_query_delay                           | 0                         |</span><br><span class="line">| mysql-default_query_timeout                         | 36000000                  |</span><br><span class="line">| mysql-have_compress                                 | <span class="literal">true</span>                      |</span><br><span class="line">| mysql-poll_timeout                                  | 2000                      |</span><br><span class="line">| mysql-interfaces                                    | 0.0.0.0:6033              |</span><br><span class="line">| mysql-default_schema                                | information_schema        |</span><br><span class="line">| mysql-stacksize                                     | 1048576                   |</span><br><span class="line">| mysql-server_version                                | 5.5.30                    |</span><br><span class="line">| mysql-connect_timeout_server                        | 3000                      |</span><br><span class="line">| mysql-monitor_username                              | proxysql                  |</span><br><span class="line">| mysql-monitor_password                              | proxysql                  |</span><br><span class="line">| mysql-monitor_history                               | 600000                    |</span><br><span class="line">| mysql-monitor_connect_interval                      | 60000                     |</span><br><span class="line">| mysql-monitor_ping_interval                         | 10000                     |</span><br><span class="line">| mysql-monitor_read_only_interval                    | 1500                      |</span><br><span class="line">| mysql-monitor_read_only_timeout                     | 500                       |</span><br><span class="line">| mysql-ping_interval_server_msec                     | 120000                    |</span><br><span class="line">| mysql-ping_timeout_server                           | 500                       |</span><br><span class="line">| mysql-commands_stats                                | <span class="literal">true</span>                      |</span><br><span class="line">| mysql-sessions_sort                                 | <span class="literal">true</span>                      |</span><br><span class="line">| mysql-connect_retries_on_failure                    | 10                        |</span><br><span class="line">| admin-stats_credentials                             | stats:stats               |</span><br><span class="line">| admin-stats_mysql_connections                       | 60                        |</span><br><span class="line">| admin-stats_mysql_connection_pool                   | 60                        |</span><br><span class="line">| admin-stats_mysql_query_cache                       | 60                        |</span><br><span class="line">| admin-stats_system_cpu                              | 60                        |</span><br><span class="line">| admin-stats_system_memory                           | 60                        |</span><br><span class="line">| admin-telnet_admin_ifaces                           | (null)                    |</span><br><span class="line">| admin-telnet_stats_ifaces                           | (null)                    |</span><br><span class="line">| admin-refresh_interval                              | 2000                      |</span><br><span class="line">| admin-read_only                                     | <span class="literal">false</span>                     |</span><br><span class="line">| admin-hash_passwords                                | <span class="literal">true</span>                      |</span><br><span class="line">| admin-cluster_username                              |                           |</span><br><span class="line">| admin-cluster_password                              |                           |</span><br><span class="line">| admin-cluster_check_interval_ms                     | 1000                      |</span><br><span class="line">| admin-cluster_check_status_frequency                | 10                        |</span><br><span class="line">| admin-cluster_mysql_query_rules_diffs_before_sync   | 3                         |</span><br><span class="line">| admin-cluster_mysql_servers_diffs_before_sync       | 3                         |</span><br><span class="line">| admin-cluster_mysql_users_diffs_before_sync         | 3                         |</span><br><span class="line">| admin-cluster_proxysql_servers_diffs_before_sync    | 3                         |</span><br><span class="line">| admin-cluster_mysql_query_rules_save_to_disk        | <span class="literal">true</span>                      |</span><br><span class="line">| admin-cluster_mysql_servers_save_to_disk            | <span class="literal">true</span>                      |</span><br><span class="line">| admin-cluster_mysql_users_save_to_disk              | <span class="literal">true</span>                      |</span><br><span class="line">| admin-cluster_proxysql_servers_save_to_disk         | <span class="literal">true</span>                      |</span><br><span class="line">| admin-checksum_mysql_query_rules                    | <span class="literal">true</span>                      |</span><br><span class="line">| admin-checksum_mysql_servers                        | <span class="literal">true</span>                      |</span><br><span class="line">| admin-checksum_mysql_users                          | <span class="literal">true</span>                      |</span><br><span class="line">| admin-web_enabled                                   | <span class="literal">false</span>                     |</span><br><span class="line">| admin-web_port                                      | 6080                      |</span><br><span class="line">| admin-admin_credentials                             | admin:admin|</span><br><span class="line">| admin-mysql_ifaces                                  | 0.0.0.0:6032              |</span><br><span class="line">| admin-version                                       | 1.4.8-32-g669c149         |</span><br><span class="line">+-----------------------------------------------------+---------------------------+</span><br><span class="line">125 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.003 sec)</span><br><span class="line"> </span><br><span class="line"><span class="comment">#登陆成功后，可通过对main库（默认登陆后即在此库）的global_variables表中的"admin-admin_credentials" 和 "admin-mysql_ifaces"</span></span><br><span class="line"><span class="comment">#两个变量进行更改来修改登录认证! 比如说修改密码或定义一个非admin的用户用于远程登录(下面会说到)。</span></span><br></pre></td></tr></table></figure><p>proxysql的6032端口是管理入口，账号密码是admin(可以动态修改),允许客户端连接；6033端口就是客户端入口，账号密码通过管理接口去设置。在proxysql本机使用mysql客户端连接到ProxySQL的管理接口(admin interface), 该接口的默认管理员用户和密码都是admin。</p><p><strong>mysql_ifaces</strong><br>也就是说proxysql有一个admin接口专门来做配置，相当于一个mysql shell可以通过sql来让配置实时生效。<br>mysql_ifaces配置了允许连接proxysql的ip和port</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@mysql-proxy ~]<span class="comment"># vim /etc/proxysql.cnf</span></span><br><span class="line">........</span><br><span class="line"><span class="comment"># 将admin_variables中的mysql_ifaces修改成允许远程访问</span></span><br><span class="line"><span class="comment">#      mysql_ifaces="127.0.0.1:6032;/tmp/proxysql_admin.sock"</span></span><br><span class="line">       mysql_ifaces=<span class="string">"0.0.0.0:6032"</span></span><br></pre></td></tr></table></figure><p>如果ip配置为0.0.0.0表示不限制ip，但是出于安全考虑，admin用户无论怎么设置都只能在本机登录!!!</p><p><strong>admin_credentials</strong><br>这个key保存所有可以操作proxysql的用户名和密码，格式为：user:pass;user1:pass1，这里可以修改密码或定义一个非admin的用户用于远程登录。 前提是保证想要管理proxysql的机器安装有mysql client客户端！</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">先在proxysql本机登录 (因为初始账号密码是admin:admin，只能在本机登录), 这里的proxysql本机地址是172.16.60.214</span><br><span class="line"> </span><br><span class="line">修改远程连接proxysql管理端口的账号和密码radmin:radmin.</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uadmin -padmin -h127.0.0.1 -P6032       </span></span><br><span class="line">Welcome to the MariaDB monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 34</span><br><span class="line">Server version: 5.5.30 (ProxySQL Admin Module)</span><br><span class="line"> </span><br><span class="line">Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.</span><br><span class="line"> </span><br><span class="line">Type <span class="string">'help;'</span> or <span class="string">'\h'</span> <span class="keyword">for</span> <span class="built_in">help</span>. Type <span class="string">'\c'</span> to clear the current input statement.</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; update global_variables <span class="built_in">set</span> variable_value = <span class="string">'admin:admin;radmin:radmin'</span> <span class="built_in">where</span> variable_name = <span class="string">'admin-admin_credentials'</span>;</span><br><span class="line">Query OK, 1 row affected (0.002 sec)</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; LOAD ADMIN VARIABLES TO RUNTIME;</span><br><span class="line">Query OK, 0 rows affected (0.000 sec)</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; SAVE ADMIN VARIABLES TO DISK;</span><br><span class="line">Query OK, 31 rows affected (0.077 sec)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">这样就可以使用下面的命令在其他机器上使用radmin用户登录（其他机器上需要有mysql client）</span><br><span class="line">[root@MGR-node3 ~]<span class="comment"># mysql -uradmin -pradmin -h172.16.60.214 -P6032        </span></span><br><span class="line">mysql: [Warning] Using a password on the <span class="built_in">command</span> line interface can be insecure.</span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 35</span><br><span class="line">Server version: 5.5.30 (ProxySQL Admin Module)</span><br><span class="line"> </span><br><span class="line">Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"> </span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"> </span><br><span class="line">Type <span class="string">'help;'</span> or <span class="string">'\h'</span> <span class="keyword">for</span> <span class="built_in">help</span>. Type <span class="string">'\c'</span> to clear the current input statement.</span><br><span class="line"> </span><br><span class="line">mysql&gt; show databases;</span><br><span class="line">+-----+---------------+-------------------------------------+</span><br><span class="line">| seq | name          | file                                |</span><br><span class="line">+-----+---------------+-------------------------------------+</span><br><span class="line">| 0   | main          |                                     |</span><br><span class="line">| 2   | disk          | /var/lib/proxysql/proxysql.db       |</span><br><span class="line">| 3   | stats         |                                     |</span><br><span class="line">| 4   | monitor       |                                     |</span><br><span class="line">| 5   | stats_history | /var/lib/proxysql/proxysql_stats.db |</span><br><span class="line">+-----+---------------+-------------------------------------+</span><br><span class="line">5 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br></pre></td></tr></table></figure><p><strong>ProxySQL的库、表说明</strong> （默认管理端口是6032，客户端服务端口是6033。默认的用户名密码都是 admin）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line">通过管理端口6032去连接的 (注意, 下面连接命令中后面的--prompt <span class="string">'admin'</span>字段可以不加，也是可以登录进去的)</span><br><span class="line">  </span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uadmin -padmin -P6032 -h127.0.0.1</span></span><br><span class="line">或者</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uadmin -padmin -P6032 -h127.0.0.1 --prompt 'admin&gt; '</span></span><br><span class="line">Welcome to the MariaDB monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 33</span><br><span class="line">Server version: 5.5.30 (ProxySQL Admin Module)</span><br><span class="line">  </span><br><span class="line">Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.</span><br><span class="line">  </span><br><span class="line">Type <span class="string">'help;'</span> or <span class="string">'\h'</span> <span class="keyword">for</span> <span class="built_in">help</span>. Type <span class="string">'\c'</span> to clear the current input statement.</span><br><span class="line">  </span><br><span class="line">admin&gt; show databases;</span><br><span class="line">+-----+---------------+-------------------------------------+</span><br><span class="line">| seq | name          | file                                |</span><br><span class="line">+-----+---------------+-------------------------------------+</span><br><span class="line">| 0   | main          |                                     |</span><br><span class="line">| 2   | disk          | /var/lib/proxysql/proxysql.db       |</span><br><span class="line">| 3   | stats         |                                     |</span><br><span class="line">| 4   | monitor       |                                     |</span><br><span class="line">| 5   | stats_history | /var/lib/proxysql/proxysql_stats.db |</span><br><span class="line">+-----+---------------+-------------------------------------+</span><br><span class="line">5 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.000 sec)</span><br><span class="line">  </span><br><span class="line">ProxySQL提供了几个库，每个库都有各自的意义；</span><br><span class="line">-  main 内存配置数据库，表里存放后端db实例、用户验证、路由规则等信息。表名以 runtime_开头的表示proxysql当前运行的配置内容，</span><br><span class="line">不能通过dml语句修改，只能修改对应的不以 runtime_ 开头的（在内存）里的表，然后 LOAD 使其生效， SAVE 使其存到硬盘以供下次重启加载。</span><br><span class="line">-  disk 是持久化到硬盘的配置，sqlite数据文件。</span><br><span class="line">-  stats 是proxysql运行抓取的统计信息，包括到后端各命令的执行次数、流量、processlist、查询种类汇总/执行时间等等。</span><br><span class="line">-  monitor 库存储 monitor 模块收集的信息，主要是对后端db的健康/延迟检查。</span><br><span class="line">  </span><br><span class="line">1) main 库 （disk库的表字段和main一样）</span><br><span class="line">admin&gt; show tables from main;</span><br><span class="line">+--------------------------------------------+</span><br><span class="line">| tables                                     |</span><br><span class="line">+--------------------------------------------+</span><br><span class="line">| global_variables                           |</span><br><span class="line">| mysql_collations                           |</span><br><span class="line">| mysql_group_replication_hostgroups         |</span><br><span class="line">| mysql_query_rules                          |</span><br><span class="line">| mysql_query_rules_fast_routing             |</span><br><span class="line">| mysql_replication_hostgroups               |</span><br><span class="line">| mysql_servers                              |</span><br><span class="line">| mysql_users                                |</span><br><span class="line">| proxysql_servers                           |</span><br><span class="line">| runtime_checksums_values                   |</span><br><span class="line">| runtime_global_variables                   |</span><br><span class="line">| runtime_mysql_group_replication_hostgroups |</span><br><span class="line">| runtime_mysql_query_rules                  |</span><br><span class="line">| runtime_mysql_query_rules_fast_routing     |</span><br><span class="line">| runtime_mysql_replication_hostgroups       |</span><br><span class="line">| runtime_mysql_servers                      |</span><br><span class="line">| runtime_mysql_users                        |</span><br><span class="line">| runtime_proxysql_servers                   |</span><br><span class="line">| runtime_scheduler                          |</span><br><span class="line">| scheduler                                  |</span><br><span class="line">+--------------------------------------------+</span><br><span class="line">20 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.001 sec)</span><br><span class="line"> </span><br><span class="line">常用的几个表介绍</span><br><span class="line">===============================================</span><br><span class="line">global_variables      </span><br><span class="line">设置变量，包括监听的端口、管理账号等。</span><br><span class="line"> </span><br><span class="line">mysql_collations      </span><br><span class="line">相关字符集和校验规则。</span><br><span class="line"> </span><br><span class="line">mysql_query_rules     </span><br><span class="line">定义查询路由规则。</span><br><span class="line"> </span><br><span class="line">mysql_replication_hostgroups  </span><br><span class="line">监视指定主机组中所有服务器的read_only值，并且根据read_only的值将服务器分配给写入器或读取器主机组。ProxySQL monitor模块会监控hostgroups</span><br><span class="line">后端所有servers 的read_only 变量，如果发现从库的read_only变为0、主库变为1，则认为角色互换了，自动改写mysql_servers表里面 hostgroup关系，</span><br><span class="line">达到自动 Failover 效果。</span><br><span class="line"> </span><br><span class="line">mysql_servers</span><br><span class="line">设置后端MySQL的表</span><br><span class="line"> </span><br><span class="line">mysql_users</span><br><span class="line">配置后端数据库的程序账号和监控账号。</span><br><span class="line"> </span><br><span class="line">scheduler</span><br><span class="line">调度器是一个类似于cron的实现，集成在ProxySQL中，具有毫秒的粒度。通过脚本检测来设置ProxySQL。</span><br><span class="line"> </span><br><span class="line">2）stats库</span><br><span class="line">MySQL [(none)]&gt; show tables from stats;</span><br><span class="line">+--------------------------------------+</span><br><span class="line">| tables                               |</span><br><span class="line">+--------------------------------------+</span><br><span class="line">| global_variables                     |</span><br><span class="line">| stats_memory_metrics                 |</span><br><span class="line">| stats_mysql_commands_counters        |</span><br><span class="line">| stats_mysql_connection_pool          |</span><br><span class="line">| stats_mysql_connection_pool_reset    |</span><br><span class="line">| stats_mysql_global                   |</span><br><span class="line">| stats_mysql_prepared_statements_info |</span><br><span class="line">| stats_mysql_processlist              |</span><br><span class="line">| stats_mysql_query_digest             |</span><br><span class="line">| stats_mysql_query_digest_reset       |</span><br><span class="line">| stats_mysql_query_rules              |</span><br><span class="line">| stats_mysql_users                    |</span><br><span class="line">| stats_proxysql_servers_checksums     |</span><br><span class="line">| stats_proxysql_servers_metrics       |</span><br><span class="line">| stats_proxysql_servers_status        |</span><br><span class="line">+--------------------------------------+</span><br><span class="line">15 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.001 sec)</span><br><span class="line"> </span><br><span class="line">常用的几个表介绍</span><br><span class="line">===============================================</span><br><span class="line">stats_mysql_commands_counters</span><br><span class="line">统计各种SQL类型的执行次数和时间，通过参数mysql-commands_stats控制开关，默认是ture。</span><br><span class="line"> </span><br><span class="line">stats_mysql_connection_pool</span><br><span class="line">连接后端MySQL的连接信息。</span><br><span class="line"> </span><br><span class="line">stats_mysql_processlist</span><br><span class="line">类似MySQL的show processlist的命令，查看各线程的状态。</span><br><span class="line"> </span><br><span class="line">stats_mysql_query_digest</span><br><span class="line">表示SQL的执行次数、时间消耗等。通过变量mysql-query_digests控制开关，默认是开。</span><br><span class="line"> </span><br><span class="line">stats_mysql_query_rules</span><br><span class="line">路由命中次数统计。</span><br><span class="line"> </span><br><span class="line">3）monitor库</span><br><span class="line">MySQL [(none)]&gt; show tables from monitor;            </span><br><span class="line">+------------------------------------+</span><br><span class="line">| tables                             |</span><br><span class="line">+------------------------------------+</span><br><span class="line">| mysql_server_connect_log           |</span><br><span class="line">| mysql_server_group_replication_log |</span><br><span class="line">| mysql_server_ping_log              |</span><br><span class="line">| mysql_server_read_only_log         |</span><br><span class="line">| mysql_server_replication_lag_log   |</span><br><span class="line">+------------------------------------+</span><br><span class="line">5 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.000 sec)</span><br><span class="line"> </span><br><span class="line">常用的几个表介绍</span><br><span class="line">===============================================</span><br><span class="line">mysql_server_connect_log</span><br><span class="line">连接到所有MySQL服务器以检查它们是否可用，该表用来存放检测连接的日志。</span><br><span class="line"> </span><br><span class="line">mysql_server_ping_log</span><br><span class="line">使用mysql_ping API ping后端MySQL服务器，检查它们是否可用，该表用来存放ping的日志。</span><br><span class="line"> </span><br><span class="line">mysql_server_replication_lag_log</span><br><span class="line">后端MySQL服务主从延迟的检测。</span><br><span class="line"> </span><br><span class="line">runtime_开头的是运行时的配置，这些是不能修改的。要修改ProxySQL的配置，需要修改了非runtime_表，</span><br><span class="line">修改后必须执行<span class="string">"LOAD ... TO RUNTIME"</span>才能加载到RUNTIME生效，执行save ... to disk才能将配置持久化保存到磁盘。</span><br></pre></td></tr></table></figure><p>global_variables 有80多个变量可以设置，其中就包括监听的端口、管理账号、禁用monitor等</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line">(admin@127.0.0.1:6032) [(none)]&gt; show tables;</span><br><span class="line">+--------------------------------------------+</span><br><span class="line">| tables                                     |</span><br><span class="line">+--------------------------------------------+</span><br><span class="line">| global_variables                           |</span><br><span class="line">| mysql_collations                           |</span><br><span class="line">| mysql_group_replication_hostgroups         |</span><br><span class="line">| mysql_query_rules                          |</span><br><span class="line">| mysql_query_rules_fast_routing             |</span><br><span class="line">| mysql_replication_hostgroups               |</span><br><span class="line">| mysql_servers                              |</span><br><span class="line">| mysql_users                                |</span><br><span class="line">| proxysql_servers                           |</span><br><span class="line">| runtime_checksums_values                   |</span><br><span class="line">| runtime_global_variables                   |</span><br><span class="line">| runtime_mysql_group_replication_hostgroups |</span><br><span class="line">| runtime_mysql_query_rules                  |</span><br><span class="line">| runtime_mysql_query_rules_fast_routing     |</span><br><span class="line">| runtime_mysql_replication_hostgroups       |</span><br><span class="line">| runtime_mysql_servers                      |</span><br><span class="line">| runtime_mysql_users                        |</span><br><span class="line">| runtime_proxysql_servers                   |</span><br><span class="line">| runtime_scheduler                          |</span><br><span class="line">| scheduler                                  |</span><br><span class="line">+--------------------------------------------+</span><br><span class="line">20 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.001 sec)</span><br><span class="line">  </span><br><span class="line">(admin@127.0.0.1:6032) [(none)]&gt; show tables from stats;</span><br><span class="line">+--------------------------------------+</span><br><span class="line">| tables                               |</span><br><span class="line">+--------------------------------------+</span><br><span class="line">| global_variables                     |</span><br><span class="line">| stats_memory_metrics                 |</span><br><span class="line">| stats_mysql_commands_counters        |</span><br><span class="line">| stats_mysql_connection_pool          |</span><br><span class="line">| stats_mysql_connection_pool_reset    |</span><br><span class="line">| stats_mysql_global                   |</span><br><span class="line">| stats_mysql_prepared_statements_info |</span><br><span class="line">| stats_mysql_processlist              |</span><br><span class="line">| stats_mysql_query_digest             |</span><br><span class="line">| stats_mysql_query_digest_reset       |</span><br><span class="line">| stats_mysql_query_rules              |</span><br><span class="line">| stats_mysql_users                    |</span><br><span class="line">| stats_proxysql_servers_checksums     |</span><br><span class="line">| stats_proxysql_servers_metrics       |</span><br><span class="line">| stats_proxysql_servers_status        |</span><br><span class="line">+--------------------------------------+</span><br><span class="line">15 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.000 sec)</span><br><span class="line">  </span><br><span class="line">(admin@127.0.0.1:6032) [(none)]&gt; show create table mysql_servers\G;</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">       table: mysql_servers</span><br><span class="line">Create Table: CREATE TABLE mysql_servers (</span><br><span class="line">    hostgroup_id INT CHECK (hostgroup_id&gt;=0) NOT NULL DEFAULT 0,</span><br><span class="line">    hostname VARCHAR NOT NULL,</span><br><span class="line">    port INT NOT NULL DEFAULT 3306,</span><br><span class="line">    status VARCHAR CHECK (UPPER(status) IN (<span class="string">'ONLINE'</span>,<span class="string">'SHUNNED'</span>,<span class="string">'OFFLINE_SOFT'</span>, <span class="string">'OFFLINE_HARD'</span>)) NOT NULL DEFAULT <span class="string">'ONLINE'</span>,</span><br><span class="line">    weight INT CHECK (weight &gt;= 0) NOT NULL DEFAULT 1,</span><br><span class="line">    compression INT CHECK (compression &gt;=0 AND compression &lt;= 102400) NOT NULL DEFAULT 0,</span><br><span class="line">    max_connections INT CHECK (max_connections &gt;=0) NOT NULL DEFAULT 1000,</span><br><span class="line">    max_replication_lag INT CHECK (max_replication_lag &gt;= 0 AND max_replication_lag &lt;= 126144000) NOT NULL DEFAULT 0,</span><br><span class="line">    use_ssl INT CHECK (use_ssl IN(0,1)) NOT NULL DEFAULT 0,</span><br><span class="line">    max_latency_ms INT UNSIGNED CHECK (max_latency_ms&gt;=0) NOT NULL DEFAULT 0,</span><br><span class="line">    comment VARCHAR NOT NULL DEFAULT <span class="string">''</span>,</span><br><span class="line">    PRIMARY KEY (hostgroup_id, hostname, port) )</span><br><span class="line">1 row <span class="keyword">in</span> <span class="built_in">set</span> (0.000 sec)</span><br><span class="line">  </span><br><span class="line">ERROR: No query specified</span><br><span class="line">  </span><br><span class="line">(admin@127.0.0.1:6032) [(none)]&gt; select * from mysql_servers;</span><br><span class="line">+--------------+---------------+------+--------+--------+-------------+-----------------+---------------------+---------+----------------+---------+</span><br><span class="line">| hostgroup_id | hostname      | port | status | weight | compression | max_connections | max_replication_lag | use_ssl | max_latency_ms | comment |</span><br><span class="line">+--------------+---------------+------+--------+--------+-------------+-----------------+---------------------+---------+----------------+---------+</span><br><span class="line">| 10           | 172.16.60.211 | 3306 | ONLINE | 1      | 0           | 1000            | 0                   | 0       | 0              |         |</span><br><span class="line">| 20           | 172.16.60.212 | 3306 | ONLINE | 1      | 0           | 1000            | 0                   | 0       | 0              |         |</span><br><span class="line">| 20           | 172.16.60.213 | 3306 | ONLINE | 1      | 0           | 1000            | 0                   | 0       | 0              |         |</span><br><span class="line">+--------------+---------------+------+--------+--------+-------------+-----------------+---------------------+---------+----------------+---------+</span><br><span class="line">3 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.000 sec)</span><br></pre></td></tr></table></figure><p><strong>-</strong>  hostgroup_id: ProxySQL通过 hostgroup (<strong>下称HG</strong>) 的形式组织后端db实例。一个 HG 代表同属于一个角色<br><strong>-</strong>  该表的主键是 (hostgroup_id, hostname, port)，可以看到一个 hostname:port 可以在多个hostgroup里面，如上面的 10.0.100.100:3307，这样可以避免 HG 1000 的从库全都不可用时，依然可以把读请求发到主库上。<br><strong>-</strong>  一个 HG 可以有多个实例，即多个从库，可以通过 weight 分配权重<br><strong>-</strong>  hostgroup_id 0 是一个特殊的HG，路由查询的时候，没有匹配到规则则默认选择 HG 0<br><strong>-</strong>  status:<br><strong>-</strong>  ONLINE: 当前后端实例状态正常<br>   <strong>-</strong>  SHUNNED: 临时被剔除，可能因为后端 too many connections error，或者超过了可容忍延迟阀值 max_replication_lag<br>   <strong>-</strong>  OFFLINE_SOFT: “软离线”状态，不再接受新的连接，但已建立的连接会等待活跃事务完成。<br>   <strong>-</strong>  OFFLINE_HARD: “硬离线”状态，不再接受新的连接，已建立的连接或被强制中断。当后端实例宕机或网络不可达，会出现。<br><strong>-</strong>  max_connections: 允许连接到该后端mysql实例的最大连接数。不要大于MySQL设置的 max_connections，如果后端实例 hostname:port 在多个 hostgroup 里，以较大者为准，而不是各自独立允许的最大连接数。<br><strong>-</strong>  max_replication_lag: 允许的最大延迟，主库不受这个影响，默认0。如果 &gt; 0， monitor 模块监控主从延迟大于阀值时，会临时把它变为 SHUNNED 。<br><strong>-</strong>  max_latency_ms: mysql_ping 响应时间，大于这个阀值会把它从连接池剔除（即使是ONLINE）<br><strong>-</strong>  comment: 备注，不建议留空。可以通过它的内容如json格式的数据，配合自己写的check脚本，完成一些自动化的工作。</p><p>表 mysql_users</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">MySQL [(none)]&gt; show create table mysql_users\G;</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">       table: mysql_users</span><br><span class="line">Create Table: CREATE TABLE mysql_users (</span><br><span class="line">    username VARCHAR NOT NULL,</span><br><span class="line">    password VARCHAR,</span><br><span class="line">    active INT CHECK (active IN (0,1)) NOT NULL DEFAULT 1,</span><br><span class="line">    use_ssl INT CHECK (use_ssl IN (0,1)) NOT NULL DEFAULT 0,</span><br><span class="line">    default_hostgroup INT NOT NULL DEFAULT 0,</span><br><span class="line">    default_schema VARCHAR,</span><br><span class="line">    schema_locked INT CHECK (schema_locked IN (0,1)) NOT NULL DEFAULT 0,</span><br><span class="line">    transaction_persistent INT CHECK (transaction_persistent IN (0,1)) NOT NULL DEFAULT 1,</span><br><span class="line">    fast_forward INT CHECK (fast_forward IN (0,1)) NOT NULL DEFAULT 0,</span><br><span class="line">    backend INT CHECK (backend IN (0,1)) NOT NULL DEFAULT 1,</span><br><span class="line">    frontend INT CHECK (frontend IN (0,1)) NOT NULL DEFAULT 1,</span><br><span class="line">    max_connections INT CHECK (max_connections &gt;=0) NOT NULL DEFAULT 10000,</span><br><span class="line">    PRIMARY KEY (username, backend),</span><br><span class="line">    UNIQUE (username, frontend))</span><br><span class="line">1 row <span class="keyword">in</span> <span class="built_in">set</span> (0.000 sec)</span><br><span class="line">  </span><br><span class="line">ERROR: No query specified</span><br><span class="line">  </span><br><span class="line">MySQL [(none)]&gt; select * from mysql_users;</span><br><span class="line">+-----------+------------+--------+---------+-------------------+----------------+---------------+------------------------+--------------+---------+----------+-----------------+</span><br><span class="line">| username  | password   | active | use_ssl | default_hostgroup | default_schema | schema_locked | transaction_persistent | fast_forward | backend | frontend | max_connections |</span><br><span class="line">+-----------+------------+--------+---------+-------------------+----------------+---------------+------------------------+--------------+---------+----------+-----------------+</span><br><span class="line">| proxysql  | proxysql   | 1      | 0       | 2                 | NULL           | 0             | 1                      | 0            | 1       | 1        | 10000           |</span><br><span class="line">| root      | passwd     | 1      | 0       | 10                | NULL           | 0             | 1                      | 0            | 1       | 1        | 10000           |</span><br><span class="line">| sqlsender | P@ssword1! | 1      | 0       | 10                | NULL           | 0             | 1                      | 0            | 1       | 1        | 10000           |</span><br><span class="line">+-----------+------------+--------+---------+-------------------+----------------+---------------+------------------------+--------------+---------+----------+-----------------+</span><br><span class="line">3 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.000 sec)</span><br><span class="line">  </span><br><span class="line">MySQL [(none)]&gt; select username,password,transaction_persistent,active,backend,frontend,max_connections from runtime_mysql_users;</span><br><span class="line">+-----------+-------------------------------------------+------------------------+--------+---------+----------+-----------------+</span><br><span class="line">| username  | password                                  | transaction_persistent | active | backend | frontend | max_connections |</span><br><span class="line">+-----------+-------------------------------------------+------------------------+--------+---------+----------+-----------------+</span><br><span class="line">| proxysql  | *BF27B4C7AAD278126E228AA8427806E870F64F39 | 1                      | 1      | 0       | 1        | 10000           |</span><br><span class="line">| root      | *59C70DA2F3E3A5BDF46B68F5C8B8F25762BCCEF0 | 1                      | 1      | 0       | 1        | 10000           |</span><br><span class="line">| sqlsender | *50572A5FABC7DA9CEE5EB5977EDDE59E38967422 | 1                      | 1      | 0       | 1        | 10000           |</span><br><span class="line">| proxysql  | *BF27B4C7AAD278126E228AA8427806E870F64F39 | 1                      | 1      | 1       | 0        | 10000           |</span><br><span class="line">| root      | *59C70DA2F3E3A5BDF46B68F5C8B8F25762BCCEF0 | 1                      | 1      | 1       | 0        | 10000           |</span><br><span class="line">| sqlsender | *50572A5FABC7DA9CEE5EB5977EDDE59E38967422 | 1                      | 1      | 1       | 0        | 10000           |</span><br><span class="line">+-----------+-------------------------------------------+------------------------+--------+---------+----------+-----------------+</span><br><span class="line">6 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.001 sec)</span><br></pre></td></tr></table></figure><p><strong>-</strong>  username, password: 连接后端db的用户密码。<br>这个密码你可以插入明文，也可以插入hash加密后的密文，proxysql会检查你插入的时候密码是否以 * 开头来判断，而且密文要在其它地方使用 PASSWORD()生成。但到 runtime_mysql_users 里，都统一变成了密文，所以可以明文插入，再 SAVE MYSQL USERS TO MEM，此时看到的也是HASH密文。<br><strong>-</strong>  active: 是否生效该用户。<br><strong>-</strong>  default_hostgroup: 这个用户的请求没有匹配到规则时，默认发到这个 hostgroup，默认0<br><strong>-</strong>  default_schema: 这个用户连接时没有指定 database name 时，默认使用的schema<br>注意表面上看默认为NULL，但实际上受到变量 mysql-default_schema 的影响，默认为 information_schema。关于这个参考我所提的 issue #988<br><strong>-</strong>  transaction_persistent: 如果设置为1，连接上ProxySQL的会话后，如果在一个hostgroup上开启了事务，那么后续的sql都继续维持在这个hostgroup上，不伦是否会匹配上其它路由规则，直到事务结束。<br>虽然默认是0，但我建议还是设成1，虽然一般来说由于前段应用的空值，为0出问题的情况几乎很小。作者也在考虑默认设成 1，refer this issue #793<br><strong>-</strong>  frontend, backend: 目前版本这两个都需要使用默认的1，将来有可能会把 Client -&gt; ProxySQL (frontend) 与 ProxySQL -&gt; BackendDB (backend)的认证分开。从 runtime_mysql_users 表内容看到，记录数比 mysql_users 多了一倍，就是把前端认证与后端认证独立出来的结果。<br><strong>-</strong>  fast_forward: 忽略查询重写/缓存层，直接把这个用户的请求透传到后端DB。相当于只用它的连接池功能，一般不用，路由规则 .* 就行了。</p><p>表 mysql_replication_hostgroups</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">MySQL [(none)]&gt; show create table mysql_replication_hostgroups\G;</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">       table: mysql_replication_hostgroups</span><br><span class="line">Create Table: CREATE TABLE mysql_replication_hostgroups (</span><br><span class="line">    writer_hostgroup INT CHECK (writer_hostgroup&gt;=0) NOT NULL PRIMARY KEY,</span><br><span class="line">    reader_hostgroup INT NOT NULL CHECK (reader_hostgroup&lt;&gt;writer_hostgroup AND reader_hostgroup&gt;0),</span><br><span class="line">    comment VARCHAR NOT NULL DEFAULT <span class="string">''</span>, UNIQUE (reader_hostgroup))</span><br><span class="line">1 row <span class="keyword">in</span> <span class="built_in">set</span> (0.001 sec)</span><br><span class="line">  </span><br><span class="line">ERROR: No query specified</span><br><span class="line">  </span><br><span class="line">MySQL [(none)]&gt; select * from mysql_replication_hostgroups;</span><br><span class="line">+------------------+------------------+---------+</span><br><span class="line">| writer_hostgroup | reader_hostgroup | comment |</span><br><span class="line">+------------------+------------------+---------+</span><br><span class="line">| 10               | 20               | 1       |</span><br><span class="line">+------------------+------------------+---------+</span><br><span class="line">1 row <span class="keyword">in</span> <span class="built_in">set</span> (0.000 sec)</span><br></pre></td></tr></table></figure><p>定义 hostgroup 的主从关系。ProxySQL monitor 模块会监控 HG 后端所有servers 的 <code>read_only</code> 变量，如果发现从库的 read_only 变为0、主库变为1，则认为角色互换了，自动改写 mysql_servers 表里面 hostgroup 关系，达到自动 Failover 效果。</p><p>表 mysql_query_rules<br>mysql_query_rules 是ProxySQL非常核心一个表，定义查询路由规则</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">MySQL [(none)]&gt; show create table mysql_query_rules\G;</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">       table: mysql_query_rules</span><br><span class="line">Create Table: CREATE TABLE mysql_query_rules (</span><br><span class="line">    rule_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,</span><br><span class="line">    active INT CHECK (active IN (0,1)) NOT NULL DEFAULT 0,</span><br><span class="line">    username VARCHAR,</span><br><span class="line">    schemaname VARCHAR,</span><br><span class="line">    flagIN INT NOT NULL DEFAULT 0,</span><br><span class="line">    client_addr VARCHAR,</span><br><span class="line">    proxy_addr VARCHAR,</span><br><span class="line">    proxy_port INT,</span><br><span class="line">    digest VARCHAR,</span><br><span class="line">    match_digest VARCHAR,</span><br><span class="line">    match_pattern VARCHAR,</span><br><span class="line">    negate_match_pattern INT CHECK (negate_match_pattern IN (0,1)) NOT NULL DEFAULT 0,</span><br><span class="line">    re_modifiers VARCHAR DEFAULT <span class="string">'CASELESS'</span>,</span><br><span class="line">    flagOUT INT,</span><br><span class="line">    replace_pattern VARCHAR,</span><br><span class="line">    destination_hostgroup INT DEFAULT NULL,</span><br><span class="line">    cache_ttl INT CHECK(cache_ttl &gt; 0),</span><br><span class="line">    reconnect INT CHECK (reconnect IN (0,1)) DEFAULT NULL,</span><br><span class="line">    timeout INT UNSIGNED,</span><br><span class="line">    retries INT CHECK (retries&gt;=0 AND retries &lt;=1000),</span><br><span class="line">    delay INT UNSIGNED,</span><br><span class="line">    next_query_flagIN INT UNSIGNED,</span><br><span class="line">    mirror_flagOUT INT UNSIGNED,</span><br><span class="line">    mirror_hostgroup INT UNSIGNED,</span><br><span class="line">    error_msg VARCHAR,</span><br><span class="line">    OK_msg VARCHAR,</span><br><span class="line">    sticky_conn INT CHECK (sticky_conn IN (0,1)),</span><br><span class="line">    multiplex INT CHECK (multiplex IN (0,1,2)),</span><br><span class="line">    <span class="built_in">log</span> INT CHECK (<span class="built_in">log</span> IN (0,1)),</span><br><span class="line">    apply INT CHECK(apply IN (0,1)) NOT NULL DEFAULT 0,</span><br><span class="line">    comment VARCHAR)</span><br><span class="line">1 row <span class="keyword">in</span> <span class="built_in">set</span> (0.001 sec)</span><br><span class="line">  </span><br><span class="line">ERROR: No query specified</span><br><span class="line">  </span><br><span class="line">MySQL [(none)]&gt; select * from mysql_query_rules;</span><br><span class="line">+---------+--------+----------+------------+--------+-------------+------------+------------+--------+----------------------+---------------+----------------------+--------------+---------+-----------------+-----------------------+-----------+-----------+---------+---------+-------+-------------------+----------------+------------------+-----------+--------+-------------+-----------+-----+-------+---------+</span><br><span class="line">| rule_id | active | username | schemaname | flagIN | client_addr | proxy_addr | proxy_port | digest | match_digest         | match_pattern | negate_match_pattern | re_modifiers | flagOUT | replace_pattern | destination_hostgroup | cache_ttl | reconnect | timeout | retries | delay | next_query_flagIN | mirror_flagOUT | mirror_hostgroup | error_msg | OK_msg | sticky_conn | multiplex | <span class="built_in">log</span> | apply | comment |</span><br><span class="line">+---------+--------+----------+------------+--------+-------------+------------+------------+--------+----------------------+---------------+----------------------+--------------+---------+-----------------+-----------------------+-----------+-----------+---------+---------+-------+-------------------+----------------+------------------+-----------+--------+-------------+-----------+-----+-------+---------+</span><br><span class="line">| 1       | 1      | NULL     | NULL       | 0      | NULL        | NULL       | NULL       | NULL   | ^SELECT.*FOR UPDATE$ | NULL          | 0                    | CASELESS     | NULL    | NULL            | 10                    | NULL      | NULL      | NULL    | NULL    | NULL  | NULL              | NULL           | NULL             | NULL      | NULL   | NULL        | NULL      | NULL | 1     | NULL    |</span><br><span class="line">| 2       | 1      | NULL     | NULL       | 0      | NULL        | NULL       | NULL       | NULL   | ^SELECT              | NULL          | 0                    | CASELESS     | NULL    | NULL            | 20                    | NULL      | NULL      | NULL    | NULL    | NULL  | NULL              | NULL           | NULL             | NULL      | NULL   | NULL        | NULL      | NULL | 1     | NULL    |</span><br><span class="line">+---------+--------+----------+------------+--------+-------------+------------+------------+--------+----------------------+---------------+----------------------+--------------+---------+-----------------+-----------------------+-----------+-----------+---------+---------+-------+-------------------+----------------+------------------+-----------+--------+-------------+-----------+-----+-------+---------+</span><br><span class="line">2 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.000 sec)</span><br></pre></td></tr></table></figure><p><strong>-</strong>  rule_id: 表主键，自增。规则处理是以 rule_id 的顺序进行。<br><strong>-</strong>  active: 只有 active=1 的规则才会参与匹配。<br><strong>-</strong>  username: 如果非 NULL，只有连接用户是 username 的值才会匹配。<br><strong>-</strong>  schemaname: 如果非 NULL，只有查询连接使用的db是 schemaname 的值才会匹配。<br>   注意如果是 NULL，不代表连接没有使用schema，而是不伦任何schema都进一步匹配。<br><strong>-</strong>  flagIN, flagOUT, apply: 用来定义路由链 chains of rules。<br>   <strong>-</strong>  首先会检查 flagIN=0 的规则，以rule_id的顺序；如果都没匹配上，则走这个用户的 default_hostgroup。<br>   <strong>-</strong>  当匹配一条规则后，会检查 flagOUT。<br>      <strong>-</strong>  如果不为NULL，并且 flagIN != flagOUT ，则进入以flagIN为上一个flagOUT值的新规则链。<br>      <strong>-</strong>  如果不为NULL，并且 flagIN = flagOUT，则应用这条规则。<br>      <strong>-</strong>  如果为NULL，或者 apply=1，则结束，应用这条规则。<br>      <strong>-</strong>  如果最终没有匹配到，则找到这个用户的 default_hostgroup。<br><strong>-</strong>  client_addr: 匹配客户端来源IP<br><strong>-</strong>  proxy_addr, proxy_port: 匹配本地proxysql的IP、端口。我目前没有想到它的应用场景，可能是把proxysql监听在多个接口上，分发到不同的业务？<br><strong>-</strong>  digest: 精确的匹配一类查询。<br><strong>-</strong>  match_digest: 正则匹配一类查询。query digest 是指对查询去掉具体值后进行“模糊化”后的查询，类似 pt-fingerprint / pt-query-digest 的效果。<br><strong>-</strong>  match_pattern: 正则匹配查询。</p><p>以上都是匹配查询的规则，1.3.5版本使用的正则引擎只有 RE2 ，1.4版本可以通过变量 mysql-query_processor_regex 设置 RE2 或者 PCRE，且1.4开始默认是PCRE。<br>推荐用 match_digest 。关于每条查询都会计算digest对性能的影响，计算query digest确实会有性能损失，但是这却是proxysql里面非常重要的特性，主要是两点：<br>   <strong>-</strong>  proxysql无法知道连接复用(multipexing)是否必须被自动禁用，比如连接里面有variables/tmp tables/lock table等特殊命令，是不能复用的。<br>   <strong>-</strong>  完整的查询去匹配正则的效率，一般没有参数化后的查询匹配效率高，因为有很长的字符串内容需要处理。再者，SELECT * FROM randomtable WHERE comment LIKE ‘%INTO sbtest1 %                FROM sbtest2 %’字符串里有类似这样的语句，很难排除误匹配。<br><strong>-</strong>  negate_match_pattern: 反向匹配，相当于对 match_digest/match_pattern 的匹配取反。<br><strong>-</strong>  re_modifiers: 修改正则匹配的参数，比如默认的：忽略大小写CASELESS、禁用GLOBAL.</p><p><strong>上面都是匹配规则，下面是匹配后的行为</strong><br><strong>-</strong>  replace_pattern: 查询重写，默认为空，不rewrite。<br><strong>-</strong>  rewrite规则要遵守 RE2::Replace 。<br>destination_hostgroup: 路由查询到这个 hostgroup。当然如果用户显式 start transaction 且 transaction_persistent=1，那么即使匹配到了，也依然按照事务里第一条sql的路由规则去走。<br><strong>-</strong>  cache_ttl: 查询结果缓存的毫秒数。<br>proxysql这个 Query Cache 与 MySQL 自带的query cache不是同一个。proxysql query cache也不会关心后端数据是否被修改，它所做的就是针对某些特定种类的查询结果进行缓存，比如一些历史数据的count结果。一般不设。<br><strong>-</strong>  timeout: 这一类查询执行的最大时间（毫秒），超时则自动kill。<br>这是对后端DB的保护机制，相当于阿里云RDS loose_max_statement_time 变量的功能，但是注意不同的是，阿里云这个变量的时间时不包括DML操作出现InnoDB行锁等待的时间，而ProxySQL的这个 timeout 是计算从发送sql到等待响应的时间。默认mysql-default_query_timeout给的是 10h .<br><strong>-</strong>  retries: 语句在执行时失败时，重试次数。默认由 mysql-query_retries_on_failure变量指定，为1 。<br>   个人建议把它设成0，即不重试。因为执行失败，对select而言很少见，主要是dml，但自己重试对数据不放心。<br><strong>-</strong>  delay: 查询延迟执行，这是ProxySQL提供的限流机制，会让其它的查询优先执行。<br>   默认值 mysql-default_query_delay，为0。我们一般不用，其实还是要配合应用端使用，比如这边延迟执行，但上层等待你返回，那前端不就堵住了，没准出现雪崩效应。<br><strong>-</strong>  mirror_flagOUT,mirror_hostgroup<br>这两个高级了，目前这部分文档不全，功能是SQL镜像。顾名思义，就是把匹配到的SQL除了发送到 destination_hostgroup，同时镜像一份到这里的hostgroup，比如我们的测试库。比如这种场景，数据库要从5.6升级到5.7，要验证现有查询语句对5.7的适用情况，就可以把生产流量镜像到5.7新库上验证。<br><strong>-</strong>  error_msg: 默认为NULL，如果指定了则这个查询直接被 block 掉，马上返回这个错误信息。<br>这个功能也很实用，比如线上突然冒出一个 “坏查询”，应用端不方便马上发版解决，我们就可以在这配置一个规则，把查询屏蔽掉，想正常的mysql报错那样抛异常。下一篇文章有演示。<br><strong>-</strong>  multiplex: 连接是否复用。<br><strong>-</strong>  log: 是否记录查询日志。可以看到log是否记录的对象是根据规则。<br>要开启日志记录，需要设置变量 mysql-eventslog_filename 来指定文件名，然后这个 log 标记为1。但是目前proxysql记录的日志是二进制格式，需要特定的工具才能读取： eventslog_reader_sample 。这个工具在源码目录 tools下面。</p><p>proxysql对后端server健康检查</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">MySQL [monitor]&gt; show variables like <span class="string">"mysql-monitor%"</span>;</span><br><span class="line">+-----------------------------------------------------+------------+</span><br><span class="line">| Variable_name                                       | Value      |</span><br><span class="line">+-----------------------------------------------------+------------+</span><br><span class="line">| mysql-monitor_enabled                               | <span class="literal">true</span>       |</span><br><span class="line">| mysql-monitor_connect_timeout                       | 600        |</span><br><span class="line">| mysql-monitor_ping_max_failures                     | 3          |</span><br><span class="line">| mysql-monitor_ping_timeout                          | 1000       |</span><br><span class="line">| mysql-monitor_read_only_max_timeout_count           | 3          |</span><br><span class="line">| mysql-monitor_replication_lag_interval              | 10000      |</span><br><span class="line">| mysql-monitor_replication_lag_timeout               | 1000       |</span><br><span class="line">| mysql-monitor_groupreplication_healthcheck_interval | 5000       |</span><br><span class="line">| mysql-monitor_groupreplication_healthcheck_timeout  | 800        |</span><br><span class="line">| mysql-monitor_replication_lag_use_percona_heartbeat |            |</span><br><span class="line">| mysql-monitor_query_interval                        | 60000      |</span><br><span class="line">| mysql-monitor_query_timeout                         | 100        |</span><br><span class="line">| mysql-monitor_slave_lag_when_null                   | 60         |</span><br><span class="line">| mysql-monitor_wait_timeout                          | <span class="literal">true</span>       |</span><br><span class="line">| mysql-monitor_writer_is_also_reader                 | <span class="literal">true</span>       |</span><br><span class="line">| mysql-monitor_username                              | monitor    |</span><br><span class="line">| mysql-monitor_password                              | P@ssword1! |</span><br><span class="line">| mysql-monitor_history                               | 600000     |</span><br><span class="line">| mysql-monitor_connect_interval                      | 60000      |</span><br><span class="line">| mysql-monitor_ping_interval                         | 10000      |</span><br><span class="line">| mysql-monitor_read_only_interval                    | 1500       |</span><br><span class="line">| mysql-monitor_read_only_timeout                     | 500        |</span><br><span class="line">+-----------------------------------------------------+------------+</span><br><span class="line">22 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.001 sec)</span><br></pre></td></tr></table></figure><h2 id="ProxySQL配置后端DB-server"><a href="#ProxySQL配置后端DB-server" class="headerlink" title="ProxySQL配置后端DB server"></a><strong>ProxySQL配置后端DB server</strong></h2><p><strong>两种方式，区别在于</strong></p><p>1)  一种是在往mysql_servers表中添加server时就为其划分好hostgroup_id（例如0表示写组，1表示读组）<br>2)  另一种往mysql_servers表中添加server时不区分hostgroup_id（例如全部设为0），然后通过mysql_replication_hostgroups表中的值，<br>根据proxysql检测到的各server的read_only变量值来自动为后端server设置hostgroup_id</p><p><strong>这里强烈推荐用第一种方式</strong><br>因为第一种是完全由我们控制的;而第二种假如我们误将读server的read_only属性设置为0，则proxysql会将其重新分配到写组，这绝对是不期望的。</p><p><strong>ProxySQL下添加与修改配置</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">1) 添加配置</span><br><span class="line">需要添加配置时，直接操作的是MEMORAY，例如：添加一个程序用户，在mysql_users表中执行一个插入操作：</span><br><span class="line">MySQL [(none)]&gt; insert into mysql_users(username,password,active,default_hostgroup,transaction_persistent) values(<span class="string">'myadmin'</span>,<span class="string">'mypass'</span>,1,0,1);</span><br><span class="line">  </span><br><span class="line">这样就完成了一个用户的添加。要让这个insert生效，还需要执行如下操作：</span><br><span class="line">MySQL [(none)]&gt;load mysql users to runtime;</span><br><span class="line">表示将修改后的配置(MEMORY层)用到实际生产环境（RUNTIME层）</span><br><span class="line">  </span><br><span class="line">如果想保存这个设置永久生效，还需要执行如下操作：</span><br><span class="line">MySQL [(none)]&gt;save mysql users to disk;</span><br><span class="line">表示将memoery中的配置保存到磁盘中去。</span><br><span class="line">  </span><br><span class="line">除了上面两个操作，还可以执行如下操作：</span><br><span class="line">MySQL [(none)]&gt;load mysql users to memory;</span><br><span class="line">表示将磁盘中持久化的配置拉一份到memory中来。</span><br><span class="line">  </span><br><span class="line">MySQL [(none)]&gt;load mysql users from config;</span><br><span class="line">表示将配置文件中的配置加载到memeory中。</span><br><span class="line">  </span><br><span class="line">2) 持久化配置</span><br><span class="line">以上SQL命令是对mysql_users进行的操作，同理，还可以对mysql_servers表、mysql_query_rules表、global_variables表等执行类似的操作。</span><br><span class="line">如对mysql_servers表插入完成数据后，要执行保存和加载操作，可执行如下SQL命令：</span><br><span class="line">MySQL [(none)]&gt; load mysql servers to runtime;</span><br><span class="line">MySQL [(none)]&gt; save mysql servers to disk;</span><br><span class="line">  </span><br><span class="line">对mysql_query_rules表插入完成数据后，要执行保存和加载操作，可执行如下SQL命令：</span><br><span class="line">MySQL [(none)]&gt; load mysql query rules to runtime;</span><br><span class="line">MySQL [(none)]&gt; save mysql query rules to disk;</span><br><span class="line">  </span><br><span class="line">对global_variables表插入完成数据后，要执行保存和加载操作，可执行如下SQL命令：</span><br><span class="line">  </span><br><span class="line">以下命令加载或保存mysql variables（global_variables）:</span><br><span class="line">MySQL [(none)]&gt;load mysql variables to runtime;</span><br><span class="line">MySQL [(none)]&gt;save mysql variables to disk;</span><br><span class="line">  </span><br><span class="line">以下命令加载或保存admin variables（select * from global_variables <span class="built_in">where</span> variable_name like <span class="string">'admin-%'</span>）:</span><br><span class="line">MySQL [(none)]&gt; load admin variables to runtime;</span><br><span class="line">MySQL [(none)]&gt;save admin variables to disk;</span><br></pre></td></tr></table></figure><h2 id="实战功能验证"><a href="#实战功能验证" class="headerlink" title="实战功能验证"></a>实战功能验证</h2><p>针对GTID模式的主从同步，另两个从库都要设置read_only=on<br>接下来通过实战操作来全面了解一下 ProxySQL 的特性和使用场景。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8307f670/1.png" alt></p><h3 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a><strong>实验环境</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">172.16.60.211    mysql-master       安装Mysql5.7</span><br><span class="line">172.16.60.212    mysql-slave1       安装Mysql5.7</span><br><span class="line">172.16.60.213    mysql-slave2       安装Mysql5.7</span><br><span class="line">172.16.60.214    mysql-proxy        安装ProxySQL，Mysql-client</span><br><span class="line"> </span><br><span class="line">系统都是CentOS7.5，MySQL版本是5.7，准备一主两从架构(基于GTID的同步,两个从库都要开启read_only=on)来配合ProxySQL。</span><br><span class="line">[root@mysql-master ~]<span class="comment"># cat /etc/redhat-release</span></span><br><span class="line">CentOS Linux release 7.5.1804 (Core)</span><br><span class="line"> </span><br><span class="line">1) 三个节点各自设置主机名</span><br><span class="line">[root@mysql-master ~]<span class="comment"># hostnamectl --static set-hostname mysql-master</span></span><br><span class="line">[root@mysql-master ~]<span class="comment"># hostname</span></span><br><span class="line">mysql-master</span><br><span class="line">  </span><br><span class="line">[root@mysql-slave1 ~]<span class="comment"># hostnamectl --static set-hostname mysql-slave1</span></span><br><span class="line">[root@mysql-slave1 ~]<span class="comment"># hostname</span></span><br><span class="line">mysql-slave</span><br><span class="line"> </span><br><span class="line">[root@mysql-slave2 ~]<span class="comment"># hostnamectl --static set-hostname mysql-slave2</span></span><br><span class="line">[root@mysql-slave2 ~]<span class="comment"># hostname</span></span><br><span class="line">mysql-slave</span><br><span class="line"> </span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># hostnamectl --static set-hostname mysql-proxy</span></span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># hostname</span></span><br><span class="line">mysql-proxy</span><br><span class="line">  </span><br><span class="line">2) 所有节点关闭selinux和iptables防火墙</span><br><span class="line">[root@mysql-master ~]<span class="comment"># setenforce 0</span></span><br><span class="line">[root@mysql-master ~]<span class="comment"># cat /etc/sysconfig/selinux |grep "SELINUX=disabled"</span></span><br><span class="line">SELINUX=disabled</span><br><span class="line">  </span><br><span class="line">[root@mysql-master ~]<span class="comment"># iptables -F</span></span><br><span class="line">[root@mysql-master ~]<span class="comment"># systemctl disable firewalld</span></span><br><span class="line">[root@mysql-master ~]<span class="comment"># systemctl stop firewalld </span></span><br><span class="line">[root@mysql-master ~]<span class="comment"># firewall-cmd --state</span></span><br><span class="line">not running</span><br></pre></td></tr></table></figure><h3 id="安装Mysql-5-7-在三个mysql节点上安装"><a href="#安装Mysql-5-7-在三个mysql节点上安装" class="headerlink" title="安装Mysql 5.7  (在三个mysql节点上安装)"></a><strong>安装Mysql 5.7  (在三个mysql节点上安装)</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">在三个mysql节点机上使用yum方式安装Mysql5.7，参考：https://www.cnblogs.com/kevingrace/p/8340690.html</span><br><span class="line">     </span><br><span class="line">安装MySQL yum资源库</span><br><span class="line">[root@mysql-master ~]<span class="comment"># yum localinstall https://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm</span></span><br><span class="line">     </span><br><span class="line">安装MySQL 5.7</span><br><span class="line">[root@mysql-master ~]<span class="comment"># yum install -y mysql-community-server</span></span><br><span class="line">     </span><br><span class="line">启动MySQL服务器和MySQL的自动启动</span><br><span class="line">[root@mysql-master ~]<span class="comment"># systemctl start mysqld.service</span></span><br><span class="line">[root@mysql-master ~]<span class="comment"># systemctl enable mysqld.service</span></span><br><span class="line">     </span><br><span class="line">设置登录密码</span><br><span class="line">由于MySQL从5.7开始不允许首次安装后使用空密码进行登录！为了加强安全性，系统会随机生成一个密码以供管理员首次登录使用，</span><br><span class="line">这个密码记录在/var/<span class="built_in">log</span>/mysqld.log文件中，使用下面的命令可以查看此密码：</span><br><span class="line">[root@mysql-master ~]<span class="comment"># cat /var/log/mysqld.log|grep 'A temporary password'</span></span><br><span class="line">2019-01-11T05:53:17.824073Z 1 [Note] A temporary password is generated <span class="keyword">for</span> root@localhost: TaN.k:*Qw2xs</span><br><span class="line">     </span><br><span class="line">使用上面查看的密码TaN.k:*Qw2xs 登录mysql，并重置密码为123456</span><br><span class="line">[root@mysql-master ~]<span class="comment"># mysql -p                 #输入默认的密码：TaN.k:*Qw2xs</span></span><br><span class="line">.............</span><br><span class="line">mysql&gt; <span class="built_in">set</span> global validate_password_policy=0;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line">     </span><br><span class="line">mysql&gt; <span class="built_in">set</span> global validate_password_length=1;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line">     </span><br><span class="line">mysql&gt; <span class="built_in">set</span> password=password(<span class="string">"123456"</span>);</span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.00 sec)</span><br><span class="line">     </span><br><span class="line">mysql&gt; flush privileges;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line">     </span><br><span class="line">查看mysql版本</span><br><span class="line">[root@mysql-master ~]<span class="comment"># mysql -p123456</span></span><br><span class="line">........</span><br><span class="line">mysql&gt; select version();</span><br><span class="line">+-----------+</span><br><span class="line">| version() |</span><br><span class="line">+-----------+</span><br><span class="line">| 5.7.24    |</span><br><span class="line">+-----------+</span><br><span class="line">1 row <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line">    </span><br><span class="line">=====================================================================</span><br><span class="line">温馨提示</span><br><span class="line">mysql5.7通过上面默认安装后，执行语句可能会报错：</span><br><span class="line">ERROR 1819 (HY000): Your password does not satisfy the current policy requirements</span><br><span class="line">    </span><br><span class="line">这个报错与Mysql 密码安全策略validate_password_policy的值有关，validate_password_policy可以取0、1、2三个值：</span><br><span class="line">解决办法：</span><br><span class="line"><span class="built_in">set</span> global validate_password_policy=0;</span><br><span class="line"><span class="built_in">set</span> global validate_password_length=1;</span><br></pre></td></tr></table></figure><h3 id="配置Mysql基于GTID的主从同步"><a href="#配置Mysql基于GTID的主从同步" class="headerlink" title="*配置Mysql基于GTID的主从同步  *"></a>*<em>配置Mysql基于GTID的主从同步  *</em></h3><p>在mysql-master 和 mysql-slave1、mysql-slave2节点上</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br></pre></td><td class="code"><pre><span class="line">1) 主数据库mysql-master (172.16.60.211)的配置操作</span><br><span class="line">[root@mysql-master ~]<span class="comment"># &gt;/etc/my.cnf</span></span><br><span class="line">[root@mysql-master ~]<span class="comment"># vim /etc/my.cnf</span></span><br><span class="line">[mysqld]</span><br><span class="line">datadir = /var/lib/mysql</span><br><span class="line">socket = /var/lib/mysql/mysql.sock</span><br><span class="line">        </span><br><span class="line">symbolic-links = 0</span><br><span class="line">        </span><br><span class="line"><span class="built_in">log</span>-error = /var/<span class="built_in">log</span>/mysqld.log</span><br><span class="line">pid-file = /var/run/mysqld/mysqld.pid</span><br><span class="line">    </span><br><span class="line"><span class="comment">#GTID:</span></span><br><span class="line">server_id = 1</span><br><span class="line">gtid_mode = on</span><br><span class="line">enforce_gtid_consistency = on</span><br><span class="line">      </span><br><span class="line"><span class="comment">#binlog</span></span><br><span class="line">log_bin = master-bin</span><br><span class="line"><span class="built_in">log</span>-slave-updates = 1</span><br><span class="line">binlog_format = row</span><br><span class="line">sync-master-info = 1    </span><br><span class="line">sync_binlog = 1        </span><br><span class="line">     </span><br><span class="line"><span class="comment">#relay log</span></span><br><span class="line">skip_slave_start = 1</span><br><span class="line"> </span><br><span class="line">配置完成之后，别忘了重启Mysql</span><br><span class="line">[root@mysql-master ~]<span class="comment"># systemctl restart mysqld</span></span><br><span class="line"> </span><br><span class="line">登录mysql，查看一下master状态， 发现多了一项<span class="string">"Executed_Gtid_Set "</span></span><br><span class="line">[root@mysql-master ~]<span class="comment"># mysql -p123456</span></span><br><span class="line">.........</span><br><span class="line">mysql&gt; show master status;</span><br><span class="line">+-------------------+----------+--------------+------------------+------------------------------------------+</span><br><span class="line">| File              | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set                        |</span><br><span class="line">+-------------------+----------+--------------+------------------+------------------------------------------+</span><br><span class="line">| master-bin.000002 |      550 |              |                  | fc39b161-22ca-11e9-a638-005056ac6820:1-2 |</span><br><span class="line">+-------------------+----------+--------------+------------------+------------------------------------------+</span><br><span class="line">1 row <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; show global variables like <span class="string">'%uuid%'</span>;</span><br><span class="line">+---------------+--------------------------------------+</span><br><span class="line">| Variable_name | Value                                |</span><br><span class="line">+---------------+--------------------------------------+</span><br><span class="line">| server_uuid   | fc39b161-22ca-11e9-a638-005056ac6820 |</span><br><span class="line">+---------------+--------------------------------------+</span><br><span class="line">1 row <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; show global variables like <span class="string">'%gtid%'</span>;</span><br><span class="line">+----------------------------------+------------------------------------------+</span><br><span class="line">| Variable_name                    | Value                                    |</span><br><span class="line">+----------------------------------+------------------------------------------+</span><br><span class="line">| binlog_gtid_simple_recovery      | ON                                       |</span><br><span class="line">| enforce_gtid_consistency         | ON                                       |</span><br><span class="line">| gtid_executed                    | fc39b161-22ca-11e9-a638-005056ac6820:1-2 |</span><br><span class="line">| gtid_executed_compression_period | 1000                                     |</span><br><span class="line">| gtid_mode                        | ON                                       |</span><br><span class="line">| gtid_owned                       |                                          |</span><br><span class="line">| gtid_purged                      |                                          |</span><br><span class="line">| session_track_gtids              | OFF                                      |</span><br><span class="line">+----------------------------------+------------------------------------------+</span><br><span class="line">8 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"> </span><br><span class="line">主库执行从库复制授权</span><br><span class="line">mysql&gt; grant replication slave,replication client on *.* to slave@<span class="string">'172.16.60.212'</span> identified by <span class="string">"slave@123"</span>;</span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.09 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; grant replication slave,replication client on *.* to slave@<span class="string">'172.16.60.213'</span> identified by <span class="string">"slave@123"</span>;</span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.03 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; flush privileges;</span><br><span class="line">Query OK, 0 rows affected (0.03 sec)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">mysql&gt; show grants <span class="keyword">for</span> slave@<span class="string">'172.16.60.212'</span>;</span><br><span class="line">+-------------------------------------------------------------------------------+</span><br><span class="line">| Grants <span class="keyword">for</span> slave@172.16.60.212                                                |</span><br><span class="line">+-------------------------------------------------------------------------------+</span><br><span class="line">| GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO <span class="string">'slave'</span>@<span class="string">'172.16.60.212'</span> |</span><br><span class="line">+-------------------------------------------------------------------------------+</span><br><span class="line">1 row <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; show grants <span class="keyword">for</span> slave@<span class="string">'172.16.60.213'</span>;</span><br><span class="line">+-------------------------------------------------------------------------------+</span><br><span class="line">| Grants <span class="keyword">for</span> slave@172.16.60.213                                                |</span><br><span class="line">+-------------------------------------------------------------------------------+</span><br><span class="line">| GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO <span class="string">'slave'</span>@<span class="string">'172.16.60.213'</span> |</span><br><span class="line">+-------------------------------------------------------------------------------+</span><br><span class="line">1 row <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"> </span><br><span class="line">在主数据库机器上创建一个测试库kevin（为了测试效果）</span><br><span class="line">mysql&gt; show databases;</span><br><span class="line">+--------------------+</span><br><span class="line">| Database           |</span><br><span class="line">+--------------------+</span><br><span class="line">| information_schema |</span><br><span class="line">| mysql              |</span><br><span class="line">| performance_schema |</span><br><span class="line">| sys                |</span><br><span class="line">+--------------------+</span><br><span class="line">4 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; CREATE DATABASE kevin CHARACTER SET utf8 COLLATE utf8_general_ci; </span><br><span class="line">Query OK, 1 row affected (0.02 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; use kevin;</span><br><span class="line">Database changed</span><br><span class="line">mysql&gt; create table <span class="keyword">if</span> not exists haha (id int(10) PRIMARY KEY AUTO_INCREMENT,name varchar(50) NOT NULL);</span><br><span class="line">Query OK, 0 rows affected (0.17 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; insert into kevin.haha values(1,<span class="string">"congcong"</span>),(2,<span class="string">"huihui"</span>),(3,<span class="string">"grace"</span>); </span><br><span class="line">Query OK, 3 rows affected (0.16 sec)</span><br><span class="line">Records: 3  Duplicates: 0  Warnings: 0</span><br><span class="line"> </span><br><span class="line">mysql&gt; select * from kevin.haha;</span><br><span class="line">+----+----------+</span><br><span class="line">| id | name     |</span><br><span class="line">+----+----------+</span><br><span class="line">|  1 | congcong |</span><br><span class="line">|  2 | huihui   |</span><br><span class="line">|  3 | grace    |</span><br><span class="line">+----+----------+</span><br><span class="line">3 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"> </span><br><span class="line">2) 从数据库mysql-slave1 (172.16.60.212)的配置操作</span><br><span class="line">与主服务器配置大概一致，除了server_id不一致外，从服务器还可以在配置文件里面添加：<span class="string">"read_only＝on"</span> ,</span><br><span class="line">使从服务器只能进行读取操作，此参数对超级用户无效，并且不会影响从服务器的复制；</span><br><span class="line">[root@mysql-slave1 ~]<span class="comment"># &gt;/etc/my.cnf</span></span><br><span class="line">[root@mysql-slave1 ~]<span class="comment"># vim /etc/my.cnf</span></span><br><span class="line">[mysqld]</span><br><span class="line">datadir = /var/lib/mysql</span><br><span class="line">socket = /var/lib/mysql/mysql.sock</span><br><span class="line">        </span><br><span class="line">symbolic-links = 0</span><br><span class="line">        </span><br><span class="line"><span class="built_in">log</span>-error = /var/<span class="built_in">log</span>/mysqld.log</span><br><span class="line">pid-file = /var/run/mysqld/mysqld.pid</span><br><span class="line">    </span><br><span class="line"><span class="comment">#GTID:</span></span><br><span class="line">server_id = 2</span><br><span class="line">gtid_mode = on</span><br><span class="line">enforce_gtid_consistency = on</span><br><span class="line">      </span><br><span class="line"><span class="comment">#binlog</span></span><br><span class="line">log_bin = master-bin</span><br><span class="line"><span class="built_in">log</span>-slave-updates = 1</span><br><span class="line">binlog_format = row</span><br><span class="line">sync-master-info = 1</span><br><span class="line">sync_binlog = 1</span><br><span class="line">      </span><br><span class="line"><span class="comment">#relay log</span></span><br><span class="line">skip_slave_start = 1</span><br><span class="line">read_only = on</span><br><span class="line"> </span><br><span class="line">配置完成之后，别忘了重启Mysql</span><br><span class="line">[root@mysql-slave1 ~]<span class="comment"># systemctl restart mysqld</span></span><br><span class="line"> </span><br><span class="line">接着登录mysql，做主从同步</span><br><span class="line">[root@mysql-slave1 ~]<span class="comment"># mysql -p123456</span></span><br><span class="line">........</span><br><span class="line">mysql&gt; show databases;</span><br><span class="line">+--------------------+</span><br><span class="line">| Database           |</span><br><span class="line">+--------------------+</span><br><span class="line">| information_schema |</span><br><span class="line">| mysql              |</span><br><span class="line">| performance_schema |</span><br><span class="line">| <span class="built_in">test</span>               |</span><br><span class="line">+--------------------+</span><br><span class="line">4 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line">   </span><br><span class="line">在从数据库里，使用change master 配置主从复制</span><br><span class="line">mysql&gt; stop slave;</span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.00 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; change master to master_host=<span class="string">'172.16.60.211'</span>,master_user=<span class="string">'slave'</span>,master_password=<span class="string">'slave@123'</span>,master_auto_position=1;</span><br><span class="line">Query OK, 0 rows affected, 2 warnings (0.24 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; start slave;</span><br><span class="line">Query OK, 0 rows affected (0.02 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; show slave status \G;</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">               Slave_IO_State: Waiting <span class="keyword">for</span> master to send event</span><br><span class="line">                  Master_Host: 172.16.60.211</span><br><span class="line">                  Master_User: slave</span><br><span class="line">                  Master_Port: 3306</span><br><span class="line">                Connect_Retry: 60</span><br><span class="line">              Master_Log_File: master-bin.000002</span><br><span class="line">          Read_Master_Log_Pos: 2069</span><br><span class="line">               Relay_Log_File: mysql-slave1-relay-bin.000002</span><br><span class="line">                Relay_Log_Pos: 2284</span><br><span class="line">        Relay_Master_Log_File: master-bin.000002</span><br><span class="line">             Slave_IO_Running: Yes</span><br><span class="line">            Slave_SQL_Running: Yes</span><br><span class="line">............</span><br><span class="line">............</span><br><span class="line">           Retrieved_Gtid_Set: fc39b161-22ca-11e9-a638-005056ac6820:1-8</span><br><span class="line">            Executed_Gtid_Set: 2afbc2f5-22cb-11e9-b9c0-00505688047c:1-2,</span><br><span class="line">fc39b161-22ca-11e9-a638-005056ac6820:1-8</span><br><span class="line">                Auto_Position: 1</span><br><span class="line">         Replicate_Rewrite_DB:</span><br><span class="line">                 Channel_Name:</span><br><span class="line">           Master_TLS_Version:</span><br><span class="line">1 row <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"> </span><br><span class="line">ERROR:</span><br><span class="line">No query specified</span><br><span class="line"> </span><br><span class="line">查看从库的gtid</span><br><span class="line">mysql&gt; show global variables like <span class="string">'%gtid%'</span>;</span><br><span class="line">+----------------------------------+------------------------------------------------------------------------------------+</span><br><span class="line">| Variable_name                    | Value                                                                              |</span><br><span class="line">+----------------------------------+------------------------------------------------------------------------------------+</span><br><span class="line">| binlog_gtid_simple_recovery      | ON                                                                                 |</span><br><span class="line">| enforce_gtid_consistency         | ON                                                                                 |</span><br><span class="line">| gtid_executed                    | 2afbc2f5-22cb-11e9-b9c0-00505688047c:1-2,</span><br><span class="line">fc39b161-22ca-11e9-a638-005056ac6820:1-8 |</span><br><span class="line">| gtid_executed_compression_period | 1000                                                                               |</span><br><span class="line">| gtid_mode                        | ON                                                                                 |</span><br><span class="line">| gtid_owned                       |                                                                                    |</span><br><span class="line">| gtid_purged                      | 2afbc2f5-22cb-11e9-b9c0-00505688047c:1-2                                           |</span><br><span class="line">| session_track_gtids              | OFF                                                                                |</span><br><span class="line">+----------------------------------+------------------------------------------------------------------------------------+</span><br><span class="line">8 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.01 sec)</span><br><span class="line"> </span><br><span class="line">接着查看从数据库的数据，发现kevin库已经同步过来了!</span><br><span class="line">mysql&gt; show databases;</span><br><span class="line">+--------------------+</span><br><span class="line">| Database           |</span><br><span class="line">+--------------------+</span><br><span class="line">| information_schema |</span><br><span class="line">| kevin              |</span><br><span class="line">| mysql              |</span><br><span class="line">| performance_schema |</span><br><span class="line">| sys                |</span><br><span class="line">+--------------------+</span><br><span class="line">5 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; select * from kevin.haha;</span><br><span class="line">+----+----------+</span><br><span class="line">| id | name     |</span><br><span class="line">+----+----------+</span><br><span class="line">|  1 | congcong |</span><br><span class="line">|  2 | huihui   |</span><br><span class="line">|  3 | grace    |</span><br><span class="line">+----+----------+</span><br><span class="line">3 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"> </span><br><span class="line">3) 从数据库mysql-slave2 (172.16.60.213)的配置操作</span><br><span class="line">[root@mysql-slave2 ~]<span class="comment"># &gt;/etc/my.cnf</span></span><br><span class="line">[root@mysql-slave2 ~]<span class="comment"># vim /etc/my.cnf</span></span><br><span class="line">[mysqld]</span><br><span class="line">datadir = /var/lib/mysql</span><br><span class="line">socket = /var/lib/mysql/mysql.sock</span><br><span class="line">        </span><br><span class="line">symbolic-links = 0</span><br><span class="line">        </span><br><span class="line"><span class="built_in">log</span>-error = /var/<span class="built_in">log</span>/mysqld.log</span><br><span class="line">pid-file = /var/run/mysqld/mysqld.pid</span><br><span class="line">    </span><br><span class="line"><span class="comment">#GTID:</span></span><br><span class="line">server_id = 3</span><br><span class="line">gtid_mode = on</span><br><span class="line">enforce_gtid_consistency = on</span><br><span class="line">      </span><br><span class="line"><span class="comment">#binlog</span></span><br><span class="line">log_bin = master-bin</span><br><span class="line"><span class="built_in">log</span>-slave-updates = 1</span><br><span class="line">binlog_format = row</span><br><span class="line">sync-master-info = 1</span><br><span class="line">sync_binlog = 1</span><br><span class="line">      </span><br><span class="line"><span class="comment">#relay log</span></span><br><span class="line">skip_slave_start = 1</span><br><span class="line">read_only = on</span><br><span class="line"> </span><br><span class="line">重启mysqld</span><br><span class="line">[root@mysql-slave2 ~]<span class="comment">#  systemctl restart mysqld </span></span><br><span class="line"> </span><br><span class="line">登录mysql，做主从复制</span><br><span class="line">[root@mysql-slave2 ~]<span class="comment"># mysql -p123456</span></span><br><span class="line">.........</span><br><span class="line">mysql&gt; stop slave;</span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.00 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; change master to master_host=<span class="string">'172.16.60.211'</span>,master_user=<span class="string">'slave'</span>,master_password=<span class="string">'slave@123'</span>,master_auto_position=1;</span><br><span class="line">Query OK, 0 rows affected, 2 warnings (0.17 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; start slave;</span><br><span class="line">Query OK, 0 rows affected (0.01 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; show slave status \G;</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">               Slave_IO_State: Waiting <span class="keyword">for</span> master to send event</span><br><span class="line">                  Master_Host: 172.16.60.211</span><br><span class="line">                  Master_User: slave</span><br><span class="line">                  Master_Port: 3306</span><br><span class="line">                Connect_Retry: 60</span><br><span class="line">              Master_Log_File: master-bin.000002</span><br><span class="line">          Read_Master_Log_Pos: 2069</span><br><span class="line">               Relay_Log_File: mysql-slave2-relay-bin.000002</span><br><span class="line">                Relay_Log_Pos: 2284</span><br><span class="line">        Relay_Master_Log_File: master-bin.000002</span><br><span class="line">             Slave_IO_Running: Yes</span><br><span class="line">            Slave_SQL_Running: Yes</span><br><span class="line">..........</span><br><span class="line">..........</span><br><span class="line">           Retrieved_Gtid_Set: fc39b161-22ca-11e9-a638-005056ac6820:1-8</span><br><span class="line">            Executed_Gtid_Set: 26e410b4-22cb-11e9-be44-005056880888:1-2,</span><br><span class="line">fc39b161-22ca-11e9-a638-005056ac6820:1-8</span><br><span class="line">                Auto_Position: 1</span><br><span class="line">         Replicate_Rewrite_DB:</span><br><span class="line">                 Channel_Name:</span><br><span class="line">           Master_TLS_Version:</span><br><span class="line">1 row <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"> </span><br><span class="line">ERROR:</span><br><span class="line">No query specified</span><br><span class="line"> </span><br><span class="line">查看从库的gtid</span><br><span class="line">mysql&gt; show global variables like <span class="string">'%gtid%'</span>;</span><br><span class="line">+----------------------------------+------------------------------------------------------------------------------------+</span><br><span class="line">| Variable_name                    | Value                                                                              |</span><br><span class="line">+----------------------------------+------------------------------------------------------------------------------------+</span><br><span class="line">| binlog_gtid_simple_recovery      | ON                                                                                 |</span><br><span class="line">| enforce_gtid_consistency         | ON                                                                                 |</span><br><span class="line">| gtid_executed                    | 26e410b4-22cb-11e9-be44-005056880888:1-2,</span><br><span class="line">fc39b161-22ca-11e9-a638-005056ac6820:1-8 |</span><br><span class="line">| gtid_executed_compression_period | 1000                                                                               |</span><br><span class="line">| gtid_mode                        | ON                                                                                 |</span><br><span class="line">| gtid_owned                       |                                                                                    |</span><br><span class="line">| gtid_purged                      | 26e410b4-22cb-11e9-be44-005056880888:1-2                                           |</span><br><span class="line">| session_track_gtids              | OFF                                                                                |</span><br><span class="line">+----------------------------------+------------------------------------------------------------------------------------+</span><br><span class="line">8 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.01 sec)</span><br><span class="line"> </span><br><span class="line">接着查看从数据库的数据，发现kevin库已经同步过来了!</span><br><span class="line">mysql&gt; show databases;</span><br><span class="line">+--------------------+</span><br><span class="line">| Database           |</span><br><span class="line">+--------------------+</span><br><span class="line">| information_schema |</span><br><span class="line">| kevin              |</span><br><span class="line">| mysql              |</span><br><span class="line">| performance_schema |</span><br><span class="line">| sys                |</span><br><span class="line">+--------------------+</span><br><span class="line">5 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; select * from kevin.haha;</span><br><span class="line">+----+----------+</span><br><span class="line">| id | name     |</span><br><span class="line">+----+----------+</span><br><span class="line">|  1 | congcong |</span><br><span class="line">|  2 | huihui   |</span><br><span class="line">|  3 | grace    |</span><br><span class="line">+----+----------+</span><br><span class="line">3 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"> </span><br><span class="line">4）再回到主数据库mysql-master (172.16.60.211)上</span><br><span class="line"> </span><br><span class="line">查看master状态，发现已经有两个slave节点正常存在同步关系了</span><br><span class="line">mysql&gt; show slave hosts;</span><br><span class="line">+-----------+------+------+-----------+--------------------------------------+</span><br><span class="line">| Server_id | Host | Port | Master_id | Slave_UUID                           |</span><br><span class="line">+-----------+------+------+-----------+--------------------------------------+</span><br><span class="line">|         3 |      | 3306 |         1 | 26e410b4-22cb-11e9-be44-005056880888 |</span><br><span class="line">|         2 |      | 3306 |         1 | 2afbc2f5-22cb-11e9-b9c0-00505688047c |</span><br><span class="line">+-----------+------+------+-----------+--------------------------------------+</span><br><span class="line">2 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"> </span><br><span class="line">5）测试数据同步</span><br><span class="line">在主数据库mysql-master (172.16.60.211)上更新数据</span><br><span class="line">mysql&gt; insert into kevin.haha values(10,<span class="string">"heifei"</span>),(11,<span class="string">"huoqiu"</span>),(12,<span class="string">"chengxihu"</span>);</span><br><span class="line">Query OK, 3 rows affected (0.05 sec)</span><br><span class="line">Records: 3  Duplicates: 0  Warnings: 0</span><br><span class="line"> </span><br><span class="line">然后在两个slave从数据库上查看，发现已正常同步过来了</span><br><span class="line">mysql&gt; select * from kevin.haha;</span><br><span class="line">+----+-----------+</span><br><span class="line">| id | name      |</span><br><span class="line">+----+-----------+</span><br><span class="line">|  1 | congcong  |</span><br><span class="line">|  2 | huihui    |</span><br><span class="line">|  3 | grace     |</span><br><span class="line">| 10 | heifei    |</span><br><span class="line">| 11 | huoqiu    |</span><br><span class="line">| 12 | chengxihu |</span><br><span class="line">+----+-----------+</span><br><span class="line">6 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br></pre></td></tr></table></figure><h3 id="安装配置ProxySQL"><a href="#安装配置ProxySQL" class="headerlink" title="安装配置ProxySQL"></a><strong>安装配置ProxySQL</strong></h3><p>已经在上面第一步中介绍了安装方法，这里采用rpm包方式安装，安装过程省略……..</p><h4 id="ProxySQL实现读写分离"><a href="#ProxySQL实现读写分离" class="headerlink" title="ProxySQL实现读写分离"></a><strong>ProxySQL实现读写分离</strong></h4><p><strong>向ProxySQL中添加MySQL节点</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">使用insert语句添加主机到mysql_servers表中，其中：hostgroup_id 为10表示写组，为20表示读组。</span><br><span class="line">  </span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uadmin -padmin -P6032 -h127.0.0.1</span></span><br><span class="line">............</span><br><span class="line">MySQL [(none)]&gt; insert into mysql_servers(hostgroup_id,hostname,port) values(10,<span class="string">'172.16.60.211'</span>,3306);</span><br><span class="line">Query OK, 1 row affected (0.000 sec)</span><br><span class="line">  </span><br><span class="line">MySQL [(none)]&gt; insert into mysql_servers(hostgroup_id,hostname,port) values(10,<span class="string">'172.16.60.212'</span>,3306);</span><br><span class="line">Query OK, 1 row affected (0.000 sec)</span><br><span class="line">  </span><br><span class="line">MySQL [(none)]&gt; insert into mysql_servers(hostgroup_id,hostname,port) values(10,<span class="string">'172.16.60.213'</span>,3306);</span><br><span class="line">Query OK, 1 row affected (0.000 sec)</span><br><span class="line"> </span><br><span class="line">==========================================================================================================</span><br><span class="line">如果在插入过程中，出现报错：</span><br><span class="line">ERROR 1045 (<span class="comment">#2800): UNIQUE constraint failed: mysql_servers.hostgroup_id, mysql_servers.hostname, mysql_servers.port</span></span><br><span class="line"> </span><br><span class="line">说明可能之前就已经定义了其他配置，可以清空这张表 或者 删除对应host的配置</span><br><span class="line">MySQL [(none)]&gt; select * from mysql_servers;</span><br><span class="line">MySQL [(none)]&gt; delete from mysql_servers;</span><br><span class="line">Query OK, 6 rows affected (0.000 sec)</span><br><span class="line">=========================================================================================================</span><br><span class="line">  </span><br><span class="line">查看这3个节点是否插入成功，以及它们的状态。</span><br><span class="line">MySQL [(none)]&gt; select * from mysql_servers\G;</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">       hostgroup_id: 10</span><br><span class="line">           hostname: 172.16.60.211</span><br><span class="line">               port: 3306</span><br><span class="line">             status: ONLINE</span><br><span class="line">             weight: 1</span><br><span class="line">        compression: 0</span><br><span class="line">    max_connections: 1000</span><br><span class="line">max_replication_lag: 0</span><br><span class="line">            use_ssl: 0</span><br><span class="line">     max_latency_ms: 0</span><br><span class="line">            comment:</span><br><span class="line">*************************** 2. row ***************************</span><br><span class="line">       hostgroup_id: 10</span><br><span class="line">           hostname: 172.16.60.212</span><br><span class="line">               port: 3306</span><br><span class="line">             status: ONLINE</span><br><span class="line">             weight: 1</span><br><span class="line">        compression: 0</span><br><span class="line">    max_connections: 1000</span><br><span class="line">max_replication_lag: 0</span><br><span class="line">            use_ssl: 0</span><br><span class="line">     max_latency_ms: 0</span><br><span class="line">            comment:</span><br><span class="line">*************************** 3. row ***************************</span><br><span class="line">       hostgroup_id: 10</span><br><span class="line">           hostname: 172.16.60.213</span><br><span class="line">               port: 3306</span><br><span class="line">             status: ONLINE</span><br><span class="line">             weight: 1</span><br><span class="line">        compression: 0</span><br><span class="line">    max_connections: 1000</span><br><span class="line">max_replication_lag: 0</span><br><span class="line">            use_ssl: 0</span><br><span class="line">     max_latency_ms: 0</span><br><span class="line">            comment:</span><br><span class="line">6 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.000 sec)</span><br><span class="line">  </span><br><span class="line">ERROR: No query specified</span><br><span class="line">  </span><br><span class="line">如上修改后，加载到RUNTIME，并保存到disk</span><br><span class="line">MySQL [(none)]&gt; load mysql servers to runtime;</span><br><span class="line">Query OK, 0 rows affected (0.006 sec)</span><br><span class="line">  </span><br><span class="line">MySQL [(none)]&gt; save mysql servers to disk;</span><br><span class="line">Query OK, 0 rows affected (0.348 sec)</span><br></pre></td></tr></table></figure><p><strong>监控后端MySQL节点</strong><br>添加Mysql节点之后，还需要监控这些后端节点。对于后端是主从复制的环境来说，这是必须的，因为ProxySQL需要通过每个节点的read_only值来自动调整<br>它们是属于读组还是写组。</p><p>首先在后端master主数据节点上创建一个用于监控的用户名(只需在master上创建即可，因为会复制到slave上)，这个用户名只需具有USAGE权限即可。如果还需<br>要监控复制结构中slave是否严重延迟于master(这个俗语叫做”拖后腿”，术语叫做”replication lag”)，则还需具备replication client权限。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line">在mysql-master主数据库节点行执行：</span><br><span class="line">[root@mysql-master ~]<span class="comment"># mysql -p123456</span></span><br><span class="line">..........</span><br><span class="line"> </span><br><span class="line">mysql&gt; create user monitor@<span class="string">'172.16.60.%'</span> identified by <span class="string">'P@ssword1!'</span>;</span><br><span class="line">Query OK, 0 rows affected (0.03 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; grant replication client on *.* to monitor@<span class="string">'172.16.60.%'</span>;</span><br><span class="line">Query OK, 0 rows affected (0.02 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; flush privileges;</span><br><span class="line">Query OK, 0 rows affected (0.02 sec)</span><br><span class="line"> </span><br><span class="line">然后回到mysql-proxy代理层节点上配置监控</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uadmin -padmin -P6032 -h127.0.0.1</span></span><br><span class="line">..........</span><br><span class="line">MySQL [(none)]&gt; <span class="built_in">set</span> mysql-monitor_username=<span class="string">'monitor'</span>;</span><br><span class="line">Query OK, 1 row affected (0.000 sec)</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; <span class="built_in">set</span> mysql-monitor_password=<span class="string">'P@ssword1!'</span>;</span><br><span class="line">Query OK, 1 row affected (0.000 sec)</span><br><span class="line"> </span><br><span class="line">修改后，加载到RUNTIME，并保存到disk</span><br><span class="line">MySQL [(none)]&gt; load mysql variables to runtime;</span><br><span class="line">Query OK, 0 rows affected (0.001 sec)</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; save mysql variables to disk;</span><br><span class="line">Query OK, 94 rows affected (0.079 sec)</span><br><span class="line"> </span><br><span class="line">验证监控结果：ProxySQL监控模块的指标都保存在monitor库的<span class="built_in">log</span>表中。</span><br><span class="line">  </span><br><span class="line">以下是连接是否正常的监控(对connect指标的监控)：</span><br><span class="line">注意：可能会有很多connect_error，这是因为没有配置监控信息时的错误，配置后如果connect_error的结果为NULL则表示正常。</span><br><span class="line">MySQL [(none)]&gt; select * from mysql_server_connect_log;</span><br><span class="line">+---------------+------+------------------+-------------------------+---------------+</span><br><span class="line">| hostname      | port | time_start_us    | connect_success_time_us | connect_error |</span><br><span class="line">+---------------+------+------------------+-------------------------+---------------+</span><br><span class="line">| 172.16.60.211 | 3306 | 1548665195883957 | 762                     | NULL          |</span><br><span class="line">| 172.16.60.212 | 3306 | 1548665195894099 | 399                     | NULL          |</span><br><span class="line">| 172.16.60.213 | 3306 | 1548665195904266 | 483                     | NULL          |</span><br><span class="line">| 172.16.60.211 | 3306 | 1548665255883715 | 824                     | NULL          |</span><br><span class="line">| 172.16.60.212 | 3306 | 1548665255893942 | 656                     | NULL          |</span><br><span class="line">| 172.16.60.211 | 3306 | 1548665495884125 | 615                     | NULL          |</span><br><span class="line">| 172.16.60.212 | 3306 | 1548665495894254 | 441                     | NULL          |</span><br><span class="line">| 172.16.60.213 | 3306 | 1548665495904479 | 638                     | NULL          |</span><br><span class="line">| 172.16.60.211 | 3306 | 1548665512917846 | 487                     | NULL          |</span><br><span class="line">| 172.16.60.212 | 3306 | 1548665512928071 | 994                     | NULL          |</span><br><span class="line">| 172.16.60.213 | 3306 | 1548665512938268 | 613                     | NULL          |</span><br><span class="line">+---------------+------+------------------+-------------------------+---------------+</span><br><span class="line">20 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.000 sec)</span><br><span class="line"> </span><br><span class="line">以下是对心跳信息的监控(对ping指标的监控)</span><br><span class="line">MySQL [(none)]&gt; select * from mysql_server_ping_log;</span><br><span class="line">+---------------+------+------------------+----------------------+------------+</span><br><span class="line">| hostname      | port | time_start_us    | ping_success_time_us | ping_error |</span><br><span class="line">+---------------+------+------------------+----------------------+------------+</span><br><span class="line">| 172.16.60.211 | 3306 | 1548665195883407 | 98                   | NULL       |</span><br><span class="line">| 172.16.60.212 | 3306 | 1548665195885128 | 119                  | NULL       |</span><br><span class="line">...........</span><br><span class="line">| 172.16.60.213 | 3306 | 1548665415889362 | 106                  | NULL       |</span><br><span class="line">| 172.16.60.213 | 3306 | 1548665562898295 | 97                   | NULL       |</span><br><span class="line">+---------------+------+------------------+----------------------+------------+</span><br><span class="line">110 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.001 sec)</span><br><span class="line"> </span><br><span class="line">read_only日志此时也为空(正常来说，新环境配置时，这个只读日志是为空的)</span><br><span class="line">MySQL [(none)]&gt; select * from mysql_server_read_only_log;</span><br><span class="line">Empty <span class="built_in">set</span> (0.000 sec)</span><br><span class="line"> </span><br><span class="line">replication_lag的监控日志为空</span><br><span class="line">MySQL [(none)]&gt; select * from mysql_server_replication_lag_log;</span><br><span class="line">Empty <span class="built_in">set</span> (0.000 sec)</span><br><span class="line"> </span><br><span class="line">指定写组的id为10，读组的id为20。</span><br><span class="line">MySQL [(none)]&gt; insert into mysql_replication_hostgroups values(10,20,1);</span><br><span class="line">Query OK, 1 row affected (0.000 sec)</span><br><span class="line"> </span><br><span class="line">在该配置加载到RUNTIME生效之前，先查看下各mysql server所在的组。</span><br><span class="line">MySQL [(none)]&gt; select hostgroup_id,hostname,port,status,weight from mysql_servers;</span><br><span class="line">+--------------+---------------+------+--------+--------+</span><br><span class="line">| hostgroup_id | hostname      | port | status | weight |</span><br><span class="line">+--------------+---------------+------+--------+--------+</span><br><span class="line">| 10           | 172.16.60.211 | 3306 | ONLINE | 1      |</span><br><span class="line">| 10           | 172.16.60.212 | 3306 | ONLINE | 1      |</span><br><span class="line">| 10           | 172.16.60.213 | 3306 | ONLINE | 1      |</span><br><span class="line">+--------------+---------------+------+--------+--------+</span><br><span class="line">3 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.000 sec)</span><br><span class="line"> </span><br><span class="line">3个节点都在hostgroup_id=10的组中。</span><br><span class="line">现在，将刚才mysql_replication_hostgroups表的修改加载到RUNTIME生效。</span><br><span class="line">MySQL [(none)]&gt; load mysql servers to runtime;</span><br><span class="line">Query OK, 0 rows affected (0.003 sec)</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; save mysql servers to disk;</span><br><span class="line">Query OK, 0 rows affected (0.361 sec)</span><br><span class="line"> </span><br><span class="line">一加载，Monitor模块就会开始监控后端的read_only值，当监控到read_only值后，就会按照read_only的值将某些节点自动移动到读/写组。</span><br><span class="line">例如，此处所有节点都在id=10的写组，slave1和slave2都是slave，它们的read_only=1，这两个节点将会移动到id=20的组。</span><br><span class="line">如果一开始这3节点都在id=20的读组，那么移动的将是Master节点，会移动到id=10的写组。</span><br><span class="line">  </span><br><span class="line">现在看结果</span><br><span class="line">MySQL [(none)]&gt; select hostgroup_id,hostname,port,status,weight from mysql_servers;</span><br><span class="line">+--------------+---------------+------+--------+--------+</span><br><span class="line">| hostgroup_id | hostname      | port | status | weight |</span><br><span class="line">+--------------+---------------+------+--------+--------+</span><br><span class="line">| 10           | 172.16.60.211 | 3306 | ONLINE | 1      |</span><br><span class="line">| 20           | 172.16.60.212 | 3306 | ONLINE | 1      |</span><br><span class="line">| 20           | 172.16.60.213 | 3306 | ONLINE | 1      |</span><br><span class="line">+--------------+---------------+------+--------+--------+</span><br><span class="line">3 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.000 sec)</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; select * from mysql_server_read_only_log;</span><br><span class="line">+---------------+------+------------------+-----------------+-----------+-------+</span><br><span class="line">| hostname      | port | time_start_us    | success_time_us | read_only | error |</span><br><span class="line">+---------------+------+------------------+-----------------+-----------+-------+</span><br><span class="line">| 172.16.60.212 | 3306 | 1548665728919212 | 1684            | 1         | NULL  |</span><br><span class="line">| 172.16.60.211 | 3306 | 1548665728918753 | 3538            | 0         | NULL  |</span><br><span class="line">| 172.16.60.213 | 3306 | 1548665728919782 | 3071            | 1         | NULL  |</span><br></pre></td></tr></table></figure><p><strong>配置mysql_users</strong><br>上面的所有配置都是关于后端MySQL节点的，现在可以配置关于SQL语句的，包括：发送SQL语句的用户、SQL语句的路由规则、SQL查询的缓存、SQL语句的重写等等。本小节是SQL请求所使用的用户配置，例如root用户。这要求我们需要先在后端MySQL节点添加好相关用户。这里以root和sqlsender两个用户名为例.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line">首先，在mysql-master主数据库节点上执行：(只需master执行即可，会复制给两个slave)</span><br><span class="line">[root@mysql-master ~]<span class="comment"># mysql -p123456</span></span><br><span class="line">.........</span><br><span class="line">mysql&gt; grant all on *.* to root@<span class="string">'172.16.60.%'</span> identified by <span class="string">'passwd'</span>;</span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.04 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; grant all on *.* to sqlsender@<span class="string">'172.16.60.%'</span> identified by <span class="string">'P@ssword1!'</span>;</span><br><span class="line">Query OK, 0 rows affected, 1 warning (0.03 sec)</span><br><span class="line"> </span><br><span class="line">mysql&gt; flush privileges;</span><br><span class="line">Query OK, 0 rows affected (0.03 sec)</span><br><span class="line"> </span><br><span class="line">然后回到mysql-proxy代理层节点，配置mysql_users表，将刚才的两个用户添加到该表中。</span><br><span class="line">admin&gt; insert into mysql_users(username,password,default_hostgroup) values(<span class="string">'root'</span>,<span class="string">'passwd'</span>,10);</span><br><span class="line">Query OK, 1 row affected (0.001 sec)</span><br><span class="line">  </span><br><span class="line">admin&gt; insert into mysql_users(username,password,default_hostgroup) values(<span class="string">'sqlsender'</span>,<span class="string">'P@ssword1!'</span>,10);</span><br><span class="line">Query OK, 1 row affected (0.000 sec)</span><br><span class="line">  </span><br><span class="line">admin&gt; load mysql users to runtime;</span><br><span class="line">Query OK, 0 rows affected (0.001 sec)</span><br><span class="line">  </span><br><span class="line">admin&gt; save mysql users to disk;</span><br><span class="line">Query OK, 0 rows affected (0.108 sec)</span><br><span class="line">  </span><br><span class="line">mysql_users表有不少字段，最主要的三个字段为username、password和default_hostgroup：</span><br><span class="line">-  username：前端连接ProxySQL，以及ProxySQL将SQL语句路由给MySQL所使用的用户名。</span><br><span class="line">-  password：用户名对应的密码。可以是明文密码，也可以是<span class="built_in">hash</span>密码。如果想使用<span class="built_in">hash</span>密码，可以先在某个MySQL节点上执行</span><br><span class="line">   select password(PASSWORD)，然后将加密结果复制到该字段。</span><br><span class="line">-  default_hostgroup：该用户名默认的路由目标。例如，指定root用户的该字段值为10时，则使用root用户发送的SQL语句默认</span><br><span class="line">   情况下将路由到hostgroup_id=10组中的某个节点。</span><br><span class="line"> </span><br><span class="line">admin&gt; select * from mysql_users\G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">              username: root</span><br><span class="line">              password: passwd</span><br><span class="line">                active: 1</span><br><span class="line">               use_ssl: 0</span><br><span class="line">     default_hostgroup: 10</span><br><span class="line">        default_schema: NULL</span><br><span class="line">         schema_locked: 0</span><br><span class="line">transaction_persistent: 1</span><br><span class="line">          fast_forward: 0</span><br><span class="line">               backend: 1</span><br><span class="line">              frontend: 1</span><br><span class="line">       max_connections: 10000</span><br><span class="line">*************************** 2. row ***************************</span><br><span class="line">              username: sqlsender</span><br><span class="line">              password: P@ssword1!</span><br><span class="line">                active: 1</span><br><span class="line">               use_ssl: 0</span><br><span class="line">     default_hostgroup: 10</span><br><span class="line">        default_schema: NULL</span><br><span class="line">         schema_locked: 0</span><br><span class="line">transaction_persistent: 1</span><br><span class="line">          fast_forward: 0</span><br><span class="line">               backend: 1</span><br><span class="line">              frontend: 1</span><br><span class="line">       max_connections: 10000</span><br><span class="line">2 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.000 sec)</span><br><span class="line">  </span><br><span class="line">虽然这里没有详细介绍mysql_users表，但上面标注了<span class="string">"注意本行"</span>的两个字段必须要引起注意。只有active=1的用户才是有效的用户。</span><br><span class="line">至于transaction_persistent字段，当它的值为1时，表示事务持久化：当某连接使用该用户开启了一个事务后，那么在事务提交/回滚之前，</span><br><span class="line">所有的语句都路由到同一个组中，避免语句分散到不同组。在以前的版本中，默认值为0，不知道从哪个版本开始，它的默认值为1。</span><br><span class="line">我们期望的值为1，所以在继续下面的步骤之前，先查看下这个值，如果为0，则执行下面的语句修改为1。</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; update mysql_users <span class="built_in">set</span> transaction_persistent=1 <span class="built_in">where</span> username=<span class="string">'root'</span>;</span><br><span class="line">Query OK, 1 row affected (0.000 sec)</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; update mysql_users <span class="built_in">set</span> transaction_persistent=1 <span class="built_in">where</span> username=<span class="string">'sqlsender'</span>;</span><br><span class="line">Query OK, 1 row affected (0.000 sec)</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; load mysql users to runtime;</span><br><span class="line">Query OK, 0 rows affected (0.001 sec)</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; save mysql users to disk;</span><br><span class="line">Query OK, 0 rows affected (0.123 sec)</span><br><span class="line"> </span><br><span class="line">然后，分别使用root用户和sqlsender用户测试下它们是否能路由到默认的hostgroup_id=10(它是一个写组)读、写数据。</span><br><span class="line">下面是通过转发端口6033连接的，连接的是转发到后端真正的数据库!</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e "select @@server_id"</span></span><br><span class="line">+-------------+</span><br><span class="line">| @@server_id |</span><br><span class="line">+-------------+</span><br><span class="line">|           1 |</span><br><span class="line">+-------------+</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e "create database proxy_test"</span></span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e "show databases;"</span></span><br><span class="line">+--------------------+</span><br><span class="line">| Database           |</span><br><span class="line">+--------------------+</span><br><span class="line">| information_schema |</span><br><span class="line">| kevin              |</span><br><span class="line">| mysql              |</span><br><span class="line">| performance_schema |</span><br><span class="line">| proxy_test         |</span><br><span class="line">| sys                |</span><br><span class="line">+--------------------+</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -usqlsender -pP@ssword1! -P6033 -h127.0.0.1 -e 'use proxy_test;create table t(id int);'</span></span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -usqlsender -pP@ssword1! -P6033 -h127.0.0.1 -e 'show tables from proxy_test;'</span></span><br><span class="line">+----------------------+</span><br><span class="line">| Tables_in_proxy_test |</span><br><span class="line">+----------------------+</span><br><span class="line">| t                    |</span><br><span class="line">+----------------------+</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -usqlsender -pP@ssword1! -P6033 -h127.0.0.1 -e 'show databases;'           </span></span><br><span class="line">+--------------------+</span><br><span class="line">| Database           |</span><br><span class="line">+--------------------+</span><br><span class="line">| information_schema |</span><br><span class="line">| kevin              |</span><br><span class="line">| mysql              |</span><br><span class="line">| performance_schema |</span><br><span class="line">| proxy_test         |</span><br><span class="line">| sys                |</span><br><span class="line">+--------------------+</span><br><span class="line"> </span><br><span class="line">然后再删除上面这个测试库</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -usqlsender -pP@ssword1! -P6033 -h127.0.0.1 -e 'drop database proxy_test;'</span></span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -usqlsender -pP@ssword1! -P6033 -h127.0.0.1 -e 'show databases;'         </span></span><br><span class="line">+--------------------+</span><br><span class="line">| Database           |</span><br><span class="line">+--------------------+</span><br><span class="line">| information_schema |</span><br><span class="line">| kevin              |</span><br><span class="line">| mysql              |</span><br><span class="line">| performance_schema |</span><br><span class="line">| sys                |</span><br><span class="line">+--------------------+</span><br></pre></td></tr></table></figure><p><strong>读写分离：配置路由规则</strong><br>ProxySQL的路由规则非常灵活，可以基于用户、基于schema以及基于每个语句实现路由规则的定制。本案例作为一个入门配置，实现一个最简单的语句级路由规则，从而实现读写分离。</p><p><strong>必须注意:</strong> 这只是实验，实际的路由规则绝不应该仅根据所谓的读、写操作进行分离，而是从各项指标中找出压力大、执行频繁的语句单独写规则、做缓存等等。和查询规则有关的表有两个:mysql_query_rules和mysql_query_rules_fast_routing，后者是前者的扩展表，1.4.7之后才支持该快速路由表。本案例只介绍第一个表。插入两个规则，目的是将select语句分离到hostgroup_id=20的读组，但由于select语句中有一个特殊语句SELECT…FOR UPDATE它会申请写锁，所以应该路由到hostgroup_id=10的写组.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uadmin -padmin -P6032 -h127.0.0.1                       </span></span><br><span class="line">............</span><br><span class="line">MySQL [(none)]&gt; insert into mysql_query_rules(rule_id,active,match_digest,destination_hostgroup,apply) VALUES (1,1,<span class="string">'^SELECT.*FOR UPDATE$'</span>,10,1), (2,1,<span class="string">'^SELECT'</span>,20,1);</span><br><span class="line">Query OK, 2 rows affected (0.000 sec)</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; load mysql query rules to runtime;</span><br><span class="line">Query OK, 0 rows affected (0.000 sec)</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; save mysql query rules to disk;</span><br><span class="line">Query OK, 0 rows affected (0.272 sec)</span><br><span class="line"> </span><br><span class="line">需要注意： select ... <span class="keyword">for</span> update规则的rule_id必须要小于普通的select规则的rule_id，因为ProxySQL是根据rule_id的顺序进行规则匹配的。</span><br><span class="line">    </span><br><span class="line">再来测试下，读操作是否路由给了hostgroup_id=20的读组, 如下发现server_id为2和3的节点 (即slave从节点)在读组内</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e 'select @@server_id'</span></span><br><span class="line">+-------------+</span><br><span class="line">| @@server_id |</span><br><span class="line">+-------------+</span><br><span class="line">|           3 |</span><br><span class="line">+-------------+</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e 'select @@server_id'</span></span><br><span class="line">+-------------+</span><br><span class="line">| @@server_id |</span><br><span class="line">+-------------+</span><br><span class="line">|           3 |</span><br><span class="line">+-------------+</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e 'select @@server_id'</span></span><br><span class="line">+-------------+</span><br><span class="line">| @@server_id |</span><br><span class="line">+-------------+</span><br><span class="line">|           2 |</span><br><span class="line">+-------------+</span><br><span class="line"> </span><br><span class="line">读操作已经路由给读组，再看看写操作。这里以事务持久化进行测试。</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e 'start transaction;select @@server_id;commit;select @@server_id;'</span></span><br><span class="line">+-------------+</span><br><span class="line">| @@server_id |</span><br><span class="line">+-------------+</span><br><span class="line">|           1 |</span><br><span class="line">+-------------+</span><br><span class="line">+-------------+</span><br><span class="line">| @@server_id |</span><br><span class="line">+-------------+</span><br><span class="line">|           3 |</span><br><span class="line">+-------------+</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e 'start transaction;select @@server_id;commit;select @@server_id;'</span></span><br><span class="line">+-------------+</span><br><span class="line">| @@server_id |</span><br><span class="line">+-------------+</span><br><span class="line">|           1 |</span><br><span class="line">+-------------+</span><br><span class="line">+-------------+</span><br><span class="line">| @@server_id |</span><br><span class="line">+-------------+</span><br><span class="line">|           2 |</span><br><span class="line"> </span><br><span class="line">显然，一切都按照预期进行。最后，如果想查看路由的信息，可查询stats库中的stats_mysql_query_digest表。</span><br><span class="line">以下是该表的一个输出格式示例(和本案例无关)。</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uadmin -padmin -P6032 -h127.0.0.1                       </span></span><br><span class="line">............</span><br><span class="line">MySQL [(none)]&gt; SELECT hostgroup hg, sum_time, count_star, digest_text FROM stats_mysql_query_digest ORDER BY sum_time DESC;</span><br><span class="line">+----+----------+------------+----------------------------------+</span><br><span class="line">| hg | sum_time | count_star | digest_text                      |</span><br><span class="line">+----+----------+------------+----------------------------------+</span><br><span class="line">| 10 | 283841   | 1          | drop database proxy_test         |</span><br><span class="line">| 10 | 161020   | 1          | create table t(id int)           |</span><br><span class="line">| 10 | 36002    | 1          | create database proxy_test       |</span><br><span class="line">| 20 | 2719     | 5          | select @@server_id               |</span><br><span class="line">| 10 | 1250     | 3          | select @@server_id               |</span><br><span class="line">| 10 | 1102     | 2          | show databases                   |</span><br><span class="line">| 10 | 789      | 2          | start transaction                |</span><br><span class="line">| 10 | 655      | 1          | SELECT DATABASE()                |</span><br><span class="line">| 10 | 629      | 1          | show databases                   |</span><br><span class="line">| 10 | 564      | 1          | show tables from proxy_test      |</span><br><span class="line">| 10 | 286      | 2          | commit                           |</span><br><span class="line">| 10 | 0        | 8          | select @@version_comment <span class="built_in">limit</span> ? |</span><br><span class="line">| 10 | 0        | 5          | select @@version_comment <span class="built_in">limit</span> ? |</span><br><span class="line">+----+----------+------------+----------------------------------+</span><br><span class="line">13 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.002 sec)</span><br></pre></td></tr></table></figure><p><strong>测试读写分离效果</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line">由于读写操作都记录在proxysql的stats_mysql_query_digest表内。</span><br><span class="line">为了测试读写分离的效果，可以先清空此表中之前的记录 (即之前在实现读写分配路由配置之前的记录)</span><br><span class="line"> </span><br><span class="line">下面这个命令是专门清空stats_mysql_query_digest表的  (使用<span class="string">"delete from stats_mysql_query_digest"</span>  清空不掉!)</span><br><span class="line">MySQL [(none)]&gt; SELECT 1 FROM stats_mysql_query_digest_reset LIMIT 1;</span><br><span class="line">+---+</span><br><span class="line">| 1 |</span><br><span class="line">+---+</span><br><span class="line">| 1 |</span><br><span class="line">+---+</span><br><span class="line">1 row <span class="keyword">in</span> <span class="built_in">set</span> (0.002 sec)</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; select hostgroup,username,digest_text,count_star from stats_mysql_query_digest;             </span><br><span class="line">Empty <span class="built_in">set</span> (0.001 sec)</span><br><span class="line"> </span><br><span class="line">在mysql-proxy代理层节点，通过proxysql进行数据写入，并查看</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e 'select * from kevin.haha;'</span></span><br><span class="line">+----+-----------+</span><br><span class="line">| id | name      |</span><br><span class="line">+----+-----------+</span><br><span class="line">|  1 | congcong  |</span><br><span class="line">|  2 | huihui    |</span><br><span class="line">|  3 | grace     |</span><br><span class="line">| 11 | huoqiu    |</span><br><span class="line">| 12 | chengxihu |</span><br><span class="line">| 21 | zhongguo  |</span><br><span class="line">+----+-----------+</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e 'delete from kevin.haha where id &gt; 3;'</span></span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e 'insert into kevin.haha values(21,"zhongguo"),(22,"xianggang"),(23,"taiwan");'</span></span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e 'update kevin.haha set name="hangzhou" where id=22 ;'                </span></span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e 'select * from kevin.haha;'                                          </span></span><br><span class="line">+----+----------+</span><br><span class="line">| id | name     |</span><br><span class="line">+----+----------+</span><br><span class="line">|  1 | congcong |</span><br><span class="line">|  2 | huihui   |</span><br><span class="line">|  3 | grace    |</span><br><span class="line">| 21 | zhongguo |</span><br><span class="line">| 22 | hangzhou |</span><br><span class="line">| 23 | taiwan   |</span><br><span class="line">+----+----------+</span><br><span class="line"> </span><br><span class="line">在mysql-master主数据库和mysql-slave1、mysql-slave2从数据上查看</span><br><span class="line">[root@mysql-master ~]<span class="comment"># mysql -p123456</span></span><br><span class="line">.........</span><br><span class="line">mysql&gt; select * from kevin.haha;</span><br><span class="line">+----+----------+</span><br><span class="line">| id | name     |</span><br><span class="line">+----+----------+</span><br><span class="line">|  1 | congcong |</span><br><span class="line">|  2 | huihui   |</span><br><span class="line">|  3 | grace    |</span><br><span class="line">| 21 | zhongguo |</span><br><span class="line">| 22 | hangzhou |</span><br><span class="line">| 23 | taiwan   |</span><br><span class="line">+----+----------+</span><br><span class="line">6 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.00 sec)</span><br><span class="line"> </span><br><span class="line">发现在客户端通过proxysql插件更新的数据，已经写到mysql-master主数据库上，并同步到mysql-slave1和mysql-slave2两个从数据库上了！</span><br><span class="line"> </span><br><span class="line">最后在proxysql管理端查看读写分离</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uadmin -padmin -h127.0.0.1 -P6032           </span></span><br><span class="line">............</span><br><span class="line">............</span><br><span class="line">MySQL [(none)]&gt; select hostgroup,username,digest_text,count_star from stats_mysql_query_digest;</span><br><span class="line">+-----------+----------+------------------------------------------------+------------+</span><br><span class="line">| hostgroup | username | digest_text                                    | count_star |</span><br><span class="line">+-----------+----------+------------------------------------------------+------------+</span><br><span class="line">| 10        | root     | insert into kevin.haha values(?,?),(?,?),(?,?) | 1          |</span><br><span class="line">| 10        | root     | delete from kevin.haha <span class="built_in">where</span> id &gt; ?            | 1          |</span><br><span class="line">| 10        | root     | update kevin.haha <span class="built_in">set</span> name=? <span class="built_in">where</span> id=?        | 1          |</span><br><span class="line">| 20        | root     | select * from kevin.haha                       | 2          |</span><br><span class="line">| 10        | root     | select @@version_comment <span class="built_in">limit</span> ?               | 5          |</span><br><span class="line">+-----------+----------+------------------------------------------------+------------+</span><br><span class="line">5 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.001 sec)</span><br><span class="line"> </span><br><span class="line">从上述结果就可以看出proxysql实现的读写分离配置是成功的，读请求是转发到group20的读组内，写请求转发到group10的写组内!!</span><br></pre></td></tr></table></figure><h4 id="负载均衡测试-加权轮询"><a href="#负载均衡测试-加权轮询" class="headerlink" title="负载均衡测试  (加权轮询)"></a><strong>负载均衡测试  (加权轮询)</strong></h4><p>如上已经配置好一主(mysql-master，在hostgroup10写组内)、两从(mysql-slave1和mysql-slave2，在hostgroup20读组内) ，并且已经在”mysql_query_rules”表中配置了路由规则，即写操作转发到hostgroup10组，读操作转发到hostgroup20组.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br></pre></td><td class="code"><pre><span class="line">MySQL [(none)]&gt; select * from mysql_query_rules;           </span><br><span class="line">+---------+--------+----------+------------+--------+-------------+------------+------------+--------+----------------------+---------------+----------------------+--------------+---------+-----------------+-----------------------+-----------+-----------+---------+---------+-------+-------------------+----------------+------------------+-----------+--------+-------------+-----------+-----+-------+---------+</span><br><span class="line">| rule_id | active | username | schemaname | flagIN | client_addr | proxy_addr | proxy_port | digest | match_digest         | match_pattern | negate_match_pattern | re_modifiers | flagOUT | replace_pattern | destination_hostgroup | cache_ttl | reconnect | timeout | retries | delay | next_query_flagIN | mirror_flagOUT | mirror_hostgroup | error_msg | OK_msg | sticky_conn | multiplex | <span class="built_in">log</span> | apply | comment |</span><br><span class="line">+---------+--------+----------+------------+--------+-------------+------------+------------+--------+----------------------+---------------+----------------------+--------------+---------+-----------------+-----------------------+-----------+-----------+---------+---------+-------+-------------------+----------------+------------------+-----------+--------+-------------+-----------+-----+-------+---------+</span><br><span class="line">| 1       | 1      | NULL     | NULL       | 0      | NULL        | NULL       | NULL       | NULL   | ^SELECT.*FOR UPDATE$ | NULL          | 0                    | CASELESS     | NULL    | NULL            | 10                    | NULL      | NULL      | NULL    | NULL    | NULL  | NULL              | NULL           | NULL             | NULL      | NULL   | NULL        | NULL      | NULL | 1     | NULL    |</span><br><span class="line">| 2       | 1      | NULL     | NULL       | 0      | NULL        | NULL       | NULL       | NULL   | ^SELECT              | NULL          | 0                    | CASELESS     | NULL    | NULL            | 20                    | NULL      | NULL      | NULL    | NULL    | NULL  | NULL              | NULL           | NULL             | NULL      | NULL   | NULL        | NULL      | NULL | 1     | NULL    |</span><br><span class="line">+---------+--------+----------+------------+--------+-------------+------------+------------+--------+----------------------+---------------+----------------------+--------------+---------+-----------------+-----------------------+-----------+-----------+---------+---------+-------+-------------------+----------------+------------------+-----------+--------+-------------+-----------+-----+-------+---------+</span><br><span class="line">2 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.000 sec)</span><br><span class="line">  </span><br><span class="line">由于hostgroup10写组内只要一个节点(mysql-master节点)，hostgroup20读组内有两个节点(mysql-slave1、mysql-slave2)</span><br><span class="line">所以这里只能测试读节点的负载均衡</span><br><span class="line">  </span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e "select @@hostname"</span></span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave1 |</span><br><span class="line">+--------------+</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e "select @@hostname"</span></span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave1 |</span><br><span class="line">+--------------+</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e "select @@hostname"</span></span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave1 |</span><br><span class="line">+--------------+</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e "select @@hostname"</span></span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave2 |</span><br><span class="line">+--------------+</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e "select @@hostname"</span></span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave2 |</span><br><span class="line">+--------------+</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e "select @@hostname"</span></span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave2 |</span><br><span class="line">+--------------+</span><br><span class="line">  </span><br><span class="line">再实验下mysql -e跟多条语句，看看如何</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e "select @@hostname;select @@hostname;select @@hostname"</span></span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave1 |</span><br><span class="line">+--------------+</span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave1 |</span><br><span class="line">+--------------+</span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave1 |</span><br><span class="line">+--------------+</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e "select @@hostname;select @@hostname;select @@hostname"</span></span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave2 |</span><br><span class="line">+--------------+</span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave2 |</span><br><span class="line">+--------------+</span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave2 |</span><br><span class="line">+--------------+</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e "select @@hostname;select @@hostname;select @@hostname"</span></span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave1 |</span><br><span class="line">+--------------+</span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave1 |</span><br><span class="line">+--------------+</span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave1 |</span><br><span class="line">+--------------+</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e "select @@hostname;select @@hostname;select @@hostname"</span></span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave1 |</span><br><span class="line">+--------------+</span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave1 |</span><br><span class="line">+--------------+</span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave1 |</span><br><span class="line">+--------------+</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e "select @@hostname;select @@hostname;select @@hostname"</span></span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave2 |</span><br><span class="line">+--------------+</span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave2 |</span><br><span class="line">+--------------+</span><br><span class="line">+--------------+</span><br><span class="line">| @@hostname   |</span><br><span class="line">+--------------+</span><br><span class="line">| mysql-slave2 |</span><br><span class="line">+--------------+</span><br><span class="line">  </span><br><span class="line">由以上结果可能会猜想并可印证：</span><br><span class="line">在一个client的一个链接周期内，所有query路由到同一台后端!</span><br><span class="line">即在同一个client的链接周期内，query路由不会转发到同组内的不同后端节点机上，只能转发到同一台后端节点机上!</span><br><span class="line">  </span><br><span class="line">但是这只是个假象!!!   是因为正好用到了select @ 语句。</span><br><span class="line">如官网所介绍:  sends a query that implicitly disables multiplexing. For example, <span class="keyword">if</span> you run “SELECT @a” , ProxySQL will <span class="built_in">disable</span></span><br><span class="line">multiplexing <span class="keyword">for</span> that client and will always use the same backend connection</span><br><span class="line">  </span><br><span class="line">最后可以知道: proxysql的负载方式目前仅为加权轮询一种（经验证所确认），并无其他机制!</span><br><span class="line"> </span><br><span class="line">===============================================================================</span><br><span class="line">可以编写一个负载均衡的shell测试脚本:</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># which mysql</span></span><br><span class="line">/usr/bin/mysql</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># vim /opt/test_proxysql_lb.sh</span></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"> </span><br><span class="line">i=0</span><br><span class="line"><span class="keyword">while</span>((<span class="variable">$i</span>&lt;200))</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">        /usr/bin/mysql -uroot -ppasswd -P6033 -h127.0.0.1 -e <span class="string">"select @@hostname;"</span> &gt;&gt; /tmp/test_proxy_sql_lb.txt</span><br><span class="line">        <span class="built_in">let</span> <span class="string">"i++"</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"<span class="variable">$i</span>"</span></span><br><span class="line">        sleep 0.1</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"> </span><br><span class="line">执行测试脚本:</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># sh -x /opt/test_proxysql_lb.sh &gt; /dev/null 2&gt;&amp;1</span></span><br><span class="line"> </span><br><span class="line">执行后检查结果</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># grep "mysql-slave1" /tmp/test_proxy_sql_lb.txt|wc -l</span></span><br><span class="line">86</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># grep "mysql-slave2" /tmp/test_proxy_sql_lb.txt|wc -l</span></span><br><span class="line">114</span><br><span class="line"> </span><br><span class="line">以上查询结果符合预期</span><br></pre></td></tr></table></figure><h4 id="开启ProxySQL的Web统计功能"><a href="#开启ProxySQL的Web统计功能" class="headerlink" title="开启ProxySQL的Web统计功能"></a><strong>开启ProxySQL的Web统计功能</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">首先打开web功能</span><br><span class="line">[root@mysql-proxy ~]<span class="comment">#  mysql -uadmin -padmin -h127.0.0.1 -P6032 </span></span><br><span class="line">............</span><br><span class="line">............</span><br><span class="line">MySQL [(none)]&gt; update global_variables <span class="built_in">set</span> variable_value=<span class="string">'true'</span> <span class="built_in">where</span> variable_name=<span class="string">'admin-web_enabled'</span>;</span><br><span class="line">Query OK, 1 row affected (0.001 sec)</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; LOAD ADMIN VARIABLES TO RUNTIME;</span><br><span class="line">Query OK, 0 rows affected (0.001 sec)</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; SAVE ADMIN VARIABLES TO DISK;</span><br><span class="line">Query OK, 31 rows affected (0.070 sec)</span><br><span class="line"> </span><br><span class="line">然后查看端口和登录web界面的用户名和密码，用户名和密码与<span class="built_in">stat</span>账户一致：</span><br><span class="line">MySQL [(none)]&gt; select * from global_variables <span class="built_in">where</span> variable_name LIKE <span class="string">'admin-web%'</span> or variable_name LIKE <span class="string">'admin-stats%'</span>;</span><br><span class="line">+-----------------------------------+----------------+</span><br><span class="line">| variable_name                     | variable_value |</span><br><span class="line">+-----------------------------------+----------------+</span><br><span class="line">| admin-stats_credentials           | stats:stats    |                <span class="comment">#账户密码</span></span><br><span class="line">| admin-stats_mysql_connections     | 60             |</span><br><span class="line">| admin-stats_mysql_connection_pool | 60             |</span><br><span class="line">| admin-stats_mysql_query_cache     | 60             |</span><br><span class="line">| admin-stats_system_cpu            | 60             |</span><br><span class="line">| admin-stats_system_memory         | 60             |</span><br><span class="line">| admin-web_enabled                 | <span class="literal">true</span>           |</span><br><span class="line">| admin-web_port                    | 6080           |                     <span class="comment">#端口</span></span><br><span class="line">+-----------------------------------+----------------+</span><br><span class="line">8 rows <span class="keyword">in</span> <span class="built_in">set</span> (0.003 sec)</span><br></pre></td></tr></table></figure><p>查看web端口是否正常打开</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@mysql-proxy ~]<span class="comment"># lsof -i:6080</span></span><br><span class="line">COMMAND    PID USER   FD   TYPE   DEVICE SIZE/OFF NODE NAME</span><br><span class="line">proxysql 22324 root   27u  IPv4 23010645      0t0  TCP *:6080 (LISTEN)</span><br></pre></td></tr></table></figure><p>访问<a href="http://172.16.60.214:6080并使用stats:stats登录即可查看一些统计信息。" rel="noopener" target="_blank">http://172.16.60.214:6080并使用stats:stats登录即可查看一些统计信息。</a></p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8307f670/2.png" alt></p><h4 id="scheduler打印proxysql状态到日志"><a href="#scheduler打印proxysql状态到日志" class="headerlink" title="scheduler打印proxysql状态到日志"></a><strong>scheduler打印proxysql状态到日志</strong></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@mysql-proxy ~]<span class="comment"># mkdir -p /opt/proxysql/log</span></span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># vim /opt/proxysql/log/status.sh</span></span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">DATE=`date <span class="string">"+%Y-%m-%d %H:%M:%S"</span>`</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"&#123;\"dateTime\":\"<span class="variable">$DATE</span>\",\"status\":\"running\"&#125;"</span> &gt;&gt; /opt/proxysql/<span class="built_in">log</span>/status_log</span><br><span class="line"> </span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># chmod 777 /opt/proxysql/log/status.sh</span></span><br><span class="line"> </span><br><span class="line">然后在proxysql插入一条scheduler (定义每分钟打印一次，即60000毫秒)</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># mysql -uadmin -padmin -h127.0.0.1 -P6032</span></span><br><span class="line">............</span><br><span class="line">............</span><br><span class="line">MySQL [(none)]&gt; insert into scheduler(active,interval_ms,filename) values (1,60000,<span class="string">'/opt/proxysql/log/status.sh'</span>);</span><br><span class="line">Query OK, 1 row affected (0.000 sec)</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; LOAD SCHEDULER TO RUNTIME;</span><br><span class="line">Query OK, 0 rows affected (0.001 sec)</span><br><span class="line"> </span><br><span class="line">MySQL [(none)]&gt; SAVE SCHEDULER TO DISK;</span><br><span class="line">Query OK, 0 rows affected (0.105 sec)</span><br><span class="line"> </span><br><span class="line">然后查看日志就可以看到proxysql 的运行结果了：</span><br><span class="line">[root@mysql-proxy ~]<span class="comment"># tail -f /opt/proxysql/log/status_log</span></span><br><span class="line">&#123;<span class="string">"dateTime"</span>:<span class="string">"2019-02-19 14:24:03"</span>,<span class="string">"status"</span>:<span class="string">"running"</span>&#125;</span><br><span class="line">&#123;<span class="string">"dateTime"</span>:<span class="string">"2019-02-19 14:25:03"</span>,<span class="string">"status"</span>:<span class="string">"running"</span>&#125;</span><br><span class="line">&#123;<span class="string">"dateTime"</span>:<span class="string">"2019-02-19 14:26:03"</span>,<span class="string">"status"</span>:<span class="string">"running"</span>&#125;</span><br><span class="line">&#123;<span class="string">"dateTime"</span>:<span class="string">"2019-02-19 14:27:03"</span>,<span class="string">"status"</span>:<span class="string">"running"</span>&#125;</span><br></pre></td></tr></table></figure></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前面文章对数据库中间层进行了选型，那么要怎么安装，怎么验证，怎么优化，又有哪些坑可以避免呢？本文就详细介绍下。&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="SQL" scheme="https://wandouduoduo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/SQL/"/>
    
      <category term="Mysql" scheme="https://wandouduoduo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/SQL/Mysql/"/>
    
    
      <category term="Mysql" scheme="https://wandouduoduo.github.io/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>生产mysql数据库集群优化&lt;一&gt;--选型proxysql</title>
    <link href="https://wandouduoduo.github.io/articles/2f5e57e1.html"/>
    <id>https://wandouduoduo.github.io/articles/2f5e57e1.html</id>
    <published>2021-06-10T10:26:36.000Z</published>
    <updated>2021-06-23T06:51:09.958Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>现在微服务几乎成为所有公司的标配，那么业务项目和数据存储的松耦合就成为基本配置，而mysql数据库在互联网公司中应用很广，几乎所有的项目都会有连它的需求。但是如果业务请求量很大，那么最先想到也是最常用的是数据库的读写分离。通常是由dba把数据库分为读写库，对数据进行更新，写入时连接读写库。查询数据时，连接读库。这样可以大大减轻写库的压力。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/2f5e57e1/1.png" alt></p><p>但是这样是由业务根据需求来区分连哪个数据库，但有些开发说我想只配置一个数据库，运维你根据请求类型来区分定义是连接只读库还是读写库。而且业务对时效性也不是很严格。那要怎么做呢？如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/2f5e57e1/2.png" alt></p><p>我们就需要增加数据库的代理层，由代理层根据定义的规则来自动区分是连接读写库还是只读库。本文就是聊聊数据库的代理层–ProxySQL。</p><a id="more"></a><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>ProxySQL是灵活强大的MySQL代理层, 是一个能实实在在用在生产环境的MySQL中间件，可以实现读写分离，支持 Query 路由功能，支持动态指定某个 SQL 进行 cache，支持动态加载配置、故障切换和一些 SQL的过滤功能。还有一些同类产品比如 DBproxy、MyCAT、OneProxy 等。但经过反复对比和测试之后，还是觉得ProxySQL是一款性能不谙，靠谱稳定的MySQL 中间件产品 ！</p><h2 id="亮点"><a href="#亮点" class="headerlink" title="亮点"></a><strong>亮点</strong></h2><ul><li>几乎所有的配置均可在线更改（其配置数据基于SQLite存储），无需重启proxysql</li><li>基于正则和client_addr的强大和灵活的路由规则</li><li>详细的状态统计，统计结果和pt-query-digest对慢日志的分析结果类似，相当于有了统一的查看sql性能和sql语句统计的入口（Designed by a DBA for DBAs）</li><li>自动重连和重新执行机制(auto-reconnect and automatic re-execution of queries using it’s Connections Pool ): 若一个请求在链接或执行过程中意外中断，proxysql会根据其内部机制重新执行该操作</li><li>query cache功能：比mysql自带QC更灵活，可在mysql_query_rules表中依据digest,match_pattern,client_addr等维度控制哪类语句可以缓存</li><li>支持连接池（connection pool）并且支持multiplexing,区别于atlas之流的连接池实现。</li></ul><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a><strong>特点</strong></h2><p>ProxySQL是一个高性能的MySQL中间件，拥有强大的规则引擎。它是用C++语言开发的，虽然是一个轻量级产品，但性能很好（据测试，能处理千亿级的数据），功能也足够，能满足中间件所需的绝大多数功能。具有以下特性：</p><ul><li>连接池，而且是 multiplexing；</li><li>主机和用户的最大连接数限制；</li><li>自动下线后端DB；<br>-  延迟超过阀值<br>-  ping 延迟超过阀值<br>-  网络不通或宕机</li><li>强大的规则路由引擎；<br>-  实现读写分离<br>-  查询重写<br>-  sql流量镜像</li><li>支持prepared statement；</li><li>支持Query Cache；</li><li>支持负载均衡，与gelera结合自动failover；</li><li>将所有配置保存写入到SQLit表中。</li><li>支持动态加载配置，即一般可以在线修改配置，但有少部分参数还是需要重启来生效。</li><li>支持query cache。</li><li>支持对query的路由，可以针对某个语句进行分配去哪个实例执行。</li><li>不支持分表，可以分库，但是利用规则配置实现分表。</li></ul><p>如上可知，ProxySQL集合了很多优秀特性于一身，那么它的缺点呢就是项目不够成熟，好在官方网站一直在及时更新，并且受到 Percona 官方的支持。</p><h2 id="管理配置"><a href="#管理配置" class="headerlink" title="管理配置"></a><strong>管理配置</strong></h2><p>ProxySQL有一个完备的配置系统，配置ProxySQL是基于sql命令的方式完成的。ProxySQL支持配置修改之后的在线保存、应用，不需要重启即可生效。整个配置系统分三层设计。</p><p>-  <strong>runtime</strong>：运行中使用的配置文件<br>-  <strong>memory</strong>：提供用户动态修改配置文件<br>-  <strong>disk</strong>：将修改的配置保存到磁盘SQLit表中（即：proxysql.db）<br>-  <strong>config</strong>：一般不使用它（即：proxysql.cnf）</p><p>如下图所示:</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/2f5e57e1/3.png" alt="img"></p><p><strong>ProxySQL配置系统分为三层的目的：</strong></p><p>1) 自动更新;<br>2) 尽可能的不重启proxysql就可以修改配置;<br>3) 方便回滚错误配置;</p><p>简单说就是配置proxysql分为三个级别，RUNTIME是即时生效的，MEMORY是保存在内存中但并不立即生效的，DISK|CONFIG FILE是持久化或写在配置文件中的。</p><p>这三个级别的配置文件互不干扰，在某个层级修改了配置文件，想要加载或保存到另一个层级，需要额外的LOAD或SAVE操作：”LOAD xx_config FROM xx_level | LOAD xx_config TO xx_level | SAVE xx_config TO xx_level | SAVE xx_config FROM xx_level”，达到加载配置或者持久化配置的目的。这三层中每层的功能与含义如下：<br>-  <strong>RUNTIME层</strong><br>代表的是ProxySQL当前生效的配置，包括 global_variables, mysql_servers, mysql_users, mysql_query_rules。无法直接修改这里的配置，必须要从下一层load进来。该层级的配置时在proxysql管理库(sqlite)的main库中以runtime_开头的表，这些表的数据库无法直接修改，只能从其他层级加载；该层代表的是ProxySQL当前生效的正在使用的配置，包括global_variables, mysql_servers, mysql_users, mysql_query_rules表。无法直接修改这里的配置，必须要从下一层load进来。也就是说RUNTIME这个顶级层，是proxysql运行过程中实际使用的那一份配置，这一份配置会直接影响到生产环境的，所以要将配置加载进RUNTIME层时需要三思而行。</p><p>-  <strong>MEMORY层</strong><br>是平时在mysql命令行修改的 main 里头配置，可以认为是SQLite数据库在内存的镜像。该层级的配置在main库中以mysql_开头的表以及global_variables表，这些表的数据可以直接修改；用户可以通过MySQL客户端连接到此接口（admin接口），然后可以在mysql命令行查询不同的表和数据库，并修改各种配置，可以认为是SQLite数据库在内存的镜像。也就是说MEMORY这个中间层，上面接着生产环境层RUNTIME，下面接着持久化层DISK和CONFIG FILE。MEMORY层是我们修改proxysql的唯一正常入口。一般来说在修改一个配置时，首先修改Memory层，确认无误后再接入RUNTIME层，最后持久化到DISK和CONFIG FILE层。也就是说memeory层里面的配置随便改，不影响生产，也不影响磁盘中保存的数据。通过admin接口可以修改mysql_servers、mysql_users、mysql_query_rules、global_variables等表的数据。</p><p>-  <strong>DISK|CONFIG FILR层</strong><br>持久存储的那份配置，一般在$(DATADIR)/proxysql.db，在重启的时候会从硬盘里加载。 /etc/proxysql.cnf文件只在第一次初始化的时候用到，完了后，如果要修改监听端口，还是需要在管理命令行里修改，再 save 到硬盘。该层级的配置在磁盘上的sqlite库或配置文件里。DISK/CONFIG FILE层表示持久存储的那份配置，持久层对应的磁盘文件是$(DATADIR)/proxysql.db，在重启ProxySQL的时候，会从proxysql.db文件中加载信息。而 /etc/proxysql.cnf文件只在第一次初始化的时候使用，之后如果要修改配置，就需要在管理端口的SQL命令行里进行修改，然后再save到硬盘。 也就是说DISK和CONFIG FILE这一层是持久化层，我们做的任何配置更改，如果不持久化下来，重启后，配置都将丢失。</p><p><strong>需要注意</strong>                                       </p><p>1) ProxySQL每一个配置项在三层中都存在，但是这三层是互相独立的，也就是说proxysql可以同时拥有三份配置，每层都是独立的，可能三份配置都不一样，也可能三份都一样。<br>2) RUNTIME层代表 ProxySQL 当前生效的正在使用的配置，无法直接修改这里的配置，必须要从下一层 “load” 进来。<br>3) MEMORY这一层上面连接 RUNTIME 层，下面连接持久化层。在这层可以正常操作 ProxySQL 配置，随便修改，不会影响生产环境。修改一个配置一般都是先在 MEMORY 层完成，然后确认正常之后再加载到 RUNTIME 和持久化到磁盘上。<br>4) DISK 和 CONFIG FILE层持久化配置信息，重启后内存中的配置信息会丢失，所以需要将配置信息保留在磁盘中。重启时，可以从磁盘快速加载回来。</p><p><strong>ProxySQL配置文件的修改流程一般是：</strong><br>- 启动时：先修改必要的CONFIG FILE配置，比如管理端口，然后启动；<br>- 其他配置：修改MEMORY中的表，然后加载到RUNTIME并持久化。</p><p><strong>ProxySQL具有一个复杂但易于使用的配置系统，可以满足以下需求：</strong><br>-  允许轻松动态更新配置（这是为了让ProxySQL用户可以在需要零宕机时间配置的大型基础架构中使用它）。与MySQL兼容的管理界面可用于此目的。<br>-  允许尽可能多的配置项目动态修改，而不需要重新启动ProxySQL进程<br>-  可以毫不费力地回滚无效配置<br>-  这是通过多级配置系统实现的，其中设置从运行时移到内存，并根据需要持久保存到磁盘。</p><p>一般，修改的配置都是在memory层。可以load到runtime，使配置在不用重启proxysql的情况下也可以生效，也可以save到disk，将对配置的修改持久化！</p><p>需要修改配置时，直接操作的是 MEMORAY，以下命令可用于加载或保存 users (mysql_users):  <strong>(序号对应上图“运行机制”草图)</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[1]: LOAD MYSQL USERS TO RUNTIME / LOAD MYSQL USERS FROM MEMORY   #常用。将修改后的配置(在memory层)用到实际生产</span><br><span class="line">[2]: SAVE MYSQL USERS TO MEMORY / SAVE MYSQL USERS FROM RUNTIME        #将生产配置拉一份到memory中</span><br><span class="line">[3]: LOAD MYSQL USERS TO MEMORY / LOAD MYSQL USERS FROM DISK           #将磁盘中持久化的配置拉一份到memory中来</span><br><span class="line">[4]: SAVE MYSQL USERS TO DISK /  SAVE MYSQL USERS FROM MEMORY     #常用。将memoery中的配置保存到磁盘中去</span><br><span class="line">[5]: LOAD MYSQL USERS FROM CONFIG                                      #将配置文件中的配置加载到memeory中</span><br></pre></td></tr></table></figure><p>个人还是比较习惯用 TO，记住往上层是 LOAD，往下层是 SAVE。以下命令加载或保存servers (mysql_servers):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[1]: LOAD MYSQL SERVERS TO RUNTIME  #常用，让修改的配置生效</span><br><span class="line">[2]: SAVE MYSQL SERVERS TO MEMORY</span><br><span class="line">[3]: LOAD MYSQL SERVERS TO MEMORY</span><br><span class="line">[4]: SAVE MYSQL SERVERS TO DISK     #常用，将修改的配置持久化</span><br><span class="line">[5]: LOAD MYSQL SERVERS FROM CONFIG</span><br></pre></td></tr></table></figure><p>后面的使用方法也基本相同，一并列出。以下命令加载或保存query rules (mysql_query_rules):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[1]: load mysql query rules to run    #常用</span><br><span class="line">[2]: save mysql query rules to mem</span><br><span class="line">[3]: load mysql query rules to mem</span><br><span class="line">[4]: save mysql query rules to disk   #常用</span><br><span class="line">[5]: load mysql query rules from config</span><br></pre></td></tr></table></figure><p>以下命令加载或保存 mysql variables (global_variables):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[1]: load mysql variables to runtime</span><br><span class="line">[2]: save mysql variables to memory</span><br><span class="line">[3]: load mysql variables to memory</span><br><span class="line">[4]: save mysql variables to disk</span><br><span class="line">[5]: load mysql variables from config</span><br></pre></td></tr></table></figure><p>以下命令加载或保存admin variables (select * from global_variables where variable_name like ‘admin-%’):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[1]: load admin variables to runtime</span><br><span class="line">[2]: save admin variables to memory</span><br><span class="line">[3]: load admin variables to memory</span><br><span class="line">[4]: save admin variables to disk</span><br><span class="line">[5]: load admin variables from config</span><br></pre></td></tr></table></figure><p><strong>ProxySQL启动过程总结:</strong><br>当proxysql启动时，首先读取配置文件CONFIG FILE(/etc/proxysql.cnf)，然后从该配置文件中获取datadir，datadir中配置的是sqlite的数据目录。如果该目录存在，且sqlite数据文件存在，那么正常启动，将sqlite中的配置项读进内存，并且加载进RUNTIME，用于初始化proxysql的运行。如果datadir目录下没有sqlite的数据文件，proxysql就会使用config file中的配置来初始化proxysql，并且将这些配置保存至数据库。sqlite数据文件可以不存在，/etc/proxysql.cnf文件也可以为空，但/etc/proxysql.cnf配置文件必须存在，否则，proxysql无法启动。</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;现在微服务几乎成为所有公司的标配，那么业务项目和数据存储的松耦合就成为基本配置，而mysql数据库在互联网公司中应用很广，几乎所有的项目都会有连它的需求。但是如果业务请求量很大，那么最先想到也是最常用的是数据库的读写分离。通常是由dba把数据库分为读写库，对数据进行更新，写入时连接读写库。查询数据时，连接读库。这样可以大大减轻写库的压力。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/2f5e57e1/1.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;但是这样是由业务根据需求来区分连哪个数据库，但有些开发说我想只配置一个数据库，运维你根据请求类型来区分定义是连接只读库还是读写库。而且业务对时效性也不是很严格。那要怎么做呢？如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/2f5e57e1/2.png&quot; alt&gt;&lt;/p&gt;
&lt;p&gt;我们就需要增加数据库的代理层，由代理层根据定义的规则来自动区分是连接读写库还是只读库。本文就是聊聊数据库的代理层–ProxySQL。&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
      <category term="SQL" scheme="https://wandouduoduo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/SQL/"/>
    
      <category term="Mysql" scheme="https://wandouduoduo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/SQL/Mysql/"/>
    
    
      <category term="Mysql" scheme="https://wandouduoduo.github.io/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>nginx配置用户名密码来控制访问请求</title>
    <link href="https://wandouduoduo.github.io/articles/edfb0ad9.html"/>
    <id>https://wandouduoduo.github.io/articles/edfb0ad9.html</id>
    <published>2021-06-08T03:06:56.000Z</published>
    <updated>2021-06-23T06:51:09.953Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>今天接了个需求：要把一些资源文件从外网提供给客户下载。处于安全和简单快捷考虑，分享一个快速实现并安全性很强的方案：nginx配置账号密码来控制，并且密码还是加密的，再增加白名单配置。此方案简单快捷和安全。</p><a id="more"></a><h2 id="方案"><a href="#方案" class="headerlink" title="方案"></a>方案</h2><h3 id="安装-htpasswd-工具"><a href="#安装-htpasswd-工具" class="headerlink" title="安装 htpasswd 工具"></a><strong>安装 htpasswd 工具</strong></h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install httpd-tools -y</span><br></pre></td></tr></table></figure><p>设置用户名和密码，并把用户名、密码保存到指定文件中：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[sun@bogon conf]$ sudo mkdir passwd</span><br><span class="line">[sun@bogon conf]$ sudo htpasswd -c passwd/passwd sun</span><br><span class="line">New password: </span><br><span class="line">Re-type new password: </span><br><span class="line">Adding password <span class="keyword">for</span> user sun</span><br><span class="line">[sun@bogon conf]$ cat passwd/passwd </span><br><span class="line">sun:<span class="variable">$apr1</span><span class="variable">$J5Sg0fQD</span><span class="variable">$KDM3Oypj8Wf9477PHDIzA0</span></span><br></pre></td></tr></table></figure><p>注意：上面的 passwd/passwd 是生成密码文件的路径，绝对路径是/etc/nginx/passwd/passwd ，然后sun是用户名，你可以根据需要自行设置成其它用户名。运行命令后，会要求你连续输入两次密码。输入成功后，会提示已经为sun这个用户添加了密码。<br>查看下生成的密码文件的内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[sun@bogon conf]$ cat passwd/passwd </span><br><span class="line">sun:$apr1$J5Sg0fQD$KDM3Oypj8Wf9477PHDIzA0</span><br></pre></td></tr></table></figure><p>其中用户名就是sun，分号后面就是密码（已经加过密）。</p><h3 id="修改-nginx-配置文件"><a href="#修改-nginx-配置文件" class="headerlink" title="修改 nginx 配置文件"></a><strong>修改 nginx 配置文件</strong></h3><p>找到 nginx 配置文件，因为我们要对整个站点开启验证，所以在配置文件中的第一个server修改如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name  localhost;</span><br><span class="line">    .......</span><br><span class="line">    #新增下面两行</span><br><span class="line">    auth_basic &quot;Please input password&quot;; #这里是验证时的提示信息</span><br><span class="line">    auth_basic_user_file /etc/nginx/passwd/passwd; # 这里是密码文件，可以填写绝对路径</span><br><span class="line">    location /&#123;</span><br><span class="line">    .......</span><br><span class="line">    root  /data;</span><br><span class="line">    autoindex on;</span><br><span class="line">    autoindex_exact_size off;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>然后nginx重新加载reload：    </p><p>以上都配置无误后，你重新访问你的站点，如果出现需要身份验证的弹窗就说明修改成功了。</p><h2 id="干货"><a href="#干货" class="headerlink" title="干货"></a>干货</h2><h3 id="htpasswd命令"><a href="#htpasswd命令" class="headerlink" title="htpasswd命令"></a><strong>htpasswd命令</strong></h3><p>htpasswd命令选项参数说明：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">-c 创建一个加密文件</span><br><span class="line">-n 不更新加密文件，只将htpasswd命令加密后的用户名密码显示在屏幕上 </span><br><span class="line">-m 默认htpassswd命令采用MD5算法对密码进行加密</span><br><span class="line">-d htpassswd命令采用CRYPT算法对密码进行加密</span><br><span class="line">-p htpassswd命令不对密码进行进行加密，即明文密码</span><br><span class="line">-s htpassswd命令采用SHA算法对密码进行加密</span><br><span class="line">-b htpassswd命令行中一并输入用户名和密码而不是根据提示输入密码</span><br><span class="line">-D 删除指定的用户</span><br></pre></td></tr></table></figure><h3 id="htpasswd例子"><a href="#htpasswd例子" class="headerlink" title="htpasswd例子"></a><strong>htpasswd例子</strong></h3><p><strong>利用htpasswd命令添加用户</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">htpasswd -bc ./.passwd sun pass</span><br></pre></td></tr></table></figure><p>在当前目录下生成一个.passwd文件，用户名sandu，密码：pass，默认采用MD5加密方式</p><p><strong>在原有密码文件中增加下一个用户</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">htpasswd -b ./.passwd sun1 pass</span><br></pre></td></tr></table></figure><p>去掉c选项，即可在第一个用户之后添加第二个用户，依此类推</p><p><strong>不更新密码文件，只显示加密后的用户名和密码</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">htpasswd -nb sun pass</span><br></pre></td></tr></table></figure><p>不更新.passwd文件，只在屏幕上输出用户名和经过加密后的密码</p><p><strong>利用htpasswd命令删除用户名和密码</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">htpasswd -D .passwd sun</span><br></pre></td></tr></table></figure><p><strong>利用 htpasswd 命令修改密码</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">htpasswd -D .passwd sun</span><br><span class="line">htpasswd -b .passwd sun pass</span><br></pre></td></tr></table></figure></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天接了个需求：要把一些资源文件从外网提供给客户下载。处于安全和简单快捷考虑，分享一个快速实现并安全性很强的方案：nginx配置账号密码来控制，并且密码还是加密的，再增加白名单配置。此方案简单快捷和安全。&lt;/p&gt;
    
    </summary>
    
      <category term="Web服务" scheme="https://wandouduoduo.github.io/categories/Web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Nginx" scheme="https://wandouduoduo.github.io/categories/Web%E6%9C%8D%E5%8A%A1/Nginx/"/>
    
    
      <category term="Nginx" scheme="https://wandouduoduo.github.io/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>nginx之location匹配优先级及顺序</title>
    <link href="https://wandouduoduo.github.io/articles/292b349b.html"/>
    <id>https://wandouduoduo.github.io/articles/292b349b.html</id>
    <published>2021-06-04T09:12:43.000Z</published>
    <updated>2021-06-04T09:54:00.644Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>nginx的使用范围和影响越来越广，很多大厂都在使用，但有些工作多年的同学可能都搞不清楚nginx中location的匹配优先级和匹配顺序是怎样的。今天又有同事不清楚，写配置时总是达不到业务需求，问到我这边帮他搞定了。那么本文就给大家详细聊聊这个问题。</p><a id="more"></a><h2 id="干货"><a href="#干货" class="headerlink" title="干货"></a>干货</h2><p>nginx的安装和搭建这里就不再赘述了。无论你是直接命令包库yum或apt-get安装还是下载源码包编译安装等等，看你喜好。</p><p>nginx是通过server块中location的配置用来匹配不同url访问：</p><p>location配置匹配方式主要包括三种：<strong>精准匹配</strong>、<strong>普通匹配</strong>和<strong>正则匹配</strong></p><p><strong>定义</strong></p><p>location = expression   精准匹配<br>location expression      普通匹配<br>location ^~ expression 普通匹配<br>location ~ regex 正则匹配（区分大小写）<br>location ~* regex 正则匹配（不区分大小写）</p><p><strong>要求</strong></p><p>精准匹配要求uri与表达式（expression）完全匹配。<br>普通匹配要求uri与表达式满足前缀匹配。<br>正则匹配要求uri与正则表达式匹配。</p><p><strong>匹配优先级和顺序规则</strong></p><p><strong>精准匹配（=）</strong>  &gt;  <strong>普通匹配（^~）</strong>  &gt;  <strong>正则匹配（<del>或</del>*）</strong> &gt;  <strong>普通匹配（直接目录）</strong></p><p>1、首先精准匹配，如能匹配，则进行转发。如未能匹配成功，则进行普通匹配（^<del>）。<br>2、nginx将uri和所有^</del>类型的普通匹配规则进行匹配。如有多条规则均命中，则选择最长匹配。匹配成功后，进行转发。否则，则进行正则匹配。<br>3、正则匹配与顺序有关，按编写顺序进行匹配，一旦匹配成功，则转发请求并停止匹配。匹配不成功，则进行普通匹配（location expression ）<br>4、进行普通匹配（location expression），匹配成功则转发，不成功则返回错误码。</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;nginx的使用范围和影响越来越广，很多大厂都在使用，但有些工作多年的同学可能都搞不清楚nginx中location的匹配优先级和匹配顺序是怎样的。今天又有同事不清楚，写配置时总是达不到业务需求，问到我这边帮他搞定了。那么本文就给大家详细聊聊这个问题。&lt;/p&gt;
    
    </summary>
    
      <category term="Web服务" scheme="https://wandouduoduo.github.io/categories/Web%E6%9C%8D%E5%8A%A1/"/>
    
      <category term="Nginx" scheme="https://wandouduoduo.github.io/categories/Web%E6%9C%8D%E5%8A%A1/Nginx/"/>
    
    
      <category term="Nginx" scheme="https://wandouduoduo.github.io/tags/Nginx/"/>
    
  </entry>
  
  <entry>
    <title>glusterfs集群横向扩容缩容</title>
    <link href="https://wandouduoduo.github.io/articles/9e838829.html"/>
    <id>https://wandouduoduo.github.io/articles/9e838829.html</id>
    <published>2021-05-26T03:14:28.000Z</published>
    <updated>2021-05-26T04:12:52.907Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>glusterfs集群的搭建和使用这里就不再赘述了，可以看以前的教程文档。本文主要聊的是随着服务使用量的增加，那么存储集群势必要扩充空间。服务器迁移，需要先扩容后缩容等等。所以本文的主旨是聊glusterfs集群的横向优化：扩容和缩容。</p><a id="more"></a><h2 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h2><p><strong>集群搭建这里忽略</strong><br>查看glusterfs的节点和客户端挂载情况得知，目前是三个节点的<strong>分布式卷</strong>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看节点数量</span></span><br><span class="line">root@wyl01:/gsclient<span class="comment"># gluster peer status</span></span><br><span class="line">Number of Peers: 2</span><br><span class="line">Hostname: 192.168.52.123</span><br><span class="line">Uuid: 0f07e396-fc0d-476c-884a-2cfb154f48d4</span><br><span class="line">State: Peer <span class="keyword">in</span> Cluster (Connected)</span><br><span class="line">Hostname: 192.168.52.124</span><br><span class="line">Uuid: 173df46f-a90a-4b0a-a5d0-834a17df17f6</span><br><span class="line">State: Peer <span class="keyword">in</span> Cluster (Connected)</span><br><span class="line"><span class="comment">#挂载 </span></span><br><span class="line">root@wyl01:/<span class="comment"># mount -t glusterfs 192.168.52.122:gv1 /gsclient/</span></span><br><span class="line">root@wyl01:/gsclient<span class="comment"># df -h</span></span><br><span class="line">Filesystem Size Used Avail Use% Mounted on</span><br><span class="line">udev 1.9G 0 1.9G 0% /dev</span><br><span class="line">tmpfs 395M 972K 394M 1% /run</span><br><span class="line">/dev/vda3 49G 3.4G 44G 8% /</span><br><span class="line">tmpfs 2.0G 0 2.0G 0% /dev/shm</span><br><span class="line">tmpfs 5.0M 0 5.0M 0% /run/lock</span><br><span class="line">tmpfs 2.0G 0 2.0G 0% /sys/fs/cgroup</span><br><span class="line">/dev/loop0 90M 90M 0 100% /snap/core/8039</span><br><span class="line">/dev/loop1 89M 89M 0 100% /snap/core/6964</span><br><span class="line">/dev/vda2 190M 80M 97M 46% /boot</span><br><span class="line">tmpfs 395M 0 395M 0% /run/user/0</span><br><span class="line">/dev/vdb 196G 62M 186G 1% /data</span><br><span class="line">192.168.52.122:gv1 588G 8.1G 580G 2% /gsclient</span><br></pre></td></tr></table></figure><p>创建20个文件</p><p>查看文件的分布情况如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第1台</span></span><br><span class="line">root@wyl01:/data<span class="comment"># ls</span></span><br><span class="line">10.txt 11.txt 12.txt 14.txt 15.txt 16.txt 18.txt 1.txt 20.txt 2.txt 3.txt 6.txt lost+found</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第2台</span></span><br><span class="line">root@gluster002-hf-aiui:/data<span class="comment"># ls</span></span><br><span class="line">13.txt 17.txt 19.txt 4.txt 8.txt lost+found</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第3台</span></span><br><span class="line">root@gluster003-hf-aiui:/data<span class="comment"># ls</span></span><br><span class="line">5.txt 7.txt 9.txt lost+found</span><br></pre></td></tr></table></figure><h2 id="分布式卷优化"><a href="#分布式卷优化" class="headerlink" title="分布式卷优化"></a>分布式卷优化</h2><h3 id="添加节点扩容"><a href="#添加节点扩容" class="headerlink" title="添加节点扩容"></a>添加节点扩容</h3><p>现要对集群进行扩容，增加一个节点 gluster004-hf-aiui.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加一个节点</span></span><br><span class="line">root@wyl01:/gsclient<span class="comment"># gluster peer probe 192.168.52.125</span></span><br><span class="line">peer probe: success.</span><br><span class="line">root@wyl01:/gsclient<span class="comment"># gluster peer status</span></span><br><span class="line">Number of Peers: 3</span><br><span class="line">Hostname: 192.168.52.123</span><br><span class="line">Uuid: 0f07e396-fc0d-476c-884a-2cfb154f48d4</span><br><span class="line">State: Peer <span class="keyword">in</span> Cluster (Connected)</span><br><span class="line">Hostname: 192.168.52.124</span><br><span class="line">Uuid: 173df46f-a90a-4b0a-a5d0-834a17df17f6</span><br><span class="line">State: Peer <span class="keyword">in</span> Cluster (Connected)</span><br><span class="line">Hostname: 192.168.52.125</span><br><span class="line">Uuid: f6578f82-adb4-4529-b803-eedde37cb550</span><br><span class="line">State: Peer <span class="keyword">in</span> Cluster (Connected)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 增加一个brick</span></span><br><span class="line">root@wyl01:/gsclient<span class="comment"># gluster volume add-brick gv1 192.168.52.125:/data force</span></span><br><span class="line">volume add-brick: success</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看卷的信息</span></span><br><span class="line">root@wyl01:/gsclient<span class="comment"># gluster volume info</span></span><br><span class="line">Volume Name: gv1</span><br><span class="line">Type: Distribute</span><br><span class="line">Volume ID: 110caace-b49f-4493-8792-bc2982319c23</span><br><span class="line">Status: Started</span><br><span class="line">Snapshot Count: 0</span><br><span class="line">Number of Bricks: 4</span><br><span class="line">Transport-type: tcp</span><br><span class="line">Bricks:</span><br><span class="line">Brick1: 192.168.52.122:/data</span><br><span class="line">Brick2: 192.168.52.123:/data</span><br><span class="line">Brick3: 192.168.52.124:/data</span><br><span class="line">Brick4: 192.168.52.125:/data</span><br><span class="line">Options Reconfigured:</span><br><span class="line">performance.client-io-threads: on</span><br><span class="line">transport.address-family: inet</span><br><span class="line">nfs.disable: on</span><br></pre></td></tr></table></figure><p>再创建30个文件，如下所示：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">root@wyl01:/gsclient<span class="comment"># touch &#123;101..130&#125;.txt</span></span><br><span class="line"><span class="comment"># 第 1 台</span></span><br><span class="line">root@wyl01:/gsclient<span class="comment"># ls /data/</span></span><br><span class="line">101.txt 107.txt 10.txt 112.txt 114.txt 117.txt 11.txt 122.txt 12.txt 14.txt 15.txt 16.txt 18.txt 1.txt 20.txt 2.txt 3.txt 6.txt lost+found</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第 2 台</span></span><br><span class="line">root@wyl02:/data<span class="comment"># ls</span></span><br><span class="line">105.txt 115.txt 116.txt 124.txt 125.txt 127.txt 128.txt 129.txt 13.txt 17.txt 19.txt 4.txt 8.txt lost+found</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第 3 台</span></span><br><span class="line">root@wyl03-hf-aiui:/data<span class="comment"># ls</span></span><br><span class="line">102.txt 103.txt 104.txt 106.txt 108.txt 109.txt 110.txt 111.txt 121.txt 130.txt 5.txt 7.txt 9.txt lost+found</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第 4 台</span></span><br><span class="line">root@wyl04-hf-aiui:/data<span class="comment"># ls</span></span><br><span class="line">113.txt 118.txt 119.txt 120.txt 123.txt 126.txt lost+found</span><br></pre></td></tr></table></figure><p>结论：可以看出当扩容后，原先的数据不会均衡到第四台glusterfs上，但是新增加的文件是可以的。</p><h3 id="分布式卷数据rebalance"><a href="#分布式卷数据rebalance" class="headerlink" title="分布式卷数据rebalance"></a>分布式卷数据rebalance</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">root@wyl01:/gsclient<span class="comment"># gluster volume rebalance gv1 start</span></span><br><span class="line">volume rebalance: gv1: success: Rebalance on gv1 has been started successfully. Use rebalance status <span class="built_in">command</span> to check status of the rebalance process.</span><br><span class="line">ID: 76b07497-b26d-438f-bd6f-7659a9aba251</span><br><span class="line">root@wyl01:/gsclient<span class="comment"># gluster volume rebalance gv1 status</span></span><br><span class="line">Node Rebalanced-files size scanned failures skipped status run time <span class="keyword">in</span> h:m:s</span><br><span class="line"></span><br><span class="line">------</span><br><span class="line"></span><br><span class="line">192.168.52.123 4 0Bytes 13 0 0 completed 0:00:00</span><br><span class="line">192.168.52.124 1 0Bytes 14 0 0 completed 0:00:00</span><br><span class="line">192.168.52.125 0 0Bytes 6 0 0 completed 0:00:00</span><br><span class="line">localhost 12 0Bytes 18 0 0 completed 0:00:01</span><br><span class="line">volume rebalance: gv1: success</span><br><span class="line"><span class="comment">#第 1 台</span></span><br><span class="line">root@wyl01:/gsclient<span class="comment"># ls /data/</span></span><br><span class="line">101.txt 107.txt 112.txt 114.txt 117.txt 122.txt 13.txt 17.txt 4.txt 8.txt lost+found</span><br><span class="line"><span class="comment">#第 2 台</span></span><br><span class="line">root@wyl02-hf-aiui:/data<span class="comment"># ls</span></span><br><span class="line">105.txt 115.txt 116.txt 124.txt 125.txt 127.txt 128.txt 129.txt 19.txt 9.txt lost+found</span><br><span class="line"><span class="comment">#第 3 台</span></span><br><span class="line">root@wyl03-hf-aiui:/data<span class="comment"># ls</span></span><br><span class="line">100.txt 102.txt 103.txt 104.txt 106.txt 108.txt 109.txt 110.txt 111.txt 121.txt 130.txt 2.txt 5.txt 7.txt lost+found</span><br><span class="line"><span class="comment">#第 4 台</span></span><br><span class="line">root@wyl04-hf-aiui:/data<span class="comment"># ls</span></span><br><span class="line">10.txt 113.txt 118.txt 119.txt 11.txt 120.txt 123.txt 126.txt 12.txt 14.txt 15.txt 16.txt 18.txt 1.txt 20.txt 3.txt 6.txt lost+found</span><br></pre></td></tr></table></figure><p>可以看到，数据rebalance，第 4 台上的数据明显增加了。</p><p>这里有一个需要注意的地方，当数据量太大的时候，对数据进行rebalance必须要考虑的一个问题就是性能，不能因为数据rebalance而影响我们的存储的正常使用。Glusterfs也考虑到了这个问题，在进行数据rebalance时，根据实际场景不同设计了三种不同的“级别”：</p><p><strong>lazy</strong>：每次仅可以迁移一个文件<br><strong>normal</strong>：默认设置，每次迁移2个文件或者是(CPU逻辑个数-4)/2,哪个大，选哪个<br><strong>aggressive</strong>：每次迁移4个文件或者是(CPU逻辑个数-4)/2<br>通过以下命令进行配置：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume set VOLUME-NAME cluster.rebal-throttle [lazy|normal|aggressive]</span><br></pre></td></tr></table></figure><p>如将volume repvol设置为lazy</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@nwyl01 ~]<span class="comment"># gluster volume set gv1 cluster.rebal-throttle lazy</span></span><br><span class="line">volume <span class="built_in">set</span>: success</span><br></pre></td></tr></table></figure><h3 id="分布式卷缩容"><a href="#分布式卷缩容" class="headerlink" title="分布式卷缩容"></a>分布式卷缩容</h3><p>缩容之前我们先需要将数据迁移到其他的brick上，假设我们移除gluster004-hf-aiui节点</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">root@wyl01:/gsclient<span class="comment"># gluster volume remove-brick gv1 gluster004-hf-aiui:/data help</span></span><br><span class="line">Usage:</span><br><span class="line">volume remove-brick &lt;VOLNAME&gt; [replica &lt;COUNT&gt;] &lt;BRICK&gt; ... &lt;start|stop|status|commit|force&gt;</span><br><span class="line"></span><br><span class="line">root@wyl01:/gsclient<span class="comment"># gluster volume remove-brick gv1 gluster004-hf-aiui:/data start</span></span><br><span class="line">Running remove-brick with cluster.force-migration enabled can result <span class="keyword">in</span> data corruption. It is safer to <span class="built_in">disable</span> this option so that files that receive writes during migration are not migrated.</span><br><span class="line">Files that are not migrated can <span class="keyword">then</span> be manually copied after the remove-brick commit operation.</span><br><span class="line">Do you want to <span class="built_in">continue</span> with your current cluster.force-migration settings? (y/n) y</span><br><span class="line">volume remove-brick start: success</span><br><span class="line">ID: e30a9e72-53ef-4e79-a394-38dcac9061ba</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看移除节点的状态</span></span><br><span class="line">root@wyl01:/gsclient<span class="comment"># gluster volume remove-brick gv1 gluster004-hf-aiui:/data status</span></span><br><span class="line">Node Rebalanced-files size scanned failures skipped status run time <span class="keyword">in</span> h:m:s</span><br><span class="line"></span><br><span class="line">------</span><br><span class="line"></span><br><span class="line">192.168.52.125 17 0Bytes 17 0 0 completed 0:00:00</span><br><span class="line"></span><br><span class="line"><span class="comment"># 移除前先将数据同步到其他brick上</span></span><br><span class="line">root@wyl01:/gsclient<span class="comment"># gluster volume remove-brick gv1 gluster004-hf-aiui:/data commit</span></span><br><span class="line">volume remove-brick commit: success</span><br><span class="line">Check the removed bricks to ensure all files are migrated.</span><br><span class="line">If files with data are found on the brick path, copy them via a gluster mount point before re-purposing the removed brick.</span><br></pre></td></tr></table></figure><p>移除后，我们看数据的分布情况</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 第 1 台</span></span><br><span class="line">root@wyl01:/gsclient<span class="comment"># ls /data/</span></span><br><span class="line">101.txt 107.txt 112.txt 114.txt 117.txt 122.txt 13.txt 17.txt 4.txt 8.txt lost+found</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第 2 台</span></span><br><span class="line">root@wyl02-hf-aiui:/data<span class="comment"># ls</span></span><br><span class="line">105.txt 115.txt 116.txt 124.txt 125.txt 127.txt 128.txt 129.txt 19.txt 9.txt lost+found</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第 3 台</span></span><br><span class="line">root@wyl03-hf-aiui:/data<span class="comment"># ls</span></span><br><span class="line">100.txt 103.txt 106.txt 109.txt 110.txt 113.txt 119.txt 120.txt 123.txt 12.txt 14.txt 16.txt 1.txt 2.txt 5.txt 7.txt</span><br><span class="line">102.txt 104.txt 108.txt 10.txt 111.txt 118.txt 11.txt 121.txt 126.txt 130.txt 15.txt 18.txt 20.txt 3.txt 6.txt lost+found</span><br></pre></td></tr></table></figure><p>可以看到文件被迁移到其他的brick上了。</p><h2 id="复制卷的扩容rebalance缩容"><a href="#复制卷的扩容rebalance缩容" class="headerlink" title="复制卷的扩容rebalance缩容"></a>复制卷的扩容rebalance缩容</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">root@wyl01:/gsclient<span class="comment"># gluster volume info # 卷的基本信息</span></span><br><span class="line">Volume Name: gv1</span><br><span class="line">Type: Replicate</span><br><span class="line">Volume ID: ff65e899-4f30-4249-9cf4-532a7d4eab74</span><br><span class="line">Status: Started</span><br><span class="line">Snapshot Count: 0</span><br><span class="line">Number of Bricks: 1 x 2 = 2</span><br><span class="line">Transport-type: tcp</span><br><span class="line">Bricks:</span><br><span class="line">Brick1: 192.168.52.122:/data</span><br><span class="line">Brick2: 192.168.52.123:/data</span><br><span class="line">Options Reconfigured:</span><br><span class="line">transport.address-family: inet</span><br><span class="line">nfs.disable: on</span><br><span class="line">performance.client-io-threads: off</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建20个文件</span></span><br><span class="line">root@wyl01:/gsclient<span class="comment"># touch &#123;1..20&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看分布情况</span></span><br><span class="line"><span class="comment"># 第 1 台</span></span><br><span class="line">root@wyl01:/gsclient<span class="comment"># ls /data/</span></span><br><span class="line">10.txt 11.txt 12.txt 13.txt 14.txt 15.txt 16.txt 17.txt 18.txt 19.txt 1.txt 20.txt 2.txt 3.txt 4.txt 5.txt 6.txt 7.txt 8.txt 9.txt lost+found</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第 2 台</span></span><br><span class="line">root@wyl02-hf-aiui:/data<span class="comment"># ls</span></span><br><span class="line">10.txt 11.txt 12.txt 13.txt 14.txt 15.txt 16.txt 17.txt 18.txt 19.txt 1.txt 20.txt 2.txt 3.txt 4.txt 5.txt 6.txt 7.txt 8.txt 9.txt lost+found</span><br><span class="line">添加gluster003和gluster004两个节点</span><br></pre></td></tr></table></figure><h3 id="添加gluster003-节点"><a href="#添加gluster003-节点" class="headerlink" title="添加gluster003 节点"></a>添加gluster003 节点</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@wyl01:/gsclient# gluster peer probe 192.168.52.124</span><br><span class="line">peer probe: success.</span><br></pre></td></tr></table></figure><h3 id="添加gluster04-节点"><a href="#添加gluster04-节点" class="headerlink" title="添加gluster04 节点"></a>添加gluster04 节点</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@wyl01:/gsclient# gluster peer probe 192.168.52.125</span><br><span class="line">peer probe: success.</span><br></pre></td></tr></table></figure><h3 id="查看peer信息"><a href="#查看peer信息" class="headerlink" title="查看peer信息"></a>查看peer信息</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">root@wyl01:/gsclient<span class="comment"># gluster peer status</span></span><br><span class="line">Number of Peers: 3</span><br><span class="line">Hostname: 192.168.52.123</span><br><span class="line">Uuid: 0f07e396-fc0d-476c-884a-2cfb154f48d4</span><br><span class="line">State: Peer <span class="keyword">in</span> Cluster (Connected)</span><br><span class="line">Hostname: 192.168.52.124</span><br><span class="line">Uuid: 173df46f-a90a-4b0a-a5d0-834a17df17f6</span><br><span class="line">State: Peer <span class="keyword">in</span> Cluster (Connected)</span><br><span class="line">Hostname: 192.168.52.125</span><br><span class="line">Uuid: f6578f82-adb4-4529-b803-eedde37cb550</span><br><span class="line">State: Peer <span class="keyword">in</span> Cluster (Connected)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 扩容brick</span></span><br><span class="line"></span><br><span class="line">root@wyl01:/gsclient<span class="comment"># gluster volume add-brick gv1 replica 2 192.168.52.124:/data 192.168.52.125:/data force</span></span><br><span class="line">volume add-brick: success</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看卷的信息</span></span><br><span class="line"></span><br><span class="line">root@wyl01:/gsclient<span class="comment"># gluster volume info</span></span><br><span class="line">Volume Name: gv1</span><br><span class="line">Type: Distributed-Replicate</span><br><span class="line">Volume ID: ff65e899-4f30-4249-9cf4-532a7d4eab74</span><br><span class="line">Status: Started</span><br><span class="line">Snapshot Count: 0</span><br><span class="line">Number of Bricks: 2 x 2 = 4</span><br><span class="line">Transport-type: tcp</span><br><span class="line">Bricks:</span><br><span class="line">Brick1: 192.168.52.122:/data</span><br><span class="line">Brick2: 192.168.52.123:/data</span><br><span class="line">Brick3: 192.168.52.124:/data</span><br><span class="line">Brick4: 192.168.52.125:/data</span><br><span class="line">Options Reconfigured:</span><br><span class="line">transport.address-family: inet</span><br><span class="line">nfs.disable: on</span><br><span class="line">performance.client-io-threads: off</span><br></pre></td></tr></table></figure><p>发现现在变成2*2了模式了。重新写入20个txt文件，扩容后这里需要注意的是必须先rebalance。然后重新写入文件才会hash到新的节点上。之前的旧数据也会被rebalance。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@wyl01:/gsclient<span class="comment"># gluster volume rebalance gv1 start</span></span><br><span class="line">volume rebalance: gv1: success: Rebalance on gv1 has been started successfully. Use rebalance status <span class="built_in">command</span> to check status of the rebalance process.</span><br><span class="line">ID: 90df529c-d950-4010-9248-19ffa7c83853</span><br></pre></td></tr></table></figure><p>节点的缩容，这里是分布式复制，所以缩容也是成对节点的一起缩容，操作如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 开始移除节点</span></span><br><span class="line"></span><br><span class="line">root@wyl01:/gsclient<span class="comment"># gluster volume remove-brick gv1 replica 2 wyl03-hf-aiui:/data wyl04-hf-aiui:/data start</span></span><br><span class="line">Replica 2 volumes are prone to split-brain. Use Arbiter or Replica 3 to avaoid this. See: http://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/.</span><br><span class="line">Do you still want to <span class="built_in">continue</span>?</span><br><span class="line">(y/n) y</span><br><span class="line">Running remove-brick with cluster.force-migration enabled can result <span class="keyword">in</span> data corruption. It is safer to <span class="built_in">disable</span> this option so that files that receive writes during migration are not migrated.</span><br><span class="line">Files that are not migrated can <span class="keyword">then</span> be manually copied after the remove-brick commit operation.</span><br><span class="line">Do you want to <span class="built_in">continue</span> with your current cluster.force-migration settings? (y/n) y</span><br><span class="line">volume remove-brick start: success</span><br><span class="line">ID: d4ce7df1-30c9-4124-9986-c9634986609f</span><br><span class="line"></span><br><span class="line"><span class="comment"># 移除前先将数据同步到其他brick上</span></span><br><span class="line">root@wyl01:/gsclient<span class="comment"># gluster volume remove-brick gv1 replica 2 wyl03-hf-aiui:/data wyl04-hf-aiui:/data commit</span></span><br><span class="line">Replica 2 volumes are prone to split-brain. Use Arbiter or Replica 3 to avaoid this. See: http://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/.</span><br><span class="line">Do you still want to <span class="built_in">continue</span>?</span><br><span class="line">(y/n) y</span><br><span class="line">volume remove-brick commit: success</span><br><span class="line">Check the removed bricks to ensure all files are migrated.</span><br><span class="line">If files with data are found on the brick path, copy them via a gluster mount point before re-purposing the removed</span><br></pre></td></tr></table></figure></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;glusterfs集群的搭建和使用这里就不再赘述了，可以看以前的教程文档。本文主要聊的是随着服务使用量的增加，那么存储集群势必要扩充空间。服务器迁移，需要先扩容后缩容等等。所以本文的主旨是聊glusterfs集群的横向优化：扩容和缩容。&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="GlusterFS" scheme="https://wandouduoduo.github.io/tags/GlusterFS/"/>
    
  </entry>
  
  <entry>
    <title>kafka之扩容和缩容</title>
    <link href="https://wandouduoduo.github.io/articles/c34eeebc.html"/>
    <id>https://wandouduoduo.github.io/articles/c34eeebc.html</id>
    <published>2021-05-19T06:17:37.000Z</published>
    <updated>2021-05-19T06:43:23.785Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>本文讨论Kafka的扩缩容以及故障后如何“补齐”分区。实质上先扩容再缩容也是迁移的操作。</p><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>Kafka 版本2.6。</p><h2 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h2><p>扩容也就是新增节点，扩容后老的数据不会自动迁移，只有新创建的topic才可能会分配到新增的节点上面。如果我们不需要迁移旧数据，那直接把新的节点启动起来就行了，不需要做额外的操作。但有的时候，新增节点后，我们会将一些老数据迁移到新的节点上，以达到负载均衡的目的，这个时候就需要手动操作了。Kafka提供了一个脚本（在bin目录下）：<strong>kafka-reassign-partitions.sh</strong>，通过这个脚本可以重新分配分区的分布。脚本的使用比较简单，提供一个JSON格式的分配方案，然后传给脚本，脚本根据我们的分配方案重新进行平衡。</p><p>举个例子，假如现在集群有181、182两个broker，上面有4个topic：test-1，test-2，test-3，test-4，这些topic都有4个分区，2个副本，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 两个broker</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 0] ls /kafka_26/brokers/ids</span><br><span class="line">[181, 182]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 4个topic</span></span><br><span class="line">➜ bin/kafka-topics.sh --list --zookeeper localhost:2181/kafka_26</span><br><span class="line">__consumer_offsets</span><br><span class="line">test-1</span><br><span class="line">test-1</span><br><span class="line">test-3</span><br><span class="line">test-4</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">test</span>-1</span></span><br><span class="line">➜  bin/kafka-topics.sh --describe --topic test-1  --zookeeper localhost:2181/kafka_26</span><br><span class="line">Topic: test-1   PartitionCount: 4       ReplicationFactor: 2    Configs: </span><br><span class="line">        Topic: test-1   Partition: 0    Leader: 181     Replicas: 181,182       Isr: 181,182</span><br><span class="line">        Topic: test-1   Partition: 1    Leader: 182     Replicas: 182,181       Isr: 182,181</span><br><span class="line">        Topic: test-1   Partition: 2    Leader: 181     Replicas: 181,182       Isr: 181,182</span><br><span class="line">        Topic: test-1   Partition: 3    Leader: 182     Replicas: 182,181       Isr: 182,181</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">test</span>-2</span></span><br><span class="line">➜  bin/kafka-topics.sh --describe --topic test-2  --zookeeper localhost:2181/kafka_26</span><br><span class="line">Topic: test-2   PartitionCount: 4       ReplicationFactor: 2    Configs: </span><br><span class="line">        Topic: test-2   Partition: 0    Leader: 181     Replicas: 181,182       Isr: 181,182</span><br><span class="line">        Topic: test-2   Partition: 1    Leader: 182     Replicas: 182,181       Isr: 182,181</span><br><span class="line">        Topic: test-2   Partition: 2    Leader: 181     Replicas: 181,182       Isr: 181,182</span><br><span class="line">        Topic: test-2   Partition: 3    Leader: 182     Replicas: 182,181       Isr: 182,181</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">test</span>-3</span></span><br><span class="line">➜  bin/kafka-topics.sh --describe --topic test-3  --zookeeper localhost:2181/kafka_26</span><br><span class="line">Topic: test-3   PartitionCount: 4       ReplicationFactor: 2    Configs: </span><br><span class="line">        Topic: test-3   Partition: 0    Leader: 181     Replicas: 181,182       Isr: 181,182</span><br><span class="line">        Topic: test-3   Partition: 1    Leader: 182     Replicas: 182,181       Isr: 182,181</span><br><span class="line">        Topic: test-3   Partition: 2    Leader: 181     Replicas: 181,182       Isr: 181,182</span><br><span class="line">        Topic: test-3   Partition: 3    Leader: 182     Replicas: 182,181       Isr: 182,181</span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">test</span>-4</span></span><br><span class="line">➜ bin/kafka-topics.sh --describe --topic test-4  --zookeeper localhost:2181/kafka_26</span><br><span class="line">Topic: test-4   PartitionCount: 4       ReplicationFactor: 2    Configs: </span><br><span class="line">        Topic: test-4   Partition: 0    Leader: 182     Replicas: 182,181       Isr: 182,181</span><br><span class="line">        Topic: test-4   Partition: 1    Leader: 181     Replicas: 181,182       Isr: 181,182</span><br><span class="line">        Topic: test-4   Partition: 2    Leader: 182     Replicas: 182,181       Isr: 182,181</span><br><span class="line">        Topic: test-4   Partition: 3    Leader: 181     Replicas: 181,182       Isr: 181,182</span><br></pre></td></tr></table></figure><p>现在扩容了，新增了两个节点：183和184。扩容后，我们想要把test-3，test-4迁移到183，184上面去。</p><p>首先我们可以准备如下JSON格式的文件（假设文件名为<code>topics-to-move.json</code>）：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"topics"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"topic"</span>: <span class="string">"test-3"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"topic"</span>: <span class="string">"test-4"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"version"</span>: <span class="number">1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>里面写明想要重新分配的topic。然后执行如下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">➜ bin/kafka-reassign-partitions.sh --bootstrap-server localhost:9092 --topics-to-move-json-file topics-to-move.json --broker-list "183,184" --generate</span><br><span class="line"><span class="meta">#</span><span class="bash"> 当前分区的分布情况</span></span><br><span class="line">Current partition replica assignment</span><br><span class="line">&#123;"version":1,"partitions":[&#123;"topic":"test-3","partition":0,"replicas":[181,182],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-3","partition":1,"replicas":[182,181],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-3","partition":2,"replicas":[181,182],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-3","partition":3,"replicas":[182,181],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-4","partition":0,"replicas":[182,181],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-4","partition":1,"replicas":[181,182],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-4","partition":2,"replicas":[182,181],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-4","partition":3,"replicas":[181,182],"log_dirs":["any","any"]&#125;]&#125;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 建议的分区分布情况</span></span><br><span class="line">Proposed partition reassignment configuration</span><br><span class="line">&#123;"version":1,"partitions":[&#123;"topic":"test-3","partition":0,"replicas":[183,184],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-3","partition":1,"replicas":[184,183],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-3","partition":2,"replicas":[183,184],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-3","partition":3,"replicas":[184,183],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-4","partition":0,"replicas":[184,183],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-4","partition":1,"replicas":[183,184],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-4","partition":2,"replicas":[184,183],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-4","partition":3,"replicas":[183,184],"log_dirs":["any","any"]&#125;]&#125;</span><br></pre></td></tr></table></figure><p>可以看到上面的命令会列出当前分区的分布情况，并且会给出一个建议的新分区分配方案，都是JSON格式的，内容也很简单。然后我们将建议的分配方案保存为一个文件（假设文件名为<code>expand-cluster-reassignment.json</code>），当然我们也可以手动修改这个方案，只要格式正确即可。然后执行下面命令使用新的方案进行分区重分配：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">➜ bin/kafka-reassign-partitions.sh --bootstrap-server localhost:9092 --reassignment-json-file expand-cluster-reassignment.json --execute</span><br><span class="line">Current partition replica assignment</span><br><span class="line"></span><br><span class="line">&#123;"version":1,"partitions":[&#123;"topic":"test-3","partition":0,"replicas":[181,182],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-3","partition":1,"replicas":[182,181],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-3","partition":2,"replicas":[181,182],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-3","partition":3,"replicas":[182,181],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-4","partition":0,"replicas":[182,181],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-4","partition":1,"replicas":[181,182],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-4","partition":2,"replicas":[182,181],"log_dirs":["any","any"]&#125;,&#123;"topic":"test-4","partition":3,"replicas":[181,182],"log_dirs":["any","any"]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">Save this to use as the --reassignment-json-file option during rollback</span><br><span class="line">Successfully started partition reassignments for test-3-0,test-3-1,test-3-2,test-3-3,test-4-0,test-4-1,test-4-2,test-4-3</span><br></pre></td></tr></table></figure><p>这样就<strong>提交</strong>了重分配的任务，可以使用下面的命令查看任务的执行状态：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">➜ bin/kafka-reassign-partitions.sh --bootstrap-server localhost:9092 --reassignment-json-file expand-cluster-reassignment.json --verify</span><br><span class="line">Status of partition reassignment:</span><br><span class="line">Reassignment of partition test-3-0 is complete.</span><br><span class="line">Reassignment of partition test-3-1 is complete.</span><br><span class="line">Reassignment of partition test-3-2 is complete.</span><br><span class="line">Reassignment of partition test-3-3 is complete.</span><br><span class="line">Reassignment of partition test-4-0 is complete.</span><br><span class="line">Reassignment of partition test-4-1 is complete.</span><br><span class="line">Reassignment of partition test-4-2 is complete.</span><br><span class="line">Reassignment of partition test-4-3 is complete.</span><br><span class="line"></span><br><span class="line">Clearing broker-level throttles on brokers 181,182,183,184</span><br><span class="line">Clearing topic-level throttles on topics test-3,test-4</span><br></pre></td></tr></table></figure><p>完成后，我们检查一下新的test-3和test-4的分区分配情况：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">➜ bin/kafka-topics.sh --describe --topic test-3  --zookeeper localhost:2181/kafka_26</span><br><span class="line">Topic: test-3   PartitionCount: 4       ReplicationFactor: 2    Configs: </span><br><span class="line">        Topic: test-3   Partition: 0    Leader: 183     Replicas: 183,184       Isr: 183,184</span><br><span class="line">        Topic: test-3   Partition: 1    Leader: 184     Replicas: 184,183       Isr: 183,184</span><br><span class="line">        Topic: test-3   Partition: 2    Leader: 183     Replicas: 183,184       Isr: 183,184</span><br><span class="line">        Topic: test-3   Partition: 3    Leader: 184     Replicas: 184,183       Isr: 183,184</span><br><span class="line">        </span><br><span class="line">➜ bin/kafka-topics.sh --describe --topic test-4  --zookeeper localhost:2181/kafka_26</span><br><span class="line">Topic: test-4   PartitionCount: 4       ReplicationFactor: 2    Configs: </span><br><span class="line">        Topic: test-4   Partition: 0    Leader: 184     Replicas: 184,183       Isr: 183,184</span><br><span class="line">        Topic: test-4   Partition: 1    Leader: 183     Replicas: 183,184       Isr: 183,184</span><br><span class="line">        Topic: test-4   Partition: 2    Leader: 184     Replicas: 184,183       Isr: 183,184</span><br><span class="line">        Topic: test-4   Partition: 3    Leader: 183     Replicas: 183,184       Isr: 184,183</span><br></pre></td></tr></table></figure><p>可以看到，这两个topic的数据已经全部分配到183和184节点上了。</p><h2 id="缩容"><a href="#缩容" class="headerlink" title="缩容"></a>缩容</h2><p>从上面可以看到，其实数据分配完全是由我们自己把控的，缩容也只是数据迁移而已，只需要提供正确的迁移方案即可。一般生产环境很少有缩容的，但有一个场景比较常见，就是某个节点故障了，且无法恢复。以前的文章提到过，节点故障后，这个节点上的分区就丢了，Kafka不会自动在其它可用节点上重新创建一个副本，这个时候就需要我们自己手动在其他可用节点创建副本，原理和扩容是一样的。接着上面的例子，比如现在184节点故障了，且无法恢复了，而test-3和test-4有部分分区是在该节点上面的，自然也就丢了：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 节点挂了，zk中的节点已经没了</span></span><br><span class="line">[zk: localhost:2181(CONNECTED) 15] ls /kafka_26/brokers/ids</span><br><span class="line">[181, 182, 183]</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 可以看到ISR中已经没有184了</span></span><br><span class="line">➜ bin/kafka-topics.sh --describe --topic test-3  --zookeeper localhost:2181/kafka_26</span><br><span class="line">Topic: test-3   PartitionCount: 4       ReplicationFactor: 2    Configs: </span><br><span class="line">        Topic: test-3   Partition: 0    Leader: 183     Replicas: 183,184       Isr: 183</span><br><span class="line">        Topic: test-3   Partition: 1    Leader: 183     Replicas: 184,183       Isr: 183</span><br><span class="line">        Topic: test-3   Partition: 2    Leader: 183     Replicas: 183,184       Isr: 183</span><br><span class="line">        Topic: test-3   Partition: 3    Leader: 183     Replicas: 184,183       Isr: 183</span><br><span class="line">➜ bin/kafka-topics.sh --describe --topic test-4  --zookeeper localhost:2181/kafka_26</span><br><span class="line">Topic: test-4   PartitionCount: 4       ReplicationFactor: 2    Configs: </span><br><span class="line">        Topic: test-4   Partition: 0    Leader: 183     Replicas: 184,183       Isr: 183</span><br><span class="line">        Topic: test-4   Partition: 1    Leader: 183     Replicas: 183,184       Isr: 183</span><br><span class="line">        Topic: test-4   Partition: 2    Leader: 183     Replicas: 184,183       Isr: 183</span><br><span class="line">        Topic: test-4   Partition: 3    Leader: 183     Replicas: 183,184       Isr: 183</span><br></pre></td></tr></table></figure><p>这个时候，我们准备把test-3原来在184上的分区分配到181上面去，把test-4在184上的分区分配到182上去，那分配方案就是下面这样的：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">➜ cat expand-cluster-reassignment.json</span><br><span class="line">&#123;</span><br><span class="line">  "version": 1,</span><br><span class="line">  "partitions": [</span><br><span class="line">    &#123;</span><br><span class="line">      "topic": "test-3",</span><br><span class="line">      "partition": 0,</span><br><span class="line">      "replicas": [183, 181],</span><br><span class="line">      "log_dirs": ["any", "any"]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      "topic": "test-3",</span><br><span class="line">      "partition": 1,</span><br><span class="line">      "replicas": [181, 183],</span><br><span class="line">      "log_dirs": ["any", "any"]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      "topic": "test-3",</span><br><span class="line">      "partition": 2,</span><br><span class="line">      "replicas": [183, 181],</span><br><span class="line">      "log_dirs": ["any", "any"]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      "topic": "test-3",</span><br><span class="line">      "partition": 3,</span><br><span class="line">      "replicas": [181, 183],</span><br><span class="line">      "log_dirs": ["any", "any"]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      "topic": "test-4",</span><br><span class="line">      "partition": 0,</span><br><span class="line">      "replicas": [182, 183],</span><br><span class="line">      "log_dirs": ["any", "any"]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      "topic": "test-4",</span><br><span class="line">      "partition": 1,</span><br><span class="line">      "replicas": [183, 182],</span><br><span class="line">      "log_dirs": ["any", "any"]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      "topic": "test-4",</span><br><span class="line">      "partition": 2,</span><br><span class="line">      "replicas": [182, 183],</span><br><span class="line">      "log_dirs": ["any", "any"]</span><br><span class="line">    &#125;,</span><br><span class="line">    &#123;</span><br><span class="line">      "topic": "test-4",</span><br><span class="line">      "partition": 3,</span><br><span class="line">      "replicas": [183, 182],</span><br><span class="line">      "log_dirs": ["any", "any"]</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>然后执行分配方案即可：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 执行分配方案</span></span><br><span class="line">➜ bin/kafka-reassign-partitions.sh --bootstrap-server localhost:9092 --reassignment-json-file expand-cluster-reassignment.json --execute</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出略</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看进度</span></span><br><span class="line">➜ bin/kafka-reassign-partitions.sh --bootstrap-server localhost:9092 --reassignment-json-file expand-cluster-reassignment.json --verify </span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出略</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 完成后查看<span class="built_in">test</span>-3和<span class="built_in">test</span>-4</span></span><br><span class="line">➜ bin/kafka-topics.sh --describe --topic test-3  --zookeeper localhost:2181/kafka_26Topic: test-3   PartitionCount: 4       ReplicationFactor: 2    Configs: </span><br><span class="line">        Topic: test-3   Partition: 0    Leader: 183     Replicas: 183,181       Isr: 183,181</span><br><span class="line">        Topic: test-3   Partition: 1    Leader: 183     Replicas: 181,183       Isr: 183,181</span><br><span class="line">        Topic: test-3   Partition: 2    Leader: 183     Replicas: 183,181       Isr: 183,181</span><br><span class="line">        Topic: test-3   Partition: 3    Leader: 183     Replicas: 181,183       Isr: 183,181</span><br><span class="line">➜ bin/kafka-topics.sh --describe --topic test-4  --zookeeper localhost:2181/kafka_26Topic: test-4   PartitionCount: 4       ReplicationFactor: 2    Configs: </span><br><span class="line">        Topic: test-4   Partition: 0    Leader: 183     Replicas: 182,183       Isr: 183,182</span><br><span class="line">        Topic: test-4   Partition: 1    Leader: 183     Replicas: 183,182       Isr: 183,182</span><br><span class="line">        Topic: test-4   Partition: 2    Leader: 183     Replicas: 182,183       Isr: 183,182</span><br><span class="line">        Topic: test-4   Partition: 3    Leader: 183     Replicas: 183,182       Isr: 183,182</span><br></pre></td></tr></table></figure><h2 id="kafka-manager页面操作"><a href="#kafka-manager页面操作" class="headerlink" title="kafka manager页面操作"></a>kafka manager页面操作</h2><p>页面操作不支持批量操作topic，需要逐个topic进行操作。</p><p>1，进入topic视图，点击 Generate Partition Assignments 生成分区分配。进入分区分配界面，</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/c34eeebc/1.png" alt></p><p>2，对该topic需要占用的节点进行勾选，再次点击 Generate Partition Assignments</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/c34eeebc/2.png" alt></p><p>3，分区完成 ， go to topic view</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/c34eeebc/3.png" alt></p><p>4,  重新分配。 <strong>Reassign Partitions</strong></p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/c34eeebc/4.png" alt></p><p>5，go to reassign partitions 转到重新分配分区</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/c34eeebc/5.png" alt></p><p>6，验证查看</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/c34eeebc/6.png" alt></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>不管扩容还是缩容，或者是故障后手动补齐分区，实质都是分区重分配，使用<code>kafka-reassign-partitions.sh</code>脚本即可。该脚本使用也非常简单：</p><ol><li>先提供一个JSON格式的需要重分配的topic列表，然后执行<code>--generate</code>生成迁移方案文件；</li><li>然后使用<code>--execute</code>执行新的分配方案；</li><li>最后使用<code>--verify</code>查看分配方案执行进度。</li></ol><p>如果对于分配方案文件格式很熟悉，可以跳过1.</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文讨论Kafka的扩缩容以及故障后如何“补齐”分区。实质上先扩容再缩容也是迁移的操作。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.github.io/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Kafka" scheme="https://wandouduoduo.github.io/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>lvs负载均衡实战</title>
    <link href="https://wandouduoduo.github.io/articles/17e1663a.html"/>
    <id>https://wandouduoduo.github.io/articles/17e1663a.html</id>
    <published>2021-04-19T06:23:22.000Z</published>
    <updated>2021-04-20T07:35:26.203Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>通过本文掌握什么是负载均衡及负载均衡的作用和意义；了解lvs负载均衡的三种模式；了解lvs-DR负载均衡部署方法；掌握nginx实现负载均衡的方法；掌握lvs+nginx负载均衡拓扑结构。</p> <a id="more"></a><h2 id="负载均衡方案"><a href="#负载均衡方案" class="headerlink" title="负载均衡方案"></a>负载均衡方案</h2><h3 id="什么是负载均衡"><a href="#什么是负载均衡" class="headerlink" title="什么是负载均衡"></a>什么是负载均衡</h3><p> 一台普通服务器的处理能力是有限的，假如能达到每秒几万个到几十万个请求，但却无法在一秒钟内处理上百万个甚至更多的请求。但若能将多台这样的服务器组成一个系统，并通过软件技术将所有请求平均分配给所有服务器，那么这个系统就完全拥有每秒钟处理几百万个甚至更多请求的能力。这就是负载均衡最初的基本设计思想。</p><p>负载均衡是由多台服务器以对称的方式组成一个服务器集合，每台服务器都具有等价的地位，都可以单独对外提供服务而无须其他服务器的辅助。通过某种负载分担技术，将外部发送来的请求按照某种策略分配到服务器集合的某一台服务器上，而接收到请求的服务器独立地回应客户的请求。负载均衡解决了大量并发访问服务问题，其目的就是用最少的投资获得接近于大型主机的性能。 </p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/1.png" alt="img"></p><h3 id="相关技术"><a href="#相关技术" class="headerlink" title="相关技术"></a>相关技术</h3><h4 id="基于DNS的负载均衡"><a href="#基于DNS的负载均衡" class="headerlink" title="基于DNS的负载均衡"></a>基于DNS的负载均衡</h4><p>DNS（Domain Name System，域名系统），因特网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。通过主机名，最终得到该主机名对应的IP地址的过程叫做域名解析（或主机名解析）。DNS协议运行在UDP协议之上，使用端口号53。</p><p>DNS负载均衡技术是最早的负载均衡解决方案，它是通过DNS服务中的随机名字解析来实现的，在DNS服务器中，可以为多个不同的地址配置同一个名字，而最终查询这个名字的客户机将在解析这个名字时得到其中的一个地址。因此，对于同一个名字，不同的客户机会得到不同的地址，它们也就访问不同地址上的Web服务器，从而达到负载均衡的目的。</p><p>如下图：</p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/2.png" alt="img"></p><p><strong>优点</strong></p><p>实现简单、实施容易、成本低、适用于大多数TCP/IP应用；</p><p><strong>缺点</strong></p><p>1、 负载分配不均匀，DNS服务器将Http请求平均地分配到后台的Web服务器上，而不考虑每个Web服务器当前的负载情况；如果后台的Web服务器的配置和处理能力不同，最慢的Web服务器将成为系统的瓶颈，处理能力强的服务器不能充分发挥作用；</p><p>2、可靠性低，如果后台的某台Web服务器出现故障，DNS服务器仍然会把DNS请求分配到这台故障服务器上，导致不能响应客户端。</p><p>3、变更生效时间长，如果更改NDS有可能造成相当一部分客户不能享受Web服务，并且由于DNS缓存的原因，所造成的后果要持续相当长一段时间(一般DNS的刷新周期约为24小时)。</p><h4 id="基于四层交换技术的负载均衡"><a href="#基于四层交换技术的负载均衡" class="headerlink" title="基于四层交换技术的负载均衡"></a>基于四层交换技术的负载均衡</h4><p>基于四层交换技术的负载均衡是通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器与请求客户端建立TCP连接，然后发送Client请求的数据。</p><p>如下图：</p><p>​        <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/3.png" alt="img"></p><p>client发送请求至4层负载均衡器，4层负载均衡器根据负载策略把client发送的报文目标地址(原来是负载均衡设备的IP地址)修改为后端服务器（可以是web服务器、邮件服务等）IP地址，这样client就可以直接跟后端服务器建立TCP连接并发送数据。</p><p>具有代表意义的产品：LVS（开源软件），F5（硬件）</p><p><strong>优点</strong></p><p>性能高、支持各种网络协议</p><p><strong>缺点</strong></p><p>对网络依赖较大，负载智能化方面没有7层负载好（比如不支持对url个性化负载），F5硬件性能很高但成本也高需要人民币几十万，对于小公司就望而却步了。</p><h4 id="基于七层交换技术的负载均衡"><a href="#基于七层交换技术的负载均衡" class="headerlink" title="基于七层交换技术的负载均衡"></a>基于七层交换技术的负载均衡</h4><p>基于七层交换技术的负载均衡也称内容交换，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的服务器。</p><p>如下图：</p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/4.png" alt="img"></p><p>七层负载均衡服务器起了一个代理服务器的作用，client要访问webserver要先与七层负载设备进行三次握手后建立TCP连接，把要访问的报文信息发送给七层负载均衡；然后七层负载均衡再根据设置的均衡规则选择特定的webserver，然后通过三次握手与此台webserver建立TCP连接，然后webserver把需要的数据发送给七层负载均衡设备，负载均衡设备再把数据发送给client。</p><p>具有代表意义的产品：nginx（软件）、apache（软件）</p><p><strong>优点</strong></p><p>对网络依赖少，负载智能方案多（比如可根据不同的url进行负载）</p><p><strong>缺点</strong></p><p>网络协议有限，nginx和apache支持http负载，性能没有4层负载高</p><h3 id="确定使用四层-七层负载结合方案"><a href="#确定使用四层-七层负载结合方案" class="headerlink" title="确定使用四层+七层负载结合方案"></a>确定使用四层+七层负载结合方案</h3><p>四层负载使用lvs软件或F5硬件实现。</p><p>七层负载使用nginx实现。</p><p>如下图是lvs+nginx的拓扑结构：</p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/5.png" alt="img"></p><h3 id="nginx集群背景"><a href="#nginx集群背景" class="headerlink" title="nginx集群背景"></a>nginx集群背景</h3><p>在keepalived+nginx的主备容灾高可用的架构中，nginx是作为外部访问系统的唯一入口，理论上一台nginx的最大并发量可以高达50000，但是当并发量更大的时候，keepalived+nginx的高可用机制是没办法满足需求的，因为keepalived+nginx的架构中确确实实是一台nginx在工作，只有当master宕机或异常时候，备份机才会上位。那么如何解决更大的高并发问题呢，也许会问能不能搭建nginx集群，直接对外提供访问？</p><p>很显然这是欠妥当的，因为当nginx作为外部的唯一访问入口，没办法直接以集群的形式对外提供服务，没有那么多的公网ip资源可用，既太浪费也不友好。但是在内网环境下，是可以用nginx集群（nginx横向扩展服务集合）的，当然总得有一个对外入口，所以需要在nginx集群之上，在加一层负载均衡器，作为系统的唯一入口。</p><h2 id="lvs实现四层负载DR模式"><a href="#lvs实现四层负载DR模式" class="headerlink" title="lvs实现四层负载DR模式"></a>lvs实现四层负载DR模式</h2><h3 id="什么是lvs"><a href="#什么是lvs" class="headerlink" title="什么是lvs"></a>什么是lvs</h3><p>LVS是Linux Virtual Server的简写，意即Linux虚拟服务器，是一个虚拟的服务器集群系统。本项目在1998年5月由章文嵩博士成立，是中国国内最早出现的自由软件项目之一。</p><h3 id="lvs实现负载的三种方式"><a href="#lvs实现负载的三种方式" class="headerlink" title="lvs实现负载的三种方式"></a>lvs实现负载的三种方式</h3><p>运行 lPVS软件的服务器，在整个负载均衡集群中承担一调度角色 软件的服务器，（即 向真实服务器分配从客户端过来的请求。LVS中的调度方法有三种 ：NAT（Network Address Translation网络地址转换）、TUN（tunnel 隧道）、DR（direct route 直接路由）</p><h3 id="LVS-DR-模式"><a href="#LVS-DR-模式" class="headerlink" title="LVS-DR 模式"></a>LVS-DR 模式</h3><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/6.png" alt="img"></p><p>请求由LVS接受，由真实提供服务的服务器(RealServer, RS)直接返回给用户，返回的时候不经过LVS。</p><p>DR模式下需要LVS服务器和RS绑定同一个VIP， 一个请求过来时，LVS只需要将网络帧的MAC地址修改为某一台RS的MAC，该包就会被转发到相应的RS处理，注意此时的源IP和目标IP都没变，RS收到LVS转发来的包，发现MAC是自己的，发现IP也是自己的，于是这个包被合法地接受，而当RS返回响应时，只要直接向源IP(即用户的IP)返回即可，不再经过LVS。</p><p>DR模式下，lvs接收请求输入，将请求转发给RS，由RS输出响应给用户，性能非常高。</p><p>它的不足之处是要求负载均衡器与RS在一个物理段上。</p><h3 id="LVS-NAT模式"><a href="#LVS-NAT模式" class="headerlink" title="LVS-NAT模式"></a>LVS-NAT模式</h3><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/7.png" alt="img"></p><p>NAT(Network Address Translation)是一种外网和内网地址映射的技术。NAT模式下，LVS需要作为RS的网关，当网络包到达LVS时，LVS做目标地址转换(DNAT)，将目标IP改为RS的IP。RS接收到包以后，处理完，返回响应时，源IP是RS IP，目标IP是客户端的IP，这时RS的包通过网关(LVS)中转，LVS会做源地址转换(SNAT)，将包的源地址改为VIP，对于客户端只知道是LVS直接返回给它的。</p><p>NAT模式请求和响应都需要经过lvs，性能没有DR模式好。</p><h3 id="LVS-TUN模式"><a href="#LVS-TUN模式" class="headerlink" title="LVS-TUN模式"></a>LVS-TUN模式</h3><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/31.png" alt="img"></p><p>TUN模式是通过ip隧道技术减轻lvs调度服务器的压力，许多Internet服务（例如WEB服务器）的请求包很短小，而应答包通常很大，负载均衡器只负责将请求包分发给物理服务器，而物理服务器将应答包直接发给用户。所以，负载均衡器能处理很巨大的请求量。相比NAT性能要高的多，比DR模式的优点是不限制负载均衡器与RS在一个物理段上。但是它的不足需要所有的服务器（lvs、RS）支持”IP Tunneling”(IP Encapsulation)协议。</p><h2 id="lvs-DR实战"><a href="#lvs-DR实战" class="headerlink" title="lvs-DR实战"></a>lvs-DR实战</h2><p>vip：192.168.101.100</p><p>lvs-director：192.168.101.8</p><p>nginx1：192.168.101.3</p><p>nginx2：192.168.101.4</p><h3 id="lvs调度服务器Director安装"><a href="#lvs调度服务器Director安装" class="headerlink" title="lvs调度服务器Director安装"></a>lvs调度服务器Director安装</h3><h4 id="安装lvs"><a href="#安装lvs" class="headerlink" title="安装lvs"></a>安装lvs</h4><p>在192.168.101.8上安装lvs</p><p>centos6.5自带lvs，检查linux内核是否集成lvs模块：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">modprobe -l | grep ipvs</span><br></pre></td></tr></table></figure><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/8.png" alt="img"> </p><h4 id="安装lvs的管理工具ipvsadm"><a href="#安装lvs的管理工具ipvsadm" class="headerlink" title="安装lvs的管理工具ipvsadm"></a>安装lvs的管理工具ipvsadm</h4><ul><li>安装依赖</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y gcc gcc-c++ makepcre pcre-devel kernel-devel openssl-devel libnl-devel popt*</span><br></pre></td></tr></table></figure><ul><li>安装ipvsadm</li></ul><p>将ipvsadm-1.26.tar.gz拷贝至/usr/local/下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span></span><br><span class="line">tar -zxvf ipvsadm-1.26.tar.gz</span><br><span class="line"><span class="built_in">cd</span> ipvsadm-1.26</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line">或者</span><br><span class="line">yum install ipvsadm -y</span><br></pre></td></tr></table></figure><p>校验是否安装成功：</p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/9.png" alt="img"></p><h4 id="真实服务器Real-Server安装"><a href="#真实服务器Real-Server安装" class="headerlink" title="真实服务器Real Server安装"></a>真实服务器Real Server安装</h4><p>在192.168.101.3和192.168.101.4上安装nginx。</p><p><strong>nginx配置文件</strong></p><p>创建nginx-lvs.conf，http内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line"></span><br><span class="line">    include       mime.types;</span><br><span class="line"></span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line"></span><br><span class="line">    sendfile        on;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line"></span><br><span class="line">        listen       80;</span><br><span class="line"></span><br><span class="line">        server_name  localhost;</span><br><span class="line"></span><br><span class="line">        location / &#123;</span><br><span class="line"></span><br><span class="line">            root   html;</span><br><span class="line"></span><br><span class="line">            index  index.html index.htm;</span><br><span class="line"></span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h3 id="Director-Server配置"><a href="#Director-Server配置" class="headerlink" title="Director Server配置"></a>Director Server配置</h3><h4 id="在eth0上绑定虚拟ip"><a href="#在eth0上绑定虚拟ip" class="headerlink" title="在eth0上绑定虚拟ip"></a>在eth0上绑定虚拟ip</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig eth0:0 192.168.101.100 broadcast 192.168.101.100 netmask 255.255.255.255 up</span><br></pre></td></tr></table></figure><p>此处在eth0设备上绑定了一个虚拟设备eth0:0，同时设置了一个虚拟IP是<em>192.168.101.100</em>，然后指定广播地址也为<em>192.168.101.100</em>，需要特别注意的是，虚拟ip地址的广播地址是它本身，子网掩码是255.255.255.255。</p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/10.png" alt="img"></p><h4 id="添加路由规则"><a href="#添加路由规则" class="headerlink" title="添加路由规则"></a>添加路由规则</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">route add -host 192.168.101.100 dev eth0:0</span><br></pre></td></tr></table></figure><h4 id="启用系统的包转发功能"><a href="#启用系统的包转发功能" class="headerlink" title="启用系统的包转发功能"></a>启用系统的包转发功能</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"1"</span> &gt;/proc/sys/net/ipv4/ip_forward</span><br></pre></td></tr></table></figure><p>参数值为1时启用ip转发，为0时禁止ip转发。</p><h4 id="清除原有转发规则"><a href="#清除原有转发规则" class="headerlink" title="清除原有转发规则"></a>清除原有转发规则</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipvsadm --clear</span><br></pre></td></tr></table></figure><h4 id="添加虚拟IP规则"><a href="#添加虚拟IP规则" class="headerlink" title="添加虚拟IP规则"></a>添加虚拟IP规则</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipvsadm -A -t 192.168.101.100:80 -s rr</span><br></pre></td></tr></table></figure><p> -s rr表示采用轮询策略。</p><p>:80表示负载转发的端口是80</p><h4 id="在虚拟IP中添加服务规则"><a href="#在虚拟IP中添加服务规则" class="headerlink" title="在虚拟IP中添加服务规则"></a>在虚拟IP中添加服务规则</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ipvsadm -a -t 192.168.101.100:80 -r 192.168.101.3:80 -g</span><br><span class="line">ipvsadm -a -t 192.168.101.100:80 -r 192.168.101.4:80 -g</span><br></pre></td></tr></table></figure><p>在新加虚拟IP记录中添加两条新的Real Server记录，-g表示指定LVS 的工作模式为直接路由模式。</p><p>lvs进行负载转发需要保证lvs负载的端口要和nginx服务的端口的一致，这里都为80。</p><h4 id="重启lvs"><a href="#重启lvs" class="headerlink" title="重启lvs"></a>重启lvs</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ipvsadm</span><br></pre></td></tr></table></figure><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/11.png" alt="img"></p><h3 id="Real-Server配置"><a href="#Real-Server配置" class="headerlink" title="Real Server配置"></a>Real Server配置</h3><p>在lvs的DR和TUn模式下，用户的访问请求到达真实服务器后，是直接返回给用户的，而不再经过前端的Director Server，因此，就需要在每个Real server节点上增加虚拟的VIP地址，这样数据才能直接返回给用户。</p><h4 id="在回环设备上绑定了一个虚拟IP地址"><a href="#在回环设备上绑定了一个虚拟IP地址" class="headerlink" title="在回环设备上绑定了一个虚拟IP地址"></a>在回环设备上绑定了一个虚拟IP地址</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ifconfig lo:0 192.168.101.100 broadcast 192.168.101.100 netmask 255.255.255.255 up</span><br><span class="line">/sbin/route add -host 192.168.101.100 dev lo:0</span><br></pre></td></tr></table></figure><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/12.png" alt="img"></p><h4 id="关闭arp解析"><a href="#关闭arp解析" class="headerlink" title="关闭arp解析"></a>关闭arp解析</h4><p>arp_announce ：定义不同级别：当ARP请求通过某个端口进来是否利用这个接口来回应。</p><p>​         0 -利用本地的任何地址，不管配置在哪个接口上去响应ARP请求；</p><p>​         1 - 避免使用另外一个接口上的mac地址去响应ARP请求；</p><p>​         2 - 尽可能使用能够匹配到ARP请求的最佳地址。</p><p>arp_ignore：当ARP请求发过来后发现自己正是请求的地址是否响应；</p><p>​            0 - 利用本地的任何地址，不管配置在哪个接口上去响应ARP请求；</p><p>​            1 - 哪个接口上接受ARP请求，就从哪个端口上回应。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"1"</span> &gt;/proc/sys/net/ipv4/conf/lo/arp_ignore</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"2"</span> &gt;/proc/sys/net/ipv4/conf/lo/arp_announce </span><br><span class="line"><span class="built_in">echo</span> <span class="string">"1"</span> &gt;/proc/sys/net/ipv4/conf/all/arp_ignore</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"2"</span> &gt;/proc/sys/net/ipv4/conf/all/arp_announce </span><br><span class="line"></span><br><span class="line">sysctl -p <span class="comment">#使用修改生效</span></span><br></pre></td></tr></table></figure><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/13.png" alt="img"></p><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><h4 id="预期目标"><a href="#预期目标" class="headerlink" title="预期目标"></a>预期目标</h4><p>由于lvs设置为rr轮询策略，当访问虚IP <a href="http://192.168.101.100，每次刷新请求通过lvs负载到不同的服务器。" rel="noopener" target="_blank">http://192.168.101.100，每次刷新请求通过lvs负载到不同的服务器。</a></p><h4 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h4><p>1、测试时需要在nginx的http中设置keepalive_timeout  0; 取消使用http持久连接模式，保证每次客户端发起请求都需要向服务端建立连接，这样做是为了每次刷新页面都要经过lvs负载转发。</p><p>2、lvs进行负载转发需要保证lvs负载的端口要和nginx服务的端口的一致，这里都为80。</p><p>keepalive_timeout说明：</p><p>在nginx中keepalive_timeout的默认值是75秒，默认使用http持久连接模式，可使客户端到服务器端的连接持续有效，当出现对服务器的后继请求时，可避免建立或重新建立连接。生产环境建议keepalive_timeout不要设置为0。</p><h4 id="测试过程"><a href="#测试过程" class="headerlink" title="测试过程"></a>测试过程</h4><p>修改192.168.101.3和192.168.101.4下html目录中index.html的内容使之个性化。</p><p>第一次请求：<a href="http://192.168.101.100" rel="noopener" target="_blank">http://192.168.101.100</a></p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/14.png" alt="img"></p><p>刷新，相当于第二次请求：</p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/15.png" alt="img"></p><p>依次交替测试，发现每次请求被负载到不同的nginx上。</p><p>任意停止掉一个nginx，请求<a href="http://192.168.101.100继续可以浏览，由于lvs采用轮询策略如果其中一个nginx请求不可到达则去请求另外的nginx。" rel="noopener" target="_blank">http://192.168.101.100继续可以浏览，由于lvs采用轮询策略如果其中一个nginx请求不可到达则去请求另外的nginx。</a></p><h3 id="脚本封装"><a href="#脚本封装" class="headerlink" title="脚本封装"></a>脚本封装</h3><p>为了方便配置启动lvs将上边Director Server和Real Server的配置过程封装在shell脚本中。</p><h4 id="Director-Server配置-1"><a href="#Director-Server配置-1" class="headerlink" title="Director Server配置"></a>Director Server配置</h4><p>在/etc/init.d下创建lvsdr，内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line"><span class="comment"># 定义虚拟ip</span></span><br><span class="line">VIP=192.168.101.100 <span class="comment">#虚拟 ip根据需求修改</span></span><br><span class="line"><span class="comment"># 定义realserver,并已空格分开，根据需求修改</span></span><br><span class="line">RIPS=<span class="string">"192.168.101.3 192.168.101.4"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义提供服务的端口</span></span><br><span class="line">SERVICE=80</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用init.d脚本的标准库</span></span><br><span class="line">. /etc/rc.d/init.d/<span class="built_in">functions</span></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line">        start)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Start LVS of DR Mode"</span></span><br><span class="line">        <span class="comment"># 开启ip转发</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"1"</span> &gt; /proc/sys/net/ipv4/ip_forward</span><br><span class="line">        <span class="comment"># 绑定虚拟ip</span></span><br><span class="line">        ifconfig eth0:0 <span class="variable">$VIP</span> broadcast <span class="variable">$VIP</span> netmask 255.255.255.255 up</span><br><span class="line">        route add -host <span class="variable">$VIP</span> dev eth0:0</span><br><span class="line">        <span class="comment"># 清除lvs规则</span></span><br><span class="line">        ipvsadm -C</span><br><span class="line">        <span class="comment"># 添加一条虚拟服务器记录</span></span><br><span class="line">    <span class="comment"># -p指定一定的时间内将相同的客户端分配到同一台后端服务器</span></span><br><span class="line">    <span class="comment"># 用于解决session的问题,测试时或有别的解决方案时建议去掉</span></span><br><span class="line">        ipvsadm -A -t <span class="variable">$VIP</span>:<span class="variable">$SERVICE</span> -s rr</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 添加真实服务器记录</span></span><br><span class="line">        <span class="keyword">for</span> RIP <span class="keyword">in</span> <span class="variable">$RIPS</span></span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="variable">$RIP</span>:<span class="variable">$SERVICE</span>;</span><br><span class="line">                ipvsadm -a -t <span class="variable">$VIP</span>:<span class="variable">$SERVICE</span> -r <span class="variable">$RIP</span>:<span class="variable">$SERVICE</span> -g</span><br><span class="line">        <span class="keyword">done</span></span><br><span class="line">        <span class="comment"># 设置tcp tcpfin  udp的超时连接值</span></span><br><span class="line">        ipvsadm --<span class="built_in">set</span> 30 120 300</span><br><span class="line">        ipvsadm</span><br><span class="line">        ;;</span><br><span class="line"></span><br><span class="line">        stop)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Stop LVS DR"</span></span><br><span class="line">        ifconfig eth0:0 down</span><br><span class="line">        ipvsadm -C</span><br><span class="line">        ;;</span><br><span class="line">        *)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Usage:<span class="variable">$0</span> &#123;start ¦ stop&#125;"</span></span><br><span class="line">        <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#修改脚本权限：</span></span><br><span class="line">chmod +x /etc/init.d/lvsdr</span><br><span class="line"><span class="comment">#启动Director server：</span></span><br><span class="line">service lvsdr start</span><br><span class="line"><span class="comment">#停止Director server：</span></span><br><span class="line">service lvsdr stop</span><br></pre></td></tr></table></figure><h4 id="Real-Server配置-1"><a href="#Real-Server配置-1" class="headerlink" title="Real Server配置"></a>Real Server配置</h4><p>在/etc/init.d下创建lvsdr，内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/sh</span></span><br><span class="line">VIP=192.168.101.100 <span class="comment">#虚拟ip，根据需求修改</span></span><br><span class="line">. /etc/rc.d/init.d/<span class="built_in">functions</span></span><br><span class="line"><span class="keyword">case</span> <span class="variable">$1</span> <span class="keyword">in</span></span><br><span class="line">        start)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"lo:0 port starting"</span></span><br><span class="line">        <span class="comment"># 为了相应lvs调度器转发过来的包,需在本地lo接口上绑定vip</span></span><br><span class="line">        ifconfig lo:0 <span class="variable">$VIP</span> broadcast <span class="variable">$VIP</span> netmask 255.255.255.255 up</span><br><span class="line">        <span class="comment"># 限制arp请求</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"1"</span> &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"2"</span> &gt; /proc/sys/net/ipv4/conf/lo/arp_announce</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"1"</span> &gt; /proc/sys/net/ipv4/conf/all/arp_ignore</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"2"</span> &gt; /proc/sys/net/ipv4/conf/all/arp_announce</span><br><span class="line">        ;;</span><br><span class="line">        stop)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"lo:0 port closing"</span></span><br><span class="line">        ifconfig lo:0 down</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"0"</span> &gt; /proc/sys/net/ipv4/conf/lo/arp_ignore</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"0"</span> &gt; /proc/sys/net/ipv4/conf/lo/arp_announce</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"0"</span> &gt; /proc/sys/net/ipv4/conf/all/arp_ignore</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"0"</span> &gt; /proc/sys/net/ipv4/conf/all/arp_announce</span><br><span class="line">        ;;</span><br><span class="line">        *)</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"Usage: <span class="variable">$0</span> &#123;start ¦ stop&#125;"</span></span><br><span class="line">        <span class="built_in">exit</span> 1</span><br><span class="line"><span class="keyword">esac</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#修改脚本权限：</span></span><br><span class="line">chmod +x /etc/init.d/lvsdr</span><br><span class="line"><span class="comment">#启动real server：</span></span><br><span class="line">service lvsdr start</span><br><span class="line"><span class="comment">#停止real server：</span></span><br><span class="line">service lvsdr stop</span><br></pre></td></tr></table></figure><h2 id="lvs四层-nginx七层负载均衡"><a href="#lvs四层-nginx七层负载均衡" class="headerlink" title="lvs四层+nginx七层负载均衡"></a>lvs四层+nginx七层负载均衡</h2><h3 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h3><p>lvs采用DR模式基本上没有性能瓶颈，用户请求输入至lvs经过负载转发到后台服务上，通过后台服务输出响应给用户。nginx的负载性能远没有lvs好，lvs四层+nginx七层负载的好处是最前端是lvs接收请求进行负载转发，由多个nginx共同完成七层负载，这样nginx的负载性能就可以线性扩展。</p><h3 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h3><p>vip：192.168.101.100</p><p>lvs-director：192.168.101.8</p><p>nginx1：192.168.101.3                              安装nginx</p><p>nginx2：192.168.101.4                              安装nginx</p><p>tomcat1：192.168.101.5                           安装tomcat</p><p>tomcat2：192.168.101.6                           安装tomcat</p><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><h4 id="Director-Server配置-2"><a href="#Director-Server配置-2" class="headerlink" title="Director Server配置"></a>Director Server配置</h4><p>vip：192.168.101.100</p><p>lvs-director：192.168.101.8</p><p>参考lvs四层负载DR模式进行配置</p><h4 id="Real-Server配置-2"><a href="#Real-Server配置-2" class="headerlink" title="Real Server配置"></a>Real Server配置</h4><p>nginx1：192.168.101.3                              安装nginx</p><p>nginx2：192.168.101.4                              安装nginx</p><p>参考lvs四层负载DR模式进行配置，需要修改nginx的配置文件使每个nginx对两个tomcat进行负载，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">    include       mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line">    sendfile        on;</span><br><span class="line"></span><br><span class="line">   upstream tomcat_server_pool&#123;</span><br><span class="line">        server 192.168.101.5:8080 weight=10;</span><br><span class="line">        server 192.168.101.6:8080 weight=10;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    server &#123;</span><br><span class="line">        listen 80;</span><br><span class="line">        server_name localhost;</span><br><span class="line">        location / &#123;</span><br><span class="line">                 proxy_pass http://tomcat_server_pool;</span><br><span class="line">                 index index.jsp index.html index.htm;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="测试-1"><a href="#测试-1" class="headerlink" title="测试"></a>测试</h3><p>请求<a href="http://192.168.101.100，lvs负载到不同的nginx上，如果停止任意一台nginx或停止任意一台tomcat不影响访问。" rel="noopener" target="_blank">http://192.168.101.100，lvs负载到不同的nginx上，如果停止任意一台nginx或停止任意一台tomcat不影响访问。</a></p><h2 id="lvs高可用-了解"><a href="#lvs高可用-了解" class="headerlink" title="lvs高可用(了解)"></a>lvs高可用(了解)</h2><h3 id="什么是高可用"><a href="#什么是高可用" class="headerlink" title="什么是高可用"></a>什么是高可用</h3><p>lvs作为负载均衡器，所有请求都先到达lvs，可见lvs处于非常重要的位置，如果lvs服务器宕机后端web服务将无法提供服务，影响严重。</p><p>为了屏蔽负载均衡服务器的宕机，需要建立一个备份机。主服务器和备份机上都运行高可用（High Availability）监控程序，通过传送诸如“I am alive”这样的信息来监控对方的运行状况。当备份机不能在一定的时间内收到这样的信息时，它就接管主服务器的服务IP并继续提供负载均衡服务；当备份管理器又从主管理器收到“I am alive”这样的信息时，它就释放服务IP地址，这样的主服务器就开始再次提供负载均衡服务。</p><h3 id="keepalived-lvs实现主备"><a href="#keepalived-lvs实现主备" class="headerlink" title="keepalived+lvs实现主备"></a>keepalived+lvs实现主备</h3><h4 id="什么是keepalived"><a href="#什么是keepalived" class="headerlink" title="什么是keepalived"></a>什么是keepalived</h4><p>keepalived是集群管理中保证集群高可用的一个服务软件，用来防止单点故障。</p><p>Keepalived的作用是检测web服务器的状态，如果有一台web服务器死机，或工作出现故障，Keepalived将检测到，并将有故障的web服务器从系统中剔除，当web服务器工作正常后Keepalived自动将web服务器加入到服务器群中，这些工作全部自动完成，不需要人工干涉，需要人工做的只是修复故障的web服务器。</p><h4 id="keepalived工作原理"><a href="#keepalived工作原理" class="headerlink" title="keepalived工作原理"></a>keepalived工作原理</h4><p>keepalived是以VRRP协议为实现基础的，VRRP全称Virtual Router Redundancy Protocol，即虚拟路由冗余协议。</p><p>虚拟路由冗余协议，可以认为是实现路由器高可用的协议，即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个master和多个backup，master上面有一个对外提供服务的vip（该路由器所在局域网内其他机器的默认路由为该vip），master会发组播，当backup收不到VRRP包时就认为master宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master。这样的话就可以保证路由器的高可用了。</p><p>keepalived主要有三个模块，分别是core、check和VRRP。core模块为keepalived的核心，负责主进程的启动、维护以及全局配置文件的加载和解析。check负责健康检查，包括常见的各种检查方式。VRRP模块是来实现VRRP协议的。</p><h4 id="keepalived-lvs实现主备过程"><a href="#keepalived-lvs实现主备过程" class="headerlink" title="keepalived+lvs实现主备过程"></a>keepalived+lvs实现主备过程</h4><p><strong>初始状态</strong></p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/16.png" alt="img"></p><p><strong>主机宕机</strong></p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/17.png" alt="img"></p><p><strong>主机恢复</strong></p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/18.png" alt="img"> </p><h3 id="准备环境-1"><a href="#准备环境-1" class="headerlink" title="准备环境"></a>准备环境</h3><p>vip：192.168.101.100</p><p>lvs-director：192.168.101.8   主lvs</p><p>lvs-director：192.168.101.9   备lvs</p><p>nginx1：192.168.101.3                              安装nginx</p><p>nginx2：192.168.101.4                              安装nginx</p><p>tomcat1：192.168.101.5                           安装tomcat</p><p>tomcat2：192.168.101.6                           安装tomcat</p><h3 id="安装keepalived"><a href="#安装keepalived" class="headerlink" title="安装keepalived"></a>安装keepalived</h3><p>分别在主备lvs上安装keepalived，参考“<a href="https://www.cnblogs.com/arjenlee/p/9256068.html" rel="noopener" target="_blank">安装手册</a>”进行安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install keepalived -y</span><br></pre></td></tr></table></figure><h3 id="配置keepalived"><a href="#配置keepalived" class="headerlink" title="配置keepalived"></a>配置keepalived</h3><h4 id="主lvs"><a href="#主lvs" class="headerlink" title="主lvs"></a>主lvs</h4><p>修改主lvs下/etc/keepalived/keepalived.conf文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">   notification_email &#123;</span><br><span class="line">    #xxxx@itcast.com                                   # 发生故障时发送的邮箱</span><br><span class="line">   &#125;</span><br><span class="line">   #notification_email_from xxxx@itcast.com             # 使用哪个邮箱发送</span><br><span class="line">   #smtp_server xxx.com                                  # 发件服务器</span><br><span class="line">   smtp_connect_timeout 30</span><br><span class="line">   router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER             # 标示为主lvs</span><br><span class="line">    interface eth0           # HA检测端口</span><br><span class="line">    virtual_router_id 51     # 主备的virtual_router_id 必须相同</span><br><span class="line">    priority 100             # 优先级,备lvs要比主lvs稍小</span><br><span class="line">    advert_int 1             # VRRP Multicast 广播周期秒数</span><br><span class="line">    authentication &#123;         # 定义认证</span><br><span class="line">        auth_type PASS       # 认证方式为口令认证</span><br><span class="line">        auth_pass 1111       # 定义口令</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;      # 定义vip</span><br><span class="line">        192.168.101.100        # 多个vip可换行添加</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_server 192.168.101.100 80 &#123;</span><br><span class="line">    delay_loop 6       # 每隔6秒查看realserver状态</span><br><span class="line">    lb_algo wlc        # 调度算法为加权最小连接数</span><br><span class="line">    lb_kind DR         # lvs工作模式为DR(直接路由)模式</span><br><span class="line">    nat_mask 255.255.255.0</span><br><span class="line">    persistence_timeout 50  # 同一IP 的连接50秒内被分配到同一台realserver(测试时建议改为0)</span><br><span class="line">    protocol TCP            # 用TCP监测realserver的状态</span><br><span class="line"></span><br><span class="line">    real_server 192.168.101.3 80 &#123;       # 定义realserver</span><br><span class="line">        weight 3                       # 定义权重</span><br><span class="line">        TCP_CHECK &#123;  # 注意TCP_CHECK和&#123;之间的空格,如果没有的话只会添加第一个realserver</span><br><span class="line">            connect_timeout 3          # 三秒无响应超时</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">            connect_port 80</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    real_server 192.168.101.4 80 &#123;</span><br><span class="line">        weight 3</span><br><span class="line">        TCP_CHECK &#123;</span><br><span class="line">            connect_timeout 3</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">            connect_port 80</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="备lvs"><a href="#备lvs" class="headerlink" title="备lvs"></a>备lvs</h4><p>修改备lvs下/etc/keepalived/keepalived.conf文件</p><p><strong>配置备</strong>lvs<strong>时需要注意：需要修改state**</strong>为BACKUP , priority<strong><strong>比MASTER</strong></strong>低，virtual_router_id<strong><strong>和master</strong></strong>的值一致**</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">   notification_email &#123;</span><br><span class="line">    #xxxx@itcast.com                                   # 发生故障时发送的邮箱</span><br><span class="line">   &#125;</span><br><span class="line">   #notification_email_from xxxx@itcast.com             # 使用哪个邮箱发送</span><br><span class="line">   #smtp_server xxx.com                                  # 发件服务器</span><br><span class="line">   smtp_connect_timeout 30</span><br><span class="line">   router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP             # 标示为备lvs</span><br><span class="line">    interface eth0           # HA检测端口</span><br><span class="line">    virtual_router_id 51     # 主备的virtual_router_id 必须相同</span><br><span class="line">    priority 99              # 优先级,备lvs要比主lvs稍小</span><br><span class="line">    advert_int 1             # VRRP Multicast 广播周期秒数</span><br><span class="line">    authentication &#123;         # 定义认证</span><br><span class="line">        auth_type PASS       # 认证方式为口令认证</span><br><span class="line">        auth_pass 1111       # 定义口令</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;      # 定义vip</span><br><span class="line">        192.168.101.100        # 多个vip可换行添加</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_server 192.168.101.100 80 &#123;</span><br><span class="line">    delay_loop 6       # 每隔6秒查看realserver状态</span><br><span class="line">    lb_algo wlc        # 调度算法为加权最小连接数</span><br><span class="line">    lb_kind DR         # lvs工作模式为DR(直接路由)模式</span><br><span class="line">    nat_mask 255.255.255.0</span><br><span class="line">    persistence_timeout 50  # 同一IP 的连接50秒内被分配到同一台realserver(测试时建议改为0)</span><br><span class="line">    protocol TCP            # 用TCP监测realserver的状态</span><br><span class="line"></span><br><span class="line">    real_server 192.168.101.3 80 &#123;       # 定义realserver</span><br><span class="line">        weight 3                       # 定义权重</span><br><span class="line">        TCP_CHECK &#123;  # 注意TCP_CHECK和&#123;之间的空格,如果没有的话只会添加第一个realserver</span><br><span class="line">            connect_timeout 3          # 三秒无响应超时</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">            connect_port 80</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    real_server 192.168.101.4 80 &#123;</span><br><span class="line">        weight 3</span><br><span class="line">        TCP_CHECK &#123;</span><br><span class="line">            connect_timeout 3</span><br><span class="line">            nb_get_retry 3</span><br><span class="line">            delay_before_retry 3</span><br><span class="line">            connect_port 80</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="测试-2"><a href="#测试-2" class="headerlink" title="测试"></a>测试</h3><h4 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h4><ul><li>director Server启动：</li></ul><p><strong>注意：使用keepalived就不用手动配置启动lvs，在主、备lvs上启动keepalived即可。</strong></p><p>主备lvs（192.168.101.8、192.168.101.9）都启动keepalived。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service keepalived start</span><br></pre></td></tr></table></figure><ul><li>real server启动：</li></ul><p>192.168.101.3、192.168.101.4启动nginx和lvs的realserver配置</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/nginx/sbin</span><br><span class="line">./nginx -c /usr/<span class="built_in">local</span>/nginx/conf/nginx-lvs.conf</span><br></pre></td></tr></table></figure><p> 启动lvs的realserver配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service lvsdr start</span><br></pre></td></tr></table></figure><p> <strong>注意：real server的lvs配置需要使用lvsdr脚本。</strong></p><ul><li>tomcat 启动</li></ul><p>略</p><h4 id="初始状态"><a href="#初始状态" class="headerlink" title="初始状态"></a>初始状态</h4><p>查看主lvs的eth0设置：</p><p>vip绑定在主lvs的eth0上。</p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/19.png" alt="img"></p><p>查询lvs状态：</p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/20.png" alt="img"></p><p>查看备lvs的eth0设置：</p><p>vip没有绑定在备lvs的eth0上。</p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/21.png" alt="img"></p><p>访问<a href="http://192.168.101.100，可以正常负载。" rel="noopener" target="_blank">http://192.168.101.100，可以正常负载。</a></p><h4 id="主机宕机"><a href="#主机宕机" class="headerlink" title="主机宕机"></a>主机宕机</h4><p>将主lvs的keepalived停止或将主lvs关机(相当于模拟宕机)，查看主lvs的eth0：</p><p>eth0没有绑定vip</p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/22.png" alt="img"> </p><p>查看备lvs的eth0：</p><p>vip已经漂移到备lvs。</p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/23.png" alt="img"></p><p>访问<a href="http://192.168.101.100，可以正常负载。" rel="noopener" target="_blank">http://192.168.101.100，可以正常负载。</a></p><h4 id="主机恢复"><a href="#主机恢复" class="headerlink" title="主机恢复"></a>主机恢复</h4><p>将主lvs的keepalived启动。</p><p>查看主lvs的eth0：</p><p>查看备lvs的eth0：</p><p>vip漂移到主lvs。</p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/24.png" alt="img"></p><p>查看备lvs的eth0：</p><p>eth0没有绑定vip</p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/25.png" alt="img"></p><p>访问<a href="http://192.168.101.100，可以正常负载。" rel="noopener" target="_blank">http://192.168.101.100，可以正常负载。</a></p><h3 id="keepalived-lvs实现双主"><a href="#keepalived-lvs实现双主" class="headerlink" title="keepalived+lvs实现双主"></a>keepalived+lvs实现双主</h3><p>上边主备方案是当前只有一台lvs工作，这造成资源浪费，可以采用双主结构，让两台lvs当前都进行工作，采用dns轮询方式，当用户访问域名通过dns轮询每台lvs，双主结构需要两个vip，这两个vip要绑定域名。</p><p> 同样，在每台lvs上安装keepalived软件，当keepalived检测到其中一个lvs宕机则将宕机的vip漂移到活动lvs上，当lvs恢复则vip又重新漂移回来。</p><h4 id="初始状态-1"><a href="#初始状态-1" class="headerlink" title="初始状态"></a>初始状态</h4><p>每台lvs绑定一个vip，共两个vip，DNS设置域名对应这两个vip，通过DNS轮询每次解析到不同的vip上即解析到不同的lvs上。</p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/26.png" alt="img"></p><h4 id="其中一个主机宕机"><a href="#其中一个主机宕机" class="headerlink" title="其中一个主机宕机"></a>其中一个主机宕机</h4><p>其中一个主机宕机，每台lvs上安装的keepalived程序会检测到对方宕机，将宕机一方的vip漂移至活动的lvs服务器上，这样DNS轮询全部到一台lvs继续对外提供服务。</p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/27.png" alt="img"></p><h4 id="主机恢复-1"><a href="#主机恢复-1" class="headerlink" title="主机恢复"></a>主机恢复</h4><p>当主机恢复又回到初始状态，每个vip绑定在不同的lvs上。</p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/28.png" alt="img"></p><h2 id="lvs扩展的思考"><a href="#lvs扩展的思考" class="headerlink" title="lvs扩展的思考"></a>lvs扩展的思考</h2><p>前端使用1到2台lvs作为负载基本可以满足中小型网站的并发要求，当lvs的负载成为瓶颈此时就需要对lvs进行优化、扩展。</p><ul><li><strong>方案1：LVS-ospf集群</strong></li></ul><p>​         OSPF(Open Shortest Path First开放式最短路径优先）是一个内部网关协议(Interior Gateway Protocol，简称IGP），用于在单一自治系统（autonomous system,AS）内决策路由。</p><p>LVS（DR）通过ospfd，做lvs集群，实现一个VIP，多台LVS同时工作提供服务，这种方案需要依赖三层交换机设备实现。</p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/29.png" alt="img"> </p><p>用户请求（VIP：42.xx.xx.100）到达三层交换机之后，通过对原地址、端口和目的地址、端口的hash，将链接分配到集群中的某一台LVS上，LVS通过内网（10.101.10.x）向后端转发请求，后端再将数据返回给用户。</p><p>LVS-ospf集群模式的最大优势就在于：</p><p>1.LVS调度机自由伸缩，横向线性扩展（最大8台，受限于三层设备允许的等价路由数目maximum load-balancing）；</p><p>2.LVS机器同时工作，不存在备机，提高利用率；</p><p>3.做到了真正的高可用，某台LVS机器宕机后，不会影响服务</p><ul><li><strong>方案2：DNS轮询</strong></li></ul><p>上面讲的是一组双主结构，可以采用多组双主结构达到横向扩展lvs的目的，此方案需要每台lvs都绑定一个vip（公网ip），DNS设置域名轮询多个vip，如下图：</p><p> <img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/17e1663a/30.png" alt="img"></p><ul><li><strong>方案3：使用硬件负载均衡设置</strong> </li></ul><p>​         如果资金允许可以购买硬件设置来完成负载均衡，性能不错的有F5、Array等都可以满足超高并发的要求。</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;通过本文掌握什么是负载均衡及负载均衡的作用和意义；了解lvs负载均衡的三种模式；了解lvs-DR负载均衡部署方法；掌握nginx实现负载均衡的方法；掌握lvs+nginx负载均衡拓扑结构。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.github.io/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Lvs" scheme="https://wandouduoduo.github.io/tags/Lvs/"/>
    
  </entry>
  
  <entry>
    <title>k8s网络flannel和calico网络模式对比</title>
    <link href="https://wandouduoduo.github.io/articles/8b98d1d.html"/>
    <id>https://wandouduoduo.github.io/articles/8b98d1d.html</id>
    <published>2021-04-12T03:40:08.000Z</published>
    <updated>2021-04-20T07:31:14.800Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>Kubernetes跨主机容器之间的通信组件，目前主流的是flannel和calico，本文对两个组件进行简单介绍和对比。</p><a id="more"></a><h2 id="Flannel-架构"><a href="#Flannel-架构" class="headerlink" title="Flannel 架构"></a>Flannel 架构</h2><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a><strong>原理</strong></h3><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8b98d1d/2.png" alt="img"></p><p>由CoreOS开发的项目Flannel，可能是最直接和最受欢迎的CNI插件。它是容器编排系统中最成熟的网络结构示例之一，旨在实现更好的容器间和主机间网络。随着CNI概念的兴起，Flannel CNI插件算是早期的入门。</p><p>与其他方案相比，Flannel相对容易安装和配置。它被打包为单个二进制文件FlannelD，许多常见的Kubernetes集群部署工具和许多Kubernetes发行版都可以默认安装Flannel。Flannel可以使用Kubernetes集群的现有etcd集群来使用API存储其状态信息，因此不需要专用的数据存储。</p><p>Flannel配置第3层IPv4 Overlay网络。它会创建一个大型内部网络，跨越集群中每个节点。在此Overlay网络中，每个节点都有一个子网，用于在内部分配IP地址。在配置Pod时，每个节点上的Docker桥接口都会为每个新容器分配一个地址。同一主机中的Pod可以使用Docker桥接进行通信，而不同主机上的pod会使用flanneld将其流量封装在UDP数据包中，以便路由到适当的目标。</p><p>Flannel有几种不同类型的后端可用于封装和路由。默认和推荐的方法是使用VXLAN，因为VXLAN性能更良好并且需要的手动干预更少。</p><h2 id="Calico-架构"><a href="#Calico-架构" class="headerlink" title="Calico 架构"></a><strong>Calico 架构</strong></h2><h3 id="组件"><a href="#组件" class="headerlink" title="组件"></a>组件</h3><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8b98d1d/1.jpg" alt></p><p>calico包括如下重要组件：Felix，etcd，BGP Client，BGP Route Reflector。下面分别说明一下这些组件。</p><p>Felix：主要负责路由配置以及ACLS规则的配置以及下发，它存在在每个node节点上。</p><p>etcd：分布式键值存储，主要负责网络元数据一致性，确保Calico网络状态的准确性，可以与kubernetes共用；</p><p>BGPClient(BIRD), 主要负责把 Felix写入 kernel的路由信息分发到当前 Calico网络，确保 workload间的通信的有效性；</p><p>BGPRoute Reflector(BIRD), 大规模部署时使用，摒弃所有节点互联的mesh模式，通过一个或者多个 BGPRoute Reflector 来完成集中式的路由分发；</p><h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8b98d1d/3.png" alt="img"></p><h3 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h3><p>如下图所示，描述了从源容器经过源宿主机，经过数据中心的路由，然后到达目的宿主机最后分配到目的容器的过程。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8b98d1d/4.png" alt="img"></p><h3 id="跨主机通信"><a href="#跨主机通信" class="headerlink" title="跨主机通信"></a>跨主机通信</h3><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8b98d1d/6.jpg" alt></p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8b98d1d/7.jpg" alt></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>从上述的原理可以看出，flannel在进行路由转发的基础上进行了封包解包的操作，这样浪费了CPU的计算资源。下图是从网上找到的各个开源网络组件的性能对比。可以看出无论是带宽还是网络延迟，calico和主机的性能是差不多的。<br><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8b98d1d/5.png" alt="img">  </p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Kubernetes跨主机容器之间的通信组件，目前主流的是flannel和calico，本文对两个组件进行简单介绍和对比。&lt;/p&gt;
    
    </summary>
    
      <category term="容器编排" scheme="https://wandouduoduo.github.io/categories/%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92/"/>
    
      <category term="K8s" scheme="https://wandouduoduo.github.io/categories/%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92/K8s/"/>
    
    
      <category term="K8s" scheme="https://wandouduoduo.github.io/tags/K8s/"/>
    
  </entry>
  
  <entry>
    <title>Docker快速安装jumperserver</title>
    <link href="https://wandouduoduo.github.io/articles/4c63da33.html"/>
    <id>https://wandouduoduo.github.io/articles/4c63da33.html</id>
    <published>2021-04-09T03:57:50.000Z</published>
    <updated>2021-04-09T05:51:39.892Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>Jumpserver堡垒机的作用和好处这里就不再赘述，本文教你快速用docker容器安装jumperserver，让你快速体验。本教程是在单机上操作，处于以后扩展的需求，强烈建议在多台服务器上搭建。</p><a id="more"></a><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt</span><br><span class="line">yum -y install wget</span><br><span class="line">wget https://github.com/jumpserver/installer/releases/download/v2.8.2/jumpserver-installer-v2.8.2.tar.gz</span><br><span class="line">tar -xf jumpserver-installer-v2.8.2.tar.gz</span><br><span class="line"><span class="built_in">cd</span> jumpserver-installer-v2.8.2</span><br></pre></td></tr></table></figure><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim config-example.txt</span><br><span class="line">所有配置都在此文件中，按照实际情况填写信息即可。</span><br></pre></td></tr></table></figure><h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line">./jmsctl.sh install</span><br><span class="line"></span><br><span class="line">       ██╗██╗   ██╗███╗   ███╗██████╗ ███████╗███████╗██████╗ ██╗   ██╗███████╗██████╗</span><br><span class="line">       ██║██║   ██║████╗ ████║██╔══██╗██╔════╝██╔════╝██╔══██╗██║   ██║██╔════╝██╔══██╗</span><br><span class="line">       ██║██║   ██║██╔████╔██║██████╔╝███████╗█████╗  ██████╔╝██║   ██║█████╗  ██████╔╝</span><br><span class="line">  ██   ██║██║   ██║██║╚██╔╝██║██╔═══╝ ╚════██║██╔══╝  ██╔══██╗╚██╗ ██╔╝██╔══╝  ██╔══██╗</span><br><span class="line">  ╚█████╔╝╚██████╔╝██║ ╚═╝ ██║██║     ███████║███████╗██║  ██║ ╚████╔╝ ███████╗██║  ██║</span><br><span class="line">   ╚════╝  ╚═════╝ ╚═╝    ╚═╝╚═╝     ╚══════╝╚══════╝╚═╝  ╚═╝  ╚═══╝  ╚══════╝╚═╝  ╚═╝</span><br><span class="line"></span><br><span class="line">                                                             Version:  v2.8.2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; 安装配置 Docker</span><br><span class="line">1. 安装 Docker</span><br><span class="line">开始下载 Docker 程序 ...</span><br><span class="line">完成</span><br><span class="line">开始下载 Docker Compose 程序 ...</span><br><span class="line">完成</span><br><span class="line"></span><br><span class="line">2. 配置 Docker</span><br><span class="line">是否需要自定义 Docker 数据目录, 默认将使用 /var/lib/docker 目录? (y/n)  (默认为 n): n</span><br><span class="line">完成</span><br><span class="line"></span><br><span class="line">3. 启动 Docker</span><br><span class="line">Docker 版本发生改变 或 Docker 配置文件发生变化，是否要重启? (y/n)  (默认为 y): y</span><br><span class="line">完成</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; 加载 Docker 镜像</span><br><span class="line">Docker: Pulling from jumpserver/core:v2.8.2         [ OK ]</span><br><span class="line">Docker: Pulling from jumpserver/koko:v2.8.2         [ OK ]</span><br><span class="line">Docker: Pulling from jumpserver/luna:v2.8.2         [ OK ]</span><br><span class="line">Docker: Pulling from jumpserver/nginx:alpine2       [ OK ]</span><br><span class="line">Docker: Pulling from jumpserver/redis:6-alpine      [ OK ]</span><br><span class="line">Docker: Pulling from jumpserver/lina:v2.8.2         [ OK ]</span><br><span class="line">Docker: Pulling from jumpserver/mysql:5             [ OK ]</span><br><span class="line">Docker: Pulling from jumpserver/guacamole:v2.8.2    [ OK ]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; 安装配置 JumpServer</span><br><span class="line">1. 检查配置文件</span><br><span class="line">配置文件位置: /opt/jumpserver/config</span><br><span class="line">/opt/jumpserver/config/config.txt                 [ √ ]</span><br><span class="line">/opt/jumpserver/config/nginx/lb_http_server.conf  [ √ ]</span><br><span class="line">/opt/jumpserver/config/nginx/lb_ssh_server.conf   [ √ ]</span><br><span class="line">/opt/jumpserver/config/core/config.yml   [ √ ]</span><br><span class="line">/opt/jumpserver/config/koko/config.yml   [ √ ]</span><br><span class="line">/opt/jumpserver/config/mysql/my.cnf      [ √ ]</span><br><span class="line">/opt/jumpserver/config/redis/redis.conf  [ √ ]</span><br><span class="line">完成</span><br><span class="line"></span><br><span class="line">2. 配置 Nginx</span><br><span class="line">配置文件位置:: /opt/jumpserver/config/nginx/cert</span><br><span class="line">/opt/jumpserver/config/nginx/cert/server.crt  [ √ ]</span><br><span class="line">/opt/jumpserver/config/nginx/cert/server.key  [ √ ]</span><br><span class="line">完成</span><br><span class="line"></span><br><span class="line">3. 备份配置文件</span><br><span class="line">备份至 /opt/jumpserver/config/backup/config.txt.2021-03-19_08-01-51</span><br><span class="line">完成</span><br><span class="line"></span><br><span class="line">4. 配置网络</span><br><span class="line">是否需要支持 IPv6? (y/n)  (默认为 n): n</span><br><span class="line">完成</span><br><span class="line"></span><br><span class="line">5. 配置加密密钥</span><br><span class="line">SECRETE_KEY:     ICAgIGluZXQ2IDI0MDk6OGE0ZDpjMjg6ZjkwMTo6ZDRjLzEyO</span><br><span class="line">BOOTSTRAP_TOKEN: ICAgIGluZXQ2IDI0</span><br><span class="line">完成</span><br><span class="line"></span><br><span class="line">6. 配置持久化目录</span><br><span class="line">是否需要自定义持久化存储, 默认将使用目录 /opt/jumpserver? (y/n)  (默认为 n): n</span><br><span class="line">完成</span><br><span class="line"></span><br><span class="line">7. 配置 MySQL</span><br><span class="line">是否使用外部mysql (y/n)  (默认为n): n</span><br><span class="line"></span><br><span class="line">8. 配置 Redis</span><br><span class="line">是否使用外部redis  (y/n)  (默认为n): n</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; 安装完成了</span><br><span class="line">1. 可以使用如下命令启动, 然后访问</span><br><span class="line">./jmsctl.sh start</span><br><span class="line"></span><br><span class="line">2. 其它一些管理命令</span><br><span class="line">./jmsctl.sh stop</span><br><span class="line">./jmsctl.sh restart</span><br><span class="line">./jmsctl.sh backup</span><br><span class="line">./jmsctl.sh upgrade</span><br><span class="line">更多还有一些命令, 你可以 ./jmsctl.sh --<span class="built_in">help</span> 来了解</span><br><span class="line"></span><br><span class="line">3. Web 访问</span><br><span class="line">http://192.168.100.248:8080</span><br><span class="line">https://192.168.100.248:8443</span><br><span class="line">默认用户: admin  默认密码: admin</span><br><span class="line"></span><br><span class="line">4. SSH/SFTP 访问</span><br><span class="line">ssh admin@192.168.100.248 -p2222</span><br><span class="line">sftp -P2222 admin@192.168.100.248</span><br><span class="line"></span><br><span class="line">5. 更多信息</span><br><span class="line">我们的官网: https://www.jumpserver.org/</span><br><span class="line">我们的文档: https://docs.jumpserver.org/</span><br></pre></td></tr></table></figure></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Jumpserver堡垒机的作用和好处这里就不再赘述，本文教你快速用docker容器安装jumperserver，让你快速体验。本教程是在单机上操作，处于以后扩展的需求，强烈建议在多台服务器上搭建。&lt;/p&gt;
    
    </summary>
    
      <category term="容器技术" scheme="https://wandouduoduo.github.io/categories/%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Docker" scheme="https://wandouduoduo.github.io/tags/Docker/"/>
    
      <category term="Jumperserver" scheme="https://wandouduoduo.github.io/tags/Jumperserver/"/>
    
  </entry>
  
  <entry>
    <title>微服务之注册中心选型</title>
    <link href="https://wandouduoduo.github.io/articles/997cf319.html"/>
    <id>https://wandouduoduo.github.io/articles/997cf319.html</id>
    <published>2021-03-29T06:04:50.000Z</published>
    <updated>2021-03-29T10:42:31.059Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>服务注册中心本质上是为了解耦服务提供者和服务消费者。对于任何一个微服务，原则上都应存在或者支持多个提供者，这是由微服务的分布式属性决定的。更进一步，为了支持弹性扩缩容特性，一个微服务的提供者的数量和分布往往是动态变化的，也是无法预先确定的。因此，原本在单体应用阶段常用的静态LB机制就不再适用了，需要引入额外的组件来管理微服务提供者的注册与发现，而这个组件就是服务注册中心。</p><a id="more"></a><h2 id="CAP"><a href="#CAP" class="headerlink" title="CAP"></a>CAP</h2><h3 id="CAP理论"><a href="#CAP理论" class="headerlink" title="CAP理论"></a>CAP理论</h3><p>CAP理论是分布式架构中重要理论</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">一致性(Consistency) (所有节点在同一时间具有相同的数据)</span><br><span class="line">可用性(Availability) (保证每个请求不管成功或者失败都有响应)</span><br><span class="line">分隔容忍(Partition tolerance) (系统中任意信息的丢失或失败不会影响系统的继续运作)</span><br></pre></td></tr></table></figure><h3 id="CAP理解"><a href="#CAP理解" class="headerlink" title="CAP理解"></a>CAP理解</h3><p>P的理解是在整个系统中某个部分挂掉或者宕机了，并不影响整个系统的运作或者使用，是网络层面的，通常认为网络是顺畅流通的。</p><p>A可用性是系统的某个节点挂了，但并不影响系统的接受请求或者发出响应。</p><p>C一致性是客户端请求系统中的任意节点，获取的返回结果都是一致的。系统中各个节点会实时同步信息来保证</p><h3 id="CAP侧重"><a href="#CAP侧重" class="headerlink" title="CAP侧重"></a>CAP侧重</h3><p>但CAP 3项不可能都取，只能取其中2两项，造成侧重点不同。</p><p>如果C是第一需求的话，那么会影响A的性能，因为要数据同步，不然请求结果会有差异，但是数据同步会消耗时间，期间可用性就会降低。</p><p>如果A是第一需求，那么只要有一个服务在，就能正常接受请求，但是对与返回结果一致就不能保证，原因是，在分布式部署的时候，数据一致的过程不可能想切线路那么快。</p><p>再如果，同事满足一致性和可用性，那么分区容错就很难保证了，只能是单点，也是分布式的基本核心。好了，明白这些理论，就可以在相应的场景选取服务注册与发现了</p><h2 id="服务注册中心解决方案"><a href="#服务注册中心解决方案" class="headerlink" title="服务注册中心解决方案"></a>服务注册中心解决方案</h2><p>设计或者选型一个服务注册中心，首先要考虑的就是服务注册与发现机制。纵观当下各种主流的服务注册中心解决方案，大致可归为三类：</p><ul><li>应用内：直接集成到应用中，依赖于应用自身完成服务的注册与发现。最典型的是Netflix提供的Eureka</li><li>应用外：把应用当成黑盒，通过应用外的某种机制将服务注册到注册中心，最小化对应用的侵入性，比如Airbnb的SmartStack，HashiCorp的Consul</li><li>DNS：将服务注册为DNS的SRV记录，严格来说，是一种特殊的应用外注册方式。SkyDNS是其中的代表</li></ul><p><em>注1：对于第一类注册方式，除了Eureka这种一站式解决方案，还可以基于ZooKeeper或者Etcd自行实现一套服务注册机制，这在大公司比较常见，但对于小公司而言显然性价比太低。</em></p><p><em>注2：由于DNS固有的缓存缺陷，本文不对第三类注册方式作深入探讨。</em></p><p>除了基本的服务注册与发现机制，从开发和运维角度，至少还要考虑如下五个方面：</p><ul><li>测活：服务注册之后，如何对服务进行测活以保证服务的可用性？</li><li>负载均衡：当存在多个服务提供者时，如何均衡各个提供者的负载？</li><li>集成：在服务提供端或者调用端，如何集成注册中心？</li><li>运行时依赖：引入注册中心之后，对应用的运行时环境有何影响？</li><li>可用性：如何保证注册中心本身的可用性，特别是消除单点故障？</li></ul><h2 id="主流注册中心产品"><a href="#主流注册中心产品" class="headerlink" title="主流注册中心产品"></a>主流注册中心产品</h2><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/997cf319/1.png" alt></p><p><em>Consul是支持自动注销服务实例， 请见文档： <a href="https://www.consul.io/api-docs/agent/service，在check的" rel="noopener" target="_blank">https://www.consul.io/api-docs/agent/service，在check的</a> DeregisterCriticalServiceAfter 这个参数</em><br><em>新版本的Dubbo也扩展了对 Consul 的支持。 参考: <a href="https://github.com/apache/dubbo/tree/master/dubbo-registry" rel="noopener" target="_blank">https://github.com/apache/dubbo/tree/master/dubbo-registry</a></em></p><h3 id="Zookeeper-gt-CP"><a href="#Zookeeper-gt-CP" class="headerlink" title="Zookeeper -&gt; CP"></a>Zookeeper -&gt; CP</h3><p>与 Eureka 有所不同，Zookeeper 在设计时就紧遵CP原则，即任何时候对 Zookeeper 的访问请求能得到一致的数据结果，同时系统对网络分割具备容错性，但是 Zookeeper 不能保证每次服务请求都是可达的。</p><p>从 Zookeeper 的实际应用情况来看，在使用 Zookeeper 获取服务列表时，如果此时的 Zookeeper 集群中的 Leader 宕机了，该集群就要进行 Leader 的选举，又或者 Zookeeper 集群中半数以上服务器节点不可用（例如有三个节点，如果节点一检测到节点三挂了 ，节点二也检测到节点三挂了，那这个节点才算是真的挂了），那么将无法处理该请求。所以说，Zookeeper不能保证服务可用性。</p><p>当然，在大多数分布式环境中，尤其是涉及到数据存储的场景，数据一致性应该是首先被保证的，这也是 Zookeeper 设计紧遵CP原则的另一个原因。</p><p>但是对于服务发现来说，情况就不太一样了，针对同一个服务，即使注册中心的不同节点保存的服务提供者信息不尽相同，也并不会造成灾难性的后果。</p><p>因为对于服务消费者来说，能消费才是最重要的，消费者虽然拿到可能不正确的服务实例信息后尝试消费一下，也要胜过因为无法获取实例信息而不去消费，导致系统异常要好（淘宝的双十一，京东的618就是紧遵AP的最好参照）。</p><p>当master节点因为网络故障与其他节点失去联系时，剩余节点会重新进行leader选举。问题在于，选举leader的时间太长，30~120s，而且选举期间整个zk集群都是不可用的，这就导致在选举期间注册服务瘫痪。</p><p>在云部署环境下， 因为网络问题使得zk集群失去master节点是大概率事件，虽然服务能最终恢复，但是漫长的选举事件导致注册长期不可用是不能容忍的。</p><h3 id="Eureka-gt-AP"><a href="#Eureka-gt-AP" class="headerlink" title="Eureka  -&gt; AP"></a>Eureka  -&gt; AP</h3><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/997cf319/2.png" alt></p><p>Spring Cloud Netflix 在设计 Eureka 时就紧遵AP原则（尽管现在2.0发布了，但是由于其闭源的原因 ，但是目前 Ereka 1.x 任然是比较活跃的）。</p><p>Eureka Server 也可以运行多个实例来构建集群，解决单点问题，但不同于 ZooKeeper 的选举 leader 的过程，Eureka Server 采用的是Peer to Peer 对等通信。这是一种去中心化的架构，无 master/slave 之分，每一个 Peer 都是对等的。在这种架构风格中，节点通过彼此互相注册来提高可用性，每个节点需要添加一个或多个有效的 serviceUrl 指向其他节点。每个节点都可被视为其他节点的副本。</p><p>在集群环境中如果某台 Eureka Server 宕机，Eureka Client 的请求会自动切换到新的 Eureka Server 节点上，当宕机的服务器重新恢复后，Eureka 会再次将其纳入到服务器集群管理之中。当节点开始接受客户端请求时，所有的操作都会在节点间进行复制（replicate To Peer）操作，将请求复制到该 Eureka Server 当前所知的其它所有节点中。</p><p>当一个新的 Eureka Server 节点启动后，会首先尝试从邻近节点获取所有注册列表信息，并完成初始化。Eureka Server 通过 getEurekaServiceUrls() 方法获取所有的节点，并且会通过心跳契约的方式定期更新。</p><p>默认情况下，如果 Eureka Server 在一定时间内没有接收到某个服务实例的心跳（默认周期为30秒），Eureka Server 将会注销该实例（默认为90秒， eureka.instance.lease-expiration-duration-in-seconds 进行自定义配置）。</p><p>当 Eureka Server 节点在短时间内丢失过多的心跳时，那么这个节点就会进入自我保护模式。</p><p>Eureka的集群中，只要有一台Eureka还在，就能保证注册服务可用（保证可用性），只不过查到的信息可能不是最新的（不保证强一致性）。除此之外，Eureka还有一种自我保护机制，如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障，此时会出现以下几种情况：</p><ul><li>Eureka不再从注册表中移除因为长时间没有收到心跳而过期的服务；</li><li>Eureka仍然能够接受新服务注册和查询请求，但是不会被同步到其它节点上（即保证当前节点依然可用）</li><li>当网络稳定时，当前实例新注册的信息会被同步到其它节点中；</li></ul><p>因此，Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像zookeeper那样使得整个注册服务瘫痪。</p><h3 id="Consul"><a href="#Consul" class="headerlink" title="Consul"></a>Consul</h3><p>Consul 是 HashiCorp 公司推出的开源工具，用于实现分布式系统的服务发现与配置。Consul 使用 Go 语言编写，因此具有天然可移植性（支持Linux、windows和Mac OS X）。</p><p>Consul 内置了服务注册与发现框架、分布一致性协议实现、健康检查、Key/Value 存储、多数据中心方案，不再需要依赖其他工具（比如 ZooKeeper 等），使用起来也较为简单。</p><p>Consul 遵循CAP原理中的CP原则，保证了强一致性和分区容错性，且使用的是Raft算法，比zookeeper使用的Paxos算法更加简单。虽然保证了强一致性，但是可用性就相应下降了，例如服务注册的时间会稍长一些，因为 Consul 的 raft 协议要求必须过半数的节点都写入成功才认为注册成功 ；在leader挂掉了之后，重新选举出leader之前会导致Consul 服务不可用。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/997cf319/3.png" alt></p><p>Consul本质上属于应用外的注册方式，但可以通过SDK简化注册流程。而服务发现恰好相反，默认依赖于SDK，但可以通过Consul Template（下文会提到）去除SDK依赖。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/997cf319/4.png" alt></p><p><strong>Consul Template</strong></p><p>Consul，默认服务调用者需要依赖Consul SDK来发现服务，这就无法保证对应用的零侵入性。</p><p>所幸通过Consul Template，可以定时从Consul集群获取最新的服务提供者列表并刷新LB配置（比如nginx的upstream），这样对于服务调用者而言，只需要配置一个统一的服务调用地址即可。</p><p>Consul强一致性(C)带来的是：</p><p>服务注册相比Eureka会稍慢一些。因为Consul的raft协议要求必须过半数的节点都写入成功才认为注册成功<br>Leader挂掉时，重新选举期间整个consul不可用。保证了强一致性但牺牲了可用性。</p><p>Eureka保证高可用(A)和最终一致性：</p><p>服务注册相对要快，因为不需要等注册信息replicate到其他节点，也不保证注册信息是否replicate成功<br>当数据出现不一致时，虽然A, B上的注册信息不完全相同，但每个Eureka节点依然能够正常对外提供服务，这会出现查询服务信息时如果请求A查不到，但请求B就能查到。如此保证了可用性但牺牲了一致性。<br>其他方面，eureka就是个servlet程序，跑在servlet容器中; Consul则是go编写而成。</p><h3 id="Nacos"><a href="#Nacos" class="headerlink" title="Nacos"></a>Nacos</h3><p>Nacos是阿里开源的，Nacos 支持基于 DNS 和基于 RPC 的服务发现。在Spring Cloud中使用Nacos，只需要先下载 Nacos 并启动 Nacos server，Nacos只需要简单的配置就可以完成服务的注册发现。</p><p>Nacos除了服务的注册发现之外，还支持动态配置服务。动态配置服务可以让您以中心化、外部化和动态化的方式管理所有环境的应用配置和服务配置。动态配置消除了配置变更时重新部署应用和服务的需要，让配置管理变得更加高效和敏捷。配置中心化管理让实现无状态服务变得更简单，让服务按需弹性扩展变得更容易。</p><p>一句话概括就是Nacos = Spring Cloud注册中心 + Spring Cloud配置中心。</p><p>参考链接：</p><p><a href="https://yq.aliyun.com/articles/698930" rel="noopener" target="_blank">https://yq.aliyun.com/articles/698930</a></p><p><a href="https://nacos.io" rel="noopener" target="_blank">https://nacos.io</a></p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;服务注册中心本质上是为了解耦服务提供者和服务消费者。对于任何一个微服务，原则上都应存在或者支持多个提供者，这是由微服务的分布式属性决定的。更进一步，为了支持弹性扩缩容特性，一个微服务的提供者的数量和分布往往是动态变化的，也是无法预先确定的。因此，原本在单体应用阶段常用的静态LB机制就不再适用了，需要引入额外的组件来管理微服务提供者的注册与发现，而这个组件就是服务注册中心。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>手把手搭建k8s集群和kubesphere</title>
    <link href="https://wandouduoduo.github.io/articles/b645bc81.html"/>
    <id>https://wandouduoduo.github.io/articles/b645bc81.html</id>
    <published>2021-03-17T08:45:52.000Z</published>
    <updated>2021-04-02T11:18:06.871Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>本文将从零开始在干净的机器上安装 <code>Docker、Kubernetes (使用 kubeadm)、Calico、NFS StorageClass等</code>，通过手把手的教程演示如何搭建一个 <code>Kubernetes集群</code>，并在 K8s集群之上安装开源的<code>KubeSphere</code> 容器平台可视化运营集群环境。</p><a id="more"></a><h2 id="环境和版本"><a href="#环境和版本" class="headerlink" title="环境和版本"></a>环境和版本</h2><p>所有机器处于同一内网网段，并且可以互相通信。</p><table><thead><tr><th align="center">机器IP</th><th align="center">工作内容</th></tr></thead><tbody><tr><td align="center">10.220.170.240</td><td align="center">NFS</td></tr><tr><td align="center">10.209.208.238</td><td align="center">master</td></tr><tr><td align="center">10.145.197.182</td><td align="center">nodes0</td></tr><tr><td align="center">10.145.197.176</td><td align="center">nodes1</td></tr><tr><td align="center">10.145.197.120</td><td align="center">nodes2</td></tr><tr><td align="center">10.209.33.24</td><td align="center">nodes3</td></tr></tbody></table><p>Docker版本： v19.03.4</p><p>k8s集群(kubeadm、kubelet 和 kubectl等)版本：v1.17.3</p><p>kubesphere版本：v3.0</p><h2 id="准备环境"><a href="#准备环境" class="headerlink" title="准备环境"></a>准备环境</h2><p>在所有节点上执行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 为了方便本操作关闭了防火墙，也建议你这样操作</span></span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭 SeLinux</span></span><br><span class="line">setenforce 0</span><br><span class="line">sed -i <span class="string">"s/SELINUX=enforcing/SELINUX=disabled/g"</span> /etc/selinux/config</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭 swap</span></span><br><span class="line">swapoff -a</span><br><span class="line">yes | cp /etc/fstab /etc/fstab_bak</span><br><span class="line">cat /etc/fstab_bak |grep -v swap &gt; /etc/fstab</span><br></pre></td></tr></table></figure><p>更换CentOS YUM源为阿里云yum源</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装wget</span></span><br><span class="line">yum install wget -y</span><br><span class="line"><span class="comment"># 备份</span></span><br><span class="line">mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup</span><br><span class="line"><span class="comment"># 获取阿里云yum源</span></span><br><span class="line">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo</span><br><span class="line"><span class="comment"># 获取阿里云epel源</span></span><br><span class="line">wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo</span><br><span class="line"><span class="comment"># 清理缓存并创建新的缓存</span></span><br><span class="line">yum clean all &amp;&amp; yum makecache</span><br><span class="line"><span class="comment"># 系统更新</span></span><br><span class="line">yum update -y</span><br></pre></td></tr></table></figure><p>时间同步并确认</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">timedatectl</span><br><span class="line">timedatectl <span class="built_in">set</span>-ntp <span class="literal">true</span></span><br></pre></td></tr></table></figure><h2 id="安装-Docker"><a href="#安装-Docker" class="headerlink" title="安装 Docker"></a>安装 Docker</h2><h3 id="安装-Docker-1"><a href="#安装-Docker-1" class="headerlink" title="安装 Docker"></a>安装 Docker</h3><p>每台机器上也都要安装Docker</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装 Docker CE</span></span><br><span class="line"><span class="comment"># 设置仓库</span></span><br><span class="line"><span class="comment"># 安装所需包</span></span><br><span class="line">yum install -y yum-utils \</span><br><span class="line">    device-mapper-persistent-data \</span><br><span class="line">    lvm2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 新增 Docker 仓库,速度慢的可以换阿里云的源。</span></span><br><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line"><span class="comment"># 阿里云源地址</span></span><br><span class="line"><span class="comment"># http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装 Docker CE.</span></span><br><span class="line">yum install -y containerd.io-1.2.10 \</span><br><span class="line">    docker-ce-19.03.4 \</span><br><span class="line">    docker-ce-cli-19.03.4</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动 Docker 并添加开机启动</span></span><br><span class="line">systemctl start docker</span><br><span class="line">systemctl <span class="built_in">enable</span> docker</span><br></pre></td></tr></table></figure><h3 id="修改Cgroup-Driver"><a href="#修改Cgroup-Driver" class="headerlink" title="修改Cgroup Driver"></a>修改Cgroup Driver</h3><p>需要将Docker的Cgroup Driver 修改为 <strong>systemd</strong>，不然在为Kubernetes 集群添加节点时会报如下错误：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 执行 kubeadm join 的 WARNING 信息</span></span><br><span class="line">[WARNING IsDockerSystemdCheck]: detected <span class="string">"cgroupfs"</span> as the Docker cgroup driver. The recommended driver is <span class="string">"systemd"</span>. Please follow the guide at https://kubernetes.io/docs/setup/cri/</span><br></pre></td></tr></table></figure><p>目前 Docker 的 Cgroup Driver 看起来应该是这样的：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker info|grep <span class="string">"Cgroup Driver"</span></span><br><span class="line">  Cgroup Driver: cgroupfs</span><br></pre></td></tr></table></figure><p>需要将这个值修改为 <strong>systemd</strong> 。同时将registry替换成国内的一些仓库地址，以免直接在官方仓库拉取镜像会很慢，操作如下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Setup daemon.</span></span><br><span class="line">cat &gt; /etc/docker/daemon.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"exec-opts"</span>: [<span class="string">"native.cgroupdriver=systemd"</span>],</span><br><span class="line">    <span class="string">"log-driver"</span>: <span class="string">"json-file"</span>,</span><br><span class="line">    <span class="string">"log-opts"</span>: &#123;</span><br><span class="line">    <span class="string">"max-size"</span>: <span class="string">"100m"</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">"storage-driver"</span>: <span class="string">"overlay2"</span>,</span><br><span class="line">    <span class="string">"registry-mirrors"</span>:[</span><br><span class="line">        <span class="string">"https://kfwkfulq.mirror.aliyuncs.com"</span>,</span><br><span class="line">        <span class="string">"https://2lqq34jg.mirror.aliyuncs.com"</span>,</span><br><span class="line">        <span class="string">"https://pee6w651.mirror.aliyuncs.com"</span>,</span><br><span class="line">        <span class="string">"http://hub-mirror.c.163.com"</span>,</span><br><span class="line">        <span class="string">"https://docker.mirrors.ustc.edu.cn"</span>,</span><br><span class="line">        <span class="string">"https://registry.docker-cn.com"</span></span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">mkdir -p /etc/systemd/system/docker.service.d</span><br><span class="line"></span><br><span class="line"><span class="comment"># Restart docker.</span></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><h2 id="安装-kubeadm、kubelet-和-kubectl"><a href="#安装-kubeadm、kubelet-和-kubectl" class="headerlink" title="安装 kubeadm、kubelet 和 kubectl"></a>安装 kubeadm、kubelet 和 kubectl</h2><h3 id="安装准备"><a href="#安装准备" class="headerlink" title="安装准备"></a>安装准备</h3><p>需要在每台机器上安装以下的软件包：</p><ul><li>kubeadm：用来初始化集群的指令。</li><li>kubelet：在集群中的每个节点上用来启动 pod 和容器等。</li><li>kubectl：用来与集群通信的命令行工具（Worker 节点可以不装，但是我装了，不影响什么）。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置K8S的yum源</span></span><br><span class="line"><span class="comment"># 这部分用是阿里云的源，如果可以访问Google，则建议用官方的源</span></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">repo_gpgcheck=0</span><br><span class="line">gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg       http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment"># 官方源配置如下</span></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=1</span><br><span class="line">repo_gpgcheck=1</span><br><span class="line">gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="开始安装"><a href="#开始安装" class="headerlink" title="开始安装"></a>开始安装</h3><p>安装指定版本 kubelet、 kubeadm 、kubectl， 这里选择当前较新的稳定版 Kubernetes 1.17.3，如果选择的版本不一样，在执行集群初始化的时候，注意 –kubernetes-version 的值。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 增加配置</span></span><br><span class="line">cat &lt;&lt;EOF &gt; /etc/sysctl.d/k8s.conf</span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line"><span class="comment"># 加载</span></span><br><span class="line">sysctl --system</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装</span></span><br><span class="line">yum install -y kubelet-1.17.3 kubeadm-1.17.3 kubectl-1.17.3 --disableexcludes=kubernetes</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动并设置 kubelet 开机启动</span></span><br><span class="line">systemctl start kubelet</span><br><span class="line">systemctl <span class="built_in">enable</span> --now kubelet</span><br></pre></td></tr></table></figure><h2 id="使用-Kubeadm创建集群"><a href="#使用-Kubeadm创建集群" class="headerlink" title="使用 Kubeadm创建集群"></a>使用 Kubeadm创建集群</h2><h3 id="初始化Master节点"><a href="#初始化Master节点" class="headerlink" title="初始化Master节点"></a>初始化Master节点</h3><p>在 Master上执行初始化，执行初始化使用 kubeadm init 命令。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置hosts</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"127.0.0.1 <span class="variable">$(hostname)</span>"</span> &gt;&gt; /etc/hosts</span><br><span class="line"><span class="built_in">export</span> MASTER_IP=10.209.208.238</span><br><span class="line"><span class="built_in">export</span> APISERVER_NAME=kuber4s.api</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$&#123;MASTER_IP&#125;</span> <span class="variable">$&#123;APISERVER_NAME&#125;</span>"</span> &gt;&gt; /etc/hosts</span><br></pre></td></tr></table></figure><p>下面有不带注释的初始化命令，建议先查看带注释的每个参数对应的意义，确保与你的当前配置的环境是一致的，然后再执行初始化操作，避免踩雷。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化 Control-plane/Master 节点</span></span><br><span class="line">kubeadm init \</span><br><span class="line">    --apiserver-advertise-address 0.0.0.0 \</span><br><span class="line">    <span class="comment"># API 服务器所公布的其正在监听的 IP 地址,指定“0.0.0.0”以使用默认网络接口的地址</span></span><br><span class="line">    <span class="comment"># 切记只可以是内网IP，不能是外网IP，如果有多网卡，可以使用此选项指定某个网卡</span></span><br><span class="line">    --apiserver-bind-port 6443 \</span><br><span class="line">    <span class="comment"># API 服务器绑定的端口,默认 6443</span></span><br><span class="line">    --cert-dir /etc/kubernetes/pki \</span><br><span class="line">    <span class="comment"># 保存和存储证书的路径，默认值："/etc/kubernetes/pki"</span></span><br><span class="line">    --control-plane-endpoint kuber4s.api \</span><br><span class="line">    <span class="comment"># 为控制平面指定一个稳定的 IP 地址或 DNS 名称,</span></span><br><span class="line">    <span class="comment"># 这里指定的 kuber4s.api 已经在 /etc/hosts 配置解析为本机IP</span></span><br><span class="line">    --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers \</span><br><span class="line">    <span class="comment"># 选择用于拉取Control-plane的镜像的容器仓库，默认值："k8s.gcr.io"</span></span><br><span class="line">    <span class="comment"># 因 Google被墙，这里选择国内仓库</span></span><br><span class="line">    --kubernetes-version 1.17.3 \</span><br><span class="line">    <span class="comment"># 为Control-plane选择一个特定的 Kubernetes 版本， 默认值："stable-1"</span></span><br><span class="line">    --node-name master01 \</span><br><span class="line">    <span class="comment">#  指定节点的名称,不指定的话为主机hostname，默认可以不指定</span></span><br><span class="line">    --pod-network-cidr 10.10.0.0/16 \</span><br><span class="line">    <span class="comment"># 指定pod的IP地址范围</span></span><br><span class="line">    --service-cidr 10.20.0.0/16 \</span><br><span class="line">    <span class="comment"># 指定Service的VIP地址范围</span></span><br><span class="line">    --service-dns-domain cluster.local \</span><br><span class="line">    <span class="comment"># 为Service另外指定域名，默认"cluster.local"</span></span><br><span class="line">    --upload-certs</span><br><span class="line">    <span class="comment"># 将 Control-plane 证书上传到 kubeadm-certs Secret</span></span><br></pre></td></tr></table></figure><p>不带注释的内容如下，如果初始化超时，可以修改DNS为8.8.8.8后重启网络服务再次尝试。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init \</span><br><span class="line"> --apiserver-advertise-address 0.0.0.0 \</span><br><span class="line"> --apiserver-bind-port 6443 \</span><br><span class="line"> --cert-dir /etc/kubernetes/pki \</span><br><span class="line"> --control-plane-endpoint kuber4s.api \</span><br><span class="line"> --image-repository registry.cn-hangzhou.aliyuncs.com/google_containers \</span><br><span class="line"> --kubernetes-version 1.17.3 \</span><br><span class="line"> --pod-network-cidr 10.10.0.0/16 \</span><br><span class="line"> --service-cidr 10.20.0.0/16 \</span><br><span class="line"> --service-dns-domain cluster.local \</span><br><span class="line"> --upload-certs</span><br></pre></td></tr></table></figure><p>接下来这个过程有点漫长（初始化会下载镜像、创建配置文件、启动容器等操作），泡杯茶，耐心等待。你也可以执行 tailf /var/log/messages 来实时查看系统日志，观察 Master 的初始化进展，期间碰到一些报错不要紧张，可能只是暂时的错误，等待最终反馈的结果即可。</p><p>如果初始化最终成功执行，你将看到如下信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run <span class="string">"kubectl apply -f [podnetwork].yaml"</span> with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of the control-plane node running the following <span class="built_in">command</span> on each as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join kuber4s.api:6443 --token 0j287q.jw9zfjxud8w85tis \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:5e8bcad5ec97c1025e8044f4b8fd0a4514ecda4bac2b3944f7f39ccae9e4921f \</span><br><span class="line">    --control-plane --certificate-key 528b0b9f2861f8f02dfd4a59fc54ad21e42a7dea4dc5552ac24d9c650c5d4d80</span><br><span class="line"></span><br><span class="line">Please note that the certificate-key gives access to cluster sensitive data, keep it secret!</span><br><span class="line">As a safeguard, uploaded-certs will be deleted <span class="keyword">in</span> two hours; If necessary, you can use</span><br><span class="line"><span class="string">"kubeadm init phase upload-certs --upload-certs"</span> to reload certs afterward.</span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join kuber4s.api:6443 --token 0j287q.jw9zfjxud8w85tis \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:5e8bcad5ec97c1025e8044f4b8fd0a4514ecda4bac2b3944f7f39ccae9e4921f</span><br></pre></td></tr></table></figure><p>为普通用户添加 kubectl 运行权限，命令内容在初始化成功后的输出内容中可以看到。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p <span class="variable">$HOME</span>/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf <span class="variable">$HOME</span>/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) <span class="variable">$HOME</span>/.kube/config</span><br></pre></td></tr></table></figure><p>建议root用户也进行以上操作，作者使用的是root用户执行的初始化操作，然后在操作完成后查看集群状态的时候，出现如下错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The connection to the server localhost:8080 was refused - did you specify the right host or port?</span><br></pre></td></tr></table></figure><p>这时候请备份好 kubeadm init 输出中的 kubeadm join 命令，因为将会需要这个命令来给集群添加节点。</p><h3 id="安装Pod网络附加组件"><a href="#安装Pod网络附加组件" class="headerlink" title="安装Pod网络附加组件"></a>安装Pod网络附加组件</h3><p>集群必须安装Pod网络插件，以使Pod可以相互通信，只需在Master节点操作，其他新加入的节点会自动创建相关pod。必须在任何应用程序之前部署网络组件。另外，在安装网络之前，CoreDNS将不会启动，你可以通过命令 来查看CoreDNS 的状态</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看 CoreDNS 的状态,并不是 Running 状态</span></span><br><span class="line">$ kubectl get pods --all-namespaces|grep coredns</span><br><span class="line">kube-system   coredns-7f9c544f75-bzksd    0/1   Pending   0     14m</span><br><span class="line">kube-system   coredns-7f9c544f75-mtrwq    0/1   Pending   0     14m</span><br></pre></td></tr></table></figure><p>kubeadm 支持多种网络插件，我们选择Calico 网络插件（kubeadm 仅支持基于容器网络接口（CNI）的网络（不支持kubenet），默认情况下，它给出的pod的IP段地址是 192.168.0.0/16 ,如果你的机器已经使用了此IP段，就需要修改这个配置项，将其值改为在初始化 Master 节点时使用 kubeadm init –pod-network-cidr=x.x.x.x/x 的IP地址段，即我们上面配置的 10.10.0.0/16 ，大概在625行左右，操作如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取配置文件</span></span><br><span class="line">mkdir calico &amp;&amp; <span class="built_in">cd</span> calico</span><br><span class="line">wget https://docs.projectcalico.org/v3.8/manifests/calico.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改配置文件</span></span><br><span class="line"><span class="comment"># 找到 625 行左右的 192.168.0.0/16 ，并修改为我们初始化时配置的 10.10.0.0/16</span></span><br><span class="line">vim calico.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 部署 Pod 网络组件</span></span><br><span class="line">kubectl apply -f calico.yaml</span><br></pre></td></tr></table></figure><p>稍等片刻查询 pod 详情，你也可以使用 watch 命令来实时查看 pod 的状态，等待 Pod 网络组件部署成功后，就可以看到一些信息了，包括 Pod 的 IP 地址信息，这个过程时间可能会有点长。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">watch -n 2 kubectl get pods --all-namespaces -o wide</span><br></pre></td></tr></table></figure><h3 id="将Worker节点添加到Kubernetes"><a href="#将Worker节点添加到Kubernetes" class="headerlink" title="将Worker节点添加到Kubernetes"></a>将Worker节点添加到Kubernetes</h3><p>请首先确认所有Worker节点满足第一部分的环境说明，并且已经安装了 Docker 和 kubeadm、kubelet 、kubectl，并且已经启动 kubelet。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加 Hosts 解析</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"127.0.0.1 <span class="variable">$(hostname)</span>"</span> &gt;&gt; /etc/hosts</span><br><span class="line"><span class="built_in">export</span> MASTER_IP=10.209.208.238</span><br><span class="line"><span class="built_in">export</span> APISERVER_NAME=kuber4s.api</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"<span class="variable">$&#123;MASTER_IP&#125;</span> <span class="variable">$&#123;APISERVER_NAME&#125;</span>"</span> &gt;&gt; /etc/hosts</span><br></pre></td></tr></table></figure><p>将 Worker 节点添加到集群，这里注意，执行后可能会报错，有幸的话你会跳进这个坑，这是因为 Worker 节点加入集群的命令实际上在初始化 master 时已经有提示出来了，不过两小时后会删除上传的证书，所以如果你此时加入集群的时候提示证书相关的错误，请执行 kubeadm init phase upload-certs –upload-certs 重新加载证书。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join kuber4s.api:6443 --token 0y1dj2.ih27ainxwyib0911 \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:5204b3e358a0d568e147908cba8036bdb63e604d4f4c1c3730398f33144fac61 \</span><br></pre></td></tr></table></figure><p>执行加入操作，你可能会发现卡着不动，大概率是因为令牌ID对此集群无效或已过 2 小时的有效期（通过执行 kubeadm join –v=5 来获取详细的加入过程，看到了内容为 ”token id “0y1dj2” is invalid for this cluster or it has expired“ 的提示），接下来需要在 Master 上通过 kubeadm token create 来创建新的令牌。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ kubeadm token create --<span class="built_in">print</span>-join-command</span><br><span class="line">W0129 19:10:04.842735   15533 validation.go:28] Cannot validate kube-proxy config - no validator is available</span><br><span class="line">W0129 19:10:04.842808   15533 validation.go:28] Cannot validate kubelet config - no validator is available</span><br><span class="line"><span class="comment"># 输出结果如下</span></span><br><span class="line">kubeadm join kuber4s.api:6443 --token 1hk9bc.oz7f3lmtbzf15x9b     --discovery-token-ca-cert-hash sha256:5e8bcad5ec97c1025e8044f4b8fd0a4514ecda4bac2b3944f7f39ccae9e4921f</span><br></pre></td></tr></table></figure><p>在 Worker节点上重新执行加入集群命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join kuber4s.api:6443 \</span><br><span class="line">    --token 1hk9bc.oz7f3lmtbzf15x9b \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:5e8bcad5ec97c1025e8044f4b8fd0a4514ecda4bac2b3944f7f39ccae9e4921f</span><br></pre></td></tr></table></figure><p>接下来在Master上查看 Worker 节点加入的状况，直到 Worker 节点的状态变为 Ready 便证明加入成功，这个过程可能会有点漫长，30 分钟以内都算正常的，主要看你网络的情况或者说拉取镜像的速度；另外不要一看到 /var/log/messages 里面报错就慌了，那也得看具体报什么错，看不懂就稍微等一下，一般在 Master 上能看到已经加入（虽然没有Ready）就没什么问题。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">watch kubectl get nodes -o wide</span><br></pre></td></tr></table></figure><h2 id="安装nfs服务"><a href="#安装nfs服务" class="headerlink" title="安装nfs服务"></a>安装nfs服务</h2><p>kubesphere安装条件是必须k8s集群有StorageClass，这里用nfs。所以需要安装nfs服务来作为StorageClass。</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y nfs-utils</span><br></pre></td></tr></table></figure><h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /data/k8s --创建一个存储目录</span><br><span class="line">vi /etc/exports</span><br><span class="line">/data/k8s    *(rw,sync,no_root_squash)</span><br><span class="line"><span class="comment">#目录/data/k8s共享给10.0.0.0/8网段，允许读写，同步写入</span></span><br><span class="line"><span class="comment">#第一列代表共享哪个目录;第二列代表允许哪个客户端去访问;第三列共享目录的一些权限设置</span></span><br><span class="line"><span class="comment">#权限：ro 只读 rw允许读写 sync同步写入 no_root_squash当客户机以root身份访问时，赋予root权限（即超级用户保留权限）否则，root用户所有请求映射成anonymous用户一样的权限（默认）</span></span><br></pre></td></tr></table></figure><h3 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h3><p>先启动rpcbind,再启动nfs</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl start rpcbind</span><br><span class="line">systemctl start nfs</span><br><span class="line">netstat -anptu | grep rpcbind</span><br></pre></td></tr></table></figure><h2 id="安装-StorageClass"><a href="#安装-StorageClass" class="headerlink" title="安装 StorageClass"></a>安装 StorageClass</h2><p>Kubernetes 支持多种 StorageClass，这选择NFS 作为集群的 StorageClass。</p><h3 id="下载所需文件"><a href="#下载所需文件" class="headerlink" title="下载所需文件"></a>下载所需文件</h3><p>下载所需文件，并进行内容调整</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir nfsvolume &amp;&amp; <span class="built_in">cd</span> nfsvolume</span><br><span class="line"><span class="keyword">for</span> file <span class="keyword">in</span> class.yaml deployment.yaml rbac.yaml ; <span class="keyword">do</span> wget https://raw.githubusercontent.com/kubernetes-incubator/external-storage/master/nfs-client/deploy/<span class="variable">$file</span> ; <span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>修改 deployment.yaml 中的两处 NFS 服务器 IP 和目录</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">...</span></span><br><span class="line"><span class="attr">          env:</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">PROVISIONER_NAME</span></span><br><span class="line"><span class="attr">              value:</span> <span class="string">fuseim.pri/ifs</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">NFS_SERVER</span></span><br><span class="line"><span class="attr">              value:</span> <span class="number">10.220</span><span class="number">.170</span><span class="number">.240</span></span><br><span class="line"><span class="attr">            - name:</span> <span class="string">NFS_PATH</span></span><br><span class="line"><span class="attr">              value:</span> <span class="string">/data/k8s</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">nfs-client-root</span></span><br><span class="line"><span class="attr">          nfs:</span></span><br><span class="line"><span class="attr">            server:</span> <span class="number">10.220</span><span class="number">.170</span><span class="number">.240</span></span><br><span class="line"><span class="attr">            path:</span> <span class="string">/data/k8s</span></span><br></pre></td></tr></table></figure><h3 id="部署创建"><a href="#部署创建" class="headerlink" title="部署创建"></a>部署创建</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f rbac.yaml</span><br><span class="line">kubectl create -f class.yaml</span><br><span class="line">kubectl create -f deployment.yaml</span><br></pre></td></tr></table></figure><p>在集群内所有机器上安装nfs-utils并启动。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">yum -y install nfs-utils</span><br><span class="line">systemctl start nfs-utils</span><br><span class="line">systemctl <span class="built_in">enable</span> nfs-utils</span><br><span class="line">rpcinfo -p</span><br></pre></td></tr></table></figure><p>查看storageclass</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get storageclass</span><br><span class="line">NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE</span><br><span class="line">managed-nfs-storage fuseim.pri/ifs Delete Immediate <span class="literal">false</span> 10m</span><br></pre></td></tr></table></figure><h3 id="标记默认的-StorageClass"><a href="#标记默认的-StorageClass" class="headerlink" title="标记默认的 StorageClass"></a>标记默认的 StorageClass</h3><p>操作命令格式如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl patch storageclass managed-nfs-storage -p <span class="string">'&#123;"metadata": &#123;"annotations":&#123;"storageclass.kubernetes.io/is-default-class":"true"&#125;&#125;&#125;'</span></span><br></pre></td></tr></table></figure><p>请注意，最多只能有一个 StorageClass 能够被标记为默认。</p><p>验证标记是否成功</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl get storageclass</span><br><span class="line">NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE</span><br><span class="line">managed-nfs-storage (default) fuseim.pri/ifs Delete Immediate <span class="literal">false</span> 12m</span><br></pre></td></tr></table></figure><h2 id="安装KubeSphere3-0"><a href="#安装KubeSphere3-0" class="headerlink" title="安装KubeSphere3.0"></a>安装KubeSphere3.0</h2><p><a href="https://kubesphere.com.cn/docs/zh-CN/" rel="noopener" target="_blank">KubeSphere</a> 是在 <a href="https://kubernetes.io/" rel="noopener" target="_blank">Kubernetes</a> 之上构建的以应用为中心的容器平台，提供简单易用的操作界面以及向导式操作方式，在降低用户使用容器调度平台学习成本的同时，极大减轻开发、测试、运维的日常工作的复杂度，旨在解决 Kubernetes 本身存在的存储、网络、安全和易用性等痛点。除此之外，平台已经整合并优化了多个适用于容器场景的功能模块，以完整的解决方案帮助企业轻松应对敏捷开发与自动化运维、DevOps、微服务治理、灰度发布、多租户管理、工作负载和集群管理、监控告警、日志查询与收集、服务与网络、应用商店、镜像构建与镜像仓库管理和存储管理等多种场景。后续版本将提供和支持多集群管理、大数据、AI 等场景。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/b645bc81/4.png" alt></p><h3 id="安装要求"><a href="#安装要求" class="headerlink" title="安装要求"></a>安装要求</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">k8s集群版本必须是1.15.x, 1.16.x, 1.17.x, or 1.18.x</span><br><span class="line">必须有默认的storageclass</span><br><span class="line">内存和cpu最低要求：CPU &gt; 1 Core, Memory &gt; 2 G</span><br></pre></td></tr></table></figure><p>按照上面教程操作，完全符合要求。</p><h3 id="安装yaml文件"><a href="#安装yaml文件" class="headerlink" title="安装yaml文件"></a>安装yaml文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://github.com/kubesphere/ks-installer/releases/download/v3.0.0/kubesphere-installer.yaml</span><br><span class="line"></span><br><span class="line">kubectl apply -f https://github.com/kubesphere/ks-installer/releases/download/v3.0.0/cluster-configuration.yaml</span><br></pre></td></tr></table></figure><h3 id="查看安装日志"><a href="#查看安装日志" class="headerlink" title="查看安装日志"></a>查看安装日志</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl logs -n kubesphere-system $(kubectl get pod -n kubesphere-system -l app=ks-install -o jsonpath=<span class="string">'&#123;.items[0].metadata.name&#125;'</span>) -f</span><br></pre></td></tr></table></figure><h3 id="查看所有pod"><a href="#查看所有pod" class="headerlink" title="查看所有pod"></a>查看所有pod</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -A</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/b645bc81/1.png" alt></p><h3 id="登陆kubesphere"><a href="#登陆kubesphere" class="headerlink" title="登陆kubesphere"></a>登陆kubesphere</h3><p>浏览器访问ip:30880    用户名：admin     默认密码：P@88w0rd</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/b645bc81/2.png" alt></p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/b645bc81/3.png" alt></p><h2 id="补充内容"><a href="#补充内容" class="headerlink" title="补充内容"></a>补充内容</h2><ul><li>kubeadm init               初始化Kubernetes主节点</li><li>kubeadm token          管理 kubeadm join 的令牌，包括查看、创建和删除等</li><li>kubeadm reset           将kubeadm init或kubeadm join对主机的更改恢复到之前状态，一般与 -f 参数使用</li></ul><p><strong>POD创建流程</strong></p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/b645bc81/5.png" alt></p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/b645bc81/6.png" alt></p><p><strong>Ingress与Service关系图</strong></p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/b645bc81/7.png" alt></p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文将从零开始在干净的机器上安装 &lt;code&gt;Docker、Kubernetes (使用 kubeadm)、Calico、NFS StorageClass等&lt;/code&gt;，通过手把手的教程演示如何搭建一个 &lt;code&gt;Kubernetes集群&lt;/code&gt;，并在 K8s集群之上安装开源的&lt;code&gt;KubeSphere&lt;/code&gt; 容器平台可视化运营集群环境。&lt;/p&gt;
    
    </summary>
    
      <category term="容器编排" scheme="https://wandouduoduo.github.io/categories/%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92/"/>
    
      <category term="K8s" scheme="https://wandouduoduo.github.io/categories/%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92/K8s/"/>
    
    
      <category term="K8s" scheme="https://wandouduoduo.github.io/tags/K8s/"/>
    
  </entry>
  
  <entry>
    <title>带你彻底了解lstio是什么东东</title>
    <link href="https://wandouduoduo.github.io/articles/8fe28783.html"/>
    <id>https://wandouduoduo.github.io/articles/8fe28783.html</id>
    <published>2021-03-02T02:16:35.000Z</published>
    <updated>2021-03-16T10:33:08.068Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>如果你保持学习新技术的触角来持续拓展技术储备的广度的话，很可能在不同的地方听说过<code>Istio</code>，可能还知道它和Service Mesh有着牵扯。本文可作为了解<code>Istio</code>的入门介绍，介绍什么是<code>Istio</code>，<code>Istio</code>为什么最近这么火，以及<code>Istio</code>解决了哪些问题，能给我们带来什么好处。</p><a id="more"></a><h2 id="什么是Istio"><a href="#什么是Istio" class="headerlink" title="什么是Istio"></a>什么是Istio</h2><p>官方对 Istio 的介绍浓缩成了一句话：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">An open platform to connect, secure, control and observe services.</span><br></pre></td></tr></table></figure><p>翻译过来，就是”连接、安全加固、控制和观察服务的开放平台“。开放平台就是指它本身是开源的，服务对应的是微服务，也可以粗略地理解为单个应用。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8fe28783/1.jpeg" alt="img"></p><p>中间的四个动词就是 Istio 的主要功能，官方也各有一句话的说明。这里再阐释一下：</p><ul><li>连接（Connect）：智能控制服务之间的调用流量，能够实现灰度升级、AB 测试和红黑部署等功能</li><li>安全加固（Secure）：自动为服务之间的调用提供认证、授权和加密。</li><li>控制（Control）：应用用户定义的 policy，保证资源在消费者中公平分配。</li><li>观察（Observe）：查看服务运行期间的各种数据，比如日志、监控和 tracing，了解服务的运行情况。</li></ul><p>虽然听起来非常高级，功能非常强大，但是一股脑出现这么多名词，还都是非常虚的概念，说了跟没说一样。要想理解上面这几句话的含义，我们还是从头说起，先聊聊 Service Mesh。</p><p><strong>NOTE：</strong>其实 Istio 的源头是微服务，但这又是一个比较大的话题，目前可以参考网络上各种文章。如果有机会，我们再来聊聊微服务。</p><h2 id="什么是Service-Mesh"><a href="#什么是Service-Mesh" class="headerlink" title="什么是Service Mesh"></a>什么是Service Mesh</h2><p>一般介绍 Service Mesh 的文章都会从网络层的又一个抽象说起，把 Service Mesh 看做建立在 TCP 层之上的微服务层。我这次换个思路，从 Service Mesh 的技术根基——网络代理来分析。</p><p>说起网络代理，我们会想到翻墙，如果对软件架构比较熟悉的会想到 Nginx 等反向代理软件。</p><p>其实网络代理的范围比较广，可以肯定的说，有网络访问的地方就会有代理的存在。</p><p>Wikipedia 对代理的定义如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">In computer networks, a proxy server is a server (a computer system or an application) that acts as an intermediary for requests from clients seeking resources from other servers.</span><br></pre></td></tr></table></figure><p><strong>NOTE：</strong>代理可以是嵌套的，也就是说通信双方 A、B 中间可以多多层代理，而这些代理的存在有可能对 A、B 是透明的。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8fe28783/2.jpeg" alt="img"></p><p>简单来说，网络代理可以简单类比成现实生活中的中介，本来需要通信的双方因为各种原因在中间再加上一道关卡。本来双方就能完成的通信，为何非要多此一举呢？</p><p>那是因为代理可以为整个通信带来更多的功能，比如：</p><ul><li>拦截：代理可以选择性拦截传输的网络流量，比如一些公司限制员工在上班的时候不能访问某些游戏或者电商网站，再比如把我们和世界隔离开来的 GFW，还有在数据中心中拒绝恶意访问的网关。</li><li>统计：既然所有的流量都经过代理，那么代理也可以用来统计网络中的数据信息，比如了解哪些人在访问哪些网站，通信的应答延迟等。</li><li>缓存：如果通信双方比较”远“，访问比较慢，那么代理可以把最近访问的数据缓存在本地，后面的访问不用访问后端来做到加速。CDN 就是这个功能的典型场景。</li><li>分发：如果某个通信方有多个服务器后端，代理可以根据某些规则来选择如何把流量发送给多个服务器，也就是我们常说的负载均衡功能，比如著名的 Nginx 软件。</li><li>跳板：如果 A、B 双方因为某些原因不能直接访问，而代理可以和双方通信，那么通过代理，双方可以绕过原来的限制进行通信。这应该是广大中国网民比较熟悉的场景。</li><li>注入：既然代理可以看到流量，那么它也可以修改网络流量，可以自动在收到的流量中添加一些数据，比如有些宽带提供商的弹窗广告。</li><li>……</li></ul><p>不是要讲 Service Mesh 吗？为什么扯了一堆代理的事情？因为 Service Mesh 可以看做是传统代理的升级版，用来解决现在微服务框架中出现的问题，可以把 Service Mesh 看做是分布式的微服务代理。</p><p>在传统模式下，代理一般是集中式的单独的服务器，所有的请求都要先通过代理，然后再流入转发到实际的后端。</p><p>而在 Service Mesh 中，代理变成了分布式的，它常驻在了应用的身边（最常见的就是 Kubernetes Sidecar 模式，每一个应用的 Pod 中都运行着一个代理，负责流量相关的事情）。</p><p>这样的话，应用所有的流量都被代理接管，那么这个代理就能做到上面提到的所有可能的事情，从而带来无限的想象力。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8fe28783/3.jpeg" alt="img"></p><p>此外，原来的代理都是基于网络流量的，一般都是工作在 IP 或者 TCP 层，很少关心具体的应用逻辑。</p><p>但是 Service Mesh 中，代理会知道整个集群的所有应用信息，并且额外添加了热更新、注入服务发现、降级熔断、认证授权、超时重试、日志监控等功能，让这些通用的功能不必每个应用都自己实现，放在代理中即可。</p><p>换句话说，Service Mesh 中的代理对微服务中的应用做了定制化的改进！</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8fe28783/4.jpeg" alt="img"></p><p>就这样，借着微服务和容器化的东风，传统的代理摇身一变，成了如今炙手可热的 Service Mesh。</p><p>应用微服务之后，每个单独的微服务都会有很多副本，而且可能会有多个版本，这么多微服务之间的相互调用和管理非常复杂，但是有了 Service Mesh，我们可以把这块内容统一在代理层。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8fe28783/5.jpeg" alt="img"></p><p>有了看起来四通八达的分布式代理，我们还需要对这些代理进行统一的管理。</p><p>手动更新每个代理的配置，对代理进行升级或者维护是个不可持续的事情，在前面的基础上，在加上一个控制中心，一个完整的 Service Mesh 就成了。</p><p>管理员只需要根据控制中心的 API 来配置整个集群的应用流量、安全规则即可，代理会自动和控制中心打交道根据用户的期望改变自己的行为。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8fe28783/6.jpeg" alt="img"></p><p><strong>NOTE：</strong>所以你也可以理解 Service Mesh 中的代理会抢了 Nginx 的生意，这也是为了 Nginx 也要开始做 NginMesh 的原因。</p><h2 id="再来看Istio"><a href="#再来看Istio" class="headerlink" title="再来看Istio"></a>再来看Istio</h2><p>了解了 Service Mesh 的概念，我们再来看 Istio ，也许就会清楚很多。首先来看 Istio 官方给出的架构图：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8fe28783/7.jpeg" alt="img"></p><p>可以看到，Istio 就是我们上述提到的 Service Mesh 架构的一种实现，服务之间的通信（比如这里的 Service A 访问 Service B）会通过代理（默认是 Envoy）来进行。</p><p>而且中间的网络协议支持 HTTP/1.1，HTTP/2，gRPC 或者 TCP，可以说覆盖了主流的通信协议。</p><p>控制中心做了进一步的细分，分成了 Pilot、Mixer 和 Citadel，它们的各自功能如下：</p><ul><li>Pilot：为 Envoy 提供了服务发现，流量管理和智能路由（AB 测试、金丝雀发布等），以及错误处理（超时、重试、熔断）功能。 用户通过 Pilot 的 API 管理网络相关的资源对象，Pilot 会根据用户的配置和服务的信息把网络流量管理变成 Envoy 能识别的格式分发到各个 Sidecar 代理中。</li><li>Mixer：为整个集群执行访问控制（哪些用户可以访问哪些服务）和 Policy 管理（Rate Limit，Quota 等），并且收集代理观察到的服务之间的流量统计数据。</li><li>Citadel：为服务之间提供认证和证书管理，可以让服务自动升级成 TLS 协议。</li></ul><p>代理会和控制中心通信，一方面可以获取需要的服务之间的信息，另一方面也可以汇报服务调用的 Metrics 数据。</p><p>知道了 Istio 的核心架构，再来看看它的功能描述就非常容易理解了：</p><ul><li>连接：控制中心可以从集群中获取所有服务的信息，并分发给代理，这样代理就能根据用户的期望来完成服务之间的通信（自动地服务发现、负载均衡、流量控制等）。</li><li>安全加固：因为所有的流量都是通过代理的，那么代理接收到不加密的网络流量之后，可以自动做一次封装，把它升级成安全的加密流量。</li><li>控制：用户可以配置各种规则（比如 RBAC 授权、白名单、Rate Limit 或者 Quota 等），当代理发现服务之间的访问不符合这些规则，就直接拒绝掉。</li><li>观察：所有的流量都经过代理，因此代理对整个集群的访问情况知道得一清二楚，它把这些数据上报到控制中心，那么管理员就能观察到整个集群的流量情况了</li></ul><h2 id="Istio解决什么问题"><a href="#Istio解决什么问题" class="headerlink" title="Istio解决什么问题"></a>Istio解决什么问题</h2><p>虽然看起来非常炫酷，功能也很强大，但是一个架构和产品出来都是要解决具体的问题。所以这部分我们来看看微服务架构中的难题以及 Istio 给出的答案。</p><p>首先，原来的单个应用拆分成了许多分散的微服务，它们之间相互调用才能完成一个任务，而一旦某个过程出错（组件越多，出错的概率也就越大），就非常难以排查。</p><p>用户请求出现问题无外乎两个问题：错误和响应慢。如果请求错误，那么我们需要知道那个步骤出错了，这么多的微服务之间的调用怎么确定哪个有调用成功？哪个没有调用成功呢？</p><p>如果是请求响应太慢，我们就需要知道到底哪些地方比较慢？整个链路的调用各阶段耗时是多少？哪些调用是并发执行的，哪些是串行的？这些问题需要我们能非常清楚整个集群的调用以及流量情况。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8fe28783/8.jpeg" alt="img"></p><p>此外，微服务拆分成这么多组件，如果单个组件出错的概率不变，那么整体有地方出错的概率就会增大。服务调用的时候如果没有错误处理机制，那么会导致非常多的问题。</p><p>比如如果应用没有配置超时参数，或者配置的超时参数不对，则会导致请求的调用链超时叠加，对于用户来说就是请求卡住了。</p><p>如果没有重试机制，那么因为各种原因导致的偶发故障也会导致直接返回错误给用户，造成不好的用户体验。</p><p>此外，如果某些节点异常（比如网络中断，或者负载很高），也会导致应用整体的响应时间变长，集群服务应该能自动避开这些节点上的应用。</p><p>最后，应用也是会出现 Bug 的，各种 Bug 会导致某些应用不可访问。这些问题需要每个应用能及时发现问题，并做好对应的处理措施。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8fe28783/9.jpeg" alt="img"></p><p>应用数量的增多，对于日常的应用发布来说也是个难题。应用的发布需要非常谨慎，如果应用都是一次性升级的，出现错误会导致整个线上应用不可用，影响范围太大。</p><p>而且，很多情况我们需要同时存在不同的版本，使用 AB 测试验证哪个版本更好。</p><p>如果版本升级改动了 API，并且互相有依赖，那么我们还希望能自动地控制发布期间不同版本访问不同的地址。这些问题都需要智能的流量控制机制。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8fe28783/10.jpeg" alt="img"></p><p>为了保证整个系统的安全性，每个应用都需要实现一套相似的认证、授权、HTTPS、限流等功能。</p><p>一方面大多数的程序员都对安全相关的功能并不擅长或者感兴趣，另外这些完全相似的内容每次都要实现一遍是非常冗余的。这个问题需要一个能自动管理安全相关内容的系统。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/8fe28783/11.jpeg" alt="img"></p><p>上面提到的这些问题是不是非常熟悉？它们就是 Istio 尝试解决的问题，如果把上面的问题和 Istio 提供的功能做个映射，你会发现它们非常匹配，毕竟 Istio 就是为了解决微服务的这些问题才出现的。</p><h2 id="用什么姿势接入Istio？"><a href="#用什么姿势接入Istio？" class="headerlink" title="用什么姿势接入Istio？"></a>用什么姿势接入Istio？</h2><p>虽然 Istio 能解决那么多的问题，但是引入 Istio 并不是没有代价的。最大的问题是 Istio 的复杂性，强大的功能也意味着 Istio 的概念和组件非常多，要想理解和掌握 Istio ，并成功在生产环境中部署需要非常详细的规划。</p><p>一般情况下，集群管理团队需要对 Kubernetes 非常熟悉，了解常用的使用模式，然后采用逐步演进的方式把 Istio 的功能分批掌控下来。</p><p><strong>第一步，自然是在测试环境搭建一套 Istio 的集群，理解所有的核心概念和组件。</strong></p><p>了解 Istio 提供的接口和资源，知道它们的用处，思考如何应用到自己的场景中，然后是熟悉 Istio 的源代码，跟进社区的 Issues，了解目前还存在的 Issues 和 Bug，思考如何规避或者修复。</p><p>这一步是基础，需要积累到 Istio 安装部署、核心概念、功能和缺陷相关的知识，为后面做好准备。</p><p><strong>第二步，可以考虑接入 Istio 的观察性功能，包括 Logging、Tracing、Metrics 数据。</strong></p><p>应用部署到集群中，选择性地（一般是流量比较小，影响范围不大的应用）为一些应用开启 Istio 自动注入功能，接管应用的流量，并安装 Prometheus 和 Zipkin 等监控组件，收集系统所有的监控数据。</p><p>这一步可以试探性地了解 Istio 对应用的性能影响，同时建立服务的性能测试基准，发现服务的性能瓶颈，帮助快速定位应用可能出现的问题。</p><p>此时，这些功能可以是对应用开发者透明的，只需要集群管理员感知，这样可以减少可能带来的风险。</p><p><strong>第三步，为应用配置 Time Out 超时参数、自动重试、熔断和降级等功能，增加服务的容错性。</strong></p><p>这样可以避免某些应用错误进行这些配置导致问题的出现，这一步完成后需要通知所有的应用开发者删除掉在应用代码中对应的处理逻辑。这一步需要开发者和集群管理员同时参与。</p><p><strong>第四步，和 Ingress、Helm、应用上架等相关组件和流程对接，使用 Istio 接管应用的升级发布流程。</strong></p><p>让开发者可以配置应用灰度发布升级的策略，支持应用的蓝绿发布、金丝雀发布以及 AB 测试。</p><p><strong>第五步，接入安全功能。配置应用的 TLS 互信，添加 RBAC 授权，设置应用的流量限制，提升整个集群的安全性。</strong></p><p>因为安全的问题配置比较繁琐，而且优先级一般会比功能性相关的特性要低，所以这里放在了最后。</p><p>当然这个步骤只是一个参考，每个公司需要根据自己的情况、人力、时间和节奏来调整，找到适合自己的方案。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Istio 的架构在数据中心和集群管理中非常常见，每个 Agent 分布在各个节点上（可以是服务器、虚拟机、Pod、容器）负责接收指令并执行，以及汇报信息。</p><p>控制中心负责汇聚整个集群的信息，并提供 API 让用户对集群进行管理。</p><p>Kubernetes 也是类似的架构，SDN（Software Defined Network） 也是如此。</p><p>相信以后会有更多类似架构的出现，这是因为数据中心要管理的节点越来越多，我们需要把任务执行分布到各节点（Agent 负责的功能）。</p><p>同时也需要对整个集群进行管理和控制（Control Plane 的功能），完全去中心化的架构是无法满足后面这个要求的。</p><p>Istio 的出现为负责的微服务架构减轻了很多的负担，开发者不用关心服务调用的超时、重试、Rate Limit 的实现，服务之间的安全、授权也自动得到了保证。</p><p>集群管理员也能够很方便地发布应用（AB 测试和灰度发布），并且能清楚看到整个集群的运行情况。</p><p>但是这并不表明有了 Istio 就可以高枕无忧了，Istio 只是把原来分散在应用内部的复杂性统一抽象出来放到了统一的地方，并没有让原来的复杂消失不见。</p><p>因此我们需要维护 Istio 整个集群，而 Istio 的架构比较复杂，尤其是它一般还需要架在 Kubernetes 之上，这两个系统都比较复杂，而且它们的稳定性和性能会影响到整个集群。</p><p>因此再采用 Isito 之前，必须做好清楚的规划，权衡它带来的好处是否远大于额外维护它的花费，需要有相关的人才对整个网络、Kubernetes 和 Istio 都比较了解才行。</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如果你保持学习新技术的触角来持续拓展技术储备的广度的话，很可能在不同的地方听说过&lt;code&gt;Istio&lt;/code&gt;，可能还知道它和Service Mesh有着牵扯。本文可作为了解&lt;code&gt;Istio&lt;/code&gt;的入门介绍，介绍什么是&lt;code&gt;Istio&lt;/code&gt;，&lt;code&gt;Istio&lt;/code&gt;为什么最近这么火，以及&lt;code&gt;Istio&lt;/code&gt;解决了哪些问题，能给我们带来什么好处。&lt;/p&gt;
    
    </summary>
    
      <category term="容器编排" scheme="https://wandouduoduo.github.io/categories/%E5%AE%B9%E5%99%A8%E7%BC%96%E6%8E%92/"/>
    
    
      <category term="K8s" scheme="https://wandouduoduo.github.io/tags/K8s/"/>
    
  </entry>
  
  <entry>
    <title>详解sql和nosql如何选型</title>
    <link href="https://wandouduoduo.github.io/articles/f84ad4f6.html"/>
    <id>https://wandouduoduo.github.io/articles/f84ad4f6.html</id>
    <published>2021-01-29T10:57:09.000Z</published>
    <updated>2021-01-29T11:06:49.543Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><strong>前言</strong></h2><p>你是否在为系统的数据库来一波大流量就几乎打满CPU，日常CPU居高不下烦恼？你是否在各种NoSql间纠结不定，到底该选用那种最好？今天的你就是昨天的我，这也是写这篇文章的初衷。</p><p>这篇文章是我好几个月来一直想写的一篇文章，也是一直想学习的一个内容，作为互联网从业人员，我们要知道关系型数据库（MySql、Oracle）无法满足我们对存储的所有要求，因此对底层存储的选型，对每种存储引擎的理解非常重要。同时也由于过去一段时间的工作经历，对这块有了一些更多的思考，想通过自己的总结把这块写出来分享给大家。</p><a id="more"></a><p><strong>结构化数据、非结构化数据与半结构化数据</strong></p><p>文章的开始，聊一下结构化数据、非结构化数据与半结构化数据，因为数据特点的不同，将在技术上直接影响存储引擎的选型。</p><p>首先是结构化数据，根据定义<strong>结构化数据指的是由二维表结构来逻辑表达和实现的数据，严格遵循数据格式与长度规范，也称作为行数据</strong>，特点为：数据以行为单位，一行数据表示一个实体的信息，每一行数据的属性是相同的。例如：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/f84ad4f6/1.png" alt="img"></p><p>因此关系型数据库完美契合结构化数据的特点，关系型数据库也是关系型数据最主要的存储与管理引擎。</p><p>非结构化数据，指的是<strong>数据结构不规则或不完整，没有任何预定义的数据模型，不方便用二维逻辑表来表现的数据</strong>，例如办公文档（Word）、文本、图片、HTML、各类报表、视频音频等。</p><p>介于结构化与非结构化数据之间的数据就是半结构化数据了，它是结构化数据的一种形式，虽然<strong>不符合二维逻辑这种数据模型结构，但是包含相关标记，用来分割语义元素以及对记录和字段进行分层</strong>。常见的半结构化数据有XML和JSON，例如：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">person</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>张三<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">age</span>&gt;</span>18<span class="tag">&lt;/<span class="name">age</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">phone</span>&gt;</span>12345<span class="tag">&lt;/<span class="name">phone</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">person</span>&gt;</span></span><br></pre></td></tr></table></figure><p>这种结构也被成为自描述的结构。</p><h2 id="关系型数据库"><a href="#关系型数据库" class="headerlink" title="关系型数据库"></a>关系型数据库</h2><h3 id="以关系型数据库的方式做存储的架构演进"><a href="#以关系型数据库的方式做存储的架构演进" class="headerlink" title="以关系型数据库的方式做存储的架构演进"></a><strong>以关系型数据库的方式做存储的架构演进</strong></h3><p>首先，我们看一下使用关系型数据库的方式，企业一个系统发展的几个阶段的架构演进（由于本文写的是Sql与NoSql，因此只以存储方式作为切入点，不会涉及类似MQ、ZK这些中间件内容）：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/f84ad4f6/2.png" alt="img"></p><p>阶段一：企业刚发展的阶段，最简单，一个应用服务器配一个关系型数据库，每次读写数据库。</p><p>阶段二：无论是使用MySQL还是Oracle还是别的关系型数据库，数据库通常不会先成为性能瓶颈，通常随着企业规模的扩大，一台应用服务器扛不住上游过来的流量且一台应用服务器会产生单点故障的问题，因此<strong>加应用服务器并且在流量入口使用Nginx做一层负载均衡</strong>，保证把流量均匀打到应用服务器上。</p><p>阶段三：随着企业规模的继续扩大，此时由于读写都在同一个数据库上，数据库性能出现一定的瓶颈，此时简单地做一层<strong>读写分离</strong>，每次写主库，读备库，主备库之间通过binlog同步数据，就能很大程度上解决这个阶段的数据库性能问题</p><p>阶段四：企业发展越来越好了，业务越来越大了，做了读写分离数据库压力还是越来越大，这时候怎么办呢，一台数据库扛不住，那我们就分几台吧，做<strong>分库分表</strong>，对表做垂直拆分，对库做水平拆分。以扩数据库为例，扩出两台数据库，以一定的单号（例如交易单号），以一定的规则（例如取模），交易单号对2取模为0的丢到数据库1去，交易单号对2取模为1的丢到数据库2去，通过这样的方式将写数据库的流量均分到两台数据库上。一般分库分表会使用Shard的方式，通过一个中间件，便于连接管理、数据监控且客户端无需感知数据库ip</p><h3 id="关系型数据库的优点"><a href="#关系型数据库的优点" class="headerlink" title="关系型数据库的优点"></a><strong>关系型数据库的优点</strong></h3><p>上面的方式，看似可以解决问题（实际上确实也能解决很多问题），正常对关系型数据库做一下读写分离 + 分库分表，支撑个1W+的读写QPS还是问题不大的。但是受限于关系型数据库本身，这套架构方案依然有着明显的不足，下面对利用关系型数据库方式做存储的方案的优点先进行一下分析，后一部分再分析一下缺点，对某个技术的优缺点的充分理解是技术选型的前提。</p><ul><li><strong>易理解</strong></li></ul><p>　　因为行 + 列的二维表逻辑是非常贴近逻辑世界的一个概念，关系模型相对网状、层次等其他模型更加容易被理解</p><ul><li><strong>操作方便</strong></li></ul><p>　　通用的SQL语言使得操作关系型数据库非常方便，支持join等复杂查询，Sql + 二维关系是关系型数据库最无可比拟的优点，这种易用性非常贴近开发者</p><ul><li><strong>数据一致性</strong></li></ul><p>　　支持ACID特性，可以维护数据之间的一致性，这是使用数据库非常重要的一个理由之一，例如同银行转账，张三转给李四100元钱，张三扣100元，李四加100元，而且必须同时成功或者同时失败，否则就会造成用户的资损</p><ul><li><strong>数据稳定</strong></li></ul><p>　　数据持久化到磁盘，没有丢失数据风险，支持海量数据存储</p><ul><li><strong>服务稳定</strong></li></ul><p>　　最常用的关系型数据库产品MySql、Oracle服务器性能卓越，服务稳定，通常很少出现宕机异常</p><h3 id="关系型数据库的缺点"><a href="#关系型数据库的缺点" class="headerlink" title="关系型数据库的缺点"></a><strong>关系型数据库的缺点</strong></h3><p>紧接着的，我们看一下关系型数据库的缺点，也是比较明显的。</p><ul><li><strong>高并发下IO压力大</strong></li></ul><p>　　数据按行存储，即使只针对其中某一列进行运算，也会将整行数据从存储设备中读入内存，导致IO较高</p><ul><li><strong>为维护索引付出的代价大</strong></li></ul><p>　　为了提供丰富的查询能力，通常热点表都会有多个二级索引，一旦有了二级索引，数据的新增必然伴随着所有二级索引的新增，数据的更新也必然伴随着所有二级索引的更新，这不可避免地降低了关系型数据库的读写能力，且索引越多读写能力越差。有机会的话可以看一下自己公司的数据库，除了数据文件不可避免地占空间外，索引占的空间其实也并不少</p><ul><li><strong>为维护数据一致性付出的代价大</strong></li></ul><p>　　数据一致性是关系型数据库的核心，但是同样为了维护数据一致性的代价也是非常大的。我们都知道SQL标准为事务定义了不同的隔离级别，从低到高依次是读未提交、读已提交、可重复度、串行化，事务隔离级别越低，可能出现的并发异常越多，但是通常而言能提供的并发能力越强。那么为了保证事务一致性，数据库就需要提供并发控制与故障恢复两种技术，前者用于减少并发异常，后者可以在系统异常的时候保证事务与数据库状态不会被破坏。对于并发控制，其核心思想就是加锁，无论是乐观锁还是悲观锁，只要提供的隔离级别越高，那么读写性能必然越差</p><ul><li><strong>水平扩展后带来的种种问题难处理</strong></li></ul><p>　　前文提过，随着企业规模扩大，一种方式是对数据库做分库，做了分库之后，数据迁移（1个库的数据按照一定规则打到2个库中）、跨库join（订单数据里有用户数据，两条数据不在同一个库中）、分布式事务处理都是需要考虑的问题，尤其是分布式事务处理，业界当前都没有特别好的解决方案</p><ul><li><strong>表结构扩展不方便</strong></li></ul><p>　　由于数据库存储的是结构化数据，因此表结构schema是固定的，扩展不方便，如果需要修改表结构，需要执行DDL（data definition language）语句修改，修改期间会导致锁表，部分服务不可用</p><ul><li><strong>全文搜索功能弱</strong></li></ul><p>　　例如like “%中国真伟大%”，只能搜索到”2019年中国真伟大，爱祖国”，无法搜索到”中国真是太伟大了”这样的文本，即不具备分词能力，且like查询在”%中国真伟大”这样的搜索条件下，无法命中索引，将会导致查询效率大大降低</p><p>写了这么多，我的理解核心还是前三点，它反映出的一个问题是<strong>关系型数据库在高并发下的能力是有瓶颈的</strong>，尤其是写入/更新频繁的情况下，出现瓶颈的结果就是数据库CPU高、Sql执行慢、客户端报数据库连接池不够等错误，因此例如万人秒杀这种场景，我们绝对不可能通过数据库直接去扣减库存。</p><p>可能有朋友说，数据库在高并发下的能力有瓶颈，我公司有钱，加CPU、换固态硬盘、继续买服务器加数据库做分库不就好了，问题是这是一种性价比非常低的方式，花1000万达到的效果，换其他方式可能100万就达到了，不考虑人员、服务器投入产出比的Leader就是个不合格的Leader，且关系型数据库的方式，受限于它本身的特点，可能花了钱都未必能达到想要的效果。至于什么是花100万就能达到花1000万效果的方式呢？可以继续往下看，这就是我们要说的NoSql。</p><h2 id="非关系型数据库"><a href="#非关系型数据库" class="headerlink" title="非关系型数据库"></a>非关系型数据库</h2><h3 id="结合NoSql的方式做存储的架构演进"><a href="#结合NoSql的方式做存储的架构演进" class="headerlink" title="结合NoSql的方式做存储的架构演进"></a><strong>结合NoSql的方式做存储的架构演进</strong></h3><p>像上文分析的，数据库作为一种关系型数据的存储引擎，存储的是关系型数据，它有优点，同时也有明显的缺点，因此通常在企业规模不断扩大的情况下，不会一味指望通过增强数据库的能力来解决数据存储问题，而是会引入其他存储，也就是我们说的NoSql。</p><p>NoSql的全称为Not Only SQL，泛指非关系型数据库，是对关系型数据库的一种<strong>补充</strong>，特别注意补充这两个字，这意味着NoSql与关系型数据库并不是对立关系，二者各有优劣，取长补短，在合适的场景下选择合适的存储引擎才是正确的做法。</p><p>比较简单的NoSql就是缓存：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/f84ad4f6/3.png" alt="img"></p><p>针对那些读远多于写的数据，引入一层缓存，每次读从缓存中读取，缓存中读取不到，再去数据库中取，取完之后再写入到缓存，对数据做好失效机制通常就没有大问题了。通常来说，缓存是性能优化的第一选择也是见效最明显的方案。</p><p>但是，缓存通常都是KV型存储且容量有限（基于内存），无法解决所有问题，于是再进一步的优化，我们继续引入其他NoSql：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/f84ad4f6/4.png" alt="img"></p><p>数据库、缓存与其他NoSql并行工作，充分发挥每种NoSql的特点。当然NoSql在性能方面大大优于关系挺数据库的同时，往往也伴随着一些特性的缺失，比较常见的就是事务功能的缺失。</p><p>下面看一下常用的NoSql及他们的代表产品，并对每种NoSql的优缺点和适用场景做一下分析，便于熟悉每种NoSql的特点，方便技术选型。</p><h3 id="KV型NoSql（代表—-Redis）"><a href="#KV型NoSql（代表—-Redis）" class="headerlink" title="KV型NoSql（代表—-Redis）"></a><strong>KV型NoSql（代表—-Redis）</strong></h3><p>KV型NoSql顾名思义就是以键值对形式存储的非关系型数据库，是最简单、最容易理解也是大家最熟悉的一种NoSql，因此比较快地带过。Redis、MemCache是其中的代表，Redis又是KV型NoSql中应用最广泛的NoSql，KV型数据库以Redis为例，最大的优点我总结下来就两点：</p><ul><li>数据基于内存，读写效率高</li><li>KV型数据，时间复杂度为O(1)，查询速度快</li></ul><p>因此，KV型NoSql最大的优点就是<strong>高性能</strong>，利用Redis自带的BenchMark做基准测试，TPS可达到10万的级别，性能非常强劲。同样的Redis也有所有KV型NoSql都有的比较明显的缺点：</p><ul><li>只能根据K查V，无法根据V查K</li><li>查询方式单一，只有KV的方式，不支持条件查询，多条件查询唯一的做法就是数据冗余，但这会极大的浪费存储空间</li><li>内存是有限的，无法支持海量数据存储</li><li>同样的，由于KV型NoSql的存储是基于内存的，会有丢失数据的风险</li></ul><p>综上所述，KV型NoSql最合适的场景就是<strong>缓存</strong>的场景：</p><ul><li>读远多于写</li><li>读取能力强</li><li>没有持久化的需求，可以容忍数据丢失，反正丢了再查询一把写入就是了</li></ul><p>例如根据用户id查询用户信息，每次根据用户id去缓存中查询一把，查到数据直接返回，查不到去关系型数据库里面根据id查询一把数据写到缓存中去。</p><h3 id="搜索型NoSql（代表—-ElasticSearch）"><a href="#搜索型NoSql（代表—-ElasticSearch）" class="headerlink" title="搜索型NoSql（代表—-ElasticSearch）"></a><strong>搜索型NoSql（代表—-ElasticSearch）</strong></h3><p>传统关系型数据库主要通过索引来达到快速查询的目的，但是在全文搜索的场景下，索引是无能为力的，like查询一来无法满足所有模糊匹配需求，二来使用限制太大且使用不当容易造成慢查询，<strong>搜索型NoSql的诞生正是为了解决关系型数据库全文搜索能力较弱的问题</strong>，ElasticSearch是搜索型NoSql的代表产品。</p><p>全文搜索的原理是<strong>倒排索引</strong>，我们看一下什么是倒排索引。要说倒排索引我们先看下什么是正排索引，传统的正排索引是<strong>文档–&gt;关键字</strong>的映射，例如”Tom is my friend”这句话，会将其切分为”Tom”、”is”、”my”、”friend”四个单词，在搜索的时候对文档进行扫描，符合条件的查出来。这种方式原理非常简单，但是由于其检索效率太低，基本没什么实用价值。</p><p>倒排索引则完全相反，它是<strong>关键字–&gt;文档</strong>的映射，我用张表格展示一下就比较清楚了：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/f84ad4f6/5.png" alt="img"></p><p>意思是我现在这里有四个短句：</p><ul><li>“Tom is Tom”</li><li>“Tom is my friend”</li><li>“Thank you, Betty”</li><li>“Tom is Betty’s husband”</li></ul><p>搜索引擎会根据一定的切分规则将这句话切成N个关键字，并以关键字的维度维护关键字在每个文本中的出现次数。这样下次搜索”Tom”的时候，由于Tom这个词语在”Tom is Tom”、”Tom is my friend”、”Tom is Betty’s husband”三句话中都有出现，因此这三条记录都会被检索出来，且由于”Tom is Tom”这句话中”Tom”出现了2次，因此这条记录对”Tom”这个单词的匹配度最高，最先展示。这就是搜索引擎倒排索引的基本原理，假设某个关键字在某个文档中出现，那么倒排索引中有两部分内容：</p><ul><li>文档ID</li><li>在该文档中出现的位置情况</li></ul><p>可以举一反三，我们搜索”Betty Tom”这两个词语也是一样，搜索引擎将”Betty Tom”切分为”Tom”、”Betty”两个单词，根据开发者指定的满足率，比如满足率=50%，那么只要记录中出现了两个单词之一的记录都会被检索出来，再按照匹配度进行展示。</p><p>搜索型NoSql以ElasticSearch为例，它的优点为：</p><ul><li>支持分词场景、全文搜索，这是区别于关系型数据库最大特点</li><li>支持条件查询，支持聚合操作，类似关系型数据库的Group By，但是功能更加强大，适合做数据分析</li><li>数据写文件无丢失风险，在集群环境下可以方便横向扩展，可承载PB级别的数据</li><li>高可用，自动发现新的或者失败的节点，重组和重新平衡数据，确保数据是安全和可访问的</li></ul><p>同样，ElasticSearch也有比较明显的缺点：</p><ul><li><p>性能全靠内存来顶，也是使用的时候最需要注意的点，非常吃硬件资源、吃内存，大数据量下64G + SSD基本是标配，算得上是数据库中的爱马仕了。为什么要专门提一下内存呢，因为内存这个东西是很值钱的，相同的配置多一倍内存，一个月差不多就要多花几百块钱，至于ElasticSearch内存用在什么地方，大概有如下这些：</p></li><li><ul><li>Indexing Buffer—-ElasticSearch基于Luence，Lucene的倒排索引是先在内存里生成，然后定期以Segment File的方式刷磁盘的，每个Segment File实际就是一个完整的倒排索引</li><li>Segment Memory—-倒排索引前面说过是基于关键字的，Lucene在4.0后会将所有关键字以FST这种数据结构的方式将所有关键字在启动的时候全量加载到内存，加快查询速度，官方建议至少留系统一半内存给Lucene</li><li>各类缓存—-Filter Cache、Field Cache、Indexing Cache等，用于提升查询分析性能，例如Filter Cache用于缓存使用过的Filter的结果集</li><li>Cluter State Buffer—-ElasticSearch被设计为每个Node都可以响应用户请求，因此每个Node的内存中都包含有一份集群状态的拷贝，一个规模很大的集群这个状态信息可能会非常大</li></ul></li><li><p>读写之间有延迟，写入的数据差不多1s样子会被读取到，这也正常，写入的时候自动加入这么多索引肯定影响性能</p></li><li><p>数据结构灵活性不高，ElasticSearch这个东西，字段一旦建立就没法修改类型了，假如建立的数据表某个字段没有加全文索引，想加上，那么只能把整个表删了再重建</p></li></ul><p>因此，搜索型NoSql最适用的场景就是<strong>有条件搜索尤其是全文搜索的场景</strong>，作为关系型数据库的一种替代方案。</p><p>另外，搜索型数据库还有一种特别重要的应用场景。我们可以想，一旦对数据库做了分库分表后，原来可以在单表中做的聚合操作、统计操作是否统统失效？例如我把订单表分16个库，1024张表，那么订单数据就散落在1024张表中，我想要统计昨天浙江省单笔成交金额最高的订单是哪笔如何做？我想要把昨天的所有订单按照时间排序分页展示如何做？<strong>这就是搜索型NoSql的另一大作用了，我们可以把分表之后的数据统一打在搜索型NoSql中，利用搜索型NoSql的搜索与聚合能力完成对全量数据的查询</strong>。</p><p>至于为什么把它放在KV型NoSql后面作为第二个写呢，因为通常搜索型NoSql也会作为一层前置缓存，来对关系型数据库进行保护。</p><h3 id="列式NoSql（代表—-HBase）"><a href="#列式NoSql（代表—-HBase）" class="headerlink" title="列式NoSql（代表—-HBase）"></a><strong>列式NoSql（代表—-HBase）</strong></h3><p>列式NoSql，大数据时代最具代表性的技术之一了，以HBase为代表。</p><p>列式NoSql是基于列式存储的，那么什么是列式存储呢，列式NoSql和关系型数据库一样都有主键的概念，区别在于关系型数据库是按照行组织的数据：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/f84ad4f6/6.png" alt="img"></p><p>看到每行有name、phone、address三个字段，这是行式存储的方式，且可以观察id = 2的这条数据，即使phone字段没有，它也是占空间的。</p><p>列式存储完全是另一种方式，它是按每一列进行组织的数据：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/f84ad4f6/7.png" alt="img"></p><p><img src="https://img2018.cnblogs.com/blog/801753/201908/801753-20190810184238996-511911560.png" alt="img"></p><p>这么做有什么好处呢？大致有以下几点：</p><ul><li>查询时只有指定的列会被读取，不会读取所有列</li><li>存储上节约空间，Null值不会被存储，一列中有时候会有很多重复数据（尤其是枚举数据，性别、状态等），这类数据可压缩，行式数据库压缩率通常在3:1<del>5:1之间，列式数据库的压缩率一般在8:1</del>30:1左右</li><li>列数据被组织到一起，一次磁盘IO可以将一列数据一次性读取到内存中</li></ul><p>第二点说到了数据压缩，什么意思呢，以比较常见的字典表压缩方式举例：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/f84ad4f6/8.jpg" alt="img"></p><p>自己看图理解一下，应该就懂了。 </p><p>接着继续讲讲优缺点，列式NoSql，以HBase为代表的，优点为：</p><ul><li>海量数据无限存储，PB级别数据随便存，底层基于HDFS（Hadoop文件系统），数据持久化</li><li>读写性能好，只要没有滥用造成数据热点，读写基本随便玩</li><li>横向扩展在关系型数据库及非关系型数据库中都是最方便的之一，只需要添加新机器就可以实现数据容量的线性增长，且可用在廉价服务器上，节省成本</li><li>本身没有单点故障，可用性高</li><li>可存储结构化或者半结构化的数据</li><li>列数理论上无限，HBase本身只对列族数量有要求，建议1~3个</li></ul><p>说了这么多HBase的优点，又到了说HBase缺点的时候了：</p><ul><li>HBase是Hadoop生态的一部分，因此它本身是一款比较重的产品，依赖很多Hadoop组件，数据规模不大没必要用，运维还是有点复杂的</li><li>KV式，不支持条件查询，或者说条件查询非常非常弱吧，HBase在Scan扫描一批数据的情况下还是提供了前缀匹配这种API的，条件查询除非定义多个RowKey做数据冗余</li><li>不支持分页查询，因为统计不了数据总数</li></ul><p>因此<strong>HBase比较适用于那种KV型的且未来无法预估数据增长量的场景</strong>，另外HBase使用还是需要一定的经验，主要体现在RowKey的设计上。</p><h3 id="文档型NoSql（代表—-MongoDB）"><a href="#文档型NoSql（代表—-MongoDB）" class="headerlink" title="文档型NoSql（代表—-MongoDB）"></a><strong>文档型NoSql（代表—-MongoDB）</strong></h3><p>坦白讲，根据我的工作经历，文档型NoSql我只有比较浅的使用经验，因此这部分只能结合之前的使用与网上的文章大致给大家介绍一下。</p><p>什么是文档型NoSql呢，文档型NoSql指的是将半结构化数据存储为文档的一种NoSql，文档型NoSql通常以JSON或者XML格式存储数据，因此文档型NoSql是没有Schema的，由于没有Schema的特性，我们可以随意地存储与读取数据，因此文档型NoSql的出现是<strong>解决关系型数据库表结构扩展不方便的问题的</strong>。</p><p>MongoDB是文档型NoSql的代表产品，同时也是所有NoSql产品中的明星产品之一，因此这里以MongoDB为例。按我的理解，作为文档型NoSql，MongoDB是一款完全和关系型数据库对标的产品，就我们从存储上来看：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/f84ad4f6/9.png" alt="img"></p><p>看到，关系型数据库是按部就班地每个字段一列存，在MongDB里面就是一个JSON字符串存储。关系型数据可以为name、phone建立索引，MongoDB使用createIndex命令一样可以为列建立索引，建立索引之后可以大大提升查询效率。其他方面而言，就大的基本概念，二者之间基本也是类似的：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/f84ad4f6/10.png" alt="img"></p><p>因此，对于MongDB，我们只要理解成一个Free-Schema的关系型数据库就完事了，它的优缺点比较一目了然，优点：</p><ul><li>没有预定义的字段，扩展字段容易</li><li>相较于关系型数据库，读写性能优越，命中二级索引的查询不会比关系型数据库慢，对于非索引字段的查询则是全面胜出</li></ul><p>缺点在于：</p><ul><li>不支持事务操作，虽然Mongodb4.0之后宣称支持事务，但是效果待观测</li><li>多表之间的关联查询不支持（虽然有嵌入文档的方式），join查询还是需要多次操作</li><li>空间占用较大，这个是MongDB的设计问题，空间预分配机制 + 删除数据后空间不释放，只有用db.repairDatabase()去修复才能释放</li><li>目前没发现MongoDB有关系型数据库例如MySql的Navicat这种成熟的运维工具</li></ul><p>总而言之，MongDB的使用场景很大程度上可以对标关系型数据库，但是比较适合处理那些没有join、没有强一致性要求且表Schema会常变化的数据。</p><h2 id="总结：数据库与NoSql及各种NoSql间的对比"><a href="#总结：数据库与NoSql及各种NoSql间的对比" class="headerlink" title="总结：数据库与NoSql及各种NoSql间的对比"></a><strong>总结：数据库与NoSql及各种NoSql间的对比</strong></h2><p>最后一部分，做一个总结，本文归根到底是两个话题：</p><ul><li>何时选用关系型数据库，何时选用非关系型数据库</li><li>选用非关系型数据库，使用哪种非关系型数据库</li></ul><p>首先是第一个话题，关系型数据库与非关系型数据库的选择，在我理解里面无非就是两点考虑：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/f84ad4f6/11.png" alt="img"></p><p>第一点，不多解释应该都理解，非关系型数据库都是通过牺牲了ACID特性来获取更高的性能的，假设两张表之间有比较强的一致性需求，那么这类数据是不适合放在非关系型数据库中的。</p><p>第二点，核心数据不走非关系型数据库，例如用户表、订单表，但是这有一个前提，就是这一类核心数据会有多种查询模式，例如用户表有ABCD四个字段，可能根据AB查，可能根据AC查，可能根据D查，假设核心数据，但是就是个KV形式，比如用户的聊天记录，那么HBase一存就完事了。</p><p>这几年的工作经验来看，非核心数据尤其是日志、流水一类中间数据千万不要写在关系型数据库中，这一类数据通常有两个特点：</p><ul><li>写远高于读</li><li>写入量巨大</li></ul><p>一旦使用关系型数据库作为存储引擎，将大大降低关系型数据库的能力，正常读写QPS不高的核心服务会受这一类数据读写的拖累。</p><p>接着是第二个问题，如果我们使用非关系型数据库作为存储引擎，那么如何选型？其实上面的文章基本都写了，这里只是做一个总结（所有的缺点都不会体现事务这个点，因为这是所有NoSql相比关系型数据库共有的一个问题）：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/f84ad4f6/12.png" alt="img"></p><p>但是这里特别说明，<strong>选型一定要结合实际情况而不是照本宣科</strong>，比如：</p><ul><li>企业发展之初，明明一个关系型数据库就能搞定且支撑一年的架构，搞一套大而全的技术方案出来</li><li>有一些数据条件查询多，更适合使用ElasticSearch做存储降低关系型数据库压力，但是公司成本有限，这种情况下这类数据可以尝试继续使用关系型数据库做存储</li><li>有一类数据格式简单，就是个KV类型且增长量大，但是公司没有HBase这方面的人才，运维上可能会有一定难度，出于实际情况考虑，可先用关系型数据库顶一阵子</li></ul><p>所以，如果不考虑实际情况，虽然合适有些存储引擎更加合适，但是强行使用反而适得其反，总而言之，适合自己的才是最好的。</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;&lt;strong&gt;前言&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;你是否在为系统的数据库来一波大流量就几乎打满CPU，日常CPU居高不下烦恼？你是否在各种NoSql间纠结不定，到底该选用那种最好？今天的你就是昨天的我，这也是写这篇文章的初衷。&lt;/p&gt;
&lt;p&gt;这篇文章是我好几个月来一直想写的一篇文章，也是一直想学习的一个内容，作为互联网从业人员，我们要知道关系型数据库（MySql、Oracle）无法满足我们对存储的所有要求，因此对底层存储的选型，对每种存储引擎的理解非常重要。同时也由于过去一段时间的工作经历，对这块有了一些更多的思考，想通过自己的总结把这块写出来分享给大家。&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="Sql" scheme="https://wandouduoduo.github.io/tags/Sql/"/>
    
  </entry>
  
  <entry>
    <title>Opensips+RTPEngine+FreeSwitch实现FS高可用</title>
    <link href="https://wandouduoduo.github.io/articles/ec271ad5.html"/>
    <id>https://wandouduoduo.github.io/articles/ec271ad5.html</id>
    <published>2021-01-14T03:26:59.000Z</published>
    <updated>2021-01-14T13:16:44.981Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/ec271ad5/1.png" alt="image.png"></p><a id="more"></a><h2 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h2><p><strong>对于初学者，整个架构涉及的知识点很多，配置项复杂，建议使用下面的调试方法：</strong></p><ol><li>保证UA直连freeswitch 已经都正常通话且有声音，这也是本文的前提</li><li>软电话注册正常</li><li>FS直接originate 到软电话 playback一段录音能听到声音</li><li>FS直接originate 到软电话 echo能听到声音</li><li>webrtc 使用ws 注册正常，重复3、4 步骤</li><li>互拨测试，每一阶段不正常使用chrome的debug和抓包查看SIP、SDP、ICE是否正常：<ul><li>软电话-&gt;软电话</li><li>软电话-&gt;webrtc</li><li>webrtc-&gt;软电话</li><li>webrtc-&gt;webrtc</li></ul></li><li>webrtc从ws 切换到wss，重复上面的2、3、4、5、6步骤。</li></ol><h4 id="熟练使用抓包工具"><a href="#熟练使用抓包工具" class="headerlink" title="熟练使用抓包工具"></a>熟练使用抓包工具</h4><ol><li>chrome 调试模式，可以查看websocket的每一个frame内容</li><li>软电话可以使用Wireshark 之类工具抓包查看内容</li><li>不确定声音问题时可以抓包查看是否有持续的UDP包收到或者发送。</li></ol><h2 id="经历历程"><a href="#经历历程" class="headerlink" title="经历历程"></a>经历历程</h2><ul><li>最初是想UA 经过 opensips转发 REGISTER 后直接在fs保存穿透后的地址，UA连上Opensips之后将自己的地址经过转发传给FS1存储，这样是不是FS1可以直接通过contact找到坐席了呢？<code>三者在同一个局域网是可以的</code>，但是如果op和fs在外网，这是UA链接op就会涉及到NAT打洞的相关问题，即使FS保存了UA打洞后的ip和端口，由于NAT的限制，该端口可能只能UA和OP能够使用，FS是不能够使用的（但是不同的NAT环境可能又可以，但是我们不能指望用户的环境是最优环境）。<br><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/ec271ad5/2.png" alt="image.png"></li></ul><p>这里有一定的联想：<code>是否有一种可以通过一种keepalive的机制随时监控多台fs的状态，UA发送SIP时通过某个接口实时获取可用的一台FS主机IP，实现客户端级别的高可用。这里后面想了想：首先如果一台fs宕机则一半的客户端需要重新登录，其次比如INVITE失败不能自动重试其他机器。</code></p><ul><li>那么使用使用op转发，fs 用户的contact 保存 op 的地址。<ul><li>坐席呼叫坐席,INVITE消息流转：<br>UA1 ——&gt; OpenSips ——-&gt; FS ——-&gt; OpenSips ——&gt; UA2</li><li>FS直接originate：<br>FS —-(udp)—-&gt; OpenSips ——-(ws)—-&gt; UA</li></ul></li><li>保存上op的地址之后，对于软电话其实到这里注册已经可以了，接下来是声音。</li><li>发现从fs直接<code>originate user/1000 &amp;echo()</code>是没有声音的，通过抓包会发现UA收到的INVITE的SDP信息有问题(查看o=的IP)，可能会是FS的内网地址。<br>这里直接在opensips的脚本中判断从内部收到的INVITE，fix_nated_sdp到fs的外网IP即可，参考：<a href="https://opensips.org/pipermail/users/2013-August/026471.html" rel="noopener" target="_blank">https://opensips.org/pipermail/users/2013-August/026471.html</a></li><li>软电话一切调通后开始测试webrtc，使用web登录1000 账号之后显示登录成功，但是<code>originate user/1000 &amp;echo()</code>会直接失败，并且开始siptrace也不显示有任何sip发送出去，猜测<code>U-&gt;O 注册时的contact带有“transport=ws”，如果不删除，在FS保存时也会保存transport=ws，使得FS以为这是一个web client，于是从FS呼叫用户时会向Opensips 的5060端口发送websocket请求，导致根本无法呼出（本来应该是udp通讯）</code></li><li>【最终采用的方案】那么就删除“transport=ws”（目前是直接操作contact字段字符串，暂时没有更好的方案），这样在FS保存的就没有了（OP自己保存的信息依然知道是ws，要问OP怎么保存：save(“location”) + lookup()），FS会使用udp和OP通讯，信令正常，但是发送到web UA的时候会报“SIP/2.0 603 Failed to get local SDP”，原因是FS发送的INVITE中的SDP 音频编码不包含 Chrome 用的 SAVPF，说白了就是FS发的是一个给软电话的请求，web client处理不了。</li><li>解决：originate 需要加上 “originate {media_webrtc=true}user/8800 &amp;echo” 这样就会当成一个web发送请求，但是这样如果一个FS有软电话也有web，不是很好区别（因为对于fs来说不知道客户端类型。如果是软电话但是加上了media_webrtc=true，会报IP/2.0 488 Not Acceptable Here）</li><li>无法在OP中做判断然后修改，有些加密信息需要fs生成</li><li>【最终采用的方案】使用RTPEngine 协商双方的编码以及转码</li><li>注意SDP对应的IP，如果是websocket 还需要有ICE的candidate ip 协商过程。此外如果rtpengine所在机器有内网和公网ip还需要在offer中指定方向。</li></ul><h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><ul><li>websocket连接opensips出现自动登出的问题。fs返回的REGISTER的OK中的contact包含的expire时间时180秒，也就是UA会在180秒内重新发起REGITER进行续期。但是opensips的websocket连接时间为120秒，否则连接会被关闭。<br>解决：1、调小FS的<code>sip-force-expires</code>,或者2、调整opensips的<code>tcp_connection_lifetime</code>参数大于180秒，或者3、<code>modparam(&quot;registrar&quot;, &quot;tcp_persistent_flag&quot;, &quot;TCP_PERSISTENT&quot;)</code>并且<code>setflag(TCP_PERSISTENT);</code>,设置超时时间为REGISTER中的exipre时间。</li></ul><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>（和顶部的官方推荐架构一样。。。。）</p><ul><li>opensips 仅作为消息转发，不负责语音通讯</li><li>使用rtpengine来进行rtp转发以及sdp的协商</li><li>一台opensips后对应多台freeswitch</li><li>opensips需要数据库存储相关负载以及保活信息</li><li>多台FS共用数据库</li><li>多台opensips间使用负载均衡中间件（阿里SLB，提供端口检测心跳）</li></ul><h2 id="开启端口-公网"><a href="#开启端口-公网" class="headerlink" title="开启端口(公网)"></a>开启端口(公网)</h2><ul><li>Opensips 开启：7443(wss) 5060(UDP)</li><li>Freeswitch 开启RTP端口段（线路方侧） 5080（线路方SIP） 5060(理论上不需要开启公网，但是出现了Opensip转发BYE通过公网转发给FS，待研究)</li><li>RTPengine 开启RTP端口段（坐席侧）</li></ul><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="FS安装"><a href="#FS安装" class="headerlink" title="FS安装"></a>FS安装</h3><p>略，修改多台FS的数据库指向同一mysql，用于共享数据。</p><h3 id="RTPEngine安装"><a href="#RTPEngine安装" class="headerlink" title="RTPEngine安装"></a>RTPEngine安装</h3><p><a href="https://github.com/sipwise/rtpengine" rel="noopener" target="_blank">https://github.com/sipwise/rtpengine</a></p><h3 id="Opensips安装"><a href="#Opensips安装" class="headerlink" title="Opensips安装"></a>Opensips安装</h3><ul><li>下载源码并选择模块</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost /]<span class="comment"># cd /usr/local/src </span></span><br><span class="line">[root@localhost src]<span class="comment"># git clone https://github.com/OpenSIPS/opensips.git -b 2.4 opensips-2.4</span></span><br><span class="line">[root@localhost src]<span class="comment"># cd opensips-2.4</span></span><br><span class="line">[root@localhost src]<span class="comment"># yum install mysql mysql-devel gcc gcc-c++ ncurses-devel flex bison</span></span><br><span class="line">[root@localhost opensips-2.4]<span class="comment"># make all</span></span><br></pre></td></tr></table></figure><p>如果这里报错，停止，装好依赖再make all</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opensips-2.4]# make menuconfig</span><br></pre></td></tr></table></figure><p>进入这个菜单后，根据需要使用这个工具（左右键进入返回，空格键选中，回车键确定），但有个必须的是进入<code>Configure Compile Options</code> —&gt; Configure Excluded Modules，按空格选中[*] db_mysql，返回上一级，Save Chnahes, 返回主菜单选择<code>Compile And Install OpenSIPS</code>编译安装即可。完成后会回到这个界面，保存退出。</p><ul><li>重要目录</li></ul><h3 id="配置文件目录"><a href="#配置文件目录" class="headerlink" title="配置文件目录"></a>配置文件目录</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost /]<span class="comment"># ls /usr/local/etc/opensips/</span></span><br><span class="line">opensips.cfg  opensips.cfg.sample  opensipsctlrc  opensipsctlrc.sample  osipsconsolerc  osipsconsolerc.sample  scenario_callcenter.xml</span><br></pre></td></tr></table></figure><h3 id="运行程序目录"><a href="#运行程序目录" class="headerlink" title="运行程序目录"></a>运行程序目录</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost /]<span class="comment"># ls /usr/local/sbin</span></span><br><span class="line">curses.out  opensips  opensipsctl  opensipsdbctl  opensipsunix  osipsconfig  osipsconsole</span><br></pre></td></tr></table></figure><h3 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost /]<span class="comment"># cd /usr/local/etc/opensips/</span></span><br><span class="line">[root@localhost opensips]<span class="comment"># vi opensipsctlrc</span></span><br></pre></td></tr></table></figure><h3 id="修改后的配置"><a href="#修改后的配置" class="headerlink" title="修改后的配置"></a>修改后的配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">SIP_DOMAIN=192.168.0.191</span><br><span class="line">DBENGINE=MYSQL</span><br><span class="line">DBPORT=3306</span><br><span class="line">DBHOST=localhost</span><br><span class="line">DBNAME=opensips</span><br><span class="line">DB_PATH=<span class="string">"/usr/local/etc/opensips/dbtext"</span></span><br><span class="line">DBRWUSER=opensips</span><br><span class="line">DBRWPW=<span class="string">"opensipsrw"</span></span><br></pre></td></tr></table></figure><p>这里主要是mysql连接信息，保证能正常连接即可。还有一个SIP_DOMAIN能连接到本服务的域名或者IP地址即可。</p><h3 id="修改opensips-cfg"><a href="#修改opensips-cfg" class="headerlink" title="修改opensips.cfg"></a>修改opensips.cfg</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opensips]<span class="comment"># vi opensips.cfg</span></span><br></pre></td></tr></table></figure><h3 id="修改配置项"><a href="#修改配置项" class="headerlink" title="修改配置项"></a>修改配置项</h3><p>注意，下面的配置文件只是简单的示例，很多功能比如 save location、wss、rtpengine没有使用到，鉴于公司项目原因，暂时不公开脚本。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line">log_level=3  #老版本日志级别参数为debug，级别范围1-4，建议生产上设置为1，为3或者4时将产生大量日志，磁盘空间很快就不够了</span><br><span class="line">sip_warning=0</span><br><span class="line">log_stderror=yes</span><br><span class="line">log_facility=LOG_LOCAL0</span><br><span class="line">log_name=&quot;opensips&quot;</span><br><span class="line">#debug_mode=yes#开启时需要直接opensips 启动前端模式</span><br><span class="line">children=2</span><br><span class="line">dns_try_ipv6=no</span><br><span class="line">auto_aliases=no</span><br><span class="line">listen=udp:10.0.11.84:5060</span><br><span class="line">mpath=&quot;/usr/local//lib64/opensips/modules/&quot;</span><br><span class="line">#fork=no</span><br><span class="line">loadmodule &quot;db_mysql.so&quot;</span><br><span class="line">loadmodule &quot;signaling.so&quot;</span><br><span class="line">loadmodule &quot;sl.so&quot;</span><br><span class="line">loadmodule &quot;tm.so&quot;</span><br><span class="line">loadmodule &quot;rr.so&quot;</span><br><span class="line">loadmodule &quot;uri.so&quot;</span><br><span class="line">loadmodule &quot;dialog.so&quot;</span><br><span class="line">loadmodule &quot;maxfwd.so&quot;</span><br><span class="line">loadmodule &quot;textops.so&quot;</span><br><span class="line">loadmodule &quot;mi_fifo.so&quot;</span><br><span class="line">loadmodule &quot;dispatcher.so&quot;</span><br><span class="line">loadmodule &quot;load_balancer.so&quot;</span><br><span class="line">loadmodule &quot;sipmsgops.so&quot;</span><br><span class="line">loadmodule &quot;proto_udp.so&quot;</span><br><span class="line">modparam(&quot;mi_fifo&quot;, &quot;fifo_name&quot;, &quot;/tmp/opensips_fifo&quot;)</span><br><span class="line">modparam(&quot;dialog&quot;, &quot;db_mode&quot;, 1)</span><br><span class="line">modparam(&quot;dialog&quot;, &quot;db_url&quot;,&quot;mysql://root:root@10.0.11.84/opensips&quot;)</span><br><span class="line">modparam(&quot;rr&quot;, &quot;enable_double_rr&quot;, 1)</span><br><span class="line">modparam(&quot;rr&quot;, &quot;append_fromtag&quot;, 1)</span><br><span class="line">modparam(&quot;tm&quot;, &quot;fr_timer&quot;, 2)</span><br><span class="line">modparam(&quot;dispatcher&quot;, &quot;ds_ping_method&quot;, &quot;OPTIONS&quot;)</span><br><span class="line">modparam(&quot;dispatcher&quot;, &quot;ds_ping_interval&quot;, 5)</span><br><span class="line">modparam(&quot;dispatcher&quot;, &quot;ds_probing_threshhold&quot;, 2)</span><br><span class="line">modparam(&quot;dispatcher&quot;, &quot;ds_probing_mode&quot;, 1)</span><br><span class="line">modparam(&quot;dispatcher&quot;, &quot;db_url&quot;,&quot;mysql://root:root@10.0.11.84/opensips&quot;)</span><br><span class="line">modparam(&quot;load_balancer&quot;, &quot;db_url&quot;,&quot;mysql://root:root@10.0.11.84/opensips&quot;)</span><br><span class="line">modparam(&quot;load_balancer&quot;, &quot;probing_method&quot;, &quot;OPTIONS&quot;)</span><br><span class="line">modparam(&quot;load_balancer&quot;, &quot;probing_interval&quot;, 5)</span><br><span class="line">route&#123;</span><br><span class="line">        if (!mf_process_maxfwd_header(&quot;10&quot;)) &#123;</span><br><span class="line">                sl_send_reply(&quot;483&quot;,&quot;Too Many Hops&quot;);</span><br><span class="line">                exit;</span><br><span class="line">        &#125;</span><br><span class="line">        if (!has_totag()) &#123;</span><br><span class="line">                record_route();</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">                loose_route();</span><br><span class="line">                t_relay();</span><br><span class="line">                exit;</span><br><span class="line">        &#125;</span><br><span class="line">        if (is_method(&quot;CANCEL&quot;)) &#123;</span><br><span class="line">                if ( t_check_trans() )</span><br><span class="line">                        t_relay();</span><br><span class="line">                exit;</span><br><span class="line">        &#125;</span><br><span class="line">        if (is_method(&quot;INVITE&quot;)) &#123;</span><br><span class="line">                if ( !lb_start(&quot;1&quot;,&quot;pstn&quot;)) &#123;</span><br><span class="line">                        send_reply(&quot;500&quot;,&quot;No Destination available&quot;);</span><br><span class="line">                        exit;</span><br><span class="line">                &#125;</span><br><span class="line">                t_on_failure(&quot;GW_FAILOVER&quot;);</span><br><span class="line">                #if (!load_balance(&quot;1&quot;,&quot;pstn&quot;,&quot;1&quot;)) &#123;</span><br><span class="line">                #        send_reply(&quot;503&quot;,&quot;Service Unavailable&quot;);</span><br><span class="line">                #        exit;</span><br><span class="line">                #&#125;</span><br><span class="line">        &#125;</span><br><span class="line">        else if (is_method(&quot;REGISTER&quot;)) &#123;</span><br><span class="line">                if (!ds_select_dst(&quot;1&quot;, &quot;0&quot;)) &#123;</span><br><span class="line">                        send_reply(&quot;503&quot;,&quot;Service Unavailable&quot;);</span><br><span class="line">                        exit;</span><br><span class="line">                &#125;</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">                send_reply(&quot;405&quot;,&quot;Method Not Allowed&quot;);</span><br><span class="line">                exit;</span><br><span class="line">        &#125;</span><br><span class="line">        if (!t_relay()) &#123;</span><br><span class="line">                sl_reply_error();</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line">failure_route[GW_FAILOVER] &#123;</span><br><span class="line">        if (t_was_cancelled()) &#123;</span><br><span class="line">                exit;</span><br><span class="line">        &#125;</span><br><span class="line">        # failure detection with redirect to next available trunk</span><br><span class="line">        if (t_check_status(&quot;(408)|([56][0-9][0-9])&quot;)) &#123;</span><br><span class="line">                xlog(&quot;Failed trunk $rd/$du detected \n&quot;);</span><br><span class="line">                if ( lb_next() ) &#123;</span><br><span class="line">                        t_on_failure(&quot;GW_FAILOVER&quot;);</span><br><span class="line">                        t_relay();</span><br><span class="line">                        exit;</span><br><span class="line">                &#125;</span><br><span class="line">                send_reply(&quot;500&quot;,&quot;All GW are down&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里listen如果你不确定该怎么填的话，运行下面的命令看一下，一般是本机IP。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opensips]<span class="comment"># ip route get 8.8.8.8 | head -n +1 | tr -s " " | cut -d " " -f 7</span></span><br></pre></td></tr></table></figure><h3 id="部分关键脚本"><a href="#部分关键脚本" class="headerlink" title="部分关键脚本"></a>部分关键脚本</h3><ul><li>删除<code>transport=wss</code></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$var(ct) = $ct;</span><br><span class="line">$var(str) = &apos;;transport=wss&apos;;</span><br><span class="line">$var(pos) = $(var(ct)&#123;s.index, $var(str)&#125;);</span><br><span class="line">$var(end) = $var(pos) + $(var(str)&#123;s.len&#125;);</span><br><span class="line">$var(res) = $(var(ct)&#123;s.substr, 0, $var(pos)&#125;) + $(var(ct)&#123;s.substr, $var(end), 0&#125;);</span><br><span class="line">remove_hf(&quot;Contact&quot;);</span><br><span class="line">append_hf(&quot;Contact: $var(res)\r\n&quot;);</span><br></pre></td></tr></table></figure><h3 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opensips]<span class="comment"># cd /usr/local/sbin</span></span><br><span class="line">[root@localhost sbin]<span class="comment"># opensipsdbctl create</span></span><br><span class="line">……</span><br><span class="line">INFO: creating database opensips ...</span><br><span class="line">INFO: Using table engine MyISAM.</span><br><span class="line">INFO: Core OpenSIPS tables successfully created.</span><br><span class="line">Install presence related tables? (Y/n): y</span><br><span class="line">INFO: creating presence tables into opensips ...</span><br><span class="line">INFO: Presence tables successfully created.</span><br><span class="line">Install tables <span class="keyword">for</span> </span><br><span class="line">    b2b</span><br><span class="line">    cachedb_sql</span><br><span class="line">    call_center</span><br><span class="line">    carrierroute</span><br><span class="line">    cpl</span><br><span class="line">    domainpolicy</span><br><span class="line">    emergency</span><br><span class="line">    fraud_detection</span><br><span class="line">    freeswitch_scripting</span><br><span class="line">    imc</span><br><span class="line">    registrant</span><br><span class="line">    siptrace</span><br><span class="line">    userblacklist</span><br><span class="line">? (Y/n): y</span><br><span class="line">INFO: creating extra tables into opensips ...</span><br><span class="line">INFO: Extra tables successfully created.</span><br></pre></td></tr></table></figure><p>之后就是根据提示傻瓜操作创建数据库就好了，如果前面的mysql环境没装好，数据库连接有问题，这里就会报错，如果提示类似下面的编码问题，输入latin1即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WARNING: Your current default mysql characters set cannot be used to create DB. Please choice another one from the following list:</span><br></pre></td></tr></table></figure><p>这一步完成之后，会在数据库新建一个opensips（名字是在上面的配置文件里设置的）的数据库。</p><h3 id="将日志输出到指定文件"><a href="#将日志输出到指定文件" class="headerlink" title="将日志输出到指定文件"></a>将日志输出到指定文件</h3><p>在/etc/rsyslog.conf追加OpenSIPS日志输出配置。（注：OpenSIPS配置文件中log_stderror和debug_mode需设置成no，否则可能不能输出单独日志）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">"local0.*                        /var/log/opensips.log"</span> &gt;&gt;/etc/rsyslog.conf</span><br></pre></td></tr></table></figure><p>修改配置文件后需要重启日志服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service rsyslog restart</span><br></pre></td></tr></table></figure><h3 id="启动opensips"><a href="#启动opensips" class="headerlink" title="启动opensips"></a>启动opensips</h3><ul><li><p>启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost sbin]<span class="comment"># opensipsctl start</span></span><br><span class="line">INFO: Starting OpenSIPS : </span><br><span class="line">INFO: started (pid: 26051)</span><br></pre></td></tr></table></figure></li><li><p>查看opensips进程</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost sbin]<span class="comment"># ps -aux | grep opensips</span></span><br><span class="line">root      3504  0.0  0.4  70536  4420 ?        S    3月07   0:00 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3505  3.1  0.1  70776  1368 ?        S    3月07  12:35 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3506  0.1  0.0  70536   476 ?        S    3月07   0:29 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3507  0.0  0.0  70536   688 ?        S    3月07   0:08 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3508  0.0  0.2  70536  2396 ?        S    3月07   0:03 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3509  0.0  0.1  70536  1424 ?        S    3月07   0:01 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3510  0.0  0.1  70536  1912 ?        S    3月07   0:01 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3511  0.0  0.2  70536  2392 ?        S    3月07   0:01 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br><span class="line">root      3512  0.0  0.1  70536  1164 ?        S    3月07   0:01 /usr/<span class="built_in">local</span>/sbin/opensips -P /var/run/opensips.pid</span><br></pre></td></tr></table></figure></li></ul><h2 id="配置Opensips"><a href="#配置Opensips" class="headerlink" title="配置Opensips"></a>配置Opensips</h2><h3 id="添加负载节点"><a href="#添加负载节点" class="headerlink" title="添加负载节点"></a>添加负载节点</h3><p>在数据库添加两个负载节点信息，地址对应多个FS的地址等<br>添加后可以通过<code>opensipsctl fifo lb_reload</code> 进行reload</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`opensips`</span>.<span class="string">`load_balancer`</span> (<span class="string">`id`</span>, <span class="string">`group_id`</span>, <span class="string">`dst_uri`</span>, <span class="string">`resources`</span>, <span class="string">`probe_mode`</span>, <span class="string">`description`</span>) <span class="keyword">VALUES</span> (<span class="string">'1'</span>, <span class="string">'1'</span>, <span class="string">'sip:172.16.100.10'</span>, <span class="string">'vm=100;conf=100;transc=100;pstn=500'</span>, <span class="string">'1'</span>, <span class="string">'FS1'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="string">`opensips`</span>.<span class="string">`load_balancer`</span> (<span class="string">`id`</span>, <span class="string">`group_id`</span>, <span class="string">`dst_uri`</span>, <span class="string">`resources`</span>, <span class="string">`probe_mode`</span>, <span class="string">`description`</span>) <span class="keyword">VALUES</span> (<span class="string">'2'</span>, <span class="string">'1'</span>, <span class="string">'sip:172.16.100.11'</span>, <span class="string">'vm=100;conf=100;transc=100;pstn=500'</span>, <span class="string">'1'</span>, <span class="string">'FS2'</span>);</span><br></pre></td></tr></table></figure><h3 id="添加FreeSWITCH到调度列表-转发SIP消息的路由"><a href="#添加FreeSWITCH到调度列表-转发SIP消息的路由" class="headerlink" title="添加FreeSWITCH到调度列表(转发SIP消息的路由)"></a>添加FreeSWITCH到调度列表(转发SIP消息的路由)</h3><p>执行以下命令将两个节点添加到调度列表，（这里添加调度器的命令和1.7版本是有区别的）<br>添加后可以通过<code>opensipsctl fifo ds_reload</code> 进行reload</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">opensipsctl dispatcher addgw 1 sip:172.16.100.10 5060 0 50 <span class="string">'FS1'</span> <span class="string">'节点1'</span></span><br><span class="line">opensipsctl dispatcher addgw 1 sip:172.16.100.11 5060 0 50 <span class="string">'FS2'</span> <span class="string">'节点2'</span></span><br></pre></td></tr></table></figure><p>添加调度列表成功后，在两个FreeSWITCH的控制通过siptrace on打开sip消息跟踪即可看到OpenSIPS节点不停在跟FreeSWITCH通过”OPTIONS“消息进行握手。</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/ec271ad5/1.png&quot; alt=&quot;image.png&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.github.io/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务搭建" scheme="https://wandouduoduo.github.io/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="Linux" scheme="https://wandouduoduo.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>做好运维真的不容易</title>
    <link href="https://wandouduoduo.github.io/articles/71d403c4.html"/>
    <id>https://wandouduoduo.github.io/articles/71d403c4.html</id>
    <published>2020-12-31T09:09:04.000Z</published>
    <updated>2020-12-31T09:17:30.024Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>以前和一个项目经理沟通时，提到能否提前半天将变更申请提交过来，而这位项目经理很不理解的看着我问：“你们运维不就是在生产环境部署个程序嘛，这么简单的工作还需要提前半天？而且你们不懂程序，也评审不出什么吧？”。运维这么多年来，听到对运维工作抱有这种认识和看法的人很多。它侧面反映了企业中其他团队团队对运维的认识往往局限于一些简单操作性的工作。例如：应用服务故障时重启、应用配置变更、增删改查数据或者所有软硬件使用问题等等。运维真的是这样吗？</p><a id="more"></a><p><strong>如何理解运维呢？</strong></p><p>百度百科对运维的定义是：企业 IT 部门采用相关的方法、手段、技术、制度、流程和文档等，对IT 软硬运行环境(软件环境、网络环境等)、IT 业务系统和 IT 运维人员进行的综合的管理。从定义中看，运维岗位是一个综合了技术和管理能力复合型岗位，并且需要掌握大量的方法论与技术栈，是这么一个角色。</p><p>运维就运维技术与资源可以狭义定义为“监、管、控”三点。技术与资源主要是支撑运维/运营的质量、效率和成本的平衡。以下简单摘录了运维的一些能力要求：</p><ul><li><strong>运维规范的落地</strong>：以ITIL、ISO20000、ITSS.1等方法论，结合外部监管及内部规范的落地；</li><li><strong>监管机构的要求落地</strong>：理解、快速响应、落地监管机构的管理要求；</li><li><strong>基本保障</strong>：配置、监控、应用发布、资源扩容、事件、问题等；</li><li><strong>基础能力</strong>：网络、服务器、操作系统、数据库、中间件、JVM、应用等基本使用与调优；</li><li><strong>业务服务能力</strong>：SLA，服务台、业务咨询、维护、经验库、等支持能力；</li><li><strong>可用性管理能力</strong>：巡检、业务系统连续性、可用性，基础架构及应用系统的高可用、备件冗余资源；</li><li><strong>风险、安全管理能力</strong>：操作、审计、监管风险，漏洞、攻击管控；</li><li><strong>故障管理能力</strong>：事件、问题管理水平与能力；</li><li><strong>持续交付能力</strong>：应用变更、基础资源、办公服务交付能力；</li><li><strong>主动优化能力</strong>：架构优化、性能响应效率、客户体验等</li><li><strong>应急演练</strong>：架构高可用、突发事件、业务故障的架构、方案、文档、人员熟练程度等</li><li><strong>业务支撑</strong>：数据维护、数据提取、参数维护等；</li><li><strong>运行分析能力</strong>：容量、性能、可用性分析等；</li><li><strong>运营能力</strong>：促进业务痛点的发现与解决、客户及业务业务体验等；</li><li><strong>成本控制</strong>：更好的评估人力、硬件、带宽、软件，节省成本；</li><li><strong>运维开发</strong>：运维自动化工具的建设，运维开发能力的培养；</li><li><strong>其它</strong></li></ul><p>不同企业需要运维的能力会有不同的扩展，同时上述能力要求的每一点展开来说都是一个复杂的技术栈。例如：<code>基础能力</code>中的linux操作系统内核优化，就让运维人员对技术能力的深度有了严格要求。要不你搞不定的。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/71d403c4/1.png" alt="图片"></p><p>说道这里肯定会有人说：上述技术栈的能力要求通常是存在于个别公司中，这种公司运维团队仍处在传统式运维阶段，并且自动化程度不高。的确理论上所有运维操作性、执行命令的工作都可以整合为经验，并通过自动化工具落地实现。现在大部分互联网企业对外都鼓吹说公司自动化运维工作覆盖面很高，己经开始迈向智能化，做到了AIOps，甚至提出了NoOps的解决方案等等。对于这些互联网公司的自动化对日常运维工作真实覆盖面暂时无法考证，但以我个人经验来看，至少金融企业的自动化覆盖面还有很长的路要走，并且肯定还会很大一部份工作很难自动化。毕竟工作类型太多，在有限的投入上只能集中精力去做投入产出比更高的运维自动化工作。下图以一个运维工具思维导图来简单列示一些常规的运维操作，可以看出其实很难有一套能解决所有运维操作的工具或平台。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/71d403c4/2.jpg" alt="img"></p><p>并且随着业务要求越来越高、规模越来越大、监管要求越来越严，纵使外部如何宣称自动化或智能化对运维人员经验、技术和管理能力替代，企业内的运维还需要认清实际情况，并结合企业整体战略定位，强调运维团队在运维管理与技术能力方面的广度和深度，再有侧重、分先后的逐步实现自动化。在未来相当长一段时间，企业的运维岗位仍是一个复杂、综合性比较强的工作岗。</p><h2 id="运维之痛"><a href="#运维之痛" class="headerlink" title="运维之痛"></a>运维之痛</h2><p>近年来互联网的飞速普及，运维技术也快速发展，各行业运维水平也得到了较大提升，同时运维圈技术分享也越来越开放，从国外google的SRE理念，到国内腾讯的蓝鲸、织云等平台，以及借助于各种运维专题的公众号和运维大会等等，有大量的互联网人、企业的运维团队进行分享。就对我的影响来说，萧田国的《运维 2.0：危机前的自我拯救》，将我头脑中零碎理解整合成一个概念，再接下来运维人员开始有了一些反思与自嘲，如下截图：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/71d403c4/3.jpg" alt="图片"></p><h3 id="团队之痛"><a href="#团队之痛" class="headerlink" title="团队之痛"></a><strong>团队之痛</strong></h3><p>前面讲到，在企业内部其它团队对运维的认识通常只是简单操作，出故障时才会想到，才回去找的团队。随着信息技术的发展与业务的发展，运维团队的痛点越来越明显，企业内对运维团队的不满声音也越来越多，反思一下原因，可分为外部客观原因和内部因素。</p><h4 id="外部原因"><a href="#外部原因" class="headerlink" title="外部原因"></a>外部原因</h4><p>当前在大数据的背景下，所有互联网企业的运维都面临着业务规模不断扩大，业务竞争越来越激烈，监管要求越来越严格，数据中心条件也越来越高，大量新技术、开源架构、平台或系统的引入取代了传统稳定系统架构的等等因素影响。</p><ul><li><strong>运维团队的角色</strong>：大部分运维团队都是一个技术支持部门，企业对运维团队的重视程度通常不如业务开发团队，更不用说是前端业务部门。这就造成了运维部门的规模和人员储备不大。像google在《google sre运维解密》一书中提到，由于google的数据中心规模急剧扩大，系统越来越复杂，而运维人员规模又跟不上，所以他们的运维团队采用组建sre的运维开发团队来实现自救。</li><li><strong>业务对运维服务质量的要求</strong>：互联网的发展，让现在越来越多的业务从线下走到了线上。 为了赢得更多用户的青睐和提高用户体验。一方面业务要求更多和体验更佳的业务性能；另一方面业务对应用发布的交付速度有了更高的要求。前者会产生更复杂的系统架构设计，后者需要更高效的应用发布迭代支持。但两者都会对系统响应效率和稳定性带来影响。</li><li><strong>外部监管要求：</strong>长期以来，为了防范金融风险，监管机构对金融企业保持强监管的方式，十九大后，监管对金融企业的信息技术的稳定性和规范性进一步加强。在强监管情况下，信息系统的稳定性有了进一步保证，但也给运维团队带来更高的要求，客观上也加大了工作量，并由于规范流程而带来的工作效率的下降。</li><li><strong>业务并发要求：</strong>用户量的激增和营销活动不断推出，需要系统具备更高的并发处理能力，架构不断引入大量分布式、开源架构来替代传统相对成熟稳定的架构来满足业务需要，这些变化都给运维的能力带来挑战。</li><li><strong>数据中心规模增大：</strong>数据中心的多中心建设，虚拟化上云，去中心化等等，分布式架构的引入也使得应用系统规模成倍的增加。</li></ul><h4 id="内部因素"><a href="#内部因素" class="headerlink" title="内部因素"></a>内部因素</h4><p>网上有一个调查数据，在整个运维成本的分配中，软硬件和网络设备的维护成本占 30%，维护服务成本占30%，而内部运维的人力成本则占了40%。这里的人力成本包括人员招聘、培训和流失等成本，如果将维护服务成本也纳入到人力成本上，则人力这一块的成本将上升为70%，影响这个人力成本的因素主要有：</p><ul><li><strong>运维能力模型：</strong>ITIL、ISO20000、ITSS.1是运维领域中比较成体系化的方法论（目前更为火爆的devops更倾向于是一种思路），其中只有ITSS.1提出了运维能力模型的概念，但在量化运维人员具体能力的实际操作上比较难落地。简单的说你很难判断一个运维人员如何做才是做得优，如何是中，如何差，而这些评价通常比较主观，这也客观影响了运维人员不断增加技能、优化工作效率的动力。</li><li><strong>运维规范化：</strong>团队扩大到一定规模，以口口相传的传授，结合个体责任心、工作习惯为主的工作方式很容易出现操作风险，且无法进行量化绩效管理，管理规范无法落地。</li><li><strong>运维精细化程度：</strong>运维团队通常是从纵向职能型的方式形成，这种方式能培养全能型、经验丰富的专家式人才，这些专家式人才利用经验能快速解决职责下的常规问题，且效率比较高，适合小型的团队。随着团队的不断壮大，面对的问题越来越复杂，技术要求越来越多，一方面人的精力有限，很多人不能满足这种专家式人才的要求；另一方面也会产生很多重复性的工作；同时对于人员流失带来的影响比较大。这时就需要将纵向工作精细化，再辅助横向人员对工作进行持续的优化。</li><li><strong>运维目标：</strong>运维的目标往往以被动式的目标为主，被动处理故障、被动解决问题、被动提供应用交付、被动节省成本等，这种被动式的运维目标导致计划性工作无法开展，缺乏持续不断的自我提高优化机制，主动提高效率、质量，降低成本，并由运维向主动运营目标去转变。</li><li><strong>自动化能力：</strong>IT软硬件体量庞大，且增长迅速，手工操作的机器任务太多；运维数据越来越多；故障定位越来越难，人工经验依赖高；监控手段不够及时、全面；应用发布、资源交付效率低下；没有主动的容量、性能分析、体验分析能力……这些都是常见的一些痛点。</li></ul><h3 id="个体之痛"><a href="#个体之痛" class="headerlink" title="个体之痛"></a>个体之痛</h3><p>​       作为运维人员同样面临不少痛点：工作时间、工作性质、工作压力、学习压力、职业发展等等，下面简单罗列：</p><ul><li><strong>7*24小时制的工作时间</strong>：运维人员的节假日是不完整的，通常节假日需要运维值班保障或在家通过VPN远程操作、甚至和家人团聚时还需要远程指导进行应急排障；运维人员工作性质不同其他人，为了不影响业务，应用的发布、基础设施的变更、演练等工作都会放到晚上，对客的业务系统还可能要安排到深夜凌晨。这种随时可能发生，随时处理的工作状态是其它人员所不具备的痛点。</li><li><strong>高度压力的工作</strong>：“如履薄冰”这个词很好的形容了运维的工作状态。因为任何一个生产操作都可能对业务带来影响，所以运维的操作必须十分细心谨慎。同时在运维故障处理时，需要面对来自业务、客户、开发、领导的各层压力，细心冷静的排除故障，是一个考研心理素质的高压工作。</li><li><strong>被动的工作</strong>：常有人形容运维就是一个“消防员”，常常被动救火，这个形容很贴切。在缺乏一些主动分析、优化、预测性的工作的背景下，运维团队的大部份工作常以被动为主，是负责应急救火、打扫战场、负责收尾的那群默默的人。</li><li><strong>对工作的认识</strong>：运维人通常会认为运维就是一个背锅侠的角色。像开发程序问题、硬件问题、系统软件问题、业务需求问题等等都需要运维去解决处理，而这些问题对业务可用性的影响也要运维来承担，这也是运维的跗骨之痛，很影响个人心情和工作积极性。</li><li><strong>职业压力</strong>：运维工作一方面主要要和机器或系统软件打交道，相对于开发、项目管理等IT岗位来说，转型机会的面比较窄；同时，运维岗位中重复操作性的工作占比较多，如缺乏引导容易让运维人员产生麻木的状态，失去持续改善的动力和积极性；另外运维需要掌握的技能和管理理念很多，这对于运维人员的学习能力也有很高要求。</li></ul><h2 id="自救"><a href="#自救" class="headerlink" title="自救"></a>自救</h2><h3 id="SRE"><a href="#SRE" class="headerlink" title="SRE"></a><strong>SRE</strong></h3><p>SRE这个名词最早是从《google sre 运维解密》一书中获得，全称是Site Reliability Engineering，翻译过来就是：站点可靠性工程师。google对SRE的职责描述是：确保站点的可用性。</p><p>为了达到这个目的，一方面他需要对站点涉及的系统、组件熟悉，也要关注生产运行时的状态，为此，他需要自研并维护很多工具和系统支撑系统的运行，比如自动化发布系统，监控系统，日志系统，服务器资源分配和编排等等。SRE是一个综合素质很高的全能手，能力进行分解主要有三块：</p><ul><li><strong>熟悉系统架构与运行状态</strong>：SRE需要懂服务器基础架构、操作系统、网络、中间件容器、常用编程语言、全局的架构意识、非常强的问题分析能力、极高的抗压能力（以便沉着高效地排障），他们还需要懂性能调优理论。为了保证系统架构的高可用，SRE甚至会有意识的破坏自己的系统，以提高系统可用性。</li><li><strong>熟悉运维涉及的管理方法</strong>：SRE需根据企业自身发展需要，清楚运维涉及的各项工作的流程方法论，比如故障处理、应用发布、可用性管理等等，SRE十分重视运维流程的持续改善，比如对故障的追根溯源，怀疑一切的方式持续改进。</li><li><strong>运维开发+产品经理</strong>：SRE在运行保障过程中的手段更加自动化，更高效，这种高效来源于自动化工具、监控工具的支撑，且他们还需要是这些工具的主要开发者，他们要不断优化和调整，使整个工具使用起来更加得心应手。为此SRE有一个一半一半理念，就是50%用于日常保障，50%用于项目性的工作，这个项目性的工作主要体现在运维开发与运维产品经理的角色。</li></ul><h3 id="运维开发"><a href="#运维开发" class="headerlink" title="运维开发"></a>运维开发</h3><p>运维开发主要体现在运维工具层面，不同的团队有不同的理解，通常有三类：</p><ul><li><strong>完全自建：</strong>运维开发团队利用开源技术结合自身需要进行二次开发。这种方式在互联网企业比较流行，具体的成效大小和收效与这个运维开发团队的整体规划或资源投入有关；</li><li><strong>外购开发资源或工具产品</strong>：运维开发团队主要是结合企业痛点承担产品经理的角色。调研、外购、使用、维护，这种方式常出现在传统的企业，尤其适用于投入运维开发人员较少的企业，这种方式是投入收效快，但是对外部资源依赖比较大，不利于后续持续优化和改善；</li><li><strong>外购与自建相结合：</strong>运维开发团队在整个工具体系下，针对部份组件选择性的引入一些成熟的工具体系，同时要求这类成熟的工具需要开放一定的接口或源码支持，对于一些与公司个性强的环节采用自研的方式。这种方式目前逐渐被运一些传统企业，比如金融企业所接受。</li></ul><p>总的来说，不管选用上面哪一种方式，运维开发团队都应该有一个整体、统一的一体化工具建设规划，并在建设过程中始终保持对运维工具体系的掌控能力，并在工具体系的上层为其它运维人员提供简易的、可创造性的“开发能力”，比如所见即所得的工具可视化、可定制的运维报表、拖拉拽方式的流程及脚本组件的拼装等运维开发方式。</p><h3 id="DevOps"><a href="#DevOps" class="headerlink" title="DevOps"></a><strong>DevOps</strong></h3><p><strong>DevOps概述</strong></p><p>DevOps一词的来自于Development和Operations的组合，突出软件开发人员和运维人员的沟通合作，通过自动化流程来使得软件构建、测试、发布更加快捷、频繁和可靠，他是一种方法论，包含一套基本原则和实践，工具是为有效落实这套方法论提供支持。</p><p>在软件全生命周期管理过程中，包括开发，构建，测试，发布，运营，在这个全生命周期管理过程中出现了开发团队与运维团队的部门墙，这是因为开发团队关注需求的实现，希望尽快实现变更；而运维团队更关注于系统运行的稳定，而变更往往是生产应用不稳定的原因。DEVOPS方法论的出现主要是为了解决这个协作问题，目的是让软件交付更加高效，质量更高，生产端更加敏捷，生产运行过程中的问题能更加高效的反馈到开发，形成一个全生命周期的闭环。随着业务对运维交付能力的时效性要求越来越高，运维团队面临“吃力不讨好”的问题：</p><p><strong>吃力</strong>：花费大量时间在应用部署的操作性工作中。这部份部署变更包括新功能的上线以及修复功能BUG两方法。</p><p><strong>不讨好</strong>：操作性的工作越多，带来的操作风险就越大。有个统计，如果手工运行5条命令的情况下，成功部署的概率就已跌至86%；如需手工运行55条命令，成功部署的概率将跌至22%；如需手工运行100条命令，成功部署的概率将趋近于0（仅为2%）。</p><p>DevOps这一理念鼓励开发者和运维人员之间所进行的<strong>沟通</strong>、<strong>协作</strong>、<strong>集成</strong>和<strong>自动化</strong>，借此有助于改善双方在交付软件过程中的速度和质量。侧重于通过标准化开发环境和自动化交付流程改善交付工作的可预测性、效率、安全性，以及可维护性。</p><h3 id="实践中的DevOps"><a href="#实践中的DevOps" class="headerlink" title="实践中的DevOps"></a><strong>实践中的DevOps</strong></h3><p>可以从工具链、团队文化、自动化、敏捷看板等角度讲DevOps，如下图：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/71d403c4/4.jpg" alt="图片"></p><p><strong>从DevOps的落地效率来看</strong>：需要将DevOps进行聚焦，聚焦到交付能力上，这方面，行业里比较标准化的评估是去年底由中国信息通信研究院，联合一些互联网企业、运维社区，以及一些金融、传统企业联合进行编制的DevOps标准（券商行业中华泰参加了编制）。从这个能力模型公布出来的一些介绍看，标准对DevOps范围比较克制主要以交付能力来分解敏捷开发、持续交付、技术运营、应用架构、团队架构，这和最早的DevOps能力环比较吻合：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/71d403c4/5.jpg" alt="图片"></p><p><strong>从运维的交付场景看</strong>：主要是资源交付与应用交付，其中资源交付以IAAS、PAAS云的建设为主，通过云管平台的工具链将基础设施、网络、硬件、虚拟化、容器、运行中间件等系统软硬件交付能力自动化，并通过CMDB整合DevOps能力环之上的应用场景，实现资源的快速交付。资源交付能力主要在于IAAS、PAAS层的云平台标准化、自动化、平台扩展性等方面的建设程度。应用的快速交付比资源交付更为复杂，应用交付涉及全链路的整合，链路上的节点越多落地的难度越大，因为它不仅涉及技术，还涉及理念的认同与聚焦。应用交付能力要实现，最简单的技术栈工具需要CMDB、应用发布工具、应用版本库、监控工具，上述工具对内要与云平台对接，对外要提供接口给开发、测试工具。当然如开发、测试也能和运维使用同一套发布工具、应用版本库则效果更好，不过，实际实施过程中团队之间还是会有不少冲突，比如开发关注源代码版本管理，测试、运维关注运行版本的管理，需各个团队共同付出共建技术链。</p><h3 id="运营"><a href="#运营" class="headerlink" title="运营"></a><strong>运营</strong></h3><p>关于运维圈里运营的概念，以转型口号喊得比较多，我对运维当中的运营有业务运营与技术运营两个维度的理解。业务运营是通过功能优化或工具开发等方式解决业务工作痛点，或通过运行分析发现影响业务开展的因素，并推动相关的优化，最终提升业务能力。技术运营则主要从技术角度去降低IT成本，提升IT服务质量与效率。具体的实施内容可以考虑如下：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/71d403c4/6.jpg" alt="img"></p><p>从上述概括可以看出，当前运维里面的运营，与运维数据密切相关，需要基于运维大数据平台来提升运营质量。</p><p>为了进一步说明运营，这里举两个例子：</p><h4 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h4><p>优锘科技CEO的陈傲寒在2016年写过一篇文章《IT：从运维到运营》，虽然己过去1年多，仍是我读过最好的一篇。全文从企业、运维团队角度出发分析什么是运维、什么是运营，再将运营分解到不同角色上的理解与落地的方向，全文均是干货，值得通读，这里只列出一个思维导图。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/71d403c4/7.jpg" alt="图片"></p><h4 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h4><p>腾讯QQ逐渐被微信团队替代过程中，QQ技术运维团队是如何通过各种方式去为企业带来效益，比如他们通过运维分析，得到如何更加合理的使用带宽、资源，大大减少了公司在基础设施方面的投入。在企业中，也同样有很多空间可以去尝试，比如分析业务痛点，为业务提供快速的策略性的工具来替代重复操作性的业务操作；通过运维数据分析，发现客户体验方面的痛点，推动业务功能的优化等等。</p><h3 id="AIOPS"><a href="#AIOPS" class="headerlink" title="AIOPS"></a>AIOPS</h3><p>AIOps这个词最早是在2016年由Gartner提出。AIOps是Algorithmic IT Operations的缩写，是基于算法的IT运维，即通过使用统计分析和机器学习的方法处理从各IT设备、业务应用、运维工具收集的数据，从而加强增强运维自动化能力，以便更快、更有效、更全面的实现自动化效果。以下是Gartner提出AIOps的一张图：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/71d403c4/8.jpg" alt="图片"></p><p>Gartner通过使用图1中的图解释了AIOps平台的工作原理。AIOps有两个主要组件：大数据和机器学习。它需要从孤立的IT数据中移除，以便将大量数据平台内的观察数据（例如监控系统和作业日志中发现的数据）与参与数据（通常在故障单，事件和事件记录中找到）相结合。AI然后针对组合的IT数据实施全面的分析和机器学习（ML）策略。期望的结果是持续的见解，通过自动化产生持续的改进和修复。AI可以被认为是核心IT功能的持续集成和部署（CI / CD）。</p><ul><li><strong>广泛和多样化的IT数据源</strong>：如日志类的设备日志、系统日志，应用日志、运维操作日志；指标类的监控性能指标、事件。</li><li><strong>具备针对海量数据处理与分析的运算平台</strong>：能够从现有的IT数据生成新的数据和元数据、计算和分析还消除噪音，识别模式或趋势，隔离可能的原因，揭示潜在问题，并实现其他IT特定目标。</li><li><strong>算法</strong>，充分利用IT领域的专业知识，更适当，高效的处理数据。</li><li><strong>机器学习</strong>，从根据算法分析的输出和引入系统的新数据自动更改或创建新的算法。</li><li><strong>可视化</strong>，以易于消费的方式向IT行动提供洞察和建议，以促进理解和行动。</li><li><strong>自动化</strong>，其使用分析和机器学习产生的结果自动创建和应用响应或改进已识别的问题。</li></ul><p>关于分层的思路，Gartner这样理解：</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/71d403c4/9.jpg" alt="img"></p><h3 id="AIOps与自动化的关系"><a href="#AIOps与自动化的关系" class="headerlink" title="AIOps与自动化的关系"></a><strong>AIOps与自动化的关系</strong></h3><p>AIOps很火，所以对AIOps和自动化做了一些对比。暂以一句话作个区别：AIOps是基于对运维数据（日志类、指标类数据等）的机器学习，进一步解决自动化成本高或无法解决的问题，属于<strong>运维自动化的优化，</strong>细化一下区别有：</p><ul><li><strong>概念</strong>：</li></ul><p>狭义的自动化则提运维“监、管、控”的工具。AIOps是将AI技术应用到运维领域，需要有学习、类人交互、主动决策的特征。</p><ul><li><strong>实现思路</strong>：</li></ul><p>自动化往往以过程为导向，AIOps则以目标为导向，通过对数据进行学习，得到如何实现目标。</p><ul><li><strong>门槛高度</strong>：</li></ul><p>自动化手段有丰富的落地解决方案，适合作为替代标准化的运维操作性工作，即“面”的问题。AIOps目前仍处起步阶段，不是适合替代现有的自动化，而是应该用于解决自动化不能解决或解决成本很高的问题，即“点”的问题。</p><ul><li><strong>如何整合</strong>：</li></ul><p>AIOps并非是要取代现有的自动化运维体系，而是赋予现有体系智能。AIOps就要“学习，了解”自动化工具 ，并且更好的“使用”这些工具，这个过程就是深度集成，它的核心是对这些工具API的自主认知和自主使用。</p><p>虽然行业内的智能运维理念十分火热，但实际落地成效上还主要处于研究阶段。从<strong>运维工具</strong>技术解决方案的角度看，对于智能的解读也有差别，如果将智能的特点解读为具备”模拟人，具备自学习，能够从数据中获取知识，进而进行预测/决策“来判断是否智能，<strong>智能是自动化的一个辅助手段，自动化才是终态</strong>。建立在这个认识下，我们首先需要通过自动化手段解决痛点，提高工作效率，控制风险；利用运维数字化的建设为运维智能化提供数据、数据计算的能力；在自动化、数字化水平得到一定程度后，再通过人工智能的技术去解决自动化手段解决起来费力或无法解决的局部问题，让自动化具备智能的水平。</p><h2 id="体系"><a href="#体系" class="headerlink" title="体系"></a>体系</h2><h3 id="运维的可持续改进"><a href="#运维的可持续改进" class="headerlink" title="运维的可持续改进"></a><strong>运维的可持续改进</strong></h3><p>在管理领域，戴明推出的PDCA循环可以解释运维体系需要具备的可持续改进的能力条件。PDCA循环为四个阶段，即计划（plan）、执行（do）、检查（check）、调整（Action），即在实际工作开展过程中，把各项工作按照作出计划、计划实施、检查实施效果，然后将成功的纳入标准，并不断循环改进的过程。将这个思路引入到企业的运维体系中则是针对企业业务发展的需求，制定运维体系的整体发展目标，通过不断改进的措施提高运维工作效率、控制风险，以达到理高效、更优化的资源配置，进而推动业务的发展。要做到运维体系的可持续改进，需要做到以业务导向，整体部局；团队、流程、工具三位一体；不断审视优化。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/71d403c4/11.jpg" alt></p><p><strong>P：以业务导向、整体部局</strong></p><p>运维的最根本作用是保障IT数据的连续性，这里的IT数据包括业务，以及反映业务的数据，或者换句话可以表达为：网络不断、系统不瘫、数据不丢。随着业务对IT系统依赖程度越来越高，运维又会承担更高的期望，也就是运维向运营的转化，这就需要从业务角度去不断完善运维，以促进业务为大目标。有了这个目标，那我们的运维体系的构建就需要与企业业务的发展保持同步，要让运维体系具备可持续改进的能力。</p><p>另外，可持续改进的过程不应该是大拐弯的方式进行改进，而应该不断的小调整，这就需要确保首先要建立一个整体、全局的运维体系，对运维各项工作做一个整体的规划，把眼光看得更远，往往可以更好的把控当前。</p><p><strong>D：团队、流程、工具的三位一体</strong></p><p>可持续改进的运维体系需要让运维的团队、流程、工具三位一体的作用，比方说：提高工作效率，需要团队的专业化分工、流程的标准化、工具的自动化配合作用；推动业务的发展，既需精细化运维分析、业务服务、运营等维度的工作资源投入，也需要有工具的建设来减少操作性的工作来释放人力，需要工具提供更高效的数据来源。</p><p>这里说的团队主要是从运维人力资源的分工、团队建设、工作目标导向、运维KPI等；流程是指以成熟的运维方法论为主体，结合企业和外部监管的规章制度、企业业务发展需要，而落地的标准化工作方法；工具既包括狭义运维的“监、管、控”，也包括运营体系所需要数字化、智能化的工具平台。</p><p><strong>C+A : 不断审视优化</strong></p><p>在实际工作过程中，审视检查的过程很容易被忽略，但实际上最大的收获可能就来自于这个总结、归纳的过程中，这也是可持续改进的运维体系的关键所在。比方说，运维团队可以考虑在必要环节增加横向的优化团队；运维流程也需要定期对流程的落地进行分析，并对规章制度进行查漏补缺、删减不合理的流程规范、调整无法执行的规范要求；工具的建设要不断的分析工具的使用覆盖率，如何提高覆盖率，分析是否提高了运维的效率，还是带来了反作用等分析，并不断调整优化工具的建设。</p><h3 id="转型思路"><a href="#转型思路" class="headerlink" title="转型思路"></a>转型思路</h3><p>在提出可持续的运维体系前，我们先归纳一下运维团队常见的运维痛点，以提出运维转型的思路，再看看如何构建一个可持续改进的运维体系来支撑运维转型。前面的运维之痛中提到了 “救火”、“背锅”、“低价值”、”重复操作“等标签，我们归纳下己有特点再看转型：</p><h4 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h4><p><strong>被动救火式</strong>：以被动保障业务系统运行，日常计划性工作容易被打断、搁置；</p><p><strong>问题驱动式</strong>：以系统可用性、可靠性、业务请求等问题驱动运维工作；</p><p><strong>操作运维</strong>：重复性、操作类点主要工作量的运维模式；</p><p><strong>经验式运维</strong>：由人工经验驱动的运维模式，尤其是一些经验丰富的老员工的离职在短期内会对运维质量带来一定的冲击。</p><h4 id="转型"><a href="#转型" class="headerlink" title="转型"></a><strong>转型</strong></h4><p><strong>从被动救火式向主动精细化转型</strong>：专业化分工、主动分析，主动优化，驱动开发，促进DEVOPS的落地；</p><p><strong>从问题驱动向价值驱动转型</strong>：以企业业务发展目标为主线，业务体验、服务满意度、促进业务更好发展；</p><p><strong>从操作运维向运维开发转型</strong>：通过为运维人员提供运维开发平台，降低运维开发门槛，快速落地一些紧迫的运维工具，降低操作性、重复性的运维工作；</p><p><strong>从依靠经验向智能化驱动运维转型</strong>：结合数据分析、知识库、机器学习技术促进运维智能化。</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/71d403c4/10.jpg" alt="图片"></p><h3 id="构建运维体系"><a href="#构建运维体系" class="headerlink" title="构建运维体系"></a><strong>构建运维体系</strong></h3><p>上面提到运维体系以业务导向，整体部局，团队、流程、工具三位一体，不断审视优化的建设思路，也提出了”主动精细化“、”价值驱动“、”运维开发“、”智能化运维“的转型目标，我们再将这些思路分解到团队、流程、工具的建设中，并归纳为：三大建设，十个文化的实践方法：</p><ul><li><strong>团队建设：专业化、精细化、运营化</strong></li></ul><p>我们将运维实施主体运维团队理解为团队，理想情况下，优秀的团队应该具备有合适的工作、合适的时间、合适的人、合适的行为四个要素组成。即团队要结合企业实际发展方向，制定符合企业、运维团队、个人发展的工作内容，并选择具备合适的知识、技能、认知、能力的人去完成工作，去实际个人的自我价值。</p><p>前面也提到，目前的运维织是一个被动保障业务系统运行，日常计划性工作容易被打断、搁置的工作，这种工作状态下的运维团队往往工作效率不高、容易出现操作风险。为了让运维团队具备可持续改进的能力，需要提高运维团队的工作效率，我们需要将运维工作专业化，整合通用性、操作性的工作，提高工作效率，在释放运维人员工作量后，引导运维人员有计划、可量化的去做更多分析类、优化类、业务运营的主动性工作。</p><ul><li><strong>流程建设：标准化、可视化、可量化</strong></li></ul><p>大部份运维团队会以内部企业积累的规章制度、外部监管机构的监管要求为基础，依照ITIL、ISO20000、ITSS.1、DevOps的方法论中的一个或多个组合的方式开展运维工作。这些规章制度、监管要求、方法论的整合、落地、持续改进的过程即为流程建设的过程。</p><p>流程建设首先需要标准化流程，要先梳理好己有的流程制度，约定工作的流转方式，再通过可视化将流程整合在日常工作中，最后通过流程落地数据的分析与工具建设，持续改善提高流程落地的效率，控制操作风险。</p><ul><li><strong>工具建设：自动化、数字化、智能化、服务化</strong></li></ul><p>工具的建设也以可持续改进的思路构建，以整合存量资源、引入成熟或开源技术为主，建立一体化的运维工具体系，通过体系化的思路实现运维工具（“监、管、控”）的互联互通，有序建设，实现自动化运维，全面控制风险、提高工作效率、释放人力；通过建立运维数据分析平台，实现数字化运营，提供运维数据集中与治理、主动分析的能力；在数字化运营的基础上通过运维数据挖掘、学习，优化运维或运营场景，向智能化发展；服务化则是以IT服务的方式将运维能力向处输出。</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;以前和一个项目经理沟通时，提到能否提前半天将变更申请提交过来，而这位项目经理很不理解的看着我问：“你们运维不就是在生产环境部署个程序嘛，这么简单的工作还需要提前半天？而且你们不懂程序，也评审不出什么吧？”。运维这么多年来，听到对运维工作抱有这种认识和看法的人很多。它侧面反映了企业中其他团队团队对运维的认识往往局限于一些简单操作性的工作。例如：应用服务故障时重启、应用配置变更、增删改查数据或者所有软硬件使用问题等等。运维真的是这样吗？&lt;/p&gt;
    
    </summary>
    
      <category term="心得体会" scheme="https://wandouduoduo.github.io/categories/%E5%BF%83%E5%BE%97%E4%BD%93%E4%BC%9A/"/>
    
    
      <category term="Experiences" scheme="https://wandouduoduo.github.io/tags/Experiences/"/>
    
  </entry>
  
  <entry>
    <title>详解docker-compose安装sentry集群解决方案&lt;二&gt;</title>
    <link href="https://wandouduoduo.github.io/articles/312eda9c.html"/>
    <id>https://wandouduoduo.github.io/articles/312eda9c.html</id>
    <published>2020-12-29T09:32:11.000Z</published>
    <updated>2021-01-14T02:51:50.235Z</updated>
    
    <content type="html"><![CDATA[<div id="vip-container"><p>接上篇文章，上篇文章详细介绍了架构和单节点的搭建、配置和优化。本篇详细介绍集群方案。特别提醒没看上篇文章的请返回先看，本篇集群是在上篇文章的基础上配置的，并且上篇文章中的简单步骤，本篇不再说明，直接跳过。详解docker-compose安装sentry集群篇现在开始。</p><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>上篇文章中的3个节点，并都已执行完install.sh没有报错。</p><p><strong>主节点</strong>：192.168.1.100</p><p><strong>从节点</strong>：192.168.1.101，192.168.1.102</p><h2 id="教程"><a href="#教程" class="headerlink" title="教程"></a>教程</h2><h3 id="规划"><a href="#规划" class="headerlink" title="规划"></a>规划</h3><h4 id="任务目标"><a href="#任务目标" class="headerlink" title="任务目标"></a><strong>任务目标</strong></h4><p>Sentry平台三台服务器集群部署</p><h4 id="部署方式"><a href="#部署方式" class="headerlink" title="部署方式"></a><strong>部署方式</strong></h4><p>采用docker平台，准确说应该是：docker-compose</p><h4 id="主节点"><a href="#主节点" class="headerlink" title="主节点"></a>主节点</h4><p>服务端模块：redis、postgres、memcached、stmp、sentry-web、sentry-worker和sentry-corn</p><p>功能如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">redis  <span class="comment">#支持消息队列和任务调度</span></span><br><span class="line">postgres <span class="comment">#数据存储</span></span><br><span class="line">memcached <span class="comment">#kv存储，用于worker数据管理</span></span><br><span class="line">stmp <span class="comment">#邮件服务</span></span><br><span class="line">sentry-cron <span class="comment">#实现定时任务，如定时群发邮件</span></span><br><span class="line">sentry-worker <span class="comment">#处理数据解析等任务，完成异常的分类、入库等操作</span></span><br><span class="line">sentry-web <span class="comment">#网络服务，后台网站和报错接口</span></span><br></pre></td></tr></table></figure><h4 id="从节点"><a href="#从节点" class="headerlink" title="从节点"></a>从节点</h4><p>剩下2台作为从节点，组件有：sentry-worker、sentry-web和memcached。从节点可以随负载变化动态扩容</p><h3 id="修改主节点配置"><a href="#修改主节点配置" class="headerlink" title="修改主节点配置"></a>修改主节点配置</h3><p>修改主节点配置文件docker-compose.yml，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">version: &apos;3.4&apos;</span><br><span class="line"></span><br><span class="line">x-defaults: &amp;defaults</span><br><span class="line">  restart: unless-stopped</span><br><span class="line">  build:</span><br><span class="line">    context: .</span><br><span class="line">  depends_on:</span><br><span class="line">    - redis</span><br><span class="line">    - postgres</span><br><span class="line">    - memcached</span><br><span class="line">    - smtp</span><br><span class="line">  env_file: .env</span><br><span class="line">  environment:</span><br><span class="line">    SENTRY_MEMCACHED_HOST: memcached</span><br><span class="line">    SENTRY_REDIS_HOST: redis</span><br><span class="line">    SENTRY_POSTGRES_HOST: postgres</span><br><span class="line">    SENTRY_DB_PASSWORD: postgres</span><br><span class="line">    SENTRY_EMAIL_HOST: smtp</span><br><span class="line">  volumes:</span><br><span class="line">    - sentry-data:/var/lib/sentry/files</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  smtp:</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    image: tianon/exim4</span><br><span class="line">    ports:</span><br><span class="line">      - &apos;192.168.1.100:25:25&apos;</span><br><span class="line"></span><br><span class="line">  memcached:</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    image: memcached:1.5-alpine</span><br><span class="line">    ports:</span><br><span class="line">      - &apos;192.168.1.100:11211:11211&apos;</span><br><span class="line"></span><br><span class="line">  redis:</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    image: redis:3.2-alpine</span><br><span class="line">    ports:</span><br><span class="line">      - &apos;192.168.1.100:6379:6379&apos;</span><br><span class="line"></span><br><span class="line">  postgres:</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    image: postgres:9.5</span><br><span class="line">    ports:</span><br><span class="line">      - &apos;192.168.1.100:5432:5432&apos;</span><br><span class="line">    volumes:</span><br><span class="line">      - sentry-postgres:/var/lib/postgresql/data</span><br><span class="line"></span><br><span class="line">  web:</span><br><span class="line">    &lt;&lt;: *defaults</span><br><span class="line">    ports:</span><br><span class="line">      - &apos;9000:9000&apos;</span><br><span class="line">  cron:</span><br><span class="line">    &lt;&lt;: *defaults</span><br><span class="line">    command: run cron</span><br><span class="line"></span><br><span class="line">  worker:</span><br><span class="line">    &lt;&lt;: *defaults</span><br><span class="line">    command: run worker</span><br><span class="line">   </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">volumes:</span><br><span class="line">    sentry-data:</span><br><span class="line">      external: true</span><br><span class="line">    sentry-postgres:</span><br><span class="line">      external: true</span><br></pre></td></tr></table></figure><h3 id="修改从节点配置"><a href="#修改从节点配置" class="headerlink" title="修改从节点配置"></a>修改从节点配置</h3><p>修改从节点配置文件docker-compose.yml，配置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">version: &apos;3.4&apos;</span><br><span class="line"></span><br><span class="line">x-defaults: &amp;defaults</span><br><span class="line">  restart: unless-stopped</span><br><span class="line">  build:</span><br><span class="line">    context: .</span><br><span class="line">  env_file: .env</span><br><span class="line">  environment:</span><br><span class="line">    SENTRY_MEMCACHED_HOST: memcached</span><br><span class="line">    SENTRY_REDIS_HOST: 192.168.1.100</span><br><span class="line">    SENTRY_POSTGRES_HOST: 192.168.1.100</span><br><span class="line">    SENTRY_DB_PASSWORD: postgres</span><br><span class="line">    SENTRY_EMAIL_HOST: 192.168.1.100</span><br><span class="line">  volumes:</span><br><span class="line">    - sentry-data:/var/lib/sentry/files</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  web:</span><br><span class="line">    &lt;&lt;: *defaults</span><br><span class="line">    ports:</span><br><span class="line">      - &apos;9000:9000&apos;</span><br><span class="line">  memcached:</span><br><span class="line">    restart: unless-stopped</span><br><span class="line">    image: memcached:1.5-alpine</span><br><span class="line">  worker:</span><br><span class="line">    &lt;&lt;: *defaults</span><br><span class="line">    command: run worker -c 3</span><br><span class="line">volumes:</span><br><span class="line">    sentry-data:</span><br><span class="line">      external: true</span><br></pre></td></tr></table></figure><h3 id="统一存储"><a href="#统一存储" class="headerlink" title="统一存储"></a>统一存储</h3><p>集群分布式部署需要一个统一的存储服务，用于sourcemap等文件的存储。采用minio，部署在主节点。</p><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /opt/minio/&#123;data,config&#125;</span><br><span class="line"></span><br><span class="line">docker run -p 6000:9000 --name minio \</span><br><span class="line">    -d --restart=always \</span><br><span class="line">    -e <span class="string">"MINIO_ACCESS_KEY=wandouduoduo"</span> \</span><br><span class="line">    -e <span class="string">"MINIO_SECRET_KEY=wdddxxxx"</span> \</span><br><span class="line">    -v /opt/minio/data:/data \</span><br><span class="line">    -v /opt/minio/config:/root/.minio \</span><br><span class="line">    minio/minio server /data</span><br></pre></td></tr></table></figure><h4 id="创建bucket"><a href="#创建bucket" class="headerlink" title="创建bucket"></a>创建bucket</h4><p>访问minio页面</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/312eda9c/1.png" alt></p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/312eda9c/2.png" alt></p><p>主从节点的配置文件config.yml添加filestore信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">filestore.backend: &apos;s3&apos;</span><br><span class="line">filestore.options:</span><br><span class="line">  access_key: &apos;wandouduoduo&apos;</span><br><span class="line">  secret_key: &apos;wdddxxxx&apos;</span><br><span class="line">  bucket_name: &apos;sentry&apos;</span><br><span class="line">  endpoint_url: &apos;http://172.16.1.100:6000&apos;</span><br></pre></td></tr></table></figure><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>启动服务时，可worker数量可根据机器核数进行配置。</p><h4 id="主节点启动"><a href="#主节点启动" class="headerlink" title="主节点启动"></a>主节点启动</h4><p>启动2个worker和1个web实例</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose up -d --scale worker=2</span><br></pre></td></tr></table></figure><h4 id="从节点启动"><a href="#从节点启动" class="headerlink" title="从节点启动"></a>从节点启动</h4><p>启动4个worker和一个web实例 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose up -d --scale worker=4</span><br></pre></td></tr></table></figure><p><em>注意：以上配置需要根据服务器和流量的情况调整，以最大化利用机器资源。前端上传sourcemap文件较多时，worker耗费cpu资源会比较厉害</em></p><h3 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h3><p>然后负载均衡到所有节点的9000端口，访问即可，到这里集群搭建完成。</p><p><em>注意：这里做负载均衡时调用策略要用ip  hash方式。如用轮训方式，web页面输入密码，会轮训到下个节点登录不了。</em></p><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><h3 id="redis拆分"><a href="#redis拆分" class="headerlink" title="redis拆分"></a>redis拆分</h3><p>上报时的并发太大，可以考虑将redis单独拆分出来。拆分出来redis，自行搭建集群。</p><p>sentry的配置更改如下：</p><p>连接外部redis集群环境配置需添加下面几项</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SENTRY_REDIS_HOST: xx.xx.xx.xx</span><br><span class="line">SENTRY_REDIS_PASSWORD: xxxxxxxxxxxx</span><br><span class="line">SENTRY_REDIS_PORT: xxx</span><br></pre></td></tr></table></figure><p>主节点docker-compose.yaml配置</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/312eda9c/3.png" alt></p><p>从节点docker-compose.yml配置</p><p><img src="https://cdn.jsdelivr.net/gh/wandouduoduo/wandouduoduo.github.io@master/articles/312eda9c/4.png" alt></p><h3 id="添加清理定时任务"><a href="#添加清理定时任务" class="headerlink" title="添加清理定时任务"></a>添加清理定时任务</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker <span class="built_in">exec</span> -i onpremise-912_worker_1 sentry cleanup --days 60 &amp;&amp; docker <span class="built_in">exec</span> -i -u postgres onpremise-912_postgres_1 vacuumdb -U postgres -d postgres -v -f --analyze</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>sentry集群方案已全部搭建完成，当然该集群还可以横向扩展等等优化。</p></div><script src="https://my.openwrite.cn/js/readmore.js" type="text/javascript"></script><script>var isMobile = navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i);if (!isMobile) {    var btw = new BTWPlugin();    btw.init({        "id": "vip-container",        "blogId": "19128-1606361858239-837",        "name": "运维随笔",        "qrcode": "https://wandouduoduo.github.io/about/index/gongzhonghao.jpg",        "keyword": "yunwei"    });}</script>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;接上篇文章，上篇文章详细介绍了架构和单节点的搭建、配置和优化。本篇详细介绍集群方案。特别提醒没看上篇文章的请返回先看，本篇集群是在上篇文章的基础上配置的，并且上篇文章中的简单步骤，本篇不再说明，直接跳过。详解docker-compose安装sentry集群篇现在开始。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
