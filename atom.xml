<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>豌豆多多</title>
  
  <subtitle>Deveops Study Notes</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://wandouduoduo.netlify.com/"/>
  <updated>2019-12-10T09:18:52.522Z</updated>
  <id>https://wandouduoduo.netlify.com/</id>
  
  <author>
    <name>WanDouDuoDuo</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>shell中的多进程并发</title>
    <link href="https://wandouduoduo.netlify.com/articles/d7c52fa4.html"/>
    <id>https://wandouduoduo.netlify.com/articles/d7c52fa4.html</id>
    <published>2019-12-10T08:23:40.000Z</published>
    <updated>2019-12-10T09:18:52.522Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>日常工作中编写shell脚本处理事务，很多时候需要一次性处理很多，需要用到循环，但是循环体内还是线性的，还是要一个个处理，这样并不会节省很多时间，只是节省了人工一次次输入的繁琐。但是对于提高处理能力，没有实质性的提高。这就需要考虑并发。但Shell中并没有真正意义的多线程，要实现多线程可以启动多个后端进程，最大程度利用cpu性能。即：多进程并发，本篇教程由浅入深详细介绍了shell中的多进程并发。</p><a id="more"></a><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>所谓的多进程只不过是将多个任务放到后台执行而已，很多人都用到过，所以现在讲的主要是控制，而不是实现。</p><h4 id="实验一"><a href="#实验一" class="headerlink" title="实验一"></a>实验一</h4><p>先看一个小shell：</p><p><img src="/articles/d7c52fa4/1.jpg" alt></p><p>看执行结果：</p><p><img src="/articles/d7c52fa4/2.jpg" alt></p><p>很明显是8s，这种不占处理器却有很耗时的进程，我们可以通过一种后台运行的方式<br>来达到节约时间的目的。</p><h4 id="实验二"><a href="#实验二" class="headerlink" title="实验二"></a>实验二</h4><p>如下为改进：</p><p><img src="/articles/d7c52fa4/3.jpg" alt="img"></p><p>用“{}”将主执行程序变为一个块，用&amp;放入后台，四次执行全部放入后台后，我们需要用一个wait指令，等待所有后台进程执行结束，不然 系统是不会等待的，直接继续执行后续指令，知道整个程序结束。<br>看结果：</p><p><img src="/articles/d7c52fa4/4.jpg" alt="img"> </p><p>可以看到，时间已经大大缩短了！</p><h4 id="实验三"><a href="#实验三" class="headerlink" title="实验三"></a>实验三</h4><p>以上实验虽然达到了多线程并发的目的，但有一个缺陷，不能控制运行在后台的进程数。为了控制进程，我们引入了管道 和文件操作符。</p><p>无名管道： 就是我们经常使用的 例如： cat text | grep “abc”   那个“|”就是管道，只不过是无名的，可以直接作为两个进程的数据通道<br>有名管道： mkfilo  可以创建一个管道文件 ，例如： mkfifo　fifo_file</p><p>管道有一个特点，如果管道中没有数据，那么取管道数据的操作就会停滞，直到管道内进入数据，然后读出后才会终止这一操作，同理，写入管道的操作，如果没有读取操作，这一个动作也会停滞。</p><p><img src="/articles/d7c52fa4/5.jpg" alt="img"> </p><p>当我们试图用echo想管道文件中写入数据时，由于没有任何进程在对它做读取操作，所以它会一直停留在那里等待读取操作，此时我们在另一终端上用cat指令做读取操作</p><p><img src="/articles/d7c52fa4/6.jpg" alt="img"> </p><p>你会发现读取操作一旦执行，写入操作就可以顺利完成了，同理，先做读取操作也是一样的：<br><img src="/articles/d7c52fa4/7.jpg" alt="img"> </p><p>由于没有管道内没有数据，所以读取操作一直滞留在那里等待写入的数据<br><img src="/articles/d7c52fa4/8.jpg" alt></p><p>一旦有了写入的数据，读取操作立刻顺利完成</p><p>以上实验，看以看到，仅仅一个管道文件似乎很难实现 我们的目的（控制后台线程数),  所以 接下来介绍 文件操作符，这里只做简单的介绍，如果不熟悉的可以自行查阅资料。<br>系统运行起始，就相应设备自动绑定到了 三个文件操作符   分别为 0  1  2 对应 stdin ，stdout， stderr 。<br>在 /proc/self/fd 中 可以看到 这三个三个对应文件</p><p><img src="/articles/d7c52fa4/9.jpg" alt="img"> </p><p>输出到这三个文件的内容都会显示出来。只是因为显示器作为最常用的输出设备而被绑定。</p><p>我们可以exec 指令自行定义、绑定文件操作符，文件操作符一般从3–（n-1）都可以随便使用<br>此处的n 为 ulimit -n 的定义值得<br><img src="/articles/d7c52fa4/10.jpg" alt="img"> </p><p>可以看到 我的 n值为1024 ，所以文件操作符只能使用 0-1023，可自行定义的 就只能是 3-1023 了。</p><p>直接上代码，然后根据代码分析每行代码的含义：<br><img src="/articles/d7c52fa4/11.jpg" alt="img"> </p><p><strong>代码解释</strong></p><p>第3行：  接受信号 2 （ctrl +C）做的操作。exec 1000&gt;&amp;-和exec 1000&lt;&amp;- 是关闭fd1000的意思，我们生成做绑                定时 可以用 exec 1000&lt;&gt;testfifo 来实现，但关闭时必须分开来写，&gt; 读的绑定，&lt; 标识写的绑定  &lt;&gt; 则                标识 对文件描述符 1000的所有操作等同于对管道文件testfifo的操作。</p><p>第5-7行：分别为 创建管道文件，文件操作符绑定，删除管道文件<br>　　　　  可能会有疑问，为什么不能直接使用管道文件呢？　<br>　　　　  事实上，这并非多此一举，刚才已经说明了管道文件的一个重要特性了，那就是读写必须同时存在<br>　　　　  缺少某一种操作，另一种操作就是滞留，而绑定文件操作符　正好解决了这个问题。</p><p>第9-12 行： 对文件操作符进行写入操作。通过一个for循环写入10个空行，这个10就是我们要定义的后台线程数                     量。<br>                     为什么写入空行而不是10个字符呢 ？<br>                     这是因为，管道文件的读取 是以行为单位的。<br><img src="/articles/d7c52fa4/12.jpg" alt="img"><br>                      当我们试图用 read 读取管道中的一个字符时，结果是不成功的，而刚才我们已经证实使用cat是可以                      读取的。</p><p>第17-24行：这里假定我们有100个任务，我们要实现的时 ，保证后台只有10个进程在同步运行 。read -u1000 的                     作用是：读取一次管道中的一行，在这儿就是读取一个空行。减少操作附中的一个空行之后，执行一                     次任务（当然是放到后台执行），需要注意的是，这个任务在后台执行结束以后会向文件操作符中写                    入一个空行，这就是重点所在，如果我们不在某种情况某种时刻向操作符中写入空行，那么结果就                    是：在后台放入10个任务之后，由于操作符中没有可读取的空行，导致  read -u1000 这儿 始终停顿。</p><p>后边的 就不用解释了。</p><p>贴下执行结果：<br><img src="/articles/d7c52fa4/13.jpg" alt="img"> </p><p>每次的停顿中都能看到  只有10个进程在运行<br>一共耗时50s  一共100个任务，每次10个 ，每个5s 正好50s。上边的结果图之所以这么有规律，这是因为我们所执行的100个任务耗时都是相同的。</p><p>比如，系统将第一批10个任务放入后台的过程所消耗的时间 几乎可以忽略不计，也就是说这10个任务几乎可以任务是同时运行，当然也就可以认为是同时结束了，而按照刚才的分析，一个任务结束时就会向文件描述符写入空行，既然是同时结束的，那么肯定是同时写入的空行，所以下一批任务又几乎同时运行，如此循环下去的。实际应用时，肯定不是这个样子的，比如，第一个放到后台执行的任务，是最耗时间的，那他肯定就会是最后一个执行完毕。所以，实际上来说，只要有一个任务完成，那么下一个任务就可以被放到后台并发执行了。  </p><h2 id="范例"><a href="#范例" class="headerlink" title="范例"></a>范例</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">trap</span> <span class="string">"exec 1000&gt;&amp;-;exec 1000&lt;&amp;-;exit 0"</span> 2</span><br><span class="line"></span><br><span class="line">mkfifo testfifo</span><br><span class="line"><span class="built_in">exec</span> 1000&lt;&gt;testfifo</span><br><span class="line">rm -fr testfifo</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>((n=1;n&lt;=10;n++))</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> &gt;&amp;1000</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">start=`date <span class="string">"+%s"</span>`</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>((i=1;i&lt;=100;i++))</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">read</span> -u1000</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"success <span class="variable">$i</span>"</span>;</span><br><span class="line">        sleep 5</span><br><span class="line"></span><br><span class="line">        <span class="built_in">echo</span> &gt;&amp;1000</span><br><span class="line">    &#125;&amp;</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">wait</span></span><br><span class="line"></span><br><span class="line">end=`date <span class="string">"+%s"</span>`</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Time: `expr <span class="variable">$end</span> - <span class="variable">$start</span>`"</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">exec</span> 1000&gt;&amp;-</span><br><span class="line"><span class="built_in">exec</span> 1000&lt;&amp;-</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;日常工作中编写shell脚本处理事务，很多时候需要一次性处理很多，需要用到循环，但是循环体内还是线性的，还是要一个个处理，这样并不会节省很多时间，只是节省了人工一次次输入的繁琐。但是对于提高处理能力，没有实质性的提高。这就需要考虑并发。但Shell中并没有真正意义的多线程，要实现多线程可以启动多个后端进程，最大程度利用cpu性能。即：多进程并发，本篇教程由浅入深详细介绍了shell中的多进程并发。&lt;/p&gt;
    
    </summary>
    
      <category term="编程积累" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/"/>
    
      <category term="Shell" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/Shell/"/>
    
    
      <category term="Shell" scheme="https://wandouduoduo.netlify.com/tags/Shell/"/>
    
  </entry>
  
  <entry>
    <title>Python多进程和多线程效率最优选</title>
    <link href="https://wandouduoduo.netlify.com/articles/4efb4de8.html"/>
    <id>https://wandouduoduo.netlify.com/articles/4efb4de8.html</id>
    <published>2019-11-29T08:51:15.000Z</published>
    <updated>2019-11-29T10:50:01.362Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>通过实例实验，比较用多线程和多进程耗时情况，并进行总结归纳，选择效率最高的方法。</p><a id="more"></a><h2 id="多线程和多进程测试"><a href="#多线程和多进程测试" class="headerlink" title="多线程和多进程测试"></a>多线程和多进程测试</h2><h4 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h4><ul><li>python3.6</li><li>threading和multiprocessing</li><li>四核+三星250G-850-SSD</li></ul><p>自从用多进程和多线程进行编程,一致没搞懂到底谁更快。网上很多都说python多进程更快，因为GIL(全局解释器锁)。但是我在写代码的时候，测试时间却是多线程更快，所以这到底是怎么回事？最近再做分词工作，原来的代码速度太慢，想提速，所以来探求一下有效方法(文末有代码和效果图)</p><p>这里先来一张程序的结果图，说明线程和进程谁更快</p><p><img src="/articles/4efb4de8/1.png" alt></p><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">并行是指两个或者多个事件在同一时刻发生。并发是指两个或多个事件在同一时间间隔内发生</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">线程是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一个程序的执行实例就是一个进程。</span><br></pre></td></tr></table></figure><h4 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h4><p>而python里面的多线程显然得拿到GIL,执行code，最后释放GIL。所以由于GIL，多线程的时候拿不到，实际上，它是并发实现，即多个事件，在同一时间间隔内发生。</p><p>但进程有独立GIL，所以可以并行实现。因此，针对多核CPU，理论上采用多进程更能有效利用资源。</p><h4 id="现实问题"><a href="#现实问题" class="headerlink" title="现实问题"></a>现实问题</h4><p>在网上的教程里面，经常能见到python多线程的身影。比如网络爬虫的教程、端口扫描的教程。</p><p>这里拿端口扫描来说，大家可以用多进程实现下面的脚本，会发现python多进程更快。那么不就是和我们分析相悖了吗？</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys,threading</span><br><span class="line"><span class="keyword">from</span> socket <span class="keyword">import</span> *</span><br><span class="line"> </span><br><span class="line">host = <span class="string">"127.0.0.1"</span> <span class="keyword">if</span> len(sys.argv)==<span class="number">1</span> <span class="keyword">else</span> sys.argv[<span class="number">1</span>]</span><br><span class="line">portList = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">1000</span>)]</span><br><span class="line">scanList = []</span><br><span class="line">lock = threading.Lock()</span><br><span class="line">print(<span class="string">'Please waiting... From '</span>,host)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scanPort</span><span class="params">(port)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        tcp = socket(AF_INET,SOCK_STREAM)</span><br><span class="line">        tcp.connect((host,port))</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> lock.acquire():</span><br><span class="line">            print(<span class="string">'[+]port'</span>,port,<span class="string">'open'</span>)</span><br><span class="line">            lock.release()</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        tcp.close()</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> portList:</span><br><span class="line">    t = threading.Thread(target=scanPort,args=(p,))</span><br><span class="line">    scanList.append(t)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(portList)):</span><br><span class="line">    scanList[i].start()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(portList)):</span><br><span class="line">    scanList[i].join()</span><br></pre></td></tr></table></figure><h4 id="谁更快"><a href="#谁更快" class="headerlink" title="谁更快"></a>谁更快</h4><p>因为python锁的问题，线程进行锁竞争、切换线程，会消耗资源。所以，大胆猜测一下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">在CPU密集型任务下，多进程更快，或者说效果更好；而IO密集型，多线程能有效提高效率。</span><br></pre></td></tr></table></figure><p>大家看一下下面的代码:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"> </span><br><span class="line">max_process = <span class="number">4</span></span><br><span class="line">max_thread = max_process</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(n,n2)</span>:</span></span><br><span class="line">    <span class="comment">#cpu密集型</span></span><br><span class="line">    <span class="keyword">for</span>  i <span class="keyword">in</span> range(<span class="number">0</span>,n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,(int)(n*n*n*n2)):</span><br><span class="line">            t = i*j</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">thread_main</span><span class="params">(n2)</span>:</span></span><br><span class="line">    thread_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,max_thread):</span><br><span class="line">        t = threading.Thread(target=fun,args=(<span class="number">50</span>,n2))</span><br><span class="line">        thread_list.append(t)</span><br><span class="line"> </span><br><span class="line">    start = time.time()</span><br><span class="line">    print(<span class="string">' [+] much thread start'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> thread_list:</span><br><span class="line">        i.start()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> thread_list:</span><br><span class="line">        i.join()</span><br><span class="line">    print(<span class="string">' [-] much thread use '</span>,time.time()-start,<span class="string">'s'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_main</span><span class="params">(n2)</span>:</span></span><br><span class="line">    p = multiprocessing.Pool(max_process)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,max_process):</span><br><span class="line">        p.apply_async(func = fun,args=(<span class="number">50</span>,n2))</span><br><span class="line">    start = time.time()</span><br><span class="line">    print(<span class="string">' [+] much process start'</span>)</span><br><span class="line">    p.close()<span class="comment">#关闭进程池</span></span><br><span class="line">    p.join()<span class="comment">#等待所有子进程完毕</span></span><br><span class="line">    print(<span class="string">' [-] much process use '</span>,time.time()-start,<span class="string">'s'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">"[++]When n=50,n2=0.1:"</span>)</span><br><span class="line">    thread_main(<span class="number">0.1</span>)</span><br><span class="line">    process_main(<span class="number">0.1</span>)</span><br><span class="line">    print(<span class="string">"[++]When n=50,n2=1:"</span>)</span><br><span class="line">    thread_main(<span class="number">1</span>)</span><br><span class="line">    process_main(<span class="number">1</span>)</span><br><span class="line">    print(<span class="string">"[++]When n=50,n2=10:"</span>)</span><br><span class="line">    thread_main(<span class="number">10</span>)</span><br><span class="line">    process_main(<span class="number">10</span>)</span><br></pre></td></tr></table></figure><p>结果如下：</p><p><img src="/articles/4efb4de8/2.png" alt></p><p>可以看出来，当对cpu使用率越来越高的时候（代码循环越多的时候），差距越来越大。</p><p><strong>验证我们猜想(在CPU密集型任务下，多进程更快，或者说效果更好；而IO密集型，多线程能有效提高效率。</strong></p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>CPU密集型代码(如：各种循环处理、计数等等)，适合用多进程<br>IO密集型代码(如：文件处理、网络爬虫等)，适合用多线程</p><h2 id="判断方法"><a href="#判断方法" class="headerlink" title="判断方法"></a>判断方法</h2><p>1，直接看CPU占用率或硬盘IO读写速度<br>2，大致上归纳：计算较多为CPU密集型；时间等待较多(如网络爬虫)为IO密集型。</p><h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>对于IO密集型任务：</p><p>单进程单线程直接执行用时：10.0333秒<br>多线程执行用时：4.0156秒<br>多进程执行用时：5.0182秒<br>说明多线程适合IO密集型任务。</p><p>对于计算密集型任务</p><p>单进程单线程直接执行用时：10.0273秒<br>多线程执行用时：13.247秒<br>多进程执行用时：6.8377秒</p><p><strong>说明多进程适合计算密集型任务</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义全局变量Queue</span></span><br><span class="line">g_queue = multiprocessing.Queue()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_queue</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"init g_queue start"</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> g_queue.empty():</span><br><span class="line">        g_queue.get()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">for</span> _index <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        g_queue.put(_index)</span><br><span class="line">    print(<span class="string">"init g_queue end"</span>)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个IO密集型任务：利用time.sleep()</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">task_io</span><span class="params">(task_id)</span>:</span></span><br><span class="line">    print(<span class="string">"IOTask[%s] start"</span> % task_id)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> g_queue.empty():</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data = g_queue.get(block=<span class="literal">True</span>, timeout=<span class="number">1</span>)</span><br><span class="line">            print(<span class="string">"IOTask[%s] get data: %s"</span> % (task_id, data))</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> excep:</span><br><span class="line">            print(<span class="string">"IOTask[%s] error: %s"</span> % (task_id, str(excep)))</span><br><span class="line">    print(<span class="string">"IOTask[%s] end"</span> % task_id)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">g_search_list = list(range(<span class="number">10000</span>))</span><br><span class="line"><span class="comment"># 定义一个计算密集型任务：利用一些复杂加减乘除、列表查找等</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">task_cpu</span><span class="params">(task_id)</span>:</span></span><br><span class="line">    print(<span class="string">"CPUTask[%s] start"</span> % task_id)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> g_queue.empty():</span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">            count += pow(<span class="number">3</span>*<span class="number">2</span>, <span class="number">3</span>*<span class="number">2</span>) <span class="keyword">if</span> i <span class="keyword">in</span> g_search_list <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data = g_queue.get(block=<span class="literal">True</span>, timeout=<span class="number">1</span>)</span><br><span class="line">            print(<span class="string">"CPUTask[%s] get data: %s"</span> % (task_id, data))</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> excep:</span><br><span class="line">            print(<span class="string">"CPUTask[%s] error: %s"</span> % (task_id, str(excep)))</span><br><span class="line">    print(<span class="string">"CPUTask[%s] end"</span> % task_id)</span><br><span class="line">    <span class="keyword">return</span> task_id</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">"cpu count:"</span>, multiprocessing.cpu_count(), <span class="string">"\n"</span>)</span><br><span class="line">    print(<span class="string">u"========== 直接执行IO密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    task_io(<span class="number">0</span>)</span><br><span class="line">    print(<span class="string">u"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 多线程执行IO密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    thread_list = [threading.Thread(target=task_io, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        <span class="keyword">if</span> t.is_alive():</span><br><span class="line">            t.join()</span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 多进程执行IO密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    process_list = [multiprocessing.Process(target=task_io, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(multiprocessing.cpu_count())]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        p.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        <span class="keyword">if</span> p.is_alive():</span><br><span class="line">            p.join()</span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 直接执行CPU密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    task_cpu(<span class="number">0</span>)</span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 多线程执行CPU密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    thread_list = [threading.Thread(target=task_cpu, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        <span class="keyword">if</span> t.is_alive():</span><br><span class="line">            t.join()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 多进程执行cpu密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    process_list = [multiprocessing.Process(target=task_cpu, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(multiprocessing.cpu_count())]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        p.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        <span class="keyword">if</span> p.is_alive():</span><br><span class="line">            p.join()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;通过实例实验，比较用多线程和多进程耗时情况，并进行总结归纳，选择效率最高的方法。&lt;/p&gt;
    
    </summary>
    
      <category term="编程积累" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/"/>
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/Python/"/>
    
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Multiprocessing基础</title>
    <link href="https://wandouduoduo.netlify.com/articles/9a80786c.html"/>
    <id>https://wandouduoduo.netlify.com/articles/9a80786c.html</id>
    <published>2019-11-29T07:40:05.000Z</published>
    <updated>2019-11-29T10:50:01.360Z</updated>
    
    <content type="html"><![CDATA[<p>multiprocessing是Python的标准模块，它既可以用来编写多进程，也可以用来编写多线程。如果是多线程的话，用multiprocessing.dummy即可，用法与multiprocessing基本相同，这里主要介绍多进程的用法，欢迎纠错。</p><h2 id="Multiprocessing介绍"><a href="#Multiprocessing介绍" class="headerlink" title="Multiprocessing介绍"></a>Multiprocessing介绍</h2><h5 id="为什么要使用python多进程？"><a href="#为什么要使用python多进程？" class="headerlink" title="为什么要使用python多进程？"></a>为什么要使用python<strong>多进程</strong>？</h5><p>因为python使用全局解释器锁(GIL)，他会将进程中的线程序列化，也就是多核cpu实际上并不能达到并行提高速度的目的，而使用多进程则是不受限的，所以实际应用中都是推荐多进程的。<br>如果每个子进程执行需要消耗的时间非常短（执行+1操作等），这不必使用多进程，因为进程的启动关闭也会耗费资源。<br>当然使用多进程往往是用来处理CPU密集型（科学计算）的需求，如果是IO密集型（文件读取，爬虫等）则可以使用多线程去处理。</p><a id="more"></a><h2 id="multiprocessing常用组件及功能"><a href="#multiprocessing常用组件及功能" class="headerlink" title="multiprocessing常用组件及功能"></a>multiprocessing常用组件及功能</h2><p>创建管理进程模块：</p><ul><li>Process (用于创建进程模块）</li><li>Pool（用于创建管理进程池）</li><li>Queue（用于进程通信，资源共享）</li><li>Value，Array（用于进程通信，资源共享）</li><li>Pipe（用于管道通信）</li><li>Manager（用于资源共享）</li></ul><p>同步子进程模块：</p><ul><li>Condition</li><li>Event</li><li>Lock</li><li>RLock</li><li>Semaphore</li></ul><h2 id="Multiprocessing进程管理模块"><a href="#Multiprocessing进程管理模块" class="headerlink" title="Multiprocessing进程管理模块"></a>Multiprocessing进程管理模块</h2><p>说明：由于篇幅有限，模块具体用法结束请参考每个模块的具体链接。</p><h5 id="Process模块"><a href="#Process模块" class="headerlink" title="Process模块"></a>Process模块</h5><p>Process模块用来创建子进程，是Multiprocessing核心模块，使用方式与Threading类似，可以实现多进程的创建，启动，关闭等操作。</p><h5 id="Pool模块"><a href="#Pool模块" class="headerlink" title="Pool模块"></a>Pool模块</h5><p>Pool模块是用来创建管理进程池的，当子进程非常多且需要控制子进程数量时可以使用此模块。</p><h5 id="Queue模块"><a href="#Queue模块" class="headerlink" title="Queue模块"></a>Queue模块</h5><p>Queue模块用来控制进程安全，与线程中的Queue用法一样。</p><h5 id="Pipe模块"><a href="#Pipe模块" class="headerlink" title="Pipe模块"></a>Pipe模块</h5><p>Pipe模块用来管道操作。</p><h5 id="Manager模块"><a href="#Manager模块" class="headerlink" title="Manager模块"></a>Manager模块</h5><p>Manager模块常与Pool模块一起使用，作用是共享资源。</p><h4 id="Multiprocessing同步进程模块"><a href="#Multiprocessing同步进程模块" class="headerlink" title="Multiprocessing同步进程模块"></a>Multiprocessing同步进程模块</h4><h5 id="Lock模块"><a href="#Lock模块" class="headerlink" title="Lock模块"></a>Lock模块</h5><p>作用：当多个进程需要访问共享资源的时候，Lock可以用来避免访问的冲突。</p><p>具体场景：所有的任务在打印的时候都会向同一个标准输出(stdout)输出。这样输出的字符会混合在一起，无法阅读。使用Lock同步，在一个任务输出完成之后，再允许另一个任务输出，可以避免多个任务同时向终端输出。</p><p>代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process, Lock  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">l</span><span class="params">(lock, num)</span>:</span>      </span><br><span class="line">lock.acquire()      </span><br><span class="line"><span class="keyword">print</span> <span class="string">"Hello Num: %s"</span> % (num)      </span><br><span class="line">lock.release()  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:      </span><br><span class="line">lock = Lock()  <span class="comment">#这个一定要定义为全局    </span></span><br><span class="line"><span class="keyword">for</span> num <span class="keyword">in</span> range(<span class="number">20</span>):          </span><br><span class="line">Process(target=l, args=(lock, num)).start()  <span class="comment">#这个类似多线程中的threading，但是进程太多了，控制不了。</span></span><br></pre></td></tr></table></figure><h5 id="Semaphore模块"><a href="#Semaphore模块" class="headerlink" title="Semaphore模块"></a>Semaphore模块</h5><p>作用：用来控制对共享资源的访问数量，例如池的最大连接数。</p><h5 id="Event模块"><a href="#Event模块" class="headerlink" title="Event模块"></a>Event模块</h5><p>作用：用来实现进程间同步通信。</p><h2 id="Multiprocessing-dummy多线程"><a href="#Multiprocessing-dummy多线程" class="headerlink" title="Multiprocessing.dummy多线程"></a>Multiprocessing.dummy多线程</h2><p>Multiprocessing.dummy用法与Multiprocessing用法基本相同，只不过是用来创建多线程。</p><h2 id="使用Multiprocessing疑问"><a href="#使用Multiprocessing疑问" class="headerlink" title="使用Multiprocessing疑问"></a>使用Multiprocessing疑问</h2><ul><li><em>启动多进程的代码一定要放在</em> if <strong>name</strong>==”<strong>main</strong>“: <em>后面吗？</em></li></ul><p>　　解答：windows系统下，想要启动一个子进程，必须加上<em>if *</em>name<strong>==”</strong>main*<em>“:</em>，linux则不需要。</p><ul><li><em>父进程中的全局变量能被子进程共享吗？</em></li></ul><p>　　解答：不行，因为每个进程享有独立的内存数据，如果想要共享资源，可以使用Manage类，或者Queue等模块。</p><ul><li><em>子进程能结束其他子进程或父进程吗？如果能，怎么通过子进程去结束所有进程?</em></li></ul><p>　　解答：此需求可以稍作修改：所有的子进程都是为了完成一件事情，而当某个子进程完成该事情后，父进程就该结束所有子进程，请问该怎么做？此时结束所有子进程的操作可以交给父进程去做，因为子进程想要结束另外的子进程比较难实现。<br>　　那么问题就又变成了父进程什么时候该结束所有进程？<br>　　其中一个思路是<em>获取每个子进程的返回值</em>，一旦有返回True（结束的标记），则立马结束所有进程；<br>　　另外一种思路是<em>使用共享资源</em>，父进程可以一直去判断这个公共资源，一旦子进程将它改变，则结束所有子进程。（推荐使用前者，因为多进程中不推荐使用资源共享）</p><ul><li><em>子进程中还能再创建子进程吗？</em></li></ul><p>解答：可以，子进程可以再创建进程，线程中也可以创建进程。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;multiprocessing是Python的标准模块，它既可以用来编写多进程，也可以用来编写多线程。如果是多线程的话，用multiprocessing.dummy即可，用法与multiprocessing基本相同，这里主要介绍多进程的用法，欢迎纠错。&lt;/p&gt;
&lt;h2 id=&quot;Multiprocessing介绍&quot;&gt;&lt;a href=&quot;#Multiprocessing介绍&quot; class=&quot;headerlink&quot; title=&quot;Multiprocessing介绍&quot;&gt;&lt;/a&gt;Multiprocessing介绍&lt;/h2&gt;&lt;h5 id=&quot;为什么要使用python多进程？&quot;&gt;&lt;a href=&quot;#为什么要使用python多进程？&quot; class=&quot;headerlink&quot; title=&quot;为什么要使用python多进程？&quot;&gt;&lt;/a&gt;为什么要使用python&lt;strong&gt;多进程&lt;/strong&gt;？&lt;/h5&gt;&lt;p&gt;因为python使用全局解释器锁(GIL)，他会将进程中的线程序列化，也就是多核cpu实际上并不能达到并行提高速度的目的，而使用多进程则是不受限的，所以实际应用中都是推荐多进程的。&lt;br&gt;如果每个子进程执行需要消耗的时间非常短（执行+1操作等），这不必使用多进程，因为进程的启动关闭也会耗费资源。&lt;br&gt;当然使用多进程往往是用来处理CPU密集型（科学计算）的需求，如果是IO密集型（文件读取，爬虫等）则可以使用多线程去处理。&lt;/p&gt;
    
    </summary>
    
      <category term="编程积累" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/"/>
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/Python/"/>
    
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python之多进程详解</title>
    <link href="https://wandouduoduo.netlify.com/articles/a5c1f14c.html"/>
    <id>https://wandouduoduo.netlify.com/articles/a5c1f14c.html</id>
    <published>2019-11-29T07:34:06.000Z</published>
    <updated>2019-11-29T10:50:01.364Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>Python中的multiprocess提供了Process类，实现进程相关的功能。但是它基于fork机制，因此不被windows平台支持。想要在windows中运行，必须使用 if <strong>name</strong> == ‘<strong>main</strong>: 的方式)。并且多进程就是开启多个进程，每个进程之间是不会互相通信互相干扰的，适用于密集计算。</p><a id="more"></a><h2 id="案例一-基础用法"><a href="#案例一-基础用法" class="headerlink" title="案例一 基础用法"></a>案例一 基础用法</h2><p>多进程的使用方法和多线程使用方法基本一样，所以如果你会多线程用法多进程也就懂了，有一点要注意，定义多进程，然后传递参数的时候，如果是有一个参数就是用args=（i，）一定要加上逗号，如果有两个或者以上的参数就不用这样。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">import multiprocessing</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line">def fun(i):</span><br><span class="line">    print sys.path</span><br><span class="line">    print sys.version_info</span><br><span class="line">    print sys.platform</span><br><span class="line">    print sys.long_info</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    m = multiprocessing.Process(target=fun,args=(1,))</span><br><span class="line">    m.start()</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[&apos;E:\\python27\\python study&apos;, &apos;E:\\python27&apos;, &apos;C:\\windows\\SYSTEM32\\python27.zip&apos;, &apos;F:\\Python27\\DLLs&apos;, &apos;F:\\Python27\\lib&apos;, &apos;F:\\Python27\\lib\\plat-win&apos;, &apos;F:\\Python27\\lib\\lib-tk&apos;, &apos;F:\\Python27&apos;, &apos;F:\\Python27\\lib\\site-packages&apos;, &apos;F:\\Python27\\lib\\site-packages\\certifi-2017.7.27.1-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\idna-2.6-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\pypiwin32-219-py2.7-win-amd64.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\future-0.16.0-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\dis3-0.1.1-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\macholib-1.8-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\pefile-2017.9.3-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\altgraph-0.14-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\beautifulsoup4-4.6.0-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\chardet-3.0.4-py2.7.egg&apos;]</span><br><span class="line">sys.version_info(major=2, minor=7, micro=14, releaselevel=&apos;final&apos;, serial=0)</span><br><span class="line">win32</span><br><span class="line">sys.long_info(bits_per_digit=30, sizeof_digit=4)</span><br></pre></td></tr></table></figure><h2 id="案例二-数据通信"><a href="#案例二-数据通信" class="headerlink" title="案例二 数据通信"></a>案例二 数据通信</h2><p>ipc：就是进程间的通信模式，常用的一半是socke，rpc，pipe和消息队列等。</p><p>multiprocessing提供了threading包中没有的IPC(比如Pipe和Queue)，效率上更高。应优先考虑Pipe和Queue，避免使用Lock/Event/Semaphore/Condition等同步方式 (因为它们占据的不是用户进程的资源)。</p><h4 id="使用Array共享数据"><a href="#使用Array共享数据" class="headerlink" title="使用Array共享数据"></a>使用Array共享数据</h4><p>对于Array数组类，括号内的“i”表示它内部的元素全部是int类型，而不是指字符“i”，数组内的元素可以预先指定，也可以只指定数组的长度。Array类在实例化的时候必须指定数组的数据类型和数组的大小，类似temp = Array(‘i’, 5)。对于数据类型有下面的对应关系：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&apos;c&apos;: ctypes.c_char, &apos;u&apos;: ctypes.c_wchar,</span><br><span class="line">&apos;b&apos;: ctypes.c_byte, &apos;B&apos;: ctypes.c_ubyte,</span><br><span class="line">&apos;h&apos;: ctypes.c_short, &apos;H&apos;: ctypes.c_ushort,</span><br><span class="line">&apos;i&apos;: ctypes.c_int, &apos;I&apos;: ctypes.c_uint,</span><br><span class="line">&apos;l&apos;: ctypes.c_long, &apos;L&apos;: ctypes.c_ulong,</span><br><span class="line">&apos;f&apos;: ctypes.c_float, &apos;d&apos;: ctypes.c_double</span><br></pre></td></tr></table></figure><p>代码实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Process</span><br><span class="line">from multiprocessing import Array</span><br><span class="line"></span><br><span class="line">def func(i,temp):</span><br><span class="line">    temp[0] += 100</span><br><span class="line">    print(&quot;进程%s &quot; % i, &apos; 修改数组第一个元素后-----&gt;&apos;, temp[0])</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    temp = Array(&apos;i&apos;, [1, 2, 3, 4])</span><br><span class="line">    for i in range(10):</span><br><span class="line">        p = Process(target=func, args=(i, temp))</span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">进程2   修改数组第一个元素后-----&gt; 101</span><br><span class="line">进程4   修改数组第一个元素后-----&gt; 201</span><br><span class="line">进程5   修改数组第一个元素后-----&gt; 301</span><br><span class="line">进程3   修改数组第一个元素后-----&gt; 401</span><br><span class="line">进程1   修改数组第一个元素后-----&gt; 501</span><br><span class="line">进程6   修改数组第一个元素后-----&gt; 601</span><br><span class="line">进程9   修改数组第一个元素后-----&gt; 701</span><br><span class="line">进程8   修改数组第一个元素后-----&gt; 801</span><br><span class="line">进程0   修改数组第一个元素后-----&gt; 901</span><br><span class="line">进程7   修改数组第一个元素后-----&gt; 1001</span><br></pre></td></tr></table></figure><h4 id="使用Manager共享数据"><a href="#使用Manager共享数据" class="headerlink" title="使用Manager共享数据"></a>使用Manager共享数据</h4><p>通过Manager类也可以实现进程间数据的共享，主要用于线程池之间通信，Manager()返回的manager对象提供一个服务进程，使得其他进程可以通过代理的方式操作Python对象。manager对象支持 list, dict, Namespace, Lock, RLock, Semaphore, BoundedSemaphore, Condition, Event, Barrier, Queue, Value ,Array等多种格式。</p><p>代码实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Process</span><br><span class="line">from multiprocessing import Manager</span><br><span class="line"></span><br><span class="line">def func(i, dic):</span><br><span class="line">    dic[&quot;num&quot;] = 100+i</span><br><span class="line">    print(dic.items())</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    dic = Manager().dict()</span><br><span class="line">    for i in range(10):</span><br><span class="line">        p = Process(target=func, args=(i, dic))</span><br><span class="line">        p.start()</span><br><span class="line">        p.join()</span><br></pre></td></tr></table></figure><h4 id="使用queues的Queue类共享数据"><a href="#使用queues的Queue类共享数据" class="headerlink" title="使用queues的Queue类共享数据"></a>使用queues的Queue类共享数据</h4><p>multiprocessing是一个包，它内部有一个queues模块，提供了一个Queue队列类，可以实现进程间的数据共享，如下例所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import multiprocessing</span><br><span class="line">from multiprocessing import Process</span><br><span class="line">from multiprocessing import queues</span><br><span class="line"></span><br><span class="line">def func(i, q):</span><br><span class="line">    ret = q.get()</span><br><span class="line">    print(&quot;进程%s从队列里获取了一个%s，然后又向队列里放入了一个%s&quot; % (i, ret, i))</span><br><span class="line">    q.put(i)</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    lis = queues.Queue(20, ctx=multiprocessing)</span><br><span class="line">    lis.put(0)</span><br><span class="line">    for i in range(10):</span><br><span class="line">        p = Process(target=func, args=(i, lis,))</span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">进程1从队列里获取了一个0，然后又向队列里放入了一个1</span><br><span class="line">进程4从队列里获取了一个1，然后又向队列里放入了一个4</span><br><span class="line">进程2从队列里获取了一个4，然后又向队列里放入了一个2</span><br><span class="line">进程6从队列里获取了一个2，然后又向队列里放入了一个6</span><br><span class="line">进程0从队列里获取了一个6，然后又向队列里放入了一个0</span><br><span class="line">进程5从队列里获取了一个0，然后又向队列里放入了一个5</span><br><span class="line">进程9从队列里获取了一个5，然后又向队列里放入了一个9</span><br><span class="line">进程7从队列里获取了一个9，然后又向队列里放入了一个7</span><br><span class="line">进程3从队列里获取了一个7，然后又向队列里放入了一个3</span><br><span class="line">进程8从队列里获取了一个3，然后又向队列里放入了一个8</span><br></pre></td></tr></table></figure><p>例如来跑多进程对一批IP列表进行运算，运算后的结果都存到Queue队列里面，这个就必须使用multiprocessing提供的Queue来实现</p><p>关于queue和Queue，在Python库中非常频繁的出现，很容易就搞混淆了。甚至是multiprocessing自己还有一个Queue类(大写的Q)和的Manager类中提供的Queue方法，一样能实现消息队列queues.Queue的功能，导入方式是from multiprocessing import Queue，前者Queue用于多个进程间通信，和queues.Queue()差不多，后者Manager().queue用于进程池之间通信。</p><h4 id="使用pipe实现进程间通信"><a href="#使用pipe实现进程间通信" class="headerlink" title="使用pipe实现进程间通信"></a>使用pipe实现进程间通信</h4><p>pipe只能适用于两个进程间通信，queue则没这个限制，他有两个方法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">receive_pi = Pipe()</span><br><span class="line"># 定义变量，用来获取数据</span><br><span class="line">send_pi = Pipe()</span><br><span class="line"># 用来发送数据</span><br></pre></td></tr></table></figure><p>具体例子如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pipe,Process</span><br><span class="line">import time</span><br><span class="line">def produce(pipe):</span><br><span class="line">    pipe.send(&apos;666&apos;)</span><br><span class="line">    time.sleep(1)</span><br><span class="line">def consumer(pipe):</span><br><span class="line">    print(pipe.recv())</span><br><span class="line">    # 有些类似socket的recv方法</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    send_pi,recv_pi = Pipe()</span><br><span class="line">    my_pro = Process(target=produce,args=(send_pi,))</span><br><span class="line">    my_con = Process(target=consumer,args=(recv_pi,))</span><br><span class="line">    my_pro.start()</span><br><span class="line">    my_con.start()</span><br><span class="line">    my_pro.join()</span><br><span class="line">    my_con.join()</span><br></pre></td></tr></table></figure><p>pipe相当于queue的一个子集，只能服务两个进程，pipe的性能高于queue。</p><h2 id="案例三-进程锁"><a href="#案例三-进程锁" class="headerlink" title="案例三 进程锁"></a>案例三 进程锁</h2><p>一般来说每个进程使用单独的空间，不必加进程锁的，但是如果你需要先实现进程数据共享，<strong>使用案例二中的代码</strong>，又害怕造成数据抢夺和脏数据的问题。就可以设置进程锁，与threading类似，在multiprocessing里也有同名的锁类RLock，Lock，Event，Condition和 Semaphore，连用法都是一样样的。</p><p><strong>如果有多个进程要上锁，使用multiprocessing.Manager().BoundedSemaphore(1)</strong></p><p>代码实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Process</span><br><span class="line">from multiprocessing import Array</span><br><span class="line">from multiprocessing import RLock, Lock, Event, Condition, Semaphore</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">def func(i,lis,lc):</span><br><span class="line">    lc.acquire()</span><br><span class="line">    lis[0] = lis[0] - 1</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    print(&apos;say hi&apos;, lis[0])</span><br><span class="line">    lc.release()</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    array = Array(&apos;i&apos;, 1)</span><br><span class="line">    array[0] = 10</span><br><span class="line">    lock = RLock()</span><br><span class="line">    for i in range(10):</span><br><span class="line">        p = Process(target=func, args=(i, array, lock))</span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">say hi 9</span><br><span class="line">say hi 8</span><br><span class="line">say hi 7</span><br><span class="line">say hi 6</span><br><span class="line">say hi 5</span><br><span class="line">say hi 4</span><br><span class="line">say hi 3</span><br><span class="line">say hi 2</span><br><span class="line">say hi 1</span><br><span class="line">say hi 0</span><br></pre></td></tr></table></figure><h2 id="案例四-进程池"><a href="#案例四-进程池" class="headerlink" title="案例四 进程池"></a>案例四 进程池</h2><p>from multiprocessing import Pool导入就行，非常容易使用的。进程池内部维护了一个进程序列，需要时就去进程池中拿取一个进程，如果进程池序列中没有可供使用的进程，那么程序就会等待，直到进程池中有可用进程为止。</p><ol><li>apply() 同步执行（串行）</li><li>apply_async() 异步执行（并行）</li><li>terminate() 立刻关闭进程池</li><li>join() 主进程等待所有子进程执行完毕。必须在close或terminate()之后。</li><li>close() 等待所有进程结束后，才关闭进程池。</li></ol><p>代码实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">import time</span><br><span class="line">def func(args):</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    print(&quot;正在执行进程 &quot;, args)</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    p = Pool(5)     # 创建一个包含5个进程的进程池</span><br><span class="line">    for i in range(30):</span><br><span class="line">        # 有30个任务</span><br><span class="line">        p.apply_async(func=func, args=(i,))</span><br><span class="line">        # 异步执行，并发。这里不用target，要用func</span><br><span class="line">    p.close()           # 等子进程执行完毕后关闭进程池</span><br><span class="line">    # time.sleep(2)</span><br><span class="line">    # p.terminate()     # 立刻关闭进程池</span><br><span class="line">    p.join()</span><br></pre></td></tr></table></figure><p>from multiprocessing.dummy import Pool as ThreadPool 是多线程进程池，绑定一个cpu核心。from multiprocessing import Pool多进程，运行于多个cpu核心。multiprocessing 是多进程模块， 而multiprocessing.dummy是以相同API实现的多线程模块。<br>没有绕过GIL情况下，多线程一定受GIL限制。</p><p>代码实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing.dummy import Pool as tp</span><br><span class="line">def fun(i):</span><br><span class="line">    print i+i+i+i</span><br><span class="line"></span><br><span class="line">list_i=[range(100)]</span><br><span class="line"></span><br><span class="line">px = tp(processes=8)</span><br><span class="line"># 开启8个线程池</span><br><span class="line">px.map(fun,list_i)</span><br><span class="line">px.close()</span><br><span class="line">px.join()</span><br></pre></td></tr></table></figure><p>使用dummy方法可以不用<strong>name</strong>=’<strong>main</strong>‘，并且用法很简单，开启线程池用法一样，需要注意的是导入的参数，要在一个列表中导入。比如你有一批数据要放进这个线程池，就直接把这批数据放在一个列表中。</p><h2 id="案例五-爬虫进程池"><a href="#案例五-爬虫进程池" class="headerlink" title="案例五 爬虫进程池"></a>案例五 爬虫进程池</h2><p>案例来自<a href="https://morvanzhou.github.io/tutorials/data-manipulation/scraping/4-01-distributed-scraping/" target="_blank" rel="noopener">莫凡</a></p><h4 id="什么是分布式爬虫"><a href="#什么是分布式爬虫" class="headerlink" title="什么是分布式爬虫"></a>什么是分布式爬虫</h4><p>分布式爬虫主要是为了非常有效率的抓取网页, 我们的程序一般是单线程跑的, 指令也是一条条处理的, 每执行完一条指令才能跳到下一条. 那么在爬虫的世界里, 这里存在着一个问题.</p><p>如果你已经顺利地执行过了前几节的爬虫代码, 你会发现, 有时候代码运行的时间大部分都花在了下载网页上. 有时候不到一秒能下载好一张网页的 HTML, 有时候却要几十秒. 而且非要等到 HTML 下载好了以后, 才能执行网页分析等步骤. 这非常浪费时间.</p><p>如果我们能合理利用计算资源, 在下载一部分网页的时候就已经开始分析另一部分网页了. 这将会大大节省整个程序的运行时间. 又或者, 我们能同时下载多个网页, 同时分析多个网页, 这样就有种事倍功半的效用. 分布式爬虫的体系有很多种, 处理优化的问题也是多样的. 这里有一篇博客可以当做扩展阅读, 来了解当今比较流行的分布式爬虫框架.</p><h4 id="我们的分布式爬虫"><a href="#我们的分布式爬虫" class="headerlink" title="我们的分布式爬虫"></a>我们的分布式爬虫</h4><p>而今天我们想搭建的这一个爬虫, 就是同时下载, 同时分析的这一种类型的分布式爬虫. 虽然算不上特别优化的框架, 但是概念理解起来比较容易. 我有尝试过徒手写高级一点的分布式爬虫, 但是写起来非常麻烦. 我琢磨了一下, 打算给大家介绍的这种分布式爬虫代码也较好写, 而且效率比普通爬虫快了3.5倍. 我也特地画了张图给大家解释一下要搭建的分布式爬虫.</p><p><img src="/articles/a5c1f14c/1.png" alt="img"></p><p>主要来说, 我们最开始有一个网页, 比如说是莫烦Python的首页, 然后首页中有很多 url, 我们使用多进程 (Python多进程教程) 同时开始下载这些 url, 得到这些 url 的 HTML 以后, 同时开始解析 (比如 BeautifulSoup) 网页内容. 在网页中寻找这个网站还没有爬过的链接. 最终爬完整个 莫烦 Python 网站所有页面.</p><p>有了这种思路, 我们就可以开始写代码了. 你可以在我的 Github 一次性观看全部代码.</p><p>首先 import 全部要用的模块, 并规定一个主页. 注意, 我用这份代码测试我内网的网站(速度不受外网影响) 所以使用的 base_url 是 “<a href="http://127.0.0.1:4000/”" target="_blank" rel="noopener">http://127.0.0.1:4000/”</a>, 如果你要爬 莫烦Python, 你的 base_url 要是 “<a href="https://morvanzhou.github.io/”" target="_blank" rel="noopener">https://morvanzhou.github.io/”</a> (下载速度会受外网影响).</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import multiprocessing as mp</span><br><span class="line">import time</span><br><span class="line">from urllib.request import urlopen, urljoin</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line"># base_url = &quot;http://127.0.0.1:4000/&quot;</span><br><span class="line">base_url = &apos;https://morvanzhou.github.io/&apos;</span><br></pre></td></tr></table></figure><p>我们定义两个功能, 一个是用来爬取网页的(crawl), 一个是解析网页的(parse). 有了前几节内容的铺垫, 你应该能一言看懂下面的代码. crawl() 用 urlopen 来打开网页, 我用的内网测试, 所以为了体现下载网页的延迟, 添加了一个 time.sleep(0.1) 的下载延迟. 返回原始的 HTML 页面, parse() 就是在这个 HTML 页面中找到需要的信息, 我们用 BeautifulSoup 找 (BeautifulSoup 教程). 返回找到的信息.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">def crawl(url):</span><br><span class="line">    response = urlopen(url)</span><br><span class="line">    # time.sleep(0.1)             # slightly delay for downloading</span><br><span class="line">    return response.read().decode()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def parse(html):</span><br><span class="line">    soup = BeautifulSoup(html, &apos;lxml&apos;)</span><br><span class="line">    urls = soup.find_all(&apos;a&apos;, &#123;&quot;href&quot;: re.compile(&apos;^/.+?/$&apos;)&#125;)</span><br><span class="line">    title = soup.find(&apos;h1&apos;).get_text().strip()</span><br><span class="line">    page_urls = set([urljoin(base_url, url[&apos;href&apos;]) for url in urls])   # 去重</span><br><span class="line">    url = soup.find(&apos;meta&apos;, &#123;&apos;property&apos;: &quot;og:url&quot;&#125;)[&apos;content&apos;]</span><br><span class="line">    return title, page_urls, url</span><br></pre></td></tr></table></figure><p>网页中爬取中, 肯定会爬到重复的网址, 为了去除掉这些重复, 我们使用 python 的 set 功能. 定义两个 set, 用来搜集爬过的网页和没爬过的.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">unseen = set([base_url,])</span><br><span class="line">seen = set()</span><br></pre></td></tr></table></figure><h4 id="测试普通爬法"><a href="#测试普通爬法" class="headerlink" title="测试普通爬法"></a>测试普通爬法</h4><p>为了对比效果, 我们将在下面对比普通的爬虫和这种分布式的效果. 如果是普通爬虫, 我简化了一下接下来的代码, 将一些不影响的代码去除掉了, 如果你想看全部的代码, 请来到我的 Github. 我们用循环一个个 crawl unseen 里面的 url, 爬出来的 HTML 放到 parse 里面去分析得到结果. 接着就是更新 seen 和 unseen 这两个集合了.</p><p>特别注意: 任何网站都是有一个服务器压力的, 如果你爬的过于频繁, 特别是使用多进程爬取或异步爬取, 一次性提交请求给服务器太多次, 这将可能会使得服务器瘫痪, 你可能再也看不到莫烦 Python 了. 所以为了安全起见, 我限制了爬取数量(restricted_crawl=True). 因为我测试使用的是内网 “<a href="http://127.0.0.1:4000/”" target="_blank" rel="noopener">http://127.0.0.1:4000/”</a> 所以不会有这种压力. 你在以后的爬网页中, 会经常遇到这样的爬取次数的限制 (甚至被封号). 我以前爬 github 时就被限制成一小时只能爬60页.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># DON&apos;T OVER CRAWL THE WEBSITE OR YOU MAY NEVER VISIT AGAIN</span><br><span class="line">if base_url != &quot;http://127.0.0.1:4000/&quot;:</span><br><span class="line">    restricted_crawl = True</span><br><span class="line">else:</span><br><span class="line">    restricted_crawl = False</span><br><span class="line"></span><br><span class="line">while len(unseen) != 0:                 # still get some url to visit</span><br><span class="line">    if restricted_crawl and len(seen) &gt;= 20:</span><br><span class="line">        break</span><br><span class="line">    htmls = [crawl(url) for url in unseen]</span><br><span class="line">    results = [parse(html) for html in htmls]</span><br><span class="line"></span><br><span class="line">    seen.update(unseen)         # seen the crawled</span><br><span class="line">    unseen.clear()              # nothing unseen</span><br><span class="line"></span><br><span class="line">    for title, page_urls, url in results:</span><br><span class="line">        unseen.update(page_urls - seen)     # get new url to crawl</span><br></pre></td></tr></table></figure><p>使用这种单线程的方法, 在我的内网上面爬, 爬完整个 莫烦Python, 一共消耗 52.3秒. 接着我们把它改成多进程分布式.</p><h4 id="测试分布式爬法"><a href="#测试分布式爬法" class="headerlink" title="测试分布式爬法"></a>测试分布式爬法</h4><p>还是上一个 while 循环, 首先我们创建一个进程池(Pool). 不太懂进程池的朋友看过来. 然后我们修改得到 htmls 和 results 的两句代码. 其他都不变, 只将这两个功能给并行了. 我在这里写的都是简化代码, 你可以在这里 看到完整代码.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">pool = mp.Pool(4)</span><br><span class="line">while len(unseen) != 0:</span><br><span class="line">    # htmls = [crawl(url) for url in unseen]</span><br><span class="line">    # ---&gt;</span><br><span class="line">    crawl_jobs = [pool.apply_async(crawl, args=(url,)) for url in unseen]</span><br><span class="line">    htmls = [j.get() for j in crawl_jobs]</span><br><span class="line"></span><br><span class="line">    # results = [parse(html) for html in htmls]</span><br><span class="line">    # ---&gt;</span><br><span class="line">    parse_jobs = [pool.apply_async(parse, args=(html,)) for html in htmls]</span><br><span class="line">    results = [j.get() for j in parse_jobs]</span><br></pre></td></tr></table></figure><p>还是在内网测试, 只用了 16.3秒!! 这可比上面的单线程爬虫快了3.5倍. 而且我还不是在外网测试的. 如果在外网, 爬取一张网页的时间更长, 使用多进程会更加有效率, 节省的时间更多.</p><h2 id="各模块作用"><a href="#各模块作用" class="headerlink" title="各模块作用"></a>各模块作用</h2><h4 id="Process介绍"><a href="#Process介绍" class="headerlink" title="Process介绍"></a>Process介绍</h4><p>构造方法:</p><ol><li>Process([group [, target [, name [, args [, kwargs]]]]])</li><li>group: 线程组，目前还没有实现，库引用中提示必须是None；</li><li>target: 要执行的方法；</li><li>name: 进程名；</li><li>args/kwargs: 要传入方法的参数。</li></ol><p>实例方法:</p><ol><li>is_alive()：返回进程是否在运行。</li><li>join([timeout])：阻塞当前上下文环境的进程程，直到调用此方法的进程终止或到达指定的3. timeout（可选参数）。</li><li>start()：进程准备就绪，等待CPU调度。</li><li>run()：strat()调用run方法，如果实例进程时未制定传入target，这star执行t默认run()方法。</li><li>terminate()：不管任务是否完成，立即停止工作进程。</li></ol><p>属性：</p><ol><li>authkey</li><li>daemon：和线程的setDeamon功能一样（将父进程设置为守护进程，当父进程结束时，子进程也结束）。</li><li>exitcode(进程在运行时为None、如果为–N，表示被信号N结束）。</li><li>name：进程名字。</li><li>pid：进程号。</li></ol><h4 id="Pool介绍"><a href="#Pool介绍" class="headerlink" title="Pool介绍"></a>Pool介绍</h4><p>Multiprocessing.Pool可以提供指定数量的进程供用户调用，当有新的请求提交到pool中时，如果池还没有满，那么就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到规定最大值，那么该请求就会等待，直到池中有进程结束，才会创建新的进程来执行它。在共享资源时，只能使用Multiprocessing.Manager类，而不能使用Queue或者Array。Pool类用于需要执行的目标很多，而手动限制进程数量又太繁琐时，如果目标少且不用控制进程数量则可以用Process类。</p><p>构造方法：</p><ol><li>Pool([processes[, initializer[, initargs[, maxtasksperchild[, context]]]]])</li><li>processes ：使用的工作进程的数量，如果processes是None那么使用 os.cpu_count()返回的数量。</li><li>initializer： 如果initializer是None，那么每一个工作进程在开始的时候会调用initializer(*initargs)。</li><li>maxtasksperchild：工作进程退出之前可以完成的任务数，完成后用一个新的工作进程来替代原进程，来让闲置的资源被释放。maxtasksperchild默认是None，意味着只要Pool存在工作进程就会一直存活。</li><li>context: 用在制定工作进程启动时的上下文，一般使用 multiprocessing.Pool() 或者一个context对象的Pool()方法来创建一个池，两种方法都适当的设置了context。</li></ol><p>实例方法：</p><ol><li>apply_async(func[, args[, kwds[, callback]]]) 它是非阻塞。</li><li>apply(func[, args[, kwds]])是阻塞的</li><li>close() 关闭pool，使其不在接受新的任务。</li><li>terminate() 关闭pool，结束工作进程，不在处理未完成的任务。</li><li>join() 主进程阻塞，等待子进程的退出， join方法要在close或terminate之后使用。</li></ol><p>Pool使用方法</p><p>Pool+map函数</p><p>说明：此写法缺点在于只能通过map向函数传递一个参数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">def test(i):</span><br><span class="line">    print i</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    lists=[1,2,3]</span><br><span class="line">    pool=Pool(processes=2) #定义最大的进程数</span><br><span class="line">    pool.map(test,lists)        #p必须是一个可迭代变量。</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure><p>异步进程池（非阻塞）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">def test(i):</span><br><span class="line">    print i</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    pool = Pool(processes=10)</span><br><span class="line">    for i  in xrange(500):</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        For循环中执行步骤：</span><br><span class="line">        （1）循环遍历，将500个子进程添加到进程池（相对父进程会阻塞）</span><br><span class="line">        （2）每次执行10个子进程，等一个子进程执行完后，立马启动新的子进程。（相对父进程不阻塞）</span><br><span class="line"></span><br><span class="line">        apply_async为异步进程池写法。</span><br><span class="line">        异步指的是启动子进程的过程，与父进程本身的执行（print）是异步的，而For循环中往进程池添加子进程的过程，与父进程本身的执行却是同步的。</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        pool.apply_async(test, args=(i,)) #维持执行的进程总数为10，当一个进程执行完后启动一个新进程.       </span><br><span class="line">    print “test”</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure><p>执行顺序：For循环内执行了2个步骤，第一步：将500个对象放入进程池（阻塞）。第二步：同时执行10个子进程（非阻塞），有结束的就立即添加，维持10个子进程运行。（apply_async方法的会在执行完for循环的添加步骤后，直接执行后面的print语句，而apply方法会等所有进程池中的子进程运行完以后再执行后面的print语句）</p><p>注意：调用join之前，先调用close或者terminate方法，否则会出错。执行完close后不会有新的进程加入到pool,join函数等待所有子进程结束。</p><p>同步进程池（阻塞）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">def test(p):</span><br><span class="line">       print p</span><br><span class="line">       time.sleep(3)</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    pool = Pool(processes=10)</span><br><span class="line">    for i  in xrange(500):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    实际测试发现，for循环内部执行步骤：</span><br><span class="line">    （1）遍历500个可迭代对象，往进程池放一个子进程</span><br><span class="line">    （2）执行这个子进程，等子进程执行完毕，再往进程池放一个子进程，再执行。（同时只执行一个子进程）</span><br><span class="line">    for循环执行完毕，再执行print函数。</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">        pool.apply(test, args=(i,))   #维持执行的进程总数为10，当一个进程执行完后启动一个新进程.</span><br><span class="line">    print “test”</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure><p>说明：for循环内执行的步骤顺序，往进程池中添加一个子进程，执行子进程，等待执行完毕再添加一个子进程…..等500个子进程都执行完了，再执行print “test”。（从结果来看，并没有多进程并发）</p><h4 id="子进程返回值"><a href="#子进程返回值" class="headerlink" title="子进程返回值"></a>子进程返回值</h4><p>在实际使用多进程的时候，可能需要获取到子进程运行的返回值。如果只是用来存储，则可以将返回值保存到一个数据结构中；如果需要判断此返回值，从而决定是否继续执行所有子进程，则会相对比较复杂。另外在Multiprocessing中，可以利用Process与Pool创建子进程，这两种用法在获取子进程返回值上的写法上也不相同。这篇中，我们直接上代码，分析多进程中获取子进程返回值的不同用法，以及优缺点。</p><p>初级用法（Pool）</p><p>目的：存储子进程返回值</p><p>说明：如果只是单纯的存储子进程返回值，则可以使用Pool的apply_async异步进程池；当然也可以使用Process，用法与threading中的相同，这里只介绍前者。</p><p>实例：当进程池中所有子进程执行完毕后，输出每个子进程的返回值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">def test(p):     </span><br><span class="line">    return p</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    pool = Pool(processes=10)</span><br><span class="line">    result=[]</span><br><span class="line">    for i  in xrange(50000):</span><br><span class="line">       &apos;&apos;&apos;</span><br><span class="line">       for循环执行流程：</span><br><span class="line">       （1）添加子进程到pool，并将这个对象（子进程）添加到result这个列表中。（此时子进程并没有运行）</span><br><span class="line">       （2）执行子进程（同时执行10个）</span><br><span class="line">       &apos;&apos;&apos;</span><br><span class="line">       result.append(pool.apply_async(test, args=(i,)))#维持执行的进程总数为10，当一个进程执行完后添加新进程.       </span><br><span class="line">    pool.join()</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    遍历result列表，取出子进程对象，访问get()方法，获取返回值。（此时所有子进程已执行完毕）</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    for i in result:</span><br><span class="line">        print i.get()</span><br></pre></td></tr></table></figure><p>错误写法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">for i  in xrange(50000):</span><br><span class="line">   t=pool.apply_async(test, args=(i,)))</span><br><span class="line">   print t.get()</span><br></pre></td></tr></table></figure><p>说明：这样会造成阻塞，因为get()方法只能等子进程运行完毕后才能调用成功，否则会一直阻塞等待。如果写在for循环内容，相当于变成了同步，执行效率将会非常低。</p><p>高级用法（Pool）<br>目的：父进程实时获取子进程返回值，以此为标记结束所有进程。</p><p>实例（一）<br>执行子进程的过程中，不断获取返回值并校验，如果返回值为True则结果所有进程。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">import Queue</span><br><span class="line">import time</span><br><span class="line">def test(p):</span><br><span class="line">    time.sleep(0.001)</span><br><span class="line">    if p==10000:</span><br><span class="line">        return True</span><br><span class="line">    else:</span><br><span class="line">        return False</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    pool = Pool(processes=10)</span><br><span class="line">    q=Queue.Queue()</span><br><span class="line">    for i  in xrange(50000):</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        将子进程对象存入队列中。</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        q.put(pool.apply_async(test, args=(i,)))#维持执行的进程总数为10，当一个进程执行完后添加新进程.       </span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    因为这里使用的为pool.apply_async异步方法，因此子进程执行的过程中，父进程会执行while，获取返回值并校验。</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    while 1:</span><br><span class="line">        if q.get().get():</span><br><span class="line">            pool.terminate() #结束进程池中的所有子进程。</span><br><span class="line">            break</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure><p>说明：总共要执行50000个子进程（并发数量为10），当其中一个子进程返回True时，结束进程池。因为使用了apply_async为异步进程，因此在执行完for循环的添加子进程操作后（只是添加并没有执行完所有的子进程），可以直接执行while代码，实时判断子进程返回值是否有True，有的话结束所有进程。</p><p>优点：不必等到所有子进程结束再结束程序，只要得到想要的结果就可以提前结束，节省资源。</p><p>不足：当需要执行的子进程非常大时，不适用，因为for循环在添加子进程时，要花费很长的时间，虽然是异步，但是也需要等待for循环添加子进程操作结束才能执行while代码，因此会比较慢。</p><p>实例（二）</p><p>多线程+多进程，添加执行子进程的过程中，不断获取返回值并校验，如果返回值为True则结果所有进程。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">import Queue</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">def test(p):</span><br><span class="line">    time.sleep(0.001)</span><br><span class="line">    if p==10000:</span><br><span class="line">        return True</span><br><span class="line">    else:</span><br><span class="line">        return False</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    result=Queue.Queue() #队列</span><br><span class="line">    pool = Pool()</span><br><span class="line">    def pool_th():</span><br><span class="line">        for i  in xrange(50000000): ##这里需要创建执行的子进程非常多</span><br><span class="line">            try:</span><br><span class="line">                result.put(pool.apply_async(test, args=(i,)))</span><br><span class="line">            except:</span><br><span class="line">                break</span><br><span class="line">    def result_th():</span><br><span class="line">        while 1:</span><br><span class="line">            a=result.get().get() #获取子进程返回值</span><br><span class="line">            if a:</span><br><span class="line">                pool.terminate() #结束所有子进程</span><br><span class="line">                break</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    利用多线程，同时运行Pool函数创建执行子进程，以及运行获取子进程返回值函数。</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    t1=threading.Thread(target=pool_th)</span><br><span class="line">    t2=threading.Thread(target=result_th)</span><br><span class="line">    t1.start()</span><br><span class="line">    t2.start()</span><br><span class="line">    t1.join()</span><br><span class="line">    t2.join()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure><p>执行流程：利用多线程，创建一个执行pool_th函数线程，一个执行result_th函数线程，pool_th函数用来添加进程池，开启进程执行功能函数并将子进程对象存入队列，而result_th()函数用来不停地从队列中取子进程对象，调用get（）方法获取返回值。等发现其中存在子进程的返回值为True时，结束所有进程，最后结束线程。</p><p>优点：弥补了实例（一）的不足，即使for循环的子进程数量很多，也能提高性能，因为for循环与判断子进程返回值同时进行。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;Python中的multiprocess提供了Process类，实现进程相关的功能。但是它基于fork机制，因此不被windows平台支持。想要在windows中运行，必须使用 if &lt;strong&gt;name&lt;/strong&gt; == ‘&lt;strong&gt;main&lt;/strong&gt;: 的方式)。并且多进程就是开启多个进程，每个进程之间是不会互相通信互相干扰的，适用于密集计算。&lt;/p&gt;
    
    </summary>
    
      <category term="编程积累" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/"/>
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/Python/"/>
    
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python之多线程详解</title>
    <link href="https://wandouduoduo.netlify.com/articles/e0b461d5.html"/>
    <id>https://wandouduoduo.netlify.com/articles/e0b461d5.html</id>
    <published>2019-11-29T07:28:51.000Z</published>
    <updated>2019-11-29T10:50:01.363Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>线程是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务，多线程就是在一个进程中的多个线程，如果使用多线程默认开启一个主线程，按照程序需求自动开启多个线程(也可以自己定义线程数)。</p><a id="more"></a><h2 id="多线程知识点"><a href="#多线程知识点" class="headerlink" title="多线程知识点"></a>多线程知识点</h2><ol><li>Python 在设计之初就考虑到要在解释器的主循环中，同时只有一个线程在执行，即在任意时刻，只有一个线程在解释器中运行。对Python 虚拟机的访问由全局解释器锁（GIL）来控制，正是这个锁能保证同一时刻只有一个线程在运行。</li><li>多线程共享主进程的资源，所以可能还会改变其中的变量，这个时候就要加上线程锁，每次执行完一个线程在执行下一个线程。</li><li>因为每次只能有一个线程运行，多线程怎么实现的呢？Python解释器中一个线程做完了任务然后做IO(文件读写)操作的时候，这个线程就退出，然后下一个线程开始运行，循环之。</li><li>当你读完上面三点你就知道多线程如何运行起来，并且知道多线程常用在那些需要等待然后执行的应用程序上(比如爬虫读取到数据，然后保存的时候下一个线程开始启动)也就是说多线程适用于IO密集型的任务量（文件存储，网络通信）。</li><li>注意一点，定义多线程，然后传递参数的时候，如果是有一个参数就是用args=（i，）一定要加上逗号，如果有两个或者以上的参数就不用这样。</li></ol><h2 id="代码实例"><a href="#代码实例" class="headerlink" title="代码实例"></a>代码实例</h2><h4 id="案例一-多线程核心用法"><a href="#案例一-多线程核心用法" class="headerlink" title="案例一 多线程核心用法"></a>案例一 多线程核心用法</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line"></span><br><span class="line">def loop():</span><br><span class="line">    #定义一个要循环的函数，当然后面肯定会定义好几个函数</span><br><span class="line">    print &apos;thread %s is running...&apos; % threading.current_thread().name</span><br><span class="line">    #threading.current_thread().name就是当前线程的名字  在声明线程的时候可以自定义子线程的名字</span><br><span class="line">    n = 0</span><br><span class="line">    while n &lt; 10:</span><br><span class="line">        n = n + 1</span><br><span class="line">        print &apos;%s &gt;&gt;&gt; %s&apos; % (threading.current_thread().name, n)</span><br><span class="line">        #输出当前线程名字  和循环的参数n</span><br><span class="line">    print &apos;thread %s ended.&apos; % threading.current_thread().name</span><br><span class="line">print &apos;thread %s is running...&apos; % threading.current_thread().name</span><br><span class="line"></span><br><span class="line">#下面的一部分就是threading的核心用法</span><br><span class="line">#包括target name args 之类的 一般我只用targer=你定义的函数名</span><br><span class="line">t = threading.Thread(target=loop, name=&apos;线程名:&apos;)</span><br><span class="line"># 在这里就申明了这个线程的名字</span><br><span class="line">t.start()</span><br><span class="line">#开始</span><br><span class="line">t.join()</span><br><span class="line">#关于join的相关信息我会在后面的代码详说</span><br><span class="line">print &apos;thread %s ended.&apos; % threading.current_thread().name</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">thread MainThread is running...</span><br><span class="line">thread 线程名: is running...</span><br><span class="line">线程名: &gt;&gt;&gt; 1</span><br><span class="line">线程名: &gt;&gt;&gt; 2</span><br><span class="line">线程名: &gt;&gt;&gt; 3</span><br><span class="line">线程名: &gt;&gt;&gt; 4</span><br><span class="line">线程名: &gt;&gt;&gt; 5</span><br><span class="line">线程名: &gt;&gt;&gt; 6</span><br><span class="line">线程名: &gt;&gt;&gt; 7</span><br><span class="line">线程名: &gt;&gt;&gt; 8</span><br><span class="line">线程名: &gt;&gt;&gt; 9</span><br><span class="line">线程名: &gt;&gt;&gt; 10</span><br><span class="line">thread 线程名: ended.</span><br><span class="line">thread MainThread ended.</span><br></pre></td></tr></table></figure><h4 id="案例二-线程锁"><a href="#案例二-线程锁" class="headerlink" title="案例二 线程锁"></a>案例二 线程锁</h4><p>前面有说到过，多线程是共享内存的，所以其中的变量如果发生了改变的话就会改变后边的变量，导致异常，这个时候可以加上线程锁。线程锁的概念就是主要这个线程运行完后再运行下一个线程。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line"></span><br><span class="line">def loop():</span><br><span class="line">    l.acquire()</span><br><span class="line">    # 这里相当于把线程加了锁，目前只允许这一个线程运行</span><br><span class="line">    print &apos;thread %s is running...&apos; % threading.current_thread().name</span><br><span class="line">    #threading.current_thread().name就是当前线程的名字  在声明线程的时候可以自定义子线程的名字</span><br><span class="line">    n = 0</span><br><span class="line">    while n &lt; 10:</span><br><span class="line">        n = n + 1</span><br><span class="line">        print &apos;%s &gt;&gt;&gt; %s&apos; % (threading.current_thread().name, n)</span><br><span class="line">        #输出当前线程名字  和循环的参数n</span><br><span class="line">    print &apos;thread %s ended.&apos; % threading.current_thread().name</span><br><span class="line">    l.release()</span><br><span class="line">    # 这里是把线程锁解开，可以再运行写一个线程</span><br><span class="line">print &apos;thread %s is running...&apos; % threading.current_thread().name</span><br><span class="line"></span><br><span class="line">#下面的一部分就是threading的核心用法</span><br><span class="line">#包括target name args 之类的 一般我只用targer=你定义的函数名</span><br><span class="line">t = threading.Thread(target=loop, name=&apos;线程名:&apos;)</span><br><span class="line">l = threading.Lock()</span><br><span class="line"># 这里申明一个线程锁</span><br><span class="line">t.start()</span><br><span class="line">#开始</span><br><span class="line">t.join()</span><br><span class="line">#关于join的相关信息我会在后面的代码详说</span><br><span class="line">print &apos;thread %s ended.&apos; % threading.current_thread().name</span><br></pre></td></tr></table></figure><p>使用线程锁后，程序按照一个一个有序执行。其中lock还有Rlock的方法，RLock允许在同一线程中被多次acquire。而Lock却不允许这种情况。否则会出现死循环，程序不知道解哪一把锁。注意：如果使用RLock，那么acquire和release必须成对出现，即调用了n次acquire，必须调用n次的release才能真正释放所占用的锁</p><h4 id="案例三-join-方法的使用"><a href="#案例三-join-方法的使用" class="headerlink" title="案例三 join()方法的使用"></a>案例三 join()方法的使用</h4><p>在多线程中，每个线程自顾执行自己的任务，当最后一个线程运行完毕后再退出，所以这个时候如果你要打印信息的话，会看到打印出来的信息错乱无章，有的时候希望主线程能够等子线程执行完毕后在继续执行，就是用join()方法。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line">t00 = time.time()</span><br><span class="line"># 获取当前时间戳</span><br><span class="line">def cs1():</span><br><span class="line">    time0 = time.time()</span><br><span class="line">    for x in range(9):</span><br><span class="line">        print x + time.time()-time0</span><br><span class="line">        # 计算用了多少时间</span><br><span class="line">        print threading.current_thread().name</span><br><span class="line">        # 打印这个线程名字</span><br><span class="line"></span><br><span class="line">def cs2():</span><br><span class="line">    for x1 in range(6,9):</span><br><span class="line">        print x1</span><br><span class="line">        print threading.current_thread().name</span><br><span class="line"></span><br><span class="line">threads=[]</span><br><span class="line"># 定义一个空的列表</span><br><span class="line">t1 = threading.Thread(target=cs1)</span><br><span class="line">t2 = threading.Thread(target=cs2)</span><br><span class="line">threads.append(t1)</span><br><span class="line">threads.append(t2)</span><br><span class="line"># 把这两个线程的任务加载到这个列表中</span><br><span class="line">for x in threads:</span><br><span class="line">    x.start()</span><br><span class="line">    # 然后执行，这个案例很常用，就是有多个函数要多线程执行的时候用到</span><br><span class="line">    # 如果一个程序有多个函数，但是你只想其中的某一个或者某两个函数多线程，用法一样加入空的列表即可</span><br><span class="line">    x.join()</span><br><span class="line">    #线程堵塞 先运行第一个在运行第二个</span><br><span class="line">#x.join()</span><br><span class="line">#注意你的join放在这里是没有意义的，和不加join一样。线程不堵塞  但是会出现不匀称的表现  并且会修改不同线程中的变量</span><br><span class="line">print &apos;use time.&#123;&#125;&apos;.format(time.time()-t00)</span><br></pre></td></tr></table></figure><p>关于setDaemon()的概念就是：主线程A中，创建了子线程B，并且在主线程A中调用了B.setDaemon(),这个的意思是，把主线程A设置为守护线程，这时候，要是主线程A执行结束了，就不管子线程B是否完成,一并和主线程A退出.这就是setDaemon方法的含义，这基本和join是相反的。此外，还有个要特别注意的：必须在start() 方法调用之前设置，如果不设置为守护线程，程序会被无限挂起。</p><h4 id="案例四-线程锁之信号Semaphore"><a href="#案例四-线程锁之信号Semaphore" class="headerlink" title="案例四 线程锁之信号Semaphore"></a>案例四 线程锁之信号Semaphore</h4><p>类名：BoundedSemaphore。这种锁允许一定数量的线程同时更改数据，它不是互斥锁。比如地铁安检，排队人很多，工作人员只允许一定数量的人进入安检区，其它的人继续排队。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">import threading</span><br><span class="line"></span><br><span class="line">def run(n, se):</span><br><span class="line">    se.acquire()</span><br><span class="line">    print(&quot;run the thread: %s&quot; % n)</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    se.release()</span><br><span class="line"></span><br><span class="line"># 设置允许5个线程同时运行</span><br><span class="line">semaphore = threading.BoundedSemaphore(5)</span><br><span class="line">for i in range(20):</span><br><span class="line">    t = threading.Thread(target=run, args=(i,semaphore))</span><br><span class="line">    t.start()</span><br></pre></td></tr></table></figure><p>运行后，可以看到5个一批的线程被放行。</p><h4 id="案例五-线程锁之事件Event"><a href="#案例五-线程锁之事件Event" class="headerlink" title="案例五 线程锁之事件Event"></a>案例五 线程锁之事件Event</h4><p>事件线程锁的运行机制：<br>全局定义了一个Flag，如果Flag的值为False，那么当程序执行wait()方法时就会阻塞，如果Flag值为True，线程不再阻塞。这种锁，类似交通红绿灯（默认是红灯），它属于在红灯的时候一次性阻挡所有线程，在绿灯的时候，一次性放行所有排队中的线程。<br>事件主要提供了四个方法set()、wait()、clear()和is_set()。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">调用clear()方法会将事件的Flag设置为False。</span><br><span class="line">调用set()方法会将Flag设置为True。</span><br><span class="line">调用wait()方法将等待“红绿灯”信号。</span><br><span class="line">is_set():判断当前是否&quot;绿灯放行&quot;状态</span><br></pre></td></tr></table></figure><p>下面是一个模拟红绿灯，然后汽车通行的例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">#利用Event类模拟红绿灯</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">event = threading.Event()</span><br><span class="line"># 定义一个事件的对象</span><br><span class="line">def lighter():</span><br><span class="line">    green_time = 5       </span><br><span class="line">    # 绿灯时间</span><br><span class="line">    red_time = 5         </span><br><span class="line">    # 红灯时间</span><br><span class="line">    event.set()          </span><br><span class="line">    # 初始设为绿灯</span><br><span class="line">    while True:</span><br><span class="line">        print(&quot;\33[32;0m 绿灯亮...\033[0m&quot;)</span><br><span class="line">        time.sleep(green_time)</span><br><span class="line">        event.clear()</span><br><span class="line">        print(&quot;\33[31;0m 红灯亮...\033[0m&quot;)</span><br><span class="line">        time.sleep(red_time)</span><br><span class="line">        event.set()</span><br><span class="line"></span><br><span class="line">def run(name):</span><br><span class="line">    while True:</span><br><span class="line">        if event.is_set():      </span><br><span class="line">        # 判断当前是否&quot;放行&quot;状态</span><br><span class="line">            print(&quot;一辆[%s] 呼啸开过...&quot; % name)</span><br><span class="line">            time.sleep(1)</span><br><span class="line">        else:</span><br><span class="line">            print(&quot;一辆[%s]开来，看到红灯，无奈的停下了...&quot; % name)</span><br><span class="line">            event.wait()</span><br><span class="line">            print(&quot;[%s] 看到绿灯亮了，瞬间飞起.....&quot; % name)</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    light = threading.Thread(target=lighter,)</span><br><span class="line">    light.start()</span><br><span class="line">        for name in [&apos;奔驰&apos;, &apos;宝马&apos;, &apos;奥迪&apos;]:</span><br><span class="line">        car = threading.Thread(target=run, args=(name,))</span><br><span class="line">        car.start()</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">绿灯亮...</span><br><span class="line">一辆[奔驰] 呼啸开过...</span><br><span class="line">一辆[宝马] 呼啸开过...</span><br><span class="line">一辆[奥迪] 呼啸开过...</span><br><span class="line">一辆[奥迪] 呼啸开过...</span><br><span class="line">......</span><br><span class="line"> 红灯亮...</span><br><span class="line">一辆[宝马]开来，看到红灯，无奈的停下了...</span><br><span class="line">一辆[奥迪]开来，看到红灯，无奈的停下了...</span><br><span class="line">一辆[奔驰]开来，看到红灯，无奈的停下了...</span><br><span class="line">绿灯亮...</span><br><span class="line">[奥迪] 看到绿灯亮了，瞬间飞起.....</span><br><span class="line">一辆[奥迪] 呼啸开过...</span><br><span class="line">[奔驰] 看到绿灯亮了，瞬间飞起.....</span><br><span class="line">一辆[奔驰] 呼啸开过...</span><br><span class="line">[宝马] 看到绿灯亮了，瞬间飞起.....</span><br><span class="line">一辆[宝马] 呼啸开过...</span><br><span class="line">一辆[奥迪] 呼啸开过...</span><br><span class="line">......</span><br></pre></td></tr></table></figure><h4 id="案例六-线程锁之条件Condition"><a href="#案例六-线程锁之条件Condition" class="headerlink" title="案例六 线程锁之条件Condition"></a>案例六 线程锁之条件Condition</h4><p>Condition称作条件锁，依然是通过acquire()/release()加锁解锁。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">wait([timeout])方法将使线程进入Condition的等待池等待通知，并释放锁。使用前线程必须已获得锁定，否则将抛出异常。</span><br><span class="line">notify()方法将从等待池挑选一个线程并通知，收到通知的线程将自动调用acquire()尝试获得锁定（进入锁定池），其他线程仍然在等待池中。调用这个方法不会释放锁定。使用前线程必须已获得锁定，否则将抛出异常。</span><br><span class="line">notifyAll()方法将通知等待池中所有的线程，这些线程都将进入锁定池尝试获得锁定。调用这个方法不会释放锁定。使用前线程必须已获得锁定，否则将抛出异常。</span><br></pre></td></tr></table></figure><p>实际案例</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">num = 0</span><br><span class="line">con = threading.Condition()</span><br><span class="line">class Foo(threading.Thread):</span><br><span class="line"></span><br><span class="line">    def __init__(self, name, action):</span><br><span class="line">        super(Foo, self).__init__()</span><br><span class="line">        self.name = name</span><br><span class="line">        self.action = action</span><br><span class="line"></span><br><span class="line">    def run(self):</span><br><span class="line">        global num</span><br><span class="line">        con.acquire()</span><br><span class="line">        print(&quot;%s开始执行...&quot; % self.name)</span><br><span class="line">        while True:</span><br><span class="line">            if self.action == &quot;add&quot;:</span><br><span class="line">                num += 1</span><br><span class="line">            elif self.action == &apos;reduce&apos;:</span><br><span class="line">                num -= 1</span><br><span class="line">            else:</span><br><span class="line">                exit(1)</span><br><span class="line">            print(&quot;num当前为：&quot;, num)</span><br><span class="line">            time.sleep(1)</span><br><span class="line">            if num == 5 or num == 0:</span><br><span class="line">                print(&quot;暂停执行%s！&quot; % self.name)</span><br><span class="line">                con.notify()</span><br><span class="line">                con.wait()</span><br><span class="line">                print(&quot;%s开始执行...&quot; % self.name)</span><br><span class="line">        con.release()</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    a = Foo(&quot;线程A&quot;, &apos;add&apos;)</span><br><span class="line">    b = Foo(&quot;线程B&quot;, &apos;reduce&apos;)</span><br><span class="line">    a.start()</span><br><span class="line">    b.start()</span><br></pre></td></tr></table></figure><p>如果不强制停止，程序会一直执行下去，并循环下面的结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">线程A开始执行...</span><br><span class="line">num当前为： 1</span><br><span class="line">num当前为： 2</span><br><span class="line">num当前为： 3</span><br><span class="line">num当前为： 4</span><br><span class="line">num当前为： 5</span><br><span class="line">暂停执行线程A！</span><br><span class="line">线程B开始执行...</span><br><span class="line">num当前为： 4</span><br><span class="line">num当前为： 3</span><br><span class="line">num当前为： 2</span><br><span class="line">num当前为： 1</span><br><span class="line">num当前为： 0</span><br><span class="line">暂停执行线程B！</span><br><span class="line">线程A开始执行...</span><br><span class="line">num当前为： 1</span><br><span class="line">num当前为： 2</span><br><span class="line">num当前为： 3</span><br><span class="line">num当前为： 4</span><br><span class="line">num当前为： 5</span><br><span class="line">暂停执行线程A！</span><br><span class="line">线程B开始执行...</span><br></pre></td></tr></table></figure><h4 id="案例-七定时器"><a href="#案例-七定时器" class="headerlink" title="案例 七定时器"></a>案例 七定时器</h4><p>定时器Timer类是threading模块中的一个小工具，用于指定n秒后执行某操作。一个简单但很实用的东西。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from threading import Timer</span><br><span class="line">def hello():</span><br><span class="line">    print(&quot;hello, world&quot;)</span><br><span class="line">t = Timer(1, hello)</span><br><span class="line"># 表示1秒后执行hello函数</span><br><span class="line">t.start()</span><br></pre></td></tr></table></figure><h4 id="案例八-通过with语句使用线程锁"><a href="#案例八-通过with语句使用线程锁" class="headerlink" title="案例八 通过with语句使用线程锁"></a>案例八 通过with语句使用线程锁</h4><p>类似于上下文管理器，所有的线程锁都有一个加锁和释放锁的动作，非常类似文件的打开和关闭。在加锁后，如果线程执行过程中出现异常或者错误，没有正常的释放锁，那么其他的线程会造到致命性的影响。通过with上下文管理器，可以确保锁被正常释放。其格式如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">with some_lock:</span><br><span class="line">    # 执行任务...</span><br></pre></td></tr></table></figure><p>这相当于：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">some_lock.acquire()</span><br><span class="line">try:</span><br><span class="line">    # 执行任务..</span><br><span class="line">finally:</span><br><span class="line">    some_lock.release()</span><br></pre></td></tr></table></figure><h2 id="threading-的常用属性"><a href="#threading-的常用属性" class="headerlink" title="threading 的常用属性"></a>threading 的常用属性</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">current_thread()    返回当前线程</span><br><span class="line">active_count()    返回当前活跃的线程数，1个主线程+n个子线程</span><br><span class="line">get_ident()    返回当前线程</span><br><span class="line">enumerater()    返回当前活动 Thread 对象列表</span><br><span class="line">main_thread()    返回主 Thread 对象</span><br><span class="line">settrace(func)    为所有线程设置一个 trace 函数</span><br><span class="line">setprofile(func)    为所有线程设置一个 profile 函数</span><br><span class="line">stack_size([size])    返回新创建线程栈大小；或为后续创建的线程设定栈大小为 size</span><br><span class="line">TIMEOUT_MAX    Lock.acquire(), RLock.acquire(), Condition.wait() 允许的最大超时时间</span><br></pre></td></tr></table></figure><h2 id="线程池-threadingpool"><a href="#线程池-threadingpool" class="headerlink" title="线程池 threadingpool"></a>线程池 threadingpool</h2><p>在使用多线程处理任务时也不是线程越多越好。因为在切换线程的时候，需要切换上下文环境，线程很多的时候，依然会造成CPU的大量开销。为解决这个问题，线程池的概念被提出来了。</p><p>预先创建好一个数量较为优化的线程组，在需要的时候立刻能够使用，就形成了线程池。在Python中，没有内置的较好的线程池模块，需要自己实现或使用第三方模块。<br>需要注意的是，线程池的整体构造需要自己精心设计，比如某个函数定义存在多少个线程，某个函数定义什么时候运行这个线程，某个函数定义去获取线程获取任务，某个线程设置线程守护(线程锁之类的)，等等…<br>在网上找了几个案例，供大家学习参考。</p><p>下面是一个简单的线程池：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">import queue</span><br><span class="line">import time</span><br><span class="line">import threading</span><br><span class="line">class MyThreadPool:</span><br><span class="line">    def __init__(self, maxsize=5):</span><br><span class="line">        self.maxsize = maxsize</span><br><span class="line">        self._pool = queue.Queue(maxsize)   # 使用queue队列，创建一个线程池</span><br><span class="line">        for _ in range(maxsize):</span><br><span class="line">            self._pool.put(threading.Thread)</span><br><span class="line">    def get_thread(self):</span><br><span class="line">        return self._pool.get()</span><br><span class="line"></span><br><span class="line">    def add_thread(self):</span><br><span class="line">        self._pool.put(threading.Thread)</span><br><span class="line"></span><br><span class="line">def run(i, pool):</span><br><span class="line">    print(&apos;执行任务&apos;, i)</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    pool.add_thread()   # 执行完毕后，再向线程池中添加一个线程类</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    pool = MyThreadPool(5)  # 设定线程池中最多只能有5个线程类</span><br><span class="line">    for i in range(20):</span><br><span class="line">        t = pool.get_thread()   # 每个t都是一个线程类</span><br><span class="line">        obj = t(target=run, args=(i, pool)) # 这里的obj才是正真的线程对象</span><br><span class="line">        obj.start()</span><br><span class="line">    print(&quot;活动的子线程数： &quot;, threading.active_count()-1)</span><br></pre></td></tr></table></figure><p>分析一下上面的代码：</p><ol><li>实例化一个MyThreadPool的对象，在其内部建立了一个最多包含5个元素的阻塞队列，并一次性将5个Thread类型添加进去。</li><li>循环100次，每次从pool中获取一个thread类，利用该类，传递参数，实例化线程对象。</li><li>在run()方法中，每当任务完成后，又为pool添加一个thread类，保持队列中始终有5个thread类。</li><li>一定要分清楚，代码里各个变量表示的内容。t表示的是一个线程类，也就是threading.Thread，而obj才是正真的线程对象。</li></ol><p>上面的例子是把线程类当做元素添加到队列内，从而实现的线程池。这种方法比较糙，每个线程使用后就被抛弃，并且一开始就将线程开到满，因此性能较差。下面是一个相对好一点的例子，在这个例子中，队列里存放的不再是线程类，而是任务，线程池也不是一开始就直接开辟所有线程，而是根据需要，逐步建立，直至池满。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">一个基于thread和queue的线程池，以任务为队列元素，动态创建线程，重复利用线程，</span><br><span class="line">通过close和terminate方法关闭线程池。</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">import queue</span><br><span class="line">import threading</span><br><span class="line">import contextlib</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"># 创建空对象,用于停止线程</span><br><span class="line">StopEvent = object()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def callback(status, result):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    根据需要进行的回调函数，默认不执行。</span><br><span class="line">    :param status: action函数的执行状态</span><br><span class="line">    :param result: action函数的返回值</span><br><span class="line">    :return:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def action(thread_name, arg):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    真实的任务定义在这个函数里</span><br><span class="line">    :param thread_name: 执行该方法的线程名</span><br><span class="line">    :param arg: 该函数需要的参数</span><br><span class="line">    :return:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 模拟该函数执行了0.1秒</span><br><span class="line">    time.sleep(0.1)</span><br><span class="line">    print(&quot;第%s个任务调用了线程 %s，并打印了这条信息！&quot; % (arg+1, thread_name))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class ThreadPool:</span><br><span class="line"></span><br><span class="line">    def __init__(self, max_num, max_task_num=None):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        初始化线程池</span><br><span class="line">        :param max_num: 线程池最大线程数量</span><br><span class="line">        :param max_task_num: 任务队列长度</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 如果提供了最大任务数的参数，则将队列的最大元素个数设置为这个值。</span><br><span class="line">        if max_task_num:</span><br><span class="line">            self.q = queue.Queue(max_task_num)</span><br><span class="line">        # 默认队列可接受无限多个的任务</span><br><span class="line">        else:</span><br><span class="line">            self.q = queue.Queue()</span><br><span class="line">        # 设置线程池最多可实例化的线程数</span><br><span class="line">        self.max_num = max_num</span><br><span class="line">        # 任务取消标识</span><br><span class="line">        self.cancel = False</span><br><span class="line">        # 任务中断标识</span><br><span class="line">        self.terminal = False</span><br><span class="line">        # 已实例化的线程列表</span><br><span class="line">        self.generate_list = []</span><br><span class="line">        # 处于空闲状态的线程列表</span><br><span class="line">        self.free_list = []</span><br><span class="line"></span><br><span class="line">    def put(self, func, args, callback=None):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        往任务队列里放入一个任务</span><br><span class="line">        :param func: 任务函数</span><br><span class="line">        :param args: 任务函数所需参数</span><br><span class="line">        :param callback: 任务执行失败或成功后执行的回调函数，回调函数有两个参数</span><br><span class="line">        1、任务函数执行状态；2、任务函数返回值（默认为None，即：不执行回调函数）</span><br><span class="line">        :return: 如果线程池已经终止，则返回True否则None</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 先判断标识，看看任务是否取消了</span><br><span class="line">        if self.cancel:</span><br><span class="line">            return</span><br><span class="line">        # 如果没有空闲的线程，并且已创建的线程的数量小于预定义的最大线程数，则创建新线程。</span><br><span class="line">        if len(self.free_list) == 0 and len(self.generate_list) &lt; self.max_num:</span><br><span class="line">            self.generate_thread()</span><br><span class="line">        # 构造任务参数元组，分别是调用的函数，该函数的参数，回调函数。</span><br><span class="line">        w = (func, args, callback,)</span><br><span class="line">        # 将任务放入队列</span><br><span class="line">        self.q.put(w)</span><br><span class="line"></span><br><span class="line">    def generate_thread(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        创建一个线程</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 每个线程都执行call方法</span><br><span class="line">        t = threading.Thread(target=self.call)</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line">    def call(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        循环去获取任务函数并执行任务函数。在正常情况下，每个线程都保存生存状态，  直到获取线程终止的flag。</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 获取当前线程的名字</span><br><span class="line">        current_thread = threading.currentThread().getName()</span><br><span class="line">        # 将当前线程的名字加入已实例化的线程列表中</span><br><span class="line">        self.generate_list.append(current_thread)</span><br><span class="line">        # 从任务队列中获取一个任务</span><br><span class="line">        event = self.q.get()</span><br><span class="line">        # 让获取的任务不是终止线程的标识对象时</span><br><span class="line">        while event != StopEvent:</span><br><span class="line">            # 解析任务中封装的三个参数</span><br><span class="line">            func, arguments, callback = event</span><br><span class="line">            # 抓取异常，防止线程因为异常退出</span><br><span class="line">            try:</span><br><span class="line">                # 正常执行任务函数</span><br><span class="line">                result = func(current_thread, *arguments)</span><br><span class="line">                success = True</span><br><span class="line">            except Exception as e:</span><br><span class="line">                # 当任务执行过程中弹出异常</span><br><span class="line">                result = None</span><br><span class="line">                success = False</span><br><span class="line">            # 如果有指定的回调函数</span><br><span class="line">            if callback is not None:</span><br><span class="line">                # 执行回调函数，并抓取异常</span><br><span class="line">                try:</span><br><span class="line">                    callback(success, result)</span><br><span class="line">                except Exception as e:</span><br><span class="line">                    pass</span><br><span class="line">            # 当某个线程正常执行完一个任务时，先执行worker_state方法</span><br><span class="line">            with self.worker_state(self.free_list, current_thread):</span><br><span class="line">                # 如果强制关闭线程的flag开启，则传入一个StopEvent元素</span><br><span class="line">                if self.terminal:</span><br><span class="line">                    event = StopEvent</span><br><span class="line">                # 否则获取一个正常的任务，并回调worker_state方法的yield语句</span><br><span class="line">                else:</span><br><span class="line">                    # 从这里开始又是一个正常的任务循环</span><br><span class="line">                    event = self.q.get()</span><br><span class="line">        else:</span><br><span class="line">            # 一旦发现任务是个终止线程的标识元素，将线程从已创建线程列表中删除</span><br><span class="line">            self.generate_list.remove(current_thread)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def close(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        执行完所有的任务后，让所有线程都停止的方法</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 设置flag</span><br><span class="line">        self.cancel = True</span><br><span class="line">        # 计算已创建线程列表中线程的个数，</span><br><span class="line">        # 然后往任务队列里推送相同数量的终止线程的标识元素</span><br><span class="line">        full_size = len(self.generate_list)</span><br><span class="line">        while full_size:</span><br><span class="line">            self.q.put(StopEvent)</span><br><span class="line">            full_size -= 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def terminate(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        在任务执行过程中，终止线程，提前退出。</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.terminal = True</span><br><span class="line">        # 强制性的停止线程</span><br><span class="line">        while self.generate_list:</span><br><span class="line">            self.q.put(StopEvent)</span><br><span class="line"></span><br><span class="line"># 该装饰器用于上下文管理</span><br><span class="line">    @contextlib.contextmanager</span><br><span class="line">    def worker_state(self, state_list, worker_thread):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        用于记录空闲的线程，或从空闲列表中取出线程处理任务</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 将当前线程，添加到空闲线程列表中</span><br><span class="line">        state_list.append(worker_thread)</span><br><span class="line">        # 捕获异常</span><br><span class="line">        try:</span><br><span class="line">            # 在此等待</span><br><span class="line">            yield</span><br><span class="line">        finally:</span><br><span class="line">            # 将线程从空闲列表中移除</span><br><span class="line">            state_list.remove(worker_thread)</span><br><span class="line"></span><br><span class="line"># 调用方式</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    # 创建一个最多包含5个线程的线程池</span><br><span class="line">    pool = ThreadPool(5)</span><br><span class="line">    # 创建100个任务，让线程池进行处理</span><br><span class="line">    for i in range(100):</span><br><span class="line">        pool.put(action, (i,), callback)</span><br><span class="line">    # 等待一定时间，让线程执行任务</span><br><span class="line">    time.sleep(3)</span><br><span class="line">    print(&quot;-&quot; * 50)</span><br><span class="line">    print(&quot;\033[32;0m任务停止之前线程池中有%s个线程，空闲的线程有%s个！\033[0m&quot;</span><br><span class="line">          % (len(pool.generate_list), len(pool.free_list)))</span><br><span class="line">    # 正常关闭线程池</span><br><span class="line">    pool.close()</span><br><span class="line">    print(&quot;任务执行完毕，正常退出！&quot;)</span><br><span class="line">    # 强制关闭线程池</span><br><span class="line">    # pool.terminate()</span><br><span class="line">    # print(&quot;强制停止任务！&quot;)</span><br></pre></td></tr></table></figure><p>关于线程池其实涉及到工程设计，需要自己很熟练的运行面向对象程序设计。</p><h2 id="生产者和消费者模式"><a href="#生产者和消费者模式" class="headerlink" title="生产者和消费者模式"></a>生产者和消费者模式</h2><p>生产者就是生成任务，消费者就是解决处理任务。比如在一个程序中，代码是按照重上往下执行，有的时候做等待的时间完全可以用来做任务处理或者做别的事情，为了节省时间，可以借助多线程的功能（自顾自完成自己线程任务）加上Queue队列特性（管道模式。里面存储数据，然后提供给线程处理）完成生产者和消费者模式。关于Queue的用法参考我之前的文章。</p><h4 id="案例一"><a href="#案例一" class="headerlink" title="案例一"></a>案例一</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">import sys</span><br><span class="line">import Queue</span><br><span class="line">import time</span><br><span class="line">import threading</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line">q = Queue.Queue(10)</span><br><span class="line">def get(i):</span><br><span class="line">    # 这个函数用来生产任务，接受参数i，也可以不传入参数</span><br><span class="line">    while 1:</span><br><span class="line">        time.sleep(2)</span><br><span class="line">        # 这里可以做一些动作，比如过去网站的网址之类的</span><br><span class="line">        q.put(i)</span><br><span class="line">        # 然后把得到的数据放在消息队列中</span><br><span class="line">def fun(o):</span><br><span class="line">    # 这个函数用来处理任务，必须要接受参数</span><br><span class="line">    q.get(o)</span><br><span class="line">    # 得到获取接受来的参数</span><br><span class="line">    print o*10</span><br><span class="line">    # 然后对获取的参数作处理，我这里仅仅打印数据乘以10</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for i in range(100):</span><br><span class="line">    # 生产任务启动，有100个任务量要产生</span><br><span class="line">    t1 = threading.Thread(target=get, args=(i,))</span><br><span class="line">    t1.start()</span><br><span class="line">for o in range(100):</span><br><span class="line">    # 处理任务启动</span><br><span class="line">    t = threading.Thread(target=fun, args=(o,))</span><br><span class="line">    t.start()</span><br></pre></td></tr></table></figure><p>上面这个代码主要是针对骨架进行拆分解说，一般的生产者消费者模式都是这种构架，下面用一个更加清晰的案例来帮助理解。</p><h4 id="案例二"><a href="#案例二" class="headerlink" title="案例二"></a>案例二</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line">import time</span><br><span class="line">import queue</span><br><span class="line">import threading</span><br><span class="line"></span><br><span class="line">q = queue.Queue(10)     # 生成一个队列，用来保存“包子”，最大数量为10</span><br><span class="line"></span><br><span class="line">def productor(i):</span><br><span class="line">    # 厨师不停地每2秒做一个包子</span><br><span class="line">    while True:</span><br><span class="line">        q.put(&quot;厨师 %s 做的包子！&quot; % i)</span><br><span class="line">        time.sleep(2)</span><br><span class="line"></span><br><span class="line">def consumer(j):</span><br><span class="line">    # 顾客不停地每秒吃一个包子</span><br><span class="line">    while True:</span><br><span class="line">        print(&quot;顾客 %s 吃了一个 %s&quot;%(j,q.get()))</span><br><span class="line">        time.sleep(1)</span><br><span class="line"></span><br><span class="line"># 实例化了3个生产者（厨师）</span><br><span class="line">for i in range(3):</span><br><span class="line">    t = threading.Thread(target=productor, args=(i,))</span><br><span class="line">    t.start()</span><br><span class="line"># 实例化了10个消费者（顾客）</span><br><span class="line">for j in range(10):</span><br><span class="line">    v = threading.Thread(target=consumer, args=(j,))</span><br><span class="line">    v.start()</span><br></pre></td></tr></table></figure><h4 id="案例三"><a href="#案例三" class="headerlink" title="案例三"></a>案例三</h4><p>使用生产者消费者模式实现代理IP扫描并且同步扫描代理IP是否可用，如果不适用生产者消费者模式的话，首先要获取代理IP，然后把获取到的IP放在一个列表，然后在扫描列表的IP，扫描过程为—-&gt;获取IP—-&gt;IP保存—-&gt;IP存活扫描。过程是单向的，也就是说没办法同步一边获取IP然后马上验证。</p><p>下面的代码是用生产者消费者模式实现代理IP的获取与存活扫描。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"># @Time    : 2018/5/3 0003 10:52</span><br><span class="line"># @Author  : Sun</span><br><span class="line"># @Blog    : wandouduoduo</span><br><span class="line"># @File    : 生产者消费者.py</span><br><span class="line"># @Software: PyCharm</span><br><span class="line">import sys</span><br><span class="line">import Queue</span><br><span class="line">import time</span><br><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import threading</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line">q = Queue.Queue(10)</span><br><span class="line">headers=&#123;&apos;User-Agent&apos;:&apos;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36&apos;&#125;</span><br><span class="line">def get_ip(page):</span><br><span class="line">    url1=&apos;http://www.66ip.cn/mo.php?sxb=&amp;tqsl=30&amp;port=&amp;export=&amp;ktip=&amp;sxa=&amp;submit=%CC%E1++%C8%A1&amp;textarea=&apos;</span><br><span class="line">    url2=&apos;http://www.xicidaili.com/nn/%s&apos;</span><br><span class="line">    for i in range(1,page):</span><br><span class="line">        url1_1=url1+str(i)</span><br><span class="line">        url2_2=url2+str(i)</span><br><span class="line">        try:</span><br><span class="line">            r = requests.get(url=url1_1,headers=headers,timeout=5)</span><br><span class="line">            #time.sleep(20)</span><br><span class="line">            rr = re.findall(&apos;        (.*?)&lt;br /&gt;&apos;,r.content)</span><br><span class="line">            for x in rr:</span><br><span class="line">                q.put(x)</span><br><span class="line">            time.sleep(20)</span><br><span class="line">        except Exception,e:</span><br><span class="line">            print e</span><br><span class="line">        try:</span><br><span class="line">            time.sleep(30)</span><br><span class="line">            r = requests.get(url=url2_2,headers=headers,timeout=5)</span><br><span class="line">            rr = re.findall(&apos;/&gt;&lt;/td&gt;(.*?)&lt;a href&apos;,r.content,re.S)</span><br><span class="line">            for x in rr:</span><br><span class="line">                x1 = x.replace(&apos;\n&apos;,&apos;&apos;).replace(&apos;&lt;td&gt;&apos;,&apos;&apos;).replace(&quot;&lt;/td&gt;&quot;,&apos;:&apos;).replace(&apos;      &apos;,&apos;&apos;).replace(&apos;:  &apos;,&apos;&apos;)</span><br><span class="line">                print x1</span><br><span class="line">                q.put(x1)</span><br><span class="line">            time.sleep(20)</span><br><span class="line">        except Exception,e:</span><br><span class="line">            print e</span><br><span class="line">def scan_ip():</span><br><span class="line">    while 1:</span><br><span class="line">        proxies=&#123;&#125;</span><br><span class="line">        ip = q.get()</span><br><span class="line">        proxies[&apos;http&apos;] = str(ip)</span><br><span class="line">        try:</span><br><span class="line">            req2 = requests.get(url=&apos;http://blog.csdn.net/lzy98&apos;, proxies=proxies, headers=headers, timeout=5)</span><br><span class="line">            if &apos;One puls&apos; in req2.content:</span><br><span class="line">                print str(proxies[&apos;http&apos;]) + unicode(&apos;该代理可正常访问网页...&apos;,&apos;utf-8&apos;)</span><br><span class="line">            else:</span><br><span class="line">                print unicode(&apos;  该代理无法访问网页,继续验证下一代理...&apos;, &apos;utf-8&apos;)</span><br><span class="line">        except :</span><br><span class="line">            print str(proxies[&apos;http&apos;])+unicode(&apos;  无法连接到代理服务器&apos;,&apos;utf-8&apos;)</span><br><span class="line"></span><br><span class="line">for i in range(2):</span><br><span class="line">    # 这里是要开2个任务量，就是2个线程</span><br><span class="line">    t = threading.Thread(target=get_ip,args=(10,))</span><br><span class="line">    # 传入的参数是10，回归到get_ip函数，发现传入的参数就是要扫描提供代理网站的页数</span><br><span class="line">    t.start()</span><br><span class="line"></span><br><span class="line">t1 = threading.Thread(target=scan_ip)</span><br><span class="line">t1.start()</span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">177.132.249.127:20183无法连接到代理服务器</span><br><span class="line">39.104.82.143:8080无法连接到代理服务器</span><br><span class="line">123.231.203.139:8080无法连接到代理服务器</span><br><span class="line">180.250.43.66:8080该代理可正常访问网页...</span><br><span class="line">189.127.238.65:8080无法连接到代理服务器</span><br><span class="line">107.178.3.105:8181该代理可正常访问网页...</span><br><span class="line">95.31.80.67:53281该代理可正常访问网页...</span><br><span class="line">79.174.160.167:8080无法连接到代理服务器</span><br><span class="line">223.242.94.36:31588无法连接到代理服务器</span><br><span class="line">该代理无法访问网页,继续验证下一代理...</span><br><span class="line">5.188.155.243:8080无法连接到代理服务器</span><br><span class="line">180.183.17.151:8080该代理可正常访问网页...</span><br><span class="line">113.90.247.99:8118该代理可正常访问网页...</span><br><span class="line">180.119.65.184:3128无法连接到代理服务器</span><br></pre></td></tr></table></figure><h2 id="Python3中的线程池方法"><a href="#Python3中的线程池方法" class="headerlink" title="Python3中的线程池方法"></a>Python3中的线程池方法</h2><p>虽然在2版本中并没有线程池，但是在3版本中有相关线程池的使用方法。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">from concurrent.futures import ThreadPoolExecutor</span><br><span class="line">executor = ThreadPoolExecutor(3)</span><br><span class="line"># 实例化线程池对象，开启3个线程</span><br><span class="line">def fun(a,b):</span><br><span class="line">    print (a,b)</span><br><span class="line">    returl a**b</span><br><span class="line"># 定义一个函数</span><br><span class="line">executor.submit(fun,2,5) # y运行结果：2,5</span><br><span class="line"># 这是调用与开启线程</span><br><span class="line">result=executor.submit(fun,5,2)</span><br><span class="line">print result # 运行结果: 25</span><br><span class="line"># 如果要有很多参数传入进行运算</span><br><span class="line">executor.map(fun,[1,2,3,4],[2,3,5,6])</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;线程是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务，多线程就是在一个进程中的多个线程，如果使用多线程默认开启一个主线程，按照程序需求自动开启多个线程(也可以自己定义线程数)。&lt;/p&gt;
    
    </summary>
    
      <category term="编程积累" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/"/>
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/categories/%E7%BC%96%E7%A8%8B%E7%A7%AF%E7%B4%AF/Python/"/>
    
    
      <category term="Python" scheme="https://wandouduoduo.netlify.com/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>glusterfs常用命令</title>
    <link href="https://wandouduoduo.netlify.com/articles/4f1d1494.html"/>
    <id>https://wandouduoduo.netlify.com/articles/4f1d1494.html</id>
    <published>2019-11-26T08:03:27.000Z</published>
    <updated>2019-11-26T09:20:44.545Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>glusterfs作为分布式存储，优点和安装这里就不再赘述了，看博客中教程。本文主要是介绍glusterfs常用命令和案例。</p><a id="more"></a><h2 id="命令详解"><a href="#命令详解" class="headerlink" title="命令详解"></a>命令详解</h2><h4 id="服务器节点"><a href="#服务器节点" class="headerlink" title="服务器节点"></a>服务器节点</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看所有节点信息，显示时不包括本节点</span></span><br><span class="line">gluster peer status </span><br><span class="line"><span class="comment">#添加节点</span></span><br><span class="line">gluster peer probe NODE-NAME </span><br><span class="line"><span class="comment">#移除节点，需要提前将该节点上的brick移除</span></span><br><span class="line">gluster peer detach NODE-NAME</span><br></pre></td></tr></table></figure><h4 id="glusterd服务"><a href="#glusterd服务" class="headerlink" title="glusterd服务"></a>glusterd服务</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#启动glusterd服务</span></span><br><span class="line">/etc/init.d/glusterd start </span><br><span class="line"><span class="comment">#关闭glusterd服务</span></span><br><span class="line">/etc/init.d/glusterd stop </span><br><span class="line"><span class="comment">#查看glusterd服务</span></span><br><span class="line">/etc/init.d/glusterd status</span><br></pre></td></tr></table></figure><h4 id="卷管理"><a href="#卷管理" class="headerlink" title="卷管理"></a>卷管理</h4><h5 id="创建卷"><a href="#创建卷" class="headerlink" title="创建卷"></a>创建卷</h5><p><strong>复制卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法： gluster volume create NEW-VOLNAME [replica COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK</span><br><span class="line"></span><br><span class="line">示例1：gluster volume create <span class="built_in">test</span>-volume replica 2 transport tcp server1:/exp1/brick server2:/exp2/brick</span><br></pre></td></tr></table></figure><p><strong>条带卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法：gluster volume create NEW-VOLNAME [stripe COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK...</span><br><span class="line"></span><br><span class="line">示例：gluster volume create <span class="built_in">test</span>-volume stripe 2 transport tcp server1:/exp1/brick server2:/exp2/brick</span><br></pre></td></tr></table></figure><p><strong>分布式卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">语法： gluster volume create NEW-VOLNAME [transport tcp | rdma | tcp, rdma] NEW-BRICK</span><br><span class="line"></span><br><span class="line">示例1：gluster volume create <span class="built_in">test</span>-volume server1:/exp1/brick server2:/exp2/brick</span><br><span class="line">示例2：gluster volume create <span class="built_in">test</span>-volume transport rdma server1:/exp1/brick server2:/exp2/brick server3:/exp3/brick server4:/exp4/brick</span><br></pre></td></tr></table></figure><p><strong>分布式复制卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">语法： gluster volume create NEW-VOLNAME [replica COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK...</span><br><span class="line">示例： gluster volume create <span class="built_in">test</span>-volume replica 2 transport tcp server1:/exp1/brick server2:/exp2/brick server3:/exp3/brick server4:/exp4/brick</span><br></pre></td></tr></table></figure><p> <strong>分布式条带卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法：gluster volume create NEW-VOLNAME [stripe COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK...</span><br><span class="line"></span><br><span class="line">示例：gluster volume create <span class="built_in">test</span>-volume stripe 2 transport tcp server1:/exp1/brick server2:/exp2/brick server3:/exp3/brick server4:/exp4/brick</span><br></pre></td></tr></table></figure><p><strong>条带复制卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">语法：gluster volume create NEW-VOLNAME [stripe COUNT] [replica COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK...</span><br><span class="line"></span><br><span class="line">示例：gluster volume create <span class="built_in">test</span>-volume stripe 2 replica 2 transport tcp server1:/exp1/brick server2:/exp2/brick server3:/exp3/brick server4:/exp4/brick</span><br></pre></td></tr></table></figure><h5 id="启动卷"><a href="#启动卷" class="headerlink" title="启动卷"></a>启动卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume start <span class="built_in">test</span>-volume</span><br></pre></td></tr></table></figure><h5 id="停止卷"><a href="#停止卷" class="headerlink" title="停止卷"></a>停止卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume stop <span class="built_in">test</span>-volume</span><br></pre></td></tr></table></figure><p> <strong>删除卷</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先停止卷后才能删除</span></span><br><span class="line">gluster volume delete <span class="built_in">test</span>-volume</span><br></pre></td></tr></table></figure><h5 id="查看卷"><a href="#查看卷" class="headerlink" title="查看卷"></a>查看卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#列出集群中的所有卷</span></span><br><span class="line">gluster volume list </span><br><span class="line"><span class="comment">#查看集群中的卷信息</span></span><br><span class="line">gluster volume info [all] </span><br><span class="line"><span class="comment">#查看集群中的卷状态</span></span><br><span class="line">gluster volume status [all] </span><br><span class="line"></span><br><span class="line">gluster volume status [detail| clients | mem | inode | fd]</span><br></pre></td></tr></table></figure><h5 id="配置卷"><a href="#配置卷" class="headerlink" title="配置卷"></a>配置卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume <span class="built_in">set</span> &lt;VOLNAME&gt; &lt;OPTION&gt; &lt;PARAMETER&gt;</span><br></pre></td></tr></table></figure><h5 id="扩展卷"><a href="#扩展卷" class="headerlink" title="扩展卷"></a>扩展卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gluster volume add-brick &lt;VOLNAME&gt; &lt;NEW-BRICK&gt;</span><br><span class="line"><span class="comment">#注意，如果是复制卷或者条带卷，则每次添加的Brick数必须是replica或者stripe的整数倍。</span></span><br></pre></td></tr></table></figure><h5 id="收缩卷"><a href="#收缩卷" class="headerlink" title="收缩卷"></a>收缩卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#先将数据迁移到其它可用的Brick，迁移结束后才将该Brick移除：</span></span><br><span class="line">gluster volume remove-brick start</span><br><span class="line"><span class="comment">#在执行了start之后，可以使用status命令查看移除进度：</span></span><br><span class="line">gluster volume remove-brick status</span><br><span class="line"><span class="comment">#不进行数据迁移，直接删除该Brick：</span></span><br><span class="line">gluster volume remove-brick commit</span><br><span class="line"><span class="comment">#注意，如果是复制卷或者条带卷，则每次移除的Brick数必须是replica或者stripe的整数倍。</span></span><br></pre></td></tr></table></figure><h5 id="迁移卷"><a href="#迁移卷" class="headerlink" title="迁移卷"></a>迁移卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#使用start命令开始进行迁移：</span></span><br><span class="line">gluster volume replace-brick start</span><br><span class="line"><span class="comment">#在数据迁移过程中，可以使用pause命令暂停迁移：</span></span><br><span class="line">gluster volume replace-brick pause</span><br><span class="line"><span class="comment">#在数据迁移过程中，可以使用abort命令终止迁移：</span></span><br><span class="line">gluster volume replace-brick abort</span><br><span class="line"><span class="comment">#在数据迁移过程中，可以使用status命令查看迁移进度：</span></span><br><span class="line">gluster volume replace-brick status</span><br><span class="line"><span class="comment">#在数据迁移结束后，执行commit命令来进行Brick替换：</span></span><br><span class="line">gluster volume replace-brick commit</span><br></pre></td></tr></table></figure><h5 id="重新均衡卷"><a href="#重新均衡卷" class="headerlink" title="重新均衡卷"></a>重新均衡卷</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#不迁移数据：</span></span><br><span class="line">gluster volume rebalance lay-outstart</span><br><span class="line">gluster volume rebalance start</span><br><span class="line">gluster volume rebalance startforce</span><br><span class="line">gluster volume rebalance status</span><br><span class="line">gluster volume rebalance stop</span><br></pre></td></tr></table></figure><h4 id="Brick管理"><a href="#Brick管理" class="headerlink" title="Brick管理"></a>Brick管理</h4><h5 id="添加Brick"><a href="#添加Brick" class="headerlink" title="添加Brick"></a>添加Brick</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume add-brick <span class="built_in">test</span>-volume 192.168.1.&#123;151,152&#125;:/mnt/brick2</span><br></pre></td></tr></table></figure><h5 id="删除Brick"><a href="#删除Brick" class="headerlink" title="删除Brick"></a>删除Brick</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#若是副本卷，则移除的Bricks数是replica的整数倍</span></span><br><span class="line">gluster volume remove-brick <span class="built_in">test</span>-volume 192.168.1.&#123;151,152&#125;:/mnt/brick2 start</span><br><span class="line"><span class="comment">#在执行开始移除之后，可以使用status命令进行移除状态查看。</span></span><br><span class="line">gluster volume remove-brick <span class="built_in">test</span>-volume 192.168.1.&#123;151,152&#125;:/mnt/brick2 status</span><br><span class="line"><span class="comment">#使用commit命令执行Brick移除，则不会进行数据迁移而直接删除Brick，符合不需要数据迁移的用户需求。</span></span><br><span class="line">gluster volume remove-brick <span class="built_in">test</span>-volume 192.168.1.&#123;151,152&#125;:/mnt/brick2 commit</span><br></pre></td></tr></table></figure><h5 id="替换Brick"><a href="#替换Brick" class="headerlink" title="替换Brick"></a>替换Brick</h5><p>任务：把192.168.1.151:/mnt/brick0 替换为192.168.1.151:/mnt/brick2</p><p><strong>开始替换</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">gluster volume replace-brick <span class="built_in">test</span>-volume 192.168.1.:/mnt/brick0 ..152:/mnt/brick2 start</span><br><span class="line">异常信息：volume replace-brick: failed: /data/share2 or a prefix of it is already part of a volume</span><br><span class="line"></span><br><span class="line"><span class="comment">#说明 /mnt/brick2 曾经是一个Brick。具体解决方法</span></span><br><span class="line">rm -rf /mnt/brick2/.glusterfs</span><br><span class="line"></span><br><span class="line">setfattr -x trusted.glusterfs.volume-id /mnt/brick2</span><br><span class="line">setfattr -x trusted.gfid /mnt/brick2</span><br><span class="line"></span><br><span class="line"><span class="comment">#如上，执行replcace-brick卷替换启动命令，使用start启动命令后，开始将原始Brick的数据迁移到即将需要替换的Brick上。</span></span><br></pre></td></tr></table></figure><p><strong>查看是否替换完</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume replace-brick <span class="built_in">test</span>-volume 192.168.1.151:/mnt/brick0 ..152:/mnt/brick2 status</span><br></pre></td></tr></table></figure><p><strong>在数据迁移的过程中，可以执行abort命令终止Brick替换。</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gluster volume replace-brick <span class="built_in">test</span>-volume 192.168.1.151:/mnt/brick0 ..152:/mnt/brick2 abort</span><br></pre></td></tr></table></figure><p><strong>在数据迁移结束之后，执行commit命令结束任务，则进行Brick替换。使用volume info命令可以查看到Brick已经被替换</strong>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">gluster volume replace-brick <span class="built_in">test</span>-volume 192.168.1.151:/mnt/brick0 .152:/mnt/brick2 commit</span><br><span class="line"><span class="comment">#此时我们再往 /sf/data/vs/gfs/rep2上添加数据的话，数据会同步到 192.168.1.152:/mnt/brick0和192.168.1.152:/mnt/brick2上。而不会同步到192.168.1.151:/mnt/brick0 上。</span></span><br></pre></td></tr></table></figure><h4 id="文件系统扩展属性"><a href="#文件系统扩展属性" class="headerlink" title="文件系统扩展属性"></a>文件系统扩展属性</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获取文件扩展属性</span></span><br><span class="line">getfattr -d -m . -e hex filename</span><br><span class="line">getfattr -d -m <span class="string">"trusted.afr.*"</span> -e hex filename</span><br></pre></td></tr></table></figure><h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><h4 id="增加节点"><a href="#增加节点" class="headerlink" title="增加节点"></a>增加节点</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#hosts文件中添加对应服务器解析</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"ip   gs3"</span> &gt;&gt;/etc/hosts</span><br><span class="line"><span class="comment">#查看节点信息</span></span><br><span class="line">gluster peer status</span><br><span class="line"><span class="comment">#添加节点</span></span><br><span class="line">gluster peer probe gs3</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据卷添加新的brick</span></span><br><span class="line">gluster volume add-brick 卷名 replica 添加后的副本个数 brick所在的IP:brick所在的地址 force</span><br><span class="line">最后的force是因为，gluster集群推荐不要和系统公用磁盘，如果公用就需添加。</span><br><span class="line"></span><br><span class="line">例如：</span><br><span class="line">mkdir -p /brick/gv0</span><br><span class="line">gluster volume add-brick gv0 replica 2 gs2:/brick/gv0  force</span><br></pre></td></tr></table></figure><h4 id="删除节点"><a href="#删除节点" class="headerlink" title="删除节点"></a>删除节点</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#查看节点信息</span></span><br><span class="line">gluster peer status</span><br><span class="line"><span class="comment"># 删除操作,注意删除节点必须先删除brick</span></span><br><span class="line">gluster peer detach gs3</span><br></pre></td></tr></table></figure><p><img src="/articles/4f1d1494/1.png" alt></p><p>上面报错，是因为没有删除brick导致。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#数据卷移除旧的brick</span></span><br><span class="line">gluster volume remove-brick 卷名 replica 移除后的副本个数 brick所在的IP:brick所在的地址</span><br><span class="line"></span><br><span class="line">例如：移除gs3上的static卷</span><br><span class="line">gluster volume remove-brick static gs3:/data/volume/brick/static</span><br></pre></td></tr></table></figure><p><img src="/articles/4f1d1494/2.png" alt></p><p>执行移除报错，是因为先删除副本。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gluster volume remove-brick gv0 replica 2  gs3:/brick/gv0 force</span><br><span class="line"><span class="comment">#注意副本数为删除后还剩的个数</span></span><br><span class="line"><span class="comment">#然后再移除节点</span></span><br><span class="line">gluster peer detach gs3</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;glusterfs作为分布式存储，优点和安装这里就不再赘述了，看博客中教程。本文主要是介绍glusterfs常用命令和案例。&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.netlify.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="GlusterFS" scheme="https://wandouduoduo.netlify.com/tags/GlusterFS/"/>
    
  </entry>
  
  <entry>
    <title>GlusterFS分布式存储集群之使用</title>
    <link href="https://wandouduoduo.netlify.com/articles/35de9bb2.html"/>
    <id>https://wandouduoduo.netlify.com/articles/35de9bb2.html</id>
    <published>2019-11-05T03:56:15.000Z</published>
    <updated>2019-11-05T06:32:39.546Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Glusterfs逻辑卷创建与使用"><a href="#Glusterfs逻辑卷创建与使用" class="headerlink" title="Glusterfs逻辑卷创建与使用"></a>Glusterfs逻辑卷创建与使用</h1><p>volume是brick的组合，并且大部分glusterfs文件系统的操作都在volume上。</p><p>glusterfs支持4种基本卷，并可以根据需求对4种基本卷进行组合形成多种扩展卷（得益于glusterfs的模块化堆栈架构设计）。</p><p>以下主要展示各类型逻辑卷的功能性，未对性能做测试验证。</p><a id="more"></a><h2 id="分布式卷"><a href="#分布式卷" class="headerlink" title="分布式卷"></a>分布式卷</h2><p>分布式卷（Distributed Glusterfs Volume，又称DHT），glusterfs创建volume不指定卷类型时，默认即分布式卷，特点如下：</p><ol><li>根据hash算法，将多个文件分布到卷中的多个brick server上，类似（不是）raid0，但文件无分片；</li><li>方便扩展空间，但无冗余保护；</li><li>由于使用本地文件系统进行存储（brick server 的本地文件系统），存取效率不高；</li><li>受限于本地文件系统对单文件容量的限制，支持超大型文件系统有问题。</li></ol><p><img src="/articles/35de9bb2/1.png" alt="img"></p><h4 id="创建存储目录（optional）"><a href="#创建存储目录（optional）" class="headerlink" title="创建存储目录（optional）"></a>创建存储目录（optional）</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在brick server节点创建存储目录，即brick所在；</span></span><br><span class="line"><span class="comment"># 以glusterfs01节点为例，注意各brick server挂载磁盘的目录名的不同</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># mkdir -p /brick1/dis_volume</span></span><br></pre></td></tr></table></figure><h4 id="创建分布式卷"><a href="#创建分布式卷" class="headerlink" title="创建分布式卷"></a>创建分布式卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [transport [tcp | rdma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 演示分布式卷的创建，两个server节点即可，创建名为”distributed-volume”的逻辑卷</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create distributed-volume glusterfs01:/brick1/dis_volume glusterfs02:/brick2/dis_volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/2.png" alt="img"></p><h4 id="卷信息-状态"><a href="#卷信息-状态" class="headerlink" title="卷信息/状态"></a>卷信息/状态</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令”gluster volume list”可列出已创建的卷；</span></span><br><span class="line"><span class="comment"># 命令”gluster volume info”可不指定具体的卷，即列出所有卷信息；</span></span><br><span class="line"><span class="comment"># info中给出除卷名外，还有卷类型，状态，brick组成等信息；</span></span><br><span class="line"><span class="comment"># 其中状态为“Created”，需要通过命令启动后才可被挂载使用，在创建成功后的提示信息中有提到”please start the volume to access data”</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info distributed-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/3.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看卷状态；</span></span><br><span class="line"><span class="comment"># 展示卷中每个brick的状态，以及每个brick服务的监听端口</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume status distributed-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/4.png" alt="img"></p><h4 id="启动卷"><a href="#启动卷" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start distributed-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/5.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 再次查看卷信息，状态变为"Started"</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info distributed-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/6.png" alt="img"></p><h4 id="client挂载"><a href="#client挂载" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在客户端创建挂载目录</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/distributed</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 挂载时，可使用任意1台已加入可信存储池并已创建对应卷类型的server节点；</span></span><br><span class="line"><span class="comment"># brick以”SERVER:EXPORT”的形式标识</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:distributed-volume /mnt/distributed/</span></span><br></pre></td></tr></table></figure><h4 id="查看挂载情况"><a href="#查看挂载情况" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过“df -Th”命令可查看被挂载的volume，被挂载的文件系统，已经挂载卷的容量是2个brick容量之和</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/7.png" alt="img"></p><h4 id="查看brick的监听端口"><a href="#查看brick的监听端口" class="headerlink" title="查看brick的监听端口"></a>查看brick的监听端口</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># server节点上每启动1个brick，即启动1个brick服务，具备相应的服务监听端口，起始端口号是tcp49152</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># netstat -tunlp | grep gluster</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/8.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 另外，client连接的即brick服务的监听端口</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># netstat -nt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/9.png" alt="img"></p><h4 id="存储测试"><a href="#存储测试" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/distributed/</span></span><br><span class="line">[root@glusterfs-client distributed]<span class="comment"># touch distributed&#123;1..4&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/dis_volume/</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/10.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/dis_volume/</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/11.png" alt="img"></p><p><strong>结论：分布式卷将多个文件分布存储在多个brick server，但并无副本。</strong> </p><h2 id="条带卷（Deprecated）"><a href="#条带卷（Deprecated）" class="headerlink" title="条带卷（Deprecated）"></a>条带卷（Deprecated）</h2><p>条带卷（Striped Glusterfs Volume），特点如下：</p><ol><li>每个文件被分片成等同于brick数量的chunks，然后以round robin的方式将每个chunk存储到1个brick，相当于raid0；</li><li>单一超大容量文件可被分片，不受brick server本地文件系统的限制；</li><li>文件分片后，并发粒度是chunks，分布式读写性能较高，但分片随机读写可能会导致硬盘iops较高；</li><li>无冗余，1个server节点故障会导致所有数据丢失。</li></ol><p><img src="/articles/35de9bb2/12.png" alt="img"></p><h4 id="创建条带卷"><a href="#创建条带卷" class="headerlink" title="创建条带卷"></a>创建条带卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [stripe COUNT] [transport [tcp | dma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”strsipe-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的条带数量，数量需要与后续使用brick server数量对等；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create stripe-volume stripe 3 transport tcp glusterfs01:/brick1/str_volume glusterfs02:/brick2/str_volume glusterfs03:/brick3/str_volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/13.png" alt="img"></p><h4 id="启动卷-1"><a href="#启动卷-1" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start stripe-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/14.png" alt="img"></p><h4 id="client挂载-1"><a href="#client挂载-1" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/stripe</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:stripe-volume /mnt/stripe/</span></span><br></pre></td></tr></table></figure><h4 id="查看挂载情况-1"><a href="#查看挂载情况-1" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是3个brick容量之和</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/15.png" alt="img"></p><h4 id="存储测试-1"><a href="#存储测试-1" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/stripe/</span></span><br><span class="line">[root@glusterfs-client stripe]<span class="comment"># touch stripe&#123;1..6&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向strip1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client stripe]<span class="comment"># echo "this is stripe1.txt" &gt;&gt; strip1.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/str_volume/</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># cat /brick1/str_volume/strip1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/16.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/str_volume/</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># cat /brick2/str_volume/strip1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/17.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs03节点</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># tree /brick3/str_volume/</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># cat /brick3/str_volume/strip1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/18.png" alt="img"></p><p><strong>结论：条带卷将1个文件分片存储在多个brick server，但并无副本。</strong></p><h2 id="复制卷"><a href="#复制卷" class="headerlink" title="复制卷"></a>复制卷</h2><p>复制卷（Replicated Glusterfs Volume，又称AFR（Auto File Replication）），特点如下：</p><ol><li>每个文件同步复制镜像到多个brick，相当于文件级raid1；</li><li>副本数量通常设置为2或3，设置的副本数量需要是brick数量（至少为2）的倍数（如2台brick server，可设置副本数为2/4/6/…；如3台brick server，可设置副本数为3/6/9/…；依次类推），且每个brick的容量相等；</li><li>读性能提升，写性能下降，因为<strong>glusterfs的复制是同步事务操作，即写文件时，先把这个文件锁住，然后同时写两个或多个副本，写完后解锁，操作结束</strong>（ceph采用异步写副本，即写到一个主OSD便返回，这个OSD再通过内部网络异步写到其余OSD）；</li><li>通常与分布式卷或条带卷组合使用，解决前两者的冗余问题；</li><li>提升数据可靠性，但磁盘利用率低；</li><li>副本数设置为2时，可能会有脑裂（Split-brain）的风险（风险提示，但可配置），主要因在两个副本不一致时，无法仲裁以哪个副本为准，解决方案是加入仲裁或者设置3副本。</li></ol><p><img src="/articles/35de9bb2/19.png" alt="img"></p><h4 id="创建复制卷"><a href="#创建复制卷" class="headerlink" title="创建复制卷"></a>创建复制卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [replica COUNT] [transport [tcp | rdma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”replica-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的副本数量，数量需要与后续使用brick server数量对等；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式；</span></span><br><span class="line"><span class="comment"># 副本数为2时，有脑裂风险提示，提示采用3副本或仲裁机制，验证环境略过即可</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create replica-volume replica 2 transport tcp glusterfs01:/brick1/repl_volume glusterfs02:/brick2/repl_volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/20.png" alt="img"></p><h4 id="启动卷-2"><a href="#启动卷-2" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start replica-volume</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info replica-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/21.png" alt="img"></p><h4 id="client挂载-2"><a href="#client挂载-2" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/replica</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:replica-volume /mnt/replica/</span></span><br></pre></td></tr></table></figure><h4 id="查看挂载情况-2"><a href="#查看挂载情况-2" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是1个brick的容量</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/22.png" alt="img"></p><h4 id="存储测试-2"><a href="#存储测试-2" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/replica/</span></span><br><span class="line">[root@glusterfs-client replica]<span class="comment"># touch replica&#123;1..4&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向replica1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client replica]<span class="comment"># echo "this is replica1.txt" &gt;&gt; replica1.txt</span></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/repl_volume/</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># cat /brick1/repl_volume/replica1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/23.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/repl_volume/</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># cat /brick2/repl_volume/replica1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/24.png" alt="img"></p><p><strong>结论：复制卷将1个文件同步镜像到多个brick server，数据有冗余备份。</strong></p><h4 id="AFR恢复原理"><a href="#AFR恢复原理" class="headerlink" title="AFR恢复原理"></a>AFR恢复原理</h4><p>数据恢复只针对复制卷，AFR数据修复主要涉及三个方面：ENTRY，META，DATA。</p><p>记录描述副本状态的称之为<strong>ChangeLog</strong>，记录在每个副本文件扩展属性里，读入内存后以矩阵形式判断是否需要修复以及要以哪个副本为Source进行修复；初始值以及正常值为0（注：ENTRY和META,DATA分布对应着一个数值）。</p><p>以冗余度为2，即含有2个副本A和B的DATA修复为例，write的步骤分解为：</p><ol><li>下发Write操作；</li><li>加锁Lock；</li><li>向A，B副本的ChangeLog分别加1，记录到各副本的扩展属性中；</li><li>对A，B副本进行写操作；</li><li>若副本写成功则ChangeLog减1，若该副本写失败则ChangLog值不变，记录到各个副本的扩展属性中；</li><li>解锁UnLock；</li><li>向上层返回，只要有一个副本写成功就返回成功。 </li></ol><p>上述操作在AFR中是完整的一个transaction动作，根据两个副本记录的ChangeLog的数值确定了副本的几种状态：</p><ol><li>WISE：智慧的，即该副本的ChangeLog中对应的值是0，而另一副本对应的数值大于0；</li><li>INNOCENT：无辜的，即两副本的ChangeLog对应的值都是0；</li><li>FOOL：愚蠢的，即该副本的ChangeLog对应的值大于是0，而另一副本对应的数值是0；</li><li>IGNORANT，忽略的，即该副本的ChangeLog丢失。</li></ol><p>恢复分以下场景：</p><ol><li><p>1个节点changelog状态为WISE，其余节点为FOOL或其他非WISE状态，以WISE节点去恢复其他节点；</p></li><li><p>所有节点是IGNORANT状态，手动触发heal，通过命令以UID最小的文件作为source，去恢复大小为0的其他文件；</p></li><li><p>多个状态是WISE时，即出现脑裂状态，脑裂的文件通常读不出来，报”Input/Output error”，可查看日志/var/log/glusterfs/glustershd.log。</p><p>脑裂原理及解决方案：[<a href="https://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/]" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/]</a>(<a href="https://docs.gluster.org/en/latest/Administrator" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator</a> Guide/Split brain and ways to deal with it/)</p></li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过命令查看副本文件的扩展属性：getfattr -m . -d -e hex [filename]</span></span><br><span class="line"><span class="comment"># “trusted.afr.xxx”部分即扩展属性，值是24bit，分3部分，依次标识DATA ，META， ENTRY 3者的changelog</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># getfattr -m . -d -e hex /brick1/repl_volume/replica1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/25.png" alt="img"></p><h2 id="分布式复制卷"><a href="#分布式复制卷" class="headerlink" title="分布式复制卷"></a>分布式复制卷</h2><p>分布式复制卷（Distributed Replicated Glusterfs Volume），是分布式卷与复制卷的组合，兼具两者的功能，特点如下：</p><ol><li>若干brick组成1个复制卷，另外若干brick组成其他复制卷；单个文件在复制卷内数据保持副本，不同文件在不同复制卷之间进行哈希分布；即分布式卷跨复制卷集（replicated sets ）；</li><li>brick server数量是副本数量的倍数，且&gt;=2倍，即最少需要4台brick server，同时组建复制卷集的brick容量相等。</li></ol><p><img src="/articles/35de9bb2/26.png" alt="img"></p><h4 id="创建分布式复制卷"><a href="#创建分布式复制卷" class="headerlink" title="创建分布式复制卷"></a>创建分布式复制卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [replica COUNT] [transport [tcp | rdma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”distributed-replica-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的副本数量，brick server数量是副本数量的倍数，且&gt;=2倍；</span></span><br><span class="line"><span class="comment"># 不需要指出分布式卷类型，只要副本数量与brick server数量不等且符合倍数关系，即是分布式复制卷；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式；</span></span><br><span class="line"><span class="comment"># 副本数为2时，有脑裂风险提示，提示采用3副本或仲裁机制，验证环境略过即可</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create distributed-replica-volume replica 2 transport tcp \</span></span><br><span class="line"> glusterfs01:/brick1/dis_repl_volume \</span><br><span class="line"> glusterfs02:/brick2/dis_repl_volume \</span><br><span class="line"> glusterfs03:/brick3/dis_repl_volume \</span><br><span class="line"> glusterfs04:/brick4/dis_repl_volume</span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/27.png" alt="img"></p><h4 id="启动卷-3"><a href="#启动卷-3" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 卷类型：分布式复制卷</span></span><br><span class="line"><span class="comment"># “Number of Bricks”：2副本，2个副本集（replicated sets ），4个brick server</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start distributed-replica-volume</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info distributed-replica-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/28.png" alt="img"></p><h4 id="client挂载-3"><a href="#client挂载-3" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/distributed-replica</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:distributed-replica-volume /mnt/distributed-replica/</span></span><br></pre></td></tr></table></figure><h4 id="查看挂载情况-3"><a href="#查看挂载情况-3" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是2个副本集（replicated sets ）容量之和</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/29.png" alt="img"></p><h4 id="存储测试-3"><a href="#存储测试-3" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/distributed-replica/</span></span><br><span class="line">[root@glusterfs-client distributed-replica]<span class="comment"># touch distributed-replica&#123;1..6&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向distributed-replica1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client distributed-replica]<span class="comment"># echo "this is distributed-replica1.txt" &gt;&gt; distributed-replica1.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/dis_repl_volume/</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/30.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/dis_repl_volume/</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/31.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs03节点</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># tree /brick3/dis_repl_volume/</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># cat /brick3/dis_repl_volume/distributed-replica1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/32.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs04节点</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># tree /brick4/dis_repl_volume/</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># cat /brick4/dis_repl_volume/distributed-replica1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/33.png" alt="img"></p><p><strong>结论：分布式复制卷将数据文件分布在多个复制集（replicated sets ）中，每个复制集中数据有镜像冗余。</strong></p><h2 id="分布式条带卷（Deprecated）"><a href="#分布式条带卷（Deprecated）" class="headerlink" title="分布式条带卷（Deprecated）"></a>分布式条带卷（Deprecated）</h2><p>分布式条带卷（Distributed Striped Glusterfs Volume），是分布式卷与条带卷的组合，兼具两者的功能，特点如下：</p><ol><li>若干brick组成1个条带卷，另外若干brick组成其他条带卷；单个文件在条带卷内数据以条带的形式存储，不同文件在不同条带卷之间进行哈希分布；即分布式卷跨条带卷；</li><li>brick server数量是条带数的倍数，且&gt;=2倍，即最少需要4台brick server。</li></ol><p><img src="/articles/35de9bb2/34.png" alt="img"></p><h4 id="创建分布式条带卷"><a href="#创建分布式条带卷" class="headerlink" title="创建分布式条带卷"></a>创建分布式条带卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [stripe COUNT] [transport [tcp | rdma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”distributed-stripe-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的条带数，brick server数量是条带数量的倍数，且&gt;=2倍；</span></span><br><span class="line"><span class="comment"># 不需要指出分布式卷类型，只要条带数量与brick server数量不等且符合倍数关系，即是分布式复制卷；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式；</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create distributed-stripe-volume stripe 2 transport tcp \</span></span><br><span class="line"> glusterfs01:/brick1/dis_str_volume \</span><br><span class="line"> glusterfs02:/brick2/dis_str_volume \</span><br><span class="line"> glusterfs03:/brick3/dis_str_volume \</span><br><span class="line"> glusterfs04:/brick4/dis_str_volume</span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/35.png" alt="img"></p><h4 id="启动卷-4"><a href="#启动卷-4" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 卷类型：分布式条带卷</span></span><br><span class="line"><span class="comment"># “Number of Bricks”：2分布集，2条带集（replicated sets ），4个brick server</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start distributed-stripe-volume</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info distributed-stripe-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/36.png" alt="img"></p><h4 id="client挂载-4"><a href="#client挂载-4" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/distributed-stripe</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:distributed-stripe-volume /mnt/distributed-stripe/</span></span><br></pre></td></tr></table></figure><h4 id="查看挂载情况-4"><a href="#查看挂载情况-4" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是4个brick容量之和</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/37.png" alt="img"></p><h4 id="存储测试-4"><a href="#存储测试-4" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/distributed-stripe/</span></span><br><span class="line">[root@glusterfs-client distributed-stripe]<span class="comment"># touch distributed-stripe&#123;1..6&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向distributed-stripe1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client distributed-stripe]<span class="comment"># echo "this is distributed-stripe1.txt" &gt;&gt; distributed-stripe1.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/dis_str_volume/</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/38.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/dis_str_volume/</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/39.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs03节点</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># tree /brick3/dis_str_volume/</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># cat /brick3/dis_str_volume/distributed-stripe1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/40.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs04节点</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># tree /brick4/dis_str_volume/</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># cat /brick4/dis_str_volume/distributed-stripe1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/41.png" alt="img"></p><p><strong>结论：分布式条带卷将数据文件分布在多个条带集中，每个条带集中数据再以条带的形式存储在对应条带集中的全部brick上，数据无冗余备份。</strong></p><h2 id="条带镜像卷（Deprecated）"><a href="#条带镜像卷（Deprecated）" class="headerlink" title="条带镜像卷（Deprecated）"></a>条带镜像卷（Deprecated）</h2><p>条带复制卷（STRIPE REPLICA Volume），是条带与复制卷的组合，兼具两者的功能，特点如下：</p><ol><li>若干brick组成1个复制卷，另外若干brick组成其他复制卷；单个文件以条带的形式存储在2个或多个复制集（replicated sets ），复制集内文件分片以副本的形式保存；相当于文件级raid01；</li><li>brick server数量是副本数的倍数，且&gt;=2倍，即最少需要4台brick server。</li></ol><p><img src="/articles/35de9bb2/42.png" alt="img"></p><h2 id="分布式条带镜像卷（Deprecated）"><a href="#分布式条带镜像卷（Deprecated）" class="headerlink" title="分布式条带镜像卷（Deprecated）"></a>分布式条带镜像卷（Deprecated）</h2><p>分布式条带复制卷（DISTRIBUTE STRIPE REPLICA VOLUME），是分布式卷，条带与复制卷的组合，兼具三者的功能，特点如下：</p><ol><li>多个文件哈希分布到到多个条带集中，单个文件在条带集中以条带的形式存储在2个或多个复制集（replicated sets ），复制集内文件分片以副本的形式保存；</li><li>brick server数量是副本数的倍数，且&gt;=2倍，即最少需要4台brick server。</li></ol><p><img src="/articles/35de9bb2/43.png" alt="img"></p><h2 id="纠删卷"><a href="#纠删卷" class="headerlink" title="纠删卷"></a>纠删卷</h2><p>纠删卷（Dispersed Volumes）是v3.6版本后发布的一种volume特点如下：</p><ol><li>基于纠删码（erasure codes， EC）实现，类似于raid5/6（取决于redundancy等级）；</li><li>通过配置redundancy（冗余）级别提高可靠性，在保证较高的可靠性同时，可以提升物理存储空间的利用率；</li><li>文件被分割成大小相同的chunk(块)，每个chunk又被分割成fragment，冗余信息的fragment随之生成，且同一个fragment只会保存一个brick上；</li><li>redundancy均匀分布存储在所有的brick，逻辑卷的有效空间是<usable size> = <brick size> * (#bricks - redundancy)；</brick></usable></li><li>在数据恢复时，只要(#bricks - redundancy)个fragment（数据或冗余信息）可用，就能正常恢复数据；</li><li>卷中所有brick容量需要相同，否则最小的brick满容量时，数据无法写入；</li><li>实际部署时，redundancy &lt; #bricks / 2 (or equivalently, redundancy * 2 &lt; #bricks)，即brick至少是3个；redundancy设置为0时，DispersedVolume等同于分布式卷；若redundancy设置为brick/2时，DispersedVolume等同于复制卷。</li></ol><h4 id="创建纠删卷"><a href="#创建纠删卷" class="headerlink" title="创建纠删卷"></a>创建纠删卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create [disperse [&lt;count&gt;]] [redundancy &lt;count&gt;] [transport tcp | rdma | tcp,rdma]</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”disperse-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的brick server数量；</span></span><br><span class="line"><span class="comment"># 冗余等级”redundancy”需要根据使用brick server数量(“disperse conunt”)，并结合期望的冗余度数综合考量；</span></span><br><span class="line"><span class="comment"># 也可不设置冗余等级”redundancy”，系统会根据brick server数量(“disperse conunt”)自动计算最优值，确认即可；如disperse conunt=3，则redundancy=1（无“warning message”）；disperse conunt=6，则redundancy=2（有“warning message”）；但disperse conunt=4，则无最优值，此时使用默认redundancy=1（有“warning message”）；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式，默认即tcp；</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create disperse-volume disperse 3 transport tcp \</span></span><br><span class="line"> glusterfs01:/brick1/disperse_volume \</span><br><span class="line"> glusterfs02:/brick2/disperse_volume \</span><br><span class="line"> glusterfs03:/brick3/disperse_volume</span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/44.png" alt="img"></p><h4 id="启动卷-5"><a href="#启动卷-5" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 卷类型：disperse卷</span></span><br><span class="line"><span class="comment"># “Number of Bricks”：rudundancy=1，3个brick server</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start disperse-volume</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info disperse-volume</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/45.png" alt="img"></p><h4 id="client挂载-5"><a href="#client挂载-5" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/disperse</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:disperse-volume /mnt/disperse/</span></span><br></pre></td></tr></table></figure><h4 id="查看挂载情况-5"><a href="#查看挂载情况-5" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是2个brick容量之和，&lt;usable size&gt; = &lt;brick size&gt; * (#bricks - redundancy)</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/46.png" alt="img"></p><h4 id="存储测试-5"><a href="#存储测试-5" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/disperse/</span></span><br><span class="line">[root@glusterfs-client disperse]<span class="comment"># touch disperse&#123;1..4&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向distributed-replica1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client disperse]<span class="comment"># echo "this is disperse1.txt" &gt;&gt; disperse1.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/disperse_volume/</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># cat /brick1/disperse_volume/disperse1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/47.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/disperse_volume/</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># cat /brick2/disperse_volume/disperse1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/48.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># glusterfs03节点</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># tree /brick3/disperse_volume/</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># cat /brick3/disperse_volume/disperse1.txt</span></span><br></pre></td></tr></table></figure><p><img src="/articles/35de9bb2/49.png" alt="img"></p><p><strong>结论：纠删卷将数据文件（含冗余信息）分布在多个brick中，数据有冗余。</strong></p><h2 id="分布式纠删卷"><a href="#分布式纠删卷" class="headerlink" title="分布式纠删卷"></a>分布式纠删卷</h2><p>分布式纠删卷（Distributed Dispersed Volumes）等效于分布式复制卷，但使用的是纠删子卷，而非复制子卷。</p><h1 id="Glusterfs管理"><a href="#Glusterfs管理" class="headerlink" title="Glusterfs管理"></a>Glusterfs管理</h1><h2 id="均衡卷"><a href="#均衡卷" class="headerlink" title="均衡卷"></a>均衡卷</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不迁移数据</span></span><br><span class="line">gluster volume VOLNAME rebalance [fix-layout start | start | startforce | status | stop]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修复卷（只针对复制卷）</span></span><br><span class="line">gluster volume heal REPLICATE-VOLNAME/DISPERSE-VOLNAME       <span class="comment">#只修复有问题的文件  </span></span><br><span class="line">gluster volume heal REPLICATE-VOLNAME/DISPERSE-VOLNAME full    <span class="comment">#修复所有文件  </span></span><br><span class="line">gluster volume heal REPLICATE-VOLNAME/DISPERSE-VOLNAME info    <span class="comment">#查看自愈详情  </span></span><br><span class="line">gluster volume heal REPLICATE-VOLNAME/DISPERSE-VOLNAME info healed|heal-failed|split-brain</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置卷</span></span><br><span class="line">gluster volume <span class="built_in">set</span> options</span><br></pre></td></tr></table></figure><h2 id="删除卷"><a href="#删除卷" class="headerlink" title="删除卷"></a>删除卷</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 删除卷操作，必须先停用卷；</span></span><br><span class="line"><span class="comment"># 最后可清空brick server节点对应目录下的内容</span></span><br><span class="line">gluster volume stop distributed-volume</span><br><span class="line">gluster volume delete distributed-volume</span><br><span class="line">rm -f /brick1/dis_volume</span><br></pre></td></tr></table></figure><h2 id="brick管理"><a href="#brick管理" class="headerlink" title="brick管理"></a>brick管理</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加brick</span></span><br><span class="line">gluster volume add-brick VOLNAME NEW-BRICK</span><br><span class="line"></span><br><span class="line"><span class="comment"># 移除brick</span></span><br><span class="line">gluster volume remove-brick VOLNAME BRICK [start | status | commit]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换brick</span></span><br><span class="line">gluster volume replace-brick VOLNAME BRICKNEW-BRICK [start | pause | sbortstatus | commit]</span><br></pre></td></tr></table></figure><h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p>相关日志，在/var/log/glusterfs/目录下，可根据需要查看；</p><p>如/var/log/glusterfs/brick/下是各brick创建的日志；</p><p>如/var/log/glusterfs/cmd_history.log是命令执行记录日志；</p><p>如/var/log/glusterfs/glusterd.log是glusterd守护进程日志。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Glusterfs逻辑卷创建与使用&quot;&gt;&lt;a href=&quot;#Glusterfs逻辑卷创建与使用&quot; class=&quot;headerlink&quot; title=&quot;Glusterfs逻辑卷创建与使用&quot;&gt;&lt;/a&gt;Glusterfs逻辑卷创建与使用&lt;/h1&gt;&lt;p&gt;volume是brick的组合，并且大部分glusterfs文件系统的操作都在volume上。&lt;/p&gt;
&lt;p&gt;glusterfs支持4种基本卷，并可以根据需求对4种基本卷进行组合形成多种扩展卷（得益于glusterfs的模块化堆栈架构设计）。&lt;/p&gt;
&lt;p&gt;以下主要展示各类型逻辑卷的功能性，未对性能做测试验证。&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.netlify.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="GlusterFS" scheme="https://wandouduoduo.netlify.com/tags/GlusterFS/"/>
    
  </entry>
  
  <entry>
    <title>GlusterFS分布式存储集群之部署</title>
    <link href="https://wandouduoduo.netlify.com/articles/e3bb873c.html"/>
    <id>https://wandouduoduo.netlify.com/articles/e3bb873c.html</id>
    <published>2019-11-05T03:37:42.000Z</published>
    <updated>2019-11-05T04:36:27.123Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Glusterfs框架"><a href="#Glusterfs框架" class="headerlink" title="Glusterfs框架"></a>Glusterfs框架</h1><p>Glusterfs（Gluster file system）是开源的，具有强大横向扩展能力的（scale-out）,分布式的，可将来自多个服务器的存储资源通过tcp/ip或infiniBand RDMA 网络整合到一个统一的全局命名空间中的文件系统。</p><h2 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h2><p><img src="/articles/e3bb873c/1.png" alt="img"></p><ol><li>GlusterFS主要由存储服务器（Brick Server）、客户端以及 NFS/Samba 存储网关组成；</li><li>架构中无元数据服务器组件，无对于提升整个系统的性单点故障和性能瓶颈问题，可提高系统扩展性、性能、可靠性和稳定性；</li><li>GlusterFS支持 TCP/IP 和 InfiniBand RDMA 高速网络互联；</li><li>客户端可通过原生 GlusterFS 协议访问数据，其他没有运行 GlusterFS 客户端的终端可通过 NFS/CIFS 标准协议通过存储网关访问数据（存储网关提供弹性卷管理和访问代理功能）；</li><li>存储服务器主要提供基本的数据存储功能，客户端弥补了没有元数据服务器的问题，承担了更多的功能，包括数据卷管理、I/O 调度、文件定位、数据缓存等功能，利用 FUSE（File system in User Space）模块将 GlusterFS 挂载到本地文件系统之上，实现 POSIX 兼容的方式来访问系统数据。</li></ol><h2 id="常见术语"><a href="#常见术语" class="headerlink" title="常见术语"></a>常见术语</h2><ol><li>Brick：GlusterFS中最基本的存储单元，表示为受信存储池（trusted storage pool）中输出的目录，供客户端挂载用，可以通过主机名与目录名来标识，如’SERVER:EXPORT’；</li><li>Volume：卷，逻辑上由N个brick组成；</li><li>FUSE：Unix-like OS上的可动态加载的模块，允许用户不用修改内核即可创建自己的文件系统；</li><li>Glusterd：Gluster management daemon，在trusted storage pool中所有的服务器上运行；</li><li>Volfile：Glusterfs进程的配置文件，通常是位于/var/lib/glusterd/vols/目录下的{volname}文件；</li><li>Self-heal：用于后台运行检测复本卷中文件与目录的不一致性并解决这些不一致；</li><li>Split-brain：脑裂；</li><li>GFID：GlusterFS卷中的每个文件或目录都有一个唯一的128位的数据相关联，用于模拟inode；</li><li>Namespace：每个Gluster卷都导出单个ns作为POSIX的挂载点。</li></ol><h2 id="数据访问流程"><a href="#数据访问流程" class="headerlink" title="数据访问流程"></a>数据访问流程</h2><p><img src="/articles/e3bb873c/2.png" alt="img"></p><ol><li>在客户端,用户通过 glusterfs的mount point读写数据；</li><li>用户的这个操作被递交给本地 Linux 系统的VFS 来处理；</li><li>VFS 将数据递交给 FUSE 内核文件系统（在启动 glusterfs 客户端以前,需要向系统注册一个实际的文件系统 FUSE），该文件系统与 ext3 在同一个层次， ext3 是对实际的磁盘进行处理，而 fuse 文件系统则是将数据通过 /dev/fuse 这个设备文件递交给了glusterfs client 端，可以将 fuse 文件系统理解为一个代理；</li><li>数据被 fuse 递交给 Glusterfs client 后， client 对数据进行一些指定的处理（即按 client 配置文件来进行的一系列处理）；</li><li>在 glusterfs client 的处理末端,通过网络将数据递交给 Glusterfs Server, 并且将数据写入到服务器所控制的存储设备上。</li></ol><a id="more"></a><h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><ol><li><p>Quick Start Guide：<a href="http://gluster.readthedocs.io/en/latest/Quick-Start-Guide/Quickstart/" target="_blank" rel="noopener">http://gluster.readthedocs.io/en/latest/Quick-Start-Guide/Quickstart/</a></p></li><li><p>Install-Guide：<a href="https://docs.gluster.org/en/latest/Install-Guide/Install/" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Install-Guide/Install/</a></p></li><li><p>CentOS gluster-Quickstart：<a href="https://wiki.centos.org/SpecialInterestGroup/Storage/gluster-Quickstart" target="_blank" rel="noopener">https://wiki.centos.org/SpecialInterestGroup/Storage/gluster-Quickstart</a></p></li><li><p>Type of Volumes：<a href="https://docs.gluster.org/en/latest/Quick-Start-Guide/Architecture/#types-of-volumes" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Quick-Start-Guide/Architecture/#types-of-volumes</a></p></li><li><p>Setting up GlusterFS Volumes：[<a href="https://docs.gluster.org/en/latest/Administrator%20Guide/Setting%20Up%20Volumes/]" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator%20Guide/Setting%20Up%20Volumes/]</a>(<a href="https://docs.gluster.org/en/latest/Administrator" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator</a> Guide/Setting Up Volumes/)</p></li><li><p>脑裂：[<a href="https://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/]" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/]</a>(<a href="https://docs.gluster.org/en/latest/Administrator" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator</a> Guide/Split brain and ways to deal with it/)</p></li><li><p>Glusterfs技术详解（推荐）：<a href="https://czero000.github.io/2016/04/05/glusterfs-technical-explanation.html" target="_blank" rel="noopener">https://czero000.github.io/2016/04/05/glusterfs-technical-explanation.html</a></p></li></ol><h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><h2 id="环境规划"><a href="#环境规划" class="headerlink" title="环境规划"></a>环境规划</h2><table><thead><tr><th><strong>Hostname</strong></th><th><strong>IP</strong></th><th><strong>Service</strong></th><th><strong>Remark</strong></th></tr></thead><tbody><tr><td>glusterfs-client</td><td>172.30.200.50</td><td>glusterfs(3.12.9)glusterfs-fuse</td><td>客户端</td></tr><tr><td>glusterfs01</td><td>172.30.200.51</td><td>glusterfs(3.12.9)glusterfs-server(3.12.9)glusterfs-fuse</td><td>服务器端</td></tr><tr><td>glusterfs02</td><td>172.30.200.52</td><td>glusterfs(3.12.9)glusterfs-server(3.12.9)glusterfs-fuse</td><td>服务器端</td></tr><tr><td>glusterfs03</td><td>172.30.200.53</td><td>glusterfs(3.12.9)glusterfs-server(3.12.9)glusterfs-fuse</td><td>服务器端</td></tr><tr><td>glusterfs04</td><td>172.30.200.54</td><td>glusterfs(3.12.9)glusterfs-server(3.12.9)glusterfs-fuse</td><td>服务器端</td></tr></tbody></table><h2 id="设置hosts"><a href="#设置hosts" class="headerlink" title="设置hosts"></a>设置hosts</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 所有节点保持一致的hosts即可，以gluster01节点为例；</span></span><br><span class="line"><span class="comment"># 绑定hosts不是必须的，后续组建受信存储池也可使用ip的形式</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># vim /etc/hosts </span></span><br><span class="line"><span class="comment"># glusterfs</span></span><br><span class="line">172.30.200.50   glusterfs-client</span><br><span class="line">172.30.200.51   glusterfs01</span><br><span class="line">172.30.200.52   glusterfs02</span><br><span class="line">172.30.200.53   glusterfs03</span><br><span class="line">172.30.200.54   glusterfs04</span><br><span class="line"></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># cat /etc/hosts</span></span><br></pre></td></tr></table></figure><p><img src="/articles/e3bb873c/3.png" alt="img"></p><h2 id="设置ntp"><a href="#设置ntp" class="headerlink" title="设置ntp"></a>设置ntp</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 至少4个Brick Server节点需要保持时钟同步（重要），以glusterfs01节点为例</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># yum install chrony -y </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑/etc/chrony.conf文件，设置”172.20.0.252”为时钟源；</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># egrep -v "^$|^#" /etc/chrony.conf </span></span><br><span class="line">server 172.20.0.252 iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">logdir /var/<span class="built_in">log</span>/chrony</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置开机启动，并重启</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># systemctl enable chronyd.service</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># systemctl restart chronyd.service</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看状态</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># systemctl status chronyd.service</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># chronyc sources -v</span></span><br></pre></td></tr></table></figure><h2 id="设置glusterfs-packages"><a href="#设置glusterfs-packages" class="headerlink" title="设置glusterfs packages"></a>设置glusterfs packages</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 全部节点安装glusterfs yum源</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># yum install -y centos-release-gluster </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># yum repolist</span></span><br></pre></td></tr></table></figure><h2 id="设置iptables"><a href="#设置iptables" class="headerlink" title="设置iptables"></a>设置iptables</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 提前统一设置iptables（至少4个Brick Server节点），以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 初始环境已使用iptables替代centos7.x自带的firewalld，同时关闭selinux；</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># vim /etc/sysconfig/iptables</span></span><br><span class="line"><span class="comment"># tcp24007:24008：glusterfsd daemon management服务监听端口；</span></span><br><span class="line"><span class="comment"># tcp49152:49160：3.4版本之后（之前的版本的起始端口是24009），启动1个brick，即启动1个监听端口，起始端口为49152，依次类推，如这里设置49152:49160，可开启9个brick；</span></span><br><span class="line"><span class="comment"># 另如果启动nfs server，需要开启38465:38467，111等端口</span></span><br><span class="line">-A INPUT -p tcp -m state --state NEW -m tcp --dport 24007:24008 -j ACCEPT</span><br><span class="line">-A INPUT -p tcp -m state --state NEW -m tcp --dport 49152:49160 -j ACCEPT</span><br><span class="line"></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># service iptables restart</span></span><br></pre></td></tr></table></figure><h1 id="设置glusterfs"><a href="#设置glusterfs" class="headerlink" title="设置glusterfs"></a>设置glusterfs</h1><h2 id="mount-brick"><a href="#mount-brick" class="headerlink" title="mount brick"></a>mount brick</h2><h4 id="创建分区"><a href="#创建分区" class="headerlink" title="创建分区"></a>创建分区</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 各brick server的磁盘挂载前需要创建分区并格式化，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 将整个/dev/sdb磁盘设置为1个分区，分区设置默认即可</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># fdisk /dev/sdb</span></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): n</span><br><span class="line">Select (default p): </span><br><span class="line">Partition number (1-4, default 1): </span><br><span class="line">First sector (2048-209715199, default 2048): </span><br><span class="line">Last sector, +sectors or +size&#123;K,M,G&#125; (2048-209715199, default 209715199): </span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): w</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># fdisk -l /dev/sdb</span></span><br></pre></td></tr></table></figure><p><img src="/articles/e3bb873c/4.png" alt="img"></p><h4 id="格式化分区"><a href="#格式化分区" class="headerlink" title="格式化分区"></a>格式化分区</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs01 ~]<span class="comment"># mkfs.xfs -i size=512 /dev/sdb1</span></span><br></pre></td></tr></table></figure><p><img src="/articles/e3bb873c/5.png" alt="img"></p><h4 id="挂载分区"><a href="#挂载分区" class="headerlink" title="挂载分区"></a>挂载分区</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建挂载目录，目录名自定义；</span></span><br><span class="line"><span class="comment"># 这里为区分，可以将4个server节点的目录名按顺序命名（非必须）</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># mkdir -p /brick1</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># mkdir -p /brick2</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># mkdir -p /brick3</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># mkdir -p /brick4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改/etc/fstab文件，以glusterfs01节点为例，注意其余3各节点挂载点目录名不同；</span></span><br><span class="line"><span class="comment"># 第一栏：设备装置名；</span></span><br><span class="line"><span class="comment"># 第二栏：挂载点；</span></span><br><span class="line"><span class="comment"># 第三栏：文件系统；</span></span><br><span class="line"><span class="comment"># 第四栏：文件系统参数，默认情况使用 defaults 即可，同时具有 rw, suid, dev, exec, auto, nouser, async 等参数；</span></span><br><span class="line"><span class="comment"># 第五栏：是否被 dump 备份命令作用，"0"代表不做 dump 备份； "1"代表要每天进行 dump； "2"代表其他不定日期的 dump； 通常设置"0" 或者"1"；</span></span><br><span class="line"><span class="comment"># 第六栏：是否以 fsck 检验扇区，启动过程中，系统默认会以 fsck 检验 filesystem 是否完整 (clean)， 但某些 filesystem 是不需要检验的，如swap；"0"是不要检验，"1"表示最早检验(一般只有根目录会配置为 "1")，"2"是检验，但晚于"1"；通常根目录配置为"1" ，其余需要要检验的 filesystem 都配置为"2"；</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># echo "/dev/sdb1 /brick1                               xfs     defaults        1 2" &gt;&gt; /etc/fstab</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 挂载并展示</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># mount -a &amp;&amp; mount</span></span><br></pre></td></tr></table></figure><p><img src="/articles/e3bb873c/6.png" alt="img"></p><h2 id="启动glusterfs-server"><a href="#启动glusterfs-server" class="headerlink" title="启动glusterfs-server"></a>启动glusterfs-server</h2><h4 id="安装glusterfs-server"><a href="#安装glusterfs-server" class="headerlink" title="安装glusterfs-server"></a>安装glusterfs-server</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在4个brick server节点安装glusterfs-server，以glusterfs01节点为例</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># yum install -y glusterfs-server</span></span><br></pre></td></tr></table></figure><h4 id="启动glusterfs-server-1"><a href="#启动glusterfs-server-1" class="headerlink" title="启动glusterfs-server"></a>启动glusterfs-server</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@glusterfs01 ~]<span class="comment"># systemctl enable glusterd</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># systemctl restart glusterd</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看状态</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># systemctl status glusterd</span></span><br></pre></td></tr></table></figure><p><img src="/articles/e3bb873c/7.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看服务监听端口</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># netstat -tunlp</span></span><br></pre></td></tr></table></figure><p><img src="/articles/e3bb873c/8.png" alt="img"></p><h2 id="组建受信存储池"><a href="#组建受信存储池" class="headerlink" title="组建受信存储池"></a>组建受信存储池</h2><p>受信存储池（trusted storage pools），是1个可信的网络存储服务器，为卷提供brick，可以理解为集群。 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在任意一个server节点组建受信存储池均可，即由任意节点邀请其他节点组建存储池；</span></span><br><span class="line"><span class="comment"># 组建时，做为”邀请者”，不需要再加入本节点；</span></span><br><span class="line"><span class="comment"># 使用ip或dns主机名解析都可以，这里已在hosts文件绑定主机，采用主机名；</span></span><br><span class="line"><span class="comment"># 从集群移除节点：gluster peer detach &lt;ip or hostname&gt;</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster peer probe glusterfs02</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster peer probe glusterfs03</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster peer probe glusterfs04</span></span><br></pre></td></tr></table></figure><p><img src="/articles/e3bb873c/9.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看受信存储池状态；</span></span><br><span class="line"><span class="comment"># 在glusterfs01节点查看集群状态，不会list出本节点，只展示peers</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster peer status</span></span><br></pre></td></tr></table></figure><p><img src="/articles/e3bb873c/10.png" alt="img"></p><h2 id="设置glusterfs-client"><a href="#设置glusterfs-client" class="headerlink" title="设置glusterfs-client"></a>设置glusterfs-client</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 客户端主要安装两个组件，glusterfs与glusterfs-fuse；</span></span><br><span class="line"><span class="comment"># glusterfs-client具备如数据卷管理、I/O 调度、文件定位、数据缓存等功能；</span></span><br><span class="line"><span class="comment"># glusterfs-fuse将远端glusterfs挂载到本地文件系统，可通过”modinfo fuse”，“ll /dev/fuse”等命令查看</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># yum install -y glusterfs glusterfs-fuse</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Glusterfs框架&quot;&gt;&lt;a href=&quot;#Glusterfs框架&quot; class=&quot;headerlink&quot; title=&quot;Glusterfs框架&quot;&gt;&lt;/a&gt;Glusterfs框架&lt;/h1&gt;&lt;p&gt;Glusterfs（Gluster file system）是开源的，具有强大横向扩展能力的（scale-out）,分布式的，可将来自多个服务器的存储资源通过tcp/ip或infiniBand RDMA 网络整合到一个统一的全局命名空间中的文件系统。&lt;/p&gt;
&lt;h2 id=&quot;框架&quot;&gt;&lt;a href=&quot;#框架&quot; class=&quot;headerlink&quot; title=&quot;框架&quot;&gt;&lt;/a&gt;框架&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/articles/e3bb873c/1.png&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;GlusterFS主要由存储服务器（Brick Server）、客户端以及 NFS/Samba 存储网关组成；&lt;/li&gt;
&lt;li&gt;架构中无元数据服务器组件，无对于提升整个系统的性单点故障和性能瓶颈问题，可提高系统扩展性、性能、可靠性和稳定性；&lt;/li&gt;
&lt;li&gt;GlusterFS支持 TCP/IP 和 InfiniBand RDMA 高速网络互联；&lt;/li&gt;
&lt;li&gt;客户端可通过原生 GlusterFS 协议访问数据，其他没有运行 GlusterFS 客户端的终端可通过 NFS/CIFS 标准协议通过存储网关访问数据（存储网关提供弹性卷管理和访问代理功能）；&lt;/li&gt;
&lt;li&gt;存储服务器主要提供基本的数据存储功能，客户端弥补了没有元数据服务器的问题，承担了更多的功能，包括数据卷管理、I/O 调度、文件定位、数据缓存等功能，利用 FUSE（File system in User Space）模块将 GlusterFS 挂载到本地文件系统之上，实现 POSIX 兼容的方式来访问系统数据。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;常见术语&quot;&gt;&lt;a href=&quot;#常见术语&quot; class=&quot;headerlink&quot; title=&quot;常见术语&quot;&gt;&lt;/a&gt;常见术语&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;Brick：GlusterFS中最基本的存储单元，表示为受信存储池（trusted storage pool）中输出的目录，供客户端挂载用，可以通过主机名与目录名来标识，如’SERVER:EXPORT’；&lt;/li&gt;
&lt;li&gt;Volume：卷，逻辑上由N个brick组成；&lt;/li&gt;
&lt;li&gt;FUSE：Unix-like OS上的可动态加载的模块，允许用户不用修改内核即可创建自己的文件系统；&lt;/li&gt;
&lt;li&gt;Glusterd：Gluster management daemon，在trusted storage pool中所有的服务器上运行；&lt;/li&gt;
&lt;li&gt;Volfile：Glusterfs进程的配置文件，通常是位于/var/lib/glusterd/vols/目录下的{volname}文件；&lt;/li&gt;
&lt;li&gt;Self-heal：用于后台运行检测复本卷中文件与目录的不一致性并解决这些不一致；&lt;/li&gt;
&lt;li&gt;Split-brain：脑裂；&lt;/li&gt;
&lt;li&gt;GFID：GlusterFS卷中的每个文件或目录都有一个唯一的128位的数据相关联，用于模拟inode；&lt;/li&gt;
&lt;li&gt;Namespace：每个Gluster卷都导出单个ns作为POSIX的挂载点。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;数据访问流程&quot;&gt;&lt;a href=&quot;#数据访问流程&quot; class=&quot;headerlink&quot; title=&quot;数据访问流程&quot;&gt;&lt;/a&gt;数据访问流程&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/articles/e3bb873c/2.png&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在客户端,用户通过 glusterfs的mount point读写数据；&lt;/li&gt;
&lt;li&gt;用户的这个操作被递交给本地 Linux 系统的VFS 来处理；&lt;/li&gt;
&lt;li&gt;VFS 将数据递交给 FUSE 内核文件系统（在启动 glusterfs 客户端以前,需要向系统注册一个实际的文件系统 FUSE），该文件系统与 ext3 在同一个层次， ext3 是对实际的磁盘进行处理，而 fuse 文件系统则是将数据通过 /dev/fuse 这个设备文件递交给了glusterfs client 端，可以将 fuse 文件系统理解为一个代理；&lt;/li&gt;
&lt;li&gt;数据被 fuse 递交给 Glusterfs client 后， client 对数据进行一些指定的处理（即按 client 配置文件来进行的一系列处理）；&lt;/li&gt;
&lt;li&gt;在 glusterfs client 的处理末端,通过网络将数据递交给 Glusterfs Server, 并且将数据写入到服务器所控制的存储设备上。&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.netlify.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="GlusterFS" scheme="https://wandouduoduo.netlify.com/tags/GlusterFS/"/>
    
  </entry>
  
  <entry>
    <title>分布式存储的优劣对比</title>
    <link href="https://wandouduoduo.netlify.com/articles/455d7de6.html"/>
    <id>https://wandouduoduo.netlify.com/articles/455d7de6.html</id>
    <published>2019-11-04T04:20:43.000Z</published>
    <updated>2019-11-04T04:31:50.576Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文通过对比当前主流的几种分布式存储方案（Ceph,TFS,FastDFS,MogileFS,MooseFS,GlusterFS等），让你知道他们的优缺点，便于你根据使用场景选择合适的方案。</p><h2 id="系统整体对比"><a href="#系统整体对比" class="headerlink" title="系统整体对比"></a>系统整体对比</h2><table><thead><tr><th>对比说明/文件系统</th><th>TFS</th><th>FastDFS</th><th>MogileFS</th><th>MooseFS</th><th>GlusterFS</th><th>Ceph</th></tr></thead><tbody><tr><td>开发语言</td><td>C++</td><td>C</td><td>Perl</td><td>C</td><td>C</td><td>C++</td></tr><tr><td>开源协议</td><td>GPL V2</td><td>GPL V3</td><td>GPL</td><td>GPL V3</td><td>GPL V3</td><td>LGPL</td></tr><tr><td>数据存储方式</td><td>块</td><td>文件/Trunk</td><td>文件</td><td>块</td><td>文件/块</td><td>对象/文件/块</td></tr><tr><td>集群节点通信协议</td><td>私有协议（TCP）</td><td>私有协议（TCP）</td><td>HTTP</td><td>私有协议（TCP）</td><td>私有协议（TCP）/ RDAM(远程直接访问内存)</td><td>私有协议（TCP）</td></tr><tr><td>专用元数据存储点</td><td>占用NS</td><td>无</td><td>占用DB</td><td>占用MFS</td><td>无</td><td>占用MDS</td></tr><tr><td>在线扩容</td><td>支持</td><td>支持</td><td>支持</td><td>支持</td><td>支持</td><td>支持</td></tr><tr><td>冗余备份</td><td>支持</td><td>支持</td><td>-</td><td>支持</td><td>支持</td><td>支持</td></tr><tr><td>单点故障</td><td>存在</td><td>不存在</td><td>存在</td><td>存在</td><td>不存在</td><td>存在</td></tr><tr><td>跨集群同步</td><td>支持</td><td>部分支持</td><td>-</td><td>-</td><td>支持</td><td>不适用</td></tr><tr><td>易用性</td><td>安装复杂，官方文档少</td><td>安装简单，社区相对活跃</td><td>-</td><td>安装简单，官方文档多</td><td>安装简单，官方文档专业化</td><td>安装简单，官方文档专业化</td></tr><tr><td>适用场景</td><td>跨集群的小文件</td><td>单集群的中小文件</td><td>-</td><td>单集群的大中文件</td><td>跨集群云存储</td><td>单集群的大中小文件</td></tr></tbody></table><p>开源协议说明</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">GPL:不允许修改后和衍生的代码做为闭源的商业软件发布和销售，修改后该软件产品必须也采用GPL协议；</span><br><span class="line">GPL V2：修改文本的整体就必须按照GPL流通，不仅该修改文本的源码必须向社 会公开，而且对于这种修改文本的流通不准许附加修改者自己作出的限制;</span><br><span class="line">GPL V3：要求用户公布修改的源代码，还要求公布相关硬件;LGPL：更宽松的GPL</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="TFS"><a href="#TFS" class="headerlink" title="TFS"></a>TFS</h2><p>TFS（Taobao File System）是由淘宝开发的一个分布式文件系统，其内部经过特殊的优化处理，适用于海量的小文件存储，目前已经对外开源；</p><p>TFS采用自有的文件系统格式存储，因此需要专用的API接口去访问，目前官方提供的客户端版本有：C++/JAVA/PHP。</p><p><img src="/articles/455d7de6/1.png" alt="img"></p><ul><li>特性</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1）在TFS文件系统中，NameServer负责管理文件元数据，通过HA机制实现主备热切换，由于所有元数据都是在内存中，其处理效率非常高效，系统架构也非常简单，管理也很方便；</span><br><span class="line">2）TFS的DataServer作为分部署数据存储节点，同时也具备负载均衡和冗余备份的功能，由于采用自有的文件系统，对小文件会采取合并策略，减少数据碎片，从而提升IO性能；</span><br><span class="line">3）TFS将元数据信息（BlockID、FileID）直接映射至文件名中，这一设计大大降低了存储元数据的内存空间；</span><br></pre></td></tr></table></figure><ul><li>优点</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1）针对小文件量身定做，随机IO性能比较高；</span><br><span class="line">2）支持在线扩容机制，增强系统的可扩展性；</span><br><span class="line">3）实现了软RAID，增强系统的并发处理能力及数据容错恢复能力；</span><br><span class="line">4）支持主备热倒换，提升系统的可用性；</span><br><span class="line">5）支持主从集群部署，其中从集群主要提供读/备功能；</span><br></pre></td></tr></table></figure><ul><li>缺点</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1）TFS只对小文件做优化，不适合大文件的存储；</span><br><span class="line">2）不支持POSIX通用接口访问，通用性较低；</span><br><span class="line">3）不支持自定义目录结构，及文件权限控制；</span><br><span class="line">4）通过API下载，存在单点的性能瓶颈；</span><br><span class="line">5）官方文档非常少，学习成本高；</span><br></pre></td></tr></table></figure><ul><li>应用场景</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1）多集群部署的应用</span><br><span class="line">2）存储后基本不做改动</span><br><span class="line">3）海量小型文件</span><br><span class="line">根据目前官方提供的材料，对单个集群节点，存储节点在1000台以内可以良好工作，如存储节点扩大可能会出现NameServer的性能瓶颈，目前淘宝线上部署容量已达到1800TB规模（2009年数据）</span><br></pre></td></tr></table></figure><ul><li><p>安装及使用</p></li><li><p><a href="http://blog.csdn.net/junefsh/article/details/43987811" target="_blank" rel="noopener">安装指导</a></p></li><li><p><a href="http://blog.csdn.net/junefsh/article/details/43987829" target="_blank" rel="noopener">TFS_配置使用</a></p></li></ul><p> <strong>源代码路径</strong>：<a href="http://code.taobao.org/p/tfs/src/" target="_blank" rel="noopener">http://code.taobao.org/p/tfs/src/</a></p><p> <strong>参考</strong></p><p> <strong><a href="http://rdc.taobao.com/blog/cs/?p=128" target="_blank" rel="noopener">http://rdc.taobao.com/blog/cs/?p=128</a></strong></p><p> <strong><a href="http://elf8848.iteye.com/blog/1724423" target="_blank" rel="noopener">http://elf8848.iteye.com/blog/1724423</a></strong></p><p> <strong><a href="http://baike.baidu.com/view/1030880.htm" target="_blank" rel="noopener">http://baike.baidu.com/view/1030880.htm</a></strong></p><p> <strong><a href="http://blog.yunnotes.net/index.php/install_document_for_tfs/" target="_blank" rel="noopener">http://blog.yunnotes.net/index.php/install_document_for_tfs/</a></strong></p><h2 id="FastDFS"><a href="#FastDFS" class="headerlink" title="FastDFS"></a><strong>FastDFS</strong></h2><p><img src="/articles/455d7de6/2.png" alt="img"></p><p>FastDFS是国人开发的一款分布式文件系统，目前社区比较活跃。如上图所示系统中存在三种节点：Client、Tracker、Storage，在底层存储上通过逻辑的分组概念，使得通过在同组内配置多个Storage，从而实现软RAID10,提升并发IO的性能、简单负载均衡及数据的冗余备份；同时通过线性的添加新的逻辑存储组，从容实现存储容量的线性扩容。</p><p>文件下载上，除了支持通过API方式，目前还提供了apache和nginx的插件支持，同时也可以不使用对应的插件，直接以Web静态资源方式对外提供下载。</p><p>目前FastDFS(V4.x)代码量大概6w多行，内部的网络模型使用比较成熟的libevent三方库，具备高并发的处理能力。</p><ul><li><strong>特性</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1）在上述介绍中Tracker服务器是整个系统的核心枢纽，其完成了访问调度（负载均衡），监控管理Storage服务器，由此可见Tracker的作用至关重要，也就增加了系统的单点故障，为此FastDFS支持多个备用的Tracker，虽然实际测试发现备用Tracker运行不是非常完美，但还是能保证系统可用。</span><br><span class="line">2）在文件同步上，只有同组的Storage才做同步，由文件所在的源Storage服务器push至其它Storage服务器，目前同步是采用Binlog方式实现，由于目前底层对同步后的文件不做正确性校验，因此这种同步方式仅适用单个集群点的局部内部网络，如果在公网上使用，肯定会出现损坏文件的情况，需要自行添加文件校验机制。</span><br><span class="line">3）支持主从文件，非常适合存在关联关系的图片，在存储方式上，FastDFS在主从文件ID上做取巧，完成了关联关系的存储。</span><br></pre></td></tr></table></figure><ul><li><strong>优点</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1）系统无需支持POSIX(可移植操作系统)，降低了系统的复杂度，处理效率更高</span><br><span class="line">2）支持在线扩容机制，增强系统的可扩展性</span><br><span class="line">3）实现了软RAID，增强系统的并发处理能力及数据容错恢复能力</span><br><span class="line">4）支持主从文件，支持自定义扩展名</span><br><span class="line">5）主备Tracker服务，增强系统的可用性</span><br></pre></td></tr></table></figure><ul><li><strong>缺点</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1）不支持断点续传，对大文件将是噩梦（FastDFS不适合大文件存储）</span><br><span class="line">2）不支持POSIX通用接口访问，通用性较低</span><br><span class="line">3）对跨公网的文件同步，存在较大延迟，需要应用做相应的容错策略</span><br><span class="line">4）同步机制不支持文件正确性校验，降低了系统的可用性</span><br><span class="line">5）通过API下载，存在单点的性能瓶颈</span><br></pre></td></tr></table></figure><ul><li><strong>应用场景</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1）单集群部署的应用</span><br><span class="line">2）存储后基本不做改动</span><br><span class="line">3）小中型文件根据</span><br><span class="line">目前官方提供的材料，现有的使用FastDFS系统存储容量已经达到900T，物理机器已经达到100台（50个组）</span><br></pre></td></tr></table></figure><p> <a href="http://blog.csdn.net/junefsh/article/details/43987863" target="_blank" rel="noopener">安装指导_FastDFS</a></p><p> <strong>源码路径：</strong><a href="https://github.com/happyfish100/fastdfs" target="_blank" rel="noopener">https://github.com/happyfish100/fastdfs</a></p><ul><li><p><strong>参考</strong></p><p><a href="https://code.google.com/p/fastdfs/" target="_blank" rel="noopener">https://code.google.com/p/fastdfs/</a> </p><p><a href="http://bbs.chinaunix.net/forum-240-1.html" target="_blank" rel="noopener">http://bbs.chinaunix.net/forum-240-1.html</a></p><p><a href="http://portal.ucweb.local/docz/spec/platform/datastore/fastdfs" target="_blank" rel="noopener">http://portal.ucweb.local/docz/spec/platform/datastore/fastdfs</a></p></li></ul><h2 id="MooseFS"><a href="#MooseFS" class="headerlink" title="MooseFS"></a><strong>MooseFS</strong></h2><p>MooseFS是一个高可用的故障容错分布式文件系统，它支持通过FUSE方式将文件挂载操作，同时其提供的web管理界面非常方便查看当前的文件存储状态。</p><ul><li><strong>特性</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1）从下图中我们可以看到MooseFS文件系统由四部分组成：Managing Server 、Data Server 、Metadata Backup Server 及Client</span><br><span class="line">2）其中所有的元数据都是由Managing Server管理，为了提高整个系统的可用性，Metadata Backup Server记录文件元数据操作日志，用于数据的及时恢复</span><br><span class="line">3）Data Server可以分布式部署，存储的数据是以块的方式分布至各存储节点的，因此提升了系统的整体性能，同时Data Server提供了冗余备份的能力，提升系统的可靠性</span><br><span class="line">4）Client通过FUSE方式挂载，提供了类似POSIX的访问方式，从而降低了Client端的开发难度，增强系统的通用性</span><br></pre></td></tr></table></figure><p><img src="/articles/455d7de6/3.png" alt="img"></p><ul><li>元数据服务器（master）:负责各个数据存储服务器的管理，文件读写调度，文件空间回收以及恢复</li><li>元数据日志服务器（metalogger）:负责备份master服务器的变化日志文件，以便于在master server出问题的时候接替其进行工作</li><li>数据存储服务器（chunkserver）:数据实际存储的地方，由多个物理服务器组成，负责连接管理服务器，听从管理服务器调度，提供存储空间，并为客户提供数据传输；多节点拷贝;在数据存储目录，看不见实际的数据</li></ul><p><img src="/articles/455d7de6/4.png" alt="img"></p><ul><li><strong>优点</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1）部署安装非常简单，管理方便</span><br><span class="line">2）支持在线扩容机制，增强系统的可扩展性</span><br><span class="line">3）实现了软RAID，增强系统的 并发处理能力及数据容错恢复能力</span><br><span class="line">4）数据恢复比较容易，增强系统的可用性5）有回收站功能，方便业务定制</span><br></pre></td></tr></table></figure><ul><li><strong>缺点</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1）存在单点性能瓶颈及单点故障</span><br><span class="line">2）MFS Master节点很消耗内存</span><br><span class="line">3）对于小于64KB的文件，存储利用率较低</span><br></pre></td></tr></table></figure><ul><li><strong>应用场景</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1）单集群部署的应用</span><br><span class="line">2）中、大型文件</span><br></pre></td></tr></table></figure><ul><li><p>参考</p><p><a href="http://portal.ucweb.local/docz/spec/platform/datastore/moosefsh" target="_blank" rel="noopener">http://portal.ucweb.local/docz/spec/platform/datastore/moosefsh</a> </p><p><a href="http://www.moosefs.org/" target="_blank" rel="noopener">http://www.moosefs.org/</a> </p><p><a href="http://sourceforge.net/projects/moosefs/?source=directory" target="_blank" rel="noopener">http://sourceforge.net/projects/moosefs/?source=directory</a></p></li></ul><h2 id="GlusterFS"><a href="#GlusterFS" class="headerlink" title="GlusterFS"></a><strong>GlusterFS</strong></h2><p>GlusterFS是Red Hat旗下的一款开源分布式文件系统，它具备高扩展、高可用及高性能等特性，由于其无元数据服务器的设计，使其真正实现了线性的扩展能力，使存储总容量可 轻松达到PB级别，支持数千客户端并发访问；对跨集群，其强大的Geo-Replication可以实现集群间数据镜像，而且是支持链式复制，这非常适用 于垮集群的应用场景</p><ul><li><strong>特性</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1）目前GlusterFS支持FUSE方式挂载，可以通过标准的NFS/SMB/CIFS协议像访问本体文件一样访问文件系统，同时其也支持HTTP/FTP/GlusterFS访问，同时最新版本支持接入Amazon的AWS系统</span><br><span class="line">2）GlusterFS系统通过基于SSH的命令行管理界面，可以远程添加、删除存储节点，也可以监控当前存储节点的使用状态</span><br><span class="line">3）GlusterFS支持集群节点中存储虚拟卷的扩容动态扩容；同时在分布式冗余模式下，具备自愈管理功能，在Geo冗余模式下，文件支持断点续传、异步传输及增量传送等特点</span><br></pre></td></tr></table></figure><p><img src="/articles/455d7de6/5.jpg" alt></p><ul><li><strong>优点</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">1）系统支持POSIX(可移植操作系统)，支持FUSE挂载通过多种协议访问，通用性比较高</span><br><span class="line">2）支持在线扩容机制，增强系统的可扩展性</span><br><span class="line">3）实现了软RAID，增强系统的 并发处理能力及数据容错恢复能力</span><br><span class="line">4）强大的命令行管理，降低学习、部署成本</span><br><span class="line">5）支持整个集群镜像拷贝，方便根据业务压力，增加集群节点</span><br><span class="line">6）官方资料文档专业化，该文件系统由Red Hat企业级做维护，版本质量有保障</span><br></pre></td></tr></table></figure><ul><li><strong>缺点</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1）通用性越强，其跨越的层次就越多，影响其IO处理效率</span><br><span class="line">2）频繁读写下，会产生垃圾文件，占用磁盘空间</span><br></pre></td></tr></table></figure><ul><li><strong>应用场景</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1）多集群部署的应用</span><br><span class="line">2）中大型文件根据目前官方提供的材料，现有的使用GlusterFS系统存储容量可轻松达到PB</span><br></pre></td></tr></table></figure><ul><li><strong>术语：</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">brick：分配到卷上的文件系统块；</span><br><span class="line">client：挂载卷，并对外提供服务；</span><br><span class="line">server：实际文件存储的地方；</span><br><span class="line">subvolume：被转换过的文件系统块；</span><br><span class="line">volume：最终转换后的文件系统卷。</span><br></pre></td></tr></table></figure><ul><li><p><strong>参考</strong></p><p><a href="http://www.gluster.org/" target="_blank" rel="noopener">http://www.gluster.org/</a></p><p><a href="http://www.gluster.org/wp-content/uploads/2012/05/Gluster_File_System-3.3.0-Administration_Guide-en-US.pdf" target="_blank" rel="noopener">http://www.gluster.org/wp-content/uploads/2012/05/Gluster_File_System-3.3.0-Administration_Guide-en-US.pdf</a></p><p><a href="http://blog.csdn.net/liuben/article/details/6284551" target="_blank" rel="noopener">http://blog.csdn.net/liuben/article/details/6284551</a></p></li></ul><h2 id="Ceph"><a href="#Ceph" class="headerlink" title="Ceph"></a><strong>Ceph</strong></h2><p>Ceph是一个可以按对象/块/文件方式存储的开源分布式文件系统，其设计之初，就将单点故障作为首先要解决的问题，因此该系统具备高可用性、高性能及可 扩展等特点。该文件系统支持目前还处于试验阶段的高性能文件系统BTRFS(B-Tree文件系统)，同时支持按OSD方式存储，因此其性能是很卓越的， 因为该系统处于试商用阶段，需谨慎引入到生产环境</p><ul><li><strong>特性</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1）Ceph底层存储是基于RADOS（可靠的、自动的分布式对象存储），它提供了LIBRADOS/RADOSGW/RBD/CEPH FS方式访问底层的存储系统，如下图所示</span><br><span class="line">2）通过FUSE，Ceph支持类似的POSIX访问方式；Ceph分布式系统中最关键的MDS节点是可以部署多台，无单点故障的问题，且处理性能大大提升</span><br><span class="line">3）Ceph通过使用CRUSH算法动态完成文件inode number到object number的转换，从而避免再存储文件metadata信息，增强系统的灵活性</span><br></pre></td></tr></table></figure><ul><li><strong>优点</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1）支持对象存储（OSD）集群，通过CRUSH算法，完成文件动态定位， 处理效率更高</span><br><span class="line">2）支持通过FUSE方式挂载，降低客户端的开发成本，通用性高</span><br><span class="line">3）支持分布式的MDS/MON，无单点故障</span><br><span class="line">4）强大的容错处理和自愈能力5）支持在线扩容和冗余备份，增强系统的可靠性</span><br></pre></td></tr></table></figure><ul><li><strong>缺点</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1）目前处于试验阶段，系统稳定性有待考究</span><br></pre></td></tr></table></figure><ul><li><strong>应用场景</strong></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1）全网分布式部署的应用</span><br><span class="line">2）对实时性、可靠性要求比较高官方宣传，存储容量可轻松达到PB级别</span><br></pre></td></tr></table></figure><p> <strong>源码路径：</strong><a href="https://github.com/ceph/ceph" target="_blank" rel="noopener">https://github.com/ceph/ceph</a></p><ul><li><p><strong>参考</strong></p><p><a href="http://ceph.com/" target="_blank" rel="noopener">http://ceph.com/</a></p></li></ul><h2 id="MogileFS"><a href="#MogileFS" class="headerlink" title="MogileFS"></a><strong>MogileFS</strong></h2><ul><li><p>开发语言：perl</p></li><li><p>开源协议：GPL</p></li><li><p>依赖数据库</p></li><li><p>Trackers(控制中心):负责读写数据库，作为代理复制storage间同步的数据</p></li><li><p>Database:存储源数据（默认mysql）</p></li><li><p>Storage:文件存储</p></li><li><p>除了API，可以通过与nginx集成，对外提供下载服务</p></li></ul><p> <strong>源码路径：</strong><a href="https://github.com/mogilefs" target="_blank" rel="noopener">https://github.com/mogilefs</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;本文通过对比当前主流的几种分布式存储方案（Ceph,TFS,FastDFS,MogileFS,MooseFS,GlusterFS等），让你知道他们的优缺点，便于你根据使用场景选择合适的方案。&lt;/p&gt;
&lt;h2 id=&quot;系统整体对比&quot;&gt;&lt;a href=&quot;#系统整体对比&quot; class=&quot;headerlink&quot; title=&quot;系统整体对比&quot;&gt;&lt;/a&gt;系统整体对比&lt;/h2&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;对比说明/文件系统&lt;/th&gt;
&lt;th&gt;TFS&lt;/th&gt;
&lt;th&gt;FastDFS&lt;/th&gt;
&lt;th&gt;MogileFS&lt;/th&gt;
&lt;th&gt;MooseFS&lt;/th&gt;
&lt;th&gt;GlusterFS&lt;/th&gt;
&lt;th&gt;Ceph&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;&lt;tr&gt;
&lt;td&gt;开发语言&lt;/td&gt;
&lt;td&gt;C++&lt;/td&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;Perl&lt;/td&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;C++&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;开源协议&lt;/td&gt;
&lt;td&gt;GPL V2&lt;/td&gt;
&lt;td&gt;GPL V3&lt;/td&gt;
&lt;td&gt;GPL&lt;/td&gt;
&lt;td&gt;GPL V3&lt;/td&gt;
&lt;td&gt;GPL V3&lt;/td&gt;
&lt;td&gt;LGPL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;数据存储方式&lt;/td&gt;
&lt;td&gt;块&lt;/td&gt;
&lt;td&gt;文件/Trunk&lt;/td&gt;
&lt;td&gt;文件&lt;/td&gt;
&lt;td&gt;块&lt;/td&gt;
&lt;td&gt;文件/块&lt;/td&gt;
&lt;td&gt;对象/文件/块&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;集群节点通信协议&lt;/td&gt;
&lt;td&gt;私有协议（TCP）&lt;/td&gt;
&lt;td&gt;私有协议（TCP）&lt;/td&gt;
&lt;td&gt;HTTP&lt;/td&gt;
&lt;td&gt;私有协议（TCP）&lt;/td&gt;
&lt;td&gt;私有协议（TCP）/ RDAM(远程直接访问内存)&lt;/td&gt;
&lt;td&gt;私有协议（TCP）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;专用元数据存储点&lt;/td&gt;
&lt;td&gt;占用NS&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;占用DB&lt;/td&gt;
&lt;td&gt;占用MFS&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;td&gt;占用MDS&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;在线扩容&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;冗余备份&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;单点故障&lt;/td&gt;
&lt;td&gt;存在&lt;/td&gt;
&lt;td&gt;不存在&lt;/td&gt;
&lt;td&gt;存在&lt;/td&gt;
&lt;td&gt;存在&lt;/td&gt;
&lt;td&gt;不存在&lt;/td&gt;
&lt;td&gt;存在&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;跨集群同步&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;部分支持&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;支持&lt;/td&gt;
&lt;td&gt;不适用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;易用性&lt;/td&gt;
&lt;td&gt;安装复杂，官方文档少&lt;/td&gt;
&lt;td&gt;安装简单，社区相对活跃&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;安装简单，官方文档多&lt;/td&gt;
&lt;td&gt;安装简单，官方文档专业化&lt;/td&gt;
&lt;td&gt;安装简单，官方文档专业化&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;适用场景&lt;/td&gt;
&lt;td&gt;跨集群的小文件&lt;/td&gt;
&lt;td&gt;单集群的中小文件&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;单集群的大中文件&lt;/td&gt;
&lt;td&gt;跨集群云存储&lt;/td&gt;
&lt;td&gt;单集群的大中小文件&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;开源协议说明&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;GPL:不允许修改后和衍生的代码做为闭源的商业软件发布和销售，修改后该软件产品必须也采用GPL协议；&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;GPL V2：修改文本的整体就必须按照GPL流通，不仅该修改文本的源码必须向社 会公开，而且对于这种修改文本的流通不准许附加修改者自己作出的限制;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;GPL V3：要求用户公布修改的源代码，还要求公布相关硬件;LGPL：更宽松的GPL&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="数据库" scheme="https://wandouduoduo.netlify.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="Linux" scheme="https://wandouduoduo.netlify.com/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>基于Keepalived+Haproxy搭建四层负载均衡器</title>
    <link href="https://wandouduoduo.netlify.com/articles/95471f15.html"/>
    <id>https://wandouduoduo.netlify.com/articles/95471f15.html</id>
    <published>2019-11-02T13:42:25.000Z</published>
    <updated>2019-11-04T01:49:45.715Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​        Haproxy是稳定、高性能、高可用性的负载均衡解决方案，支持HTTP及TCP代理后端服务器池，因支持强大灵活的7层acl规则，广泛作为HTTP反向代理。本文则详细介绍如何利用它的四层交换与Keepalived实现一个负载均衡器，适用于Socket、ICE、Mail、Mysql、私有通讯等任意TCP服务。系统架构图如下：</p><p><img src="/articles/95471f15/0.027865917857136546.png" alt="点击在新窗口中浏览此图片"></p><a id="more"></a><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>OS:    Centos6.x(64X)<br>MASTER:   192.168.0.20<br>BACKUP:   192.168.0.21<br>VIP:  192.168.0.100<br>Serivce Port: 11231</p><h2 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h2><h4 id="添加非本机IP邦定支持"><a href="#添加非本机IP邦定支持" class="headerlink" title="添加非本机IP邦定支持"></a><strong>添加非本机IP邦定支持</strong></h4><p>#vim  /etc/sysctl.conf</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">net.ipv4.ip_nonlocal_bind=1</span><br><span class="line"></span><br><span class="line"><span class="comment">#sysctl –p</span></span><br></pre></td></tr></table></figure><h4 id="配置平台日志支持"><a href="#配置平台日志支持" class="headerlink" title="配置平台日志支持"></a>配置平台日志支持</h4><p>#vim  /etc/syslog.conf  添加</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">local3.*        /var/log/haproxy.log</span><br><span class="line">local0.*        /var/log/haproxy.log</span><br></pre></td></tr></table></figure><p>#vim /etc/sysconfig/syslog</p><p>修改：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SYSLOGD_OPTIONS=&quot;-r -m 0&quot;</span><br></pre></td></tr></table></figure><p>#/etc/init.d/syslog restart</p><h4 id="关闭SELINUX"><a href="#关闭SELINUX" class="headerlink" title="关闭SELINUX"></a>关闭SELINUX</h4><p>vim /etc/sysconfig/selinux<br>修改</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELINUX=disabled</span><br></pre></td></tr></table></figure><p>#setenforce 0</p><h4 id="配置iptables"><a href="#配置iptables" class="headerlink" title="配置iptables"></a>配置iptables</h4><p>添加VRRP通讯支持</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -A INPUT -d 224.0.0.18 -j ACCEPT</span><br></pre></td></tr></table></figure><h4 id="Keepalived的安装、配置"><a href="#Keepalived的安装、配置" class="headerlink" title="Keepalived的安装、配置"></a>Keepalived的安装、配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#mkdir -p /home/install/keepalivedha</span></span><br><span class="line"><span class="comment">#cd /home/install/keepalivedha</span></span><br><span class="line"><span class="comment">#wget http://www.keepalived.org/software/keepalived-1.2.2.tar.gz</span></span><br><span class="line"><span class="comment">#tar zxvf keepalived-1.2.2.tar.gz</span></span><br><span class="line"><span class="comment">#cd keepalived-1.2.2</span></span><br><span class="line"><span class="comment">#./configure</span></span><br><span class="line"><span class="comment">#make &amp;&amp; make install</span></span><br><span class="line"><span class="comment">#cp /usr/local/etc/rc.d/init.d/keepalived /etc/rc.d/init.d/</span></span><br><span class="line"><span class="comment">#cp /usr/local/etc/sysconfig/keepalived /etc/sysconfig/</span></span><br><span class="line"><span class="comment">#mkdir /etc/keepalived</span></span><br><span class="line"><span class="comment">#cp /usr/local/etc/keepalived/keepalived.conf /etc/keepalived/</span></span><br><span class="line"><span class="comment">#cp /usr/local/sbin/keepalived /usr/sbin/</span></span><br></pre></td></tr></table></figure><p>#vim  /etc/keepalived/keepalived.conf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">! Configuration File for keepalived </span><br><span class="line"></span><br><span class="line">global_defs &#123;  </span><br><span class="line">   notification_email &#123;  </span><br><span class="line">         liutiansi@gmail.com  </span><br><span class="line">   &#125;  </span><br><span class="line">   notification_email_from liutiansi@gmail.com  </span><br><span class="line">   smtp_connect_timeout 3  </span><br><span class="line">   smtp_server 127.0.0.1  </span><br><span class="line">   router_id LVS_DEVEL  </span><br><span class="line">&#125;  </span><br><span class="line">vrrp_script chk_haproxy &#123;  </span><br><span class="line">    script &quot;killall -0 haproxy&quot;  </span><br><span class="line">    interval 2  </span><br><span class="line">    weight 2  </span><br><span class="line">&#125;  </span><br><span class="line">vrrp_instance VI_1 &#123;  </span><br><span class="line">    interface eth1  </span><br><span class="line">    state MASTER # 从为BACKUP  </span><br><span class="line">    priority 101 # 从为100  </span><br><span class="line">    virtual_router_id 50 #路由ID，可通过#tcpdump vrrp查看。  </span><br><span class="line">    garp_master_delay 1 #主从切换时间，单位为秒。  </span><br><span class="line">  </span><br><span class="line">    authentication &#123;  </span><br><span class="line">        auth_type PASS  </span><br><span class="line">        auth_pass KJj23576hYgu23IP  </span><br><span class="line">    &#125;  </span><br><span class="line">    track_interface &#123;  </span><br><span class="line">       eth0  </span><br><span class="line">       eth1  </span><br><span class="line">    &#125;  </span><br><span class="line">    virtual_ipaddress &#123;  </span><br><span class="line">        192.168.0.100  </span><br><span class="line">    &#125;  </span><br><span class="line">    track_script &#123;  </span><br><span class="line">        chk_haproxy  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    #状态通知  </span><br><span class="line">    notify_master &quot;/etc/keepalived/Mailnotify.py master&quot;  </span><br><span class="line">    notify_backup &quot;/etc/keepalived/Mailnotify.py backup&quot;  </span><br><span class="line">    notify_fault &quot;/etc/keepalived/Mailnotify.py fault&quot;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="Haproxy的安装与配置"><a href="#Haproxy的安装与配置" class="headerlink" title="Haproxy的安装与配置"></a>Haproxy的安装与配置</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#cd /home/install/keepalivedha</span><br><span class="line">#wget http://haproxy.1wt.eu/download/1.4/src/haproxy-1.4.11.tar.gz</span><br><span class="line">#tar -zxvf haproxy-1.4.11.tar.gz</span><br><span class="line">#cd haproxy-1.4.11</span><br><span class="line">#make install</span><br><span class="line">#mkdir -p /usr/local/haproxy/etc</span><br><span class="line">#mkdir -p /usr/local/haproxy/sbin</span><br><span class="line">#cp examples/haproxy.cfg /usr/local/haproxy/etc</span><br><span class="line">#ln -s /usr/local/sbin/haproxy /usr/local/haproxy/sbin/haproxy</span><br></pre></td></tr></table></figure><p>#vim  /usr/local/haproxy/etc/haproxy.cfg</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"># this config needs haproxy-1.1.28 or haproxy-1.2.1</span><br><span class="line">global  </span><br><span class="line">#        log 127.0.0.1   local0  </span><br><span class="line">        log 127.0.0.1   local1 notice  </span><br><span class="line">        maxconn 5000  </span><br><span class="line">        uid 99  </span><br><span class="line">        gid 99  </span><br><span class="line">        daemon  </span><br><span class="line">        pidfile /usr/local/haproxy/haproxy.pid  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">defaults  </span><br><span class="line">        log     global  </span><br><span class="line">        mode    http  </span><br><span class="line">        #option httplog  </span><br><span class="line">        option  dontlognull  </span><br><span class="line">        retries 3  </span><br><span class="line">        option redispatch  </span><br><span class="line">        maxconn 2000  </span><br><span class="line">        contimeout      5000  </span><br><span class="line">        clitimeout      50000  </span><br><span class="line">        srvtimeout      50000  </span><br><span class="line">  </span><br><span class="line">listen  ICE01   192.168.0.100:11231  </span><br><span class="line">        mode tcp #配置TCP模式  </span><br><span class="line">        maxconn 2000  </span><br><span class="line">        balance roundrobin  </span><br><span class="line">        server  ice-192.168.0.128 192.168.0.128:11231 check inter 5000 fall 1 rise 2  </span><br><span class="line">        server  ice-192.168.0.129 192.168.0.129:11231 check inter 5000 fall 1 rise 2  </span><br><span class="line">        server  ice-192.168.0.130 192.168.0.130:11231 check inter 5000 fall 1 rise 2  </span><br><span class="line">        server  ice-192.168.0.131 192.168.0.131:11231 check inter 5000 fall 1 rise 2  </span><br><span class="line">        server  ice-192.168.0.132 192.168.0.132:11231 check inter 5000 fall 1 rise 2  </span><br><span class="line">        server  ice-192.168.0.34 192.168.0.34:11231 check inter 5000 fall 1 rise 2  </span><br><span class="line">        srvtimeout      20000  </span><br><span class="line">  </span><br><span class="line">listen stats_auth 192.168.0.20:80  </span><br><span class="line"># listen stats_auth 192.168.0.21:80 # backup config  </span><br><span class="line">        stats enable  </span><br><span class="line">        stats uri  /admin-status #管理地址  </span><br><span class="line">        stats auth  admin:123456 #管理帐号:管理密码  </span><br><span class="line">        stats admin if TRUE</span><br></pre></td></tr></table></figure><h4 id="邮件通知程序-python实现"><a href="#邮件通知程序-python实现" class="headerlink" title="邮件通知程序(python实现)"></a>邮件通知程序(python实现)</h4><p>#vim  /etc/keepalived/Mailnotify.py</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/local/bin/python  </span></span><br><span class="line"><span class="comment">#coding: utf-8  </span></span><br><span class="line"><span class="keyword">from</span> email.MIMEMultipart <span class="keyword">import</span> MIMEMultipart  </span><br><span class="line"><span class="keyword">from</span> email.MIMEText <span class="keyword">import</span> MIMEText  </span><br><span class="line"><span class="keyword">from</span> email.MIMEImage <span class="keyword">import</span> MIMEImage  </span><br><span class="line"><span class="keyword">from</span> email.header <span class="keyword">import</span> Header  </span><br><span class="line"><span class="keyword">import</span> sys  </span><br><span class="line"><span class="keyword">import</span> smtplib  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#---------------------------------------------------------------  </span></span><br><span class="line"><span class="comment"># Name:        Mailnotify.py  </span></span><br><span class="line"><span class="comment"># Purpose:     Mail notify to SA  </span></span><br><span class="line"><span class="comment"># Author:      Liutiansi  </span></span><br><span class="line"><span class="comment"># Email:       liutiansi@gamil.com  </span></span><br><span class="line"><span class="comment"># Created:     2011/03/09  </span></span><br><span class="line"><span class="comment"># Copyright:   (c) 2011  </span></span><br><span class="line"><span class="comment">#--------------------------------------------------------------  </span></span><br><span class="line">strFrom = <span class="string">'admin@domain.com'</span>  </span><br><span class="line">strTo = <span class="string">'liutiansi@gmail.com'</span>  </span><br><span class="line">smtp_server=<span class="string">'smtp.domain.com'</span>  </span><br><span class="line">smtp_pass=<span class="string">'123456'</span>  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> sys.argv[<span class="number">1</span>]!=<span class="string">"master"</span> <span class="keyword">and</span> sys.argv[<span class="number">1</span>]!=<span class="string">"backup"</span>  <span class="keyword">and</span> sys.argv[<span class="number">1</span>]!=<span class="string">"fault"</span>:  </span><br><span class="line">    sys.exit()  </span><br><span class="line"><span class="keyword">else</span>:  </span><br><span class="line">    notify_type=sys.argv[<span class="number">1</span>]  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">mail_title=<span class="string">'[紧急]负载均衡器邮件通知'</span>  </span><br><span class="line">mail_body_plain=notify_type+<span class="string">'被激活，请做好应急处理。'</span>  </span><br><span class="line">mail_body_html=<span class="string">'&lt;b&gt;&lt;font color=red&gt;'</span>+notify_type+<span class="string">'被激活，请做好应急处理。&lt;/font&gt;&lt;/b&gt;'</span>  </span><br><span class="line">  </span><br><span class="line">msgRoot = MIMEMultipart(<span class="string">'related'</span>)  </span><br><span class="line">msgRoot[<span class="string">'Subject'</span>] =Header(mail_title,<span class="string">'utf-8'</span>)  </span><br><span class="line">msgRoot[<span class="string">'From'</span>] = strFrom  </span><br><span class="line">msgRoot[<span class="string">'To'</span>] = strTo  </span><br><span class="line">  </span><br><span class="line">msgAlternative = MIMEMultipart(<span class="string">'alternative'</span>)  </span><br><span class="line">msgRoot.attach(msgAlternative)  </span><br><span class="line">  </span><br><span class="line">msgText = MIMEText(mail_body_plain, <span class="string">'plain'</span>, <span class="string">'utf-8'</span>)  </span><br><span class="line">msgAlternative.attach(msgText)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">msgText = MIMEText(mail_body_html, <span class="string">'html'</span>,<span class="string">'utf-8'</span>)  </span><br><span class="line">msgAlternative.attach(msgText)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">smtp = smtplib.SMTP()  </span><br><span class="line">smtp.connect(smtp_server)  </span><br><span class="line">smtp.login(smtp_user,smtp_pass)  </span><br><span class="line">smtp.sendmail(strFrom, strTo, msgRoot.as_string())  </span><br><span class="line">smtp.quit()</span><br></pre></td></tr></table></figure><p>注：修改成系统python实际路径“#!/usr/local/bin/python”(第一行)</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">#chmod +x /etc/keepalived/Mailnotify.py</span><br><span class="line">#/usr/local/haproxy/sbin/haproxy -f /usr/local/haproxy/etc/haproxy.cfg</span><br><span class="line">#service keepalived start</span><br></pre></td></tr></table></figure><h4 id="查看VRRP通讯记录"><a href="#查看VRRP通讯记录" class="headerlink" title="查看VRRP通讯记录"></a>查看VRRP通讯记录</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#tcpdump vrrp</span><br><span class="line"></span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span><br><span class="line">listening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes</span><br><span class="line">15:49:05.270017  IP 192.168.0.20 &gt; VRRP.MCAST.NET: VRRPv2, Advertisement, vrid 50,  prio 100, authtype simple, intvl 1s, length 20</span><br></pre></td></tr></table></figure><h2 id="Haproxy界面"><a href="#Haproxy界面" class="headerlink" title="Haproxy界面"></a>Haproxy界面</h2><p>访问<a href="http://192.168.0.20/admin-status，输入帐号admin密码123456进入管理监控平台。" target="_blank" rel="noopener">http://192.168.0.20/admin-status，输入帐号admin密码123456进入管理监控平台。</a></p><p><img src="/articles/95471f15/0.39497361121703545.png" alt="点击在新窗口中浏览此图片"></p><p>haproxy-1.4.9以后版本最大的亮点是添加了手工启用/禁用功能，对升级变更应用时非常有用。</p><h2 id="邮件通知"><a href="#邮件通知" class="headerlink" title="邮件通知"></a>邮件通知</h2><p><img src="/articles/95471f15/0.6085717838496976.png" alt="点击在新窗口中浏览此图片"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;​        Haproxy是稳定、高性能、高可用性的负载均衡解决方案，支持HTTP及TCP代理后端服务器池，因支持强大灵活的7层acl规则，广泛作为HTTP反向代理。本文则详细介绍如何利用它的四层交换与Keepalived实现一个负载均衡器，适用于Socket、ICE、Mail、Mysql、私有通讯等任意TCP服务。系统架构图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/95471f15/0.027865917857136546.png&quot; alt=&quot;点击在新窗口中浏览此图片&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Haproxy" scheme="https://wandouduoduo.netlify.com/tags/Haproxy/"/>
    
      <category term="Keepalived" scheme="https://wandouduoduo.netlify.com/tags/Keepalived/"/>
    
  </entry>
  
  <entry>
    <title>centos7安装redis教程</title>
    <link href="https://wandouduoduo.netlify.com/articles/39f481b5.html"/>
    <id>https://wandouduoduo.netlify.com/articles/39f481b5.html</id>
    <published>2019-11-02T02:54:48.000Z</published>
    <updated>2019-11-04T01:49:45.698Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a><strong>安装</strong></h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#通过wget方式直接在linux上下载Redis</span></span><br><span class="line">wget http://download.redis.io/releases/redis-4.0.9.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment">#解压下载的redis-2.6.17.tar.gz 文件</span></span><br><span class="line">tar xzf redis-4.0.9.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment">#进入解压后的文件夹</span></span><br><span class="line"><span class="built_in">cd</span>  redis-4.0.9</span><br><span class="line"></span><br><span class="line"><span class="comment">#编译安装</span></span><br><span class="line">make</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><ul><li><p>通过执行src文件夹下的redis-server，可以启动redis服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./src/redis-server</span><br></pre></td></tr></table></figure></li><li><p>通过执行src文件夹下的redis-cli， 可以访问redis服务。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">./src/redis-cli</span><br><span class="line">redis&gt; <span class="built_in">set</span> foo bar</span><br><span class="line">Ok</span><br><span class="line">redis&gt; get foo</span><br><span class="line"><span class="string">"bar"</span></span><br></pre></td></tr></table></figure></li></ul><h2 id="排错"><a href="#排错" class="headerlink" title="排错"></a><strong>排错</strong></h2><p>CentOS5.7默认没有安装gcc，这会导致我们无法make成功。使用yum安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install gcc</span><br></pre></td></tr></table></figure><p>make时报如下错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">zmalloc.h:50:31: error: jemalloc/jemalloc.h: No such file or directory</span><br><span class="line">zmalloc.h:55:2: error: #error &quot;Newer version of jemalloc required&quot;</span><br><span class="line">make[1]: *** [adlist.o] Error 1</span><br><span class="line">make[1]: Leaving directory `/data0/src/redis-2.6.2/src&apos;</span><br><span class="line">make: *** [all] Error 2</span><br></pre></td></tr></table></figure><p>原因是jemalloc重载了Linux下的ANSI C的malloc和free函数。解决办法：make时添加参数。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make MALLOC=libc</span><br></pre></td></tr></table></figure><p>make之后，会出现一句提示</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Hint: To run <span class="string">'make test'</span> is a good idea ;)</span><br></pre></td></tr></table></figure><p>但是不测试，通常是可以使用的。若我们运行make test ，会有如下提示</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[devnote@devnote src]$ make <span class="built_in">test</span></span><br><span class="line">You need tcl 8.5 or newer <span class="keyword">in</span> order to run the Redis <span class="built_in">test</span></span><br><span class="line">make: ***[<span class="built_in">test</span>] Error_1</span><br></pre></td></tr></table></figure><p>解决办法是用yum安装tcl8.5（或去tcl的官方网站<a href="http://www.tcl.tk/下载8.5版本，并参考官网介绍进行安装）" target="_blank" rel="noopener">http://www.tcl.tk/下载8.5版本，并参考官网介绍进行安装）</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install tcl</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;&lt;strong&gt;安装&lt;/strong&gt;&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#通过wget方式直接在linux上下载Redis&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;wget http://download.redis.io/releases/redis-4.0.9.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#解压下载的redis-2.6.17.tar.gz 文件&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;tar xzf redis-4.0.9.tar.gz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#进入解压后的文件夹&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt;  redis-4.0.9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;#编译安装&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;make&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Redis" scheme="https://wandouduoduo.netlify.com/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>haproxy+keepalived实现Web服务器负载均衡</title>
    <link href="https://wandouduoduo.netlify.com/articles/c0e454fd.html"/>
    <id>https://wandouduoduo.netlify.com/articles/c0e454fd.html</id>
    <published>2019-11-02T02:17:03.000Z</published>
    <updated>2019-11-04T01:49:45.699Z</updated>
    
    <content type="html"><![CDATA[<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p><strong>操作系统</strong>：CentOS 6.X 64位</p><p><strong>Web服务器</strong>：192.168.21.127、192.168.21.128</p><p><strong>站点</strong>：bbs.osyunwei.com和sns.osyunwei.com部署在两台Web服务器上</p><h2 id="实现目的"><a href="#实现目的" class="headerlink" title="实现目的"></a><strong>实现目的</strong></h2><p>增加两台服务器（主主模式），通过HAProxy+Keepalived实现Web服务器负载均衡</p><h2 id="架构规划"><a href="#架构规划" class="headerlink" title="架构规划"></a><strong>架构规划</strong></h2><p>HAProxy服务器：192.168.21.129、192.168.21.130</p><p>虚拟服务器（VIP）：192.168.21.253、192.168.21.254</p><h2 id="验证说明"><a href="#验证说明" class="headerlink" title="验证说明"></a><strong>验证说明</strong></h2><ol><li>VIP：192.168.21.253指向192.168.21.129；VIP：192.168.21.254指向192.168.21.130；</li><li>当192.168.21.129宕机时，VIP：192.168.21.253漂移到192.168.21.130上；</li><li>当192.168.21.130宕机时，VIP：192.168.21.254漂移到192.168.21.129上；</li></ol><p>这样的主主模式好处是，两台服务器在提供服务的同时，又互为对方的备份服务器。</p><a id="more"></a><h2 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a><strong>操作步骤</strong></h2><p><strong>两台HAProxy服务器上分别操作</strong></p><h4 id="关闭SElinux"><a href="#关闭SElinux" class="headerlink" title="关闭SElinux"></a>关闭SElinux</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/selinux/config</span><br><span class="line"></span><br><span class="line"><span class="comment">#SELINUX=enforcing #注释掉</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#SELINUXTYPE=targeted #注释掉</span></span><br><span class="line"></span><br><span class="line">SELINUX=disabled <span class="comment">#增加</span></span><br><span class="line"></span><br><span class="line">:wq!  <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">setenforce 0 <span class="comment">#使配置立即生效</span></span><br></pre></td></tr></table></figure><h4 id="配置防火墙"><a href="#配置防火墙" class="headerlink" title="配置防火墙"></a>配置防火墙</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/sysconfig/iptables  <span class="comment">#编辑</span></span><br><span class="line"></span><br><span class="line">-A RH-Firewall-1-INPUT -d 224.0.0.18 -j ACCEPT  <span class="comment">#允许组播地址通信</span></span><br><span class="line"></span><br><span class="line">-A RH-Firewall-1-INPUT -p    vrrp    -j ACCEPT  <span class="comment">#允许VRRP（虚拟路由器冗余协）通信</span></span><br><span class="line"></span><br><span class="line">-A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT  <span class="comment">#允许80端口通过防火墙</span></span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">/etc/init.d/iptables restart <span class="comment">#重启防火墙使配置生效</span></span><br></pre></td></tr></table></figure><h4 id="安装HAProxy"><a href="#安装HAProxy" class="headerlink" title="安装HAProxy"></a>安装HAProxy</h4><h6 id="创建HAProxy运行账户和组"><a href="#创建HAProxy运行账户和组" class="headerlink" title="创建HAProxy运行账户和组"></a>创建HAProxy运行账户和组</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">groupadd haproxy #添加haproxy组</span><br><span class="line"></span><br><span class="line">useradd -g haproxy haproxy -s /bin/false #创建nginx运行账户haproxy并加入到haproxy组，不允许haproxy用户直接登录系统</span><br></pre></td></tr></table></figure><h6 id="安装编译工具"><a href="#安装编译工具" class="headerlink" title="安装编译工具"></a>安装编译工具</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install  gcc gcc-c++ make openssl-devel kernel-devel</span><br></pre></td></tr></table></figure><h6 id="安装HAProxy-1"><a href="#安装HAProxy-1" class="headerlink" title="安装HAProxy"></a>安装HAProxy</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">HAProxy下载地址：http://haproxy.1wt.eu/download/1.4/src/haproxy-1.4.24.tar.gz</span><br><span class="line"></span><br><span class="line">上传haproxy-1.4.24.tar.gz到/usr/<span class="built_in">local</span>/src目录中</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src <span class="comment">#进入软件包存放目录</span></span><br><span class="line"></span><br><span class="line">tar zxvf haproxy-1.4.24.tar.gz <span class="comment">#解压</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span>  haproxy-1.4.24  <span class="comment">#进入安装目录</span></span><br><span class="line"></span><br><span class="line">make  TARGET=linux26 CPU=x86_64  PREFIX=/usr/<span class="built_in">local</span>/haprpxy  <span class="comment">#编译</span></span><br><span class="line"></span><br><span class="line">make install PREFIX=/usr/<span class="built_in">local</span>/haproxy  <span class="comment">#安装</span></span><br><span class="line"></span><br><span class="line">参数说明：</span><br><span class="line"></span><br><span class="line">TARGET=linux26</span><br><span class="line"></span><br><span class="line">\<span class="comment">#使用uname -r查看内核，如：2.6.18-371.el5，此时该参数就为linux26</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#kernel 大于2.6.28的用：TARGET=linux2628</span></span><br><span class="line"></span><br><span class="line">CPU=x86_64   <span class="comment">#使用uname -r查看系统信息，如x86_64 x86_64 x86_64 GNU/Linux，此时该参数就为x86_64</span></span><br><span class="line"></span><br><span class="line">PREFIX=/usr/<span class="built_in">local</span>/haprpxy   <span class="comment">#/usr/local/haprpxy为haprpxy安装路径</span></span><br></pre></td></tr></table></figure><h6 id="设置HAProxy"><a href="#设置HAProxy" class="headerlink" title="设置HAProxy"></a>设置HAProxy</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p  /usr/<span class="built_in">local</span>/haproxy/conf  <span class="comment">#创建配置文件目录</span></span><br><span class="line"></span><br><span class="line">mkdir -p /etc/haproxy  <span class="comment">#创建配置文件目录</span></span><br><span class="line"></span><br><span class="line">cp /usr/<span class="built_in">local</span>/src/haproxy-1.4.24/examples/haproxy.cfg  /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg  <span class="comment">#拷贝配置模板文件</span></span><br><span class="line"></span><br><span class="line">ln -s  /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg   /etc/haproxy/haproxy.cfg  <span class="comment">#添加配置文件软连接</span></span><br><span class="line"></span><br><span class="line">cp -r  /usr/<span class="built_in">local</span>/src/haproxy-1.4.24/examples/errorfiles  /usr/<span class="built_in">local</span>/haproxy/errorfiles  <span class="comment">#拷贝错误页面</span></span><br><span class="line"></span><br><span class="line">ln -s  /usr/<span class="built_in">local</span>/haproxy/errorfiles  /etc/haproxy/errorfiles  <span class="comment">#添加软连接</span></span><br><span class="line"></span><br><span class="line">mkdir -p  /usr/<span class="built_in">local</span>/haproxy/<span class="built_in">log</span>  <span class="comment">#创建日志文件目录</span></span><br><span class="line"></span><br><span class="line">touch  /usr/<span class="built_in">local</span>/haproxy/<span class="built_in">log</span>/haproxy.log  <span class="comment">#创建日志文件</span></span><br><span class="line"></span><br><span class="line">ln -s  /usr/<span class="built_in">local</span>/haproxy/<span class="built_in">log</span>/haproxy.log  /var/<span class="built_in">log</span>/haproxy.log  <span class="comment">#添加软连接</span></span><br><span class="line"></span><br><span class="line">cp /usr/<span class="built_in">local</span>/src/haproxy-1.4.24/examples/haproxy.init  /etc/rc.d/init.d/haproxy  <span class="comment">#拷贝开机启动文件</span></span><br><span class="line"></span><br><span class="line">chmod +x  /etc/rc.d/init.d/haproxy  <span class="comment">#添加脚本执行权限</span></span><br><span class="line"></span><br><span class="line">chkconfig haproxy on  <span class="comment">#设置开机启动</span></span><br><span class="line"></span><br><span class="line">ln -s  /usr/<span class="built_in">local</span>/haproxy/sbin/haproxy  /usr/sbin  <span class="comment">#添加软连接</span></span><br></pre></td></tr></table></figure><h6 id="配置haproxy-cfg参数"><a href="#配置haproxy-cfg参数" class="headerlink" title="配置haproxy.cfg参数"></a>配置haproxy.cfg参数</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br></pre></td><td class="code"><pre><span class="line">cp  /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg   /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg-bak  <span class="comment">#备份</span></span><br><span class="line"></span><br><span class="line">vim  /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg  <span class="comment">#编辑，修改</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#####################################################################</span></span><br><span class="line"></span><br><span class="line">\<span class="comment"># this config needs haproxy-1.1.28 or haproxy-1.2.1</span></span><br><span class="line"></span><br><span class="line">global</span><br><span class="line"></span><br><span class="line"><span class="built_in">log</span> 127.0.0.1   local0 <span class="comment">#在本机记录日志</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">log</span> 127.0.0.1   local1 notice</span><br><span class="line"></span><br><span class="line">\<span class="comment">#log loghost    local0 info</span></span><br><span class="line"></span><br><span class="line">maxconn 65535   <span class="comment">#每个进程可用的最大连接数</span></span><br><span class="line"></span><br><span class="line">nbproc  8  <span class="comment">#进程数量，可以设置多个，提高处理效率</span></span><br><span class="line"></span><br><span class="line">chroot /usr/<span class="built_in">local</span>/haproxy  <span class="comment">#haproxy安装目录</span></span><br><span class="line"></span><br><span class="line">uid 500  <span class="comment">#运行haproxy的用户uid（cat /etc/passwd查看）</span></span><br><span class="line"></span><br><span class="line">gid 500  <span class="comment">#运行haproxy的组uid（cat /etc/group查看）</span></span><br><span class="line"></span><br><span class="line">daemon   <span class="comment">#以后台守护进程运行</span></span><br><span class="line"></span><br><span class="line">pidfile /usr/<span class="built_in">local</span>/haproxy/haproxy.pid  <span class="comment">#将所有进程写入pid文件</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#debug   #调试模式</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#quiet   #安装模式</span></span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line"></span><br><span class="line">\<span class="comment">#log     global</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">log</span>  127.0.0.1   local3  <span class="comment">#日志文件设置</span></span><br><span class="line"></span><br><span class="line">mode    http  <span class="comment">#运行模式tcp、http、health</span></span><br><span class="line"></span><br><span class="line">option  httplog</span><br><span class="line"></span><br><span class="line">option  http-pretend-keepalive  <span class="comment">#服务器端保持长连接</span></span><br><span class="line"></span><br><span class="line">option  http-server-close   <span class="comment">#每次请求完毕后主动关闭http通道</span></span><br><span class="line"></span><br><span class="line">option  forceclose    <span class="comment">#服务端响应后主动关闭请求连接，及早释放服务连接，不必等到客户端应答确认</span></span><br><span class="line"></span><br><span class="line">option  httpclose       <span class="comment">#每次请求完毕后主动关闭http通道</span></span><br><span class="line"></span><br><span class="line">option  accept-invalid-http-request       <span class="comment">#接受无效的http请求，一般建议不设置，但是可解决部分杂牌浏览器访问打不开页面问题</span></span><br><span class="line"></span><br><span class="line">option  dontlognull     <span class="comment">#不记录健康检查的日志信息</span></span><br><span class="line"></span><br><span class="line">option  redispatch  <span class="comment">#如果后端有服务器宕机，强制切换到正常服务器</span></span><br><span class="line"></span><br><span class="line">option  abortonclose  <span class="comment">#丢弃由于客户端等待时间过长而关闭连接但仍在haproxy等待队列中的请求</span></span><br><span class="line"></span><br><span class="line">option  forwardfor  except 127.0.0.0/8  <span class="comment">#不记录本机转发的日志</span></span><br><span class="line"></span><br><span class="line">option  originalto  <span class="comment">#记录客户端访问的目的IP</span></span><br><span class="line"></span><br><span class="line">maxconn  65535  <span class="comment">#每个进程可用的最大连接数</span></span><br><span class="line"></span><br><span class="line">balance <span class="built_in">source</span>  <span class="comment">#同一IP地址的所有请求都发送到同一服务器</span></span><br><span class="line"></span><br><span class="line">retries 3   <span class="comment">#三次连接失败，则判断服务不可用</span></span><br><span class="line"></span><br><span class="line">contimeout      5000  <span class="comment">#连接超时</span></span><br><span class="line"></span><br><span class="line">clitimeout      50000 <span class="comment">#客户端超时</span></span><br><span class="line"></span><br><span class="line">srvtimeout      50000 <span class="comment">#服务器超时</span></span><br><span class="line"></span><br><span class="line">timeout check 5s  <span class="comment">#检测超时</span></span><br><span class="line"></span><br><span class="line">timeout http-request 5s  <span class="comment">#http请求超时时间</span></span><br><span class="line"></span><br><span class="line">timeout queue 30s  <span class="comment">#一个请求在队列里的超时时间</span></span><br><span class="line"></span><br><span class="line">timeout http-keep-alive  5s  <span class="comment">#设置http-keep-alive的超时时间</span></span><br><span class="line"></span><br><span class="line">stats refresh 30s <span class="comment">#统计页面自动刷新时间</span></span><br><span class="line"></span><br><span class="line">stats uri  /haproxy-status  <span class="comment">#统计页面URL路径</span></span><br><span class="line"></span><br><span class="line">stats realm haproxy-status  <span class="comment">#统计页面输入密码框提示信息</span></span><br><span class="line"></span><br><span class="line">stats auth admin:123456     <span class="comment">#统计页面用户名和密码</span></span><br><span class="line"></span><br><span class="line">stats hide-version          <span class="comment">#隐藏统计页面上HAProxy版本信息</span></span><br><span class="line"></span><br><span class="line">frontend    web  <span class="comment">#自定义描述信息</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">bind</span> :80  <span class="comment">#监听80端口</span></span><br><span class="line"></span><br><span class="line">acl bbs.osyunwei.com  hdr(host) -i bbs.osyunwei.com  <span class="comment">#规则设置，-i后面是要访问的域名，如果访问bbs.osyunwei.com这个域名，就负载均衡到bbs.osyunwei.com作用域</span></span><br><span class="line"></span><br><span class="line">use_backend bbs.osyunwei.com <span class="keyword">if</span> bbs.osyunwei.com   <span class="comment">#acl和if后面的名称必须相同这里为bbs.osyunwei.com</span></span><br><span class="line"></span><br><span class="line">acl sns.osyunwei.com  hdr(host) -i sns.osyunwei.com  <span class="comment">#规则设置，-i后面是要访问的域名，如果访问sns.osyunwei.com这个域名，就负载均衡到sns.osyunwei.com作用域</span></span><br><span class="line"></span><br><span class="line">use_backend sns.osyunwei.com <span class="keyword">if</span> sns.osyunwei.com</span><br><span class="line"></span><br><span class="line">backend     bbs.osyunwei.com</span><br><span class="line"></span><br><span class="line">mode http</span><br><span class="line"></span><br><span class="line">balance   <span class="built_in">source</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#option  httpchk /index.php  #检测服务器此文件是否存在，如果没有，则认为服务器连接异常，此参数可以不设置</span></span><br><span class="line"></span><br><span class="line">server     192.168.21.127  192.168.21.127:80   check  inter  2000  rise 3  fall  3  weight 100   <span class="comment">#inter  2000 心跳检测时间；rise 3 三次连接成功，表示服务器正常；fall  3 三次连接失败，表示服务器异常； weight 100 权重设置</span></span><br><span class="line"></span><br><span class="line">server     192.168.21.128  192.168.21.128:80   check  inter  2000  rise 3  fall  3  weight 100</span><br><span class="line"></span><br><span class="line">backend     sns.osyunwei.com</span><br><span class="line"></span><br><span class="line">mode http</span><br><span class="line"></span><br><span class="line">balance   <span class="built_in">source</span>  <span class="comment">#设置负载均衡模式，source保存session值，roundrobin轮询模式</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#option  httpchk /index.php  #检测服务器此文件是否存在，如果没有，则认为服务器连接异常，此参数可以不设置</span></span><br><span class="line"></span><br><span class="line">server     192.168.21.127  192.168.21.127:80   check  inter  2000  rise 3  fall  3  weight 100</span><br><span class="line"></span><br><span class="line">server     192.168.21.128  192.168.21.128:80   check  inter  2000  rise 3  fall  3  weight 100</span><br><span class="line"></span><br><span class="line">\<span class="comment">#errorloc  503  http://www.osyunwei.com/404.html</span></span><br><span class="line"></span><br><span class="line">errorfile 403 /etc/haproxy/errorfiles/403.http</span><br><span class="line"></span><br><span class="line">errorfile 500 /etc/haproxy/errorfiles/500.http</span><br><span class="line"></span><br><span class="line">errorfile 502 /etc/haproxy/errorfiles/502.http</span><br><span class="line"></span><br><span class="line">errorfile 503 /etc/haproxy/errorfiles/503.http</span><br><span class="line"></span><br><span class="line">errorfile 504 /etc/haproxy/errorfiles/504.http</span><br><span class="line"></span><br><span class="line">\<span class="comment">#####################################################################</span></span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">service haproxy start <span class="comment">#启动</span></span><br><span class="line"></span><br><span class="line">service haproxy stop  <span class="comment">#关闭</span></span><br><span class="line"></span><br><span class="line">service haproxy restart  <span class="comment">#重启</span></span><br></pre></td></tr></table></figure><h6 id="设置HAProxy日志"><a href="#设置HAProxy日志" class="headerlink" title="设置HAProxy日志"></a>设置HAProxy日志</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">vim  /etc/syslog.conf  <span class="comment">#编辑，在最下边增加</span></span><br><span class="line"></span><br><span class="line">\<span class="comment"># haproxy.log</span></span><br><span class="line"></span><br><span class="line">local0.*          /var/<span class="built_in">log</span>/haproxy.log</span><br><span class="line"></span><br><span class="line">local3.*          /var/<span class="built_in">log</span>/haproxy.log</span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">vi  /etc/sysconfig/syslog   <span class="comment">#编辑修改</span></span><br><span class="line"></span><br><span class="line">SYSLOGD_OPTIONS=<span class="string">"-r -m 0"</span>   <span class="comment">#接收远程服务器日志</span></span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">service syslog restart  <span class="comment">#重启syslog</span></span><br></pre></td></tr></table></figure><h4 id="安装keepalived"><a href="#安装keepalived" class="headerlink" title="安装keepalived"></a>安装keepalived</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">下载keeplived：http://www.keepalived.org/software/keepalived-1.2.12.tar.gz</span><br><span class="line"></span><br><span class="line">上传keepalived-1.2.12.tar.gz到/usr/<span class="built_in">local</span>/src目录</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src</span><br><span class="line"></span><br><span class="line">tar zxvf keepalived-1.2.12.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> keepalived-1.2.12</span><br><span class="line"></span><br><span class="line">./configure  <span class="comment">#配置，必须看到以下提示，说明配置正确，才能继续安装</span></span><br><span class="line"></span><br><span class="line">Use IPVS Framework : Yes</span><br><span class="line"></span><br><span class="line">IPVS sync daemon support : Yes</span><br><span class="line"></span><br><span class="line">Use VRRP Framework       : Yes</span><br><span class="line"></span><br><span class="line">make <span class="comment">#编辑</span></span><br><span class="line"></span><br><span class="line">make install  <span class="comment">#安装</span></span><br><span class="line"></span><br><span class="line">cp /usr/<span class="built_in">local</span>/etc/sysconfig/keepalived  /etc/sysconfig/</span><br><span class="line"></span><br><span class="line">mkdir /etc/keepalived</span><br><span class="line"></span><br><span class="line">cp /usr/<span class="built_in">local</span>/etc/keepalived/keepalived.conf /etc/keepalived/</span><br><span class="line"></span><br><span class="line">cp /usr/<span class="built_in">local</span>/sbin/keepalived /usr/sbin/</span><br><span class="line"></span><br><span class="line">cp /usr/<span class="built_in">local</span>/etc/rc.d/init.d/keepalived  /etc/rc.d/init.d/</span><br><span class="line"></span><br><span class="line">chmod +x /etc/rc.d/init.d/keepalived  <span class="comment">#添加执行权限</span></span><br><span class="line"></span><br><span class="line">chkconfig keepalived on  <span class="comment">#设置开机启动</span></span><br><span class="line"></span><br><span class="line">service keepalived start <span class="comment">#启动</span></span><br><span class="line"></span><br><span class="line">service keepalived stop  <span class="comment">#关闭</span></span><br><span class="line"></span><br><span class="line">service keepalived restart  <span class="comment">#重启</span></span><br></pre></td></tr></table></figure><h6 id="配置keepalived"><a href="#配置keepalived" class="headerlink" title="配置keepalived"></a>配置keepalived</h6><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line">cp /etc/keepalived/keepalived.conf  /etc/keepalived/keepalived.conf-bak</span><br><span class="line"></span><br><span class="line">vi /etc/keepalived/keepalived.conf  <span class="comment">#编辑，修改为以下代码</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#########################################################</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#以下为192.168.21.129服务器：</span></span><br><span class="line"></span><br><span class="line">! Configuration File <span class="keyword">for</span> keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line"></span><br><span class="line">notification_email &#123;</span><br><span class="line"></span><br><span class="line">acassen@firewall.loc</span><br><span class="line"></span><br><span class="line">failover@firewall.loc</span><br><span class="line"></span><br><span class="line">sysadmin@firewall.loc</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">notification_email_from Alexandre.Cassen@firewall.loc</span><br><span class="line"></span><br><span class="line">smtp_server 192.168.200.1</span><br><span class="line"></span><br><span class="line">smtp_connect_timeout 30</span><br><span class="line"></span><br><span class="line">router_id LVS_DEVEL</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script chk_haproxy &#123;</span><br><span class="line"></span><br><span class="line">script <span class="string">"/etc/keepalived/check_haproxy.sh"</span>  <span class="comment">#HAproxy服务监控脚本</span></span><br><span class="line"></span><br><span class="line">interval 2</span><br><span class="line"></span><br><span class="line">weight 2</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line"></span><br><span class="line">state MASTER</span><br><span class="line"></span><br><span class="line">interface eth0</span><br><span class="line"></span><br><span class="line">virtual_router_id 51</span><br><span class="line"></span><br><span class="line">priority 100</span><br><span class="line"></span><br><span class="line">advert_int 1</span><br><span class="line"></span><br><span class="line">authentication &#123;</span><br><span class="line"></span><br><span class="line">auth_type PASS</span><br><span class="line"></span><br><span class="line">auth_pass 1111</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">track_script &#123;</span><br><span class="line"></span><br><span class="line">chk_haproxy <span class="comment">#监测haproxy进程状态</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_ipaddress &#123;</span><br><span class="line"></span><br><span class="line">192.168.21.253</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">notify_master <span class="string">"/etc/keepalived/clean_arp.sh  192.168.21.253"</span>  <span class="comment">#更新虚拟服务器（VIP）地址的arp记录到网关</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_2 &#123;</span><br><span class="line"></span><br><span class="line">state BACKUP</span><br><span class="line"></span><br><span class="line">interface eth0</span><br><span class="line"></span><br><span class="line">virtual_router_id 52</span><br><span class="line"></span><br><span class="line">priority 99</span><br><span class="line"></span><br><span class="line">advert_int 1</span><br><span class="line"></span><br><span class="line">authentication &#123;</span><br><span class="line"></span><br><span class="line">auth_type PASS</span><br><span class="line"></span><br><span class="line">auth_pass 1111</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_ipaddress &#123;</span><br><span class="line"></span><br><span class="line">192.168.21.254</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">notify_master <span class="string">"/etc/keepalived/clean_arp.sh  192.168.21.254"</span>  <span class="comment">#更新虚拟服务器（VIP）地址的arp记录到网关</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">\<span class="comment">#########################################################</span></span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#########################################################</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#以下为192.168.21.130服务器：</span></span><br><span class="line"></span><br><span class="line">192.168.21.130</span><br><span class="line"></span><br><span class="line">! Configuration File <span class="keyword">for</span> keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line"></span><br><span class="line">notification_email &#123;</span><br><span class="line"></span><br><span class="line">acassen@firewall.loc</span><br><span class="line"></span><br><span class="line">failover@firewall.loc</span><br><span class="line"></span><br><span class="line">sysadmin@firewall.loc</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">notification_email_from Alexandre.Cassen@firewall.loc</span><br><span class="line"></span><br><span class="line">smtp_server 192.168.200.1</span><br><span class="line"></span><br><span class="line">smtp_connect_timeout 30</span><br><span class="line"></span><br><span class="line">router_id LVS_DEVEL</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script chk_haproxy &#123;</span><br><span class="line"></span><br><span class="line">script <span class="string">"/etc/keepalived/check_haproxy.sh"</span>  <span class="comment">#HAproxy服务监控脚本</span></span><br><span class="line"></span><br><span class="line">interval 2</span><br><span class="line"></span><br><span class="line">weight 2</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line"></span><br><span class="line">state BACKUP</span><br><span class="line"></span><br><span class="line">interface eth0</span><br><span class="line"></span><br><span class="line">virtual_router_id 51</span><br><span class="line"></span><br><span class="line">priority 99</span><br><span class="line"></span><br><span class="line">advert_int 1</span><br><span class="line"></span><br><span class="line">authentication &#123;</span><br><span class="line"></span><br><span class="line">auth_type PASS</span><br><span class="line"></span><br><span class="line">auth_pass 1111</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">track_script &#123;</span><br><span class="line"></span><br><span class="line">chk_haproxy <span class="comment">#监测haproxy进程状态</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_ipaddress &#123;</span><br><span class="line"></span><br><span class="line">192.168.21.253</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">notify_master <span class="string">"/etc/keepalived/clean_arp.sh  192.168.21.253"</span>  <span class="comment">#更新虚拟服务器（VIP）地址的arp记录到网关</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_2 &#123;</span><br><span class="line"></span><br><span class="line">state MASTER</span><br><span class="line"></span><br><span class="line">interface eth0</span><br><span class="line"></span><br><span class="line">virtual_router_id 52</span><br><span class="line"></span><br><span class="line">priority 100</span><br><span class="line"></span><br><span class="line">advert_int 1</span><br><span class="line"></span><br><span class="line">authentication &#123;</span><br><span class="line"></span><br><span class="line">auth_type PASS</span><br><span class="line"></span><br><span class="line">auth_pass 1111</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_ipaddress &#123;</span><br><span class="line"></span><br><span class="line">192.168.21.254</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">notify_master <span class="string">"/etc/keepalived/clean_arp.sh  192.168.21.254"</span>  <span class="comment">#更新虚拟服务器（VIP）地址的arp记录到网关</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">\<span class="comment">#########################################################</span></span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br></pre></td></tr></table></figure><h4 id="设置HAproxy服务监控脚本"><a href="#设置HAproxy服务监控脚本" class="headerlink" title="设置HAproxy服务监控脚本"></a>设置HAproxy服务监控脚本</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">vim  /etc/keepalived/check_haproxy.sh <span class="comment">#编辑，添加以下代码</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#########################################################</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">A=`ps -C haproxy --no-header | wc -l`</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$A</span> -eq 0 ]</span><br><span class="line"></span><br><span class="line"><span class="keyword">then</span> service haproxy start</span><br><span class="line"></span><br><span class="line">sleep 3</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ `ps -C haproxy --no-header | wc -l ` -eq 0 ]</span><br><span class="line"></span><br><span class="line"><span class="keyword">then</span> service keepalived stop</span><br><span class="line"></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#########################################################</span></span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">chmod +x /etc/keepalived/check_haproxy.sh   <span class="comment">#添加执行权限</span></span><br></pre></td></tr></table></figure><h4 id="设置更新虚拟服务器（VIP）地址的arp记录到网关脚本"><a href="#设置更新虚拟服务器（VIP）地址的arp记录到网关脚本" class="headerlink" title="设置更新虚拟服务器（VIP）地址的arp记录到网关脚本"></a>设置更新虚拟服务器（VIP）地址的arp记录到网关脚本</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">vim  /etc/keepalived/clean_arp.sh  <span class="comment">#编辑，添加以下代码</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">VIP=<span class="variable">$1</span></span><br><span class="line"></span><br><span class="line">GATEWAY=192.168.21.2 <span class="comment">#网关地址</span></span><br><span class="line"></span><br><span class="line">/sbin/arping -I eth0 -c 5 -s <span class="variable">$VIP</span> <span class="variable">$GATEWAY</span> &amp;&gt;/dev/null</span><br><span class="line"></span><br><span class="line">:wq!  <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">chmod +x /etc/keepalived/clean_arp.sh  <span class="comment">#添加脚本执行权限</span></span><br></pre></td></tr></table></figure><h4 id="系统内核优化"><a href="#系统内核优化" class="headerlink" title="系统内核优化"></a>系统内核优化</h4><p>在两台HAProxy服务器上分别操作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">sed -i &quot;s/net.ipv4.ip_forward = 0/net.ipv4.ip_forward = 1/g&quot; &apos;/etc/sysctl.conf&apos;</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.core.somaxconn = 262144&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.core.netdev_max_backlog = 262144&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.core.wmem_default = 8388608&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.core.rmem_default = 8388608&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.core.rmem_max = 16777216&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.core.wmem_max = 16777216&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.route.gc_timeout = 20&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.ip_local_port_range = 1025 65535&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_retries2 = 5&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_fin_timeout = 30&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_syn_retries = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_synack_retries = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_timestamps = 0&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_tw_recycle = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_tw_reuse = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_keepalive_time = 120&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_keepalive_probes = 3&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_keepalive_intvl = 15&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_max_tw_buckets = 200000&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_max_orphans = 3276800&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_max_syn_backlog = 262144&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_wmem = 8192 131072 16777216&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_rmem = 32768 131072 16777216&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_mem = 94500000 915000000 927000000&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.ip_conntrack_max = 25000000&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.netfilter.ip_conntrack_max = 25000000&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.netfilter.ip_conntrack_tcp_timeout_established = 180&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.netfilter.ip_conntrack_tcp_timeout_time_wait = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.netfilter.ip_conntrack_tcp_timeout_close_wait = 60&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.netfilter.ip_conntrack_tcp_timeout_fin_wait = 120&quot; &gt;&gt; /etc/sysctl.conf</span><br></pre></td></tr></table></figure><h2 id="测试验证"><a href="#测试验证" class="headerlink" title="测试验证"></a>测试验证</h2><h4 id="测试HAProxy-Keepalived是否正常运行"><a href="#测试HAProxy-Keepalived是否正常运行" class="headerlink" title="测试HAProxy+Keepalived是否正常运行"></a><strong>测试HAProxy+Keepalived是否正常运行</strong></h4><h6 id="打开HAProxy监控页面"><a href="#打开HAProxy监控页面" class="headerlink" title="打开HAProxy监控页面"></a>打开HAProxy监控页面</h6><p><a href="http://bbs.osyunwei.com/haproxy-status" target="_blank" rel="noopener">http://bbs.osyunwei.com/haproxy-status</a></p><p>输入用户名/密码： admin/123456</p><p>登录之后如下图所示</p><p><img src="/articles/c0e454fd/2883.jpg" alt="2883"></p><p><img src="/articles/c0e454fd/2884.jpg" alt="2884"></p><h6 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h6><p>bbs.osyunwei.com 解析到192.168.21.253；</p><p>sns.osyunwei.com 解析到192.168.21.254；</p><p>在两台HAProxy服务器：192.168.21.129、192.168.21.130上执行命令：ip addr</p><p>如下图所示:</p><p><img src="/articles/c0e454fd/2885.jpg" alt="2885"></p><p><img src="/articles/c0e454fd/haproxy-keepalived%E5%AE%9E%E7%8E%B0Web%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%5C2886.jpg" alt="2886"></p><p>可以看出现在VIP：192.168.21.253指向192.168.21.129；VIP：192.168.21.254指向192.168.21.130；</p><p>在浏览器中打开</p><p><a href="http://bbs.osyunwei.com/" target="_blank" rel="noopener">http://bbs.osyunwei.com/</a></p><p><a href="http://sns.osyunwei.com/" target="_blank" rel="noopener">http://sns.osyunwei.com/</a></p><p>如下图所示：</p><p><img src="/articles/c0e454fd/2887.jpg" alt="2887"></p><p>此时，bbs和sns域名都被均衡到192.168.21.127上面</p><h6 id="停止192-168-21-127上面的nginx服务"><a href="#停止192-168-21-127上面的nginx服务" class="headerlink" title="停止192.168.21.127上面的nginx服务"></a>停止192.168.21.127上面的nginx服务</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service nginx stop</span><br></pre></td></tr></table></figure><p>继续打开上面的两个网址，如下图所示：</p><p><img src="/articles/c0e454fd/2888.jpg" alt="2888"></p><p>此时，bbs和sns域名都被均衡到192.168.21.128上面（由于192.168.21.127服务器nginx服务被关闭，实现了故障转移）</p><h6 id="关闭192-168-21-129上面的keepalived服务"><a href="#关闭192-168-21-129上面的keepalived服务" class="headerlink" title="关闭192.168.21.129上面的keepalived服务"></a>关闭192.168.21.129上面的keepalived服务</h6><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service  keepalived  stop</span><br></pre></td></tr></table></figure><p>此时，在两台HAProxy服务器：192.168.21.129、192.168.21.130上执行命令：ip addr</p><p>如下图所示：</p><p><img src="/articles/c0e454fd/2889.jpg" alt="2889"></p><p><img src="/articles/c0e454fd/2890.jpg" alt="2890"></p><p>可以看出VIP：192.168.21.253和192.168.21.254均指向到192.168.21.130；</p><p>此时，打开<a href="http://bbs.osyunwei.com/如下图所示：" target="_blank" rel="noopener">http://bbs.osyunwei.com/如下图所示：</a></p><p><img src="/articles/c0e454fd/2891.jpg" alt="2891"></p><p>可以正常访问</p><h6 id="恢复192-168-21-129上面的keepalived服务，恢复192-168-21-127上面的nginx服务"><a href="#恢复192-168-21-129上面的keepalived服务，恢复192-168-21-127上面的nginx服务" class="headerlink" title="恢复192.168.21.129上面的keepalived服务，恢复192.168.21.127上面的nginx服务"></a>恢复192.168.21.129上面的keepalived服务，恢复192.168.21.127上面的nginx服务</h6><p>停止192.168.21.130上面的Keepalived服务</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service keepalived stop</span><br></pre></td></tr></table></figure><p>在两台HAProxy服务器：192.168.21.129、192.168.21.130上执行命令：ip addr</p><p>如下图所示：</p><p><img src="/articles/c0e454fd/2892.jpg" alt="2892"></p><p><img src="/articles/c0e454fd/2893.jpg" alt="2893"></p><p>可以看出VIP：192.168.21.253和192.168.21.254均指向到192.168.21.129；</p><p>此时，打开<a href="http://sns.osyunwei.com/如下图所示：" target="_blank" rel="noopener">http://sns.osyunwei.com/如下图所示：</a></p><p><img src="/articles/c0e454fd/2894.jpg" alt="2894"></p><p>可以正常访问</p><p>备注：</p><p>查看HAProxy日志文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tail -f /var/log/haproxy.log</span><br></pre></td></tr></table></figure><p><strong>至此，HAProxy+Keepalived实现Web服务器负载均衡配置完成。</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;环境&quot;&gt;&lt;a href=&quot;#环境&quot; class=&quot;headerlink&quot; title=&quot;环境&quot;&gt;&lt;/a&gt;环境&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;操作系统&lt;/strong&gt;：CentOS 6.X 64位&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Web服务器&lt;/strong&gt;：192.168.21.127、192.168.21.128&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;站点&lt;/strong&gt;：bbs.osyunwei.com和sns.osyunwei.com部署在两台Web服务器上&lt;/p&gt;
&lt;h2 id=&quot;实现目的&quot;&gt;&lt;a href=&quot;#实现目的&quot; class=&quot;headerlink&quot; title=&quot;实现目的&quot;&gt;&lt;/a&gt;&lt;strong&gt;实现目的&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;增加两台服务器（主主模式），通过HAProxy+Keepalived实现Web服务器负载均衡&lt;/p&gt;
&lt;h2 id=&quot;架构规划&quot;&gt;&lt;a href=&quot;#架构规划&quot; class=&quot;headerlink&quot; title=&quot;架构规划&quot;&gt;&lt;/a&gt;&lt;strong&gt;架构规划&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;HAProxy服务器：192.168.21.129、192.168.21.130&lt;/p&gt;
&lt;p&gt;虚拟服务器（VIP）：192.168.21.253、192.168.21.254&lt;/p&gt;
&lt;h2 id=&quot;验证说明&quot;&gt;&lt;a href=&quot;#验证说明&quot; class=&quot;headerlink&quot; title=&quot;验证说明&quot;&gt;&lt;/a&gt;&lt;strong&gt;验证说明&lt;/strong&gt;&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;VIP：192.168.21.253指向192.168.21.129；VIP：192.168.21.254指向192.168.21.130；&lt;/li&gt;
&lt;li&gt;当192.168.21.129宕机时，VIP：192.168.21.253漂移到192.168.21.130上；&lt;/li&gt;
&lt;li&gt;当192.168.21.130宕机时，VIP：192.168.21.254漂移到192.168.21.129上；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这样的主主模式好处是，两台服务器在提供服务的同时，又互为对方的备份服务器。&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Haproxy" scheme="https://wandouduoduo.netlify.com/tags/Haproxy/"/>
    
      <category term="Keepalived" scheme="https://wandouduoduo.netlify.com/tags/Keepalived/"/>
    
  </entry>
  
  <entry>
    <title>haproxy+keepalived实现高可用负载均衡</title>
    <link href="https://wandouduoduo.netlify.com/articles/9ad4df0e.html"/>
    <id>https://wandouduoduo.netlify.com/articles/9ad4df0e.html</id>
    <published>2019-11-02T01:53:34.000Z</published>
    <updated>2019-11-04T01:49:45.711Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>在运维的日常工作中和很多服务打交道，为了保证各个服务健康稳定运行，高可用和高负载是在一个服务搭建好后，必须要考虑的问题。本文介绍了一种常用的高可用和负载均衡的解决方案：KA+HA(haproxy+keepalived)</p><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>haproxy keepalived  主：192.168.1.192<br>haproxy keepalived  备：192.168.1.193<br>vip：192.168.1.200<br>web：192.168.1.187:80 </p><p>​            192.168.1.187:8000</p><h2 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h2><p><img src="/articles/9ad4df0e/0.115069789831175.png" alt="img"></p><a id="more"></a><h2 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h2><p>在192.168.1.192上：<br><strong>keepalived</strong>的安装:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf keepalived-1.1.17.tar.gz</span><br><span class="line">ln -s /usr/src/kernels/2.6.18-128.el5-i686/ /usr/src/linux</span><br><span class="line"><span class="built_in">cd</span> keepalived-1.1.17</span><br><span class="line">./configure --prefix=/ --mandir=/usr/<span class="built_in">local</span>/share/man/ --with-kernel-dir=/usr/src/kernels/2.6.18-128.el5-i686/</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"><span class="built_in">cd</span> /etc/keepalived/</span><br><span class="line">mv keepalived.conf keepalived.conf.default</span><br><span class="line">vim keepalived.conf</span><br><span class="line"></span><br><span class="line">! Configuration File <span class="keyword">for</span> keepalived</span><br><span class="line">vrrp_script chk_http_port &#123;</span><br><span class="line">script <span class="string">"/etc/keepalived/check_haproxy.sh"</span></span><br><span class="line">interval 2</span><br><span class="line">weight 2</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">state MASTER <span class="comment">#192.168.1.193上改为BACKUP</span></span><br><span class="line">interface eth0</span><br><span class="line">virtual_router_id 51 </span><br><span class="line">priority 150 <span class="comment">#192.168.1.193上改为120</span></span><br><span class="line">advert_int 1</span><br><span class="line">authentication &#123;</span><br><span class="line">auth_type PASS</span><br><span class="line">auth_pass 1111</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">track_script &#123;</span><br><span class="line">chk_http_port</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_ipaddress &#123;</span><br><span class="line">192.168.1.200 </span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vi /etc/keepalived/check_haproxy.sh</span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">A=`ps -C haproxy --no-header |wc -l`</span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$A</span> -eq 0 ];<span class="keyword">then</span></span><br><span class="line">/usr/<span class="built_in">local</span>/haproxy/sbin/haproxy -f /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg</span><br><span class="line">sleep 3</span><br><span class="line"><span class="keyword">if</span> [ `ps -C haproxy --no-header |wc -l` -eq 0 ];<span class="keyword">then</span></span><br><span class="line">/etc/init.d/keepalived stop</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">chmod 755 /etc/keepalived/check_haproxy.sh</span><br></pre></td></tr></table></figure><p><strong>haproxy</strong>的安装(主备都一样)：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf haproxy-1.4.9.tar.gz</span><br><span class="line"><span class="built_in">cd</span> haproxy-1.4.9</span><br><span class="line">make TARGET=linux26 PREFIX=/usr/<span class="built_in">local</span>/haproxy install</span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/haproxy/</span><br><span class="line">mkdir conf logs</span><br><span class="line"><span class="built_in">cd</span> conf</span><br><span class="line">vim haproxy.cfg</span><br><span class="line"></span><br><span class="line">global</span><br><span class="line"><span class="built_in">log</span> 127.0.0.1 local3 info</span><br><span class="line">maxconn 4096</span><br><span class="line">user nobody</span><br><span class="line">group nobody</span><br><span class="line">daemon</span><br><span class="line">nbproc 1</span><br><span class="line">pidfile /usr/<span class="built_in">local</span>/haproxy/logs/haproxy.pid</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">maxconn 2000</span><br><span class="line">contimeout 5000</span><br><span class="line">clitimeout 30000</span><br><span class="line">srvtimeout 30000</span><br><span class="line">mode http</span><br><span class="line"><span class="built_in">log</span> global</span><br><span class="line"><span class="built_in">log</span> 127.0.0.1 local3 info</span><br><span class="line">stats uri /admin?stats</span><br><span class="line">option forwardfor</span><br><span class="line"></span><br><span class="line">frontend http_server</span><br><span class="line"><span class="built_in">bind</span> :80</span><br><span class="line"><span class="built_in">log</span> global</span><br><span class="line">default_backend info_cache</span><br><span class="line">acl <span class="built_in">test</span> hdr_dom(host) -i test.domain.com</span><br><span class="line">use_backend cache_test <span class="keyword">if</span> <span class="built_in">test</span></span><br><span class="line"></span><br><span class="line">backend info_cache</span><br><span class="line"><span class="comment">#balance roundrobin</span></span><br><span class="line">balance <span class="built_in">source</span></span><br><span class="line">option httpchk HEAD /haproxy.txt HTTP/1.1\r\nHost:192.168.1.187</span><br><span class="line">server inst2 192.168.1.187:80 check inter 5000 fall 3</span><br><span class="line"></span><br><span class="line">backend cache_test</span><br><span class="line">balance roundrobin</span><br><span class="line"><span class="comment">#balance source</span></span><br><span class="line">option httpchk HEAD /haproxy.txt HTTP/1.1\r\nHost:test.domain.com</span><br><span class="line">server inst1 192.168.1.187:8000 check inter 5000 fall 3</span><br></pre></td></tr></table></figure><h2 id="两台机器上分别启动"><a href="#两台机器上分别启动" class="headerlink" title="两台机器上分别启动"></a>两台机器上分别启动</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/etc/init.d/keepalived start （这条命令会自动把haproxy启动）</span><br></pre></td></tr></table></figure><h2 id="验证测试"><a href="#验证测试" class="headerlink" title="验证测试"></a>验证测试</h2><h4 id="两台机器上分别执行"><a href="#两台机器上分别执行" class="headerlink" title="两台机器上分别执行"></a>两台机器上分别执行</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip add</span><br></pre></td></tr></table></figure><p>主: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000<br>link/ether 00:0c:29:98:cd:c0 brd ff:ff:ff:ff:ff:ff<br>inet 192.168.1.192/24 brd 192.168.1.255 scope global eth0<br><strong>inet 192.168.1.200/32 scope global eth0</strong><br>inet6 fe80::20c:29ff:fe98:cdc0/64 scope link<br>valid_lft forever preferred_lft forever</p><p>备: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000<br>link/ether 00:0c:29:a6:0c:7e brd ff:ff:ff:ff:ff:ff<br>inet 192.168.1.193/24 brd 255.255.255.254 scope global eth0<br>inet6 fe80::20c:29ff:fea6:c7e/64 scope link<br>valid_lft forever preferred_lft forever</p><h4 id="停掉主上的haproxy"><a href="#停掉主上的haproxy" class="headerlink" title="停掉主上的haproxy"></a>停掉主上的haproxy</h4><p>3秒后keepalived会自动将其再次启动</p><h4 id="停掉主的keepalived"><a href="#停掉主的keepalived" class="headerlink" title="停掉主的keepalived"></a>停掉主的keepalived</h4><p>备机马上接管服务<br>备: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000<br>link/ether 00:0c:29:a6:0c:7e brd ff:ff:ff:ff:ff:ff<br>inet 192.168.1.193/24 brd 255.255.255.254 scope global eth0<br><strong>inet 192.168.1.200/32 scope global eth0</strong><br>inet6 fe80::20c:29ff:fea6:c7e/64 scope link<br>valid_lft forever preferred_lft forever</p><h4 id="更改hosts"><a href="#更改hosts" class="headerlink" title="更改hosts"></a>更改hosts</h4><p>192.168.1.200 test.com<br>192.168.1.200 test.domain.com<br>通过IE测试，可以发现<br>test.com的请求发向了192.168.1.187:80<br>test.domain.com的请求发向了192.168.1.187:8000<br><img src="/articles/9ad4df0e/0.6843823240075992.png" alt="img"></p><p><img src="/articles/9ad4df0e/0.9408829897802136.png" alt="img"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;在运维的日常工作中和很多服务打交道，为了保证各个服务健康稳定运行，高可用和高负载是在一个服务搭建好后，必须要考虑的问题。本文介绍了一种常用的高可用和负载均衡的解决方案：KA+HA(haproxy+keepalived)&lt;/p&gt;
&lt;h2 id=&quot;环境&quot;&gt;&lt;a href=&quot;#环境&quot; class=&quot;headerlink&quot; title=&quot;环境&quot;&gt;&lt;/a&gt;环境&lt;/h2&gt;&lt;p&gt;haproxy keepalived  主：192.168.1.192&lt;br&gt;haproxy keepalived  备：192.168.1.193&lt;br&gt;vip：192.168.1.200&lt;br&gt;web：192.168.1.187:80 &lt;/p&gt;
&lt;p&gt;​            192.168.1.187:8000&lt;/p&gt;
&lt;h2 id=&quot;架构图&quot;&gt;&lt;a href=&quot;#架构图&quot; class=&quot;headerlink&quot; title=&quot;架构图&quot;&gt;&lt;/a&gt;架构图&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/articles/9ad4df0e/0.115069789831175.png&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="运维技术" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/"/>
    
      <category term="服务部署" scheme="https://wandouduoduo.netlify.com/categories/%E8%BF%90%E7%BB%B4%E6%8A%80%E6%9C%AF/%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2/"/>
    
    
      <category term="Haproxy" scheme="https://wandouduoduo.netlify.com/tags/Haproxy/"/>
    
      <category term="Keepalived" scheme="https://wandouduoduo.netlify.com/tags/Keepalived/"/>
    
  </entry>
  
  <entry>
    <title>ssh端口转发：ssh隧道</title>
    <link href="https://wandouduoduo.netlify.com/articles/b406f6c6.html"/>
    <id>https://wandouduoduo.netlify.com/articles/b406f6c6.html</id>
    <published>2019-10-30T02:43:48.000Z</published>
    <updated>2019-10-31T10:44:34.902Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>“ssh端口转发”还有一个更加形象的名字，叫做”ssh隧道”，当然，只是纯粹的通过”ssh隧道”这几个字去理解它可能不太容易，我们来描述一些实际的场景，在这些场景中我们可能会遇到一些问题，而这些问题可以通过”ssh隧道”解决，通过这样的方式，我们反而更加容易理解”ssh隧道”是什么以及它的作用。</p><p>假如我们现在有两个台主机，主机A与主机B，主机A上安装有mysql客户端，主机B上安装有mysql服务端，现在，主机A中的mysql客户端需要与主机B中的mysql服务端进行通讯，则需要从mysql的客户端连接到mysql服务端。如下图所示</p><p><img src="/articles/b406f6c6/1.png" alt="ssh端口转发：ssh隧道"></p><p>然而我们知道，mysql在传输数据时是进行明文传输的，如果主机A与主机B只能通过公网进行通讯，那么暴露在公网的mysql通讯是非常不安全的，所以，我们需要借助一些手段，提高访问mysql服务时的安全性，比如，我们可以使用SSL证书为数据加密，或者使用stunnel加密隧道，我们还可以使用VPN，当然，这些方法都不是这篇文章所要描述的重点，我们此处要总结的是”ssh隧道”这种方法，我们可以利用ssh，搭建出一条”通道”，然后将mysq的客户端与服务端通过这条”ssh通道”连接起来，如下图所示</p><p><img src="/articles/b406f6c6/2.png" alt="ssh端口转发：ssh隧道"></p><p>mysql的客户端与服务端的连接方式从原来直连的方式变成了如上图所示的连接方式，它们之间并不直接进行通讯，而是借助ssh隧道将通讯数据转发，虽然仍然跨越了公网，但是由于ssh本身的安全特性，所以别人无法看到明文传输的数据，数据依靠ssh隧道实现了加密的效果，达到了保护数据安全的作用，提升了mysql的客户端与服务端通讯的安全性。</p><a id="more"></a><h2 id="本地转发"><a href="#本地转发" class="headerlink" title="本地转发"></a>本地转发</h2><p>经过上述描述，我想你对”ssh隧道”应该已经有了初步的理解，那么现在我们来实际动手配置一下。</p><p>首选，将实验环境准备好，两台主机的信息如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">ServerA：10.1.0.1</span><br><span class="line"></span><br><span class="line">ServerB：10.1.0.2</span><br><span class="line"></span><br><span class="line">ServerA中并不存在mysql服务。</span><br><span class="line"></span><br><span class="line">ServerB中已经安装了mysql服务，mysql服务已经启动并监听了3306端口。</span><br></pre></td></tr></table></figure><p>现在，我们只要在ServerA中执行如下命令，即可在ServerA与ServerB之间建立一条ssh隧道，执行如下命令时会提示输入ServerB的密码</p><p><img src="/articles/b406f6c6/3.png" alt="ssh端口转发：ssh隧道"></p><p>如上图所示，执行上图中的命令后，我们直接从主机A连接到了主机B，这条连接就是我们创建的”ssh隧道”。</p><p>我们先来简单的解释一下上图中命令的含义，为了方便解释，我们把命令分成3部分理解，如下图所示。</p><p><img src="/articles/b406f6c6/4.png" alt="ssh端口转发：ssh隧道"></p><p>第1部分为-L选项，-L 选项表示使用”本地转发”建立ssh隧道，本地转发是什么意思呢？</p><p>“本地转发”表示本地的某个端口上的通讯数据会被转发到目标主机的对应端口，你可以把它抽象的理解成一种”映射”，注意，我们把执行上述命令的主机称为”本地主机”。</p><p>比如，访问本地(当前主机)的端口A，就相当于访问目标主机的端口B，因为当你访问本地的端口A时，通讯数据会被转发到目标主机的端口B，这就是本地转发，其实，”本地转发”是与”远程转发”相对应的，但是我们还没有介绍到远程转发，所以并不用在意那么多，我们只要先了解本地转发的作用就行了。</p><p>刚才说过，”本地转发”表示本地的某个端口上的通讯数据会被转发到目标主机的对应端口，那么你一定能够理解上述命令中第2部分的含义了</p><p>第2部分表示：通讯数据会从本地的9906端口上被转发，最终被转发到10.1.0.2的3306端口。</p><p>第3部分表示：我们创建的ssh隧道是连接到10.1.0.2上的root用户的，其实，第3部分可以与之前的ssh连在一起去理解，比如，ssh <a href="mailto:root@10.1.0.2" target="_blank" rel="noopener">root@10.1.0.2</a>，其实就是使用ssh命令从ServerA中连接到ServerB的root用户，这就是为什么执行上述命令以后，会提示我们输入10.1.0.2中root用户的密码，当然，如果你已经在ServerB中配置好了ServerA对应用户的公钥，那么则可以省去输入密码的步骤直接连接，此时，ServerA的角色是ssh的客户端，ServerB的角色是ssh的服务端，而这条ssh隧道就是建立在ServerA与ServerB之间的。</p><p>了解完上述命令的3个部分，我们来把它当做一个整体去理解一下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -L 9906:10.1.0.2:3306 root@10.1.0.2</span><br></pre></td></tr></table></figure><p>上述命令表示从本机(ServerA)建立一个到ServerB(10.1.0.2)的ssh隧道，使用本地端口转发模式，监听ServerA本地的9906端口，访问本机的9906端口时，通讯数据将会被转发到ServerB(10.1.0.2)的3306端口。</p><p>好了，命令解释完了，现在我们来试试实际的使用效果，注意，此刻我们已经创建了ssh隧道，从serverA中已经连接到了ServerB，不要退出这个ssh连接，否则刚才创建的ssh隧道将会消失（稍后会介绍怎样后台建立连接），此刻，我们再打开一个新的ssh连接，连接到ServerA，如下图所示</p><p><img src="/articles/b406f6c6/5.png" alt="ssh端口转发：ssh隧道"></p><p>在新链接中查看对应的端口号，本地回环地址的9906端口已经被监听了（稍后介绍怎样监听ServerA中指定的IP，即非本地回环地址）。</p><p>此时，我们直接在ServerA中通过mysql命令访问127.0.0.1的9906端口，就相当于访问ServerB的mysql服务了，我们来试试。</p><p>执行mysql命令时需要指定IP与端口号，因为我的ServerB中的mysql只是用于测试，所以没有为用户设置密码，如下图即可连接</p><p><img src="/articles/b406f6c6/6.png" alt="ssh端口转发：ssh隧道"></p><p>如上图所示，已经可以正常在ServerA中连接到数据库，但是连接的数据库其实是ServerB中的mysql服务。</p><p>这就是通过ssh隧道访问远程主机的mysql服务的示例，这样做就是利用ssh的安全特性加密了mysql的通讯数据。</p><p>在没有使用ssh隧道时，直接从ServerA跨越公网访问ServerB的mysql服务时，如果在ServerB中通过抓包工具对通讯网卡进行抓包，可以直接从抓到的数据包中看到mysql的传输数据。</p><p>但是如果使用了ssh隧道，并且在ServerB中仅对通讯网卡进行抓包时，则只能看到经过加密的ssh数据包，此时，如果对ServerB的本地回环网卡同时进行抓包，则可以看到未加密的mysql传输数据，不过，这并不影响mysql通讯数据跨越公网时的安全性，因为这时已经是ServerB本机中的数据传输了，也就是说，mysql通讯数据在跨越公网时，是经过ssh隧道加密的，mysql通讯数据到达ServerB本机以后，是明文传输的。</p><p>不过，当我们执行上述命令创建ssh隧道时，总会从ServerA中连接到ServerB中，而通常，我们只希望建立ssh隧道，并不会使用到这个新建立的ssh连接，而且在实际使用中，我们往往会在建立隧道以后，退出当前的ssh会话，所以，上述命令并不能满足我们的需求，因为，我们一旦退出对应的ssh会话，相应的ssh隧道也会消失，所以，我们还需要配合另外两个选项，”-N选项”与”-f选项”，我们一一道来。</p><p>首先来试试”-N选项”，当配合此选项创建ssh隧道时，并不会打开远程shell连接到目标主机，我们来试试，如下图所示，配合-N选项创建隧道，输入ServerB的密码以后，并没有连接到ServerB，而是停留在了如下图的位置</p><p><img src="/articles/b406f6c6/7.png" alt="ssh端口转发：ssh隧道"></p><p>此时，再打开一个新的ssh会话连接到ServerA，可以看到，9906端口已经被监听。</p><p>但是，这样仍然不能满足我们的要求，虽然建立隧道时并没有连接到ServerB，但是，我们仍然不能关闭创建ssh隧道时所使用的ssh会话。</p><p>这时，只要配合”-f”选项即可，”-f”选项表示后台运行ssh隧道，即使我们关闭了创建隧道时所使用的ssh会话，对应的ssh隧道也不会消失，”-f”选项需要跟”-N”选项配合使用，所以通常，我们会使用如下命令创建ssh隧道</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -f -N -L 9906:10.1.0.2:3306 root@10.1.0.2</span><br></pre></td></tr></table></figure><p>配合上述选项创建ssh隧道时，即使我们完全关闭了执行命令时的ssh会话，对应创建的隧道也可以完全正常运行。</p><p>不过，当我们使用上述命令建立隧道时，只有127.0.0.1这个回环地址的9906端口会被监听，这样就会出现一个小问题，也就是说，我们只能在ServerA本机上访问9906端口，并不能通过其他主机访问ServerA的9906端口，因为ServerA其他IP的9906端口并未被监听，那么怎么办呢？很简单，使用如下命令，即可让9906端口监听在ServerA中指定的IP上</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -f -N -L 10.1.0.1:9906:10.1.0.2:3306 root@10.1.0.2</span><br></pre></td></tr></table></figure><p>在ServerA中执行上述命令时，ServerA的10.1.0.1的9906端口会被监听，此刻，我们可以通过其他主机访问10.1.0.1的9906端口，即可访问到ServerB中的mysql服务，其实，与之前的命令相比，只是在9906前增加了ServerA中对应的IP地址罢了，很简单吧。</p><p>如果你觉得这还不够，希望ServerA中的所有IP地址的9906端口都被监听，那么可以在建立隧道时开启”网关功能”，使用”-g”选项可以开启”网关功能”，开启网关功能以后，ServerA中的所有IP都会监听对应端口，示例如下</p><p><img src="/articles/b406f6c6/8.png" alt="ssh端口转发：ssh隧道"></p><p>好了，说了这么多，终于把ssh隧道(本地转发)给解释明白了，不过，我们也只是说明了本地转发，现在，我们来聊聊远程转发。</p><h2 id="远程转发"><a href="#远程转发" class="headerlink" title="远程转发"></a>远程转发</h2><p>在了解远程转发之前，请先确定你已经理解了”本地转发”。</p><p>老规矩，为了方便理解，我们先来描述一个场景。</p><p>公司有一台服务器ServerB，ServerB处于公司的内网中，公司内网中的所有主机都通过路由器访问互联网（典型的NAT网络），ServerB中有提供mysql服务，如果此时，我们想要通过外网访问到ServerB中的mysql服务，该怎么办呢？通常的做法是，通过路由器或者防火墙，将公司的固定外网IP上的某个端口映射到ServerB内网IP的3306端口上，这样，我们只要访问公司外网IP的对应端口，即可访问到内网ServerB中的mysql服务了，但是，如果你没有权限控制公司的防火墙或者路由器呢，这时该怎么办呢？</p><p>假设，你无法控制防火墙去进行端口映射，但是，公司在公网上有另外一台服务器ServerA，ServerA有自己的公网IP，你有权控制ServerA，这时，我们就可以利用ServerA达到我们的目的，聪明如你，一定想到了解决方案，没错，我们可以在ServerA与ServerB之间创建一条SSH隧道，利用这条隧道将ServerA中的某个端口(假设仍然使用9906端口)与ServerB中的3306端口连接起来，这样，当我们访问ServerA的9906端口时，就相当于访问到内网ServerB中的mysql服务了，那么，我们能不能使用之前的”本地转发”的方式，在ServerA中创建SSH隧道呢？我们来模拟一下，看看会不会遇到什么问题，如果想要使用之前的命令创建SSH隧道，那么我们则需要在ServerA中执行如下命令。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -f -N -L AIP:9906:BIP:3306 root@BIP</span><br></pre></td></tr></table></figure><p>问题来了，ServerA有自己的公网IP，我们只要把上述命令中的AIP替换成ServerA的公网IP即可，但是ServerB是内网主机，虽然ServerB能够通过公司内的路由器访问到互联网，但是ServerB并不持有任何公网IP，ServerB只有内网IP，所以，我们并不可能把上述命令中的BIP替换成B主机的内网IP，所以，使用上述命令是无法在ServerA中创建ssh隧道连接到ServerB的，那么该怎么办呢？</p><p>虽然我们无法从ServerA中使用ssh命令连接到ServerB，但是，我们可以从ServerB中使用ssh命令连接到ServerA啊，虽然ServerB是没有公网IP的内网主机，但是它仍然可以依靠公司的路由器访问互联网，所以，我们只要在ServerB中执行如下命令，即可从ServerB中连接到ServerA中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh root@AIP</span><br></pre></td></tr></table></figure><p>那么，按照这个思路，我们似乎找到了方向，我们现在需要一种方法，能够从ServerB中创建SSH隧道连接到ServerA，并且，隧道创建后，ServerA中会监听9906端口，以便别人能够通过外网访问，也就是说，我们需要一种方法，能够满足如下两个条件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">条件1：从ServerB中主动连接到ServerA，即在ServerB中执行创建隧道的命令，连接到ServerA。</span><br><span class="line"></span><br><span class="line">条件2：隧道创建后，转发端口需要监听在ServerA中，以便利用ServerA访问到内网的ServerB。</span><br></pre></td></tr></table></figure><p>这种方法就是”远程转发”。</p><p>你可能还是不太明白，没有关系，我们先来实际动手操作一下，稍后，我们会对比本地转发与远程转发的具体区别。</p><p>为了方便，我们仍然使用之前的实验环境，假设ServerA是外网主机，ServerB是内网主机，ServerA的IP为10.1.0.1（假设此IP为公网IP），ServerB的IP为10.1.0.2，并且已经将之前本地转发的进程关闭，相当于一个没有任何隧道的新的实验环境。</p><p>使用”-R选项”，可以创建一个”远程转发”模式的ssh隧道，我们在ServerB中，执行如下命令即可</p><p><img src="/articles/b406f6c6/9.png" alt="ssh端口转发：ssh隧道"></p><p>上述命令在ServerB中执行，执行后，即可在ServerA与ServerB之间建立ssh隧道，此时，ServerB是ssh客户端，ServerA是ssh服务端，隧道建立后，ServerA中的9906端口会被监听，在ServerA中查看对应端口，如下图所示</p><p><img src="/articles/b406f6c6/10.png" alt="ssh端口转发：ssh隧道"></p><p>从图中可以看出，ServerA中的9906端口已经被监听，此刻，我们通过外网IP登录到ServerA，在ServerA中访问本地回环地址的9906端口，即可访问到内网ServerB中的mysql服务，如下图所示。</p><p><img src="/articles/b406f6c6/11.png" alt="ssh端口转发：ssh隧道"></p><p>不过你肯定注意到了，当使用远程转发的命令时，我并没有指定监听ServerA的外网IP，也没有使用”-g选项”开启网关功能，这是因为，即使你在命令中指定了IP地址，最终在ServerA中还是会只监听127.0.0.1的9906端口，你可以在ServerB中尝试一下如下命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -f -N -R 10.1.0.1:9906:10.1.0.2:3306 root@10.1.0.1</span><br></pre></td></tr></table></figure><p>即使在ServerB中执行上述命令时指定了IP或者开启了网关功能，ServerA的9906端口仍然只监听在127.0.0.1上，当然，如果你一心想要通过别的主机访问ServerA的9906端口，也可以使用其他程序去反代ServerA的9906端口，还有，我在实际的使用过程中，如果使用远程转发穿透到内网，ssh隧道将会非常不稳定，隧道会莫名其妙的消失或者失效，特别是在没有固定IP的网络内，网上有些朋友提供了autossh的解决方案，不过我并没有尝试过，如果你有兴趣，可以试一试。</p><h2 id="本地转发与远程转发的区别"><a href="#本地转发与远程转发的区别" class="headerlink" title="本地转发与远程转发的区别"></a>本地转发与远程转发的区别</h2><p>读到此处，你可能会有些蒙圈，”远程转发”与”本地转发”到底有什么不一样，我们来对比一下</p><p>在对比之前，再强调一点，我们把执行创建隧道命令的主机称为本地主机(本地)。</p><p><strong>“本地转发”</strong></p><p>在本机执行创建隧道的命令时，本地是ssh客户端，隧道的另一头是远程主机(ssh服务端)，本地主机(也就是ssh客户端)会监听一个端口，当访问本地主机的这个端口时，通讯数据会通过ssh隧道转发到ssh服务端(即远程主机)，远程主机再将通讯数据发往应用服务所监听端口，在本地转发中，本地主机不仅扮演了ssh客户端的角色，也扮演了应用程序的客户端(比如mysql客户端)，远程主机不仅扮演了ssh服务端，也扮演了应用程序服务端(比如mysql服务端)，那么我们可以总结一下，本地转发的特性如下</p><p>本地主机：隧道的一头，本地主机既是ssh客户端，又是应用客户端</p><p>远程主机：隧道的另一头，远程主机既是ssh服务端，又是应用服务端</p><p>隧道创建以后，转发端口监听在本地主机中，即监听在ssh客户端主机中。</p><p><strong>“远程转发”</strong></p><p>在本机执行创建隧道的命令时，本地是ssh客户端，隧道的另一头是远程主机(ssh服务端)，远程主机(也就是ssh服务端)会监听一个端口，当访问远程主机的这个端口时，通讯数据会通过ssh隧道转发到ssh客户端(即本地主机)，本地主机再将通讯数据发往应用服务所监听端口，在远程转发中，本地主机不仅扮演了ssh客户端的角色，也扮演了应用程序的服务端(比如mysql服务端)，远程主机不仅扮演了ssh服务端，也扮演了应用程序客户端(比如mysql客户端)，那么我们可以总结一下，远程转发的特性如下</p><p>本地主机：隧道的一头，本地主机既是ssh客户端，又是应用服务端</p><p>远程主机：隧道的另一头，远程主机既是ssh服务端，又是应用客户端</p><p>隧道创建以后，转发端口监听在远程主机中，即监听在ssh服务端主机中。</p><p>“本地转发”与”远程转发”都属于ssh端口转发，也可以称呼它们为”ssh隧道”，只不过，有的朋友喜欢将”远程转发”称呼为为”ssh反向隧道”或者”ssh逆向隧道”</p><p>经过上述描述，我想你应该已经明白了它们之间的区别。</p><h2 id="一些扩展"><a href="#一些扩展" class="headerlink" title="一些扩展"></a>一些扩展</h2><p>在之前的示例中，ServerB是ssh隧道的一头，同时，ServerB也是应用的服务端，也就是说，应用程序的服务端与ssh隧道的连接端在同一台服务器上，那么，当应用程序的服务端处于其他主机时（比如ServerC），我们还能够通过ServerB去转发通讯数据吗？我们来动手试试，不过在动手之前，先来描述一下实验场景，实验场景如下图所示</p><p><img src="/articles/b406f6c6/12.png" alt="ssh端口转发：ssh隧道"></p><p>如上图所示，我们想要在A与B之间创建隧道，最终通过隧道访问到ServerC中的mysql服务。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">ServerAIP：10.1.0.1</span><br><span class="line"></span><br><span class="line">ServerBIP：10.1.0.2</span><br><span class="line"></span><br><span class="line">ServerCIP：10.1.0.3</span><br><span class="line"></span><br><span class="line">ServerA与ServerB上没有开启任何mysql服务。</span><br><span class="line"></span><br><span class="line">ServerC中开启了mysql服务，监听了3306端口。</span><br></pre></td></tr></table></figure><p>之前用于示例所创建的ssh隧道已经全部关闭，相当于一个全新的实验环境。</p><p>好了，实验环境描述完毕，现在开始实际操作，就以本地转发为例，在ServerA中执行如下命令，即可创建一条隧道并满足上图中的应用场景。</p><p><img src="/articles/b406f6c6/13.png" alt="ssh端口转发：ssh隧道"></p><p>如上图所示，ServerA的9906端口已经被监听，细心如你一定发现了，上图中的命令与之前创建隧道时所使用的命令在结构上并没有什么不同，只是目标端口所对应的IP地址变为了ServerC的IP，是不是很简单，我再来啰嗦一遍，上述命令表示，从本机（ServerA）建立一条ssh隧道连接到10.1.0.2（ServerB），隧道使用本地转发模式建立，转发端口监听在本地的9906端口上，访问本机的9906端口时，数据会被ssh隧道转发到10.1.0.3（ServerC)的3306端口。</p><p>我们来测试一下实际的使用效果，如下图所示，一切正常。</p><p><img src="/articles/b406f6c6/14.png" alt="ssh端口转发：ssh隧道"></p><p>上述场景中存在一个问题，就是数据安全性的问题，我们之所以使用ssh隧道，就是为了用它来保护明文传输的数据，从而提升安全性，不过，在上例的场景中，只有ServerA与ServerB之间的传输是受ssh隧道保护的，ServerB与ServerC之间的传输，仍然是明文的，所以，如果想要在上述场景中使用ssh隧道进行数据转发，首先要考虑ServerB与ServerC之间的网络是否可靠。</p><p>其实，当我们在创建隧道时如果开启了网关功能，那么应用客户端与ServerA之间的通讯也会面临同样的问题，如下图所示</p><p><img src="/articles/b406f6c6/15.png" alt="ssh端口转发：ssh隧道"></p><p>既然上述场景中存在没有办法通过ssh隧道保护的连接，那么为什么还要使用上述方式进行转发呢？</p><p>这是因为，在某些实际的使用场景中，我们使用ssh隧道的目的并不是提升数据的安全性，而是为了”绕过防火墙”，比如如下场景</p><p><img src="/articles/b406f6c6/16.png" alt="ssh端口转发：ssh隧道"></p><p>上图中，ServerC中提供了mysql服务，我们想要通过ServerA访问ServerC中的mysql服务，但是，ServerA与ServerC之间存在防火墙，阻断了它们的通讯，所以，我们无法从ServerA中直接访问ServerC中的服务，不过幸运的是，我们还有另外一台机器：ServerB，ServerA与ServerB之间可以自由通讯，同时，ServerB与ServerC之间也可以自由通讯，没错，你一定想到了，我们可以利用ServerB，在ServerA与ServerB之间建立ssh隧道，达到我们的最终目的：使得ServerA可以访问到ServerC中的mysql服务，如下图所示</p><p><img src="/articles/b406f6c6/17.png" alt="ssh端口转发：ssh隧道"></p><p>当上图中的ssh隧道建立以后，访问ServerA中的转发端口，即可访问到ServerC中的mysql服务，因为对于ServerC来说，ServerA是透明的，ServerC并不知道ServerA的存在，它只能看到ServerB，当你在ServerA中使用ssh隧道访问ServerC的mysql服务时，如果你在ServerC中的网卡上进行抓包，只会看到ServerB的IP地址，因为数据经过ServerB转发了。</p><h2 id="一些配置"><a href="#一些配置" class="headerlink" title="一些配置"></a>一些配置</h2><p>其实，如果想要能够正常的使用ssh端口转发，我们还需要做出正确的配置才行，之前一直没有说明，是因为openssh默认的配置就是支持端口转发的。</p><p>如果想要ssh端口转发能够正常工作，需要在ssh服务端的配置文件中将AllowTcpForwarding的值设置为yes。</p><p>此处所指的ssh服务端即ssh隧道中的一头，扮演ssh服务端角色的那台主机。</p><p>当隧道建立以后，经过一段时间后，ssh隧道链接可能会被断开，这有可能是因为ssh客户端和ssh服务端长时间没有通讯，于是ssh服务端主动断开了链接，如果想要解决这个问题，可以在ssh服务端进行配置，调整ssh服务端的ClientAliveInterval配置和ClientAliveCountMax配置即可。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>经过上述描述，我想你应该已经了解的ssh隧道的作用。</p><p>通常，ssh隧道可以帮助我们达到如下目的：</p><p>1、保护tcp会话，保护会话中明文传输的内容。</p><p>2、绕过防火墙或者穿透到内网，访问对应的服务。</p><p>为了以后方便回顾，我们将上文中使用到的命令及选项进行总结</p><p>创建隧道时的常用选项有：</p><p>“-L选项”：表示使用本地端口转发创建ssh隧道</p><p>“-R选项”：表示使用远程端口转发创建ssh隧道</p><p>“-N选项”： 表示创建隧道以后不连接到sshServer端，通常与”-f”选项连用</p><p>“-f选项”：表示在后台运行ssh隧道，通常与”-N”选项连用</p><p>“-g选项”：表示ssh隧道对应的转发端口将监听在主机的所有IP中，不使用”-g选项”时，转发端口默认只监听在主机的本地回环地址中，”-g”表示开启网关模式，远程端口转发中，无法开启网关功能。</p><p>创建本地转发模式的ssh隧道，命令如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -g -f -N -L forwardingPort:targetIP:targetPort user@sshServerIP</span><br></pre></td></tr></table></figure><p>本机上的forwardingPort将会被监听，访问本机的forwardingPort，就相当于访问targetIP的targetPort，ssh隧道建立在本机与sshServer之间。</p><p>创建远程转发模式的ssh隧道，命令如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -f -N -R forwardingPort:targetIP:targetPort user@sshServerIP</span><br></pre></td></tr></table></figure><p>sshServer上的forwardingPort将会被监听，访问sshServer上的forwardingPort，就相当于访问targetIP的targetPort，ssh隧道建立在本机与sshServer之间。</p><p>关于ssh的端口转发就总结到这里，希望可以帮助到你。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;“ssh端口转发”还有一个更加形象的名字，叫做”ssh隧道”，当然，只是纯粹的通过”ssh隧道”这几个字去理解它可能不太容易，我们来描述一些实际的场景，在这些场景中我们可能会遇到一些问题，而这些问题可以通过”ssh隧道”解决，通过这样的方式，我们反而更加容易理解”ssh隧道”是什么以及它的作用。&lt;/p&gt;
&lt;p&gt;假如我们现在有两个台主机，主机A与主机B，主机A上安装有mysql客户端，主机B上安装有mysql服务端，现在，主机A中的mysql客户端需要与主机B中的mysql服务端进行通讯，则需要从mysql的客户端连接到mysql服务端。如下图所示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/b406f6c6/1.png&quot; alt=&quot;ssh端口转发：ssh隧道&quot;&gt;&lt;/p&gt;
&lt;p&gt;然而我们知道，mysql在传输数据时是进行明文传输的，如果主机A与主机B只能通过公网进行通讯，那么暴露在公网的mysql通讯是非常不安全的，所以，我们需要借助一些手段，提高访问mysql服务时的安全性，比如，我们可以使用SSL证书为数据加密，或者使用stunnel加密隧道，我们还可以使用VPN，当然，这些方法都不是这篇文章所要描述的重点，我们此处要总结的是”ssh隧道”这种方法，我们可以利用ssh，搭建出一条”通道”，然后将mysq的客户端与服务端通过这条”ssh通道”连接起来，如下图所示&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/articles/b406f6c6/2.png&quot; alt=&quot;ssh端口转发：ssh隧道&quot;&gt;&lt;/p&gt;
&lt;p&gt;mysql的客户端与服务端的连接方式从原来直连的方式变成了如上图所示的连接方式，它们之间并不直接进行通讯，而是借助ssh隧道将通讯数据转发，虽然仍然跨越了公网，但是由于ssh本身的安全特性，所以别人无法看到明文传输的数据，数据依靠ssh隧道实现了加密的效果，达到了保护数据安全的作用，提升了mysql的客户端与服务端通讯的安全性。&lt;/p&gt;
    
    </summary>
    
      <category term="网络技术" scheme="https://wandouduoduo.netlify.com/categories/%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Network" scheme="https://wandouduoduo.netlify.com/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>SSH隧道与端口转发及内网穿透</title>
    <link href="https://wandouduoduo.netlify.com/articles/95ca2546.html"/>
    <id>https://wandouduoduo.netlify.com/articles/95ca2546.html</id>
    <published>2019-10-29T11:30:24.000Z</published>
    <updated>2019-11-01T02:54:24.770Z</updated>
    
    <content type="html"><![CDATA[<h2 id="SSH隧道与端口转发及内网穿透"><a href="#SSH隧道与端口转发及内网穿透" class="headerlink" title="SSH隧道与端口转发及内网穿透"></a>SSH隧道与端口转发及内网穿透</h2><p>大家都知道SSH是一种安全的传输协议，用在连接服务器上比较多。不过其实除了这个功能，它的隧道转发功能更是吸引人。下面是个人根据自己的需求以及在网上查找的资料配合自己的实际操作所得到的一些心得。</p><p><strong>SSH/plink命令的基本资料：</strong></p><p>首先，认识下这三个非常强大的命令：</p><blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; ssh -C -f -N -g -L listen_port:DST_Host:DST_port user@Tunnel_Host</span><br><span class="line">&gt; ssh -C -f -N -g -R listen_port:DST_Host:DST_port user@Tunnel_Host</span><br><span class="line">&gt; ssh -C -f -N -g -D listen_port user@Tunnel_Host</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p>相关参数的解释：</p><p>-f Fork into background after authentication.<br>后台认证用户/密码，通常和-N连用，不用登录到远程主机。</p><p>-L port:host:hostport<br>将本地机(客户机)的某个端口转发到远端指定机器的指定端口. 工作原理是这样的, 本地机器上分配了一个 socket 侦听 port 端口, 一旦这个端口上有了连接, 该连接就经过安全通道转发出去, 同时远程主机和 host 的 hostport 端口建立连接. 可以在配置文件中指定端口的转发. 只有 root 才能转发特权端口. IPv6 地址用另一种格式说明: port/host/hostport</p><p>-R port:host:hostport<br>将远程主机(服务器)的某个端口转发到本地端指定机器的指定端口. 工作原理是这样的, 远程主机上分配了一个 socket 侦听 port 端口, 一旦这个端口上有了连接, 该连接就经过安全通道转向出去, 同时本地主机和 host 的 hostport 端口建立连接. 可以在配置文件中指定端口的转发. 只有用 root 登录远程主机才能转发特权端口. IPv6 地址用另一种格式说明: port/host/hostport</p><p>-D port<br>指定一个本地机器 “动态的’’ 应用程序端口转发. 工作原理是这样的, 本地机器上分配了一个 socket 侦听 port 端口, 一旦这个端口上有了连接, 该连接就经过安全通道转发出去, 根据应用程序的协议可以判断出远程主机将和哪里连接. 目前支持 SOCKS4 协议, 将充当 SOCKS4 服务器. 只有 root 才能转发特权端口. 可以在配置文件中指定动态端口的转发.</p><p>-C Enable compression.<br>压缩数据传输。</p><p>-N Do not execute a shell or command.<br>不执行脚本或命令，通常与-f连用。</p><p>-g Allow remote hosts to connect to forwarded ports.<br>在-L/-R/-D参数中，允许远程主机连接到建立的转发的端口，如果不加这个参数，只允许本地主机建立连接。注：这个参数我在实践中似乎始终不起作用。</p><a id="more"></a><p><strong>建立本地SSH隧道例子</strong></p><p>在我们计划建立一个本地SSH隧道之前，我们必须清楚下面这些数据：</p><ol><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1. 中间服务器d的IP地址</span><br><span class="line">2. 要访问服务器c的IP地址</span><br><span class="line">3. 要访问服务器c的端口</span><br></pre></td></tr></table></figure></li></ol><p>现在，我们把上面这张图变得具体一些，给这些机器加上IP地址。并且根据下面这张图列出我们的计划：</p><ol><li><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. 需要访问234.234.234.234的FTP服务，也就是端口21</span><br><span class="line">2. 中间服务器是123.123.123.123</span><br></pre></td></tr></table></figure></li></ol><p>现在我们使用下面这条命令来达成我们的目的</p><blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; ssh -N -f -L 2121:234.234.234.234:21 123.123.123.123</span><br><span class="line">&gt; ftp localhost:2121 # 现在访问本地2121端口，就能连接234.234.234.234的21端口了</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p>这里我们用到了SSH客户端的三个参数，下面我们一一做出解释：</p><ul><li>-N 告诉SSH客户端，这个连接不需要执行任何命令。仅仅做端口转发</li><li>-f 告诉SSH客户端在后台运行</li><li>-L 做本地映射端口，被冒号分割的三个部分含义分别是<ul><li>需要使用的本地端口号</li><li>需要访问的目标机器IP地址（IP: 234.234.234.234）</li><li>需要访问的目标机器端口（端口: 21)</li></ul></li><li>最后一个参数是我们用来建立隧道的中间机器的IP地址(IP: 123.123.123.123)</li></ul><p>我们再重复一下-L参数的行为。-L X:Y:Z的含义是，将IP为Y的机器的Z端口通过中间服务器映射到本地机器的X端口。</p><p>在这条命令成功执行之后，我们已经具有绕过公司防火墙的能力，并且成功访问到了我们喜欢的一个FTP服务器了。</p><h5 id="如何建立远程SSH隧道"><a href="#如何建立远程SSH隧道" class="headerlink" title="如何建立远程SSH隧道"></a>如何建立远程SSH隧道</h5><p>通过建立本地SSH隧道，我们成功地绕过防火墙开始下载FTP上的资源了。那么当我们在家里的时候想要察看下载进度怎么办呢？大多数公司的网络是通过路由器接入互联网的，公司内部的机器不会直接与互联网连接，也就是不能通过互联网直接访问。通过线路D-B-A访问公司里的机器a便是不可能的。也许你已经注意到了，虽然D-B-A这个方向的连接不通，但是A-B-D这个方向的连接是没有问题的。那么，我们能否利用一条已经连接好的A-B-D方向的连接来完成D-B-A方向的访问呢？答案是肯定的，这就是远程SSH隧道的用途。</p><p>与本地SSH一样，我们在建立远程SSH隧道之前要清楚下面几个参数：</p><ul><li>需要访问内部机器的远程机器的IP地址（这里是123.123.123.123）</li><li>需要让远程机器能访问的内部机器的IP地址(这里因为是想把本机映射出去，因此IP是127.0.0.1)</li><li>需要让远程机器能访问的内部机器的端口号(端口:22)</li></ul><p>在清楚了上面的参数后，我们使用下面的命令来建立一个远程SSH隧道</p><blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; ssh -N -f -R 2222:127.0.0.1:22 123.123.123.123</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p>现在，在IP是123.123.123.123的机器上我们用下面的命令就可以登陆公司的IP是192.168.0.100的机器了。</p><blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; ssh -p 2222 localhost</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p>-N，-f 这两个参数我们已经在本地SSH隧道中介绍过了。我们现在重点说说参数-R。该参数的三个部分的含义分别是:</p><ul><li>远程机器使用的端口（2222）</li><li>需要映射的内部机器的IP地址(127.0.0.1)</li><li>需要映射的内部机器的端口(22)</li></ul><p>例如：-R X:Y:Z 就是把我们内部的Y机器的Z端口映射到远程机器的X端口上。</p><p><strong>建立SSH隧道的几个技巧</strong></p><p><strong>自动重连</strong></p><p>隧道可能因为某些原因断开，例如：机器重启，长时间没有数据通信而被路由器切断等等。因此我们可以用程序控制隧道的重新连接，例如一个简单的循环或者使用 <a href="http://cr.yp.to/daemontools.html" target="_blank" rel="noopener">djb’s daemontools</a> . 不管用哪种方法，重连时都应避免因输入密码而卡死程序。关于如何安全的避免输入密码的方法，请参考我的 <a href="http://blog.jianingy.com/node/73" target="_blank" rel="noopener">如何实现安全的免密码ssh登录</a> 。这里请注意，如果通过其他程序控制隧道连接，应当避免将SSH客户端放到后台执行，也就是去掉-f参数。</p><p><strong>保持长时间连接</strong></p><p>有些路由器会把长时间没有通信的连接断开。SSH客户端的TCPKeepAlive选项可以避免这个问题的发生，默认情况下它是被开启的。如果它被关闭了，可以在ssh的命令上加上-o TCPKeepAlive=yes来开启。</p><p>另一种方法是，去掉-N参数，加入一个定期能产生输出的命令。例如: top或者vmstat。下面给出一个这种方法的例子：</p><blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt; ssh -R 2222:localhost:22 123.123.123.123 &quot;vmstat 30&quot;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p><strong>检查隧道状态</strong></p><p>有些时候隧道会因为一些原因通信不畅而卡死，例如：由于传输数据量太大，被路由器带入stalled状态。这种时候，往往SSH客户端并不退出，而是卡死在那里。一种应对方法是，使用SSH客户端的ServerAliveInterval和ServerAliveCountMax选项。 ServerAliveInterval会在隧道无通信后的一段设置好的时间后发送一个请求给服务器要求服务器响应。如果服务器在 ServerAliveCountMax次请求后都没能响应，那么SSH客户端就自动断开连接并退出，将控制权交给你的监控程序。这两个选项的设置方法分别是在ssh时加入-o ServerAliveInterval=n和-o ServerAliveCountMax=m。其中n, m可以自行定义。</p><p><strong>如何将端口绑定到外部地址上</strong></p><p>使用上面的方法，映射的端口只能绑定在127.0.0.1这个接口上。也就是说，只能被本机自己访问到。如何才能让其他机器访问这个端口呢？我们可以把这个映射的端口绑定在0.0.0.0的接口上，方法是加上参数-b 0.0.0.0。同时还需要打开SSH服务器端的一个选项－GatewayPorts。默认情况下它应当是被打开的。如果被关闭的话，可以在/etc /sshd_config中修改GatewayPorts no为GatewayPorts yes来打开它。</p><p><strong>通过SSH隧道建立SOCKS服务器</strong></p><p>如果我们需要借助一台中间服务器访问很多资源，一个个映射显然不是高明的办法（事实上，高明确实没有用这个方法）。幸好，SSH客户端为我们提供了通过SSH隧道建立SOCKS服务器的功能。</p><p>通过下面的命令我们可以建立一个通过123.123.123.123的SOCKS服务器。</p><blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; ssh -N -f -D 1080 123.123.123 # 将端口绑定在127.0.0.1上</span><br><span class="line">&gt; ssh -N -f -D 0.0.0.0:1080 123.123.123.123 # 将端口绑定在0.0.0.0上</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></blockquote><p>通过SSH建立的SOCKS服务器使用的是SOCKS5协议，在为应用程序设置SOCKS代理的时候要特别注意。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;SSH隧道与端口转发及内网穿透&quot;&gt;&lt;a href=&quot;#SSH隧道与端口转发及内网穿透&quot; class=&quot;headerlink&quot; title=&quot;SSH隧道与端口转发及内网穿透&quot;&gt;&lt;/a&gt;SSH隧道与端口转发及内网穿透&lt;/h2&gt;&lt;p&gt;大家都知道SSH是一种安全的传输协议，用在连接服务器上比较多。不过其实除了这个功能，它的隧道转发功能更是吸引人。下面是个人根据自己的需求以及在网上查找的资料配合自己的实际操作所得到的一些心得。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SSH/plink命令的基本资料：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先，认识下这三个非常强大的命令：&lt;/p&gt;
&lt;blockquote&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&amp;gt; ssh -C -f -N -g -L listen_port:DST_Host:DST_port user@Tunnel_Host&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;gt; ssh -C -f -N -g -R listen_port:DST_Host:DST_port user@Tunnel_Host&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;gt; ssh -C -f -N -g -D listen_port user@Tunnel_Host&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/blockquote&gt;
&lt;p&gt;相关参数的解释：&lt;/p&gt;
&lt;p&gt;-f Fork into background after authentication.&lt;br&gt;后台认证用户/密码，通常和-N连用，不用登录到远程主机。&lt;/p&gt;
&lt;p&gt;-L port:host:hostport&lt;br&gt;将本地机(客户机)的某个端口转发到远端指定机器的指定端口. 工作原理是这样的, 本地机器上分配了一个 socket 侦听 port 端口, 一旦这个端口上有了连接, 该连接就经过安全通道转发出去, 同时远程主机和 host 的 hostport 端口建立连接. 可以在配置文件中指定端口的转发. 只有 root 才能转发特权端口. IPv6 地址用另一种格式说明: port/host/hostport&lt;/p&gt;
&lt;p&gt;-R port:host:hostport&lt;br&gt;将远程主机(服务器)的某个端口转发到本地端指定机器的指定端口. 工作原理是这样的, 远程主机上分配了一个 socket 侦听 port 端口, 一旦这个端口上有了连接, 该连接就经过安全通道转向出去, 同时本地主机和 host 的 hostport 端口建立连接. 可以在配置文件中指定端口的转发. 只有用 root 登录远程主机才能转发特权端口. IPv6 地址用另一种格式说明: port/host/hostport&lt;/p&gt;
&lt;p&gt;-D port&lt;br&gt;指定一个本地机器 “动态的’’ 应用程序端口转发. 工作原理是这样的, 本地机器上分配了一个 socket 侦听 port 端口, 一旦这个端口上有了连接, 该连接就经过安全通道转发出去, 根据应用程序的协议可以判断出远程主机将和哪里连接. 目前支持 SOCKS4 协议, 将充当 SOCKS4 服务器. 只有 root 才能转发特权端口. 可以在配置文件中指定动态端口的转发.&lt;/p&gt;
&lt;p&gt;-C Enable compression.&lt;br&gt;压缩数据传输。&lt;/p&gt;
&lt;p&gt;-N Do not execute a shell or command.&lt;br&gt;不执行脚本或命令，通常与-f连用。&lt;/p&gt;
&lt;p&gt;-g Allow remote hosts to connect to forwarded ports.&lt;br&gt;在-L/-R/-D参数中，允许远程主机连接到建立的转发的端口，如果不加这个参数，只允许本地主机建立连接。注：这个参数我在实践中似乎始终不起作用。&lt;/p&gt;
    
    </summary>
    
      <category term="网络技术" scheme="https://wandouduoduo.netlify.com/categories/%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Network" scheme="https://wandouduoduo.netlify.com/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>Zabbix Server增加微信告警</title>
    <link href="https://wandouduoduo.netlify.com/articles/63c5195d.html"/>
    <id>https://wandouduoduo.netlify.com/articles/63c5195d.html</id>
    <published>2019-10-29T09:06:37.000Z</published>
    <updated>2019-10-31T10:40:55.501Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>微信现在是我们手机中必不可少的软件，通过它可以和朋友亲人聊天视频等。作为运维，让监控系统通过微信报警，及时提醒我们，保证线上服务稳定运行，这是SRE的职责所在。通过本教程学习，让zabbix  server增加微信报警媒介。</p><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">[root@p34044v ~]<span class="comment"># cat /etc/redhat-release </span></span><br><span class="line">CentOS Linux release 7.7.1908 (Core)</span><br><span class="line">[root@p34044v ~]<span class="comment"># python -V</span></span><br><span class="line">Python 2.7.5</span><br><span class="line">[root@p34044v ~]<span class="comment"># zabbix_server -V</span></span><br><span class="line">zabbix_server (Zabbix) 4.0.13</span><br><span class="line">Revision 4e383bb6c5 2 October 2019, compilation time: Oct  2 2019 08:45:35</span><br><span class="line"></span><br><span class="line">Copyright (C) 2019 Zabbix SIA</span><br><span class="line">License GPLv2+: GNU GPL version 2 or later &lt;http://gnu.org/licenses/gpl.html&gt;.</span><br><span class="line">This is free software: you are free to change and redistribute it according to</span><br><span class="line">the license. There is NO WARRANTY, to the extent permitted by law.</span><br><span class="line"></span><br><span class="line">This product includes software developed by the OpenSSL Project</span><br><span class="line"><span class="keyword">for</span> use <span class="keyword">in</span> the OpenSSL Toolkit (http://www.openssl.org/).</span><br><span class="line"></span><br><span class="line">Compiled with OpenSSL 1.0.1e-fips 11 Feb 2013</span><br><span class="line">Running with OpenSSL 1.0.1e-fips 11 Feb 2013</span><br><span class="line">[root@p34044v ~]<span class="comment"># zabbix_agentd -V</span></span><br><span class="line">zabbix_agentd (daemon) (Zabbix) 4.0.9</span><br><span class="line">Revision 97a69d5d5a 5 June 2019, compilation time: Jun  7 2019 08:45:50</span><br><span class="line"></span><br><span class="line">Copyright (C) 2019 Zabbix SIA</span><br><span class="line">License GPLv2+: GNU GPL version 2 or later &lt;http://gnu.org/licenses/gpl.html&gt;.</span><br><span class="line">This is free software: you are free to change and redistribute it according to</span><br><span class="line">the license. There is NO WARRANTY, to the extent permitted by law.</span><br><span class="line"></span><br><span class="line">This product includes software developed by the OpenSSL Project</span><br><span class="line"><span class="keyword">for</span> use <span class="keyword">in</span> the OpenSSL Toolkit (http://www.openssl.org/).</span><br><span class="line"></span><br><span class="line">Compiled with OpenSSL 1.0.1e-fips 11 Feb 2013</span><br><span class="line">Running with OpenSSL 1.0.1e-fips 11 Feb 2013</span><br><span class="line">[root@p34044v ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="申请企业微信号"><a href="#申请企业微信号" class="headerlink" title="申请企业微信号"></a>申请企业微信号</h2><h5 id="申请企业号并记录相关信息"><a href="#申请企业号并记录相关信息" class="headerlink" title="申请企业号并记录相关信息"></a>申请企业号并记录相关信息</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">https://qy.weixin.qq.com</span><br><span class="line"></span><br><span class="line">后边需要用到的几个信息：</span><br><span class="line">    1.登录网页 - 我的企业 - 企业ID：xxxxx</span><br><span class="line">        或者：企业微信客户端：工作台 - 管理企业 - 企业信息 - 企业ID</span><br></pre></td></tr></table></figure><h5 id="创建应用"><a href="#创建应用" class="headerlink" title="创建应用"></a>创建应用</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">登录网页 - 应用与小程序 - 创建应用。创建完成后记录以下信息：</span><br><span class="line">    AgentId：xxxxx</span><br><span class="line">    Secret：SacUM-xxxxxxxxxx</span><br></pre></td></tr></table></figure><h5 id="添加通讯录（添加后才可接受告警消息）"><a href="#添加通讯录（添加后才可接受告警消息）" class="headerlink" title="添加通讯录（添加后才可接受告警消息）"></a>添加通讯录（添加后才可接受告警消息）</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">登录网页 - 通讯录 - 添加成员</span><br></pre></td></tr></table></figure><h2 id="设置Python脚本"><a href="#设置Python脚本" class="headerlink" title="设置Python脚本"></a>设置Python脚本</h2><h5 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y python-requests</span><br></pre></td></tr></table></figure><h5 id="准备Python脚本"><a href="#准备Python脚本" class="headerlink" title="准备Python脚本"></a>准备Python脚本</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">附录内有具体脚本内容，这里是使用Python脚本来实现的。</span><br><span class="line">脚本内有3项内容是必须根据自己情况做修改的。详情请看脚本备注</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.查看Zabbix Server脚本目录设置</span></span><br><span class="line">[root@localhost ~]<span class="comment"># grep AlertScriptsPath /etc/zabbix/zabbix_server.conf</span></span><br><span class="line"><span class="comment">### Option: AlertScriptsPath</span></span><br><span class="line"><span class="comment"># AlertScriptsPath=$&#123;datadir&#125;/zabbix/alertscripts</span></span><br><span class="line">AlertScriptsPath=/usr/lib/zabbix/alertscripts</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.编辑Python脚本</span></span><br><span class="line">vim /usr/lib/zabbix/alertscripts/weixin.py</span><br><span class="line">添加附录内脚本内容</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.给脚本执行权限</span></span><br><span class="line">chmod 755 /usr/lib/zabbix/alertscripts/weixin.py</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.测试脚本</span></span><br><span class="line">/usr/lib/zabbix/alertscripts/weixin.py name <span class="built_in">test</span> 123456</span><br><span class="line">    name：收件人账号（登录企业微信网站 - 通讯录 - 打开某个收件人 - 账号）</span><br><span class="line">    <span class="built_in">test</span>：标题?</span><br><span class="line">    123456：具体需要发送的内容</span><br><span class="line"></span><br><span class="line">如果没有错误的话，收件人将可以在手机APP企业微信上收到此消息。</span><br></pre></td></tr></table></figure><h5 id="手动建立日志文件并赋予写入权限"><a href="#手动建立日志文件并赋予写入权限" class="headerlink" title="手动建立日志文件并赋予写入权限"></a>手动建立日志文件并赋予写入权限</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">因为Python脚本设置了记录日志，但是脚本所在路径隶属于root组</span><br><span class="line">而Zabbix Server是使用zabbix用户运行的，对此目录没有写入权限</span><br><span class="line">所以这里先手动建立一个空的<span class="built_in">log</span>文件，并赋予所有用户写入权限</span><br><span class="line"></span><br><span class="line">touch /usr/lib/zabbix/alertscripts/weixin.log</span><br><span class="line">chmod 766 /usr/lib/zabbix/alertscripts/weixin.log</span><br></pre></td></tr></table></figure><h2 id="设置Zabbix-Server开启微信告警"><a href="#设置Zabbix-Server开启微信告警" class="headerlink" title="设置Zabbix Server开启微信告警"></a>设置Zabbix Server开启微信告警</h2><h5 id="添加告警媒介"><a href="#添加告警媒介" class="headerlink" title="添加告警媒介"></a>添加告警媒介</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">管理 - 报警媒介类型 - 创建媒体类型</span><br><span class="line">    名称：微信</span><br><span class="line">    类型：脚本</span><br><span class="line">    脚本名称：weixin.py</span><br><span class="line">    脚本参数：</span><br><span class="line">        &#123;ALERT.SENDTO&#125;</span><br><span class="line">        &#123;ALERT.SUBJECT&#125;</span><br><span class="line">        &#123;ALERT.MESSAGE&#125;</span><br></pre></td></tr></table></figure><h5 id="为用户添加报警媒介"><a href="#为用户添加报警媒介" class="headerlink" title="为用户添加报警媒介"></a>为用户添加报警媒介</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">管理 - 用户 - 报警媒介 - 添加</span><br><span class="line">    类型：微信</span><br><span class="line">    收件人：收件人账号（登录企业微信网站 - 通讯录 - 打开某个收件人 - 账号）</span><br><span class="line">    当启用时：1-7,00:00-24:00</span><br><span class="line">    如果存在严重性则使用：根据自己需要选择发送告警类型</span><br><span class="line">    已启用：必须勾选</span><br></pre></td></tr></table></figure><h5 id="打开触发器动作"><a href="#打开触发器动作" class="headerlink" title="打开触发器动作"></a>打开触发器动作</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1.管理 - 动作：这里默认是停用状态，需要手动开启</span><br><span class="line"></span><br><span class="line">2.管理 - 动作 - Report problems to Zabbix administrators</span><br><span class="line">    操作 - 编辑：查看【仅送到】选项是否是所有或者微信。</span><br><span class="line">    </span><br><span class="line">    关于这里的操作细节：</span><br><span class="line">    步骤：1-1（假如故障持续了1个小时，它也只发送一次。）</span><br><span class="line">             （如果改成1-0，0是表示不限制.无限发送)</span><br><span class="line">              (发送间隔是下边的【步骤持续时间】）</span><br></pre></td></tr></table></figure><h4 id="模拟测试"><a href="#模拟测试" class="headerlink" title="模拟测试"></a>模拟测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">将新某台被监控主机关机或zabbix-agentd暂停，查看是否能收到微信告警。</span><br></pre></td></tr></table></figure><h2 id="附录：使用普通微信接受消息"><a href="#附录：使用普通微信接受消息" class="headerlink" title="附录：使用普通微信接受消息"></a>附录：使用普通微信接受消息</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">成员无需下载企业微信客户端，直接用微信扫码关注微工作台，即可在微信中接收企业通知和使用企业应用。</span><br><span class="line"></span><br><span class="line">方法：登录企业微信管理页面 - 我的企业 - 微工作台 - 邀请关注的二维码</span><br><span class="line">    关注后即可。</span><br></pre></td></tr></table></figure><h2 id="附录：Python脚本内容"><a href="#附录：Python脚本内容" class="headerlink" title="附录：Python脚本内容"></a>附录：Python脚本内容</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment">#author: 1327133225@qq.com</span></span><br><span class="line"><span class="comment">#date: 2019-01-13</span></span><br><span class="line"><span class="comment">#comment: zabbix接入微信报警脚本</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置记录日志</span></span><br><span class="line">logging.basicConfig(level = logging.DEBUG, format = <span class="string">'%(asctime)s, %(filename)s, %(levelname)s, %(message)s'</span>,</span><br><span class="line">                datefmt = <span class="string">'%a, %d %b %Y %H:%M:%S'</span>,</span><br><span class="line">                filename = os.path.join(<span class="string">'/usr/lib/zabbix/alertscripts'</span>,<span class="string">'weixin.log'</span>),</span><br><span class="line">                filemode = <span class="string">'a'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 必须修改1:企业ID</span></span><br><span class="line">corpid=<span class="string">'wwxxxxxx'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 必须修改2：Secret</span></span><br><span class="line">appsecret=<span class="string">'xxxxxxxxxxxxxxxxxxxxxxxxxx'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 必须修改3:AgentId</span></span><br><span class="line">agentid=xxxxxxxxx</span><br><span class="line"><span class="comment">#获取accesstoken</span></span><br><span class="line">token_url=<span class="string">'https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid='</span> + corpid + <span class="string">'&amp;corpsecret='</span> + appsecret</span><br><span class="line">req=requests.get(token_url)</span><br><span class="line">accesstoken=req.json()[<span class="string">'access_token'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#发送消息</span></span><br><span class="line">msgsend_url=<span class="string">'https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token='</span> + accesstoken</span><br><span class="line"></span><br><span class="line">touser=sys.argv[<span class="number">1</span>]</span><br><span class="line">subject=sys.argv[<span class="number">2</span>]</span><br><span class="line"><span class="comment">#toparty='3|4|5|6'</span></span><br><span class="line">message=sys.argv[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">params=&#123;</span><br><span class="line">        <span class="string">"touser"</span>: touser,</span><br><span class="line"><span class="comment">#       "toparty": toparty,</span></span><br><span class="line">        <span class="string">"msgtype"</span>: <span class="string">"text"</span>,</span><br><span class="line">        <span class="string">"agentid"</span>: agentid,</span><br><span class="line">        <span class="string">"text"</span>: &#123;</span><br><span class="line">                <span class="string">"content"</span>: message</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"safe"</span>:<span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">req=requests.post(msgsend_url, data=json.dumps(params))</span><br><span class="line">logging.info(<span class="string">'sendto:'</span> + touser + <span class="string">';;subject:'</span> + subject + <span class="string">';;message:'</span> + message)</span><br></pre></td></tr></table></figure><h2 id="附录：shell脚本内容-待验证"><a href="#附录：shell脚本内容-待验证" class="headerlink" title="附录：shell脚本内容(待验证)"></a>附录：shell脚本内容(待验证)</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"><span class="comment">#set -x</span></span><br><span class="line">CorpID=<span class="string">"wwbc27916706540977"</span>                   <span class="comment">#我的企业下面的CorpID</span></span><br><span class="line">Secret=<span class="string">"6cMYoDUUdOiLjawS487dLr4SNp1Gku_nQTq22uV9gNM"</span>            <span class="comment">#创建的应用那有Secret</span></span><br><span class="line">GURL=<span class="string">"https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=<span class="variable">$CorpID</span>&amp;corpsecret=<span class="variable">$Secret</span>"</span></span><br><span class="line">Token=$(/usr/bin/curl -s -G <span class="variable">$GURL</span> |awk -F\": <span class="string">'&#123;print $4&#125;'</span>|awk -F\" <span class="string">'&#123;print $2&#125;'</span>)</span><br><span class="line"><span class="comment">#echo $Token</span></span><br><span class="line">PURL=<span class="string">"https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=<span class="variable">$Token</span>"</span></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">body</span></span>()&#123;</span><br><span class="line">        <span class="built_in">local</span> int agentid=1000002   <span class="comment">#改为AgentId 在创建的应用那里看</span></span><br><span class="line">        <span class="built_in">local</span> UserID=<span class="variable">$1</span>             <span class="comment">#发送的用户位于$1的字符串</span></span><br><span class="line">        <span class="built_in">local</span> PartyID=2           <span class="comment">#第一步看的通讯录中的部门ID</span></span><br><span class="line">        <span class="built_in">local</span> Msg=$(<span class="built_in">echo</span> <span class="string">"<span class="variable">$@</span>"</span> | cut -d<span class="string">" "</span> -f3-)</span><br><span class="line">        <span class="built_in">printf</span> <span class="string">'&#123;\n'</span></span><br><span class="line">        <span class="built_in">printf</span> <span class="string">'\t"touser": "'</span><span class="string">"<span class="variable">$UserID</span>"</span>\"<span class="string">",\n"</span></span><br><span class="line">        <span class="built_in">printf</span> <span class="string">'\t"toparty": "'</span><span class="string">"<span class="variable">$PartyID</span>"</span>\"<span class="string">",\n"</span></span><br><span class="line">        <span class="built_in">printf</span> <span class="string">'\t"msgtype": "text",\n'</span></span><br><span class="line">        <span class="built_in">printf</span> <span class="string">'\t"agentid": "'</span><span class="string">"<span class="variable">$agentid</span>"</span>\"<span class="string">",\n"</span></span><br><span class="line">        <span class="built_in">printf</span> <span class="string">'\t"text": &#123;\n'</span></span><br><span class="line">        <span class="built_in">printf</span> <span class="string">'\t\t"content": "'</span><span class="string">"<span class="variable">$Msg</span>"</span>\"<span class="string">"\n"</span></span><br><span class="line">        <span class="built_in">printf</span> <span class="string">'\t&#125;,\n'</span></span><br><span class="line">        <span class="built_in">printf</span> <span class="string">'\t"safe":"0"\n'</span></span><br><span class="line">        <span class="built_in">printf</span> <span class="string">'&#125;\n'</span></span><br><span class="line">&#125;</span><br><span class="line">/usr/bin/curl --data-ascii <span class="string">"<span class="variable">$(body $1 $2 $3)</span>"</span> <span class="variable">$PURL</span></span><br></pre></td></tr></table></figure><h2 id="附录：github脚本"><a href="#附录：github脚本" class="headerlink" title="附录：github脚本"></a>附录：github脚本</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/OneOaaS/weixin-alert</span><br><span class="line">使用教程参考：https://blog.51cto.com/11975865/2344314?<span class="built_in">source</span>=dra</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;微信现在是我们手机中必不可少的软件，通过它可以和朋友亲人聊天视频等。作为运维，让监控系统通过微信报警，及时提醒我们，保证线上服务稳定运行，这是SRE的职责所在。通过本教程学习，让zabbix  server增加微信报警媒介。&lt;/p&gt;
&lt;h2 id=&quot;环境&quot;&gt;&lt;a href=&quot;#环境&quot; class=&quot;headerlink&quot; title=&quot;环境&quot;&gt;&lt;/a&gt;环境&lt;/h2&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;[root@p34044v ~]&lt;span class=&quot;comment&quot;&gt;# cat /etc/redhat-release &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CentOS Linux release 7.7.1908 (Core)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@p34044v ~]&lt;span class=&quot;comment&quot;&gt;# python -V&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Python 2.7.5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@p34044v ~]&lt;span class=&quot;comment&quot;&gt;# zabbix_server -V&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;zabbix_server (Zabbix) 4.0.13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Revision 4e383bb6c5 2 October 2019, compilation time: Oct  2 2019 08:45:35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Copyright (C) 2019 Zabbix SIA&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;License GPLv2+: GNU GPL version 2 or later &amp;lt;http://gnu.org/licenses/gpl.html&amp;gt;.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;This is free software: you are free to change and redistribute it according to&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;the license. There is NO WARRANTY, to the extent permitted by law.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;This product includes software developed by the OpenSSL Project&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; use &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; the OpenSSL Toolkit (http://www.openssl.org/).&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Compiled with OpenSSL 1.0.1e-fips 11 Feb 2013&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Running with OpenSSL 1.0.1e-fips 11 Feb 2013&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@p34044v ~]&lt;span class=&quot;comment&quot;&gt;# zabbix_agentd -V&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;zabbix_agentd (daemon) (Zabbix) 4.0.9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Revision 97a69d5d5a 5 June 2019, compilation time: Jun  7 2019 08:45:50&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Copyright (C) 2019 Zabbix SIA&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;License GPLv2+: GNU GPL version 2 or later &amp;lt;http://gnu.org/licenses/gpl.html&amp;gt;.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;This is free software: you are free to change and redistribute it according to&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;the license. There is NO WARRANTY, to the extent permitted by law.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;This product includes software developed by the OpenSSL Project&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; use &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; the OpenSSL Toolkit (http://www.openssl.org/).&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Compiled with OpenSSL 1.0.1e-fips 11 Feb 2013&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;Running with OpenSSL 1.0.1e-fips 11 Feb 2013&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;[root@p34044v ~]&lt;span class=&quot;comment&quot;&gt;#&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="监控技术" scheme="https://wandouduoduo.netlify.com/categories/%E7%9B%91%E6%8E%A7%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Zabbix" scheme="https://wandouduoduo.netlify.com/categories/%E7%9B%91%E6%8E%A7%E6%8A%80%E6%9C%AF/Zabbix/"/>
    
    
      <category term="Zabbix" scheme="https://wandouduoduo.netlify.com/tags/Zabbix/"/>
    
  </entry>
  
  <entry>
    <title>zabbix使用LDAP认证并批量导入用户</title>
    <link href="https://wandouduoduo.netlify.com/articles/970a7010.html"/>
    <id>https://wandouduoduo.netlify.com/articles/970a7010.html</id>
    <published>2019-10-29T05:57:07.000Z</published>
    <updated>2019-10-31T10:40:08.777Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>公司用openldap搭了一套ldap认证系统，用于统一内部各个系统的账户，避免每次添加或删除用户还得一个个登陆上去操作，使账户密码统一，能减轻很多工作和保证安全性，今天是想把ldap与zabbix进行结合。</p><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>centos7.x</p><p>zabbix4.0.x</p><a id="more"></a><h2 id="配置zabbix"><a href="#配置zabbix" class="headerlink" title="配置zabbix"></a>配置zabbix</h2><h4 id="安装php-ldap模块"><a href="#安装php-ldap模块" class="headerlink" title="安装php-ldap模块"></a><strong>安装php-ldap模块</strong></h4><p>php需要这个模块来进行ldap认证，安装方法网上都有这里只列举一种；</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#安装</span></span><br><span class="line">yum install php-ldap</span><br><span class="line"><span class="comment">#验证</span></span><br><span class="line">》/usr/<span class="built_in">local</span>/php/bin/php -m|grep ldap</span><br><span class="line">ldap</span><br></pre></td></tr></table></figure><h4 id="zabbix页面配置"><a href="#zabbix页面配置" class="headerlink" title="zabbix页面配置"></a><strong>zabbix页面配置</strong></h4><p><img src="/articles/970a7010/1.png" alt></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">LDAP host：访问ldap的地址。格式：ldap://ip地址</span><br><span class="line">Port：默认389</span><br><span class="line">Base DN: dc=tencent,dc=com,也就是域名(tencent.com)</span><br><span class="line">Search attribute: uid，属性值，网上有填sAMAccountName。</span><br><span class="line"></span><br><span class="line">Bind DN： cn=Admin, ou=People, dc=tencent, dc=com。 cn就是在DC中创建的LDAPuser用户， ou就是LDAPuser属于哪个ou，dc=tencent和dc=com不在解释。</span><br><span class="line"></span><br><span class="line">Bind password：xxxx ，改密码为LDAPuser用户的密码</span><br><span class="line">Login：Admin</span><br><span class="line">User password：在DC中创建Admin用户的密码</span><br></pre></td></tr></table></figure><p>点击”Test”。如果没有报什么错误，就可以点击”Save”。现在ZABBIX的LDAP认证方式就已经配置完成了。</p><h4 id="用户配置"><a href="#用户配置" class="headerlink" title="用户配置"></a><strong>用户配置</strong></h4><p>上述配置完成后已经把ldap和zabbix打通了，用户登录zabbix时，会先到ldap认证，判断用户是否有效；但是zabbix不会把ldap的用户同步过了，你要登录，得先在zabbix上创建和ldap内同名的用户才行。</p><p><img src="/articles/970a7010/2.png" alt></p><p>验证登录</p><p><img src="/articles/970a7010/3.png" alt></p><h4 id="同步用户"><a href="#同步用户" class="headerlink" title="同步用户"></a>同步用户</h4><p>上面显得很被动了，于是写个脚本，定时往zabbix数据库插入用户，这样就免去手工创建的用户的烦恼。</p><p>先需要安装ldap客户端工具</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install openldap-clients</span><br></pre></td></tr></table></figure><p><img src="/articles/970a7010/4.png" alt></p><p>先查询测试</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ldapsearch -x -LLL -H ldap://xxxxx -b ou=People,dc=xxxxx,dc=net -D <span class="string">"cn=admin,dc=xxxxxx,dc=net"</span> -w 密码 displayName|sed <span class="string">'/^$/d'</span>|sed <span class="string">'1d'</span></span><br></pre></td></tr></table></figure><p><img src="/articles/970a7010/5.png" alt></p><p>uid是zabbix的alias字段，displayName需要base64解码成中文名</p><p>同步脚本如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="keyword">import</span> commands</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="comment"># 避免中文乱码</span></span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">ldap_list=<span class="string">'/usr/local/zabbix/sh/ldap.list'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 先从ldap服务器把用户数据导入文件</span></span><br><span class="line">ldap_users=commands.getoutput(<span class="string">"ldapsearch -x -LLL -H ldap://xxxxxx -b ou=People,dc=xxxxx,dc=net -D "</span>cn=admin,dc=xxxxx,dc=net<span class="string">" -w xxxxx displayName|sed '/^$/d'|sed '1d' &gt; %s"</span> % ldap_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 因为zabbix的表没有自增id，所以每次操作都会记录下id，并递增</span></span><br><span class="line">idfile = <span class="string">'/usr/local/zabbix/sh/userid'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理元数据，把文件里的每行数据转化成方便使用的格式</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_item</span><span class="params">(fobj)</span>:</span></span><br><span class="line">    item = [<span class="string">''</span>, <span class="string">''</span>, <span class="string">''</span>]</span><br><span class="line">    <span class="keyword">for</span> no,line <span class="keyword">in</span> enumerate(fobj):</span><br><span class="line">        <span class="comment">#print no,line</span></span><br><span class="line">        slot = no % <span class="number">2</span></span><br><span class="line">        item[slot] = line.rstrip()</span><br><span class="line">        <span class="keyword">if</span> slot == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_user</span><span class="params">()</span>:</span></span><br><span class="line">    conn = pymysql.connect(host=<span class="string">'2.2.2.2'</span>, port=<span class="number">3306</span>, user=<span class="string">'zabbix'</span>, passwd=<span class="string">'zabbix'</span>, db=<span class="string">'zabbix'</span>, charset=<span class="string">'utf8'</span>)</span><br><span class="line">    cur = conn.cursor()</span><br><span class="line">    fs = open(idfile,<span class="string">'r'</span>)</span><br><span class="line">    n = int(fs.read())</span><br><span class="line">    fs.close()</span><br><span class="line">    <span class="keyword">with</span> open(ldap_list) <span class="keyword">as</span> fobj:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> get_item(fobj):</span><br><span class="line">            n += <span class="number">1</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                s=<span class="string">'&#123;0&#125;&#123;1&#125;&#123;2&#125;'</span>.format(*item)</span><br><span class="line">                l = re.search(<span class="string">'uid=(.*),ou.*:: (.*)'</span>,s)</span><br><span class="line">                name = base64.b64decode(l.group(<span class="number">2</span>))</span><br><span class="line">                alias = l.group(<span class="number">1</span>)</span><br><span class="line">                search = cur.execute(<span class="string">"""select * from users where alias = %s"""</span>, (alias, ))</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> search:</span><br><span class="line">                    sql = <span class="string">"insert into users(userid,name,alias) values ('%s','%s','%s');"</span> % (n,name,alias)</span><br><span class="line">                    insert = cur.execute(sql)</span><br><span class="line">                    <span class="keyword">if</span> sql:</span><br><span class="line">                        <span class="keyword">print</span> <span class="string">"User %s Add Succed!"</span> % alias</span><br><span class="line">                        <span class="keyword">print</span> sql</span><br><span class="line">            <span class="keyword">except</span> AttributeError <span class="keyword">as</span> e:</span><br><span class="line">                <span class="keyword">print</span> e</span><br><span class="line">    conn.commit()   <span class="comment">#这步很必要，不然插入的数据不生效</span></span><br><span class="line">    cur.close()</span><br><span class="line">    conn.close()</span><br><span class="line">    fe = open(idfile,<span class="string">'w'</span>)</span><br><span class="line">    fe.write(str(n))</span><br><span class="line">    fe.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    insert_user()</span><br></pre></td></tr></table></figure><p>执行脚本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python insert_sql.py</span><br></pre></td></tr></table></figure><p><img src="/articles/970a7010/6.png" alt></p><p>到页面用户中就可看到</p><p><img src="/articles/970a7010/7.png" alt></p><p>登录下，认证是成功的，接下来，你可以对用户进行分组和授权了</p><h2 id="LDAP挂掉后该怎么办"><a href="#LDAP挂掉后该怎么办" class="headerlink" title="LDAP挂掉后该怎么办"></a>LDAP挂掉后该怎么办</h2><p>更改认证类型为Internal，然后使用Admin登陆，如果忘记密码，也可以重置Admin密码为admin。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#登录mysql，</span></span><br><span class="line"></span><br><span class="line">use zabbix;</span><br><span class="line"></span><br><span class="line">select userid,<span class="built_in">alias</span>,passwd from zabbix.users;</span><br><span class="line"></span><br><span class="line">update zabbix.users <span class="built_in">set</span> passwd=md5(<span class="string">"admin"</span>) <span class="built_in">where</span> userid=<span class="string">'1'</span>;</span><br><span class="line"></span><br><span class="line">update zabbix.config <span class="built_in">set</span> authentication_type=0;</span><br><span class="line"></span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure><p>至此，zabbix  ldap认证教程已经全面完成。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;公司用openldap搭了一套ldap认证系统，用于统一内部各个系统的账户，避免每次添加或删除用户还得一个个登陆上去操作，使账户密码统一，能减轻很多工作和保证安全性，今天是想把ldap与zabbix进行结合。&lt;/p&gt;
&lt;h2 id=&quot;环境&quot;&gt;&lt;a href=&quot;#环境&quot; class=&quot;headerlink&quot; title=&quot;环境&quot;&gt;&lt;/a&gt;环境&lt;/h2&gt;&lt;p&gt;centos7.x&lt;/p&gt;
&lt;p&gt;zabbix4.0.x&lt;/p&gt;
    
    </summary>
    
      <category term="监控技术" scheme="https://wandouduoduo.netlify.com/categories/%E7%9B%91%E6%8E%A7%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Zabbix" scheme="https://wandouduoduo.netlify.com/categories/%E7%9B%91%E6%8E%A7%E6%8A%80%E6%9C%AF/Zabbix/"/>
    
    
      <category term="Zabbix" scheme="https://wandouduoduo.netlify.com/tags/Zabbix/"/>
    
  </entry>
  
  <entry>
    <title>Nat回环(Lan--&gt;Lan端口映射原理)</title>
    <link href="https://wandouduoduo.netlify.com/articles/6fa007b.html"/>
    <id>https://wandouduoduo.netlify.com/articles/6fa007b.html</id>
    <published>2019-10-25T10:46:58.000Z</published>
    <updated>2019-11-01T02:54:48.852Z</updated>
    
    <content type="html"><![CDATA[<h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p>局域网内网有服务器对外发布，基于对服务器的保护，内网用户需通过域名或者公网ip来访问内网服务器。如下图所示：</p><p> <img src="/articles/6fa007b/1.jpg" alt="img"></p><h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><p>DNAT：转换目标ip地址。</p><p>SNAT：转换源ip地址。</p><a id="more"></a><h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>将外网202.96.128.5的80端口映射至内网192.168.2.10的80端口，外网地址对应有域名，以对外服务。同时，内网无DNS服务器，内网用户通过公网DNS解析通过同样的公网域名访问内网web服务器，要求防火墙能将内网访问该域名80端口的请求再次定向到内网服务器，使得内部访问公网域名的数据直接返回给内网服务器，以节省互联网带宽。</p><h2 id="数据流走向分析"><a href="#数据流走向分析" class="headerlink" title="数据流走向分析"></a>数据流走向分析</h2><p>内网服务器的真实ip和访问端口是192.168.2.10：80，要能够访问到这个服务器资源，必须需要把访问的目标ip 202.96.128.5转换成192.168.2.10，这样访问数据包才会转回内网，否则数据包交到公网上，将访问不到真实的服务器。那么需要在设备上做一次DNAT（对访问服务器的数据做目标ip的转换）。</p><p>如果只在设备上做一次DNAT上网转换的数据包和转发流程如下图所示:</p><p><img src="/articles/6fa007b/2.jpg" alt="img"></p><p>文中所列的数据包的结构均为：<img src="http://1874.img.pp.sohu.com.cn/images/blog/2010/7/7/16/11/12a5f3b367eg214.jpg" alt="img"></p><p>第一步：封装访问到目标ip为202.96.128.5的数据由客户端发出</p><p>第二步：在设备的LAN口接受到数据包，匹配DNAT规则，对数据包进行目标IP的转换</p><p>第三步：经过设备转换的数据包从lan口发出，交给局域网的真实服务器192.168.2.10.</p><p>第四步：服务器对访问请求做回应，它收到数据包的源ip是192.168.2.3，成为封装回应的目标ip，那么数据包有内网服务器直接发给内网主机</p><p>第五步：内网主机收到一个源ip为192.168.2.10的回应，和它发给目标ip为202.96.128.5的请求不一致，所以数据包直接被丢弃。在客户端看来，访问服务器失败。</p><p>由以上的数据包流程可以看出，要保证内网客户端能访问到服务器，只做DNAT是不够的。</p><p>那么需要服务器将回应数据发回给网关设备，再由网关设备转回给客户端，客户端才会接受数据。流程图应该如下图所示：</p><p><img src="/articles/6fa007b/3.jpg" alt="img"></p><p>那么要让服务器的数据发给网关，那么在服务器接收到的数据源IP是网关的IP，所以网关</p><p>发给服务器的数据包结构应该是：<img src="http://1874.img.pp.sohu.com.cn/images/blog/2010/7/7/16/13/12a5f3cfb78g215.jpg" alt="img"></p><p>这个数据包，和只做了一次DNAT从网关处发出的数据包：<img src="http://1821.img.pp.sohu.com.cn/images/blog/2012/3/20/17/10/u67435314_136eff6da7fg215.jpg" alt="img"></p><p>相比，源IP 做了转换。所以才需要在网关设备处再做一次SNAT。</p><p>如果网关要代理内网上外网的话，那么也启用了SNAT，进行私有地址到公网地址的转换。</p><p>所以这里的SNAT，必须要设置条件，符合条件才转换，而且要比上网的SNAT优先匹配。否则会对上网产生影响。</p><p>先经过网关设备DNAT处理，再经过SNAT处理的数据包走向如下图：</p><p><img src="/articles/6fa007b/4.jpg" alt="img"></p><p>由于在网关处做了DNAT和SNAT的转换，每做一次转换，设备都会记录一个链接，当服务器回应数据再经过网关时，网关会根据链接再做一次DNAT和SNAT，那么数据包发回给访问客户端的是:<img src="http://1871.img.pp.sohu.com.cn/images/blog/2012/3/20/17/11/u67435314_136eff82fa2g214.jpg" alt="img">，对于客户端来说，它之前是发给202.96.128.5的访问请求，所以会接受数据包。</p><p>此外对于网关设备来说，数据包是由LAN传给LAN 的，所以还需放通防火墙的LAN–LAN规则。</p><h2 id="应用举例"><a href="#应用举例" class="headerlink" title="应用举例"></a>应用举例</h2><p><strong>用户需求：</strong></p><p>用户内网有一台服务器：192.168.0.1，WAN1 口使用光纤接入，有公网IP 地址（202.x.x.x），该公网IP 地址对应一个域名：<a href="http://www.xxx.com，已经使用DNAT" target="_blank" rel="noopener">www.xxx.com，已经使用DNAT</a> 做端口映射把服务器发布至公网，并可以在公网访问<a href="http://www.xxx.com；现在要求在局域网（192.168.0.0/24" target="_blank" rel="noopener">www.xxx.com；现在要求在局域网（192.168.0.0/24</a> 连接在LAN 口），也可以通过访问域名：<a href="http://www.xxx.com" target="_blank" rel="noopener">www.xxx.com</a> 达到访问web server：192.168.0.1，规则如下：</p><p>用一国内产品演示：</p><p>1）      做端口映射，注意外网接口选择LAN 口</p><p><img src="/articles/6fa007b/Nat%E5%9B%9E%E7%8E%AF-Lan-Lan%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%E5%8E%9F%E7%90%86%5C5.jpg" alt="img"> </p><p>2）  做SNAT：将源地址转换成LAN 口。</p><p><img src="/articles/6fa007b/6.jpg" alt="img"></p><p>如果有Lan-Lan规则，放通规则。开放LAN1→LAN1 的防火墙规则：</p><p><img src="/articles/6fa007b/7.jpg" alt="img"></p><p>注意事项：</p><p>a）如果服务器在DMZ 区，则第二步可以省略，但要注意放通LAN→DMZ 的防火墙规则。</p><p>b）上面的方法也适用于WAN 口为ADSL 拨号使用动态域名的情况。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;场景&quot;&gt;&lt;a href=&quot;#场景&quot; class=&quot;headerlink&quot; title=&quot;场景&quot;&gt;&lt;/a&gt;场景&lt;/h2&gt;&lt;p&gt;局域网内网有服务器对外发布，基于对服务器的保护，内网用户需通过域名或者公网ip来访问内网服务器。如下图所示：&lt;/p&gt;
&lt;p&gt; &lt;img src=&quot;/articles/6fa007b/1.jpg&quot; alt=&quot;img&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;名词解释&quot;&gt;&lt;a href=&quot;#名词解释&quot; class=&quot;headerlink&quot; title=&quot;名词解释&quot;&gt;&lt;/a&gt;名词解释&lt;/h2&gt;&lt;p&gt;DNAT：转换目标ip地址。&lt;/p&gt;
&lt;p&gt;SNAT：转换源ip地址。&lt;/p&gt;
    
    </summary>
    
      <category term="网络技术" scheme="https://wandouduoduo.netlify.com/categories/%E7%BD%91%E7%BB%9C%E6%8A%80%E6%9C%AF/"/>
    
    
      <category term="Network" scheme="https://wandouduoduo.netlify.com/tags/Network/"/>
    
  </entry>
  
  <entry>
    <title>zabbix教程之自动注册</title>
    <link href="https://wandouduoduo.netlify.com/articles/276c6656.html"/>
    <id>https://wandouduoduo.netlify.com/articles/276c6656.html</id>
    <published>2019-10-25T02:25:23.000Z</published>
    <updated>2019-11-01T07:15:03.101Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>对于监控服务器越来越多的情况，如果还单独一个一个添加，那效率也太低，因此就要实现批量添加监控服务器的操作，Zabbix提供两种批量自动监控的方式：</p><p><strong>自动发现：由服务端主动发起，Zabbix Server开启发现进程，定时扫描局域网中IP服务器、设备。</strong></p><p><strong>自动注册：由客户端主动发起，客户端必须安装并启动Agentd，否则无法被自动注册添加至主机列表。对于使用SNMP的就要采用自动发现了。</strong></p><p>本篇教程就是自动注册，让客户端自动向Server去注册。</p><a id="more"></a><h2 id="教程"><a href="#教程" class="headerlink" title="教程"></a>教程</h2><h4 id="zabbix-agent批量安装脚本"><a href="#zabbix-agent批量安装脚本" class="headerlink" title="zabbix-agent批量安装脚本"></a>zabbix-agent批量安装脚本</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 功能：centos6.x或7.x都可以自动安装最新稳定版4.0.x agent</span></span><br><span class="line"></span><br><span class="line">vernum=`cat /etc/redhat-release|sed -r <span class="string">'s/.* ([0-9]+)\..*/\1/'</span>`</span><br><span class="line"><span class="comment"># vernum也可以这样获取： rpm -q centos-release|cut -d- -f3</span></span><br><span class="line"></span><br><span class="line">wget http://repo.zabbix.com/zabbix/4.0/rhel/<span class="variable">$&#123;vernum&#125;</span>/x86_64/zabbix-agent-4.0.9-3.el<span class="variable">$&#123;vernum&#125;</span>.x86_64.rpm</span><br><span class="line"></span><br><span class="line">rpm -ivh zabbix-agent-4.0.9-3.el<span class="variable">$&#123;vernum&#125;</span>.x86_64.rpm</span><br><span class="line"></span><br><span class="line">sed -i.ori <span class="string">'s#Server=127.0.0.1#Server=10.216.1.106#'</span> /etc/zabbix/zabbix_agentd.conf</span><br><span class="line">sed -i.ori <span class="string">'s#ServerActive=127.0.0.1#ServerActive=10.216.1.106#'</span> /etc/zabbix/zabbix_agentd.conf</span><br><span class="line">sed -i.ori <span class="string">'s#Hostname=Zabbix server#Hostname='</span>$(hostname)<span class="string">'#'</span> /etc/zabbix/zabbix_agentd.conf</span><br><span class="line">sed -i.ori <span class="string">'180a HostMetadataItem=system.uname'</span> /etc/zabbix/zabbix_agentd.conf</span><br><span class="line"></span><br><span class="line">service zabbix-agent start</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$vernum</span> == 6 ];<span class="keyword">then</span></span><br><span class="line">        chkconfig --add zabbix-agent</span><br><span class="line">        chkconfig zabbix-agent on</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">        systemctl <span class="built_in">enable</span>  zabbix-agent.service</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure><h4 id="zabbix-server页面配置"><a href="#zabbix-server页面配置" class="headerlink" title="zabbix-server页面配置"></a>zabbix-server页面配置</h4><p>配置—-&gt;动作—–&gt;事件源选择自动注册—-&gt;创建动作</p><p><img src="/articles/276c6656/1.png" alt></p><p>触发条件</p><p><img src="/articles/276c6656/2.png" alt></p><p>我这里因为都是linux服务器，并且服务器hostname都有相同后缀，所以可以设置两个条件共同满足才可以。</p><p><img src="/articles/276c6656/3.png" alt></p><p>选择操作—-&gt;添加操作：添加主机，添加群组、链接到模板</p><p><img src="/articles/276c6656/4.png" alt></p><p>点击添加完成</p><p>等待几分钟 ，新的agent就会自动注册到server上了。可以查看server和agent日志查看</p><p><img src="/articles/276c6656/5.png" alt></p><p><img src="/articles/276c6656/6.png" alt></p><h2 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h2><p>页面操作是主机元数据的值 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@centos ~]<span class="comment"># uname</span></span><br><span class="line">Linux</span><br></pre></td></tr></table></figure><p>或者是</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@centos ~]<span class="comment"># zabbix_get -s 192.168.11.12 -p 10050 -k "system.uname"</span></span><br><span class="line">Linux ltt02.xxx.net 3.10.0-693.el7.x86_64 <span class="comment">#1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64</span></span><br></pre></td></tr></table></figure><p>获取到的就是agent配置中，把类型赋值给主机元数据，在条件中就可以设定</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HostMetadataItem=system.uname</span><br></pre></td></tr></table></figure><p>同理：hostname也是一样的。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目的&quot;&gt;&lt;a href=&quot;#目的&quot; class=&quot;headerlink&quot; title=&quot;目的&quot;&gt;&lt;/a&gt;目的&lt;/h2&gt;&lt;p&gt;对于监控服务器越来越多的情况，如果还单独一个一个添加，那效率也太低，因此就要实现批量添加监控服务器的操作，Zabbix提供两种批量自动监控的方式：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;自动发现：由服务端主动发起，Zabbix Server开启发现进程，定时扫描局域网中IP服务器、设备。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;自动注册：由客户端主动发起，客户端必须安装并启动Agentd，否则无法被自动注册添加至主机列表。对于使用SNMP的就要采用自动发现了。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本篇教程就是自动注册，让客户端自动向Server去注册。&lt;/p&gt;
    
    </summary>
    
      <category term="监控技术" scheme="https://wandouduoduo.netlify.com/categories/%E7%9B%91%E6%8E%A7%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Zabbix" scheme="https://wandouduoduo.netlify.com/categories/%E7%9B%91%E6%8E%A7%E6%8A%80%E6%9C%AF/Zabbix/"/>
    
    
      <category term="Zabbix" scheme="https://wandouduoduo.netlify.com/tags/Zabbix/"/>
    
  </entry>
  
  <entry>
    <title>Zabbix在Ubuntu 14.04上apt-get安装</title>
    <link href="https://wandouduoduo.netlify.com/articles/aeb6452a.html"/>
    <id>https://wandouduoduo.netlify.com/articles/aeb6452a.html</id>
    <published>2019-10-24T14:25:16.000Z</published>
    <updated>2019-11-01T07:15:36.055Z</updated>
    
    <content type="html"><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>安装Apache、Mysql、Php、zabbix</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update </span><br><span class="line">sudo apt-get install apache2 mysql-server libapache2-mod-php5 php5-gd php5-mysql  php5-common zabbix-server-mysql zabbix-frontend-php</span><br></pre></td></tr></table></figure><a id="more"></a><h2 id="服务端配置"><a href="#服务端配置" class="headerlink" title="服务端配置"></a>服务端配置</h2><h4 id="配置数据库连接"><a href="#配置数据库连接" class="headerlink" title="配置数据库连接"></a>配置数据库连接</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/zabbix/zabbix_server.conf</span><br></pre></td></tr></table></figure><p>修改相关</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DBName=zabbix</span><br><span class="line">DBUser=zabbix</span><br><span class="line">DBPassword=zabbix</span><br><span class="line">#非必需，但推荐</span><br><span class="line">StartDiscoverers=5</span><br></pre></td></tr></table></figure><h4 id="创建mysql账号"><a href="#创建mysql账号" class="headerlink" title="创建mysql账号"></a>创建mysql账号</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql -u root -p</span><br><span class="line">mysql&gt; create user &apos;zabbix&apos;@&apos;localhost&apos; identified by &apos;zabbix&apos;;</span><br><span class="line">mysql&gt; create database zabbix default character set utf8;</span><br><span class="line">mysql&gt; grant all privileges on zabbix.* to &apos;zabbix&apos;@&apos;localhost&apos;;</span><br><span class="line">mysql&gt; flush privileges;</span><br><span class="line">mysql&gt; exit;</span><br></pre></td></tr></table></figure><h4 id="导入初始化数据"><a href="#导入初始化数据" class="headerlink" title="导入初始化数据"></a>导入初始化数据</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd /usr/share/zabbix-server-mysql/</span><br><span class="line">sudo gunzip *.gz</span><br><span class="line">mysql -u zabbix -p zabbix &lt; schema.sql</span><br><span class="line">mysql -u zabbix -p zabbix &lt; images.sql</span><br><span class="line">mysql -u zabbix -p zabbix &lt; data.sql</span><br></pre></td></tr></table></figure><h4 id="修改-PHP-参数"><a href="#修改-PHP-参数" class="headerlink" title="修改 PHP 参数"></a>修改 PHP 参数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/php5/apache2/php.ini</span><br></pre></td></tr></table></figure><p>修改项：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">post_max_size = 16M</span><br><span class="line">max_execution_time = 300</span><br><span class="line">max_input_time = 300</span><br><span class="line">date.timezone = &quot;Asia/Shanghai&quot;</span><br></pre></td></tr></table></figure><h4 id="配置网页"><a href="#配置网页" class="headerlink" title="配置网页"></a>配置网页</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /usr/share/doc/zabbix-frontend-php/examples/zabbix.conf.php.example /etc/zabbix/zabbix.conf.php</span><br><span class="line">sudo vim /etc/zabbix/zabbix.conf.php</span><br></pre></td></tr></table></figure><p>修改项</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$DB[&apos;DATABASE&apos;] = &apos;zabbix&apos;;</span><br><span class="line">$DB[&apos;USER&apos;] = &apos;zabbix&apos;;</span><br><span class="line">$DB[&apos;PASSWORD&apos;] = &apos;zabbix&apos;</span><br></pre></td></tr></table></figure><p>配置apache</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo cp /usr/share/doc/zabbix-frontend-php/examples/apache.conf /etc/apache2/conf-available/zabbix.conf</span><br><span class="line">sudo a2enconf zabbix.conf</span><br><span class="line">sudo a2enmod alias</span><br><span class="line">sudo service apache2 restart</span><br></pre></td></tr></table></figure><h4 id="配置-zabbix-server-启动"><a href="#配置-zabbix-server-启动" class="headerlink" title="配置 zabbix server 启动"></a>配置 zabbix server 启动</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/default/zabbix-server</span><br></pre></td></tr></table></figure><p>修改项：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">START=yes</span><br></pre></td></tr></table></figure><p>启动：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo service zabbix-server start</span><br></pre></td></tr></table></figure><h4 id="本机监控"><a href="#本机监控" class="headerlink" title="本机监控"></a>本机监控</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install zabbix-agent</span><br><span class="line">sudo service zabbix-agent restart</span><br></pre></td></tr></table></figure><h4 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http://xxx.xxx.xxx.xxx/zabbix</span><br></pre></td></tr></table></figure><p>缺省的账户：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Username = admin</span><br><span class="line">Password = zabbix</span><br></pre></td></tr></table></figure><h2 id="客户端配置"><a href="#客户端配置" class="headerlink" title="客户端配置"></a>客户端配置</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install zabbix-agent</span><br></pre></td></tr></table></figure><p>修改配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/zabbix/zabbix_agentd.conf</span><br></pre></td></tr></table></figure><p>调整项</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Server=127.0.0.1 #修改为 zabbix server 服务器的IP，如果有网关或被监控机为虚拟机也加上母机的IP</span><br><span class="line">ServerActive=127.0.0.1 #修改为 zabbix server 服务器的IP</span><br><span class="line">Hostname=Zabbix server #修改为网页里面添加的Hostname，需要保持一致。</span><br></pre></td></tr></table></figure><h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p><strong>中文显示</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install language-pack-zh-hans</span><br></pre></td></tr></table></figure><p><a href="http://www.ttlsa.com/monitor/zabbix/" target="_blank" rel="noopener">zabbix</a>是一个多语言监控系统，默认使用英文并且也支持中文语言，详见《<a href="http://www.ttlsa.com/zabbix/zabbix-convert-into-chinese-8-ttlsa/" target="_blank" rel="noopener">zabbix汉化方法</a>》，但是近期有人反映说zabbix里面看不到中文语言.请往下看</p><p><strong>zabbix不支持中文图</strong></p><p><img src="/articles/aeb6452a/1.png" alt="Linux"></p><p><strong>开启zabbix对中文的支持</strong></p><p>原来zabbix默认把对中文的支持给关闭了，我们需要修改zabbix的<a href="http://www.ttlsa.com/php/" target="_blank" rel="noopener">php</a>源文件. 修改站点根目录下include/locales.inc.php文件.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim include/locales.inc.php</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">getLocales</span></span>() &#123;</span><br><span class="line">        <span class="built_in">return</span> array(</span><br><span class="line">                <span class="string">'en_GB'</span> =&gt; array(<span class="string">'name'</span> =&gt; _(<span class="string">'English (en_GB)'</span>),        <span class="string">'display'</span> =&gt; <span class="literal">true</span>),</span><br><span class="line">                <span class="string">'en_US'</span> =&gt; array(<span class="string">'name'</span> =&gt; _(<span class="string">'English (en_US)'</span>),        <span class="string">'display'</span> =&gt; <span class="literal">true</span>),</span><br><span class="line">                <span class="string">'bg_BG'</span> =&gt; array(<span class="string">'name'</span> =&gt; _(<span class="string">'Bulgarian (bg_BG)'</span>),      <span class="string">'display'</span> =&gt; <span class="literal">true</span>),</span><br><span class="line">                <span class="string">'zh_CN'</span> =&gt; array(<span class="string">'name'</span> =&gt; _(<span class="string">'Chinese (zh_CN)'</span>),        <span class="string">'display'</span> =&gt; <span class="literal">true</span>),</span><br><span class="line">                //原本这里为<span class="literal">false</span>,请改为<span class="literal">true</span></span><br><span class="line">                ...........代码省略掉........</span><br><span class="line">        );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>中文乱码</strong></p><p>1、历史记录处出现 ???? 乱码：</p><p><img src="/articles/aeb6452a/2.png" alt="img"></p><p>出现原因：</p><p>mysql数据库默认字符集为 latin1，而 zabbix 需要使用 utf8，在初始化创建 zabbix 库时没有指定具体的字符集，倒入三张表时会继承 Mysql 的默认字符集，所以此处会出现乱码；</p><p><img src="/articles/aeb6452a/3.png" alt="img"></p><p>解决办法：</p><p>1、将 zabbix 数据库中的表备份；</p><p>2、手动删除 zabbix 数据库；</p><p>3、重新创建 zabbix 库时手动指定字符集为 utf8；</p><p>4、将倒出的 sql 文件中字符集为latin1的表字符集替换为 utf8；</p><p>5、将备份的zabbix库重新倒入即可；</p><p><img src="/articles/aeb6452a/4.png" alt="img"></p><p><img src="/articles/aeb6452a/5.png" alt="img"></p><p><img src="/articles/aeb6452a/6.png" alt="img"></p><p><img src="/articles/aeb6452a/7.png" alt="img"></p><p><img src="/articles/aeb6452a/8.png" alt="img"></p><p><img src="/articles/aeb6452a/9.png" alt="img"></p><p>此时重新访问 zabbix web页面，点击几次菜单，历史记录处一切正常；</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h2&gt;&lt;p&gt;安装Apache、Mysql、Php、zabbix&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get update &lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;sudo apt-get install apache2 mysql-server libapache2-mod-php5 php5-gd php5-mysql  php5-common zabbix-server-mysql zabbix-frontend-php&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="监控技术" scheme="https://wandouduoduo.netlify.com/categories/%E7%9B%91%E6%8E%A7%E6%8A%80%E6%9C%AF/"/>
    
      <category term="Zabbix" scheme="https://wandouduoduo.netlify.com/categories/%E7%9B%91%E6%8E%A7%E6%8A%80%E6%9C%AF/Zabbix/"/>
    
    
      <category term="Zabbix" scheme="https://wandouduoduo.netlify.com/tags/Zabbix/"/>
    
  </entry>
  
</feed>
